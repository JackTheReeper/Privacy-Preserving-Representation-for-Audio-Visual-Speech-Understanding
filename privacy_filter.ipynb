{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmTO7x3UuIKd3q+8m7ZBiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyAgarwal11/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/blob/main/privacy_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preliminaries**"
      ],
      "metadata": {
        "id": "qBmn_DkCFAFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "JxlYZMCuNefB",
        "outputId": "5332bf04-4d2a-4612-ac5c-96c6b6282765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/17.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/17.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/17.1 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m12.5/17.1 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.0/17.1 MB\u001b[0m \u001b[31m190.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.0/17.1 MB\u001b[0m \u001b[31m190.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.85 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "637491fd176a463f8d76b76ef48a7350"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GABUf90oBGy3",
        "outputId": "ea9805a9-6606-4e31-e3e2-3f9a8176cb4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding'...\n",
            "remote: Enumerating objects: 103708, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 103708 (delta 0), reused 0 (delta 0), pack-reused 103705\u001b[K\n",
            "Receiving objects: 100% (103708/103708), 2.95 GiB | 16.02 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "Updating files: 100% (103015/103015), done.\n",
            "/content\n",
            "fatal: destination path 'av_hubert' already exists and is not an empty directory.\n",
            "/content/av_hubert\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5869 sha256=91b9ffa9e9cedf5e664d2737f08a4a9682883d9157e80af2e9e73f20bf93a87b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n",
            "Collecting scikit-video\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.11.4)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n",
            "/content/av_hubert/fairseq\n",
            "Processing /content/av_hubert/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (3.0.8)\n",
            "Collecting hydra-core<1.1 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.23.5)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (4.10.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (4.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==1.0.0a0+afc77bd) (2.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq==1.0.0a0+afc77bd) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq==1.0.0a0+afc77bd) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+afc77bd-cp310-cp310-linux_x86_64.whl size=2472354 sha256=e74ad630bbf6843eb494714c38b4698a3b7b16830c2a7fdceb49ba1e4fc344cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rc568fuo/wheels/9d/d5/16/2858bd41b3c8f8a9994060d9742bf0c2277ddbd72d53c55737\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=95b2523c25ee1deb26867e944ac4a6ba3200a9822761b055f751678fe40293fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 colorama-0.4.6 fairseq-1.0.0a0+afc77bd hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShreyAgarwal11/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding.git\n",
        "%cd /content/\n",
        "!git clone https://github.com/facebookresearch/av_hubert.git\n",
        "\n",
        "%cd av_hubert\n",
        "!git submodule init\n",
        "!git submodule update\n",
        "!pip install scipy\n",
        "!pip install sentencepiece\n",
        "!pip install python_speech_features\n",
        "!pip install scikit-video\n",
        "\n",
        "%cd fairseq\n",
        "!pip install ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data/misc/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -O /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!wget --content-disposition https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy -O /content/data/misc/20words_mean_face.npy"
      ],
      "metadata": {
        "id": "Z8VUJ4WLkHoK",
        "outputId": "aa3cf609-1505-43db-8acb-786049c972d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-06 21:09:01--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]  61.07M  9.72MB/s    in 12s     \n",
            "\n",
            "2024-03-06 21:09:14 (5.09 MB/s) - ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "--2024-03-06 21:09:20--  https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy [following]\n",
            "--2024-03-06 21:09:21--  https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1168 (1.1K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/misc/20words_mean_face.npy’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]   1.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-06 21:09:21 (81.2 MB/s) - ‘/content/data/misc/20words_mean_face.npy’ saved [1168/1168]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import a pre-trained model**"
      ],
      "metadata": {
        "id": "B1Mx4qTIG1AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuned model -> Noise-Augmented AV-HuBERT Base"
      ],
      "metadata": {
        "id": "k9u9TinFIF3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%mkdir -p /content/data/\n",
        "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/avsr/base_noise_pt_noise_ft_433h.pt -O /content/data/finetune-model.pt"
      ],
      "metadata": {
        "id": "1e8mNAjvFS9U",
        "outputId": "86e87f6d-a357-4a17-e74f-cdba5b9a7317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/fairseq\n",
            "--2024-03-06 21:09:21--  https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/avsr/base_noise_pt_noise_ft_433h.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.124, 108.157.254.102, 108.157.254.121, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1928060481 (1.8G) [binary/octet-stream]\n",
            "Saving to: ‘/content/data/finetune-model.pt’\n",
            "\n",
            "/content/data/finet 100%[===================>]   1.79G  21.3MB/s    in 83s     \n",
            "\n",
            "2024-03-06 21:10:46 (22.0 MB/s) - ‘/content/data/finetune-model.pt’ saved [1928060481/1928060481]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Video Out of Frames**"
      ],
      "metadata": {
        "id": "vYrFJ2tuZloT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "frame_folder = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/fadg0/video/sa1'\n",
        "\n",
        "output_video_path = '/content/output_video.mp4'\n",
        "\n",
        "frame_rate = 25\n",
        "\n",
        "frame_files = [f for f in os.listdir(frame_folder) if os.path.isfile(os.path.join(frame_folder, f))]\n",
        "\n",
        "frame_files.sort()\n",
        "\n",
        "video_resolution = (512, 384)\n",
        "\n",
        "if video_resolution is None:\n",
        "    first_frame_path = os.path.join(frame_folder, frame_files[0])\n",
        "    first_frame = cv2.imread(first_frame_path)\n",
        "    video_resolution = (first_frame.shape[1], first_frame.shape[0])\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, video_resolution)\n",
        "\n",
        "for frame_file in frame_files:\n",
        "    frame_path = os.path.join(frame_folder, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "    if (frame.shape[1], frame.shape[0]) != video_resolution:\n",
        "        frame = cv2.resize(frame, video_resolution)\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "91haYEVIZtYa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/av_hubert/avhubert\n",
        "import cv2\n",
        "import tempfile\n",
        "import torch\n",
        "import utils as avhubert_utils\n",
        "from argparse import Namespace\n",
        "import fairseq\n",
        "from fairseq import checkpoint_utils, options, tasks, utils\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "LjBk19NqG-X0",
        "outputId": "3db5b8ba-9ebc-48ac-abd8-efcc735ac8bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/avhubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction using AV-HUBERT**"
      ],
      "metadata": {
        "id": "LZm64rT1hyRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_visual_feature(video_path, ckpt_path, user_dir, is_finetune_ckpt=False):\n",
        "  utils.import_user_module(Namespace(user_dir=user_dir))\n",
        "  models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
        "  transform = avhubert_utils.Compose([\n",
        "      avhubert_utils.Normalize(0.0, 255.0),\n",
        "      avhubert_utils.CenterCrop((task.cfg.image_crop_size, task.cfg.image_crop_size)),\n",
        "      avhubert_utils.Normalize(task.cfg.image_mean, task.cfg.image_std)])\n",
        "  frames = avhubert_utils.load_video(video_path)\n",
        "  print(f\"Load video {video_path}: shape {frames.shape}\")\n",
        "  frames = transform(frames)\n",
        "  print(f\"Center crop video to: {frames.shape}\")\n",
        "  frames = torch.FloatTensor(frames).unsqueeze(dim=0).unsqueeze(dim=0).cuda()\n",
        "  model = models[0]\n",
        "  if hasattr(models[0], 'decoder'):\n",
        "    print(f\"Checkpoint: fine-tuned\")\n",
        "    model = models[0].encoder.w2v_model\n",
        "  else:\n",
        "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")\n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # Specify output_layer if you want to extract feature of an intermediate layer\n",
        "    feature, _ = model.extract_finetune(source={'video': frames, 'audio': None}, padding_mask=None, output_layer=None)\n",
        "    feature = feature.squeeze(dim=0)\n",
        "  print(f\"Video feature shape: {feature.shape}\")\n",
        "  return feature\n",
        "\n",
        "mouth_roi_path, ckpt_path = \"/content/output_video.mp4\", \"/content/data/finetune-model.pt\"\n",
        "user_dir = \"/content/av_hubert/avhubert\"\n",
        "feature = extract_visual_feature(mouth_roi_path, ckpt_path, user_dir)"
      ],
      "metadata": {
        "id": "C6RNFXKwIfqN",
        "outputId": "fca66549-6105-4f34-ad9a-905b13bd3e57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/output_video.avi: shape (119, 1080, 1920)\n",
            "Center crop video to: (119, 88, 88)\n",
            "Checkpoint: fine-tuned\n",
            "Video feature shape: torch.Size([119, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A9wtiDEVrpx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}