{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "IRcv11EWEled"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyAgarwal11/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/blob/main/diffrence_pr2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dependancies"
      ],
      "metadata": {
        "id": "qBmn_DkCFAFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "JxlYZMCuNefB",
        "outputId": "6ee7259c-2036-4f88-96be-d315244971ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "5180d69f5d614bc2884b18e4a8cf91f3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GABUf90oBGy3",
        "outputId": "584c6b38-ef0f-4027-99c2-dc8e80e703b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding'...\n",
            "remote: Enumerating objects: 104887, done.\u001b[K\n",
            "remote: Counting objects: 100% (1182/1182), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1100/1100), done.\u001b[K\n",
            "remote: Total 104887 (delta 103), reused 1136 (delta 82), pack-reused 103705\u001b[K\n",
            "Receiving objects: 100% (104887/104887), 3.13 GiB | 34.51 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n",
            "Updating files: 100% (104377/104377), done.\n",
            "/content\n",
            "Cloning into 'av_hubert'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 149 (delta 18), reused 22 (delta 14), pack-reused 111\u001b[K\n",
            "Receiving objects: 100% (149/149), 4.65 MiB | 8.98 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content/av_hubert\n",
            "Submodule 'fairseq' (https://github.com/pytorch/fairseq) registered for path 'fairseq'\n",
            "Cloning into '/content/av_hubert/fairseq'...\n",
            "Submodule path 'fairseq': checked out 'afc77bdf4bb51453ce76f1572ef2ee6ddcda8eeb'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=80932c0393ef56b0861049ad4e6b75d5764df6baf40400381c88a54d3fc4242c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n",
            "Collecting scikit-video\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.11.4)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n",
            "/content/av_hubert/fairseq\n",
            "Processing /content/av_hubert/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (3.0.10)\n",
            "Collecting hydra-core<1.1 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.23.5)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (4.11.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (4.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==1.0.0a0+afc77bd) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq==1.0.0a0+afc77bd) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq==1.0.0a0+afc77bd) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+afc77bd-cp310-cp310-linux_x86_64.whl size=2472386 sha256=b8787925f9ba7193e6faec7f177a752d6d851d7b36dbe612156dd4cb1dbec0b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sh8id_nb/wheels/9d/d5/16/2858bd41b3c8f8a9994060d9742bf0c2277ddbd72d53c55737\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=cfcaffb1eb3b61cd66a19bc9f8942d123c0f7b75c13055ae16f9465a6735ed31\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 colorama-0.4.6 fairseq-1.0.0a0+afc77bd hydra-core-1.0.7 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShreyAgarwal11/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding.git\n",
        "%cd /content/\n",
        "!git clone https://github.com/facebookresearch/av_hubert.git\n",
        "\n",
        "%cd av_hubert\n",
        "!git submodule init\n",
        "!git submodule update\n",
        "!pip install scipy\n",
        "!pip install sentencepiece\n",
        "!pip install python_speech_features\n",
        "!pip install scikit-video\n",
        "\n",
        "%cd fairseq\n",
        "!pip install ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data/misc/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -O /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!wget --content-disposition https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy -O /content/data/misc/20words_mean_face.npy"
      ],
      "metadata": {
        "id": "Z8VUJ4WLkHoK",
        "outputId": "d485c720-56f2-47aa-8fb6-b40f9179fa29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-04 22:20:59--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]  61.07M   118MB/s    in 0.5s    \n",
            "\n",
            "2024-05-04 22:20:59 (118 MB/s) - ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "--2024-05-04 22:21:10--  https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy [following]\n",
            "--2024-05-04 22:21:10--  https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1168 (1.1K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/misc/20words_mean_face.npy’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]   1.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-04 22:21:10 (61.9 MB/s) - ‘/content/data/misc/20words_mean_face.npy’ saved [1168/1168]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import a pre-trained model**"
      ],
      "metadata": {
        "id": "B1Mx4qTIG1AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuned model -> Noise-Augmented AV-HuBERT Base"
      ],
      "metadata": {
        "id": "k9u9TinFIF3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%mkdir -p /content/data/\n",
        "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/avsr/base_noise_pt_noise_ft_433h.pt -O /content/data/finetune-model.pt"
      ],
      "metadata": {
        "id": "1e8mNAjvFS9U",
        "outputId": "d5815259-a3e0-4a98-eb72-e2978d11c49c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/fairseq\n",
            "--2024-05-04 22:21:10--  https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/avsr/base_noise_pt_noise_ft_433h.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.15, 13.226.210.25, 13.226.210.111, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1928060481 (1.8G) [binary/octet-stream]\n",
            "Saving to: ‘/content/data/finetune-model.pt’\n",
            "\n",
            "/content/data/finet 100%[===================>]   1.79G  45.8MB/s    in 40s     \n",
            "\n",
            "2024-05-04 22:21:51 (45.9 MB/s) - ‘/content/data/finetune-model.pt’ saved [1928060481/1928060481]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shrey's Video frame creation"
      ],
      "metadata": {
        "id": "IRcv11EWEled"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "frame_folder = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mwbt0/video/sa1'\n",
        "\n",
        "output_video_path = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/output_video.mp4'\n",
        "\n",
        "frame_rate = 25\n",
        "\n",
        "frame_files = [f for f in os.listdir(frame_folder) if os.path.isfile(os.path.join(frame_folder, f))]\n",
        "\n",
        "frame_files.sort()\n",
        "\n",
        "video_resolution = (512, 384)\n",
        "\n",
        "if video_resolution is None:\n",
        "    first_frame_path = os.path.join(frame_folder, frame_files[0])\n",
        "    first_frame = cv2.imread(first_frame_path)\n",
        "    video_resolution = (first_frame.shape[1], first_frame.shape[0])\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, video_resolution)\n",
        "\n",
        "for frame_file in frame_files:\n",
        "    frame_path = os.path.join(frame_folder, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "    if (frame.shape[1], frame.shape[0]) != video_resolution:\n",
        "        frame = cv2.resize(frame, video_resolution)\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "91haYEVIZtYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Frame creation and Deepfake video segregation"
      ],
      "metadata": {
        "id": "vYrFJ2tuZloT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video from VidTIMIT that coincide with deepfake in folder comman_data"
      ],
      "metadata": {
        "id": "6pa-2ocfE0b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "%mkdir -p /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/\n",
        "%mkdir -p /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/"
      ],
      "metadata": {
        "id": "x-h8uaJNix4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_output_video(frame_folder, frame_rate=25, video_resolution=(512, 384)):\n",
        "    frame_files = [f for f in os.listdir(frame_folder) if os.path.isfile(os.path.join(frame_folder, f))]\n",
        "    frame_files.sort()\n",
        "\n",
        "    if video_resolution is None:\n",
        "        first_frame_path = os.path.join(frame_folder, frame_files[0])\n",
        "        first_frame = cv2.imread(first_frame_path)\n",
        "        video_resolution = (first_frame.shape[1], first_frame.shape[0])\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "\n",
        "    # Split the input path and extract the necessary components\n",
        "    parts = frame_folder.split('/')\n",
        "    speaker = parts[-3]  # Get the speaker ID (e.g., fadg0)\n",
        "    video_name = parts[-1]  # Get the video name (e.g., sa1)\n",
        "\n",
        "    # Define the output path\n",
        "    output_video_path = os.path.join('/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/', f\"{video_name}-video-{speaker}.mp4\")\n",
        "\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, video_resolution)\n",
        "\n",
        "    for frame_file in frame_files:\n",
        "        frame_path = os.path.join(frame_folder, frame_file)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        if (frame.shape[1], frame.shape[0]) != video_resolution:\n",
        "            frame = cv2.resize(frame, video_resolution)\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "omNF8lSLWhP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder1 = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/DeepfakeTIMIT/higher_quality/'\n",
        "folder2 = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/'\n",
        "output_vdtimit = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/'\n",
        "\n",
        "\n",
        "# Get list of files in each folder\n",
        "files1 = os.listdir(folder1)\n",
        "files2 = os.listdir(folder2)\n",
        "\n",
        "# Extract filenames without extensions\n",
        "file_names1 = [os.path.splitext(file)[0] for file in files1]\n",
        "file_names2 = [os.path.splitext(file)[0] for file in files2]\n",
        "\n",
        "# Find common filenames\n",
        "common_file_names = set(file_names1).intersection(file_names2)\n",
        "\n",
        "# Process files with common names\n",
        "for common_name in common_file_names:\n",
        "\n",
        "    check_folder = os.path.join(folder2, common_name)\n",
        "\n",
        "    file_path2_audio = os.path.join(check_folder + '/audio')\n",
        "    try:\n",
        "        files2_in_audio = os.listdir(file_path2_audio)\n",
        "        # print(files2_in_audio)\n",
        "    except FileNotFoundError:\n",
        "        # If directory does not exist, delete it and continue to the next directory\n",
        "        shutil.rmtree(check_folder)\n",
        "        print(\"Removed dir :\",  check_folder)\n",
        "        continue\n",
        "\n",
        "    file_path1 = os.path.join(folder1, common_name)\n",
        "    file_path2 = os.path.join(folder2, common_name + '/video')\n",
        "    files1_in = os.listdir(file_path1)\n",
        "    files2_in = os.listdir(file_path2)\n",
        "\n",
        "    # Extract filenames without extensions\n",
        "    file_names1_in = [file.split('-')[0] for file in files1_in if 'video' in file]\n",
        "    # print(file_names1_in)\n",
        "    file_names2_in = [file.split('-')[0] for file in files2_in]\n",
        "    # print(file_names2_in)\n",
        "    files2_audio_in = [file.split('.')[0] for file in files2_in_audio]\n",
        "    # print(files2_audio_in)\n",
        "\n",
        "    # # Find common filenames\n",
        "    common_file_names_in = set(file_names1_in).intersection(file_names2_in)\n",
        "    # print(common_file_names_in)\n",
        "    common_audio_file = set(common_file_names_in).intersection(files2_audio_in)\n",
        "    # print(\"Printed Audio -\",common_audio_file)\n",
        "\n",
        "    for filename in common_audio_file:\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename_audio = filename + '-audio-' + common_name + '.wav'\n",
        "        # print(new_filename_audio)\n",
        "        file_path = os.path.join(output_vdtimit, new_filename_audio)\n",
        "        # print(\"New file path -\",file_path)\n",
        "        shift_path = os.path.join(check_folder + '/audio/' + filename + '.wav')\n",
        "        if os.path.exists(shift_path):\n",
        "                # print(\"Shift_path -\",shift_path)\n",
        "                shutil.copy(shift_path, file_path)\n",
        "                # print(f\"File copied successfully! '{file_path}'\")\n",
        "        else:\n",
        "          print(\"Does not exits\")\n",
        "\n",
        "    for common_name_in in common_file_names_in:\n",
        "\n",
        "      file_path1_in1 = os.path.join(file_path1, common_name_in)\n",
        "      file_path2_in2 = os.path.join(file_path2, common_name_in)\n",
        "\n",
        "      # Check if both files exist before proceeding\n",
        "\n",
        "      if os.path.exists(file_path2_in2):\n",
        "          create_output_video(file_path2_in2)\n",
        "          # Do something with the files, such as processing or using them in your code\n",
        "          # print(f\"Files with name '{common_name_in}' exist in both folders:\")\n",
        "          # print(f\"File path in folder1: {file_path1_in1}\")\n",
        "          # print(f\"File path in folder2: {file_path2_in2}\")\n",
        "          # Your code to process or use the files goes here\n",
        "      else:\n",
        "          print(f\"Files with name '{common_name_in}' do not exist in both folders.\")\n",
        "          print(f\"File path in folder1: {file_path1_in1}\")\n",
        "          print(f\"File path in folder2: {file_path2_in2}\")"
      ],
      "metadata": {
        "id": "oyOJtvRJFO4Q",
        "outputId": "02478b1a-7f35-44d7-a1e2-d092364f5d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/fcmh0\n",
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mdld0\n",
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mrgg0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video from DeepfakeTIMIT that coincide with VidTIMIT in folder comman_data_deep"
      ],
      "metadata": {
        "id": "2SrP046UFBLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_folder = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/DeepfakeTIMIT/higher_quality/'\n",
        "output_video_path = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/'\n",
        "\n",
        "# Get list of directories in the frame_folder\n",
        "directories = [os.path.join(frame_folder, name) for name in os.listdir(frame_folder) if os.path.isdir(os.path.join(frame_folder, name))]\n",
        "\n",
        "# Process files in each directory\n",
        "for directory in directories:\n",
        "    # Get list of files in each directory\n",
        "    files_in_directory = os.listdir(directory)\n",
        "    # print(\"directory -\", directory)\n",
        "    intial = directory.split('/')\n",
        "    speaker = intial[-1]\n",
        "    # print(intial[-1])\n",
        "\n",
        "    # Process each file\n",
        "    for filename in files_in_directory:\n",
        "\n",
        "      if filename.startswith('.'):\n",
        "          continue\n",
        "\n",
        "      if 'video' not in filename:\n",
        "        # print(filename)\n",
        "        file_path_audio = os.path.join(directory, filename)\n",
        "        # print(file_path)\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        # print(name)\n",
        "\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename_audio = name + '-audio-' + speaker + ext\n",
        "        # print(new_filename_audio)\n",
        "\n",
        "        # Construct the new path\n",
        "        new_path_audio = os.path.join(output_video_path, new_filename_audio)\n",
        "        # print(new_path_audio)\n",
        "\n",
        "        # Copy the file to the new path\n",
        "        shutil.copy(file_path_audio, new_path_audio)\n",
        "\n",
        "        # print(f\"File copied successfully! '{new_path_audio}'\")\n",
        "\n",
        "      if 'video' in filename:\n",
        "        # print(filename)\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        # print(file_path)\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        # print(name)\n",
        "\n",
        "        # Split the name into parts separated by '-'\n",
        "        parts = name.split('-')\n",
        "        # print(\"Parts -\",parts)\n",
        "\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename = parts[0] + '-video-' + speaker + ext\n",
        "        # print(new_filename)\n",
        "\n",
        "        # Construct the new path\n",
        "        new_path = os.path.join(output_video_path, new_filename)\n",
        "        print(new_path)\n",
        "\n",
        "        # Copy the file to the new path\n",
        "        shutil.copy(file_path, new_path)\n",
        "\n",
        "        # print(f\"File copied successfully! '{new_path}'\")"
      ],
      "metadata": {
        "id": "EQzAaXQh_u6q",
        "outputId": "3e3556d0-dba8-4421-d511-b5f0ecd5484d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si913-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx193-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1543-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx103-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2173-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx373-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx283-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx13-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx410-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1490-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si860-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si569-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1199-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx209-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx119-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1829-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx29-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx299-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx389-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si824-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1454-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2084-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx389-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1469-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx119-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si839-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx209-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx299-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2099-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx29-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx95-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx1625-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx275-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si995-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2255-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx5-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx12-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx282-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1542-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2172-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si912-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx372-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx192-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1010-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2270-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx290-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx380-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1640-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx20-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx409-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx319-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx229-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx49-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1039-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1669-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2299-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx139-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1894-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si634-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx274-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx4-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx364-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx94-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1264-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx95-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx275-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si635-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx5-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx99-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx279-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx369-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1539-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si909-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx101-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx191-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx371-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si911-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx11-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1541-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2171-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx188-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx278-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si548-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx98-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx8-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx368-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx293-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx383-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx113-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2183-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si923-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx203-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1398-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx228-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si768-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx48-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx408-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx138-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2028-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx318-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx403-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si943-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx313-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx43-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1573-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2203-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx133-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si734-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1624-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx304-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx34-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2222-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx214-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1024-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx124-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx394-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx19-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1909-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx379-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx199-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si649-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1279-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx372-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx282-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1425-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx12-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1555-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx192-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2028-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si469-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx199-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx379-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx19-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1729-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx205-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx385-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx295-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx25-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1825-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx1195-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si565-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx115-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx188-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx98-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx368-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx8-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1988-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2247-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx278-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si728-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx410-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2030-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1400-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si770-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx190-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si522-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx370-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si730-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx100-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx10-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1899-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si639-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx369-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx279-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx99-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si869-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx34-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx214-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx394-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2104-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx304-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx124-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1746-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx126-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx36-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1587-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx396-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1566-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2149-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx36-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si756-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx126-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx396-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2016-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1386-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1714-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx274-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx4-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx364-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1653-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx94-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1084-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fedw0.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AVHubert functions"
      ],
      "metadata": {
        "id": "7ZrRghxYFfWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/av_hubert/avhubert\n",
        "import cv2\n",
        "import tempfile\n",
        "import torch\n",
        "import utils as avhubert_utils\n",
        "from argparse import Namespace\n",
        "import fairseq\n",
        "from fairseq import checkpoint_utils, options, tasks, utils\n",
        "from IPython.display import HTML\n",
        "from python_speech_features import logfbank\n",
        "from scipy.io import wavfile"
      ],
      "metadata": {
        "id": "LjBk19NqG-X0",
        "outputId": "efff8b2f-6061-4a74-83e7-78477d914784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/avhubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction using AV-HUBERT**"
      ],
      "metadata": {
        "id": "LZm64rT1hyRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stacker(feats, stack_order):\n",
        "            \"\"\"\n",
        "            Concatenating consecutive audio frames\n",
        "            Args:\n",
        "            feats - numpy.ndarray of shape [T, F]\n",
        "            stack_order - int (number of neighboring frames to concatenate\n",
        "            Returns:\n",
        "            feats - numpy.ndarray of shape [T', F']\n",
        "            \"\"\"\n",
        "            feat_dim = feats.shape[1]\n",
        "            if len(feats) % stack_order != 0:\n",
        "                res = stack_order - len(feats) % stack_order\n",
        "                res = np.zeros([res, feat_dim]).astype(feats.dtype)\n",
        "                feats = np.concatenate([feats, res], axis=0)\n",
        "            feats = feats.reshape((-1, stack_order, feat_dim)).reshape(-1, stack_order*feat_dim)\n",
        "            return feats"
      ],
      "metadata": {
        "id": "KVK2SUGkWZED"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_visual_feature(video_path, audio_path, ckpt_path, user_dir, is_finetune_ckpt=False):\n",
        "  utils.import_user_module(Namespace(user_dir=user_dir))\n",
        "  models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
        "  transform = avhubert_utils.Compose([\n",
        "      avhubert_utils.Normalize(0.0, 255.0),\n",
        "      avhubert_utils.CenterCrop((task.cfg.image_crop_size, task.cfg.image_crop_size)),\n",
        "      avhubert_utils.Normalize(task.cfg.image_mean, task.cfg.image_std)])\n",
        "  frames = avhubert_utils.load_video(video_path)\n",
        "  print(f\"Load video {video_path}: shape {frames.shape}\")\n",
        "  sample_rate, wav_data = wavfile.read(audio_path)\n",
        "  audio_features = logfbank(wav_data, sample_rate).astype(np.float32)\n",
        "  audio_features = stacker(audio_features, 4)\n",
        "  print(f\"Load audio {audio_path}: shape {audio_features.shape}\")\n",
        "  audio_features = torch.FloatTensor(audio_features).unsqueeze(dim=0).permute(0, 2, 1).cuda()\n",
        "  frames = torch.FloatTensor(frames).unsqueeze(dim=0).unsqueeze(dim=0).cuda()\n",
        "  if audio_features.shape[2] < frames.shape[2]:\n",
        "    # Pad features_audio\n",
        "    padding_size = frames.shape[2] - audio_features.shape[2]\n",
        "    padding = torch.zeros((audio_features.shape[0], audio_features.shape[1], padding_size)).cuda()\n",
        "    audio_features = torch.cat([audio_features, padding], dim=2)\n",
        "  print(f\"Load video {video_path}: shape {frames.shape}\")\n",
        "  print(f\"Load audio {audio_path}: shape {audio_features.shape}\")\n",
        "  model = models[0]\n",
        "  if hasattr(models[0], 'decoder'):\n",
        "    print(f\"Checkpoint: fine-tuned\")\n",
        "    model = models[0].encoder.w2v_model\n",
        "  else:\n",
        "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")\n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # Specify output_layer if you want to extract feature of an intermediate layer\n",
        "    layer_features = []\n",
        "    for i in range(12):\n",
        "      feature, _ = model.extract_finetune(source={'video': frames, 'audio': audio_features}, padding_mask=None, output_layer=(i+1))\n",
        "      layer_features.append(feature)\n",
        "    feature, _ = model.extract_finetune(source={'video': frames, 'audio': audio_features}, padding_mask=None, output_layer=None)\n",
        "    feature = feature.squeeze(dim=0)\n",
        "  print(f\"AvHuBert Feature shape: {feature.shape}\")\n",
        "  return layer_features, feature\n"
      ],
      "metadata": {
        "id": "C6RNFXKwIfqN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_real = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/'\n",
        "folder_path_deep = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/'\n",
        "\n",
        "# Initialize an empty list to store pairs of file paths\n",
        "real_file_pairs = []\n",
        "deep_file_pairs = []\n",
        "\n",
        "# Get the list of files in the real folder\n",
        "files_real = os.listdir(folder_path_real)\n",
        "\n",
        "# Get the list of files in the deep folder\n",
        "files_deep = os.listdir(folder_path_deep)\n",
        "\n",
        "# Iterate over each file in the real folder\n",
        "for file_real in files_real:\n",
        "    # Split the filename and extension\n",
        "    name, ext_real = os.path.splitext(file_real)\n",
        "    # print(file_real)\n",
        "\n",
        "    # Check if the file is an audio file\n",
        "    if ext_real == '.wav':\n",
        "        # Construct the expected video filename\n",
        "        audio_filename_real = name\n",
        "        video_filename_real = name.replace('-audio-', '-video-')\n",
        "        # print(video_filename)\n",
        "\n",
        "        # Check if the video file exists in the deep folder\n",
        "        for file_deep in files_deep:\n",
        "            name_deep, ext_deep = os.path.splitext(file_deep)\n",
        "            # print(name_deep)\n",
        "                # Check if the file is an audio file\n",
        "            if ext_deep == '.wav':\n",
        "                # Construct the expected video filename\n",
        "                audio_filename_deep = name_deep\n",
        "                video_filename_deep = name_deep.replace('-audio-', '-video-')\n",
        "                if video_filename_deep == video_filename_real:\n",
        "                    # Construct the paths for the audio and video files in both folders\n",
        "                    audio_path_real = os.path.join(folder_path_real, audio_filename_real + ext_deep)\n",
        "                    # print(audio_path_real)\n",
        "                    video_path_real = os.path.join(folder_path_real, video_filename_real + '.mp4')\n",
        "                    audio_path_deep = os.path.join(folder_path_deep, audio_filename_deep + ext_deep)\n",
        "                    # print(audio_path_deep)\n",
        "                    video_path_deep = os.path.join(folder_path_deep, video_filename_real + '.avi')\n",
        "\n",
        "                    # Check if both audio and video files exist in both folders\n",
        "                    if os.path.exists(audio_path_real) and os.path.exists(video_path_real) and \\\n",
        "                      os.path.exists(audio_path_deep) and os.path.exists(video_path_deep):\n",
        "                        # Add the pair of paths to the list\n",
        "                        real_file_pairs.append((audio_path_real, video_path_real))\n",
        "                        deep_file_pairs.append((audio_path_deep, video_path_deep))\n",
        "\n",
        "# Print the number of file pairs found\n",
        "print(len(os.listdir(folder_path_real)))\n",
        "print(len(os.listdir(folder_path_deep)))\n",
        "print(len(real_file_pairs))\n",
        "print(len(deep_file_pairs))\n"
      ],
      "metadata": {
        "id": "QkWDR7zwuVOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8129e1-5f2d-4759-8511-113499ab2e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "580\n",
            "640\n",
            "290\n",
            "290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = \"/content/data/finetune-model.pt\"\n",
        "user_dir = \"/content/av_hubert/avhubert\"\n",
        "\n",
        "feature_real = {}\n",
        "feature_deep = {}\n",
        "\n",
        "# Counter variables to keep track of iterations\n",
        "count_real = 0\n",
        "count_deep = 0\n",
        "\n",
        "# Loop over real_file_pairs\n",
        "for pair in real_file_pairs:\n",
        "    # Increment the counter\n",
        "    count_real += 1\n",
        "\n",
        "    audio_path = pair[0]\n",
        "    mouth_roi_path = pair[1]\n",
        "    name_r, ext_r = os.path.splitext(pair[0])\n",
        "    index_data_r = name_r.split('/')[-1].replace('-audio-', '')\n",
        "\n",
        "    # Check if the index is not already in feature_real\n",
        "    if index_data_r not in feature_real:\n",
        "        layer_features, feature_real[index_data_r] = extract_visual_feature(mouth_roi_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "    # # Break after every 5 iterations\n",
        "    if count_real == 50:\n",
        "        break\n",
        "\n",
        "# Loop over deep_file_pairs\n",
        "for pair in deep_file_pairs:\n",
        "    # Increment the counter\n",
        "    count_deep += 1\n",
        "\n",
        "    audio_path = pair[0]\n",
        "    mouth_roi_path = pair[1]\n",
        "    name_d, ext_d = os.path.splitext(pair[0])\n",
        "    index_data_d = name_d.split('/')[-1].replace('-audio-', '')\n",
        "\n",
        "    # Check if the index is not already in feature_deep\n",
        "    if index_data_d not in feature_deep:\n",
        "        layer_features, feature_deep[index_data_d] = extract_visual_feature(mouth_roi_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "    # Break after every 5 iterations\n",
        "    if count_deep == 50:\n",
        "        break"
      ],
      "metadata": {
        "id": "6j5un1rYER11",
        "outputId": "90070275-5dc3-4a15-a7f1-ca22dcd0a98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-video-mrjo0.mp4: shape (138, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-audio-mrjo0.wav: shape (138, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-video-mrjo0.mp4: shape torch.Size([1, 1, 138, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-audio-mrjo0.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-video-fdac1.mp4: shape (137, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-audio-fdac1.wav: shape (137, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-video-fdac1.mp4: shape torch.Size([1, 1, 137, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-audio-fdac1.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-video-fram1.mp4: shape (114, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-audio-fram1.wav: shape (114, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-video-fram1.mp4: shape torch.Size([1, 1, 114, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-audio-fram1.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-video-fkms0.mp4: shape (102, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-audio-fkms0.wav: shape (102, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-video-fkms0.mp4: shape torch.Size([1, 1, 102, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-audio-fkms0.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-video-msjs1.mp4: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-audio-msjs1.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-video-msjs1.mp4: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-audio-msjs1.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-video-fjre0.mp4: shape (82, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-audio-fjre0.wav: shape (82, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-video-fjre0.mp4: shape torch.Size([1, 1, 82, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-audio-fjre0.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mwbt0.mp4: shape (104, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mwbt0.wav: shape (104, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mwbt0.mp4: shape torch.Size([1, 1, 104, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mwbt0.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjas0.mp4: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjas0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjas0.mp4: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjas0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-video-fjwb0.mp4: shape (123, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-audio-fjwb0.wav: shape (123, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-video-fjwb0.mp4: shape torch.Size([1, 1, 123, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-audio-fjwb0.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-video-mpgl0.mp4: shape (98, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-audio-mpgl0.wav: shape (98, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-video-mpgl0.mp4: shape torch.Size([1, 1, 98, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-audio-mpgl0.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-video-mpgl0.mp4: shape (72, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-audio-mpgl0.wav: shape (72, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-video-mpgl0.mp4: shape torch.Size([1, 1, 72, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-audio-mpgl0.wav: shape torch.Size([1, 104, 72])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([72, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fedw0.mp4: shape (92, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fedw0.wav: shape (92, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fedw0.mp4: shape torch.Size([1, 1, 92, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fedw0.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-video-felc0.mp4: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-audio-felc0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-video-felc0.mp4: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-audio-felc0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-video-faks0.mp4: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-video-faks0.mp4: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjwb0.mp4: shape (99, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjwb0.wav: shape (99, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjwb0.mp4: shape torch.Size([1, 1, 99, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjwb0.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-video-mjsw0.mp4: shape (90, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-audio-mjsw0.wav: shape (90, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-video-mjsw0.mp4: shape torch.Size([1, 1, 90, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-audio-mjsw0.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-video-mwbt0.mp4: shape (101, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-audio-mwbt0.wav: shape (101, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-video-mwbt0.mp4: shape torch.Size([1, 1, 101, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-audio-mwbt0.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-mstk0.mp4: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-mstk0.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-mstk0.mp4: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-mstk0.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-video-fjre0.mp4: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-audio-fjre0.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-video-fjre0.mp4: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-audio-fjre0.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-video-mgwt0.mp4: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-audio-mgwt0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-video-mgwt0.mp4: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-audio-mgwt0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-video-mrjo0.mp4: shape (86, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-audio-mrjo0.wav: shape (86, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-video-mrjo0.mp4: shape torch.Size([1, 1, 86, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-audio-mrjo0.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-video-mgwt0.mp4: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-audio-mgwt0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-video-mgwt0.mp4: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-audio-mgwt0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-video-mwbt0.mp4: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-audio-mwbt0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-video-mwbt0.mp4: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-audio-mwbt0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-msjs1.mp4: shape (121, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-msjs1.wav: shape (121, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-msjs1.mp4: shape torch.Size([1, 1, 121, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-msjs1.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-video-fkms0.mp4: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-audio-fkms0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-video-fkms0.mp4: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-audio-fkms0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-video-fdac1.mp4: shape (88, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-audio-fdac1.wav: shape (88, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-video-fdac1.mp4: shape torch.Size([1, 1, 88, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-audio-fdac1.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mgwt0.mp4: shape (125, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mgwt0.wav: shape (125, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mgwt0.mp4: shape torch.Size([1, 1, 125, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mgwt0.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-video-fkms0.mp4: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-video-fkms0.mp4: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-video-mpgl0.mp4: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-audio-mpgl0.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-video-mpgl0.mp4: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-audio-mpgl0.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fram1.mp4: shape (117, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fram1.wav: shape (117, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fram1.mp4: shape torch.Size([1, 1, 117, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fram1.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-video-fdrd1.mp4: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-audio-fdrd1.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-video-fdrd1.mp4: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-audio-fdrd1.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-video-mrcz0.mp4: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-audio-mrcz0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-video-mrcz0.mp4: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-audio-mrcz0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-video-mmdm2.mp4: shape (116, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-audio-mmdm2.wav: shape (116, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-video-mmdm2.mp4: shape torch.Size([1, 1, 116, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-audio-mmdm2.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-video-mmdb1.mp4: shape (97, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-audio-mmdb1.wav: shape (97, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-video-mmdb1.mp4: shape torch.Size([1, 1, 97, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-audio-mmdb1.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-video-fjem0.mp4: shape (155, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-audio-fjem0.wav: shape (155, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-video-fjem0.mp4: shape torch.Size([1, 1, 155, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-audio-fjem0.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-video-mmdb1.mp4: shape (128, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-audio-mmdb1.wav: shape (128, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-video-mmdb1.mp4: shape torch.Size([1, 1, 128, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-audio-mmdb1.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fdac1.mp4: shape (95, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fdac1.wav: shape (95, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fdac1.mp4: shape torch.Size([1, 1, 95, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fdac1.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mjar0.mp4: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mjar0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mjar0.mp4: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mjar0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-faks0.mp4: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-faks0.mp4: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-video-mjsw0.mp4: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-audio-mjsw0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-video-mjsw0.mp4: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-audio-mjsw0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-faks0.mp4: shape (81, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-faks0.wav: shape (81, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-faks0.mp4: shape torch.Size([1, 1, 81, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-faks0.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-video-fjwb0.mp4: shape (182, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-audio-fjwb0.wav: shape (182, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-video-fjwb0.mp4: shape torch.Size([1, 1, 182, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-audio-fjwb0.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-video-fram1.mp4: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-audio-fram1.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-video-fram1.mp4: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-audio-fram1.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-video-fkms0.mp4: shape (106, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-audio-fkms0.wav: shape (106, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-video-fkms0.mp4: shape torch.Size([1, 1, 106, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-audio-fkms0.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-video-fcft0.mp4: shape (112, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-audio-fcft0.wav: shape (112, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-video-fcft0.mp4: shape torch.Size([1, 1, 112, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-audio-fcft0.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-video-fcft0.mp4: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-audio-fcft0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-video-fcft0.mp4: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-audio-fcft0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mdab0.mp4: shape (149, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mdab0.wav: shape (149, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mdab0.mp4: shape torch.Size([1, 1, 149, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mdab0.wav: shape torch.Size([1, 104, 149])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([149, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mstk0.mp4: shape (93, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mstk0.wav: shape (93, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mstk0.mp4: shape torch.Size([1, 1, 93, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mstk0.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-video-mstk0.mp4: shape (69, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-audio-mstk0.wav: shape (69, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-video-mstk0.mp4: shape torch.Size([1, 1, 69, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-audio-mstk0.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-video-fkms0.mp4: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-video-fkms0.mp4: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi: shape (138, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-audio-mrjo0.wav: shape (138, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi: shape torch.Size([1, 1, 138, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-audio-mrjo0.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi: shape (137, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-audio-fdac1.wav: shape (137, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi: shape torch.Size([1, 1, 137, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-audio-fdac1.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-audio-fram1.wav: shape (114, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-audio-fram1.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi: shape (102, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-audio-fkms0.wav: shape (102, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi: shape torch.Size([1, 1, 102, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-audio-fkms0.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-audio-msjs1.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-audio-msjs1.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi: shape (82, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-audio-fjre0.wav: shape (82, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi: shape torch.Size([1, 1, 82, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-audio-fjre0.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi: shape (104, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mwbt0.wav: shape (104, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi: shape torch.Size([1, 1, 104, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mwbt0.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjas0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjas0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi: shape (123, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-audio-fjwb0.wav: shape (123, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi: shape torch.Size([1, 1, 123, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-audio-fjwb0.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi: shape (98, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-audio-mpgl0.wav: shape (98, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi: shape torch.Size([1, 1, 98, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-audio-mpgl0.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi: shape (72, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-audio-mpgl0.wav: shape (72, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi: shape torch.Size([1, 1, 72, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-audio-mpgl0.wav: shape torch.Size([1, 104, 72])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([72, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi: shape (92, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fedw0.wav: shape (92, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi: shape torch.Size([1, 1, 92, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fedw0.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-audio-felc0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-audio-felc0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi: shape (99, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjwb0.wav: shape (99, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi: shape torch.Size([1, 1, 99, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjwb0.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi: shape (90, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-audio-mjsw0.wav: shape (90, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi: shape torch.Size([1, 1, 90, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-audio-mjsw0.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi: shape (101, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-audio-mwbt0.wav: shape (101, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi: shape torch.Size([1, 1, 101, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-audio-mwbt0.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-mstk0.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-mstk0.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-audio-fjre0.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-audio-fjre0.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-audio-mgwt0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-audio-mgwt0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi: shape (86, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-audio-mrjo0.wav: shape (86, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi: shape torch.Size([1, 1, 86, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-audio-mrjo0.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-audio-mgwt0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-audio-mgwt0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-audio-mwbt0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-audio-mwbt0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi: shape (121, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-msjs1.wav: shape (121, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi: shape torch.Size([1, 1, 121, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-msjs1.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-audio-fkms0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-audio-fkms0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi: shape (88, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-audio-fdac1.wav: shape (88, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi: shape torch.Size([1, 1, 88, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-audio-fdac1.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi: shape (125, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mgwt0.wav: shape (125, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi: shape torch.Size([1, 1, 125, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mgwt0.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-audio-mpgl0.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-audio-mpgl0.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi: shape (117, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fram1.wav: shape (117, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi: shape torch.Size([1, 1, 117, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fram1.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-audio-fdrd1.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-audio-fdrd1.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-audio-mrcz0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-audio-mrcz0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi: shape (116, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-audio-mmdm2.wav: shape (116, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi: shape torch.Size([1, 1, 116, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-audio-mmdm2.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi: shape (97, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-audio-mmdb1.wav: shape (97, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi: shape torch.Size([1, 1, 97, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-audio-mmdb1.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi: shape (155, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-audio-fjem0.wav: shape (155, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi: shape torch.Size([1, 1, 155, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-audio-fjem0.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi: shape (128, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-audio-mmdb1.wav: shape (128, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi: shape torch.Size([1, 1, 128, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-audio-mmdb1.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi: shape (95, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fdac1.wav: shape (95, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi: shape torch.Size([1, 1, 95, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fdac1.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mjar0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mjar0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-audio-mjsw0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-audio-mjsw0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi: shape (81, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-faks0.wav: shape (81, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi: shape torch.Size([1, 1, 81, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-faks0.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi: shape (182, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-audio-fjwb0.wav: shape (182, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi: shape torch.Size([1, 1, 182, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-audio-fjwb0.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-audio-fram1.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-audio-fram1.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi: shape (106, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-audio-fkms0.wav: shape (106, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi: shape torch.Size([1, 1, 106, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-audio-fkms0.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi: shape (113, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-audio-fcft0.wav: shape (112, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi: shape torch.Size([1, 1, 113, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-audio-fcft0.wav: shape torch.Size([1, 104, 113])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([113, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-audio-fcft0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-audio-fcft0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi: shape (149, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mdab0.wav: shape (149, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi: shape torch.Size([1, 1, 149, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mdab0.wav: shape torch.Size([1, 104, 149])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([149, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi: shape (93, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mstk0.wav: shape (93, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi: shape torch.Size([1, 1, 93, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mstk0.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi: shape (69, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-audio-mstk0.wav: shape (69, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi: shape torch.Size([1, 1, 69, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-audio-mstk0.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_real"
      ],
      "metadata": {
        "id": "AkbrG_-FsY5B",
        "outputId": "4e9570bf-879f-4ecc-8e2f-14c8501dc351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'si1364mrjo0': tensor([[ 0.0337, -0.1497, -0.0243,  ...,  0.2315,  0.0290,  0.1629],\n",
              "         [ 0.1824, -0.0650, -0.0055,  ..., -0.1429,  0.1406,  0.1006],\n",
              "         [ 0.1506, -0.0165,  0.0294,  ..., -0.2116,  0.1907, -0.0434],\n",
              "         ...,\n",
              "         [-0.0669,  0.0628,  0.3312,  ..., -0.1542, -0.0586, -0.0743],\n",
              "         [-0.1628,  0.0195,  0.3841,  ..., -0.0440,  0.0142, -0.0896],\n",
              "         [-0.1855,  0.0034,  0.3307,  ...,  0.1063,  0.0212, -0.1072]],\n",
              "        device='cuda:0'),\n",
              " 'si844fdac1': tensor([[ 0.0372, -0.1600, -0.0227,  ...,  0.2216,  0.0322,  0.1591],\n",
              "         [ 0.1889, -0.0792, -0.0043,  ..., -0.1479,  0.1435,  0.0944],\n",
              "         [ 0.1673, -0.0344,  0.0250,  ..., -0.2216,  0.1901, -0.0467],\n",
              "         ...,\n",
              "         [-0.0475,  0.0446,  0.3250,  ..., -0.1681, -0.0527, -0.0792],\n",
              "         [-0.1483,  0.0048,  0.3779,  ..., -0.0552,  0.0187, -0.0937],\n",
              "         [-0.1741, -0.0109,  0.3278,  ...,  0.0910,  0.0260, -0.1122]],\n",
              "        device='cuda:0'),\n",
              " 'si1360fram1': tensor([[ 0.0072, -0.1443, -0.0176,  ...,  0.2343,  0.0249,  0.1746],\n",
              "         [ 0.1128, -0.0520,  0.0250,  ..., -0.1086,  0.1449,  0.0915],\n",
              "         [ 0.0819, -0.0033,  0.0516,  ..., -0.1755,  0.2143, -0.0359],\n",
              "         ...,\n",
              "         [-0.1347,  0.0525,  0.3527,  ..., -0.1316, -0.0646, -0.0771],\n",
              "         [-0.2172,  0.0200,  0.4000,  ..., -0.0223,  0.0024, -0.0948],\n",
              "         [-0.2141,  0.0228,  0.3412,  ...,  0.1099,  0.0125, -0.1113]],\n",
              "        device='cuda:0'),\n",
              " 'sx320fkms0': tensor([[ 0.0043, -0.1467, -0.0145,  ...,  0.2350,  0.0253,  0.1789],\n",
              "         [ 0.1053, -0.0555,  0.0263,  ..., -0.1069,  0.1434,  0.0925],\n",
              "         [ 0.0755, -0.0106,  0.0526,  ..., -0.1696,  0.2176, -0.0276],\n",
              "         ...,\n",
              "         [-0.1449,  0.0434,  0.3575,  ..., -0.1262, -0.0627, -0.0716],\n",
              "         [-0.2193,  0.0163,  0.4002,  ..., -0.0195, -0.0012, -0.0921],\n",
              "         [-0.2154,  0.0206,  0.3437,  ...,  0.1059,  0.0113, -0.1087]],\n",
              "        device='cuda:0'),\n",
              " 'sx189msjs1': tensor([[ 0.0073, -0.1462, -0.0172,  ...,  0.2339,  0.0259,  0.1749],\n",
              "         [ 0.1164, -0.0526,  0.0255,  ..., -0.1054,  0.1460,  0.0934],\n",
              "         [ 0.0841, -0.0058,  0.0518,  ..., -0.1719,  0.2144, -0.0297],\n",
              "         ...,\n",
              "         [-0.1339,  0.0520,  0.3575,  ..., -0.1268, -0.0617, -0.0753],\n",
              "         [-0.2142,  0.0194,  0.4013,  ..., -0.0187,  0.0036, -0.0943],\n",
              "         [-0.2130,  0.0214,  0.3415,  ...,  0.1103,  0.0151, -0.1123]],\n",
              "        device='cuda:0'),\n",
              " 'sx216fjre0': tensor([[-0.0231, -0.1300, -0.0133,  ...,  0.2515,  0.0321,  0.1874],\n",
              "         [ 0.0805, -0.0770,  0.0007,  ..., -0.1145,  0.1688,  0.1001],\n",
              "         [ 0.0564, -0.0450,  0.0237,  ..., -0.1578,  0.2528, -0.0095],\n",
              "         ...,\n",
              "         [-0.1780,  0.0075,  0.3169,  ..., -0.1198, -0.0118, -0.0391],\n",
              "         [-0.2610, -0.0017,  0.3806,  ..., -0.0011,  0.0166, -0.0714],\n",
              "         [-0.2458,  0.0212,  0.3312,  ...,  0.1370,  0.0110, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mwbt0': tensor([[ 0.0039, -0.1435, -0.0142,  ...,  0.2401,  0.0269,  0.1794],\n",
              "         [ 0.1137, -0.0542,  0.0234,  ..., -0.1071,  0.1480,  0.0953],\n",
              "         [ 0.0819, -0.0101,  0.0506,  ..., -0.1676,  0.2249, -0.0256],\n",
              "         ...,\n",
              "         [-0.1467,  0.0447,  0.3564,  ..., -0.1232, -0.0552, -0.0701],\n",
              "         [-0.2228,  0.0163,  0.3984,  ..., -0.0144,  0.0051, -0.0914],\n",
              "         [-0.2210,  0.0221,  0.3417,  ...,  0.1137,  0.0125, -0.1075]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjas0': tensor([[-0.0228, -0.1282, -0.0134,  ...,  0.2526,  0.0328,  0.1881],\n",
              "         [ 0.0863, -0.0750,  0.0033,  ..., -0.1139,  0.1672,  0.1024],\n",
              "         [ 0.0622, -0.0422,  0.0269,  ..., -0.1575,  0.2518, -0.0062],\n",
              "         ...,\n",
              "         [-0.1783,  0.0096,  0.3180,  ..., -0.1156, -0.0099, -0.0376],\n",
              "         [-0.2621,  0.0028,  0.3819,  ...,  0.0036,  0.0165, -0.0723],\n",
              "         [-0.2488,  0.0257,  0.3320,  ...,  0.1455,  0.0125, -0.0875]],\n",
              "        device='cuda:0'),\n",
              " 'si1265fjwb0': tensor([[ 0.0141, -0.1428, -0.0217,  ...,  0.2342,  0.0244,  0.1698],\n",
              "         [ 0.1297, -0.0460,  0.0175,  ..., -0.1117,  0.1411,  0.0958],\n",
              "         [ 0.0944,  0.0059,  0.0498,  ..., -0.1780,  0.2037, -0.0392],\n",
              "         ...,\n",
              "         [-0.1180,  0.0671,  0.3516,  ..., -0.1309, -0.0684, -0.0763],\n",
              "         [-0.2057,  0.0284,  0.4017,  ..., -0.0255,  0.0017, -0.0923],\n",
              "         [-0.2078,  0.0242,  0.3402,  ...,  0.1092,  0.0144, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx289mpgl0': tensor([[ 0.0091, -0.1472, -0.0139,  ...,  0.2412,  0.0297,  0.1820],\n",
              "         [ 0.1253, -0.0425,  0.0244,  ..., -0.0961,  0.1475,  0.1031],\n",
              "         [ 0.0838,  0.0024,  0.0587,  ..., -0.1476,  0.2263, -0.0181],\n",
              "         ...,\n",
              "         [-0.1254,  0.0581,  0.3635,  ..., -0.1057, -0.0637, -0.0620],\n",
              "         [-0.2037,  0.0297,  0.4090,  ..., -0.0036,  0.0025, -0.0869],\n",
              "         [-0.2093,  0.0301,  0.3528,  ...,  0.1138,  0.0200, -0.1104]],\n",
              "        device='cuda:0'),\n",
              " 'si1099mpgl0': tensor([[-0.0186, -0.1369, -0.0121,  ...,  0.2543,  0.0388,  0.1961],\n",
              "         [ 0.0951, -0.0746, -0.0009,  ..., -0.1204,  0.1830,  0.1259],\n",
              "         [ 0.0627, -0.0512,  0.0245,  ..., -0.1554,  0.2666,  0.0121],\n",
              "         ...,\n",
              "         [-0.1634,  0.0064,  0.3123,  ..., -0.1153, -0.0189, -0.0218],\n",
              "         [-0.2512,  0.0022,  0.3781,  ..., -0.0008,  0.0212, -0.0631],\n",
              "         [-0.2526,  0.0166,  0.3380,  ...,  0.1396,  0.0252, -0.0845]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fedw0': tensor([[-0.0159, -0.1243, -0.0121,  ...,  0.2576,  0.0311,  0.1828],\n",
              "         [ 0.0940, -0.0663,  0.0100,  ..., -0.1000,  0.1616,  0.0936],\n",
              "         [ 0.0694, -0.0253,  0.0391,  ..., -0.1477,  0.2515, -0.0189],\n",
              "         ...,\n",
              "         [-0.1754,  0.0226,  0.3289,  ..., -0.1140, -0.0240, -0.0498],\n",
              "         [-0.2544,  0.0087,  0.3896,  ...,  0.0032,  0.0102, -0.0778],\n",
              "         [-0.2409,  0.0304,  0.3369,  ...,  0.1420,  0.0090, -0.0946]],\n",
              "        device='cuda:0'),\n",
              " 'sx306felc0': tensor([[-0.0230, -0.1318, -0.0134,  ...,  0.2511,  0.0324,  0.1886],\n",
              "         [ 0.0821, -0.0792,  0.0004,  ..., -0.1165,  0.1715,  0.1039],\n",
              "         [ 0.0571, -0.0495,  0.0221,  ..., -0.1593,  0.2543, -0.0052],\n",
              "         ...,\n",
              "         [-0.1783,  0.0068,  0.3163,  ..., -0.1184, -0.0096, -0.0371],\n",
              "         [-0.2611, -0.0022,  0.3793,  ..., -0.0020,  0.0187, -0.0710],\n",
              "         [-0.2485,  0.0195,  0.3311,  ...,  0.1379,  0.0142, -0.0877]],\n",
              "        device='cuda:0'),\n",
              " 'sx223faks0': tensor([[-0.0198, -0.1216, -0.0138,  ...,  0.2569,  0.0346,  0.1875],\n",
              "         [ 0.0946, -0.0660,  0.0030,  ..., -0.1066,  0.1677,  0.0958],\n",
              "         [ 0.0709, -0.0275,  0.0338,  ..., -0.1508,  0.2570, -0.0169],\n",
              "         ...,\n",
              "         [-0.1764,  0.0195,  0.3217,  ..., -0.1083, -0.0122, -0.0469],\n",
              "         [-0.2584,  0.0097,  0.3857,  ...,  0.0078,  0.0144, -0.0763],\n",
              "         [-0.2453,  0.0337,  0.3332,  ...,  0.1524,  0.0100, -0.0880]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjwb0': tensor([[ 0.0014, -0.1457, -0.0121,  ...,  0.2378,  0.0261,  0.1801],\n",
              "         [ 0.1052, -0.0560,  0.0262,  ..., -0.1053,  0.1472,  0.0952],\n",
              "         [ 0.0755, -0.0118,  0.0525,  ..., -0.1633,  0.2234, -0.0224],\n",
              "         ...,\n",
              "         [-0.1497,  0.0418,  0.3587,  ..., -0.1237, -0.0549, -0.0682],\n",
              "         [-0.2238,  0.0164,  0.4016,  ..., -0.0134,  0.0036, -0.0915],\n",
              "         [-0.2197,  0.0221,  0.3468,  ...,  0.1102,  0.0137, -0.1092]],\n",
              "        device='cuda:0'),\n",
              " 'sx200mjsw0': tensor([[-2.0566e-02, -1.2432e-01, -1.3577e-02,  ...,  2.5526e-01,\n",
              "           2.9607e-02,  1.8338e-01],\n",
              "         [ 8.5371e-02, -7.2390e-02,  8.2970e-03,  ..., -1.0220e-01,\n",
              "           1.6294e-01,  9.3353e-02],\n",
              "         [ 6.5961e-02, -3.3431e-02,  3.3400e-02,  ..., -1.5043e-01,\n",
              "           2.4809e-01, -1.6579e-02],\n",
              "         ...,\n",
              "         [-1.7590e-01,  1.7300e-02,  3.2030e-01,  ..., -1.2037e-01,\n",
              "          -1.7848e-02, -4.6448e-02],\n",
              "         [-2.5933e-01,  5.5850e-03,  3.8638e-01,  ...,  1.4496e-04,\n",
              "           1.0303e-02, -7.5431e-02],\n",
              "         [-2.4106e-01,  3.0342e-02,  3.3469e-01,  ...,  1.4170e-01,\n",
              "           7.1860e-03, -9.2562e-02]], device='cuda:0'),\n",
              " 'sx23mwbt0': tensor([[ 0.0025, -0.1439, -0.0123,  ...,  0.2402,  0.0273,  0.1814],\n",
              "         [ 0.1076, -0.0529,  0.0255,  ..., -0.1038,  0.1501,  0.0953],\n",
              "         [ 0.0778, -0.0080,  0.0524,  ..., -0.1622,  0.2277, -0.0226],\n",
              "         ...,\n",
              "         [-0.1494,  0.0452,  0.3583,  ..., -0.1193, -0.0559, -0.0675],\n",
              "         [-0.2243,  0.0191,  0.4006,  ..., -0.0101,  0.0037, -0.0907],\n",
              "         [-0.2220,  0.0256,  0.3449,  ...,  0.1151,  0.0124, -0.1069]],\n",
              "        device='cuda:0'),\n",
              " 'sa2mstk0': tensor([[-0.0211, -0.1248, -0.0130,  ...,  0.2558,  0.0336,  0.1869],\n",
              "         [ 0.0907, -0.0702,  0.0030,  ..., -0.1069,  0.1693,  0.0951],\n",
              "         [ 0.0679, -0.0337,  0.0314,  ..., -0.1502,  0.2568, -0.0152],\n",
              "         ...,\n",
              "         [-0.1768,  0.0129,  0.3190,  ..., -0.1128, -0.0107, -0.0433],\n",
              "         [-0.2592,  0.0036,  0.3837,  ...,  0.0052,  0.0164, -0.0740],\n",
              "         [-0.2457,  0.0303,  0.3320,  ...,  0.1474,  0.0099, -0.0883]],\n",
              "        device='cuda:0'),\n",
              " 'si1116fjre0': tensor([[-2.2373e-02, -1.2633e-01, -1.4098e-02,  ...,  2.5344e-01,\n",
              "           3.2464e-02,  1.8662e-01],\n",
              "         [ 8.4849e-02, -7.4590e-02,  1.6153e-03,  ..., -1.1096e-01,\n",
              "           1.6800e-01,  9.7663e-02],\n",
              "         [ 6.1451e-02, -4.0138e-02,  2.6897e-02,  ..., -1.5533e-01,\n",
              "           2.5327e-01, -1.1467e-02],\n",
              "         ...,\n",
              "         [-1.7874e-01,  1.2468e-02,  3.1842e-01,  ..., -1.1770e-01,\n",
              "          -9.5204e-03, -4.1744e-02],\n",
              "         [-2.6057e-01,  2.8049e-03,  3.8228e-01,  ..., -1.7838e-04,\n",
              "           1.6679e-02, -7.1759e-02],\n",
              "         [-2.4418e-01,  2.4986e-02,  3.3159e-01,  ...,  1.4010e-01,\n",
              "           1.0695e-02, -8.9632e-02]], device='cuda:0'),\n",
              " 'sx9mgwt0': tensor([[-0.0214, -0.1309, -0.0114,  ...,  0.2514,  0.0360,  0.1900],\n",
              "         [ 0.0898, -0.0733,  0.0032,  ..., -0.1140,  0.1782,  0.1056],\n",
              "         [ 0.0645, -0.0435,  0.0266,  ..., -0.1557,  0.2635, -0.0037],\n",
              "         ...,\n",
              "         [-0.1762,  0.0087,  0.3198,  ..., -0.1089, -0.0044, -0.0383],\n",
              "         [-0.2592,  0.0020,  0.3801,  ...,  0.0061,  0.0232, -0.0721],\n",
              "         [-0.2493,  0.0244,  0.3318,  ...,  0.1488,  0.0175, -0.0859]],\n",
              "        device='cuda:0'),\n",
              " 'sx104mrjo0': tensor([[-0.0209, -0.1245, -0.0134,  ...,  0.2543,  0.0339,  0.1876],\n",
              "         [ 0.0898, -0.0705,  0.0030,  ..., -0.1103,  0.1670,  0.0977],\n",
              "         [ 0.0675, -0.0334,  0.0315,  ..., -0.1537,  0.2549, -0.0150],\n",
              "         ...,\n",
              "         [-0.1774,  0.0134,  0.3200,  ..., -0.1134, -0.0119, -0.0443],\n",
              "         [-0.2589,  0.0043,  0.3837,  ...,  0.0036,  0.0148, -0.0749],\n",
              "         [-0.2459,  0.0297,  0.3325,  ...,  0.1470,  0.0103, -0.0886]],\n",
              "        device='cuda:0'),\n",
              " 'si2169mgwt0': tensor([[ 0.0336, -0.1531, -0.0254,  ...,  0.2263,  0.0281,  0.1603],\n",
              "         [ 0.1838, -0.0674, -0.0029,  ..., -0.1395,  0.1383,  0.0999],\n",
              "         [ 0.1569, -0.0172,  0.0318,  ..., -0.2119,  0.1815, -0.0405],\n",
              "         ...,\n",
              "         [-0.0598,  0.0635,  0.3335,  ..., -0.1544, -0.0612, -0.0745],\n",
              "         [-0.1578,  0.0195,  0.3855,  ..., -0.0457,  0.0113, -0.0903],\n",
              "         [-0.1800,  0.0007,  0.3317,  ...,  0.0994,  0.0243, -0.1105]],\n",
              "        device='cuda:0'),\n",
              " 'si1553mwbt0': tensor([[ 6.1505e-02, -1.8270e-01, -2.2577e-02,  ...,  2.0218e-01,\n",
              "           4.1628e-02,  1.4101e-01],\n",
              "         [ 2.3370e-01, -1.0931e-01, -2.6595e-02,  ..., -1.7940e-01,\n",
              "           1.5029e-01,  8.2723e-02],\n",
              "         [ 2.1353e-01, -7.0665e-02,  6.1105e-03,  ..., -2.4896e-01,\n",
              "           1.8864e-01, -6.0677e-02],\n",
              "         ...,\n",
              "         [ 6.7605e-03,  2.2074e-04,  2.9472e-01,  ..., -1.9426e-01,\n",
              "          -1.9625e-02, -9.0448e-02],\n",
              "         [-1.0311e-01, -2.8520e-02,  3.5607e-01,  ..., -8.0391e-02,\n",
              "           3.5491e-02, -1.0273e-01],\n",
              "         [-1.3965e-01, -5.1976e-02,  3.1431e-01,  ...,  6.6258e-02,\n",
              "           4.4224e-02, -1.2452e-01]], device='cuda:0'),\n",
              " 'sa2msjs1': tensor([[ 1.4235e-02, -1.4513e-01, -2.1532e-02,  ...,  2.3095e-01,\n",
              "           2.5181e-02,  1.6905e-01],\n",
              "         [ 1.2928e-01, -4.6622e-02,  1.9454e-02,  ..., -1.0818e-01,\n",
              "           1.4347e-01,  9.6025e-02],\n",
              "         [ 9.5176e-02,  6.3880e-03,  5.1152e-02,  ..., -1.7624e-01,\n",
              "           2.0259e-01, -3.6020e-02],\n",
              "         ...,\n",
              "         [-1.1317e-01,  7.3411e-02,  3.5462e-01,  ..., -1.2877e-01,\n",
              "          -7.1437e-02, -7.5461e-02],\n",
              "         [-2.0168e-01,  3.3741e-02,  4.0441e-01,  ..., -2.5533e-02,\n",
              "           3.2468e-04, -9.1011e-02],\n",
              "         [-2.0372e-01,  2.4952e-02,  3.4008e-01,  ...,  1.0835e-01,\n",
              "           1.7668e-02, -1.1255e-01]], device='cuda:0'),\n",
              " 'sx230fkms0': tensor([[ 0.0099, -0.1432, -0.0189,  ...,  0.2350,  0.0241,  0.1734],\n",
              "         [ 0.1157, -0.0471,  0.0227,  ..., -0.1075,  0.1401,  0.0927],\n",
              "         [ 0.0787,  0.0032,  0.0529,  ..., -0.1737,  0.2096, -0.0391],\n",
              "         ...,\n",
              "         [-0.1323,  0.0580,  0.3581,  ..., -0.1272, -0.0680, -0.0772],\n",
              "         [-0.2130,  0.0245,  0.4033,  ..., -0.0235, -0.0026, -0.0933],\n",
              "         [-0.2112,  0.0247,  0.3416,  ...,  0.1081,  0.0125, -0.1114]],\n",
              "        device='cuda:0'),\n",
              " 'si1474fdac1': tensor([[-0.0223, -0.1241, -0.0143,  ...,  0.2549,  0.0315,  0.1851],\n",
              "         [ 0.0852, -0.0735,  0.0039,  ..., -0.1076,  0.1661,  0.0936],\n",
              "         [ 0.0636, -0.0357,  0.0295,  ..., -0.1536,  0.2516, -0.0161],\n",
              "         ...,\n",
              "         [-0.1792,  0.0141,  0.3181,  ..., -0.1202, -0.0127, -0.0437],\n",
              "         [-0.2618,  0.0035,  0.3835,  ...,  0.0013,  0.0143, -0.0738],\n",
              "         [-0.2431,  0.0288,  0.3322,  ...,  0.1423,  0.0074, -0.0901]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mgwt0': tensor([[ 0.0157, -0.1426, -0.0225,  ...,  0.2340,  0.0251,  0.1705],\n",
              "         [ 0.1358, -0.0458,  0.0164,  ..., -0.1124,  0.1431,  0.0963],\n",
              "         [ 0.1002,  0.0073,  0.0487,  ..., -0.1790,  0.2041, -0.0384],\n",
              "         ...,\n",
              "         [-0.1153,  0.0727,  0.3511,  ..., -0.1286, -0.0679, -0.0758],\n",
              "         [-0.2035,  0.0304,  0.3997,  ..., -0.0248,  0.0038, -0.0912],\n",
              "         [-0.2067,  0.0258,  0.3377,  ...,  0.1121,  0.0160, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx140fkms0': tensor([[ 0.0077, -0.1453, -0.0176,  ...,  0.2353,  0.0241,  0.1758],\n",
              "         [ 0.1138, -0.0524,  0.0235,  ..., -0.1104,  0.1378,  0.0935],\n",
              "         [ 0.0793, -0.0042,  0.0529,  ..., -0.1748,  0.2106, -0.0350],\n",
              "         ...,\n",
              "         [-0.1374,  0.0492,  0.3580,  ..., -0.1281, -0.0658, -0.0750],\n",
              "         [-0.2139,  0.0186,  0.4009,  ..., -0.0234, -0.0023, -0.0930],\n",
              "         [-0.2123,  0.0201,  0.3418,  ...,  0.1057,  0.0116, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx109mpgl0': tensor([[ 0.0125, -0.1453, -0.0172,  ...,  0.2368,  0.0287,  0.1775],\n",
              "         [ 0.1243, -0.0357,  0.0251,  ..., -0.0919,  0.1434,  0.1002],\n",
              "         [ 0.0819,  0.0137,  0.0616,  ..., -0.1489,  0.2137, -0.0226],\n",
              "         ...,\n",
              "         [-0.1216,  0.0779,  0.3657,  ..., -0.1059, -0.0737, -0.0661],\n",
              "         [-0.2051,  0.0424,  0.4145,  ..., -0.0041, -0.0017, -0.0865],\n",
              "         [-0.2074,  0.0359,  0.3505,  ...,  0.1167,  0.0193, -0.1128]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fram1': tensor([[ 0.0096, -0.1445, -0.0188,  ...,  0.2341,  0.0255,  0.1731],\n",
              "         [ 0.1209, -0.0516,  0.0236,  ..., -0.1100,  0.1445,  0.0923],\n",
              "         [ 0.0881, -0.0040,  0.0508,  ..., -0.1765,  0.2108, -0.0340],\n",
              "         ...,\n",
              "         [-0.1282,  0.0568,  0.3528,  ..., -0.1327, -0.0645, -0.0769],\n",
              "         [-0.2121,  0.0227,  0.4002,  ..., -0.0256,  0.0025, -0.0935],\n",
              "         [-0.2117,  0.0225,  0.3407,  ...,  0.1086,  0.0131, -0.1112]],\n",
              "        device='cuda:0'),\n",
              " 'si1544fdrd1': tensor([[-0.0228, -0.1244, -0.0136,  ...,  0.2544,  0.0333,  0.1861],\n",
              "         [ 0.0877, -0.0725,  0.0032,  ..., -0.1052,  0.1718,  0.0950],\n",
              "         [ 0.0657, -0.0362,  0.0284,  ..., -0.1505,  0.2579, -0.0136],\n",
              "         ...,\n",
              "         [-0.1788,  0.0141,  0.3192,  ..., -0.1124, -0.0072, -0.0425],\n",
              "         [-0.2622,  0.0046,  0.3836,  ...,  0.0074,  0.0181, -0.0730],\n",
              "         [-0.2453,  0.0315,  0.3318,  ...,  0.1485,  0.0100, -0.0877]],\n",
              "        device='cuda:0'),\n",
              " 'sx281mrcz0': tensor([[ 0.0108, -0.1414, -0.0185,  ...,  0.2367,  0.0239,  0.1747],\n",
              "         [ 0.1197, -0.0464,  0.0243,  ..., -0.1049,  0.1416,  0.0954],\n",
              "         [ 0.0828,  0.0042,  0.0540,  ..., -0.1708,  0.2113, -0.0317],\n",
              "         ...,\n",
              "         [-0.1299,  0.0612,  0.3583,  ..., -0.1256, -0.0695, -0.0740],\n",
              "         [-0.2127,  0.0282,  0.4048,  ..., -0.0185, -0.0025, -0.0921],\n",
              "         [-0.2130,  0.0293,  0.3430,  ...,  0.1139,  0.0109, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx102mmdm2': tensor([[ 0.0099, -0.1444, -0.0191,  ...,  0.2345,  0.0243,  0.1732],\n",
              "         [ 0.1206, -0.0480,  0.0227,  ..., -0.1083,  0.1412,  0.0937],\n",
              "         [ 0.0851,  0.0026,  0.0520,  ..., -0.1747,  0.2084, -0.0363],\n",
              "         ...,\n",
              "         [-0.1286,  0.0593,  0.3556,  ..., -0.1282, -0.0657, -0.0769],\n",
              "         [-0.2117,  0.0249,  0.4013,  ..., -0.0229,  0.0014, -0.0929],\n",
              "         [-0.2112,  0.0226,  0.3404,  ...,  0.1090,  0.0144, -0.1116]],\n",
              "        device='cuda:0'),\n",
              " 'sx185mmdb1': tensor([[-0.0008, -0.1455, -0.0117,  ...,  0.2385,  0.0272,  0.1809],\n",
              "         [ 0.1028, -0.0586,  0.0260,  ..., -0.1037,  0.1539,  0.0951],\n",
              "         [ 0.0756, -0.0155,  0.0496,  ..., -0.1623,  0.2313, -0.0202],\n",
              "         ...,\n",
              "         [-0.1540,  0.0379,  0.3549,  ..., -0.1217, -0.0499, -0.0673],\n",
              "         [-0.2266,  0.0131,  0.3980,  ..., -0.0109,  0.0073, -0.0911],\n",
              "         [-0.2216,  0.0204,  0.3448,  ...,  0.1126,  0.0151, -0.1079]],\n",
              "        device='cuda:0'),\n",
              " 'sx184fjem0': tensor([[ 0.0627, -0.1800, -0.0228,  ...,  0.2009,  0.0405,  0.1383],\n",
              "         [ 0.2294, -0.1084, -0.0298,  ..., -0.1753,  0.1510,  0.0822],\n",
              "         [ 0.2121, -0.0680,  0.0026,  ..., -0.2462,  0.1867, -0.0631],\n",
              "         ...,\n",
              "         [ 0.0105, -0.0010,  0.2849,  ..., -0.1989, -0.0188, -0.0953],\n",
              "         [-0.1019, -0.0282,  0.3538,  ..., -0.0850,  0.0350, -0.1082],\n",
              "         [-0.1363, -0.0527,  0.3155,  ...,  0.0635,  0.0465, -0.1290]],\n",
              "        device='cuda:0'),\n",
              " 'sx365mmdb1': tensor([[ 0.0189, -0.1429, -0.0273,  ...,  0.2287,  0.0198,  0.1659],\n",
              "         [ 0.1387, -0.0433,  0.0144,  ..., -0.1126,  0.1343,  0.0973],\n",
              "         [ 0.1041,  0.0092,  0.0482,  ..., -0.1829,  0.1884, -0.0393],\n",
              "         ...,\n",
              "         [-0.1017,  0.0791,  0.3475,  ..., -0.1311, -0.0814, -0.0719],\n",
              "         [-0.1917,  0.0361,  0.4035,  ..., -0.0290, -0.0074, -0.0912],\n",
              "         [-0.1993,  0.0261,  0.3404,  ...,  0.1044,  0.0148, -0.1118]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fdac1': tensor([[-0.0096, -0.1351, -0.0107,  ...,  0.2502,  0.0263,  0.1819],\n",
              "         [ 0.0917, -0.0663,  0.0195,  ..., -0.1041,  0.1569,  0.0924],\n",
              "         [ 0.0691, -0.0242,  0.0439,  ..., -0.1581,  0.2405, -0.0214],\n",
              "         ...,\n",
              "         [-0.1706,  0.0274,  0.3375,  ..., -0.1245, -0.0385, -0.0582],\n",
              "         [-0.2457,  0.0081,  0.3919,  ..., -0.0069,  0.0091, -0.0836],\n",
              "         [-0.2371,  0.0232,  0.3402,  ...,  0.1232,  0.0100, -0.1003]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mjar0': tensor([[ 0.0532, -0.1684, -0.0249,  ...,  0.2132,  0.0353,  0.1472],\n",
              "         [ 0.2159, -0.0904, -0.0206,  ..., -0.1643,  0.1445,  0.0897],\n",
              "         [ 0.1917, -0.0461,  0.0133,  ..., -0.2360,  0.1837, -0.0566],\n",
              "         ...,\n",
              "         [-0.0119,  0.0267,  0.3048,  ..., -0.1833, -0.0404, -0.0861],\n",
              "         [-0.1189, -0.0074,  0.3655,  ..., -0.0693,  0.0234, -0.0999],\n",
              "         [-0.1514, -0.0314,  0.3202,  ...,  0.0800,  0.0357, -0.1196]],\n",
              "        device='cuda:0'),\n",
              " 'sa1faks0': tensor([[-0.0211, -0.1240, -0.0142,  ...,  0.2552,  0.0333,  0.1860],\n",
              "         [ 0.0910, -0.0726,  0.0039,  ..., -0.1054,  0.1680,  0.0934],\n",
              "         [ 0.0694, -0.0339,  0.0302,  ..., -0.1517,  0.2542, -0.0162],\n",
              "         ...,\n",
              "         [-0.1796,  0.0163,  0.3204,  ..., -0.1158, -0.0099, -0.0448],\n",
              "         [-0.2614,  0.0051,  0.3837,  ...,  0.0039,  0.0168, -0.0745],\n",
              "         [-0.2445,  0.0309,  0.3306,  ...,  0.1469,  0.0087, -0.0886]],\n",
              "        device='cuda:0'),\n",
              " 'sx110mjsw0': tensor([[-0.0230, -0.1272, -0.0126,  ...,  0.2527,  0.0312,  0.1872],\n",
              "         [ 0.0824, -0.0747,  0.0043,  ..., -0.1114,  0.1686,  0.1000],\n",
              "         [ 0.0599, -0.0402,  0.0278,  ..., -0.1552,  0.2525, -0.0095],\n",
              "         ...,\n",
              "         [-0.1771,  0.0112,  0.3174,  ..., -0.1171, -0.0092, -0.0384],\n",
              "         [-0.2614,  0.0028,  0.3823,  ...,  0.0014,  0.0166, -0.0713],\n",
              "         [-0.2464,  0.0251,  0.3335,  ...,  0.1426,  0.0131, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa2faks0': tensor([[-2.2797e-02, -1.3038e-01, -1.4583e-02,  ...,  2.5046e-01,\n",
              "           3.3861e-02,  1.9000e-01],\n",
              "         [ 8.7162e-02, -7.9114e-02, -2.3932e-03,  ..., -1.1778e-01,\n",
              "           1.7294e-01,  1.0336e-01],\n",
              "         [ 6.2019e-02, -4.9000e-02,  1.9768e-02,  ..., -1.5948e-01,\n",
              "           2.5668e-01, -5.8069e-03],\n",
              "         ...,\n",
              "         [-1.8025e-01,  6.4512e-03,  3.1554e-01,  ..., -1.1420e-01,\n",
              "          -1.4576e-03, -3.9848e-02],\n",
              "         [-2.6216e-01, -2.3430e-03,  3.7725e-01,  ...,  3.1153e-04,\n",
              "           2.3854e-02, -7.2195e-02],\n",
              "         [-2.5041e-01,  2.1052e-02,  3.2726e-01,  ...,  1.4220e-01,\n",
              "           1.5340e-02, -8.4601e-02]], device='cuda:0'),\n",
              " 'si992fjwb0': tensor([[ 0.1106, -0.2704, -0.0029,  ...,  0.1403,  0.0545,  0.0792],\n",
              "         [ 0.2836, -0.2338, -0.0565,  ..., -0.2338,  0.1671,  0.0300],\n",
              "         [ 0.2622, -0.2131, -0.0345,  ..., -0.2746,  0.2050, -0.1089],\n",
              "         ...,\n",
              "         [ 0.0525, -0.1699,  0.1857,  ..., -0.2776,  0.0535, -0.1642],\n",
              "         [-0.0541, -0.1844,  0.2951,  ..., -0.1654,  0.0956, -0.1783],\n",
              "         [-0.0763, -0.1990,  0.3075,  ...,  0.0047,  0.0933, -0.1868]],\n",
              "        device='cuda:0'),\n",
              " 'sx280fram1': tensor([[-0.0245, -0.1269, -0.0143,  ...,  0.2529,  0.0314,  0.1862],\n",
              "         [ 0.0812, -0.0773,  0.0037,  ..., -0.1113,  0.1689,  0.0971],\n",
              "         [ 0.0591, -0.0439,  0.0255,  ..., -0.1558,  0.2508, -0.0092],\n",
              "         ...,\n",
              "         [-0.1792,  0.0124,  0.3177,  ..., -0.1220, -0.0104, -0.0404],\n",
              "         [-0.2623,  0.0022,  0.3823,  ..., -0.0024,  0.0153, -0.0712],\n",
              "         [-0.2448,  0.0259,  0.3310,  ...,  0.1388,  0.0093, -0.0890]],\n",
              "        device='cuda:0'),\n",
              " 'si2120fkms0': tensor([[ 0.0054, -0.1454, -0.0156,  ...,  0.2354,  0.0253,  0.1782],\n",
              "         [ 0.1074, -0.0538,  0.0252,  ..., -0.1072,  0.1432,  0.0924],\n",
              "         [ 0.0770, -0.0072,  0.0515,  ..., -0.1712,  0.2175, -0.0318],\n",
              "         ...,\n",
              "         [-0.1448,  0.0452,  0.3572,  ..., -0.1270, -0.0615, -0.0736],\n",
              "         [-0.2198,  0.0166,  0.4000,  ..., -0.0196,  0.0007, -0.0936],\n",
              "         [-0.2160,  0.0224,  0.3418,  ...,  0.1089,  0.0110, -0.1090]],\n",
              "        device='cuda:0'),\n",
              " 'si1808fcft0': tensor([[ 0.0073, -0.1452, -0.0176,  ...,  0.2340,  0.0252,  0.1749],\n",
              "         [ 0.1147, -0.0546,  0.0241,  ..., -0.1093,  0.1452,  0.0916],\n",
              "         [ 0.0851, -0.0077,  0.0499,  ..., -0.1764,  0.2149, -0.0355],\n",
              "         ...,\n",
              "         [-0.1363,  0.0507,  0.3540,  ..., -0.1306, -0.0620, -0.0764],\n",
              "         [-0.2164,  0.0180,  0.3983,  ..., -0.0218,  0.0038, -0.0939],\n",
              "         [-0.2141,  0.0207,  0.3396,  ...,  0.1078,  0.0122, -0.1108]],\n",
              "        device='cuda:0'),\n",
              " 'si1178fcft0': tensor([[ 3.6749e-02, -1.5935e-01, -2.1553e-02,  ...,  2.2148e-01,\n",
              "           3.0667e-02,  1.6090e-01],\n",
              "         [ 1.8511e-01, -8.0462e-02,  7.8195e-05,  ..., -1.4571e-01,\n",
              "           1.4074e-01,  9.4329e-02],\n",
              "         [ 1.6743e-01, -3.5364e-02,  2.7424e-02,  ..., -2.2293e-01,\n",
              "           1.8783e-01, -4.5636e-02],\n",
              "         ...,\n",
              "         [-5.2479e-02,  4.4527e-02,  3.2721e-01,  ..., -1.6802e-01,\n",
              "          -5.3071e-02, -7.9380e-02],\n",
              "         [-1.5103e-01,  4.8072e-03,  3.7890e-01,  ..., -5.5657e-02,\n",
              "           1.8111e-02, -9.3312e-02],\n",
              "         [-1.7642e-01, -9.1262e-03,  3.2792e-01,  ...,  9.2908e-02,\n",
              "           2.3915e-02, -1.1017e-01]], device='cuda:0'),\n",
              " 'sa1mdab0': tensor([[ 0.0612, -0.1850, -0.0193,  ...,  0.2024,  0.0413,  0.1423],\n",
              "         [ 0.2303, -0.1170, -0.0235,  ..., -0.1787,  0.1497,  0.0797],\n",
              "         [ 0.2144, -0.0805,  0.0057,  ..., -0.2491,  0.1912, -0.0640],\n",
              "         ...,\n",
              "         [ 0.0039, -0.0100,  0.2945,  ..., -0.1990, -0.0182, -0.0910],\n",
              "         [-0.1054, -0.0354,  0.3551,  ..., -0.0832,  0.0373, -0.1030],\n",
              "         [-0.1422, -0.0545,  0.3141,  ...,  0.0671,  0.0413, -0.1223]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mstk0': tensor([[-0.0148, -0.1270, -0.0115,  ...,  0.2550,  0.0294,  0.1838],\n",
              "         [ 0.0945, -0.0673,  0.0117,  ..., -0.1015,  0.1606,  0.0923],\n",
              "         [ 0.0725, -0.0254,  0.0402,  ..., -0.1516,  0.2492, -0.0209],\n",
              "         ...,\n",
              "         [-0.1737,  0.0220,  0.3287,  ..., -0.1149, -0.0252, -0.0524],\n",
              "         [-0.2525,  0.0080,  0.3890,  ...,  0.0017,  0.0114, -0.0795],\n",
              "         [-0.2423,  0.0296,  0.3361,  ...,  0.1401,  0.0086, -0.0935]],\n",
              "        device='cuda:0'),\n",
              " 'si2284mstk0': tensor([[-0.0221, -0.1369, -0.0167,  ...,  0.2465,  0.0372,  0.1958],\n",
              "         [ 0.0826, -0.0840, -0.0174,  ..., -0.1343,  0.1787,  0.1211],\n",
              "         [ 0.0510, -0.0636,  0.0007,  ..., -0.1726,  0.2626,  0.0089],\n",
              "         ...,\n",
              "         [-0.1771, -0.0130,  0.3044,  ..., -0.1168,  0.0019, -0.0271],\n",
              "         [-0.2629, -0.0142,  0.3658,  ..., -0.0056,  0.0308, -0.0659],\n",
              "         [-0.2576,  0.0076,  0.3243,  ...,  0.1383,  0.0224, -0.0805]],\n",
              "        device='cuda:0'),\n",
              " 'sx50fkms0': tensor([[ 0.0080, -0.1466, -0.0177,  ...,  0.2326,  0.0248,  0.1749],\n",
              "         [ 0.1131, -0.0524,  0.0254,  ..., -0.1085,  0.1394,  0.0936],\n",
              "         [ 0.0793, -0.0036,  0.0533,  ..., -0.1747,  0.2085, -0.0322],\n",
              "         ...,\n",
              "         [-0.1352,  0.0526,  0.3588,  ..., -0.1280, -0.0657, -0.0756],\n",
              "         [-0.2123,  0.0204,  0.4024,  ..., -0.0239, -0.0013, -0.0933],\n",
              "         [-0.2105,  0.0205,  0.3413,  ...,  0.1054,  0.0132, -0.1110]],\n",
              "        device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_deep"
      ],
      "metadata": {
        "id": "X6xDeKtVscGP",
        "outputId": "8bc846d7-5fd9-43af-d6ef-756bb3406569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'si1364mrjo0': tensor([[ 0.0321, -0.1495, -0.0234,  ...,  0.2316,  0.0286,  0.1641],\n",
              "         [ 0.1767, -0.0651, -0.0033,  ..., -0.1411,  0.1404,  0.0989],\n",
              "         [ 0.1460, -0.0175,  0.0306,  ..., -0.2103,  0.1939, -0.0450],\n",
              "         ...,\n",
              "         [-0.0735,  0.0599,  0.3316,  ..., -0.1554, -0.0606, -0.0764],\n",
              "         [-0.1686,  0.0165,  0.3847,  ..., -0.0434,  0.0144, -0.0920],\n",
              "         [-0.1892,  0.0049,  0.3314,  ...,  0.1092,  0.0190, -0.1077]],\n",
              "        device='cuda:0'),\n",
              " 'si844fdac1': tensor([[ 0.0344, -0.1576, -0.0225,  ...,  0.2241,  0.0302,  0.1604],\n",
              "         [ 0.1824, -0.0761, -0.0015,  ..., -0.1453,  0.1417,  0.0947],\n",
              "         [ 0.1597, -0.0310,  0.0280,  ..., -0.2187,  0.1911, -0.0478],\n",
              "         ...,\n",
              "         [-0.0572,  0.0468,  0.3266,  ..., -0.1675, -0.0557, -0.0794],\n",
              "         [-0.1559,  0.0062,  0.3804,  ..., -0.0533,  0.0173, -0.0945],\n",
              "         [-0.1803, -0.0074,  0.3302,  ...,  0.0945,  0.0230, -0.1122]],\n",
              "        device='cuda:0'),\n",
              " 'si1360fram1': tensor([[-0.0308, -0.1419, -0.0235,  ...,  0.2269,  0.0422,  0.1903],\n",
              "         [ 0.0971, -0.0689,  0.0105,  ..., -0.1291,  0.1926,  0.0746],\n",
              "         [ 0.1010, -0.0227,  0.0086,  ..., -0.2004,  0.2591, -0.0281],\n",
              "         ...,\n",
              "         [-0.1573,  0.0333,  0.3409,  ..., -0.0660, -0.0106, -0.0604],\n",
              "         [-0.2623,  0.0215,  0.3735,  ...,  0.0580,  0.0306, -0.0942],\n",
              "         [-0.2394,  0.0821,  0.3034,  ...,  0.2322,  0.0225, -0.0251]],\n",
              "        device='cuda:0'),\n",
              " 'sx320fkms0': tensor([[ 0.0033, -0.1466, -0.0141,  ...,  0.2357,  0.0249,  0.1795],\n",
              "         [ 0.1015, -0.0565,  0.0264,  ..., -0.1074,  0.1423,  0.0924],\n",
              "         [ 0.0730, -0.0114,  0.0520,  ..., -0.1699,  0.2185, -0.0294],\n",
              "         ...,\n",
              "         [-0.1478,  0.0408,  0.3555,  ..., -0.1286, -0.0634, -0.0718],\n",
              "         [-0.2213,  0.0149,  0.4005,  ..., -0.0199, -0.0023, -0.0930],\n",
              "         [-0.2178,  0.0209,  0.3446,  ...,  0.1070,  0.0110, -0.1091]],\n",
              "        device='cuda:0'),\n",
              " 'sx189msjs1': tensor([[ 0.0042, -0.1437, -0.0151,  ...,  0.2371,  0.0259,  0.1774],\n",
              "         [ 0.1066, -0.0525,  0.0262,  ..., -0.1054,  0.1465,  0.0919],\n",
              "         [ 0.0773, -0.0061,  0.0519,  ..., -0.1691,  0.2214, -0.0330],\n",
              "         ...,\n",
              "         [-0.1467,  0.0469,  0.3552,  ..., -0.1283, -0.0615, -0.0755],\n",
              "         [-0.2243,  0.0172,  0.4010,  ..., -0.0161,  0.0024, -0.0957],\n",
              "         [-0.2213,  0.0255,  0.3425,  ...,  0.1165,  0.0116, -0.1106]],\n",
              "        device='cuda:0'),\n",
              " 'sx216fjre0': tensor([[-0.0236, -0.1295, -0.0137,  ...,  0.2521,  0.0314,  0.1868],\n",
              "         [ 0.0791, -0.0777,  0.0005,  ..., -0.1153,  0.1660,  0.1001],\n",
              "         [ 0.0555, -0.0443,  0.0233,  ..., -0.1594,  0.2500, -0.0101],\n",
              "         ...,\n",
              "         [-0.1790,  0.0073,  0.3151,  ..., -0.1219, -0.0127, -0.0392],\n",
              "         [-0.2623, -0.0021,  0.3807,  ..., -0.0025,  0.0152, -0.0719],\n",
              "         [-0.2463,  0.0214,  0.3320,  ...,  0.1376,  0.0098, -0.0898]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mwbt0': tensor([[ 0.0031, -0.1445, -0.0142,  ...,  0.2392,  0.0263,  0.1791],\n",
              "         [ 0.1084, -0.0542,  0.0242,  ..., -0.1078,  0.1457,  0.0941],\n",
              "         [ 0.0775, -0.0099,  0.0515,  ..., -0.1679,  0.2235, -0.0284],\n",
              "         ...,\n",
              "         [-0.1477,  0.0425,  0.3550,  ..., -0.1259, -0.0583, -0.0712],\n",
              "         [-0.2236,  0.0154,  0.3998,  ..., -0.0153,  0.0029, -0.0936],\n",
              "         [-0.2208,  0.0217,  0.3439,  ...,  0.1126,  0.0125, -0.1097]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjas0': tensor([[-0.0230, -0.1290, -0.0131,  ...,  0.2524,  0.0320,  0.1879],\n",
              "         [ 0.0839, -0.0755,  0.0037,  ..., -0.1131,  0.1666,  0.1012],\n",
              "         [ 0.0607, -0.0419,  0.0271,  ..., -0.1571,  0.2509, -0.0081],\n",
              "         ...,\n",
              "         [-0.1770,  0.0097,  0.3169,  ..., -0.1166, -0.0121, -0.0385],\n",
              "         [-0.2614,  0.0028,  0.3825,  ...,  0.0018,  0.0150, -0.0729],\n",
              "         [-0.2487,  0.0262,  0.3330,  ...,  0.1455,  0.0117, -0.0884]],\n",
              "        device='cuda:0'),\n",
              " 'si1265fjwb0': tensor([[ 0.0138, -0.1436, -0.0218,  ...,  0.2345,  0.0243,  0.1699],\n",
              "         [ 0.1300, -0.0487,  0.0172,  ..., -0.1144,  0.1404,  0.0950],\n",
              "         [ 0.0960,  0.0017,  0.0485,  ..., -0.1810,  0.2043, -0.0406],\n",
              "         ...,\n",
              "         [-0.1192,  0.0622,  0.3496,  ..., -0.1352, -0.0676, -0.0770],\n",
              "         [-0.2061,  0.0241,  0.3997,  ..., -0.0279,  0.0023, -0.0928],\n",
              "         [-0.2087,  0.0219,  0.3392,  ...,  0.1090,  0.0135, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx289mpgl0': tensor([[ 0.0067, -0.1468, -0.0138,  ...,  0.2424,  0.0296,  0.1823],\n",
              "         [ 0.1197, -0.0448,  0.0236,  ..., -0.0981,  0.1496,  0.1020],\n",
              "         [ 0.0805, -0.0008,  0.0562,  ..., -0.1495,  0.2295, -0.0192],\n",
              "         ...,\n",
              "         [-0.1326,  0.0536,  0.3615,  ..., -0.1093, -0.0615, -0.0624],\n",
              "         [-0.2088,  0.0253,  0.4066,  ..., -0.0050,  0.0031, -0.0876],\n",
              "         [-0.2124,  0.0284,  0.3515,  ...,  0.1142,  0.0193, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'si1099mpgl0': tensor([[-0.0200, -0.1367, -0.0128,  ...,  0.2536,  0.0387,  0.1959],\n",
              "         [ 0.0926, -0.0763, -0.0027,  ..., -0.1226,  0.1849,  0.1244],\n",
              "         [ 0.0613, -0.0527,  0.0213,  ..., -0.1576,  0.2684,  0.0109],\n",
              "         ...,\n",
              "         [-0.1648,  0.0023,  0.3086,  ..., -0.1171, -0.0151, -0.0211],\n",
              "         [-0.2534, -0.0016,  0.3757,  ..., -0.0013,  0.0238, -0.0634],\n",
              "         [-0.2530,  0.0152,  0.3364,  ...,  0.1407,  0.0246, -0.0845]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fedw0': tensor([[-0.0169, -0.1245, -0.0130,  ...,  0.2566,  0.0309,  0.1835],\n",
              "         [ 0.0929, -0.0679,  0.0081,  ..., -0.1033,  0.1603,  0.0930],\n",
              "         [ 0.0704, -0.0266,  0.0370,  ..., -0.1508,  0.2497, -0.0202],\n",
              "         ...,\n",
              "         [-0.1761,  0.0210,  0.3257,  ..., -0.1154, -0.0213, -0.0500],\n",
              "         [-0.2561,  0.0078,  0.3880,  ...,  0.0029,  0.0115, -0.0780],\n",
              "         [-0.2421,  0.0300,  0.3354,  ...,  0.1433,  0.0085, -0.0936]],\n",
              "        device='cuda:0'),\n",
              " 'sx306felc0': tensor([[-0.0240, -0.1317, -0.0146,  ...,  0.2502,  0.0328,  0.1892],\n",
              "         [ 0.0806, -0.0807, -0.0024,  ..., -0.1192,  0.1713,  0.1043],\n",
              "         [ 0.0566, -0.0505,  0.0187,  ..., -0.1625,  0.2546, -0.0061],\n",
              "         ...,\n",
              "         [-0.1796,  0.0053,  0.3140,  ..., -0.1190, -0.0064, -0.0374],\n",
              "         [-0.2628, -0.0031,  0.3776,  ..., -0.0025,  0.0204, -0.0715],\n",
              "         [-0.2495,  0.0187,  0.3296,  ...,  0.1377,  0.0141, -0.0870]],\n",
              "        device='cuda:0'),\n",
              " 'sx223faks0': tensor([[-0.0200, -0.1223, -0.0142,  ...,  0.2563,  0.0337,  0.1870],\n",
              "         [ 0.0926, -0.0685,  0.0018,  ..., -0.1081,  0.1645,  0.0956],\n",
              "         [ 0.0700, -0.0290,  0.0319,  ..., -0.1528,  0.2535, -0.0179],\n",
              "         ...,\n",
              "         [-0.1771,  0.0176,  0.3188,  ..., -0.1118, -0.0135, -0.0468],\n",
              "         [-0.2602,  0.0082,  0.3849,  ...,  0.0060,  0.0134, -0.0764],\n",
              "         [-0.2459,  0.0322,  0.3324,  ...,  0.1510,  0.0090, -0.0888]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjwb0': tensor([[-0.0008, -0.1453, -0.0118,  ...,  0.2387,  0.0262,  0.1808],\n",
              "         [ 0.1013, -0.0575,  0.0264,  ..., -0.1065,  0.1495,  0.0939],\n",
              "         [ 0.0748, -0.0143,  0.0510,  ..., -0.1645,  0.2261, -0.0232],\n",
              "         ...,\n",
              "         [-0.1543,  0.0391,  0.3539,  ..., -0.1272, -0.0537, -0.0672],\n",
              "         [-0.2283,  0.0144,  0.3993,  ..., -0.0139,  0.0052, -0.0914],\n",
              "         [-0.2232,  0.0218,  0.3454,  ...,  0.1118,  0.0130, -0.1083]],\n",
              "        device='cuda:0'),\n",
              " 'sx200mjsw0': tensor([[-2.1014e-02, -1.2408e-01, -1.2605e-02,  ...,  2.5589e-01,\n",
              "           2.9466e-02,  1.8257e-01],\n",
              "         [ 8.3613e-02, -7.0768e-02,  9.0826e-03,  ..., -1.0080e-01,\n",
              "           1.6260e-01,  9.1813e-02],\n",
              "         [ 6.3595e-02, -3.2072e-02,  3.4370e-02,  ..., -1.4866e-01,\n",
              "           2.4855e-01, -1.7632e-02],\n",
              "         ...,\n",
              "         [-1.7604e-01,  1.6261e-02,  3.1865e-01,  ..., -1.2207e-01,\n",
              "          -2.0170e-02, -4.4449e-02],\n",
              "         [-2.5951e-01,  5.0842e-03,  3.8657e-01,  ...,  1.8064e-04,\n",
              "           1.0752e-02, -7.4890e-02],\n",
              "         [-2.4036e-01,  3.0519e-02,  3.3597e-01,  ...,  1.4265e-01,\n",
              "           6.8874e-03, -9.3277e-02]], device='cuda:0'),\n",
              " 'sx23mwbt0': tensor([[ 0.0023, -0.1446, -0.0126,  ...,  0.2393,  0.0263,  0.1808],\n",
              "         [ 0.1036, -0.0541,  0.0260,  ..., -0.1059,  0.1456,  0.0945],\n",
              "         [ 0.0744, -0.0090,  0.0531,  ..., -0.1643,  0.2244, -0.0265],\n",
              "         ...,\n",
              "         [-0.1494,  0.0430,  0.3565,  ..., -0.1250, -0.0616, -0.0681],\n",
              "         [-0.2245,  0.0178,  0.4014,  ..., -0.0138, -0.0004, -0.0917],\n",
              "         [-0.2217,  0.0242,  0.3459,  ...,  0.1130,  0.0114, -0.1082]],\n",
              "        device='cuda:0'),\n",
              " 'sa2mstk0': tensor([[-0.0224, -0.1248, -0.0142,  ...,  0.2551,  0.0338,  0.1873],\n",
              "         [ 0.0883, -0.0715,  0.0008,  ..., -0.1095,  0.1678,  0.0949],\n",
              "         [ 0.0667, -0.0342,  0.0286,  ..., -0.1532,  0.2556, -0.0168],\n",
              "         ...,\n",
              "         [-0.1775,  0.0119,  0.3157,  ..., -0.1155, -0.0102, -0.0430],\n",
              "         [-0.2611,  0.0033,  0.3822,  ...,  0.0043,  0.0163, -0.0743],\n",
              "         [-0.2459,  0.0300,  0.3312,  ...,  0.1479,  0.0091, -0.0880]],\n",
              "        device='cuda:0'),\n",
              " 'si1116fjre0': tensor([[-2.2920e-02, -1.2627e-01, -1.4684e-02,  ...,  2.5352e-01,\n",
              "           3.2366e-02,  1.8685e-01],\n",
              "         [ 8.2940e-02, -7.5871e-02,  3.0879e-04,  ..., -1.1319e-01,\n",
              "           1.6595e-01,  9.8150e-02],\n",
              "         [ 6.0528e-02, -4.0918e-02,  2.4898e-02,  ..., -1.5813e-01,\n",
              "           2.5163e-01, -1.2298e-02],\n",
              "         ...,\n",
              "         [-1.7897e-01,  1.1056e-02,  3.1452e-01,  ..., -1.1976e-01,\n",
              "          -8.6734e-03, -4.2062e-02],\n",
              "         [-2.6200e-01,  1.7057e-03,  3.8109e-01,  ..., -9.4267e-04,\n",
              "           1.6593e-02, -7.2813e-02],\n",
              "         [-2.4542e-01,  2.4561e-02,  3.3150e-01,  ...,  1.4080e-01,\n",
              "           1.0509e-02, -9.0239e-02]], device='cuda:0'),\n",
              " 'sx9mgwt0': tensor([[-2.1855e-02, -1.3138e-01, -1.2213e-02,  ...,  2.5026e-01,\n",
              "           3.4956e-02,  1.9002e-01],\n",
              "         [ 8.7677e-02, -7.5929e-02,  8.6759e-04,  ..., -1.1736e-01,\n",
              "           1.7456e-01,  1.0564e-01],\n",
              "         [ 6.3008e-02, -4.5173e-02,  2.4336e-02,  ..., -1.5946e-01,\n",
              "           2.5998e-01, -5.2715e-03],\n",
              "         ...,\n",
              "         [-1.7735e-01,  6.5645e-03,  3.1645e-01,  ..., -1.1292e-01,\n",
              "          -4.5673e-03, -3.8324e-02],\n",
              "         [-2.6069e-01, -3.7497e-05,  3.7912e-01,  ...,  2.8420e-03,\n",
              "           2.2369e-02, -7.2859e-02],\n",
              "         [-2.5039e-01,  2.2066e-02,  3.3089e-01,  ...,  1.4717e-01,\n",
              "           1.6807e-02, -8.6532e-02]], device='cuda:0'),\n",
              " 'sx104mrjo0': tensor([[-0.0218, -0.1248, -0.0138,  ...,  0.2536,  0.0333,  0.1875],\n",
              "         [ 0.0873, -0.0721,  0.0017,  ..., -0.1114,  0.1656,  0.0971],\n",
              "         [ 0.0658, -0.0347,  0.0286,  ..., -0.1557,  0.2529, -0.0154],\n",
              "         ...,\n",
              "         [-0.1783,  0.0116,  0.3175,  ..., -0.1152, -0.0116, -0.0433],\n",
              "         [-0.2609,  0.0029,  0.3827,  ...,  0.0030,  0.0148, -0.0751],\n",
              "         [-0.2467,  0.0292,  0.3319,  ...,  0.1480,  0.0105, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'si2169mgwt0': tensor([[ 0.0350, -0.1551, -0.0236,  ...,  0.2265,  0.0283,  0.1604],\n",
              "         [ 0.1857, -0.0725, -0.0037,  ..., -0.1450,  0.1373,  0.0978],\n",
              "         [ 0.1597, -0.0266,  0.0296,  ..., -0.2173,  0.1852, -0.0444],\n",
              "         ...,\n",
              "         [-0.0585,  0.0537,  0.3309,  ..., -0.1620, -0.0606, -0.0771],\n",
              "         [-0.1557,  0.0115,  0.3823,  ..., -0.0512,  0.0127, -0.0923],\n",
              "         [-0.1799, -0.0040,  0.3299,  ...,  0.0977,  0.0215, -0.1101]],\n",
              "        device='cuda:0'),\n",
              " 'si1553mwbt0': tensor([[ 0.0572, -0.1743, -0.0238,  ...,  0.2073,  0.0371,  0.1427],\n",
              "         [ 0.2236, -0.0999, -0.0236,  ..., -0.1736,  0.1439,  0.0865],\n",
              "         [ 0.2013, -0.0586,  0.0131,  ..., -0.2442,  0.1833, -0.0615],\n",
              "         ...,\n",
              "         [-0.0022,  0.0115,  0.2976,  ..., -0.1929, -0.0334, -0.0900],\n",
              "         [-0.1106, -0.0212,  0.3616,  ..., -0.0766,  0.0272, -0.1042],\n",
              "         [-0.1449, -0.0429,  0.3194,  ...,  0.0708,  0.0391, -0.1244]],\n",
              "        device='cuda:0'),\n",
              " 'sa2msjs1': tensor([[ 0.0108, -0.1425, -0.0198,  ...,  0.2347,  0.0247,  0.1717],\n",
              "         [ 0.1176, -0.0448,  0.0222,  ..., -0.1042,  0.1445,  0.0928],\n",
              "         [ 0.0830,  0.0066,  0.0522,  ..., -0.1719,  0.2097, -0.0403],\n",
              "         ...,\n",
              "         [-0.1263,  0.0652,  0.3532,  ..., -0.1279, -0.0687, -0.0792],\n",
              "         [-0.2126,  0.0293,  0.4033,  ..., -0.0212,  0.0006, -0.0945],\n",
              "         [-0.2114,  0.0278,  0.3420,  ...,  0.1131,  0.0149, -0.1128]],\n",
              "        device='cuda:0'),\n",
              " 'sx230fkms0': tensor([[ 0.0086, -0.1434, -0.0184,  ...,  0.2356,  0.0240,  0.1743],\n",
              "         [ 0.1120, -0.0486,  0.0241,  ..., -0.1069,  0.1399,  0.0918],\n",
              "         [ 0.0774,  0.0008,  0.0526,  ..., -0.1743,  0.2107, -0.0384],\n",
              "         ...,\n",
              "         [-0.1355,  0.0544,  0.3562,  ..., -0.1297, -0.0689, -0.0775],\n",
              "         [-0.2158,  0.0226,  0.4023,  ..., -0.0230, -0.0030, -0.0943],\n",
              "         [-0.2134,  0.0244,  0.3422,  ...,  0.1090,  0.0110, -0.1113]],\n",
              "        device='cuda:0'),\n",
              " 'si1474fdac1': tensor([[-0.0227, -0.1247, -0.0144,  ...,  0.2537,  0.0315,  0.1852],\n",
              "         [ 0.0839, -0.0748,  0.0032,  ..., -0.1093,  0.1643,  0.0931],\n",
              "         [ 0.0637, -0.0366,  0.0282,  ..., -0.1554,  0.2498, -0.0173],\n",
              "         ...,\n",
              "         [-0.1795,  0.0118,  0.3152,  ..., -0.1223, -0.0122, -0.0448],\n",
              "         [-0.2628,  0.0021,  0.3826,  ..., -0.0009,  0.0140, -0.0751],\n",
              "         [-0.2443,  0.0287,  0.3313,  ...,  0.1434,  0.0067, -0.0902]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mgwt0': tensor([[ 0.0153, -0.1433, -0.0225,  ...,  0.2338,  0.0236,  0.1698],\n",
              "         [ 0.1347, -0.0479,  0.0157,  ..., -0.1159,  0.1395,  0.0948],\n",
              "         [ 0.0999,  0.0033,  0.0481,  ..., -0.1821,  0.2021, -0.0416],\n",
              "         ...,\n",
              "         [-0.1151,  0.0666,  0.3484,  ..., -0.1347, -0.0705, -0.0771],\n",
              "         [-0.2029,  0.0261,  0.3989,  ..., -0.0283,  0.0016, -0.0929],\n",
              "         [-0.2072,  0.0224,  0.3379,  ...,  0.1100,  0.0139, -0.1114]],\n",
              "        device='cuda:0'),\n",
              " 'sx140fkms0': tensor([[ 0.0061, -0.1455, -0.0172,  ...,  0.2358,  0.0242,  0.1764],\n",
              "         [ 0.1085, -0.0534,  0.0243,  ..., -0.1096,  0.1385,  0.0927],\n",
              "         [ 0.0762, -0.0060,  0.0523,  ..., -0.1744,  0.2127, -0.0355],\n",
              "         ...,\n",
              "         [-0.1414,  0.0466,  0.3558,  ..., -0.1308, -0.0664, -0.0748],\n",
              "         [-0.2174,  0.0168,  0.4002,  ..., -0.0231, -0.0024, -0.0940],\n",
              "         [-0.2153,  0.0202,  0.3422,  ...,  0.1059,  0.0110, -0.1109]],\n",
              "        device='cuda:0'),\n",
              " 'sx109mpgl0': tensor([[ 0.0114, -0.1466, -0.0176,  ...,  0.2362,  0.0281,  0.1766],\n",
              "         [ 0.1222, -0.0390,  0.0244,  ..., -0.0945,  0.1438,  0.0984],\n",
              "         [ 0.0805,  0.0086,  0.0589,  ..., -0.1530,  0.2140, -0.0247],\n",
              "         ...,\n",
              "         [-0.1220,  0.0708,  0.3627,  ..., -0.1106, -0.0730, -0.0687],\n",
              "         [-0.2051,  0.0362,  0.4128,  ..., -0.0075, -0.0015, -0.0882],\n",
              "         [-0.2071,  0.0317,  0.3494,  ...,  0.1145,  0.0196, -0.1144]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fram1': tensor([[ 0.0081, -0.1443, -0.0187,  ...,  0.2346,  0.0255,  0.1741],\n",
              "         [ 0.1182, -0.0538,  0.0234,  ..., -0.1128,  0.1448,  0.0912],\n",
              "         [ 0.0883, -0.0077,  0.0489,  ..., -0.1791,  0.2137, -0.0363],\n",
              "         ...,\n",
              "         [-0.1334,  0.0511,  0.3499,  ..., -0.1357, -0.0630, -0.0783],\n",
              "         [-0.2152,  0.0177,  0.3970,  ..., -0.0267,  0.0034, -0.0946],\n",
              "         [-0.2151,  0.0212,  0.3387,  ...,  0.1097,  0.0109, -0.1107]],\n",
              "        device='cuda:0'),\n",
              " 'si1544fdrd1': tensor([[-0.0227, -0.1250, -0.0146,  ...,  0.2530,  0.0332,  0.1866],\n",
              "         [ 0.0862, -0.0745,  0.0009,  ..., -0.1086,  0.1695,  0.0951],\n",
              "         [ 0.0650, -0.0384,  0.0258,  ..., -0.1536,  0.2554, -0.0144],\n",
              "         ...,\n",
              "         [-0.1793,  0.0125,  0.3164,  ..., -0.1160, -0.0070, -0.0434],\n",
              "         [-0.2626,  0.0034,  0.3821,  ...,  0.0038,  0.0182, -0.0737],\n",
              "         [-0.2455,  0.0297,  0.3305,  ...,  0.1463,  0.0092, -0.0883]],\n",
              "        device='cuda:0'),\n",
              " 'sx281mrcz0': tensor([[ 0.0085, -0.1414, -0.0176,  ...,  0.2371,  0.0243,  0.1760],\n",
              "         [ 0.1144, -0.0475,  0.0251,  ..., -0.1053,  0.1441,  0.0931],\n",
              "         [ 0.0795,  0.0019,  0.0527,  ..., -0.1708,  0.2167, -0.0338],\n",
              "         ...,\n",
              "         [-0.1353,  0.0564,  0.3562,  ..., -0.1286, -0.0687, -0.0753],\n",
              "         [-0.2168,  0.0244,  0.4036,  ..., -0.0197, -0.0022, -0.0934],\n",
              "         [-0.2166,  0.0292,  0.3428,  ...,  0.1147,  0.0092, -0.1098]],\n",
              "        device='cuda:0'),\n",
              " 'sx102mmdm2': tensor([[ 0.0084, -0.1437, -0.0185,  ...,  0.2353,  0.0234,  0.1736],\n",
              "         [ 0.1143, -0.0485,  0.0247,  ..., -0.1072,  0.1396,  0.0921],\n",
              "         [ 0.0804,  0.0019,  0.0534,  ..., -0.1743,  0.2091, -0.0383],\n",
              "         ...,\n",
              "         [-0.1328,  0.0543,  0.3544,  ..., -0.1321, -0.0682, -0.0776],\n",
              "         [-0.2147,  0.0221,  0.4022,  ..., -0.0239, -0.0015, -0.0945],\n",
              "         [-0.2133,  0.0230,  0.3420,  ...,  0.1100,  0.0127, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx185mmdb1': tensor([[-0.0021, -0.1455, -0.0116,  ...,  0.2389,  0.0267,  0.1814],\n",
              "         [ 0.0977, -0.0606,  0.0252,  ..., -0.1058,  0.1529,  0.0938],\n",
              "         [ 0.0726, -0.0186,  0.0479,  ..., -0.1639,  0.2310, -0.0224],\n",
              "         ...,\n",
              "         [-0.1574,  0.0351,  0.3499,  ..., -0.1251, -0.0500, -0.0672],\n",
              "         [-0.2304,  0.0114,  0.3963,  ..., -0.0117,  0.0079, -0.0918],\n",
              "         [-0.2242,  0.0192,  0.3441,  ...,  0.1136,  0.0145, -0.1077]],\n",
              "        device='cuda:0'),\n",
              " 'sx184fjem0': tensor([[ 0.0633, -0.1824, -0.0211,  ...,  0.1995,  0.0395,  0.1378],\n",
              "         [ 0.2279, -0.1120, -0.0271,  ..., -0.1770,  0.1490,  0.0798],\n",
              "         [ 0.2119, -0.0731,  0.0047,  ..., -0.2480,  0.1865, -0.0662],\n",
              "         ...,\n",
              "         [ 0.0114, -0.0050,  0.2846,  ..., -0.2016, -0.0198, -0.0965],\n",
              "         [-0.1011, -0.0315,  0.3541,  ..., -0.0860,  0.0358, -0.1090],\n",
              "         [-0.1367, -0.0555,  0.3162,  ...,  0.0630,  0.0445, -0.1290]],\n",
              "        device='cuda:0'),\n",
              " 'sx365mmdb1': tensor([[ 0.0181, -0.1434, -0.0263,  ...,  0.2299,  0.0203,  0.1660],\n",
              "         [ 0.1355, -0.0453,  0.0148,  ..., -0.1132,  0.1355,  0.0958],\n",
              "         [ 0.1015,  0.0073,  0.0476,  ..., -0.1843,  0.1912, -0.0429],\n",
              "         ...,\n",
              "         [-0.1045,  0.0739,  0.3463,  ..., -0.1351, -0.0812, -0.0743],\n",
              "         [-0.1947,  0.0320,  0.4025,  ..., -0.0310, -0.0065, -0.0929],\n",
              "         [-0.2009,  0.0247,  0.3401,  ...,  0.1052,  0.0140, -0.1127]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fdac1': tensor([[-0.0107, -0.1352, -0.0108,  ...,  0.2502,  0.0262,  0.1821],\n",
              "         [ 0.0896, -0.0669,  0.0191,  ..., -0.1052,  0.1552,  0.0917],\n",
              "         [ 0.0690, -0.0235,  0.0434,  ..., -0.1590,  0.2401, -0.0239],\n",
              "         ...,\n",
              "         [-0.1712,  0.0256,  0.3354,  ..., -0.1258, -0.0379, -0.0580],\n",
              "         [-0.2467,  0.0069,  0.3918,  ..., -0.0075,  0.0084, -0.0837],\n",
              "         [-0.2386,  0.0234,  0.3400,  ...,  0.1253,  0.0099, -0.1002]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mjar0': tensor([[ 0.0525, -0.1695, -0.0234,  ...,  0.2136,  0.0354,  0.1481],\n",
              "         [ 0.2144, -0.0923, -0.0188,  ..., -0.1645,  0.1453,  0.0875],\n",
              "         [ 0.1918, -0.0501,  0.0134,  ..., -0.2360,  0.1870, -0.0584],\n",
              "         ...,\n",
              "         [-0.0159,  0.0239,  0.3049,  ..., -0.1848, -0.0404, -0.0863],\n",
              "         [-0.1215, -0.0099,  0.3654,  ..., -0.0690,  0.0244, -0.1007],\n",
              "         [-0.1540, -0.0315,  0.3213,  ...,  0.0815,  0.0347, -0.1194]],\n",
              "        device='cuda:0'),\n",
              " 'sa1faks0': tensor([[-2.1034e-02, -1.2466e-01, -1.4833e-02,  ...,  2.5455e-01,\n",
              "           3.2707e-02,  1.8555e-01],\n",
              "         [ 8.7882e-02, -7.4265e-02,  1.9939e-03,  ..., -1.0809e-01,\n",
              "           1.6368e-01,  9.3794e-02],\n",
              "         [ 6.6562e-02, -3.5678e-02,  2.8359e-02,  ..., -1.5450e-01,\n",
              "           2.5045e-01, -1.7240e-02],\n",
              "         ...,\n",
              "         [-1.8020e-01,  1.4047e-02,  3.1849e-01,  ..., -1.1973e-01,\n",
              "          -1.1978e-02, -4.6564e-02],\n",
              "         [-2.6155e-01,  2.8232e-03,  3.8337e-01,  ...,  2.7419e-04,\n",
              "           1.4559e-02, -7.4942e-02],\n",
              "         [-2.4422e-01,  2.8756e-02,  3.3078e-01,  ...,  1.4380e-01,\n",
              "           7.5664e-03, -8.9859e-02]], device='cuda:0'),\n",
              " 'sx110mjsw0': tensor([[-0.0236, -0.1280, -0.0131,  ...,  0.2519,  0.0311,  0.1872],\n",
              "         [ 0.0809, -0.0769,  0.0034,  ..., -0.1129,  0.1690,  0.1001],\n",
              "         [ 0.0591, -0.0429,  0.0255,  ..., -0.1577,  0.2519, -0.0087],\n",
              "         ...,\n",
              "         [-0.1774,  0.0101,  0.3152,  ..., -0.1200, -0.0087, -0.0386],\n",
              "         [-0.2618,  0.0016,  0.3809,  ..., -0.0006,  0.0172, -0.0718],\n",
              "         [-0.2469,  0.0238,  0.3323,  ...,  0.1415,  0.0128, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa2faks0': tensor([[-0.0231, -0.1307, -0.0150,  ...,  0.2503,  0.0333,  0.1897],\n",
              "         [ 0.0836, -0.0809, -0.0037,  ..., -0.1190,  0.1701,  0.1030],\n",
              "         [ 0.0591, -0.0507,  0.0177,  ..., -0.1614,  0.2541, -0.0066],\n",
              "         ...,\n",
              "         [-0.1813,  0.0051,  0.3138,  ..., -0.1168, -0.0029, -0.0402],\n",
              "         [-0.2630, -0.0033,  0.3771,  ..., -0.0016,  0.0231, -0.0722],\n",
              "         [-0.2509,  0.0195,  0.3275,  ...,  0.1407,  0.0144, -0.0860]],\n",
              "        device='cuda:0'),\n",
              " 'si992fjwb0': tensor([[ 0.1117, -0.2771, -0.0015,  ...,  0.1391,  0.0547,  0.0795],\n",
              "         [ 0.2824, -0.2419, -0.0550,  ..., -0.2368,  0.1682,  0.0279],\n",
              "         [ 0.2602, -0.2234, -0.0363,  ..., -0.2759,  0.2083, -0.1080],\n",
              "         ...,\n",
              "         [ 0.0500, -0.1794,  0.1812,  ..., -0.2817,  0.0572, -0.1670],\n",
              "         [-0.0552, -0.1936,  0.2924,  ..., -0.1668,  0.0985, -0.1790],\n",
              "         [-0.0781, -0.2067,  0.3075,  ...,  0.0047,  0.0945, -0.1872]],\n",
              "        device='cuda:0'),\n",
              " 'sx280fram1': tensor([[-0.0246, -0.1274, -0.0152,  ...,  0.2514,  0.0314,  0.1868],\n",
              "         [ 0.0809, -0.0794,  0.0010,  ..., -0.1141,  0.1673,  0.0975],\n",
              "         [ 0.0595, -0.0461,  0.0225,  ..., -0.1589,  0.2494, -0.0103],\n",
              "         ...,\n",
              "         [-0.1799,  0.0099,  0.3139,  ..., -0.1234, -0.0076, -0.0416],\n",
              "         [-0.2637,  0.0006,  0.3798,  ..., -0.0031,  0.0168, -0.0726],\n",
              "         [-0.2459,  0.0242,  0.3294,  ...,  0.1389,  0.0091, -0.0887]],\n",
              "        device='cuda:0'),\n",
              " 'si2120fkms0': tensor([[ 0.0044, -0.1465, -0.0156,  ...,  0.2341,  0.0243,  0.1785],\n",
              "         [ 0.1041, -0.0561,  0.0258,  ..., -0.1097,  0.1404,  0.0918],\n",
              "         [ 0.0751, -0.0095,  0.0510,  ..., -0.1747,  0.2153, -0.0330],\n",
              "         ...,\n",
              "         [-0.1461,  0.0431,  0.3555,  ..., -0.1298, -0.0636, -0.0746],\n",
              "         [-0.2205,  0.0150,  0.3992,  ..., -0.0206, -0.0007, -0.0946],\n",
              "         [-0.2171,  0.0196,  0.3420,  ...,  0.1071,  0.0107, -0.1093]],\n",
              "        device='cuda:0'),\n",
              " 'si1808fcft0': tensor([[-0.0314, -0.1414, -0.0240,  ...,  0.2280,  0.0426,  0.1899],\n",
              "         [ 0.0972, -0.0725,  0.0071,  ..., -0.1292,  0.1952,  0.0769],\n",
              "         [ 0.0996, -0.0297,  0.0055,  ..., -0.1996,  0.2614, -0.0247],\n",
              "         ...,\n",
              "         [-0.1567,  0.0294,  0.3382,  ..., -0.0691, -0.0068, -0.0591],\n",
              "         [-0.2610,  0.0176,  0.3739,  ...,  0.0556,  0.0328, -0.0945],\n",
              "         [-0.2405,  0.0823,  0.3048,  ...,  0.2330,  0.0239, -0.0271]],\n",
              "        device='cuda:0'),\n",
              " 'si1178fcft0': tensor([[ 0.0355, -0.1606, -0.0216,  ...,  0.2211,  0.0296,  0.1600],\n",
              "         [ 0.1830, -0.0821,  0.0005,  ..., -0.1461,  0.1389,  0.0934],\n",
              "         [ 0.1671, -0.0382,  0.0274,  ..., -0.2233,  0.1869, -0.0475],\n",
              "         ...,\n",
              "         [-0.0514,  0.0407,  0.3246,  ..., -0.1730, -0.0544, -0.0803],\n",
              "         [-0.1506,  0.0015,  0.3783,  ..., -0.0584,  0.0180, -0.0954],\n",
              "         [-0.1776, -0.0121,  0.3288,  ...,  0.0913,  0.0237, -0.1126]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mdab0': tensor([[ 0.0622, -0.1898, -0.0188,  ...,  0.1982,  0.0397,  0.1384],\n",
              "         [ 0.2319, -0.1232, -0.0240,  ..., -0.1824,  0.1457,  0.0763],\n",
              "         [ 0.2178, -0.0888,  0.0049,  ..., -0.2538,  0.1866, -0.0677],\n",
              "         ...,\n",
              "         [ 0.0098, -0.0191,  0.2881,  ..., -0.2070, -0.0183, -0.0939],\n",
              "         [-0.1001, -0.0432,  0.3532,  ..., -0.0900,  0.0370, -0.1070],\n",
              "         [-0.1391, -0.0639,  0.3143,  ...,  0.0611,  0.0426, -0.1273]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mstk0': tensor([[-0.0151, -0.1271, -0.0124,  ...,  0.2544,  0.0294,  0.1840],\n",
              "         [ 0.0925, -0.0688,  0.0097,  ..., -0.1047,  0.1585,  0.0929],\n",
              "         [ 0.0709, -0.0278,  0.0380,  ..., -0.1544,  0.2476, -0.0215],\n",
              "         ...,\n",
              "         [-0.1736,  0.0210,  0.3258,  ..., -0.1188, -0.0260, -0.0525],\n",
              "         [-0.2534,  0.0073,  0.3878,  ..., -0.0006,  0.0102, -0.0798],\n",
              "         [-0.2429,  0.0284,  0.3352,  ...,  0.1384,  0.0081, -0.0937]],\n",
              "        device='cuda:0'),\n",
              " 'si2284mstk0': tensor([[-0.0229, -0.1371, -0.0174,  ...,  0.2457,  0.0369,  0.1957],\n",
              "         [ 0.0808, -0.0853, -0.0189,  ..., -0.1357,  0.1782,  0.1211],\n",
              "         [ 0.0503, -0.0644, -0.0014,  ..., -0.1744,  0.2625,  0.0075],\n",
              "         ...,\n",
              "         [-0.1762, -0.0138,  0.3007,  ..., -0.1199,  0.0004, -0.0256],\n",
              "         [-0.2638, -0.0148,  0.3648,  ..., -0.0070,  0.0303, -0.0662],\n",
              "         [-0.2582,  0.0072,  0.3242,  ...,  0.1376,  0.0223, -0.0810]],\n",
              "        device='cuda:0'),\n",
              " 'sx50fkms0': tensor([[ 0.0064, -0.1465, -0.0172,  ...,  0.2337,  0.0247,  0.1757],\n",
              "         [ 0.1099, -0.0532,  0.0255,  ..., -0.1096,  0.1394,  0.0929],\n",
              "         [ 0.0780, -0.0061,  0.0526,  ..., -0.1756,  0.2107, -0.0327],\n",
              "         ...,\n",
              "         [-0.1385,  0.0483,  0.3564,  ..., -0.1321, -0.0655, -0.0750],\n",
              "         [-0.2159,  0.0176,  0.4009,  ..., -0.0243, -0.0011, -0.0941],\n",
              "         [-0.2136,  0.0195,  0.3419,  ...,  0.1055,  0.0126, -0.1114]],\n",
              "        device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Diffrential Privacy filter"
      ],
      "metadata": {
        "id": "vsuSDhRQEYF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "8O3flG4_EhHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "input_size = 768  # Size of input features\n",
        "hidden_size = 384  # Size of hidden layer\n",
        "output_size = 768  # Size of output features (deepfake-like features)\n",
        "batch_size = 24\n",
        "num_layers = 2\n",
        "noise_multiplier = 0.1\n",
        "max_grad_norm = 1.0\n",
        "num_epochs = 1000\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "0yStXMpSFxez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom dataset\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, real_features, deepfake_features):\n",
        "        self.real_features = real_features\n",
        "        self.deepfake_features = deepfake_features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.real_features[idx], self.deepfake_features[idx]"
      ],
      "metadata": {
        "id": "fl_CPzqaF4Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Uss5bl6OuqmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dict_to_tensor(feature_real, feature_deep, desired_size, device):\n",
        "  \"\"\"\n",
        "  Processes dictionaries of real and deepfake feature sequences into tensors.\n",
        "\n",
        "  Args:\n",
        "      feature_real: A dictionary of real feature sequences (tensors).\n",
        "      feature_deep: A dictionary of deepfake feature sequences (tensors).\n",
        "      desired_size: The desired size for the output tensors.\n",
        "      device: The device to move the tensors to (e.g., 'cuda:0' for GPU).\n",
        "\n",
        "  Returns:\n",
        "      A tuple of tensors representing the processed real and deepfake features.\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine keys from both dictionaries\n",
        "  all_keys = set(feature_real.keys()) | set(feature_deep.keys())\n",
        "\n",
        "  # Find minimum sequence length across all features (using chain)\n",
        "  min_length = min(len(seq) for seq in chain(feature_real.values(), feature_deep.values()))\n",
        "\n",
        "  # Process each feature sequence, considering minimum length\n",
        "  tensor_list_real = {key: None for key in all_keys}  # Initialize empty dict\n",
        "  tensor_list_deep = {key: None for key in all_keys}  # Initialize empty dict\n",
        "  for key in all_keys:\n",
        "    real_seq = feature_real.get(key)\n",
        "    deep_seq = feature_deep.get(key)\n",
        "    if real_seq is not None:\n",
        "      tensor_list_real[key] = F.interpolate(\n",
        "          real_seq[:min_length].unsqueeze(0), size=(desired_size,), mode='nearest').squeeze(0)\n",
        "    if deep_seq is not None:\n",
        "      tensor_list_deep[key] = F.interpolate(\n",
        "          deep_seq[:min_length].unsqueeze(0), size=(desired_size,), mode='nearest').squeeze(0)\n",
        "\n",
        "  # Stack and move to desired device\n",
        "  real_features_tensor = torch.stack([tensor_list_real[key] for key in feature_real.keys()]).to(device)\n",
        "  deepfake_features_tensor = torch.stack([tensor_list_deep[key] for key in feature_deep.keys()]).to(device)\n",
        "  return real_features_tensor, deepfake_features_tensor"
      ],
      "metadata": {
        "id": "FbaYoCPuLzOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic dataset\n",
        "# Convert dictionary to tensor and resize features\n",
        "real_features, deepfake_features = dict_to_tensor(feature_real, feature_deep, input_size, device)"
      ],
      "metadata": {
        "id": "hSdQOER2L2Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_features"
      ],
      "metadata": {
        "id": "rcWkNwCOxeaA",
        "outputId": "81528df5-88d3-4b1d-e376-00d80fd612b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0337, -0.1497, -0.0243,  ...,  0.2315,  0.0290,  0.1629],\n",
              "         [ 0.1824, -0.0650, -0.0055,  ..., -0.1429,  0.1406,  0.1006],\n",
              "         [ 0.1506, -0.0165,  0.0294,  ..., -0.2116,  0.1907, -0.0434],\n",
              "         ...,\n",
              "         [ 0.2791,  0.0735,  0.0227,  ..., -0.1190, -0.4003,  0.0074],\n",
              "         [ 0.2787,  0.0734,  0.0228,  ..., -0.1215, -0.4004,  0.0088],\n",
              "         [ 0.2786,  0.0735,  0.0229,  ..., -0.1232, -0.4015,  0.0099]],\n",
              "\n",
              "        [[ 0.0372, -0.1600, -0.0227,  ...,  0.2216,  0.0322,  0.1591],\n",
              "         [ 0.1889, -0.0792, -0.0043,  ..., -0.1479,  0.1435,  0.0944],\n",
              "         [ 0.1673, -0.0344,  0.0250,  ..., -0.2216,  0.1901, -0.0467],\n",
              "         ...,\n",
              "         [ 0.2975,  0.0570,  0.0192,  ..., -0.1471, -0.3939, -0.0063],\n",
              "         [ 0.2970,  0.0565,  0.0197,  ..., -0.1460, -0.3938, -0.0063],\n",
              "         [ 0.2970,  0.0560,  0.0199,  ..., -0.1455, -0.3936, -0.0058]],\n",
              "\n",
              "        [[ 0.0072, -0.1443, -0.0176,  ...,  0.2343,  0.0249,  0.1746],\n",
              "         [ 0.1128, -0.0520,  0.0250,  ..., -0.1086,  0.1449,  0.0915],\n",
              "         [ 0.0819, -0.0033,  0.0516,  ..., -0.1755,  0.2143, -0.0359],\n",
              "         ...,\n",
              "         [ 0.2232,  0.1251,  0.0354,  ..., -0.0600, -0.3834, -0.0033],\n",
              "         [ 0.2233,  0.1243,  0.0348,  ..., -0.0594, -0.3838, -0.0035],\n",
              "         [ 0.2240,  0.1234,  0.0345,  ..., -0.0599, -0.3843, -0.0041]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.0148, -0.1270, -0.0115,  ...,  0.2550,  0.0294,  0.1838],\n",
              "         [ 0.0945, -0.0673,  0.0117,  ..., -0.1015,  0.1606,  0.0923],\n",
              "         [ 0.0725, -0.0254,  0.0402,  ..., -0.1516,  0.2492, -0.0209],\n",
              "         ...,\n",
              "         [ 0.1946,  0.1038,  0.0346,  ..., -0.0725, -0.4455,  0.0026],\n",
              "         [ 0.1923,  0.1032,  0.0350,  ..., -0.0735, -0.4495,  0.0035],\n",
              "         [ 0.1899,  0.1025,  0.0358,  ..., -0.0756, -0.4555,  0.0049]],\n",
              "\n",
              "        [[-0.0221, -0.1369, -0.0167,  ...,  0.2465,  0.0372,  0.1958],\n",
              "         [ 0.0826, -0.0840, -0.0174,  ..., -0.1343,  0.1787,  0.1211],\n",
              "         [ 0.0510, -0.0636,  0.0007,  ..., -0.1726,  0.2626,  0.0089],\n",
              "         ...,\n",
              "         [-0.1771, -0.0130,  0.3044,  ..., -0.1168,  0.0019, -0.0271],\n",
              "         [-0.2629, -0.0142,  0.3658,  ..., -0.0056,  0.0308, -0.0659],\n",
              "         [-0.2576,  0.0076,  0.3243,  ...,  0.1383,  0.0224, -0.0805]],\n",
              "\n",
              "        [[ 0.0080, -0.1466, -0.0177,  ...,  0.2326,  0.0248,  0.1749],\n",
              "         [ 0.1131, -0.0524,  0.0254,  ..., -0.1085,  0.1394,  0.0936],\n",
              "         [ 0.0793, -0.0036,  0.0533,  ..., -0.1747,  0.2085, -0.0322],\n",
              "         ...,\n",
              "         [ 0.2216,  0.1213,  0.0409,  ..., -0.0617, -0.3851, -0.0047],\n",
              "         [ 0.2227,  0.1206,  0.0416,  ..., -0.0644, -0.3863, -0.0039],\n",
              "         [ 0.2225,  0.1200,  0.0427,  ..., -0.0659, -0.3888, -0.0037]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deepfake_features"
      ],
      "metadata": {
        "id": "0XsTUh5gVEOn",
        "outputId": "439e0c14-27b5-4a3c-b476-5744f91b81e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 3.2117e-02, -1.4953e-01, -2.3393e-02,  ...,  2.3164e-01,\n",
              "           2.8560e-02,  1.6406e-01],\n",
              "         [ 1.7674e-01, -6.5082e-02, -3.2546e-03,  ..., -1.4112e-01,\n",
              "           1.4044e-01,  9.8912e-02],\n",
              "         [ 1.4602e-01, -1.7526e-02,  3.0644e-02,  ..., -2.1033e-01,\n",
              "           1.9388e-01, -4.4958e-02],\n",
              "         ...,\n",
              "         [ 2.7445e-01,  7.3909e-02,  1.9542e-02,  ..., -1.1725e-01,\n",
              "          -4.0546e-01,  6.8320e-03],\n",
              "         [ 2.7438e-01,  7.4162e-02,  1.9759e-02,  ..., -1.1950e-01,\n",
              "          -4.0531e-01,  7.9358e-03],\n",
              "         [ 2.7426e-01,  7.4530e-02,  2.0117e-02,  ..., -1.2073e-01,\n",
              "          -4.0587e-01,  9.0176e-03]],\n",
              "\n",
              "        [[ 3.4436e-02, -1.5756e-01, -2.2521e-02,  ...,  2.2409e-01,\n",
              "           3.0163e-02,  1.6043e-01],\n",
              "         [ 1.8238e-01, -7.6064e-02, -1.5109e-03,  ..., -1.4532e-01,\n",
              "           1.4173e-01,  9.4654e-02],\n",
              "         [ 1.5974e-01, -3.0997e-02,  2.7993e-02,  ..., -2.1875e-01,\n",
              "           1.9105e-01, -4.7759e-02],\n",
              "         ...,\n",
              "         [ 2.8726e-01,  6.2903e-02,  1.9651e-02,  ..., -1.3937e-01,\n",
              "          -4.0017e-01, -3.9510e-03],\n",
              "         [ 2.8700e-01,  6.1975e-02,  1.9243e-02,  ..., -1.3787e-01,\n",
              "          -4.0011e-01, -4.0791e-03],\n",
              "         [ 2.8739e-01,  6.1736e-02,  1.9519e-02,  ..., -1.3767e-01,\n",
              "          -3.9945e-01, -4.3995e-03]],\n",
              "\n",
              "        [[-3.0757e-02, -1.4190e-01, -2.3544e-02,  ...,  2.2695e-01,\n",
              "           4.2190e-02,  1.9027e-01],\n",
              "         [ 9.7086e-02, -6.8938e-02,  1.0541e-02,  ..., -1.2914e-01,\n",
              "           1.9258e-01,  7.4643e-02],\n",
              "         [ 1.0102e-01, -2.2707e-02,  8.6362e-03,  ..., -2.0044e-01,\n",
              "           2.5908e-01, -2.8121e-02],\n",
              "         ...,\n",
              "         [ 2.2486e-01,  9.8309e-02, -2.1018e-02,  ..., -1.2990e-01,\n",
              "          -3.3694e-01,  1.9893e-02],\n",
              "         [ 2.2561e-01,  9.8580e-02, -2.1355e-02,  ..., -1.2795e-01,\n",
              "          -3.3861e-01,  1.9287e-02],\n",
              "         [ 2.2661e-01,  9.8659e-02, -2.1357e-02,  ..., -1.2761e-01,\n",
              "          -3.3955e-01,  1.9011e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.5143e-02, -1.2709e-01, -1.2373e-02,  ...,  2.5443e-01,\n",
              "           2.9362e-02,  1.8401e-01],\n",
              "         [ 9.2547e-02, -6.8764e-02,  9.6828e-03,  ..., -1.0467e-01,\n",
              "           1.5845e-01,  9.2928e-02],\n",
              "         [ 7.0905e-02, -2.7753e-02,  3.8029e-02,  ..., -1.5436e-01,\n",
              "           2.4760e-01, -2.1508e-02],\n",
              "         ...,\n",
              "         [ 1.9314e-01,  1.0059e-01,  3.1117e-02,  ..., -7.6773e-02,\n",
              "          -4.4561e-01, -5.1245e-04],\n",
              "         [ 1.9095e-01,  1.0028e-01,  3.2421e-02,  ..., -7.8042e-02,\n",
              "          -4.4945e-01,  6.0385e-04],\n",
              "         [ 1.8873e-01,  9.9352e-02,  3.3595e-02,  ..., -7.9798e-02,\n",
              "          -4.5578e-01,  1.7091e-03]],\n",
              "\n",
              "        [[-2.2943e-02, -1.3709e-01, -1.7439e-02,  ...,  2.4568e-01,\n",
              "           3.6937e-02,  1.9565e-01],\n",
              "         [ 8.0793e-02, -8.5318e-02, -1.8878e-02,  ..., -1.3566e-01,\n",
              "           1.7817e-01,  1.2112e-01],\n",
              "         [ 5.0304e-02, -6.4362e-02, -1.3710e-03,  ..., -1.7443e-01,\n",
              "           2.6246e-01,  7.4737e-03],\n",
              "         ...,\n",
              "         [-1.7623e-01, -1.3758e-02,  3.0073e-01,  ..., -1.1994e-01,\n",
              "           3.9272e-04, -2.5592e-02],\n",
              "         [-2.6376e-01, -1.4785e-02,  3.6478e-01,  ..., -6.9887e-03,\n",
              "           3.0288e-02, -6.6200e-02],\n",
              "         [-2.5825e-01,  7.2269e-03,  3.2424e-01,  ...,  1.3763e-01,\n",
              "           2.2313e-02, -8.0961e-02]],\n",
              "\n",
              "        [[ 6.4495e-03, -1.4651e-01, -1.7213e-02,  ...,  2.3372e-01,\n",
              "           2.4673e-02,  1.7573e-01],\n",
              "         [ 1.0992e-01, -5.3213e-02,  2.5519e-02,  ..., -1.0958e-01,\n",
              "           1.3935e-01,  9.2881e-02],\n",
              "         [ 7.7984e-02, -6.0822e-03,  5.2618e-02,  ..., -1.7556e-01,\n",
              "           2.1070e-01, -3.2668e-02],\n",
              "         ...,\n",
              "         [ 2.2052e-01,  1.1893e-01,  3.8744e-02,  ..., -6.4763e-02,\n",
              "          -3.8759e-01, -6.3891e-03],\n",
              "         [ 2.2097e-01,  1.1824e-01,  3.9431e-02,  ..., -6.6059e-02,\n",
              "          -3.8941e-01, -5.9452e-03],\n",
              "         [ 2.2158e-01,  1.1787e-01,  4.0339e-02,  ..., -6.8050e-02,\n",
              "          -3.9135e-01, -6.2366e-03]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(real_features))\n",
        "val_size = len(real_features) - train_size\n",
        "train_real, val_real = random_split(real_features, [train_size, val_size])\n",
        "train_deepfake, val_deepfake = random_split(deepfake_features, [train_size, val_size])\n"
      ],
      "metadata": {
        "id": "mhkvrReAF-1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for training and validation sets\n",
        "train_dataset = MyDataset(train_real, train_deepfake)\n",
        "val_dataset = MyDataset(val_real, val_deepfake)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "bYcpZR0xGBVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation metrics function\n",
        "def evaluate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay_epoch epochs\"\"\"\n",
        "    lr = initial_lr * (0.1**(epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Define a function to calculate moving averages\n",
        "def moving_average(data, window_size):\n",
        "    \"\"\"Calculate the moving average of data using a window size.\"\"\"\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')"
      ],
      "metadata": {
        "id": "C-Z8UlyQMvn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 1"
      ],
      "metadata": {
        "id": "lRtud1lE5luq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "    super(Generator, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Define the layers\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "    self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers[:-1]:\n",
        "      x = F.relu(layer(x))\n",
        "    x = self.layers[-1](x)\n",
        "    return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator(Generator):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm):\n",
        "        super(DPGenerator, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.noise_multiplier = noise_multiplier\n",
        "\n",
        "  def forward(self, x):\n",
        "      return super(DPGenerator, self).forward(x)\n",
        "\n",
        "  def backward(self, loss):\n",
        "      loss.backward()\n",
        "      for param in self.parameters():\n",
        "          if param.grad is not None:\n",
        "              param.grad += torch.randn_like(param.grad) * self.noise_multiplier\n",
        "              param.grad = torch.clamp(param.grad, -self.max_grad_norm, self.max_grad_norm)"
      ],
      "metadata": {
        "id": "8zObOanL5erP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = DPGenerator(input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "nteMvITmGC8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "ZCi7BmmdGJeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model(real_features)\n",
        "        loss = criterion(output, deepfake_features)\n",
        "        model.backward(loss)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SdmPbTeYYZw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 2"
      ],
      "metadata": {
        "id": "heneizAW8hUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator2, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator2(Generator2):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, max_grad_norm):\n",
        "          super(DPGenerator2, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.noise_log_std = nn.Parameter(torch.zeros(1))  # Trainable log std for noise\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super(DPGenerator2, self).forward(x)\n",
        "\n",
        "    def backward(self, loss):\n",
        "      loss.backward()\n",
        "      for param in self.parameters():\n",
        "        if param.grad is not None:\n",
        "          noise = torch.randn_like(param.grad) * torch.exp(self.noise_log_std)\n",
        "          param.grad += noise\n",
        "          param.grad = torch.clamp(param.grad, -self.max_grad_norm, self.max_grad_norm)"
      ],
      "metadata": {
        "id": "-d1UL-x58g_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model2 = DPGenerator2(input_size, hidden_size, output_size, num_layers, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer2 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion2 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "kL6oUuJm8g7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "MH8-MXJe8g0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer2.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model2(real_features)\n",
        "        loss = criterion2(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model2.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model2(real_features)\n",
        "            loss = criterion2(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fpVeqHQyBvMi",
        "outputId": "ca3f6219-4f95-4918-97ca-aa018c15f404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [1/1000], Validation Loss: 0.0297\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [2/1000], Validation Loss: 0.0297\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [3/1000], Validation Loss: 0.0297\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [4/1000], Validation Loss: 0.0297\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [5/1000], Validation Loss: 0.0297\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [6/1000], Validation Loss: 0.0297\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [7/1000], Validation Loss: 0.0297\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [8/1000], Validation Loss: 0.0297\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [9/1000], Validation Loss: 0.0297\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [10/1000], Validation Loss: 0.0297\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [11/1000], Validation Loss: 0.0297\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [12/1000], Validation Loss: 0.0297\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [13/1000], Validation Loss: 0.0297\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [14/1000], Validation Loss: 0.0297\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [15/1000], Validation Loss: 0.0297\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [16/1000], Validation Loss: 0.0297\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [17/1000], Validation Loss: 0.0297\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [18/1000], Validation Loss: 0.0297\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [19/1000], Validation Loss: 0.0297\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [20/1000], Validation Loss: 0.0297\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [21/1000], Validation Loss: 0.0297\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [22/1000], Validation Loss: 0.0297\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [23/1000], Validation Loss: 0.0297\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [24/1000], Validation Loss: 0.0297\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [25/1000], Validation Loss: 0.0297\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [26/1000], Validation Loss: 0.0297\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [27/1000], Validation Loss: 0.0297\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [28/1000], Validation Loss: 0.0297\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [29/1000], Validation Loss: 0.0297\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [30/1000], Validation Loss: 0.0297\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [31/1000], Validation Loss: 0.0297\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [32/1000], Validation Loss: 0.0297\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [33/1000], Validation Loss: 0.0297\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [34/1000], Validation Loss: 0.0297\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [35/1000], Validation Loss: 0.0297\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [36/1000], Validation Loss: 0.0297\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [37/1000], Validation Loss: 0.0297\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [38/1000], Validation Loss: 0.0297\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [39/1000], Validation Loss: 0.0297\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [40/1000], Validation Loss: 0.0297\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [41/1000], Validation Loss: 0.0297\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [42/1000], Validation Loss: 0.0297\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [43/1000], Validation Loss: 0.0297\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [44/1000], Validation Loss: 0.0297\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [45/1000], Validation Loss: 0.0297\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [46/1000], Validation Loss: 0.0297\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [47/1000], Validation Loss: 0.0297\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [48/1000], Validation Loss: 0.0297\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [49/1000], Validation Loss: 0.0297\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [50/1000], Validation Loss: 0.0297\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [51/1000], Validation Loss: 0.0297\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [52/1000], Validation Loss: 0.0297\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [53/1000], Validation Loss: 0.0297\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [54/1000], Validation Loss: 0.0297\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [55/1000], Validation Loss: 0.0297\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [56/1000], Validation Loss: 0.0297\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [57/1000], Validation Loss: 0.0297\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [58/1000], Validation Loss: 0.0297\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [59/1000], Validation Loss: 0.0297\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [60/1000], Validation Loss: 0.0297\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [61/1000], Validation Loss: 0.0297\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [62/1000], Validation Loss: 0.0297\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [63/1000], Validation Loss: 0.0297\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [64/1000], Validation Loss: 0.0297\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [65/1000], Validation Loss: 0.0297\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [66/1000], Validation Loss: 0.0297\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [67/1000], Validation Loss: 0.0297\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [68/1000], Validation Loss: 0.0297\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [69/1000], Validation Loss: 0.0297\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [70/1000], Validation Loss: 0.0297\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [71/1000], Validation Loss: 0.0297\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [72/1000], Validation Loss: 0.0297\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [73/1000], Validation Loss: 0.0297\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [74/1000], Validation Loss: 0.0297\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [75/1000], Validation Loss: 0.0297\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [76/1000], Validation Loss: 0.0297\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [77/1000], Validation Loss: 0.0297\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [78/1000], Validation Loss: 0.0297\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [79/1000], Validation Loss: 0.0297\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [80/1000], Validation Loss: 0.0297\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [81/1000], Validation Loss: 0.0297\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [82/1000], Validation Loss: 0.0297\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [83/1000], Validation Loss: 0.0297\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [84/1000], Validation Loss: 0.0297\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [85/1000], Validation Loss: 0.0297\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [86/1000], Validation Loss: 0.0297\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [87/1000], Validation Loss: 0.0297\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [88/1000], Validation Loss: 0.0297\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [89/1000], Validation Loss: 0.0297\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [90/1000], Validation Loss: 0.0297\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [91/1000], Validation Loss: 0.0297\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [92/1000], Validation Loss: 0.0297\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [93/1000], Validation Loss: 0.0297\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [94/1000], Validation Loss: 0.0297\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [95/1000], Validation Loss: 0.0297\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [96/1000], Validation Loss: 0.0297\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [97/1000], Validation Loss: 0.0297\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [98/1000], Validation Loss: 0.0297\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [99/1000], Validation Loss: 0.0297\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [100/1000], Validation Loss: 0.0297\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [101/1000], Validation Loss: 0.0297\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [102/1000], Validation Loss: 0.0297\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [103/1000], Validation Loss: 0.0297\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [104/1000], Validation Loss: 0.0297\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [105/1000], Validation Loss: 0.0297\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [106/1000], Validation Loss: 0.0297\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [107/1000], Validation Loss: 0.0297\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [108/1000], Validation Loss: 0.0297\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [109/1000], Validation Loss: 0.0297\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [110/1000], Validation Loss: 0.0297\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [111/1000], Validation Loss: 0.0297\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [112/1000], Validation Loss: 0.0297\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [113/1000], Validation Loss: 0.0297\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [114/1000], Validation Loss: 0.0297\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [115/1000], Validation Loss: 0.0297\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [116/1000], Validation Loss: 0.0297\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [117/1000], Validation Loss: 0.0297\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [118/1000], Validation Loss: 0.0297\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [119/1000], Validation Loss: 0.0297\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [120/1000], Validation Loss: 0.0297\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [121/1000], Validation Loss: 0.0297\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [122/1000], Validation Loss: 0.0297\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [123/1000], Validation Loss: 0.0297\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [124/1000], Validation Loss: 0.0297\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [125/1000], Validation Loss: 0.0297\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [126/1000], Validation Loss: 0.0297\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [127/1000], Validation Loss: 0.0297\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [128/1000], Validation Loss: 0.0297\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [129/1000], Validation Loss: 0.0297\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [130/1000], Validation Loss: 0.0297\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [131/1000], Validation Loss: 0.0297\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [132/1000], Validation Loss: 0.0297\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [133/1000], Validation Loss: 0.0297\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [134/1000], Validation Loss: 0.0297\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [135/1000], Validation Loss: 0.0297\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [136/1000], Validation Loss: 0.0297\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [137/1000], Validation Loss: 0.0297\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [138/1000], Validation Loss: 0.0297\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [139/1000], Validation Loss: 0.0297\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [140/1000], Validation Loss: 0.0297\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [141/1000], Validation Loss: 0.0297\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [142/1000], Validation Loss: 0.0297\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [143/1000], Validation Loss: 0.0297\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [144/1000], Validation Loss: 0.0297\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [145/1000], Validation Loss: 0.0297\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [146/1000], Validation Loss: 0.0297\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [147/1000], Validation Loss: 0.0297\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [148/1000], Validation Loss: 0.0297\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [149/1000], Validation Loss: 0.0297\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [150/1000], Validation Loss: 0.0297\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [151/1000], Validation Loss: 0.0297\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [152/1000], Validation Loss: 0.0297\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [153/1000], Validation Loss: 0.0297\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [154/1000], Validation Loss: 0.0297\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [155/1000], Validation Loss: 0.0297\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [156/1000], Validation Loss: 0.0297\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [157/1000], Validation Loss: 0.0297\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [158/1000], Validation Loss: 0.0297\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [159/1000], Validation Loss: 0.0297\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [160/1000], Validation Loss: 0.0297\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [161/1000], Validation Loss: 0.0297\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [162/1000], Validation Loss: 0.0297\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [163/1000], Validation Loss: 0.0297\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [164/1000], Validation Loss: 0.0297\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [165/1000], Validation Loss: 0.0297\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [166/1000], Validation Loss: 0.0297\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [167/1000], Validation Loss: 0.0297\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [168/1000], Validation Loss: 0.0297\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [169/1000], Validation Loss: 0.0297\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [170/1000], Validation Loss: 0.0297\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [171/1000], Validation Loss: 0.0297\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [172/1000], Validation Loss: 0.0297\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [173/1000], Validation Loss: 0.0297\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [174/1000], Validation Loss: 0.0297\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [175/1000], Validation Loss: 0.0297\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [176/1000], Validation Loss: 0.0297\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [177/1000], Validation Loss: 0.0297\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [178/1000], Validation Loss: 0.0297\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [179/1000], Validation Loss: 0.0297\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [180/1000], Validation Loss: 0.0297\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [181/1000], Validation Loss: 0.0297\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [182/1000], Validation Loss: 0.0297\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [183/1000], Validation Loss: 0.0297\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [184/1000], Validation Loss: 0.0297\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [185/1000], Validation Loss: 0.0297\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [186/1000], Validation Loss: 0.0297\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [187/1000], Validation Loss: 0.0297\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [188/1000], Validation Loss: 0.0297\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [189/1000], Validation Loss: 0.0297\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [190/1000], Validation Loss: 0.0297\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [191/1000], Validation Loss: 0.0297\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [192/1000], Validation Loss: 0.0297\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [193/1000], Validation Loss: 0.0297\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [194/1000], Validation Loss: 0.0297\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [195/1000], Validation Loss: 0.0297\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [196/1000], Validation Loss: 0.0297\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [197/1000], Validation Loss: 0.0297\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [198/1000], Validation Loss: 0.0297\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [199/1000], Validation Loss: 0.0297\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [200/1000], Validation Loss: 0.0297\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [201/1000], Validation Loss: 0.0297\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [202/1000], Validation Loss: 0.0297\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [203/1000], Validation Loss: 0.0297\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [204/1000], Validation Loss: 0.0297\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [205/1000], Validation Loss: 0.0297\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [206/1000], Validation Loss: 0.0297\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [207/1000], Validation Loss: 0.0297\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [208/1000], Validation Loss: 0.0297\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [209/1000], Validation Loss: 0.0297\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [210/1000], Validation Loss: 0.0297\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [211/1000], Validation Loss: 0.0297\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [212/1000], Validation Loss: 0.0297\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [213/1000], Validation Loss: 0.0297\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [214/1000], Validation Loss: 0.0297\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [215/1000], Validation Loss: 0.0297\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0285\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [216/1000], Validation Loss: 0.0297\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [217/1000], Validation Loss: 0.0297\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [218/1000], Validation Loss: 0.0297\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [219/1000], Validation Loss: 0.0297\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [220/1000], Validation Loss: 0.0297\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [221/1000], Validation Loss: 0.0297\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [222/1000], Validation Loss: 0.0297\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [223/1000], Validation Loss: 0.0297\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [224/1000], Validation Loss: 0.0297\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [225/1000], Validation Loss: 0.0297\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [226/1000], Validation Loss: 0.0297\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [227/1000], Validation Loss: 0.0297\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [228/1000], Validation Loss: 0.0297\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [229/1000], Validation Loss: 0.0297\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [230/1000], Validation Loss: 0.0297\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [231/1000], Validation Loss: 0.0297\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [232/1000], Validation Loss: 0.0297\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [233/1000], Validation Loss: 0.0297\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [234/1000], Validation Loss: 0.0297\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [235/1000], Validation Loss: 0.0297\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [236/1000], Validation Loss: 0.0297\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [237/1000], Validation Loss: 0.0297\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [238/1000], Validation Loss: 0.0297\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [239/1000], Validation Loss: 0.0297\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [240/1000], Validation Loss: 0.0297\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [241/1000], Validation Loss: 0.0297\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [242/1000], Validation Loss: 0.0297\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [243/1000], Validation Loss: 0.0297\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [244/1000], Validation Loss: 0.0297\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [245/1000], Validation Loss: 0.0297\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [246/1000], Validation Loss: 0.0297\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [247/1000], Validation Loss: 0.0297\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [248/1000], Validation Loss: 0.0297\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [249/1000], Validation Loss: 0.0297\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [250/1000], Validation Loss: 0.0297\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [251/1000], Validation Loss: 0.0297\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [252/1000], Validation Loss: 0.0297\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [253/1000], Validation Loss: 0.0297\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [254/1000], Validation Loss: 0.0297\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0284\n",
            "Epoch [255/1000], Validation Loss: 0.0297\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [256/1000], Validation Loss: 0.0297\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [257/1000], Validation Loss: 0.0297\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [258/1000], Validation Loss: 0.0297\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [259/1000], Validation Loss: 0.0297\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [260/1000], Validation Loss: 0.0297\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [261/1000], Validation Loss: 0.0297\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [262/1000], Validation Loss: 0.0297\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [263/1000], Validation Loss: 0.0297\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [264/1000], Validation Loss: 0.0297\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [265/1000], Validation Loss: 0.0297\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [266/1000], Validation Loss: 0.0297\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [267/1000], Validation Loss: 0.0297\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [268/1000], Validation Loss: 0.0297\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [269/1000], Validation Loss: 0.0297\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [270/1000], Validation Loss: 0.0297\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [271/1000], Validation Loss: 0.0297\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [272/1000], Validation Loss: 0.0297\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [273/1000], Validation Loss: 0.0297\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [274/1000], Validation Loss: 0.0297\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [275/1000], Validation Loss: 0.0297\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [276/1000], Validation Loss: 0.0297\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [277/1000], Validation Loss: 0.0297\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [278/1000], Validation Loss: 0.0297\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [279/1000], Validation Loss: 0.0297\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [280/1000], Validation Loss: 0.0297\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [281/1000], Validation Loss: 0.0297\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [282/1000], Validation Loss: 0.0297\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [283/1000], Validation Loss: 0.0297\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [284/1000], Validation Loss: 0.0297\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [285/1000], Validation Loss: 0.0297\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [286/1000], Validation Loss: 0.0297\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [287/1000], Validation Loss: 0.0297\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [288/1000], Validation Loss: 0.0297\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [289/1000], Validation Loss: 0.0297\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [290/1000], Validation Loss: 0.0297\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [291/1000], Validation Loss: 0.0297\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [292/1000], Validation Loss: 0.0297\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [293/1000], Validation Loss: 0.0297\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [294/1000], Validation Loss: 0.0297\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [295/1000], Validation Loss: 0.0297\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [296/1000], Validation Loss: 0.0297\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [297/1000], Validation Loss: 0.0297\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [298/1000], Validation Loss: 0.0297\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [299/1000], Validation Loss: 0.0297\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [300/1000], Validation Loss: 0.0297\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [301/1000], Validation Loss: 0.0297\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [302/1000], Validation Loss: 0.0297\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [303/1000], Validation Loss: 0.0297\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [304/1000], Validation Loss: 0.0297\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [305/1000], Validation Loss: 0.0297\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [306/1000], Validation Loss: 0.0297\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [307/1000], Validation Loss: 0.0297\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [308/1000], Validation Loss: 0.0297\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [309/1000], Validation Loss: 0.0297\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [310/1000], Validation Loss: 0.0297\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [311/1000], Validation Loss: 0.0297\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [312/1000], Validation Loss: 0.0297\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [313/1000], Validation Loss: 0.0297\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [314/1000], Validation Loss: 0.0297\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [315/1000], Validation Loss: 0.0297\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [316/1000], Validation Loss: 0.0297\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [317/1000], Validation Loss: 0.0297\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [318/1000], Validation Loss: 0.0297\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [319/1000], Validation Loss: 0.0297\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [320/1000], Validation Loss: 0.0297\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [321/1000], Validation Loss: 0.0297\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [322/1000], Validation Loss: 0.0297\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [323/1000], Validation Loss: 0.0297\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [324/1000], Validation Loss: 0.0297\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [325/1000], Validation Loss: 0.0297\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [326/1000], Validation Loss: 0.0297\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [327/1000], Validation Loss: 0.0297\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [328/1000], Validation Loss: 0.0297\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [329/1000], Validation Loss: 0.0297\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [330/1000], Validation Loss: 0.0297\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [331/1000], Validation Loss: 0.0297\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [332/1000], Validation Loss: 0.0297\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [333/1000], Validation Loss: 0.0297\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [334/1000], Validation Loss: 0.0297\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [335/1000], Validation Loss: 0.0297\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [336/1000], Validation Loss: 0.0297\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [337/1000], Validation Loss: 0.0297\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [338/1000], Validation Loss: 0.0297\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [339/1000], Validation Loss: 0.0297\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [340/1000], Validation Loss: 0.0297\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [341/1000], Validation Loss: 0.0297\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [342/1000], Validation Loss: 0.0297\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [343/1000], Validation Loss: 0.0297\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [344/1000], Validation Loss: 0.0297\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [345/1000], Validation Loss: 0.0297\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [346/1000], Validation Loss: 0.0297\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [347/1000], Validation Loss: 0.0297\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [348/1000], Validation Loss: 0.0297\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [349/1000], Validation Loss: 0.0297\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [350/1000], Validation Loss: 0.0297\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [351/1000], Validation Loss: 0.0297\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [352/1000], Validation Loss: 0.0297\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [353/1000], Validation Loss: 0.0297\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [354/1000], Validation Loss: 0.0297\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [355/1000], Validation Loss: 0.0297\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [356/1000], Validation Loss: 0.0297\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [357/1000], Validation Loss: 0.0297\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [358/1000], Validation Loss: 0.0297\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [359/1000], Validation Loss: 0.0297\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [360/1000], Validation Loss: 0.0297\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [361/1000], Validation Loss: 0.0297\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [362/1000], Validation Loss: 0.0297\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [363/1000], Validation Loss: 0.0297\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [364/1000], Validation Loss: 0.0297\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [365/1000], Validation Loss: 0.0297\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [366/1000], Validation Loss: 0.0297\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [367/1000], Validation Loss: 0.0297\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [368/1000], Validation Loss: 0.0297\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [369/1000], Validation Loss: 0.0297\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [370/1000], Validation Loss: 0.0297\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [371/1000], Validation Loss: 0.0297\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [372/1000], Validation Loss: 0.0297\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [373/1000], Validation Loss: 0.0297\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [374/1000], Validation Loss: 0.0297\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [375/1000], Validation Loss: 0.0297\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [376/1000], Validation Loss: 0.0297\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [377/1000], Validation Loss: 0.0297\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [378/1000], Validation Loss: 0.0297\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [379/1000], Validation Loss: 0.0297\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [380/1000], Validation Loss: 0.0297\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [381/1000], Validation Loss: 0.0297\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [382/1000], Validation Loss: 0.0297\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [383/1000], Validation Loss: 0.0297\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [384/1000], Validation Loss: 0.0297\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [385/1000], Validation Loss: 0.0297\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [386/1000], Validation Loss: 0.0297\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [387/1000], Validation Loss: 0.0297\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [388/1000], Validation Loss: 0.0297\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [389/1000], Validation Loss: 0.0297\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [390/1000], Validation Loss: 0.0297\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [391/1000], Validation Loss: 0.0297\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [392/1000], Validation Loss: 0.0297\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [393/1000], Validation Loss: 0.0297\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [394/1000], Validation Loss: 0.0297\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [395/1000], Validation Loss: 0.0297\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [396/1000], Validation Loss: 0.0297\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [397/1000], Validation Loss: 0.0297\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [398/1000], Validation Loss: 0.0297\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [399/1000], Validation Loss: 0.0297\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [400/1000], Validation Loss: 0.0297\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [401/1000], Validation Loss: 0.0297\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [402/1000], Validation Loss: 0.0297\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [403/1000], Validation Loss: 0.0297\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [404/1000], Validation Loss: 0.0297\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [405/1000], Validation Loss: 0.0297\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [406/1000], Validation Loss: 0.0297\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [407/1000], Validation Loss: 0.0297\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [408/1000], Validation Loss: 0.0297\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [409/1000], Validation Loss: 0.0297\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [410/1000], Validation Loss: 0.0297\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [411/1000], Validation Loss: 0.0297\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [412/1000], Validation Loss: 0.0297\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [413/1000], Validation Loss: 0.0297\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [414/1000], Validation Loss: 0.0297\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [415/1000], Validation Loss: 0.0297\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [416/1000], Validation Loss: 0.0297\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [417/1000], Validation Loss: 0.0297\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [418/1000], Validation Loss: 0.0297\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [419/1000], Validation Loss: 0.0297\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [420/1000], Validation Loss: 0.0297\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [421/1000], Validation Loss: 0.0297\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [422/1000], Validation Loss: 0.0297\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [423/1000], Validation Loss: 0.0297\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [424/1000], Validation Loss: 0.0297\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [425/1000], Validation Loss: 0.0297\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [426/1000], Validation Loss: 0.0297\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [427/1000], Validation Loss: 0.0297\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [428/1000], Validation Loss: 0.0297\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [429/1000], Validation Loss: 0.0297\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [430/1000], Validation Loss: 0.0297\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [431/1000], Validation Loss: 0.0297\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [432/1000], Validation Loss: 0.0297\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [433/1000], Validation Loss: 0.0297\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [434/1000], Validation Loss: 0.0297\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [435/1000], Validation Loss: 0.0297\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [436/1000], Validation Loss: 0.0297\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [437/1000], Validation Loss: 0.0297\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [438/1000], Validation Loss: 0.0297\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [439/1000], Validation Loss: 0.0297\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [440/1000], Validation Loss: 0.0297\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [441/1000], Validation Loss: 0.0297\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [442/1000], Validation Loss: 0.0297\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [443/1000], Validation Loss: 0.0297\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [444/1000], Validation Loss: 0.0297\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [445/1000], Validation Loss: 0.0297\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [446/1000], Validation Loss: 0.0297\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [447/1000], Validation Loss: 0.0297\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [448/1000], Validation Loss: 0.0297\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [449/1000], Validation Loss: 0.0297\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [450/1000], Validation Loss: 0.0297\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [451/1000], Validation Loss: 0.0297\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [452/1000], Validation Loss: 0.0297\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [453/1000], Validation Loss: 0.0297\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [454/1000], Validation Loss: 0.0297\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [455/1000], Validation Loss: 0.0297\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [456/1000], Validation Loss: 0.0297\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [457/1000], Validation Loss: 0.0297\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [458/1000], Validation Loss: 0.0297\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [459/1000], Validation Loss: 0.0297\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [460/1000], Validation Loss: 0.0297\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [461/1000], Validation Loss: 0.0297\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [462/1000], Validation Loss: 0.0297\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [463/1000], Validation Loss: 0.0297\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [464/1000], Validation Loss: 0.0297\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [465/1000], Validation Loss: 0.0297\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [466/1000], Validation Loss: 0.0297\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [467/1000], Validation Loss: 0.0297\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [468/1000], Validation Loss: 0.0297\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [469/1000], Validation Loss: 0.0297\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [470/1000], Validation Loss: 0.0297\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [471/1000], Validation Loss: 0.0297\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [472/1000], Validation Loss: 0.0297\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [473/1000], Validation Loss: 0.0297\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [474/1000], Validation Loss: 0.0297\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [475/1000], Validation Loss: 0.0297\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [476/1000], Validation Loss: 0.0297\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [477/1000], Validation Loss: 0.0297\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [478/1000], Validation Loss: 0.0297\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [479/1000], Validation Loss: 0.0297\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [480/1000], Validation Loss: 0.0297\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [481/1000], Validation Loss: 0.0297\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [482/1000], Validation Loss: 0.0297\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [483/1000], Validation Loss: 0.0297\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [484/1000], Validation Loss: 0.0297\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [485/1000], Validation Loss: 0.0297\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [486/1000], Validation Loss: 0.0297\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [487/1000], Validation Loss: 0.0297\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [488/1000], Validation Loss: 0.0297\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [489/1000], Validation Loss: 0.0297\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [490/1000], Validation Loss: 0.0297\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [491/1000], Validation Loss: 0.0297\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [492/1000], Validation Loss: 0.0297\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [493/1000], Validation Loss: 0.0297\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [494/1000], Validation Loss: 0.0297\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [495/1000], Validation Loss: 0.0297\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [496/1000], Validation Loss: 0.0297\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [497/1000], Validation Loss: 0.0297\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [498/1000], Validation Loss: 0.0297\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [499/1000], Validation Loss: 0.0297\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [500/1000], Validation Loss: 0.0297\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [501/1000], Validation Loss: 0.0297\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [502/1000], Validation Loss: 0.0297\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [503/1000], Validation Loss: 0.0297\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [504/1000], Validation Loss: 0.0297\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [505/1000], Validation Loss: 0.0297\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [506/1000], Validation Loss: 0.0297\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [507/1000], Validation Loss: 0.0297\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [508/1000], Validation Loss: 0.0297\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [509/1000], Validation Loss: 0.0297\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [510/1000], Validation Loss: 0.0297\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [511/1000], Validation Loss: 0.0297\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [512/1000], Validation Loss: 0.0297\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [513/1000], Validation Loss: 0.0297\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [514/1000], Validation Loss: 0.0297\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [515/1000], Validation Loss: 0.0297\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [516/1000], Validation Loss: 0.0297\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [517/1000], Validation Loss: 0.0297\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [518/1000], Validation Loss: 0.0297\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [519/1000], Validation Loss: 0.0297\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [520/1000], Validation Loss: 0.0297\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [521/1000], Validation Loss: 0.0297\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [522/1000], Validation Loss: 0.0297\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [523/1000], Validation Loss: 0.0297\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [524/1000], Validation Loss: 0.0297\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [525/1000], Validation Loss: 0.0297\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [526/1000], Validation Loss: 0.0297\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [527/1000], Validation Loss: 0.0297\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [528/1000], Validation Loss: 0.0297\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [529/1000], Validation Loss: 0.0297\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [530/1000], Validation Loss: 0.0297\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [531/1000], Validation Loss: 0.0297\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [532/1000], Validation Loss: 0.0297\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [533/1000], Validation Loss: 0.0297\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [534/1000], Validation Loss: 0.0297\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [535/1000], Validation Loss: 0.0297\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [536/1000], Validation Loss: 0.0297\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [537/1000], Validation Loss: 0.0297\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [538/1000], Validation Loss: 0.0297\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [539/1000], Validation Loss: 0.0297\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [540/1000], Validation Loss: 0.0297\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [541/1000], Validation Loss: 0.0297\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [542/1000], Validation Loss: 0.0297\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [543/1000], Validation Loss: 0.0297\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [544/1000], Validation Loss: 0.0297\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [545/1000], Validation Loss: 0.0297\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [546/1000], Validation Loss: 0.0297\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [547/1000], Validation Loss: 0.0297\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [548/1000], Validation Loss: 0.0297\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [549/1000], Validation Loss: 0.0297\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [550/1000], Validation Loss: 0.0297\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [551/1000], Validation Loss: 0.0297\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [552/1000], Validation Loss: 0.0297\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [553/1000], Validation Loss: 0.0297\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [554/1000], Validation Loss: 0.0297\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [555/1000], Validation Loss: 0.0297\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [556/1000], Validation Loss: 0.0297\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [557/1000], Validation Loss: 0.0297\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [558/1000], Validation Loss: 0.0297\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [559/1000], Validation Loss: 0.0297\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [560/1000], Validation Loss: 0.0297\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [561/1000], Validation Loss: 0.0297\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [562/1000], Validation Loss: 0.0297\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [563/1000], Validation Loss: 0.0297\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [564/1000], Validation Loss: 0.0297\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [565/1000], Validation Loss: 0.0297\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [566/1000], Validation Loss: 0.0297\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [567/1000], Validation Loss: 0.0297\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [568/1000], Validation Loss: 0.0297\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [569/1000], Validation Loss: 0.0297\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [570/1000], Validation Loss: 0.0297\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [571/1000], Validation Loss: 0.0297\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [572/1000], Validation Loss: 0.0297\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [573/1000], Validation Loss: 0.0297\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [574/1000], Validation Loss: 0.0297\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [575/1000], Validation Loss: 0.0297\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [576/1000], Validation Loss: 0.0297\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [577/1000], Validation Loss: 0.0297\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [578/1000], Validation Loss: 0.0297\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [579/1000], Validation Loss: 0.0297\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [580/1000], Validation Loss: 0.0297\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [581/1000], Validation Loss: 0.0297\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [582/1000], Validation Loss: 0.0297\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [583/1000], Validation Loss: 0.0297\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [584/1000], Validation Loss: 0.0297\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [585/1000], Validation Loss: 0.0297\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [586/1000], Validation Loss: 0.0297\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [587/1000], Validation Loss: 0.0297\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [588/1000], Validation Loss: 0.0297\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [589/1000], Validation Loss: 0.0297\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [590/1000], Validation Loss: 0.0297\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [591/1000], Validation Loss: 0.0297\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [592/1000], Validation Loss: 0.0297\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [593/1000], Validation Loss: 0.0297\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [594/1000], Validation Loss: 0.0297\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [595/1000], Validation Loss: 0.0297\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [596/1000], Validation Loss: 0.0297\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [597/1000], Validation Loss: 0.0297\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [598/1000], Validation Loss: 0.0297\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [599/1000], Validation Loss: 0.0297\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [600/1000], Validation Loss: 0.0297\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [601/1000], Validation Loss: 0.0297\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [602/1000], Validation Loss: 0.0297\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [603/1000], Validation Loss: 0.0297\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [604/1000], Validation Loss: 0.0297\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [605/1000], Validation Loss: 0.0297\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [606/1000], Validation Loss: 0.0297\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [607/1000], Validation Loss: 0.0297\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [608/1000], Validation Loss: 0.0297\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [609/1000], Validation Loss: 0.0297\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [610/1000], Validation Loss: 0.0297\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [611/1000], Validation Loss: 0.0297\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [612/1000], Validation Loss: 0.0297\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [613/1000], Validation Loss: 0.0297\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [614/1000], Validation Loss: 0.0297\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [615/1000], Validation Loss: 0.0297\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [616/1000], Validation Loss: 0.0297\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [617/1000], Validation Loss: 0.0297\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [618/1000], Validation Loss: 0.0297\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [619/1000], Validation Loss: 0.0297\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [620/1000], Validation Loss: 0.0297\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [621/1000], Validation Loss: 0.0297\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [622/1000], Validation Loss: 0.0297\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [623/1000], Validation Loss: 0.0297\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [624/1000], Validation Loss: 0.0297\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [625/1000], Validation Loss: 0.0297\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [626/1000], Validation Loss: 0.0297\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [627/1000], Validation Loss: 0.0297\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [628/1000], Validation Loss: 0.0297\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [629/1000], Validation Loss: 0.0297\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [630/1000], Validation Loss: 0.0297\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [631/1000], Validation Loss: 0.0297\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [632/1000], Validation Loss: 0.0297\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [633/1000], Validation Loss: 0.0297\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [634/1000], Validation Loss: 0.0297\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [635/1000], Validation Loss: 0.0297\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [636/1000], Validation Loss: 0.0297\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [637/1000], Validation Loss: 0.0297\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [638/1000], Validation Loss: 0.0297\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [639/1000], Validation Loss: 0.0297\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [640/1000], Validation Loss: 0.0297\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [641/1000], Validation Loss: 0.0297\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [642/1000], Validation Loss: 0.0297\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [643/1000], Validation Loss: 0.0297\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [644/1000], Validation Loss: 0.0297\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [645/1000], Validation Loss: 0.0297\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [646/1000], Validation Loss: 0.0297\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [647/1000], Validation Loss: 0.0297\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [648/1000], Validation Loss: 0.0297\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [649/1000], Validation Loss: 0.0297\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [650/1000], Validation Loss: 0.0297\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [651/1000], Validation Loss: 0.0297\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [652/1000], Validation Loss: 0.0297\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [653/1000], Validation Loss: 0.0297\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [654/1000], Validation Loss: 0.0297\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [655/1000], Validation Loss: 0.0297\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [656/1000], Validation Loss: 0.0297\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [657/1000], Validation Loss: 0.0297\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [658/1000], Validation Loss: 0.0297\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [659/1000], Validation Loss: 0.0297\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [660/1000], Validation Loss: 0.0297\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [661/1000], Validation Loss: 0.0297\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [662/1000], Validation Loss: 0.0297\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [663/1000], Validation Loss: 0.0297\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [664/1000], Validation Loss: 0.0297\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [665/1000], Validation Loss: 0.0297\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [666/1000], Validation Loss: 0.0297\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [667/1000], Validation Loss: 0.0297\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [668/1000], Validation Loss: 0.0297\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [669/1000], Validation Loss: 0.0297\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [670/1000], Validation Loss: 0.0297\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [671/1000], Validation Loss: 0.0297\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [672/1000], Validation Loss: 0.0297\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [673/1000], Validation Loss: 0.0297\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [674/1000], Validation Loss: 0.0297\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [675/1000], Validation Loss: 0.0297\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [676/1000], Validation Loss: 0.0297\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [677/1000], Validation Loss: 0.0297\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [678/1000], Validation Loss: 0.0297\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [679/1000], Validation Loss: 0.0297\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [680/1000], Validation Loss: 0.0297\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [681/1000], Validation Loss: 0.0297\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [682/1000], Validation Loss: 0.0297\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [683/1000], Validation Loss: 0.0297\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [684/1000], Validation Loss: 0.0297\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [685/1000], Validation Loss: 0.0297\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [686/1000], Validation Loss: 0.0297\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [687/1000], Validation Loss: 0.0297\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [688/1000], Validation Loss: 0.0297\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [689/1000], Validation Loss: 0.0297\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [690/1000], Validation Loss: 0.0297\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [691/1000], Validation Loss: 0.0297\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [692/1000], Validation Loss: 0.0297\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [693/1000], Validation Loss: 0.0297\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [694/1000], Validation Loss: 0.0297\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [695/1000], Validation Loss: 0.0297\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [696/1000], Validation Loss: 0.0297\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [697/1000], Validation Loss: 0.0297\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [698/1000], Validation Loss: 0.0297\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [699/1000], Validation Loss: 0.0297\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [700/1000], Validation Loss: 0.0297\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [701/1000], Validation Loss: 0.0297\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [702/1000], Validation Loss: 0.0297\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [703/1000], Validation Loss: 0.0297\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [704/1000], Validation Loss: 0.0297\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [705/1000], Validation Loss: 0.0297\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [706/1000], Validation Loss: 0.0297\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [707/1000], Validation Loss: 0.0297\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [708/1000], Validation Loss: 0.0297\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [709/1000], Validation Loss: 0.0297\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [710/1000], Validation Loss: 0.0297\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [711/1000], Validation Loss: 0.0297\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [712/1000], Validation Loss: 0.0297\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [713/1000], Validation Loss: 0.0297\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [714/1000], Validation Loss: 0.0297\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [715/1000], Validation Loss: 0.0297\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [716/1000], Validation Loss: 0.0297\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [717/1000], Validation Loss: 0.0297\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [718/1000], Validation Loss: 0.0297\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [719/1000], Validation Loss: 0.0297\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [720/1000], Validation Loss: 0.0297\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [721/1000], Validation Loss: 0.0297\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [722/1000], Validation Loss: 0.0297\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [723/1000], Validation Loss: 0.0297\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [724/1000], Validation Loss: 0.0297\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [725/1000], Validation Loss: 0.0297\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [726/1000], Validation Loss: 0.0297\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [727/1000], Validation Loss: 0.0297\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [728/1000], Validation Loss: 0.0297\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [729/1000], Validation Loss: 0.0297\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [730/1000], Validation Loss: 0.0297\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [731/1000], Validation Loss: 0.0297\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [732/1000], Validation Loss: 0.0297\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [733/1000], Validation Loss: 0.0297\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [734/1000], Validation Loss: 0.0297\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [735/1000], Validation Loss: 0.0297\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [736/1000], Validation Loss: 0.0297\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [737/1000], Validation Loss: 0.0297\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [738/1000], Validation Loss: 0.0297\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [739/1000], Validation Loss: 0.0297\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [740/1000], Validation Loss: 0.0297\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [741/1000], Validation Loss: 0.0297\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [742/1000], Validation Loss: 0.0297\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [743/1000], Validation Loss: 0.0297\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [744/1000], Validation Loss: 0.0297\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [745/1000], Validation Loss: 0.0297\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [746/1000], Validation Loss: 0.0297\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [747/1000], Validation Loss: 0.0297\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [748/1000], Validation Loss: 0.0297\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [749/1000], Validation Loss: 0.0297\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [750/1000], Validation Loss: 0.0297\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [751/1000], Validation Loss: 0.0297\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [752/1000], Validation Loss: 0.0297\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [753/1000], Validation Loss: 0.0297\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [754/1000], Validation Loss: 0.0297\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [755/1000], Validation Loss: 0.0297\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [756/1000], Validation Loss: 0.0297\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [757/1000], Validation Loss: 0.0297\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [758/1000], Validation Loss: 0.0297\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [759/1000], Validation Loss: 0.0297\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [760/1000], Validation Loss: 0.0297\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [761/1000], Validation Loss: 0.0297\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [762/1000], Validation Loss: 0.0297\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [763/1000], Validation Loss: 0.0297\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [764/1000], Validation Loss: 0.0297\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [765/1000], Validation Loss: 0.0297\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [766/1000], Validation Loss: 0.0297\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [767/1000], Validation Loss: 0.0297\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [768/1000], Validation Loss: 0.0297\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [769/1000], Validation Loss: 0.0297\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [770/1000], Validation Loss: 0.0297\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [771/1000], Validation Loss: 0.0297\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [772/1000], Validation Loss: 0.0297\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [773/1000], Validation Loss: 0.0297\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [774/1000], Validation Loss: 0.0297\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [775/1000], Validation Loss: 0.0297\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [776/1000], Validation Loss: 0.0297\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [777/1000], Validation Loss: 0.0297\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [778/1000], Validation Loss: 0.0297\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [779/1000], Validation Loss: 0.0297\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [780/1000], Validation Loss: 0.0297\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [781/1000], Validation Loss: 0.0297\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [782/1000], Validation Loss: 0.0297\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [783/1000], Validation Loss: 0.0297\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [784/1000], Validation Loss: 0.0297\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [785/1000], Validation Loss: 0.0297\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [786/1000], Validation Loss: 0.0297\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [787/1000], Validation Loss: 0.0297\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [788/1000], Validation Loss: 0.0297\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [789/1000], Validation Loss: 0.0297\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [790/1000], Validation Loss: 0.0297\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [791/1000], Validation Loss: 0.0297\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [792/1000], Validation Loss: 0.0297\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [793/1000], Validation Loss: 0.0297\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [794/1000], Validation Loss: 0.0297\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [795/1000], Validation Loss: 0.0297\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [796/1000], Validation Loss: 0.0297\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [797/1000], Validation Loss: 0.0297\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [798/1000], Validation Loss: 0.0297\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [799/1000], Validation Loss: 0.0297\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [800/1000], Validation Loss: 0.0297\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [801/1000], Validation Loss: 0.0297\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [802/1000], Validation Loss: 0.0297\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [803/1000], Validation Loss: 0.0297\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [804/1000], Validation Loss: 0.0297\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [805/1000], Validation Loss: 0.0297\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [806/1000], Validation Loss: 0.0297\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [807/1000], Validation Loss: 0.0297\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [808/1000], Validation Loss: 0.0297\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [809/1000], Validation Loss: 0.0297\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [810/1000], Validation Loss: 0.0297\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [811/1000], Validation Loss: 0.0297\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [812/1000], Validation Loss: 0.0297\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [813/1000], Validation Loss: 0.0297\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [814/1000], Validation Loss: 0.0297\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [815/1000], Validation Loss: 0.0297\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [816/1000], Validation Loss: 0.0297\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [817/1000], Validation Loss: 0.0297\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [818/1000], Validation Loss: 0.0297\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [819/1000], Validation Loss: 0.0297\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [820/1000], Validation Loss: 0.0297\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [821/1000], Validation Loss: 0.0297\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [822/1000], Validation Loss: 0.0297\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [823/1000], Validation Loss: 0.0297\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [824/1000], Validation Loss: 0.0297\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [825/1000], Validation Loss: 0.0297\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [826/1000], Validation Loss: 0.0297\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [827/1000], Validation Loss: 0.0297\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [828/1000], Validation Loss: 0.0297\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [829/1000], Validation Loss: 0.0297\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [830/1000], Validation Loss: 0.0297\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [831/1000], Validation Loss: 0.0297\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [832/1000], Validation Loss: 0.0297\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [833/1000], Validation Loss: 0.0297\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [834/1000], Validation Loss: 0.0297\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [835/1000], Validation Loss: 0.0297\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [836/1000], Validation Loss: 0.0297\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [837/1000], Validation Loss: 0.0297\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [838/1000], Validation Loss: 0.0297\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [839/1000], Validation Loss: 0.0297\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [840/1000], Validation Loss: 0.0297\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [841/1000], Validation Loss: 0.0297\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [842/1000], Validation Loss: 0.0297\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [843/1000], Validation Loss: 0.0297\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [844/1000], Validation Loss: 0.0297\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [845/1000], Validation Loss: 0.0297\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [846/1000], Validation Loss: 0.0297\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [847/1000], Validation Loss: 0.0297\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [848/1000], Validation Loss: 0.0297\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [849/1000], Validation Loss: 0.0297\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [850/1000], Validation Loss: 0.0297\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0285\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [851/1000], Validation Loss: 0.0297\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [852/1000], Validation Loss: 0.0297\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [853/1000], Validation Loss: 0.0297\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [854/1000], Validation Loss: 0.0297\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [855/1000], Validation Loss: 0.0297\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [856/1000], Validation Loss: 0.0297\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [857/1000], Validation Loss: 0.0297\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [858/1000], Validation Loss: 0.0297\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [859/1000], Validation Loss: 0.0297\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [860/1000], Validation Loss: 0.0297\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [861/1000], Validation Loss: 0.0297\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [862/1000], Validation Loss: 0.0297\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [863/1000], Validation Loss: 0.0297\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [864/1000], Validation Loss: 0.0297\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [865/1000], Validation Loss: 0.0297\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [866/1000], Validation Loss: 0.0297\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [867/1000], Validation Loss: 0.0297\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [868/1000], Validation Loss: 0.0297\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [869/1000], Validation Loss: 0.0297\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [870/1000], Validation Loss: 0.0297\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [871/1000], Validation Loss: 0.0297\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [872/1000], Validation Loss: 0.0297\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [873/1000], Validation Loss: 0.0297\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [874/1000], Validation Loss: 0.0297\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [875/1000], Validation Loss: 0.0297\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [876/1000], Validation Loss: 0.0297\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [877/1000], Validation Loss: 0.0297\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [878/1000], Validation Loss: 0.0297\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [879/1000], Validation Loss: 0.0297\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [880/1000], Validation Loss: 0.0297\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [881/1000], Validation Loss: 0.0297\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [882/1000], Validation Loss: 0.0297\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [883/1000], Validation Loss: 0.0297\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [884/1000], Validation Loss: 0.0297\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [885/1000], Validation Loss: 0.0297\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [886/1000], Validation Loss: 0.0297\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [887/1000], Validation Loss: 0.0297\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [888/1000], Validation Loss: 0.0297\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [889/1000], Validation Loss: 0.0297\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [890/1000], Validation Loss: 0.0297\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [891/1000], Validation Loss: 0.0297\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [892/1000], Validation Loss: 0.0297\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [893/1000], Validation Loss: 0.0297\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [894/1000], Validation Loss: 0.0297\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [895/1000], Validation Loss: 0.0297\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [896/1000], Validation Loss: 0.0297\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [897/1000], Validation Loss: 0.0297\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [898/1000], Validation Loss: 0.0297\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [899/1000], Validation Loss: 0.0297\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [900/1000], Validation Loss: 0.0297\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [901/1000], Validation Loss: 0.0297\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [902/1000], Validation Loss: 0.0297\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [903/1000], Validation Loss: 0.0297\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [904/1000], Validation Loss: 0.0297\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [905/1000], Validation Loss: 0.0297\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [906/1000], Validation Loss: 0.0297\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [907/1000], Validation Loss: 0.0297\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [908/1000], Validation Loss: 0.0297\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [909/1000], Validation Loss: 0.0297\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [910/1000], Validation Loss: 0.0297\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [911/1000], Validation Loss: 0.0297\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [912/1000], Validation Loss: 0.0297\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [913/1000], Validation Loss: 0.0297\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [914/1000], Validation Loss: 0.0297\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [915/1000], Validation Loss: 0.0297\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [916/1000], Validation Loss: 0.0297\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [917/1000], Validation Loss: 0.0297\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [918/1000], Validation Loss: 0.0297\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [919/1000], Validation Loss: 0.0297\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [920/1000], Validation Loss: 0.0297\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [921/1000], Validation Loss: 0.0297\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [922/1000], Validation Loss: 0.0297\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [923/1000], Validation Loss: 0.0297\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [924/1000], Validation Loss: 0.0297\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [925/1000], Validation Loss: 0.0297\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [926/1000], Validation Loss: 0.0297\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [927/1000], Validation Loss: 0.0297\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [928/1000], Validation Loss: 0.0297\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [929/1000], Validation Loss: 0.0297\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [930/1000], Validation Loss: 0.0297\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [931/1000], Validation Loss: 0.0297\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [932/1000], Validation Loss: 0.0297\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [933/1000], Validation Loss: 0.0297\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [934/1000], Validation Loss: 0.0297\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [935/1000], Validation Loss: 0.0297\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [936/1000], Validation Loss: 0.0297\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [937/1000], Validation Loss: 0.0297\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [938/1000], Validation Loss: 0.0297\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [939/1000], Validation Loss: 0.0297\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [940/1000], Validation Loss: 0.0297\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [941/1000], Validation Loss: 0.0297\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [942/1000], Validation Loss: 0.0297\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [943/1000], Validation Loss: 0.0297\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [944/1000], Validation Loss: 0.0297\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [945/1000], Validation Loss: 0.0297\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [946/1000], Validation Loss: 0.0297\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [947/1000], Validation Loss: 0.0297\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [948/1000], Validation Loss: 0.0297\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [949/1000], Validation Loss: 0.0297\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [950/1000], Validation Loss: 0.0297\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [951/1000], Validation Loss: 0.0297\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [952/1000], Validation Loss: 0.0297\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [953/1000], Validation Loss: 0.0297\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [954/1000], Validation Loss: 0.0297\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [955/1000], Validation Loss: 0.0297\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [956/1000], Validation Loss: 0.0297\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [957/1000], Validation Loss: 0.0297\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [958/1000], Validation Loss: 0.0297\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [959/1000], Validation Loss: 0.0297\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [960/1000], Validation Loss: 0.0297\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [961/1000], Validation Loss: 0.0297\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [962/1000], Validation Loss: 0.0297\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [963/1000], Validation Loss: 0.0297\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [964/1000], Validation Loss: 0.0297\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [965/1000], Validation Loss: 0.0297\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [966/1000], Validation Loss: 0.0297\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [967/1000], Validation Loss: 0.0297\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [968/1000], Validation Loss: 0.0297\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [969/1000], Validation Loss: 0.0297\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [970/1000], Validation Loss: 0.0297\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [971/1000], Validation Loss: 0.0297\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [972/1000], Validation Loss: 0.0297\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [973/1000], Validation Loss: 0.0297\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [974/1000], Validation Loss: 0.0297\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [975/1000], Validation Loss: 0.0297\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [976/1000], Validation Loss: 0.0297\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [977/1000], Validation Loss: 0.0297\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [978/1000], Validation Loss: 0.0297\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [979/1000], Validation Loss: 0.0297\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [980/1000], Validation Loss: 0.0297\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [981/1000], Validation Loss: 0.0297\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [982/1000], Validation Loss: 0.0297\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [983/1000], Validation Loss: 0.0297\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [984/1000], Validation Loss: 0.0297\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [985/1000], Validation Loss: 0.0297\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [986/1000], Validation Loss: 0.0297\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [987/1000], Validation Loss: 0.0297\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [988/1000], Validation Loss: 0.0297\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [989/1000], Validation Loss: 0.0297\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [990/1000], Validation Loss: 0.0297\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [991/1000], Validation Loss: 0.0297\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [992/1000], Validation Loss: 0.0297\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [993/1000], Validation Loss: 0.0297\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [994/1000], Validation Loss: 0.0297\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [995/1000], Validation Loss: 0.0297\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [996/1000], Validation Loss: 0.0297\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [997/1000], Validation Loss: 0.0297\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [998/1000], Validation Loss: 0.0297\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [999/1000], Validation Loss: 0.0297\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [1000/1000], Validation Loss: 0.0297\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 3"
      ],
      "metadata": {
        "id": "8v7yjLSS51TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator3(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator3, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator3(Generator3):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, max_grad_norm):\n",
        "          super(DPGenerator3, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "          self.noise_multiplier = nn.Parameter(torch.tensor(1.0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = F.relu(layer(x))\n",
        "            # Add noise proportional to the noise multiplier\n",
        "            noise = torch.randn_like(x) * self.noise_multiplier\n",
        "            x = x + noise  # Use x = x + noise instead of inplace operation x += noise\n",
        "        x = self.layers[-1](x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GhQGwJUW5s05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model3 = DPGenerator3(input_size, hidden_size, output_size, num_layers, max_grad_norm).to(device)\n",
        "model3.noise_multiplier.data.fill_(noise_multiplier)\n",
        "\n",
        "\n",
        "# Define the loss function\n",
        "optimizer3 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion3 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "V5TCXM3o50Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []"
      ],
      "metadata": {
        "id": "VaVk1xZK6Dgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model3.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer3.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model3(real_features)\n",
        "        loss = criterion3(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer3.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model3.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model3(real_features)\n",
        "            loss = criterion3(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bJjjJ0PrGMdm",
        "outputId": "7728e7f3-623e-4c65-e623-58acd21df6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [1/1000], Validation Loss: 0.0315\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [2/1000], Validation Loss: 0.0314\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [3/1000], Validation Loss: 0.0315\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [4/1000], Validation Loss: 0.0314\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [5/1000], Validation Loss: 0.0314\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [6/1000], Validation Loss: 0.0315\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [7/1000], Validation Loss: 0.0315\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [8/1000], Validation Loss: 0.0314\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [9/1000], Validation Loss: 0.0314\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [10/1000], Validation Loss: 0.0315\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [11/1000], Validation Loss: 0.0315\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [12/1000], Validation Loss: 0.0314\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [13/1000], Validation Loss: 0.0314\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [14/1000], Validation Loss: 0.0315\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [15/1000], Validation Loss: 0.0315\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [16/1000], Validation Loss: 0.0315\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [17/1000], Validation Loss: 0.0315\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [18/1000], Validation Loss: 0.0314\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [19/1000], Validation Loss: 0.0314\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [20/1000], Validation Loss: 0.0313\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [21/1000], Validation Loss: 0.0315\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [22/1000], Validation Loss: 0.0315\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [23/1000], Validation Loss: 0.0315\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [24/1000], Validation Loss: 0.0315\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [25/1000], Validation Loss: 0.0315\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [26/1000], Validation Loss: 0.0314\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [27/1000], Validation Loss: 0.0314\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [28/1000], Validation Loss: 0.0314\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [29/1000], Validation Loss: 0.0315\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [30/1000], Validation Loss: 0.0314\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [31/1000], Validation Loss: 0.0315\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [32/1000], Validation Loss: 0.0314\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [33/1000], Validation Loss: 0.0315\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [34/1000], Validation Loss: 0.0314\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [35/1000], Validation Loss: 0.0315\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [36/1000], Validation Loss: 0.0314\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [37/1000], Validation Loss: 0.0315\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [38/1000], Validation Loss: 0.0314\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [39/1000], Validation Loss: 0.0314\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [40/1000], Validation Loss: 0.0315\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [41/1000], Validation Loss: 0.0315\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [42/1000], Validation Loss: 0.0314\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [43/1000], Validation Loss: 0.0315\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [44/1000], Validation Loss: 0.0315\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [45/1000], Validation Loss: 0.0315\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [46/1000], Validation Loss: 0.0315\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [47/1000], Validation Loss: 0.0315\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [48/1000], Validation Loss: 0.0314\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [49/1000], Validation Loss: 0.0315\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [50/1000], Validation Loss: 0.0315\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [51/1000], Validation Loss: 0.0315\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [52/1000], Validation Loss: 0.0314\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [53/1000], Validation Loss: 0.0315\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [54/1000], Validation Loss: 0.0314\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [55/1000], Validation Loss: 0.0314\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [56/1000], Validation Loss: 0.0315\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [57/1000], Validation Loss: 0.0314\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [58/1000], Validation Loss: 0.0314\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [59/1000], Validation Loss: 0.0315\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [60/1000], Validation Loss: 0.0314\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [61/1000], Validation Loss: 0.0315\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [62/1000], Validation Loss: 0.0314\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [63/1000], Validation Loss: 0.0315\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [64/1000], Validation Loss: 0.0315\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [65/1000], Validation Loss: 0.0315\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [66/1000], Validation Loss: 0.0314\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [67/1000], Validation Loss: 0.0314\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [68/1000], Validation Loss: 0.0315\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [69/1000], Validation Loss: 0.0315\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [70/1000], Validation Loss: 0.0315\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [71/1000], Validation Loss: 0.0314\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [72/1000], Validation Loss: 0.0314\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [73/1000], Validation Loss: 0.0314\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [74/1000], Validation Loss: 0.0315\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [75/1000], Validation Loss: 0.0315\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [76/1000], Validation Loss: 0.0315\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [77/1000], Validation Loss: 0.0314\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [78/1000], Validation Loss: 0.0314\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [79/1000], Validation Loss: 0.0315\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [80/1000], Validation Loss: 0.0314\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [81/1000], Validation Loss: 0.0314\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [82/1000], Validation Loss: 0.0314\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [83/1000], Validation Loss: 0.0315\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [84/1000], Validation Loss: 0.0314\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [85/1000], Validation Loss: 0.0315\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [86/1000], Validation Loss: 0.0314\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [87/1000], Validation Loss: 0.0314\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [88/1000], Validation Loss: 0.0314\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [89/1000], Validation Loss: 0.0315\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [90/1000], Validation Loss: 0.0315\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [91/1000], Validation Loss: 0.0314\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [92/1000], Validation Loss: 0.0315\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [93/1000], Validation Loss: 0.0315\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [94/1000], Validation Loss: 0.0314\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [95/1000], Validation Loss: 0.0314\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [96/1000], Validation Loss: 0.0314\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [97/1000], Validation Loss: 0.0315\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [98/1000], Validation Loss: 0.0314\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [99/1000], Validation Loss: 0.0314\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [100/1000], Validation Loss: 0.0314\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [101/1000], Validation Loss: 0.0314\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [102/1000], Validation Loss: 0.0314\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [103/1000], Validation Loss: 0.0314\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [104/1000], Validation Loss: 0.0315\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [105/1000], Validation Loss: 0.0315\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [106/1000], Validation Loss: 0.0314\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [107/1000], Validation Loss: 0.0315\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [108/1000], Validation Loss: 0.0314\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [109/1000], Validation Loss: 0.0315\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [110/1000], Validation Loss: 0.0314\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [111/1000], Validation Loss: 0.0314\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [112/1000], Validation Loss: 0.0314\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [113/1000], Validation Loss: 0.0314\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [114/1000], Validation Loss: 0.0315\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [115/1000], Validation Loss: 0.0315\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [116/1000], Validation Loss: 0.0314\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [117/1000], Validation Loss: 0.0315\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [118/1000], Validation Loss: 0.0315\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [119/1000], Validation Loss: 0.0315\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [120/1000], Validation Loss: 0.0315\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [121/1000], Validation Loss: 0.0314\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [122/1000], Validation Loss: 0.0315\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [123/1000], Validation Loss: 0.0314\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [124/1000], Validation Loss: 0.0314\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [125/1000], Validation Loss: 0.0314\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [126/1000], Validation Loss: 0.0314\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [127/1000], Validation Loss: 0.0315\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [128/1000], Validation Loss: 0.0314\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [129/1000], Validation Loss: 0.0314\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [130/1000], Validation Loss: 0.0314\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [131/1000], Validation Loss: 0.0315\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [132/1000], Validation Loss: 0.0315\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [133/1000], Validation Loss: 0.0314\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [134/1000], Validation Loss: 0.0314\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [135/1000], Validation Loss: 0.0315\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [136/1000], Validation Loss: 0.0315\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [137/1000], Validation Loss: 0.0314\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [138/1000], Validation Loss: 0.0315\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [139/1000], Validation Loss: 0.0315\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [140/1000], Validation Loss: 0.0314\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [141/1000], Validation Loss: 0.0315\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [142/1000], Validation Loss: 0.0314\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [143/1000], Validation Loss: 0.0314\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [144/1000], Validation Loss: 0.0314\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [145/1000], Validation Loss: 0.0315\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [146/1000], Validation Loss: 0.0313\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [147/1000], Validation Loss: 0.0314\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [148/1000], Validation Loss: 0.0314\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [149/1000], Validation Loss: 0.0313\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [150/1000], Validation Loss: 0.0314\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [151/1000], Validation Loss: 0.0314\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [152/1000], Validation Loss: 0.0315\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [153/1000], Validation Loss: 0.0315\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [154/1000], Validation Loss: 0.0315\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [155/1000], Validation Loss: 0.0314\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [156/1000], Validation Loss: 0.0315\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [157/1000], Validation Loss: 0.0315\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [158/1000], Validation Loss: 0.0314\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [159/1000], Validation Loss: 0.0314\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [160/1000], Validation Loss: 0.0314\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [161/1000], Validation Loss: 0.0314\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [162/1000], Validation Loss: 0.0314\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [163/1000], Validation Loss: 0.0314\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [164/1000], Validation Loss: 0.0315\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [165/1000], Validation Loss: 0.0315\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [166/1000], Validation Loss: 0.0315\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [167/1000], Validation Loss: 0.0314\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [168/1000], Validation Loss: 0.0314\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [169/1000], Validation Loss: 0.0315\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [170/1000], Validation Loss: 0.0315\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [171/1000], Validation Loss: 0.0314\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [172/1000], Validation Loss: 0.0315\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [173/1000], Validation Loss: 0.0315\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [174/1000], Validation Loss: 0.0314\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [175/1000], Validation Loss: 0.0315\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [176/1000], Validation Loss: 0.0315\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [177/1000], Validation Loss: 0.0315\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [178/1000], Validation Loss: 0.0314\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [179/1000], Validation Loss: 0.0315\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [180/1000], Validation Loss: 0.0314\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [181/1000], Validation Loss: 0.0315\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [182/1000], Validation Loss: 0.0315\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [183/1000], Validation Loss: 0.0315\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [184/1000], Validation Loss: 0.0315\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [185/1000], Validation Loss: 0.0315\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [186/1000], Validation Loss: 0.0314\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [187/1000], Validation Loss: 0.0315\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [188/1000], Validation Loss: 0.0314\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [189/1000], Validation Loss: 0.0315\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [190/1000], Validation Loss: 0.0314\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [191/1000], Validation Loss: 0.0314\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [192/1000], Validation Loss: 0.0315\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [193/1000], Validation Loss: 0.0315\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [194/1000], Validation Loss: 0.0315\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [195/1000], Validation Loss: 0.0315\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [196/1000], Validation Loss: 0.0315\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [197/1000], Validation Loss: 0.0314\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [198/1000], Validation Loss: 0.0314\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [199/1000], Validation Loss: 0.0314\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [200/1000], Validation Loss: 0.0314\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [201/1000], Validation Loss: 0.0314\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [202/1000], Validation Loss: 0.0314\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [203/1000], Validation Loss: 0.0314\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [204/1000], Validation Loss: 0.0315\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [205/1000], Validation Loss: 0.0314\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [206/1000], Validation Loss: 0.0314\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [207/1000], Validation Loss: 0.0315\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [208/1000], Validation Loss: 0.0314\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [209/1000], Validation Loss: 0.0315\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [210/1000], Validation Loss: 0.0315\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [211/1000], Validation Loss: 0.0314\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [212/1000], Validation Loss: 0.0314\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [213/1000], Validation Loss: 0.0314\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [214/1000], Validation Loss: 0.0314\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [215/1000], Validation Loss: 0.0314\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [216/1000], Validation Loss: 0.0315\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [217/1000], Validation Loss: 0.0314\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [218/1000], Validation Loss: 0.0315\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [219/1000], Validation Loss: 0.0315\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [220/1000], Validation Loss: 0.0314\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [221/1000], Validation Loss: 0.0314\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [222/1000], Validation Loss: 0.0314\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [223/1000], Validation Loss: 0.0315\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [224/1000], Validation Loss: 0.0314\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [225/1000], Validation Loss: 0.0315\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [226/1000], Validation Loss: 0.0315\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [227/1000], Validation Loss: 0.0314\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [228/1000], Validation Loss: 0.0314\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [229/1000], Validation Loss: 0.0315\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [230/1000], Validation Loss: 0.0314\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [231/1000], Validation Loss: 0.0315\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [232/1000], Validation Loss: 0.0315\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [233/1000], Validation Loss: 0.0315\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [234/1000], Validation Loss: 0.0315\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [235/1000], Validation Loss: 0.0315\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [236/1000], Validation Loss: 0.0315\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [237/1000], Validation Loss: 0.0315\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [238/1000], Validation Loss: 0.0314\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [239/1000], Validation Loss: 0.0315\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [240/1000], Validation Loss: 0.0314\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [241/1000], Validation Loss: 0.0315\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [242/1000], Validation Loss: 0.0315\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [243/1000], Validation Loss: 0.0315\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [244/1000], Validation Loss: 0.0314\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [245/1000], Validation Loss: 0.0315\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [246/1000], Validation Loss: 0.0315\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [247/1000], Validation Loss: 0.0315\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [248/1000], Validation Loss: 0.0314\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [249/1000], Validation Loss: 0.0314\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [250/1000], Validation Loss: 0.0314\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [251/1000], Validation Loss: 0.0314\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [252/1000], Validation Loss: 0.0314\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [253/1000], Validation Loss: 0.0314\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [254/1000], Validation Loss: 0.0315\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [255/1000], Validation Loss: 0.0315\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [256/1000], Validation Loss: 0.0315\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [257/1000], Validation Loss: 0.0315\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [258/1000], Validation Loss: 0.0314\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [259/1000], Validation Loss: 0.0315\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [260/1000], Validation Loss: 0.0315\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [261/1000], Validation Loss: 0.0314\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [262/1000], Validation Loss: 0.0314\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [263/1000], Validation Loss: 0.0315\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [264/1000], Validation Loss: 0.0315\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [265/1000], Validation Loss: 0.0315\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [266/1000], Validation Loss: 0.0314\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [267/1000], Validation Loss: 0.0315\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [268/1000], Validation Loss: 0.0314\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [269/1000], Validation Loss: 0.0315\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [270/1000], Validation Loss: 0.0315\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [271/1000], Validation Loss: 0.0315\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [272/1000], Validation Loss: 0.0315\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [273/1000], Validation Loss: 0.0314\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [274/1000], Validation Loss: 0.0314\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [275/1000], Validation Loss: 0.0314\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [276/1000], Validation Loss: 0.0314\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [277/1000], Validation Loss: 0.0315\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [278/1000], Validation Loss: 0.0314\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [279/1000], Validation Loss: 0.0314\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [280/1000], Validation Loss: 0.0315\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [281/1000], Validation Loss: 0.0315\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [282/1000], Validation Loss: 0.0315\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [283/1000], Validation Loss: 0.0315\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [284/1000], Validation Loss: 0.0314\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [285/1000], Validation Loss: 0.0314\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [286/1000], Validation Loss: 0.0314\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [287/1000], Validation Loss: 0.0315\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [288/1000], Validation Loss: 0.0314\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [289/1000], Validation Loss: 0.0314\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [290/1000], Validation Loss: 0.0315\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [291/1000], Validation Loss: 0.0314\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [292/1000], Validation Loss: 0.0315\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [293/1000], Validation Loss: 0.0314\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [294/1000], Validation Loss: 0.0315\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [295/1000], Validation Loss: 0.0315\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [296/1000], Validation Loss: 0.0315\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [297/1000], Validation Loss: 0.0314\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [298/1000], Validation Loss: 0.0315\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [299/1000], Validation Loss: 0.0314\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [300/1000], Validation Loss: 0.0314\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [301/1000], Validation Loss: 0.0315\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [302/1000], Validation Loss: 0.0314\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [303/1000], Validation Loss: 0.0314\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [304/1000], Validation Loss: 0.0315\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [305/1000], Validation Loss: 0.0315\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [306/1000], Validation Loss: 0.0314\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [307/1000], Validation Loss: 0.0315\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [308/1000], Validation Loss: 0.0315\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [309/1000], Validation Loss: 0.0314\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [310/1000], Validation Loss: 0.0315\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [311/1000], Validation Loss: 0.0314\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [312/1000], Validation Loss: 0.0314\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [313/1000], Validation Loss: 0.0314\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [314/1000], Validation Loss: 0.0314\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [315/1000], Validation Loss: 0.0314\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [316/1000], Validation Loss: 0.0314\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [317/1000], Validation Loss: 0.0315\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [318/1000], Validation Loss: 0.0315\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [319/1000], Validation Loss: 0.0314\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [320/1000], Validation Loss: 0.0315\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [321/1000], Validation Loss: 0.0314\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [322/1000], Validation Loss: 0.0314\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [323/1000], Validation Loss: 0.0315\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [324/1000], Validation Loss: 0.0314\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [325/1000], Validation Loss: 0.0314\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [326/1000], Validation Loss: 0.0315\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [327/1000], Validation Loss: 0.0315\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [328/1000], Validation Loss: 0.0315\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [329/1000], Validation Loss: 0.0315\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [330/1000], Validation Loss: 0.0315\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [331/1000], Validation Loss: 0.0314\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [332/1000], Validation Loss: 0.0314\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [333/1000], Validation Loss: 0.0314\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [334/1000], Validation Loss: 0.0314\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [335/1000], Validation Loss: 0.0314\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [336/1000], Validation Loss: 0.0314\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [337/1000], Validation Loss: 0.0314\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [338/1000], Validation Loss: 0.0315\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [339/1000], Validation Loss: 0.0315\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [340/1000], Validation Loss: 0.0315\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [341/1000], Validation Loss: 0.0315\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [342/1000], Validation Loss: 0.0315\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [343/1000], Validation Loss: 0.0314\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [344/1000], Validation Loss: 0.0315\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [345/1000], Validation Loss: 0.0315\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [346/1000], Validation Loss: 0.0315\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [347/1000], Validation Loss: 0.0315\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [348/1000], Validation Loss: 0.0315\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [349/1000], Validation Loss: 0.0314\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [350/1000], Validation Loss: 0.0315\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [351/1000], Validation Loss: 0.0315\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [352/1000], Validation Loss: 0.0314\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [353/1000], Validation Loss: 0.0315\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [354/1000], Validation Loss: 0.0315\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [355/1000], Validation Loss: 0.0315\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [356/1000], Validation Loss: 0.0315\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [357/1000], Validation Loss: 0.0314\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [358/1000], Validation Loss: 0.0315\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [359/1000], Validation Loss: 0.0314\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [360/1000], Validation Loss: 0.0314\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [361/1000], Validation Loss: 0.0314\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [362/1000], Validation Loss: 0.0314\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [363/1000], Validation Loss: 0.0314\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [364/1000], Validation Loss: 0.0314\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [365/1000], Validation Loss: 0.0314\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [366/1000], Validation Loss: 0.0315\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [367/1000], Validation Loss: 0.0314\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [368/1000], Validation Loss: 0.0314\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [369/1000], Validation Loss: 0.0315\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [370/1000], Validation Loss: 0.0315\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [371/1000], Validation Loss: 0.0315\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [372/1000], Validation Loss: 0.0315\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [373/1000], Validation Loss: 0.0314\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [374/1000], Validation Loss: 0.0314\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [375/1000], Validation Loss: 0.0314\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [376/1000], Validation Loss: 0.0315\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [377/1000], Validation Loss: 0.0315\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [378/1000], Validation Loss: 0.0314\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [379/1000], Validation Loss: 0.0314\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [380/1000], Validation Loss: 0.0315\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [381/1000], Validation Loss: 0.0314\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [382/1000], Validation Loss: 0.0314\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [383/1000], Validation Loss: 0.0315\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [384/1000], Validation Loss: 0.0314\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [385/1000], Validation Loss: 0.0314\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [386/1000], Validation Loss: 0.0314\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [387/1000], Validation Loss: 0.0314\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [388/1000], Validation Loss: 0.0315\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [389/1000], Validation Loss: 0.0314\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [390/1000], Validation Loss: 0.0315\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [391/1000], Validation Loss: 0.0315\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [392/1000], Validation Loss: 0.0314\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [393/1000], Validation Loss: 0.0315\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [394/1000], Validation Loss: 0.0314\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [395/1000], Validation Loss: 0.0314\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [396/1000], Validation Loss: 0.0315\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [397/1000], Validation Loss: 0.0314\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [398/1000], Validation Loss: 0.0314\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [399/1000], Validation Loss: 0.0315\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [400/1000], Validation Loss: 0.0315\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [401/1000], Validation Loss: 0.0315\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [402/1000], Validation Loss: 0.0314\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [403/1000], Validation Loss: 0.0315\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [404/1000], Validation Loss: 0.0315\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [405/1000], Validation Loss: 0.0315\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [406/1000], Validation Loss: 0.0315\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [407/1000], Validation Loss: 0.0315\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [408/1000], Validation Loss: 0.0314\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [409/1000], Validation Loss: 0.0315\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [410/1000], Validation Loss: 0.0315\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [411/1000], Validation Loss: 0.0314\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [412/1000], Validation Loss: 0.0315\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [413/1000], Validation Loss: 0.0314\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [414/1000], Validation Loss: 0.0315\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [415/1000], Validation Loss: 0.0315\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [416/1000], Validation Loss: 0.0315\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [417/1000], Validation Loss: 0.0315\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [418/1000], Validation Loss: 0.0315\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [419/1000], Validation Loss: 0.0315\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [420/1000], Validation Loss: 0.0314\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [421/1000], Validation Loss: 0.0314\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [422/1000], Validation Loss: 0.0314\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [423/1000], Validation Loss: 0.0315\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [424/1000], Validation Loss: 0.0315\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [425/1000], Validation Loss: 0.0314\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [426/1000], Validation Loss: 0.0314\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [427/1000], Validation Loss: 0.0314\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [428/1000], Validation Loss: 0.0314\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [429/1000], Validation Loss: 0.0314\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [430/1000], Validation Loss: 0.0315\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [431/1000], Validation Loss: 0.0315\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [432/1000], Validation Loss: 0.0314\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [433/1000], Validation Loss: 0.0315\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [434/1000], Validation Loss: 0.0314\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [435/1000], Validation Loss: 0.0315\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [436/1000], Validation Loss: 0.0315\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [437/1000], Validation Loss: 0.0314\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [438/1000], Validation Loss: 0.0315\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [439/1000], Validation Loss: 0.0315\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [440/1000], Validation Loss: 0.0315\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [441/1000], Validation Loss: 0.0314\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [442/1000], Validation Loss: 0.0314\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [443/1000], Validation Loss: 0.0315\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [444/1000], Validation Loss: 0.0314\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [445/1000], Validation Loss: 0.0315\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [446/1000], Validation Loss: 0.0314\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [447/1000], Validation Loss: 0.0314\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [448/1000], Validation Loss: 0.0315\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [449/1000], Validation Loss: 0.0315\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [450/1000], Validation Loss: 0.0314\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [451/1000], Validation Loss: 0.0314\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [452/1000], Validation Loss: 0.0315\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [453/1000], Validation Loss: 0.0314\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [454/1000], Validation Loss: 0.0314\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [455/1000], Validation Loss: 0.0315\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [456/1000], Validation Loss: 0.0315\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [457/1000], Validation Loss: 0.0315\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [458/1000], Validation Loss: 0.0314\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [459/1000], Validation Loss: 0.0314\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [460/1000], Validation Loss: 0.0314\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [461/1000], Validation Loss: 0.0315\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [462/1000], Validation Loss: 0.0315\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [463/1000], Validation Loss: 0.0314\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [464/1000], Validation Loss: 0.0315\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [465/1000], Validation Loss: 0.0315\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [466/1000], Validation Loss: 0.0315\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [467/1000], Validation Loss: 0.0314\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [468/1000], Validation Loss: 0.0314\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [469/1000], Validation Loss: 0.0315\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [470/1000], Validation Loss: 0.0315\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [471/1000], Validation Loss: 0.0314\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [472/1000], Validation Loss: 0.0314\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [473/1000], Validation Loss: 0.0314\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [474/1000], Validation Loss: 0.0315\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [475/1000], Validation Loss: 0.0315\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [476/1000], Validation Loss: 0.0315\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [477/1000], Validation Loss: 0.0314\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [478/1000], Validation Loss: 0.0314\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [479/1000], Validation Loss: 0.0315\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [480/1000], Validation Loss: 0.0314\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [481/1000], Validation Loss: 0.0315\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [482/1000], Validation Loss: 0.0314\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [483/1000], Validation Loss: 0.0314\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [484/1000], Validation Loss: 0.0314\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [485/1000], Validation Loss: 0.0314\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [486/1000], Validation Loss: 0.0315\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [487/1000], Validation Loss: 0.0314\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [488/1000], Validation Loss: 0.0315\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [489/1000], Validation Loss: 0.0315\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [490/1000], Validation Loss: 0.0315\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [491/1000], Validation Loss: 0.0315\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [492/1000], Validation Loss: 0.0315\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [493/1000], Validation Loss: 0.0315\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [494/1000], Validation Loss: 0.0315\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [495/1000], Validation Loss: 0.0315\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [496/1000], Validation Loss: 0.0315\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [497/1000], Validation Loss: 0.0315\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [498/1000], Validation Loss: 0.0314\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [499/1000], Validation Loss: 0.0314\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [500/1000], Validation Loss: 0.0314\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [501/1000], Validation Loss: 0.0315\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [502/1000], Validation Loss: 0.0314\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [503/1000], Validation Loss: 0.0315\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [504/1000], Validation Loss: 0.0314\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [505/1000], Validation Loss: 0.0314\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [506/1000], Validation Loss: 0.0315\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [507/1000], Validation Loss: 0.0314\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [508/1000], Validation Loss: 0.0314\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [509/1000], Validation Loss: 0.0314\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [510/1000], Validation Loss: 0.0314\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [511/1000], Validation Loss: 0.0315\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [512/1000], Validation Loss: 0.0315\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [513/1000], Validation Loss: 0.0315\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [514/1000], Validation Loss: 0.0315\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [515/1000], Validation Loss: 0.0315\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [516/1000], Validation Loss: 0.0315\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [517/1000], Validation Loss: 0.0314\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [518/1000], Validation Loss: 0.0314\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [519/1000], Validation Loss: 0.0314\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [520/1000], Validation Loss: 0.0315\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [521/1000], Validation Loss: 0.0314\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [522/1000], Validation Loss: 0.0314\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [523/1000], Validation Loss: 0.0314\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [524/1000], Validation Loss: 0.0315\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [525/1000], Validation Loss: 0.0315\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [526/1000], Validation Loss: 0.0315\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [527/1000], Validation Loss: 0.0315\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [528/1000], Validation Loss: 0.0315\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [529/1000], Validation Loss: 0.0314\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [530/1000], Validation Loss: 0.0315\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [531/1000], Validation Loss: 0.0315\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [532/1000], Validation Loss: 0.0315\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [533/1000], Validation Loss: 0.0314\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [534/1000], Validation Loss: 0.0315\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [535/1000], Validation Loss: 0.0315\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [536/1000], Validation Loss: 0.0315\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [537/1000], Validation Loss: 0.0314\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [538/1000], Validation Loss: 0.0314\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [539/1000], Validation Loss: 0.0315\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [540/1000], Validation Loss: 0.0314\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [541/1000], Validation Loss: 0.0315\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [542/1000], Validation Loss: 0.0315\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [543/1000], Validation Loss: 0.0315\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [544/1000], Validation Loss: 0.0314\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [545/1000], Validation Loss: 0.0315\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [546/1000], Validation Loss: 0.0315\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [547/1000], Validation Loss: 0.0314\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [548/1000], Validation Loss: 0.0315\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [549/1000], Validation Loss: 0.0314\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [550/1000], Validation Loss: 0.0314\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [551/1000], Validation Loss: 0.0314\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [552/1000], Validation Loss: 0.0314\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [553/1000], Validation Loss: 0.0315\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [554/1000], Validation Loss: 0.0314\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [555/1000], Validation Loss: 0.0314\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [556/1000], Validation Loss: 0.0314\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [557/1000], Validation Loss: 0.0314\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [558/1000], Validation Loss: 0.0314\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [559/1000], Validation Loss: 0.0314\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [560/1000], Validation Loss: 0.0315\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [561/1000], Validation Loss: 0.0314\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [562/1000], Validation Loss: 0.0314\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [563/1000], Validation Loss: 0.0315\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [564/1000], Validation Loss: 0.0315\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [565/1000], Validation Loss: 0.0315\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [566/1000], Validation Loss: 0.0315\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [567/1000], Validation Loss: 0.0314\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [568/1000], Validation Loss: 0.0314\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [569/1000], Validation Loss: 0.0315\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [570/1000], Validation Loss: 0.0315\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [571/1000], Validation Loss: 0.0314\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [572/1000], Validation Loss: 0.0314\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [573/1000], Validation Loss: 0.0314\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [574/1000], Validation Loss: 0.0315\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [575/1000], Validation Loss: 0.0315\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [576/1000], Validation Loss: 0.0314\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [577/1000], Validation Loss: 0.0314\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [578/1000], Validation Loss: 0.0314\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [579/1000], Validation Loss: 0.0315\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [580/1000], Validation Loss: 0.0315\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [581/1000], Validation Loss: 0.0314\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [582/1000], Validation Loss: 0.0315\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [583/1000], Validation Loss: 0.0315\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [584/1000], Validation Loss: 0.0314\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [585/1000], Validation Loss: 0.0315\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [586/1000], Validation Loss: 0.0314\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [587/1000], Validation Loss: 0.0315\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [588/1000], Validation Loss: 0.0315\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [589/1000], Validation Loss: 0.0314\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [590/1000], Validation Loss: 0.0315\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [591/1000], Validation Loss: 0.0315\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [592/1000], Validation Loss: 0.0314\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [593/1000], Validation Loss: 0.0314\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [594/1000], Validation Loss: 0.0315\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [595/1000], Validation Loss: 0.0315\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [596/1000], Validation Loss: 0.0315\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [597/1000], Validation Loss: 0.0314\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [598/1000], Validation Loss: 0.0315\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [599/1000], Validation Loss: 0.0315\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [600/1000], Validation Loss: 0.0315\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [601/1000], Validation Loss: 0.0315\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [602/1000], Validation Loss: 0.0314\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [603/1000], Validation Loss: 0.0315\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [604/1000], Validation Loss: 0.0314\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [605/1000], Validation Loss: 0.0315\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [606/1000], Validation Loss: 0.0314\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [607/1000], Validation Loss: 0.0314\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [608/1000], Validation Loss: 0.0314\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [609/1000], Validation Loss: 0.0315\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [610/1000], Validation Loss: 0.0314\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [611/1000], Validation Loss: 0.0315\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [612/1000], Validation Loss: 0.0315\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [613/1000], Validation Loss: 0.0314\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [614/1000], Validation Loss: 0.0314\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [615/1000], Validation Loss: 0.0315\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [616/1000], Validation Loss: 0.0314\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [617/1000], Validation Loss: 0.0314\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [618/1000], Validation Loss: 0.0315\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [619/1000], Validation Loss: 0.0314\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [620/1000], Validation Loss: 0.0314\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [621/1000], Validation Loss: 0.0315\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [622/1000], Validation Loss: 0.0315\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [623/1000], Validation Loss: 0.0314\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [624/1000], Validation Loss: 0.0315\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [625/1000], Validation Loss: 0.0315\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [626/1000], Validation Loss: 0.0314\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [627/1000], Validation Loss: 0.0314\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [628/1000], Validation Loss: 0.0315\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [629/1000], Validation Loss: 0.0314\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [630/1000], Validation Loss: 0.0314\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [631/1000], Validation Loss: 0.0315\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [632/1000], Validation Loss: 0.0315\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [633/1000], Validation Loss: 0.0314\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [634/1000], Validation Loss: 0.0314\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [635/1000], Validation Loss: 0.0314\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [636/1000], Validation Loss: 0.0314\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [637/1000], Validation Loss: 0.0314\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [638/1000], Validation Loss: 0.0314\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [639/1000], Validation Loss: 0.0314\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [640/1000], Validation Loss: 0.0314\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [641/1000], Validation Loss: 0.0315\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [642/1000], Validation Loss: 0.0315\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [643/1000], Validation Loss: 0.0314\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [644/1000], Validation Loss: 0.0314\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [645/1000], Validation Loss: 0.0315\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [646/1000], Validation Loss: 0.0314\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [647/1000], Validation Loss: 0.0314\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [648/1000], Validation Loss: 0.0314\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [649/1000], Validation Loss: 0.0314\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [650/1000], Validation Loss: 0.0314\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [651/1000], Validation Loss: 0.0314\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [652/1000], Validation Loss: 0.0315\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [653/1000], Validation Loss: 0.0314\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [654/1000], Validation Loss: 0.0314\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [655/1000], Validation Loss: 0.0314\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [656/1000], Validation Loss: 0.0315\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [657/1000], Validation Loss: 0.0315\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [658/1000], Validation Loss: 0.0314\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [659/1000], Validation Loss: 0.0314\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [660/1000], Validation Loss: 0.0314\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [661/1000], Validation Loss: 0.0315\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [662/1000], Validation Loss: 0.0314\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [663/1000], Validation Loss: 0.0315\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [664/1000], Validation Loss: 0.0314\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [665/1000], Validation Loss: 0.0315\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [666/1000], Validation Loss: 0.0315\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [667/1000], Validation Loss: 0.0314\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [668/1000], Validation Loss: 0.0315\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [669/1000], Validation Loss: 0.0315\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [670/1000], Validation Loss: 0.0315\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [671/1000], Validation Loss: 0.0314\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [672/1000], Validation Loss: 0.0314\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [673/1000], Validation Loss: 0.0315\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [674/1000], Validation Loss: 0.0314\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [675/1000], Validation Loss: 0.0315\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [676/1000], Validation Loss: 0.0314\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [677/1000], Validation Loss: 0.0315\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [678/1000], Validation Loss: 0.0314\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [679/1000], Validation Loss: 0.0315\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [680/1000], Validation Loss: 0.0314\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [681/1000], Validation Loss: 0.0314\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [682/1000], Validation Loss: 0.0314\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [683/1000], Validation Loss: 0.0314\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [684/1000], Validation Loss: 0.0314\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [685/1000], Validation Loss: 0.0314\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [686/1000], Validation Loss: 0.0314\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [687/1000], Validation Loss: 0.0314\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [688/1000], Validation Loss: 0.0315\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [689/1000], Validation Loss: 0.0315\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [690/1000], Validation Loss: 0.0315\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [691/1000], Validation Loss: 0.0315\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [692/1000], Validation Loss: 0.0314\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [693/1000], Validation Loss: 0.0314\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [694/1000], Validation Loss: 0.0314\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [695/1000], Validation Loss: 0.0315\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [696/1000], Validation Loss: 0.0315\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [697/1000], Validation Loss: 0.0315\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [698/1000], Validation Loss: 0.0314\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [699/1000], Validation Loss: 0.0314\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [700/1000], Validation Loss: 0.0314\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [701/1000], Validation Loss: 0.0314\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [702/1000], Validation Loss: 0.0315\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [703/1000], Validation Loss: 0.0314\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [704/1000], Validation Loss: 0.0314\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [705/1000], Validation Loss: 0.0315\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [706/1000], Validation Loss: 0.0315\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [707/1000], Validation Loss: 0.0314\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [708/1000], Validation Loss: 0.0314\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [709/1000], Validation Loss: 0.0315\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [710/1000], Validation Loss: 0.0314\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [711/1000], Validation Loss: 0.0315\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [712/1000], Validation Loss: 0.0314\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [713/1000], Validation Loss: 0.0314\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [714/1000], Validation Loss: 0.0314\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [715/1000], Validation Loss: 0.0315\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [716/1000], Validation Loss: 0.0314\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [717/1000], Validation Loss: 0.0314\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [718/1000], Validation Loss: 0.0315\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [719/1000], Validation Loss: 0.0315\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [720/1000], Validation Loss: 0.0315\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [721/1000], Validation Loss: 0.0315\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [722/1000], Validation Loss: 0.0315\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [723/1000], Validation Loss: 0.0314\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [724/1000], Validation Loss: 0.0315\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [725/1000], Validation Loss: 0.0315\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [726/1000], Validation Loss: 0.0314\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [727/1000], Validation Loss: 0.0315\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [728/1000], Validation Loss: 0.0315\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [729/1000], Validation Loss: 0.0314\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [730/1000], Validation Loss: 0.0314\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [731/1000], Validation Loss: 0.0314\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [732/1000], Validation Loss: 0.0315\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [733/1000], Validation Loss: 0.0315\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [734/1000], Validation Loss: 0.0314\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [735/1000], Validation Loss: 0.0315\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [736/1000], Validation Loss: 0.0314\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [737/1000], Validation Loss: 0.0314\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [738/1000], Validation Loss: 0.0315\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [739/1000], Validation Loss: 0.0314\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [740/1000], Validation Loss: 0.0314\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [741/1000], Validation Loss: 0.0315\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [742/1000], Validation Loss: 0.0315\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [743/1000], Validation Loss: 0.0314\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [744/1000], Validation Loss: 0.0315\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [745/1000], Validation Loss: 0.0314\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [746/1000], Validation Loss: 0.0314\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [747/1000], Validation Loss: 0.0315\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [748/1000], Validation Loss: 0.0314\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [749/1000], Validation Loss: 0.0315\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [750/1000], Validation Loss: 0.0314\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [751/1000], Validation Loss: 0.0315\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [752/1000], Validation Loss: 0.0315\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [753/1000], Validation Loss: 0.0315\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [754/1000], Validation Loss: 0.0314\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [755/1000], Validation Loss: 0.0315\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [756/1000], Validation Loss: 0.0315\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [757/1000], Validation Loss: 0.0314\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [758/1000], Validation Loss: 0.0314\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [759/1000], Validation Loss: 0.0314\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [760/1000], Validation Loss: 0.0315\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [761/1000], Validation Loss: 0.0315\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [762/1000], Validation Loss: 0.0315\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [763/1000], Validation Loss: 0.0315\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [764/1000], Validation Loss: 0.0315\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [765/1000], Validation Loss: 0.0315\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [766/1000], Validation Loss: 0.0314\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [767/1000], Validation Loss: 0.0315\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [768/1000], Validation Loss: 0.0315\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [769/1000], Validation Loss: 0.0314\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [770/1000], Validation Loss: 0.0315\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [771/1000], Validation Loss: 0.0315\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [772/1000], Validation Loss: 0.0315\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [773/1000], Validation Loss: 0.0314\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [774/1000], Validation Loss: 0.0314\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [775/1000], Validation Loss: 0.0315\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [776/1000], Validation Loss: 0.0314\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [777/1000], Validation Loss: 0.0314\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [778/1000], Validation Loss: 0.0314\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [779/1000], Validation Loss: 0.0315\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [780/1000], Validation Loss: 0.0314\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [781/1000], Validation Loss: 0.0314\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [782/1000], Validation Loss: 0.0314\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [783/1000], Validation Loss: 0.0315\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [784/1000], Validation Loss: 0.0315\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [785/1000], Validation Loss: 0.0315\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [786/1000], Validation Loss: 0.0315\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [787/1000], Validation Loss: 0.0315\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [788/1000], Validation Loss: 0.0315\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [789/1000], Validation Loss: 0.0315\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [790/1000], Validation Loss: 0.0314\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [791/1000], Validation Loss: 0.0315\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [792/1000], Validation Loss: 0.0315\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [793/1000], Validation Loss: 0.0315\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [794/1000], Validation Loss: 0.0314\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [795/1000], Validation Loss: 0.0314\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [796/1000], Validation Loss: 0.0314\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [797/1000], Validation Loss: 0.0314\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [798/1000], Validation Loss: 0.0314\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [799/1000], Validation Loss: 0.0314\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [800/1000], Validation Loss: 0.0314\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [801/1000], Validation Loss: 0.0314\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [802/1000], Validation Loss: 0.0314\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [803/1000], Validation Loss: 0.0314\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [804/1000], Validation Loss: 0.0315\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [805/1000], Validation Loss: 0.0315\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [806/1000], Validation Loss: 0.0315\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [807/1000], Validation Loss: 0.0315\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [808/1000], Validation Loss: 0.0315\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [809/1000], Validation Loss: 0.0315\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [810/1000], Validation Loss: 0.0314\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [811/1000], Validation Loss: 0.0314\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [812/1000], Validation Loss: 0.0314\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [813/1000], Validation Loss: 0.0314\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [814/1000], Validation Loss: 0.0314\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [815/1000], Validation Loss: 0.0314\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [816/1000], Validation Loss: 0.0314\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [817/1000], Validation Loss: 0.0315\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [818/1000], Validation Loss: 0.0315\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [819/1000], Validation Loss: 0.0315\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [820/1000], Validation Loss: 0.0314\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [821/1000], Validation Loss: 0.0314\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [822/1000], Validation Loss: 0.0314\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [823/1000], Validation Loss: 0.0314\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [824/1000], Validation Loss: 0.0315\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [825/1000], Validation Loss: 0.0314\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [826/1000], Validation Loss: 0.0315\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [827/1000], Validation Loss: 0.0315\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [828/1000], Validation Loss: 0.0314\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [829/1000], Validation Loss: 0.0315\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [830/1000], Validation Loss: 0.0314\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [831/1000], Validation Loss: 0.0315\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [832/1000], Validation Loss: 0.0315\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [833/1000], Validation Loss: 0.0314\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [834/1000], Validation Loss: 0.0314\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [835/1000], Validation Loss: 0.0315\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [836/1000], Validation Loss: 0.0314\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [837/1000], Validation Loss: 0.0314\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [838/1000], Validation Loss: 0.0314\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [839/1000], Validation Loss: 0.0314\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [840/1000], Validation Loss: 0.0315\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [841/1000], Validation Loss: 0.0314\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [842/1000], Validation Loss: 0.0315\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [843/1000], Validation Loss: 0.0315\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [844/1000], Validation Loss: 0.0314\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [845/1000], Validation Loss: 0.0314\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [846/1000], Validation Loss: 0.0314\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [847/1000], Validation Loss: 0.0314\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [848/1000], Validation Loss: 0.0314\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [849/1000], Validation Loss: 0.0314\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [850/1000], Validation Loss: 0.0314\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [851/1000], Validation Loss: 0.0315\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [852/1000], Validation Loss: 0.0315\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [853/1000], Validation Loss: 0.0314\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [854/1000], Validation Loss: 0.0314\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [855/1000], Validation Loss: 0.0314\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [856/1000], Validation Loss: 0.0314\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [857/1000], Validation Loss: 0.0315\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [858/1000], Validation Loss: 0.0315\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [859/1000], Validation Loss: 0.0314\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [860/1000], Validation Loss: 0.0314\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [861/1000], Validation Loss: 0.0315\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [862/1000], Validation Loss: 0.0314\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [863/1000], Validation Loss: 0.0314\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [864/1000], Validation Loss: 0.0314\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [865/1000], Validation Loss: 0.0315\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [866/1000], Validation Loss: 0.0314\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [867/1000], Validation Loss: 0.0314\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [868/1000], Validation Loss: 0.0315\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [869/1000], Validation Loss: 0.0315\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [870/1000], Validation Loss: 0.0314\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [871/1000], Validation Loss: 0.0315\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [872/1000], Validation Loss: 0.0315\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [873/1000], Validation Loss: 0.0314\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [874/1000], Validation Loss: 0.0315\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [875/1000], Validation Loss: 0.0315\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0321\n",
            "Epoch [876/1000], Validation Loss: 0.0315\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [877/1000], Validation Loss: 0.0314\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [878/1000], Validation Loss: 0.0315\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [879/1000], Validation Loss: 0.0315\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [880/1000], Validation Loss: 0.0315\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [881/1000], Validation Loss: 0.0314\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [882/1000], Validation Loss: 0.0315\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [883/1000], Validation Loss: 0.0314\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [884/1000], Validation Loss: 0.0315\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [885/1000], Validation Loss: 0.0314\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [886/1000], Validation Loss: 0.0314\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [887/1000], Validation Loss: 0.0314\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [888/1000], Validation Loss: 0.0315\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [889/1000], Validation Loss: 0.0315\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [890/1000], Validation Loss: 0.0315\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [891/1000], Validation Loss: 0.0315\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [892/1000], Validation Loss: 0.0315\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [893/1000], Validation Loss: 0.0314\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [894/1000], Validation Loss: 0.0314\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [895/1000], Validation Loss: 0.0315\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [896/1000], Validation Loss: 0.0315\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [897/1000], Validation Loss: 0.0314\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [898/1000], Validation Loss: 0.0315\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [899/1000], Validation Loss: 0.0315\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [900/1000], Validation Loss: 0.0314\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [901/1000], Validation Loss: 0.0314\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [902/1000], Validation Loss: 0.0314\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [903/1000], Validation Loss: 0.0315\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [904/1000], Validation Loss: 0.0314\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [905/1000], Validation Loss: 0.0314\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [906/1000], Validation Loss: 0.0315\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [907/1000], Validation Loss: 0.0314\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [908/1000], Validation Loss: 0.0314\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [909/1000], Validation Loss: 0.0315\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [910/1000], Validation Loss: 0.0314\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [911/1000], Validation Loss: 0.0314\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [912/1000], Validation Loss: 0.0314\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [913/1000], Validation Loss: 0.0315\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [914/1000], Validation Loss: 0.0314\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [915/1000], Validation Loss: 0.0314\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [916/1000], Validation Loss: 0.0315\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [917/1000], Validation Loss: 0.0315\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [918/1000], Validation Loss: 0.0315\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [919/1000], Validation Loss: 0.0314\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [920/1000], Validation Loss: 0.0314\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [921/1000], Validation Loss: 0.0315\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [922/1000], Validation Loss: 0.0314\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [923/1000], Validation Loss: 0.0314\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [924/1000], Validation Loss: 0.0315\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [925/1000], Validation Loss: 0.0315\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [926/1000], Validation Loss: 0.0314\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [927/1000], Validation Loss: 0.0314\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [928/1000], Validation Loss: 0.0314\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [929/1000], Validation Loss: 0.0314\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [930/1000], Validation Loss: 0.0314\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [931/1000], Validation Loss: 0.0314\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [932/1000], Validation Loss: 0.0315\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [933/1000], Validation Loss: 0.0315\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [934/1000], Validation Loss: 0.0314\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [935/1000], Validation Loss: 0.0314\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [936/1000], Validation Loss: 0.0314\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [937/1000], Validation Loss: 0.0314\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [938/1000], Validation Loss: 0.0314\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [939/1000], Validation Loss: 0.0314\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [940/1000], Validation Loss: 0.0314\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [941/1000], Validation Loss: 0.0315\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [942/1000], Validation Loss: 0.0314\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [943/1000], Validation Loss: 0.0315\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [944/1000], Validation Loss: 0.0314\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [945/1000], Validation Loss: 0.0314\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [946/1000], Validation Loss: 0.0314\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [947/1000], Validation Loss: 0.0314\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [948/1000], Validation Loss: 0.0315\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [949/1000], Validation Loss: 0.0314\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [950/1000], Validation Loss: 0.0315\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [951/1000], Validation Loss: 0.0314\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [952/1000], Validation Loss: 0.0315\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [953/1000], Validation Loss: 0.0315\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [954/1000], Validation Loss: 0.0315\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [955/1000], Validation Loss: 0.0314\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [956/1000], Validation Loss: 0.0315\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [957/1000], Validation Loss: 0.0314\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [958/1000], Validation Loss: 0.0315\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [959/1000], Validation Loss: 0.0315\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [960/1000], Validation Loss: 0.0314\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [961/1000], Validation Loss: 0.0315\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [962/1000], Validation Loss: 0.0315\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [963/1000], Validation Loss: 0.0315\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [964/1000], Validation Loss: 0.0315\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [965/1000], Validation Loss: 0.0315\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [966/1000], Validation Loss: 0.0315\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [967/1000], Validation Loss: 0.0315\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [968/1000], Validation Loss: 0.0314\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [969/1000], Validation Loss: 0.0314\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [970/1000], Validation Loss: 0.0315\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [971/1000], Validation Loss: 0.0315\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [972/1000], Validation Loss: 0.0314\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [973/1000], Validation Loss: 0.0315\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [974/1000], Validation Loss: 0.0314\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [975/1000], Validation Loss: 0.0315\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [976/1000], Validation Loss: 0.0315\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [977/1000], Validation Loss: 0.0314\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [978/1000], Validation Loss: 0.0314\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [979/1000], Validation Loss: 0.0314\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [980/1000], Validation Loss: 0.0315\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [981/1000], Validation Loss: 0.0315\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [982/1000], Validation Loss: 0.0314\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [983/1000], Validation Loss: 0.0314\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [984/1000], Validation Loss: 0.0315\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [985/1000], Validation Loss: 0.0315\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [986/1000], Validation Loss: 0.0314\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [987/1000], Validation Loss: 0.0314\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [988/1000], Validation Loss: 0.0314\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [989/1000], Validation Loss: 0.0316\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [990/1000], Validation Loss: 0.0314\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [991/1000], Validation Loss: 0.0314\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [992/1000], Validation Loss: 0.0314\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [993/1000], Validation Loss: 0.0314\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [994/1000], Validation Loss: 0.0314\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [995/1000], Validation Loss: 0.0314\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [996/1000], Validation Loss: 0.0315\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [997/1000], Validation Loss: 0.0314\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [998/1000], Validation Loss: 0.0314\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [999/1000], Validation Loss: 0.0314\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [1000/1000], Validation Loss: 0.0315\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAGwCAYAAACJjDBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACh90lEQVR4nO2deXwN1/vHP/fe7HsksiBECCFiJ2JXqURVaRVVraVapbRaXVS1KD+ltGhLqbaWLpZqVfu177XFLvYoitiSCCISst07vz+u3Nz9zsyduTP35nm/XiGZOXPOc+bMnPPMc57zHAXDMAwIgiAIgiAITiilFoAgCIIgCMIZISWKIAiCIAiCB6REEQRBEARB8ICUKIIgCIIgCB6QEkUQBEEQBMEDUqIIgiAIgiB4QEoUQRAEQRAED9ykFsCV0Wg0uHnzJvz9/aFQKKQWhyAIgiAIFjAMgwcPHqBatWpQKi3bm0iJEpGbN28iKipKajEIgiAIguDBtWvXUKNGDYvnSYkSEX9/fwDaRggICJBYGoIgCIIg2JCfn4+oqCjdOG4JUqJEpHwKLyAggJQogiAIgnAybLnikGM5QRAEQRAED0iJIgiCIAiC4AEpUQRBEARBEDwgnyiCIAhCtqjVapSWlkotBuFiuLu7Q6VS2Z0PKVEEQRCE7GAYBllZWcjLy5NaFMJFCQoKQkREhF1xHEmJIgiCIGRHuQIVFhYGHx8fClhMCAbDMHj48CFycnIAAJGRkbzzIiWKIAiCkBVqtVqnQIWEhEgtDuGCeHt7AwBycnIQFhbGe2qPHMsJgiAIWVHuA+Xj4yOxJIQrU/582eNzR0oUQRAEIUtoCo8QEyGeL1KiCIIgCIIgeEBKFEEQBEEQBA9IiSIIgiAIGRMdHY25c+dKLQZhBlKiCIIgCEIAFAqF1Z/Jkyfzyvfw4cMYPnw45+sYhoGGYQAAnTt3xttvv82rfMIyFOKAIAiCIATg1q1but9XrVqFiRMn4vz587pjfn5+ut8ZhoFarYabm+1huGrVqpxlYRgG57MeQM0waBAZwPl6gh1kiSIIgiBkD8MweFhS5vAf5rElhw0RERG6n8DAQCgUCt3fGRkZ8Pf3x8aNG9GiRQt4enpi7969uHTpEnr16oXw8HD4+fmhVatW2LZtm0G+xtN5CoUCP/zwA5599ln4+PggNjYWf//9t4k8JWoN1BoGJWUam7L/8ccfiI+Ph6enJ6Kjo/Hll18anP/2228RGxsLLy8vhIeH4/nnn9ed+/3335GQkABvb2+EhIQgOTkZhYWFrO+bM0OWKIIgCEL2PCpVo+HEzQ4v9+yUFPh4CDdUfvjhh/jiiy8QExOD4OBgXLt2DU899RSmTZsGT09P/PTTT+jZsyfOnz+PmjVrWszn008/xcyZMzFr1ix88803GDhwIK5evYoqVapwluno0aPo168fJk+ejP79+2P//v144403EBISgiFDhuDIkSN466238PPPP6Nt27a4e/cu9uzZA0BrfRswYABmzpyJZ599Fg8ePMCePXs4KZ/ODClRBEEQBOEgpkyZgieffFL3d5UqVdCkSRPd31OnTsWff/6Jv//+G6NHj7aYz5AhQzBgwAAAwGeffYavv/4ahw4dQmpqKmeZZs+eja5du+KTTz4BANSrVw9nz57FrFmzMGTIEGRmZsLX1xdPP/00/P39UatWLTRr1gyAVokqKyvDc889h1q1agEAEhISOMvgrJASRRAEQcgeb3cVzk5JkaRcIWnZsqXB3wUFBZg8eTLWr1+vU0gePXqEzMxMq/k0btxY97uvry8CAgJ0e8Fx5dy5c+jVq5fBsXbt2mHu3LlQq9V48sknUatWLcTExCA1NRWpqam6qcQmTZqga9euSEhIQEpKCrp164bnn38ewcHBvGRxNsgniiAIgpA9CoUCPh5uDv8ROmq6r6+vwd/vvfce/vzzT3z22WfYs2cP0tPTkZCQgJKSEqv5uLu7m9wfjca27xMf/P39cezYMaxYsQKRkZGYOHEimjRpgry8PKhUKmzduhUbN25Ew4YN8c0336B+/fq4fPmyKLLIDVKiCIIgCEIi9u3bhyFDhuDZZ59FQkICIiIicOXKFYfK0KBBA+zbt89Ernr16uk25nVzc0NycjJmzpyJkydP4sqVK9ixYwcArQLXrl07fPrppzh+/Dg8PDzw559/OrQOUkHTeQRBEAQhEbGxsVizZg169uwJhUKBTz75RDSL0u3bt5Genm5wLDIyEu+++y5atWqFqVOnon///khLS8O8efPw7bffAgDWrVuH//77Dx07dkRwcDA2bNgAjUaD+vXr4+DBg9i+fTu6deuGsLAwHDx4ELdv30aDBg1EqYPcICWKIAiCICRi9uzZeOWVV9C2bVuEhoZi3LhxyM/PF6Ws5cuXY/ny5QbHpk6dio8//hi//fYbJk6ciKlTpyIyMhJTpkzBkCFDAABBQUFYs2YNJk+ejKKiIsTGxmLFihWIj4/HuXPnsHv3bsydOxf5+fmoVasWvvzyS3Tv3l2UOsgNBVNZ1iFKQH5+PgIDA3H//n0EBFCwM4IgCDYUFRXh8uXLqF27Nry8vKQWxylhGAanbtwHANQL94eXwA7yroC154zt+E0+UQRBEARBEDwgJYogCIIgCIIHpEQRBEEQBEHwgJQogiAIgiAIHshCiZo/fz6io6Ph5eWFxMREHDp0yGr61atXIy4uDl5eXkhISMCGDRsMzk+ePBlxcXHw9fVFcHAwkpOTcfDgQd35K1euYNiwYahduza8vb1Rp04dTJo0ySS42cmTJ9GhQwd4eXkhKioKM2fOFK7SBEEQBEE4NZIrUatWrcLYsWMxadIkHDt2DE2aNEFKSorF8PX79+/HgAEDMGzYMBw/fhy9e/dG7969cfr0aV2aevXqYd68eTh16hT27t2L6OhodOvWDbdv3wYAZGRkQKPR4LvvvsOZM2cwZ84cLFy4EB999JEuj/z8fHTr1g21atXC0aNHMWvWLEyePBmLFi0S94YQhBORnV+Et1cex7HMe1KLQhAE4XAkD3GQmJiIVq1aYd68eQAAjUaDqKgovPnmm/jwww9N0vfv3x+FhYVYt26d7libNm3QtGlTLFy40GwZ5UsVt23bhq5du5pNM2vWLCxYsAD//fcfAGDBggWYMGECsrKy4OHhAUC7+/batWuRkZFhNo/i4mIUFxcblBsVFUUhDgiX5eUfD2LPhVwAwJUZPSSWhnAVKMSB/VCIA9s4fYiDkpISHD16FMnJybpjSqUSycnJSEtLM3tNWlqaQXoASElJsZi+pKQEixYtQmBgoMFO2cbcv38fVapUMSinY8eOOgWqvJzz58/j3j3zX93Tp09HYGCg7icqKspieQThClzOLZRaBKIScaegGJdyClCmFieiN0FwRVIlKjc3F2q1GuHh4QbHw8PDkZWVZfaarKwsVunXrVsHPz8/eHl5Yc6cOdi6dStCQ0PN5nnx4kV88803eP31122WU37OHOPHj8f9+/d1P9euXTObjiAIQk4wDIOdGTnIul8ktShWuZH3CIUlZbhdUGw7sRPTuXNnvP3227q/o6OjMXfuXKvXKBQKrF271u6yhcqnsiC5T5RYdOnSBenp6di/fz9SU1PRr18/s35WN27cQGpqKvr27YvXXnvNrjI9PT0REBBg8EMQBCF3Np7OwtClh9Fm+napRWGFSFvL2U3Pnj2Rmppq9tyePXugUChw8uRJzvkePnwYw4cPt1c8AyZPnoymTZuaHL9165boW7YsXboUQUFBopbhKCRVokJDQ6FSqZCdnW1wPDs7GxEREWaviYiIYJXe19cXdevWRZs2bfDjjz/Czc0NP/74o0GamzdvokuXLmjbtq2Jw7ilcsrPEQRBuArlfm3Ogzx3Kxs2bBi2bt2K69evm5xbsmQJWrZsicaNG3POt2rVqvDx8RFCRJtERETA09PTIWW5ApIqUR4eHmjRogW2b6/4+tFoNNi+fTuSkpLMXpOUlGSQHgC2bt1qMb1+vvpO3zdu3EDnzp3RokULLFmyBEql4a1ISkrC7t27UVpaalBO/fr1ERwczLqOBEEQROXg6aefRtWqVbF06VKD4wUFBVi9ejWGDRuGO3fuYMCAAahevTp8fHyQkJCAFStWWM3XeDrvwoUL6NixI7y8vNCwYUNs3brV5Jpx48ahZ8eWSIythgb1Y/Hxxx/rxrOlS5fi008/xYkTJ6BQKKBQKHQyG0/nnTp1Ck888QS8vb0REhKC4cOHo6CgQHd+yJAh6N27N7744gtERkYiJCQEo0aNMhg7uZKZmYlevXrBz88PAQEB6Nevn4FR48SJE+jSpQv8/f0REBCAFi1a4MiRIwCAq1evomfPnggODoavry/i4+NNwiAJiZtoObNk7NixGDx4MFq2bInWrVtj7ty5KCwsxNChQwEAgwYNQvXq1TF9+nQAwJgxY9CpUyd8+eWX6NGjB1auXIkjR47oLEmFhYWYNm0annnmGURGRiI3Nxfz58/HjRs30LdvXwAVClStWrXwxRdf6EIfABVWphdffBGffvophg0bhnHjxuH06dP46quvMGfOHEfeHoIgCNFRKKSWgAUMA0XpQwCAorQMKHGQNcrdh/UNcnNzw6BBg7B06VJMmDABisfXrV69Gmq1GgMGDEBBQQFatGiBcePGISAgAOvXr8fLL7+MOnXqoHXr1jbL0Gg0eO655xAeHo6DBw/i/v37Bv5T5fj7+2Pq7PmoGh6JBzcv4Y2RI6Dw8MbUiRPQv39/nD59Gps2bcK2bdsAAIGBgSZ5FBYWIiUlBUlJSTh8+DBycnLw6quvYvTo0QaK4s6dOxEZGYmdO3fi4sWL6N+/P5o2bcrLRUaj0egUqH/++QdlZWUYNWoU+vfvj127dgEABg4ciGbNmmHBggVQqVRIT0+Hu7s7AGDUqFEoKSnB7t274evri7Nnz8LPz4+zHGyRXInq378/bt++jYkTJyIrKwtNmzbFpk2bdE7cmZmZBlaitm3bYvny5fj444/x0UcfITY2FmvXrkWjRo0AACqVChkZGVi2bBlyc3MREhKCVq1aYc+ePYiPjwegtShdvHgRFy9eRI0aNQzkKY/4EBgYiC1btmDUqFFo0aIFQkNDMXHiRMHnpQmCIAgWlD5EwrIGji/3o5uAhy/r5K+88gpmzZqFf/75B507dwagncrr06ePbuX2e++9p0v/5ptvYvPmzfjtt99YKVHbtm1DRkYGNm/ejGrVqgEAPvvsMxM/pgkff4zTj0Mc+NaNweDho7Hm998xdeIEeHt7w8/PD25ublbdU5YvX46ioiL89NNP8PXV3oN58+ahZ8+e+Pzzz3XjdHBwMObNmweVSoW4uDj06NED27dv56VEbd++HadOncLly5d1K9x/+uknxMfH4/Dhw2jVqhUyMzPx/vvvIy4uDgAQGxuruz4zMxN9+vRBQkICACAmJoazDFyQXIkCgNGjR2P06NFmz5Vrnvr07dtXZ1UyxsvLC2vWrLFa3pAhQzBkyBCbcjVu3Bh79uyxmc7RFJWqMX3DOXRtEI6O9apKLQ5BEATxmLi4OLRt2xaLFy9G586dcfHiRezZswdTpkwBAKjVanz22Wf47bffcOPGDZSUlKC4uJi1z9O5c+cQFRWlU6AAmHVnWbVqFWZ+OQfXrl7Bo8JClKnL4Ovnz6ku586dQ5MmTXQKFAC0a9cOGo0G58+f1ylR8fHxUKkq4lBFRkbi1KlTnMrSLzMqKsogRFDDhg0RFBSEc+fOoVWrVhg7dixeffVV/Pzzz0hOTkbfvn1Rp04dAMBbb72FkSNHYsuWLUhOTkafPn14+aGxRRZKFMGNJfuuYFnaVSxLu0oBDglJcYppICuoNQze+PUoGkYGYkxyrO0LCOlw98GpwecAAFV8PVA9yNth5XJl2LBhePPNNzF//nwsWbIEderUQadOnQBoAzt/9dVXmDt3LhISEuDr64u3337bZNsxe0hLS8PLL72EkWM/RNtOXREWEow1v6/Gz9/PE6wMfcqn0spRKBTQiLiEcvLkyXjxxRexfv16bNy4EZMmTcLKlSvx7LPP4tVXX0VKSgrWr1+PLVu2YPr06fjyyy/x5ptviiKLy4Y4cGWu33vIKb1Gw2DgDwcw7nfuS2sJ4bl29yH6fZeG7eeybSeWOdLud2A/u/+9jc1nsjFn279SiyIpTqELKxRg3H10P/DwdcwPjy+Ffv36QalUYvny5fjpp5/wyiuv6Pyj9u3bh169euGll15CkyZNEBMTg3//Zf/8NWjQANeuXcOtW7d0xw4cOGCQZv/+/ahVqxZee+s9xDdphuiYurh1wzBuoYeHB9Rqtc2yTpw4gcLCiqC6+/btg1KpRP369VnLzIXy+unHWTx79izy8vLQsGFD3bF69erhnXfewZYtW/Dcc89hyZIlunNRUVEYMWIE1qxZg3fffRfff/+9KLICpERVCk7euI99F+9g1REK/ikHPvj9JA5dvothy45ILUqlp6jU+iBCEHzw8/ND//79MX78eNy6dcvAfSQ2NhZbt27F/v37ce7cObz++usm4XSskZycjHr16mHw4ME4ceIE9uzZgwkTJhikiY2NRWZmJjb+9QeuXbmMZd8vwI5N6wzSREdH4/Lly0hPT0dubq7B6vVyBg4cCC8vLwwePBinT5/Gzp078eabb+Lll182CUbNFbVajfT0dIOfc+fOITk5GQkJCRg4cCCOHTuGQ4cOYdCgQejUqRNatmyJR48eYfTo0di1axeuXr2Kffv24fDhw2jQQOsv9/bbb2Pz5s24fPkyjh07hp07d+rOiQEpUZUAtcbJzQUuxt1C4cz2BCEEzj4tK0eGDRuGe/fuISUlxcB/6eOPP0bz5s2RkpKCzp07IyIiAr1792adr1KpxJ9//olHjx6hdevWePXVVzFt2jSDNM888wzefvttzPjkA/RL7Yhjhw9i+Jj3DdL06dMHqamp6NKlC6pWrWo2zIKPjw82b96Mu3fvolWrVnj++efRtWtX3V639lBQUIBmzZoZ/PTs2RMKhQJ//fUXgoOD0bFjRyQnJyMmJgarVq0CoF08dufOHQwaNAj16tVDv3790L17d3z66acAtMrZqFGj0KBBA6SmpqJevXr49ttv7ZbXEpJvQOzKsN3AkCsT/jyFXw9mAmC36evRq/fQZ8F+1ukJcUmZsxvnsx8AcP726DBzB67dfQTAOeuy6fQtjPjlGADnlF8ouPYpYmNpY9iT1/MAaH2iagQ7Jviks6JhmIrVeZ5uKCwuAwA0rhEkoVTywuk3ICaIyogrffU7+yeYs8tPEIS0kBJFEARRyXElxZ4gHAkpUQRBOISC4jLdlIJcIOWBIAh7oDhRBEHwhq0SUlKmQaNJmwEAlz57CiolaS9yQuEcQQ4IQnaQJYogCNHJLahYPv1IVmEFSHmQM7TuiRATIZ4vUqIIguCN849xTl8Bl6Q8AvbDh9wCCxMEF8qfL+OI61yg6TyCIBwKWRcIW6hUKgQFBSEnJweANl6RQqEAU6aNsVZWwqCoSH42gKKSMuQ9KkWInyfcVdLKp9EwuvulVqrBlGktwEVFRVKKZQDDMHhYqoaXm8qhU/wMw+Dhw4fIyclBUFCQwb5/XCElygkhZ1hCLrB9FuX7zMpWMIcix/aJiIgAAJ0iBQA597QxyQo9VXh010MSuaxx/bF819yVCPXzlFQWhmGQk6dVmDzdlCgu0+5l5/HIQXsOsqCguAx5D0vhoVIgLMDL9gUCExQUpHvO+EJKFEE4GIUcRyyCkBkKhQKRkZEICwtDaWkpAODVNbsAAE8lROLdbrUllM485fJV9fPEyteTJJWluFSN1/7cAwBIqBGIU9e1gTe3v9tZQqkMGfHLEVzILgDgeLnc3d3tskCVQ0qUE0KzIQRBVBZUKpVusLvxQDsllV+iMIkwLQfK5dMoNdLLp1Lr5KlRVCGb5HLpkfuIkaVcXJDfpDJBEC4NfQMQrg596FYeSIlyQmg2iHA2KA6RvHG21mFIFXcJXKFfICWKIIhKC32QEJUBuaqcrqAMkxJFEA6Gxm1CbtBiB9eGWlc8SImqBFD/6Hg0Ggbv/nYCy/ZfkVoU2UH+IsKi1jBIu3QHD0vktS8hIR+Mx4BHJfLYNYCm8wingAYtx7MjIwd/HLuOSX+fkVoUWUCKvHgs2HURA74/gKFLDkstisOgPo0b+vdryb7LaDBxE/534qZ0ArkQpEQRhAgUFJNVwCI0AArKikPXAAAHL9+VWBLCGfj0f2cBAGNWHpdYEteAlCiCcDBklZEP1BSEq0LWOsdASlQlgAZtx0P33Ap0b1yKMrUGeQ9LHFqm3PUDua06o/5IPEiJqgTQF4njqSz3nJdjaCW5N+WUqjVSiyAqPeftQ9MpW3Ht7kPeeWTdL6Ip8EqIKyh3pEQRBMEbtl/c9vaVGg2DxXsv4+T1PDtzcixztv6L2AkbceJantSiiMa5W/kAgM1nsnhdn3W/CG2mb0ezKVtYX1NZPlJcHVdoR1KiCEIErH1hucLXl6P568QNTFl3Fs/M2ye1KJz4avsFAMD/rT8rsSTWkfKZPHxF6xBfqnaBEZWodJASVQmgQZtwdjKyHoiSLwWZJFwVfSuxXC0+rvD6kRJFEA7GFQLMlcOnLnJyumUcNLrIdRCTA64wkBojt/Z2xXssF0iJqgTI7YUmKiHUiRN2kF9UavC3nBRxonJDShRhkbRLd/DMvL04df2+1KIQMoX1YCbTMc9R03lkCeDP70evo/HkLViw65LUorCG2rvyQEpUJYDvCz3g+wM4ef0+XvzhgLACETZhGAYnr+ehqFQee1wR9iGmNViIAVuIKWa+dbRV9nurTwAAPt+Uwa8AEflhz3/YYmZVIsMAE/48hWe/3SfbEBcy/a5xOkiJckIc7VPzoIjitzia1Ueu45l5+/Di9/JWYFk/i3rJ5DS97AoGAzndT1eAYRioNbZvavq1PPzf+nMY/vNRs+d/PZiJ45l52HPhttAisoKeC8dASpQTwtUfgF4m52PF4UwAwLHMPGkFcXHo1dAi5+kns7KJ2HDPL0xDh893oKTMugUpJ7+IVX5yMESZ+9iRQ5PLQQZ7ISWqkiHGaqT7j0qxIyNbtmZrV4JhGIz9LR0T/zottSiccKUViXJDzgqQHGEYBgt2XcKu8zlmzx+9eg837xfh7OMgooR4uMJHDClRlQCxO9mBPxzAK0uPYN6Oi+IW5CLY0x7X7z3CmmM38FPaVZtfyoRtSP8QDr4r5vi8D/YMvrsv5OLzTRkYsuSw9TKc3IR//d4j3e/m2sa5aycfSIlyQuT2VX/6hvaL7a/0GxJL4vro+2rQMm/ngVpKPtzMe2Q7EQAWblEW0b9UKmXsrRXHdb/LbcwoR55ScYOUKEIwaKBghz0dh1Lvs51P37wjIxvnRYr+zRZ6TuSHlIOZrbKlk825n9SrdwutnncFBUYOkBLlhNhjgRDzo4hr3hlZ+Zi+8RzuPyy1ndjJECv+kMKOVW6nb9zHK0uPIGXubmGFYoEc/XZuPyh22DApw+oTNrD1fll7x/XPyFUVk6tczoab1AIQlZfUuXsAADn5xZjTv6m0wsgMNoMuV2VarP3nuCIHX5ONp25h5K/HUNXf0yHliVljuSiojmxWRzxDtkqwJoOlM3cKivHbkevo07w6wgK8eMvGBke/ZgzDYMQvR1GmZvDD4JaVZl9KskQ5IXKd3+bLqRv2R0R/WFKGoUsOYdXj0ACuilLJfzrP+KnZdzEX//wrTQwbrgj9zH+x5TwArTWKkBZHj7Vsi9PY4xRlgVHLj+HzTRkYbMOp3RnJLyrD5jPZ2J6Rg+z8yvNekRJFCIaUjs6L917GzvO3Me6PU5LJwBo7Rg09HQoaOz41i8vUGPjDQQxefMhkXzKx4SM1OdGLi5yNBlJZNGw9cWzl0n9ND/x3FwBwzgHhE/TFMyeq4HeVzysq5wePJaREVTJcdSjKryRR1fUtMva0ZbFeeISCSnLvCIILMph1tgt9+c3VRczqsd9T08lvMkiJImSAHHxkhEas7yt7HMstffQ54u7b6tAJaRHC2sO/WbmXLeQjNH3jOUzfeM60DBk8qAf+u4MZGzN4xYSTXvrKATmWE4LBt89xxZddrDoZrPrheMOd2XLu7H6AchiQCVPuPyzFd//8BwB4o1NdBPq4687Z02KGzc0/pxcWaffODPXzwKsdYnjnI9t3X7aCsYcsUYRg0DjBDnu6DX2LAVe/V0uKiKO7MT7+TeQTRegjVF9Tpqmw8JRqDK09curPrt55yPkah6snzq8P8YKUqEoGfRE7BsdM5wnTlvREiI+YztHObqWTEmvtsuH0LZy6zm/lsNDNTR8R8oWUKCfEBSyghgjQP8jllmg0DB6WCOuo/dvha+bLssMnSi73iy3OrijI/eNFiLvLt4q2+jOhW55t/7n8YCZ6ztvLqww5+ABK/cQt/OcSBi0+hOIytcSSiAspUU6IzPtjzrhSdZ5fuB8NJ27GnQLh4qR88MdJ3H9kGoZADgMz2wHJ4Ev68a+3HxSz3seMcE4YhrE7FpejPhpl8DoJi4T1YRhgxsYM7P73Nv46flM6QRwAKVGVjCIeqzzYIodBnQunb9zHuN9PIie/SLA8j2XmAQC2nM0WLE8AKCrVfs0xprqIpNjT5K2mbUPbGTtQUOz4EAuVJZqy1Ez++wxaTdsm+ObkQj37htuzcFyowTKdZO+po4OYWiivSM8SdSzznsGz4ApvISlRlYwvNp/H/UelWLrvcqWP1vz0N3ux6sg1vLv6hEPLZTN+Gw/y5pQVe4JtSomx1DfukTXKVVmWdhUAMHPTeYtpJN382ElGcV6vuky6B33Zn/t2P8asTMeJa3mSySM0FOLACbHnxd95PgfX7z3EtnM5+O3IdWwY00E4wXjCMAxKyjQoVWvg6+n4R/JCdoHDy7QFG6sed58oeY4Y5DRrHzJtVkJGyO0ZuXKnEE2igqQWQxDIEuWE2GuA2HYuBwBwVuCtB/iKxQBo//kOxE/aLMnUjjMM4uZktKRobTp9C4v3XjY5LkY/yrpzNnK0dbapXzkjyK2U2SCrj7lFBaI8PyI9knJ41OUgg6tCShQhC3IeTy2eFmAzYjlgb6dlaTpPX5myVMaIX45hyrqzrPfnIoWGsMX+i7l4YVEa/rstP6utPYi36pPeKWucu/VAahEEg5SoSoYrjJdqDYPJf5/BxlO3Kg7a0ReK81FrOVOhum1bct8pKLEsg0D2fT73zvjeuMIzKSWOmKp58YeDOPDfXYz85ZjFNHwtunyeRXseGWcPl8EWR1nY+XyELfznkgiSSAMpUU6IPZ2mmC8W721fOF639vgNLN1/BSN/1evQ7aiWM4zh5mS05Vhu3NZy8ouQQxwdY1gNBukrgH83c8+bhzxy5OZ94RcByOWxFKuN5OAuYO+7zzAMRvx8FKOXGyrRj0rU6Dr7H4xfc8owvX3FORWkRBGCwbez4HpdTiVcVWhugJfD6jw+nXO52N2VB7HAfQ6UJU5i2r/7H7B2BLC8n9SSCA5b60ypml+IlMKSMv7TxmJqWUYbest1altqqW4/KMamM1lYd/IW8osqYtatP3UL/90uxIpDmRabSa73VChIiXJChHgmn1QeQVflUfszEhjedZPbdJ7Aeery4xAnylgGsacx9DtXE1nMHFvg8RW6qw4j9PjX4glVTu5FoOC21SQ226wgRzh5nJQyNb8HO+9hKV7/WX79jSOQgw5hrwwaC5ZjOXzISQ0pUZUQfzzE9x6z8aPHl0Cpi8boUZcBF7cBRbadqx39paTvA5LzgH+gT1tyG58Vezrvai67TVKN5VI9tK7c2M39G8C8FsAXde3Lx4UHDLbPRpmVuBq2bo+gAWhdtykEQ8jH1eD50MvX3i5FTi4GfCElygmx+uCVFQNbJwJXTPd88kYR7t+9DX/oDXbqUqDwDrDlEyAnQ6t8XDsElFl2Skb+LWDDB0DuBYPDjvKJYsW+OcAvfYBf+4qQuW3YVmnGhgx2+THaf7xO/oSWCu01XONEiQ2XaVmHiV7yELiVbnKYU999aYdWIdeXWiNe5H+uOPs4JOVAarChNxjR9WS+dbV/tS/3PO8Vluj2Ac28y+4DqTJCSpSrcWABsO8rYGkP3SEFgGrIxTmvV3DSazj8FXovBKMB1o8F9n8NLGgLbJ8M/Pik9pglVg8GDn0HfN9VMLHdUYaP3X5G4M09pic1GuDYT9qBLH0FVIzlaSMdx37W/n/tgM2kdvebBbeBzIO8MjW3J55FruxBwLb38bvnFG0RNsqQhS+Cugx4kGV6/OHdit/FkvPybuCzSOCfz01OmSvR4NjB74CvmwPZZ4Gfn9Uq5PpWW0Y+ShQbLuYUIGXObqw76dr7mIkBwzDQmPliYb9vpN41wojEGUtT+Ycu3zXbT+QXlaLZ1K2In6RdRNF3YZrNMmTQ20iC5ErU/PnzER0dDS8vLyQmJuLQoUNW069evRpxcXHw8vJCQkICNmzYYHB+8uTJiIuLg6+vL4KDg5GcnIyDBw0HuGnTpqFt27bw8fFBUFCQ2XIUCoXJz8qVK+2qq0O4c9HkEANgv9dbur/rKa5XnNSogRuPfRUYNbD/G+3vx3+2XMb1w9r/i4WJ6cQwwCDVFrzqthENtw82TXDqN+DvN7UD2doRaHztF5MkJp2Egv2jbVHZyMnQWuVsMSceWNwNmN8GqUoW6VkQXXoJs9wWIhJ3tDKCAe4aBtC0vTrPEN4deE4G8G0ScHoNu/QaDbD7C+DyHmB5X+DL+nC7XnFf3K8fgOqLGD1BH0ta8lBrFeXDozygyOh5/N/b2v9vGW3ro2ahuG78ALh7CfhjWMWxMr0FDYw0O9NvOn0LU/53FmqOZsj3Vp/A+ewHGL38uEiSORFGzuS2GL38ODrM3IlHJezbXIzvgoclZbh+j59FyJKVuN93abrgy/r8m6Vd7GGuHlKuNmQYBj/s+Q8H/uPZT4iApErUqlWrMHbsWEyaNAnHjh1DkyZNkJKSgpwc8w6c+/fvx4ABAzBs2DAcP34cvXv3Ru/evXH69Gldmnr16mHevHk4deoU9u7di+joaHTr1g23b1f4XZSUlKBv374YOXKkVfmWLFmCW7du6X569+4tSL3FRe8Bv5qmHcw0hi+/B/SigmvKLCocgbAQWM/MV/iTyiOIYTK1f6hLtU64+tYGG0QprDjtlittj2nz3zdQwlAGkxdbqWJddjUmG1jYHjixyvDEt4laq9z+eaa+Y//MAv54VTt1qn48uN4+h4Uec22WZ1WZyckA5rXGl3dHo6/bbnztoVVqGQYmdTKrRF3aiZUeUxGjMLU4GExdmPNUt8TGD4Ccs8DvQ60mYxgAGeu1K9h2TAWWPa2dCgMQtO4VxCkyATDwP/KN+Qxm1ARmxXBXpNSlwOe1gBk1kV+oN8iUmhlwLu8G/i8MvUvWmZHfzL3IOVvxu0ZP+ZLIEjXil2NYvO8y/j7BbUPfQgs7Aez+9zbaf74DaZekG5RsWXTMnT598z4G/nAAp64LF5zXkuKz/tQt3Mh7hF3n7V9YYE98tg6f70T7z3fiYo6wq1l3ZPD3VbNUH7Gs4NvP5eD/1p/DC4tszzA4CkmVqNmzZ+O1117D0KFD0bBhQyxcuBA+Pj5YvHix2fRfffUVUlNT8f7776NBgwaYOnUqmjdvjnnz5unSvPjii0hOTkZMTAzi4+Mxe/Zs5Ofn4+TJk7o0n376Kd555x0kJCRYlS8oKAgRERG6Hy8vL6vpi4uLkZ+fb/DjcPSf3SWpwI6pqHLJ0ILgqdAbDDRlFhWOGe7fo5YiC+76SpcZR+2miov43mM2Vpa987jc7sAXscDM2sCC9sCO/7P6aRanuYh+qn9MT5xZCyxOBQ7/YHKqmiLXbF7JyqPA0qcNp5Du3wBO/a5VJjWmX5MfMEuArFPAn8MrDupbK7ZM0PqMlcMwwM7/A06t1k6dmqFCqWOAea2AyYHAvatm0+ruzfapWsUtt2Kz1lbKfyvSKd3MXoaSh8Dtx+l+7o02ynOY4/6tTf3IDWVY5zEBVTaMeJxPodbid8To/dO/ZwyjVXLM3Ee/m/uAlS8CJ1eZnFM9vI1Nnh/iC/fvzCggGmDv3AolxUhpNuHhXe00YTl6z+SMP/R8AUvMKFHLegKMBqOLFkEFNTygLdNP309w60Tz5eo/E2bq70iy84UJ8zFo8SFcv/cI6TLZEJbt4Hv1zkPsu3gHfRbsF7Z8gfIx/8HC3xpcXKbGnUKtn+rODHYLMZxhes3S/SgsLkPeQ1O/3Ct3CsUViAeSKVElJSU4evQokpOTK4RRKpGcnIy0NPPzr2lpaQbpASAlJcVi+pKSEixatAiBgYFo0qQJZxlHjRqF0NBQtG7dGosXL7b5gk+fPh2BgYG6n6ioKM5lciEABUDeNaOjpjJG73nf4G8v6D2cjBpQmFeiuqsO4x/Psfje/UvtgbIS7Re/PuveQUOlkXKgPwhmnwJ2z6oIUJh1SuvfpHcvfyx5Hz4Ko0Gh9JHW9yrTfNsGoQDBeDx4MgwiCv+FJ0rwg8eXwJU9QImeFW1RZ+20zJx4rbXj1gmD8n1gZoVisdHX3nG9KUQW00Hl2T+n3APkPlZwVrwAHPoenihCouIcaiqy8eT934GZMVrfmz1fWM4PMGqnx06wJQ+1fj/zW+msPgAQosg3Y3bXdlkxipvw/bYpZrsvQCPlFfhc+AvIOaf1iTv2E7DuHUMlJaROxe//7dJai5b2ABgGHkwxAAYKaFBn44s278vzqt3wvHXE9GZtm2RcW7NE4o5WOV/S3Wz6w//qTVWXWu9wV3lMxQHPUeir2oXTXq9Csf8rIP+mRcXYoN03vKeNG8US0UJeSMDZm/nYmeG4cA/WjDclPONW6eAQMoRTtnqZ6U8D8jVErTnGzfJojJDhTSw9e/x2LzBP/KTNaDplq4kFVY6bqLvZTiIOubm5UKvVCA8PNzgeHh6OjAzzK5aysrLMps/KMnRcXbduHV544QU8fPgQkZGR2Lp1K0JDQznJN2XKFDzxxBPw8fHBli1b8MYbb6CgoABvvfWWxWvGjx+PsWMrHLLz8/NFVaR2e74DzC0E3j0PeFcBCnNYPcme0BsMyoqBOxcsJwbQWfXYp6Qwx9SKcGQxPnNnIWz+48FtYXvt/97BAJTopjRjdZgcCDQdaDW71R5T4K0oAc76AMUPMPT0KAy1ZCgsfNzhP3i8Tcx3HYGQWHhjPB7BCxpz3xJ/vm74d9ljRevcOq2iwQIV1JjtsbDiQM5ZYMN7mK2KQLjn42f23uNzGz+wmhfDMICyQk4PlEFZkAVc1YuevWOa7tdS5rHCdf0ocGk70PIV3bmpbkugzL+OZ1R6CseCtoZtqykFVI+7B/8I3eHcfxYiFNAqt+vfxf8e/oxbHsEohodV+fWxGVxT/xlWl2oVm8ekqh77Vun5WEFT0dH66SvENqxFLR9b+Wa5LwIAqLZPBhgrG2Cr9RT9EyuAzAPAmHSrZcgFIceep77WLv7Y/HZH1I/wFy5jaJte7HHS0cPwh2tO4YXWNR1cKnvEVsjtyf5ybiEaVQ/U/S0/FUpCJUpMunTpgvT0dOTm5uL7779Hv379cPDgQYSFhbHO45NPKqZvmjVrhsLCQsyaNcuqEuXp6QlPT0+7ZOdCkOLxl/bxX7Q+KCzxUuhZoua1ZHfR4u5AJgvTuSV/FuM3dd9XmORWBUPdLGyhkf6r1WK8y+vw2yDbMpnjzgV0VJ7EZk0r+EPPYnF0mXZQvrDF9JqcDGCVdeUOAJ5SHsCHuX8hwvO62fPhajOr1axatx7blPSm815RbUT8SiMn/BsVFp7aymz8p2GAH57QHtg5De4906CABr4KM7GpjJXjhe2BZ74BarUF1BXPS2jmpoo0R36E1+Oy7EGhsRJOY8ULwMVtaFvjdVR3u4TzjN5Hybp3gCc+AS5s1R36RjUbaWd74N7FQ3iKT/e94/8sn/vfGMO/7102n87BsPk6FyPQ6n+3CwyUKL5+MI7ey86SlFzjrvFBW1d5TbRJGWzYVssb5yPH4J6SKVGhoaFQqVTIzjbsgLOzsxEREWH2moiICFbpfX19UbduXdStWxdt2rRBbGwsfvzxR4wfP563vImJiZg6dSqKi4sdqiiZI7ToCha5z644wEGBAoAxbixXWenDRoECgL9GmT9u7OR7/TCGSqzCP4APprktRkPoDYb/s6wk49tEVvl+6/E1oAbHzybLnYMbHltU9BYAfOhue6VoVIahb1PX/yUhzTMYJQyLG3/nonbKbPJ9dqvZ7CDoyiajI4/vxY2jj+MzAR2vf2faWx1ZrJ0mzq+Y6qihyEWN37hP3fPmQTbgH247ncDIYT82MSQwl6cjlSzRw4LI0ZQiFCLfugvZD/B/68+JWwgPJPOJ8vDwQIsWLbB9+3bdMY1Gg+3btyMpKcnsNUlJSQbpAWDr1q0W0+vnW1xsnyNmeno6goODJVegAOCFyxPQTSXTLRT+3Wj++NaJhkvEZcJAt+22EzmCEsv+O8+q9mq/yE7+xinLeidN4yNFKO6hppJDhPDvnwDS5tlOJyRlxVpfr++fsJ023z5fEbs5zm5ql5APhsG3pVdGxcIehdCacdORd0y/fT7fxC4wsaOR1BYwduxYDB48GC1btkTr1q0xd+5cFBYWYuhQ7VLqQYMGoXr16pg+fToAYMyYMejUqRO+/PJL9OjRAytXrsSRI0ewaJHWp6GwsBDTpk3DM888g8jISOTm5mL+/Pm4ceMG+vatiFydmZmJu3fvIjMzE2q1Gunp6QCAunXrws/PD//73/+QnZ2NNm3awMvLC1u3bsVnn32G9957z7E3yAJhRVekFoEf5/4ntQQGDFRtk1qECrJPWzw1y30RruX0As797UCBHnNDAmX996GAT4jjy+WDdzDnSzQaBkqlY00SMvTHrcBkJZs0wnLVOfgoGnJsBnOKpFDTcVzyEvpaRyGpEtW/f3/cvn0bEydORFZWFpo2bYpNmzbpnMczMzOh1HOmbdu2LZYvX46PP/4YH330EWJjY7F27Vo0atQIAKBSqZCRkYFly5YhNzcXISEhaNWqFfbs2YP4+HhdPhMnTsSyZct0fzdr1gwAsHPnTnTu3Bnu7u6YP38+3nnnHTAMg7p16+rCMRB2oB+4UAb0UB2ynUgmRP3ew3YiV+KhfILpWYWjEjXu95PYeT4HW8d2QqA3mxUZ5pm56Tze6GznXoACwzBARlY+grw9EBFoPRyMxTwElkluSKXMylqJtoL+8yBXhUpyx/LRo0dj9OjRZs/t2rXL5Fjfvn0NrEr6eHl5Yc0a2/4+S5cuxdKlSy2eT01NRWpqqs18CIKo5HgFcUq+6og2JMmfx65jSLvarK87dPkufD3NhyKRy/h4I+8RUudqV+5dmeEcSr/xwCzUOH230PxiCTH8u0rKNHBXKXgv/zennFi1slnQZsSYGpXF1lU2kHzbF4IgCKcloDqrZMZDwe/HrmPU8mMoLrMdtDM7vwj9vktDj69NNxWXEuPx7dwt+4MLy3nMlIts0zacw7jftcGj7xQUo9GkzRjxi+m0u1hWHP2s7LVw2VL8GAu/ywlSogjCkfiZX3lKOCkh/KbUTt/Ix/qTt7DykHGwXFOu3zMTDFaO8BxRbV3lqKmo0zfui64oCVWXVUeu4UFRKf48fgMlag02n7EeZkSu03lcLE1ytUqREkUIzkPGE+NL9fyfaneSThh9OE69iEKzl6SWQDZMLx0gtQj2o7LPI+L+I234iJPX8/DtrosoNROBW64DoDF8xdS3RjhitZwl68fIX4/ppluFZuUh7b6iQjalUHdKsHysZMQwjO4e8M1TnioUKVGECDyEJ1apuwDt3wFeXA0EiRe1vXfxFCwsexq/+1kIghnVpuL3Wm0FK/eWVx3bicwhxsa1kQ6MiyQgt5lA24k4cIcRNno2vIKA1/cAvlU5XZZbwD2UxzPz9mHmpvP45YDp/opCDLxy3C7DHI42NhgX96uZ+y8EH645haNX2W/ILgRi3Uv9fNk+VutP3cKHa06ZHDf3XBpanOSqOlVASpQrEWhGWambjEvJ3wtXxlDjwIjm0UAJJE8G6nUDVOy3BOHKf0wkZpS9iN8DXsavZV1xWWMU+FAvQCWe+QZoPxZ4coruUIfiOfhE8xrgY2VboGe+MTn0c/R0RBf9iqeKPzN7yUofC/vIMRrMC+QZKqPZS8jpv970eNzTgGeA7s/XSsaappGA9sVzgRdWAL7mdwq4iwCzx/nQtuhr9DBqi+gi61HvbeLmBUQ2BrwsKHsvLDc5tGj3JbT8v21YsOsSryIzbtnYEsccMtGPnERPk4zr9x7JUpl1hOJ65iY/fzkDS5RM9SlSolyJGq2A5w2jVEOhQn7NJ3V/7lA3xcqyzvi4dCg2qluZz6ffT7g/LhfDS97ByJIxFfuwxT8L1EoCqsZZFUNh/PWgsbIfGRuG/2PwZ0Zkb93v+fDVFsEAE8qGoUvJHMNra3fU/u/hD/iGAsmTgJBY3emHjBd+03QFhlVs87K1ulHU9TpdTURSww2AArkWrCmFCl8LlWGwxycZH5Tqhcvw8LOQ1oiUz8B4GllbgmoCrV412BJmq4blVj5seGUL0G4MULWB2dP/5zEGf6rbmT13nQkD4p4CfKqYPZ/HsKy3HrvVCShRGi2fb/YSbiIUhfA2Sq0AukzQKpjlipBnIBh3X+QwQfitzMY0s/Lxc298z8uJM12B9tkGbUBAIQMD2hx4ZTK4iKUeyE/t4IdC4egNbtjhkClUntc5g02KlCgnZG7DVfig9DX8o25seKKsGKjewvAYo13982zxp/hD3R7jSofjw7Lh+EX9JEaWvgO8c0ZrndGnrlbp2qJphY2aRLQq/ha3+vwFPL9Ee77VqxVpPfzQuGgRuhR/aVng2G4263RMY+ig+3Hp0Io/3PUGx6Ba2F/vAxzQNMDM0v66wxZf0nZjgJTPgBG7K46VVTjq5sNX+3K6VQzMp6qkGOZhxpJWrigWQy/Wz3sVGzmXQYWRJdq91sbpKUx7/s3BvYcl+F2tN4D7huL1kncwoGSCpVro5CgLNFoWP+akVkmxZu2r0Qpw97GetxE/+w9Dg6LFOO/RUGu562PGmhnZBJtVnaCG6dL7EkbvWM+vwSjdMK3U0Dp3kalmeFHypxW/tzKNyXZcUxeDSsdjftO/DE+kaiOzq/W6s3dKRmp/6fQBMO4K8GGmdgubcVcwtdFGdCieixKjCC/FL6w2zLfcilmjtYks+s90qVqD8WtOYt3Jm6bpZIIYg7dQg6+UigUXZ+ULOTyshHoIHV9Vqvtmqd0t7knINX8LF5BjOSEY9zxr4Dd1F7xZ+iauBzSvOMGoTZ7AB621A/lxJhbvlr6B2wgyzCywhnagKaf5YMDDcMDNgz8Kw1tW2Ov1/XoUSuTDD5eZSMsCxz0NxD9nuT4IwHMlU3CdqZhS+0WdXJHAww94eS0QlQi8uApqlTdeKPkE36p7WS4T0CoOHj5A0iigSkzF8ZKKffxK4aZ9y930tvNRGioFjML0NSlRahW7+/ADOo/X/vhVTFtpoMRGTSLqFy3V+oc9JuPWffybXaCd7izHvxo2a1ohTVMREParwPfRqXg2fi7Tuw8qDzBKN4wtGVFxrLxNahhan3KYoIo/kkYBjfvDmNTiGWhfPBd57T7WHkj+VKtwRnfAZ7fb4RG88Mexx5soRyQYXLtD3RQYsgFQKPB92VMAgLu1n9adZ/TrVzMRN974D9+rK86XdvwQBfAxtIb6RwDPfqd9Xp78VGtFeswD96p4s/RNAECRW6D2eQiuDQxYCXhqLVoP4Ykjmno4rYnGXxo965h+eyqVWJx2HcUwVTo1MUYWx/JAml0/AdqMAl7V2yKotEIRX33kOlYcuobRy4+b5GkL0zhFpgOFzcFXjuYNljAMg30Xc/X+Fj5/hmFw8L87eO7bfTh9476N9JbPzd12weK5y7mWt20qh6sdSqORh9Jgorw4UCyZ6k0GkBLlxOTDF783/q7igKbMQMFpXTQfJxQNbWekNxWEFoPNJlHrv9Aavdg2bBylFQqg7xIU1emOC5rqqFe0DAlFP6BO0c/oUDwHT7pppyAnl+qXrcBbJaOAHrOBwOpAnS7aKbcw89NKBu/a4HXaQX+QhW1SlIYWCAaM4TH9Orn7Iq/EtPN75Kbnz9P5Q+0PKpSX4x5a5dZ4sNaf6ny2+FMc92kL9KrYm25wyTh8UdoXe7264CoTgWuMnlPzY2Wg1FyM3J5fA23eAEbsAwD0KZlUcc4rUGeR1OcKE47rTBjym70BjD0HtH9bq3ANWYdH0FrmzH39XdRUwyulHwCefmAY4DxTEwlFP+BK52+AXvNRChWGlxpZN1WG0bnV9Z8BALxdqjd16uELNHkBeOFX7e/t3wFe/A0YdxXftliH6/r3ok4XYEw6UL+7Xq4K9C2dhJ4l/2eopFrgLBNt8DcDRmu5BLRO5X1+0P7u6Q+kfmaoqAZXXHv7gX17Qt7Msx7CQOpJILYWACUPf58tZ7Px3e7/OF+nj8XgjwyDvgvT8PKPh9B/0QEcy8zDoMXC7VKg3y5dvthlO70CnBTe9aducReKDzaad/WR69yzFGjbGLlan/QhJcrJMXjGNGUGB+7Bn50JWaEy/7se5UrUtbsPcTFb72tOT+H4Blprx0el5rd3yeu5BE+WzEQJ3PEAPlBDhWtMhSP4P5omOK6pq7O+/K1pB7Rit1WMQTVrdwBG7AWiTH2+vt11EV9nJwB1uhpOL3kFYou6BXapm6DALQQIrac93rgvGA8/w+lFC47SANCpeDbaFH2DLJV5y5y+nMeZWMwPnwqEVKz0+0fTBPPUz+osTLf1LUqPOWM0+GtlCgFSpwMR2i2QrjHhONNkgtayGNPFQPFdUpaCRWU9UITH1jeFAgioZpqnMYP+wkFNA7xe+o7JqQfwAQMF0OwlJOJX/KMxv2KwR/FnuPnUUjCP/er0p0OLFV74K/0G8h4+jvascgfqpQDepvfAMgpDK5gVVupZCLOYx1anJ6cAn9wBPrwKVK1vetHru7VTjcmTdYfsmda6W1iMtjN28L6eLfb4M/99gt00JZ8y/vnXcDNsc/eSrzP29XuPcOTqPezVs3TdLSwx2oDYcSgV3IyGbKxbjuCDP04a/G0QbFOvRnwUHnNXWPKDkqs+Jfm2L4SAaNTawfQxZVDi8p1CNIy0sQpKqQTqPAEU3AbCG1lN2mHmTryuuorx5WOfnhK1CH2wqPhJPGBM/W8Ki8uwcPd/sNaNlMINz5ZMsXjeGmzer6JSNWZuOg8AeGHCcnw/TTs9o93zVIHhpe8CAIYpFdrpovMbgKYvAqXAL+on8be6LdKevArf5v2AneZXmzyCFx7BC1UtCGTidG+DzZpWuMWsgn/1OBw+n4NNp7LwH1MNzxVPxsf9O6O5lWsv13kJ8Y0fK0eRTYB07Wq1T8vMWxttEtMZA8smosxGb6ZWqACYt1CeYaLxMLojKnacq3geZh1X4IcT6WheMwhr3jDvrC4kGigxpOQDvOf2G94vfR1/QPuxcPehGunX7uDP49cx/dnGCPTRs6JFNgF6CBdSIiPLtp+N1Au69l8Ubx9Dk5kic1uQsMhD6nvEDm5COkppMF+MZVn5yMW3fQzjRMlTiyIlypXQqLV+HMO2ose3h8BAiQl/nsaq4W1sX/vSGu0Tq7T9Fa/Uf5g1htNEBTDvwDxzUwaWpZmPweKozkJ/SvKNX45VlG8ucWB1oPVj5+ZSrWUkH754lPgWfP08AZjGPGEDVyXqIbzQoXgu/kztgKHfpumOH2Pqodi/ptVrDe5ry1dwKesuRh8QNjYTW6z5/hx/ZhuahSvx07c5AIBjmXkGaU/fuM96SoHrs7RL0xS7SpoCAErLGDScuMHgfFU/T3zay/KHhVrDYLeRNUUQwTjAytgsgpIhV8uANWwvdBSvUkqFqVXt3K18/H3iJkZ2roMAL24bUgsVLsG8BckxjWuuBvryyFVx0oem81yJ8lACUa1xhqlYxfWwxPb+XFAoDBUoK4OeUt/KwDJ45OEr9yye03DsjW31HenX8szuSaZfypGrluXhw/1HpVj4j5XYQI8d2zeoE1nlp39LyuAGhoVyaxWVO643eBXnmFqcLjNuGuN7L8RAWhQYo11VaqFdn/5mL68AllyZvfW8ybHbNspdfvCqidJnD86omJQjhO8Wn+pzuYZhgHdXn+BRiv0oFQqT96f7V3uwYNclTN9wziS9XK1r+mMBGxmF8muS67tBSpQr8dh5WGxnPJWBEqXvZG75Gkc+/73n78NbK9ivlLJ1v9jcz4/+PIUZGytiA5l8QY3Yi67Fs3CYsR5jqxw2Sp6trzTjs2z65PyiUmw6ncUiJZsSLaRisSJNCvhs+WGv8y+bQYj/VIhAgxfL9tGXk33Z0rY9m+lEY+Zu+xe95u/Do1IWH6d6WGtHvsEoxYP7dJ61W8dFwS5VG8zh2SxXakiJcnIYAKj12H+kudbXRS3E0lgrz7xKoadEvfQH28ssYk3a+w9LeeQImxty6qNhgKnrzvIqpxzjKR2TF97DF5eY6rzz59OBGA9kbAbjYUsPm90Rngvsvk71/3h8nV2lioOQHfe9whKTY2KtvHt75XE8OWc3ijgO9PpsOn0LF3MKeD57/NLxck528Og6d9sFnLiWh5WHuSndCiuO5XJ89i3B5m7z/TD67fA1NJhoflcMuXxsGUNKlCvw0h/AazuA5oMAaJUCu7HyhWYwnVc3GfZirQ/cnsFOGWLTkVpL8+Pey6zKsZy5fZdLnD0AICMr32TaVYxyLeUp1+kLoRi1/JjJMVaWKB5D7Nr0m7iYU4Bd51n4a5lh74VcjPjlGJJn/2MxzV0zSmE5ltr4j6Pcl8vzReznqZizJUrByY/JHt3w1HXr8bD0WZt+E0cFdm/gi7WVgHKFlCgnR6NhUKb0fOxTon1BufoYcUVpYeWVtVLF/lpkM9AIIYGlUozzZlvdI1fv4r/bBTbTCXH/bN2j1Ll77Mqfr4jll+nLt4LHju/2InY8pv2XbK9y43MLrQ3M5X0B17qduJ5nM82kv88YWLr0xbDUBxn7I7GK4yjirjf2WDe4Xql04LYvPeft5ZS+z4L9rNNajstl/nd7oL3zCNGZt/MiOs3ahRPX8nS7hIs9nfdL2ZMoY5TIrvWMQVl8B3pnCKhmC751yHtYiie+tPy1r8uf9UF9mYCtZ7Nxxc54Mw9LypA8+x9M/vuMyWDMtt76VguGMR//RX8QHm9mx/dyiss0+HbXRZwV2I/E1oBaXKbG/J0XbUa95oIQPlHW2qBMgL7AWg45+RWO94Yxgyxfox+c1PieS90VcCneOKK4rXfBajPyMJtJtu0LjzayVD0uqyXlOkqQEuWEGH953sh7hF7z96HPgjTkPSwx+Qo8ePku90KsPLG3EIKGxUtwNukLnLlp/4Bi6+VgGMambxSbL0oxO2gTS5TQ+bP2MalIuPvCbbz20xF0/mKX9WtsSPvX46mhpfuvsBPCiG1ns9Fr/j5e15pj6f4rmLnpPJ762j7LGVd+2HMZszafx9PfcPvKtxd7pqWE2DrkxLU8ztdYe6ZaTduGn9Ou8BfIuCwLRfEJAcDlY8i4n7WlsCoU7Noyv6gUz367D4v32eli4AKY852UG6REOSHWXvS7hSXQGM22WVt6z2XuXJ8SuOODP06hqJRdiAOr2Hg5Rq84jiZTtugsbY5GX7xXlh7Gkn2Xcf3eQ4vpATGsa9zzO2609J7vYMw5BIXR37M2G4YOMLE+oHzKSd7Y88Fg6Q6yCzZp/c5YUxbKB3Z7FLELObanm43LsPXIfPLXGXy5xTSkBJ+B8vWfj0iyz5xxiWVq6zIoWe778sOeyziemYf7j2x9OAoXK0pohGoNmepNBpAS5WKolApOg96Ws3yXs2vN8sv0vij5PvDWrrtTUIL1J7XLyL/fLf2X2Ynr9/Hp/85iz4Vcg+NiT0PYyn/2lvP4+YBhMFOT1Xk88zZIy6OVzfXzBgH1dNN58hwQ+PJX+g2baSz5SS3dd1m3JYrUlii2cFGiAOCbHRdZpbNV/Z3nb+No5j0wDIO3Vx7HbHPKmSXsuD3Gt7bU+OvVCGvtqH+qsLiMtQxCfqw9++0+XMi2HUHfcogD+2RZe9z6+0Kr8wiHoIACagFerG93XTT421KWBv4Nll4uhrGq2FnrCKaZCULHGxHfQVuK68MS9h2jOczlXn7sQvYDfL3jIj5Ze9rgvBBKiXG1So2+ttlY240tGVL7vQiJNSvRmJXpvPI8evUeJv/vLAY/3izXnlYUwifKGgaBF/UkZfshZzoNzk/eUrUG6dfysDb9Jr7ecRF3HBCclasCo4BpsE1ziL0wyBLHM/PwOovwJobBNs1XiI9y9/aqdKv5yLXfICXKCbE2OCoUwryE9u6srs/QpYfxbza7KQExYR00kGu+jO2cG07czDFX4zIsnyvQ+3K12vQSGXqMFzp8+r8zuHS7wtm9/KzUdihbU9OOWluVnV8kWF7lH1SOvreOHu8UUKC4rKL9+i86IHjMOmO4LuCxGidKUWGBEkNZYJuntbAV9sD3+bP2kSaXBUmkRDkh1h4epVJh4hMlJvodlyVsxaqRx6tQgenLaj395jP8p0TZYq3N2VqcLCkBQt3/P45eZ6UAHPjvLnoL6GjuKPZc4BdziStKo/a0x6CoVmvsz8QK+o8ln4jlfCKGW0K/hhdZ+nFxLU5/gQRX2c1t+1LO8cw8xE/ajC+3nOdw79hLv/diru1EYHf/LaZhzP5qF0etbBcmEx2KlChXY9f5HE6WKHu7Vv2VOwwYnitiuKWXm+/MxZwCk15D6BfcWnZKlreDz1QJl2tWHr6Gp77aw7995NWsACrasUytQX6RfVOyrMoDAxXbBoXWCmlNYbDh6ywabI00posMTJHT+67f33G1+Oc8sP2B8c2Oi5yCJevfm30sFSVrlCtm1m65vnhit8y8nRVuJcZKo0x0KFKiXI0Jf54WJk6UEWI69TnKYVCsLxcNY9qhCl0nc7LrHLJ5+KIY5sNfVuNL7/CYDmBEnHKasTFDkCkKIfwM2aIy6ZUt35lGk6xPE6sdaJY2UHYcPMJpwwcIYMHjIDfXd2308uPI1our9aDI/Oo7vu4YQkSDZ5jH7gl2tp9JkEwLjcEqSPLjzGg6jxAMW19mUjkmFpVqeClwQohrXslgkK/XUbEtpvzu3rr/COtP3rJ5Px1xu60pZYaRooUtd9PpLKtLrc3JxVVp0flEiWBxWPjPJXxotJWE3GE7ncdmelE3m2evUCzQL4PtRwSbvfNkZIgywERUju/el1v+NXucvRVPeB4Ul6HVtO1WI5gLqbyweU40DFBUqjYJ2SIPFYqUKJdEgpApDuOdVemsNwt+c8VxNJ68BSdZbGGhzw+P99HrNHMXRi0/huUHrW9BomHhWG43Vgpgs92GrTwscet+EWZu4rBknA/lFjWRBst0vSkYMay0bOAy7uhP51kbsA6ZCaJbqja0PIltibIkHdvb/KeNZe1iY48+YO/H6iUL2z1xUVIMVq/ZJU0FuTZWNpaX86CoFH+l32RVvj2vNsMwZreBkokhipQoV4TPQHEs855Vp2BHRvu2xKYzWZw63XXl8aX2aJUirl9QJY8HJFtf/Frzt7hvtLUm1bdc8Gn7ew9LJQlW6Cj0azbqV9NNgGUFY6hEaRjL7943Oy6aHIudsNHAN0btwEUmfBzLjeH7FAqlf3Mp/9q9R3aVZcnyylc5c9T0Vnkxb69Mx7ZzljaIZycL2z1PzVnD5RI3yk1qAQjh4foynbp+H899qzXfXpnRQwyRrCOPd4E3Gob7ij6umOswyo/pK1HlsYW40GfBfsSG+XG+7vSN+wY+HnwRO2K5flts4rmScs7WC3bJwMXKptJLXKbRcI7UP/a3dN3v5ZYosax8Fjej5Z0ff1mMETskRYnRymShBnW+98DR3ej2jByHlGNJqSRLFCEanIwKCgUOXra9uzzA70tHDs5/lhwTWV9v87z9jpg2ZWA5nXfk6r2K4xzyZ7u1hz5ChSkQ/xGxr4B/sx9Y3TqJlQQ8p/M0GmDcH5Y3Y7bF3YfixP0p5zO9YLj6dZTCL5OPomg8/elILInL2idKsq7VtlLDWjYWbcZYscbKAVKiXBCuX0RspoAYcPe1WvzYt8h23o41QwuNufsidFGWtgcBuIQ4EBaho2GLtZTdnnZnwODWfWGCX7JpJwaG72MZD58m/fr+ciATRaVqznmwZdu5CmuEwW3mbU0x41jO4jq+z47xvo72IFT/wuXDU7/ejlI0hCpnzbHrrJ6Tsb+lY+PpW6LJYS+kRLkgXB8utmMh16/LKevO2he8jQNssuCrrNnqnh3x1W3dEsIuiOacreZXA0lNRagGkfK383prcnEZu9kM9H8ev4H+iw7o/hbCEf5OYQmne/vB7yfsLtNZXOz+PnHT4G85WM6lWl1tL/r9q3ENzD36Y39j95xtOJVldscLufhEkRLlgnBXothdINbL7bBXQSRfA0vhFcSmvAhLFg7jw/pTfXKCgbgb5drbFkIZyDjE0NRx+kY+52vY1LakTIMsCxa2347wizf0n95qM94DHM/LFArgcm6h7YTiFM8LS8+V3BVQBuZjXPF6zex4t+Sia5JjOcFuOo9nADZWFiK5vA0WsPWem5PfsZ2xTAPpsGTqurP4cst5XoE62WBPW2w+k422dUKFkYOHIJZXP9lHr/n7cO4WdwXNGtf1Vqs5+pUuVWvwwe+G8cAcbakQqjTWH6uM1T9Fg2GAgT8ctCqOgX+USJLJZdQgJcoJybcS/BDg9tBeu/sQNav4sErLxxIlJ9O0WJLobwAsBc6tQgGZdx9KLYJVJv19xuRYUama0/Ysp27c51U2n+m82w8MV0wyjOl2TEIrUMbwXqZv5hibjwTjlXIAUOCAbXrswVKteK/Oc1SIAzA4ed30eba6v6cIvZRcPr5pOs8JWSNggLo/j9/gMJ3HPf8yFpt3CfEqsHmhxFo6vOLQNX4ZC4Q8uhLpeFRi3XFajL62yadbkDR9h/AZGyG0876j4K8IaP//atsF/Hrwql0yPP3NXruulwohFVCpcIQVUC6vBilRLogYPlHGq4bYUsJiCbEQg9wxoy0BzJbjyG7GAUXJpA+RnJb/t9XqeTG+WIvLNMgtKEahyFZIISKOy+SDnTUXcwowZ9u/mPDnabvyKTZjnbKFXSs5OV6887z5IL5slSipHKstiefo5+x81gMkz/4H3+4yDTrrSEiJIlhHNeYzGJVJGIfFGL4vufGeTXJDLmZtqSi0ZYkSsewTZqY1hESMpp1sZnpSaPhbUxhe0+PO7heoD28Li8QhDqwdF6N5+n2Xhos5BeJvS2UDUqIIkw7vRp757Qz49IulLKbzxIYx+p+oZDhxwwsluv4YtnT/FYFytYw9yp+xqxmrOFH8izNADsvm+bsdSC97OZXpu46UKBeE6wNsPE13iuOGvdaQMiJwZcFSc4sZZNFR2JpCZuULJ5QwBGt4G1MYQydkR1tZ7QvMKpQMPK14jrJEWYpYrnf80/+Jb+2UC7Q6zwWxN2K52QjcDL9OQi5KVH5RqctNe9mqz02BIm1LxdGr9zDg+wNW07y54rjNfJy53Z1VdHtW5RpuZMz9GmeHtU8UAxOfvO3nskWPB8dmOu/Af9z2e3RmSIkiTAYZcy9x3sMSFBR5cs5bDquL1p+8hfUnb2Fu/6ZSiyIKzjrQ2uLd39LNLl3XZ91J0+0gjCksUeP+w1IE+rgLJZrT4Wgl4+e0q2gTE8L5OgaGsrJVKMTebNiRsO0y06/nYbbeLgT5RaUYtuyISFLZxpLYZRrGYuvwcf6XGzSd54Jwns7Tu6BUrTH7Eg9bdgQdZ+3kLIutQdCRzN8p7SoOQjo+/su+lV5SIYSfixRK9tL9VzDil6Ocr2MYxkAh0rB0ShbKH0g/YChXTvOMBWYMW8XxC6N9/x7INC7WrM3nLc5InLiW51hhRICUKMJgOm/Z/iuCTn/IyUoiI1EEgTHzG2GeA/9Z3sCZkBd8LFFy6GeGLDksSD5s63LmpmHAVHMBMMXA8nSeZcH5Bpt1BkiJckG49if6wSLP3soXtEOS04oRV2PoksOy8TkTAyFXdsop1AYnBLoFzjLd9eaK41Aq9B3L2V3nSj5Rcu8zLclnbRpSBou0RYOUKBfEXkuSkFu1yOEL0ZU5npnH6h4fvep8jp6WQm1UJgSJ5i/zQVmf45l5uPewYg/FjKx85BbY3lPRlfoZAeKryo7d/5oPLOoKkBJFmCCsJYoQEz9PdmtD+ixIE1kS8zjzyjg5IMT9c+YmeN9oU2FLOHEVnQ5Lz9PDEnn6ZIkNKVEuiF0dCmPoaG4vchpEHSqLg6YXvNyVsh5A2KyecwSuFNGaKwzgVLtUZ+htjsx2YYorOCg7C5b6G3MbdVcGSIlyQezVFQR1LBcsJyfDQRXv/tUehzmU8mFnRo7UIjg1lfH9mfy/s7rf2boW6C/1d3bkPv1qaXyQ+/ZYYkFKFGGCoNN58u4PnJ7iMg3eW31CajFkjxMZYmTBwn8uSS0CgMrZf1TGOjszpES5JPY6lgskBoDK+S1NEMIgxICqjb3EDbnEHBJykQshDNQihpAS5YLM32nfV6SQ5mQ59YEOFYVMH4QAyOj1kYTKqETJvcaVsEmsQkqUC7LDTj8UIS1RMtj1RRoqa71lTGX1z3Lmd9BZw3vZhRO3V2WE9s4jTBA2YrmMegQZiUI4FoUC+CntitRicOZ/J27anUfy7H/g66ESQBrHI6v+gwAAfL/7P6lFkBVkiSIMWHP8BrLuFwmWH3WBlRs5tb8rR022RWGJWmoReFEZp/PkzqYzWVKLICtIiSJM+HaXcCtznLUPVNs7B0I+UbKDrBrOhzNPRfJF7iEOCENIiSJExVk7hC30tSUIfx6/IbUIALSD8Z4LuVKLQXCELFGE3CElihAXGfWBXETJe1QqmhyE47lbaHv/NUJ+VEYdqjLW2ZkhJYoQFWftD+zuyJy14gQhIyrjFGzlq7FzQ0oUISrO2gc66zQkQbgSldEninAueClR165dw/Xr13V/Hzp0CG+//TYWLVrEOa/58+cjOjoaXl5eSExMxKFDh6ymX716NeLi4uDl5YWEhARs2LDB4PzkyZMRFxcHX19fBAcHIzk5GQcPHjRIM23aNLRt2xY+Pj4ICgoyW05mZiZ69OgBHx8fhIWF4f3330dZmTyi+DoTzqqM2K38kWM5QdiNkJuhOwuV0frmzPBSol588UXs3LkTAJCVlYUnn3wShw4dwoQJEzBlyhTW+axatQpjx47FpEmTcOzYMTRp0gQpKSnIyTEfFG///v0YMGAAhg0bhuPHj6N3797o3bs3Tp8+rUtTr149zJs3D6dOncLevXsRHR2Nbt264fbt27o0JSUl6Nu3L0aOHGm2HLVajR49eqCkpAT79+/HsmXLsHTpUkycOJF13QgtcuoPuHROdosto3oThLOiqYSmKPLfcy4UDA+1Nzg4GAcOHED9+vXx9ddfY9WqVdi3bx+2bNmCESNG4L//2AXjSkxMRKtWrTBv3jwAgEajQVRUFN588018+OGHJun79++PwsJCrFu3TnesTZs2aNq0KRYuXGi2jPz8fAQGBmLbtm3o2rWrwbmlS5fi7bffRl5ensHxjRs34umnn8bNmzcRHh4OAFi4cCHGjRuH27dvw8PDw2xZxcXFKC4uNig7KioK9+/fR0BAgO0bwpLoD9cLlpfYLB3aCkOWHJZaDABAdIgPrtx5yCrt1F7x+OSvM7zLqh3qi8u5hbyvJwgCUCpoSo+wzZUZPQTPs1x3sDV+87JElZaWwtPTEwCwbds2PPPMMwCAuLg43Lp1i1UeJSUlOHr0KJKTkyuEUSqRnJyMtLQ0s9ekpaUZpAeAlJQUi+lLSkqwaNEiBAYGokmTJqzkKi8nISFBp0CVl5Ofn48zZywPrNOnT0dgYKDuJyoqinWZroqc+j8ustgrNylQBGE/pEARcoeXEhUfH4+FCxdiz5492Lp1K1JTUwEAN2/eREhICKs8cnNzoVarDRQVAAgPD0dWlvkYPVlZWazSr1u3Dn5+fvDy8sKcOXOwdetWhIaGsq2exXLKz1li/PjxuH//vu7n2rVrrMt0WWTUCXLZmb4yTiMQBEEQ3OClRH3++ef47rvv0LlzZwwYMEBn5fn777/RunVrQQXkQ5cuXZCeno79+/cjNTUV/fr1s+hnJSSenp4ICAgw+KnsjPz1qNQi6ODia0AqFEEQBGELXhsQd+7cGbm5ucjPz0dwcLDu+PDhw+Hj48Mqj9DQUKhUKmRnZxscz87ORkREhNlrIiIiWKX39fVF3bp1UbduXbRp0waxsbH48ccfMX78eFayRUREmKwSLC/XkmyEeYpKnXMbdjk5xBMEQRDyhJcl6tGjRyguLtYpUFevXsXcuXNx/vx5hIWFscrDw8MDLVq0wPbt23XHNBoNtm/fjqSkJLPXJCUlGaQHgK1bt1pMr5+vvsO3LZKSknDq1CkD69XWrVsREBCAhg0bss6HcF5IhyIIgiBswcsS1atXLzz33HMYMWIE8vLykJiYCHd3d+Tm5mL27NkWQwcYM3bsWAwePBgtW7ZE69atMXfuXBQWFmLo0KEAgEGDBqF69eqYPn06AGDMmDHo1KkTvvzyS/To0QMrV67EkSNHdPGpCgsLMW3aNDzzzDOIjIxEbm4u5s+fjxs3bqBv3766cjMzM3H37l1kZmZCrVYjPT0dAFC3bl34+fmhW7duaNiwIV5++WXMnDkTWVlZ+PjjjzFq1CidQz3h2lCsFoIgCMIWvCxRx44dQ4cOHQAAv//+O8LDw3H16lX89NNP+Prrr1nn079/f3zxxReYOHEimjZtivT0dGzatEnnxJ2ZmWmw2q9t27ZYvnw5Fi1ahCZNmuD333/H2rVr0ahRIwCASqVCRkYG+vTpg3r16qFnz564c+cO9uzZg/j4eF0+EydORLNmzTBp0iQUFBSgWbNmaNasGY4cOaLLZ926dVCpVEhKSsJLL72EQYMGcYqBRRAEQRCEa8MrTpSPjw8yMjJQs2ZN9OvXD/Hx8Zg0aRKuXbuG+vXr4+FDdrF4XB22cSa44kxxopyVCU81wLQN56QWgyAIgrCB08WJqlu3LtauXYtr165h8+bN6NatGwAgJyeHVqQRLsG/2Q+kFoEgCIKQObyUqIkTJ+K9995DdHQ0WrdurXPs3rJlC5o1ayaogAQhBauPXrediCAIgqjU8HIsf/7559G+fXvcunXLIBJ4165d8eyzzwomHEEQBEEQhFzhpUQB2nhJERERuH5d+8Veo0YNWQTaJAiCIAiCcAS8pvM0Gg2mTJmCwMBA1KpVC7Vq1UJQUBCmTp0KjcY5gysSBEEQBEFwgZclasKECfjxxx8xY8YMtGvXDgCwd+9eTJ48GUVFRZg2bZqgQhIEQRAEQcgNXkrUsmXL8MMPP+CZZ57RHWvcuDGqV6+ON954g5QogiAIgiBcHl7TeXfv3kVcXJzJ8bi4ONy9e9duoQiCIAiCIOQOLyWqSZMmmDdvnsnxefPmoXHjxnYLRRAEQRAEIXd4TefNnDkTPXr0wLZt23QxotLS0nDt2jVs2LBBUAEJgiAIgiDkCC9LVKdOnfDvv//i2WefRV5eHvLy8vDcc8/hzJkz+Pnnn4WWkSAIgiAIQnbw2jvPEidOnEDz5s2hVquFytKpob3zCIIgCEJcnG7vPIIgCIIgiMoOKVEEQRAEQRA8ICWKIAiCIAiCB5xW5z333HNWz+fl5dkjC0EQBEEQhNPASYkKDAy0eX7QoEF2CUQQBEEQBOEMcFKilixZIpYcBEEQBEEQTgX5RBEEQRAEQfCAlCiCIAiCIAgekBJFEARBEATBA1KiCIIgCIIgeEBKFEEQBEEQBA9IiSIIgiAIguABKVEEQRAEQRA8ICWKIAiCIAiCB6REEQRBEARB8ICUKIIgCIIgCB6QEkUQBEEQBMEDUqIIgiAIgiB4QEoUQRAEQRAED0iJIgiCIAiC4AEpUQRBEARBEDwgJYogCIIgCIIHpEQRBEEQBEHwgJQogiAIgiAIHpASRRAEQRAEwQNSogjCDO8k15NaBIIgCELmkBJFEGZ4ukmk1CIIio+HSmoRCIIgXA5SogjCDAqpBSAIgiBkDylRBGEGhcK11KjU+AipRSAIyejeiJ5/QhxIiSIIMyhdS4fCG13qSC0CQUgGw0gtAXta164itQgEB0iJIggzKF3MEuVq9SEIV2VKr3ipRSA4QEoUQVQCXG16kiC44EyPP33wOBekRBGEGagfIwjXwZmm86jrcS5IiSIIM7ja16Br1YYgXBcX63pcHlKiCMIMrtaRuVp9iMpB5XxuK2WlnRZSogjCDK5niXKt+hCVg/Hd46QWweG4WNfj8pASRZjw16h2UosgOdSPSY+HG3VPlZ1X28dILQLBkq5xYVKLIAnUSxEmNIgMkFoE6XExLcoZv25/H5GEbwc2l1oMQkKUrhawjQXOWuPaob5SiyAJpEQRJjjjgCs0NP0lPcE+HngqwbX2MCQIWzhrOBJLYvduWs2xgjgYUqIIwgxO2o9ZxBnrI1crRPUgb6lFIDjCwIliHLgY5j6EEqoHYkjbaMcLIwKkRBEmyHPociyV7R64KRWCb3XTslYwFr7EfzpOpjoUqgV5SS0CQTg9jEDBu3w8VILkwxdSogjCTr4e0ExqEWwi9BRBkxqBNtPEVwtAzSr8/STkvEKyec0gqUVwCTrXr+qQcpxpet55JOWPQgHBbINSB1IlJYowwVnn5IWEyz2oFih/y4St2nBVWOpU9bOZxt6+Tc5P4ZIhrcnpXQA+7tHAIeXQdJ74cOkzGYa98iP3DZlJiSIIM8h5AOeDzf5NwC/Dcuz9QpSzMh/o4+40Tu89m8jZsVe+bUyIi6sotqREEYSduEJXwHUoc0SdhfCJaqw37di2Toj9GToh3zjBdDNRgYy/HXhhqa9g+5HlobKupkitjJESRZjgYu8wL1ytI7PlE8K1vhoWPaCaYey6j/ZaomLD/NA6umIqYMZzje3Kz5XYNrYjtrzTUWoxiEqApa5Cw1L3mdIrXjhhRICUKMIuvN3FXRnRi2eMkZpVfDDr+cbImJrKayDn4ogqtWOjLXw9VDbvgRiOt/auvhF6dZ6rKcb2UDfMH/XC/aUWg9rEhRCrKWNs+F9K3f+SEkWYwLZjS6geKLop9aU2tXhdF+rngb4to+AlspInd4Z3jMHfb7a3aTlSKLh1RmzSqtl+alpAaJ+oAC93QfMjnAepB9rKjOXX2DUaRRZK1Pz58xEdHQ0vLy8kJibi0KFDVtOvXr0acXFx8PLyQkJCAjZs2GBwfvLkyYiLi4Ovry+Cg4ORnJyMgwcPGqS5e/cuBg4ciICAAAQFBWHYsGEoKCjQnb9y5QoUCoXJz4EDB4SruJPDdeB1JHaLxWH8FireiRh89FQD1KnqhzK1DSWKY75spvPs1KHstkQZFx/o444RnerYlylBiIwzhWNgg7muQqEAIgMrgtbWrOJjNQ9rfn1S976SK1GrVq3C2LFjMWnSJBw7dgxNmjRBSkoKcnJyzKbfv38/BgwYgGHDhuH48ePo3bs3evfujdOnT+vS1KtXD/PmzcOpU6ewd+9eREdHo1u3brh9+7YuzcCBA3HmzBls3boV69atw+7duzF8+HCT8rZt24Zbt27pflq0aCH8TZAZcl4VxRb7V4ZxKMu+ohxCqVpj9bwYbc5G0bKGGDJ92D0OfZrXsCsPOQ9yneo5Ju6Ss+ECXZpLwTDAax3Yby7dJka+i0IkV6Jmz56N1157DUOHDkXDhg2xcOFC+Pj4YPHixWbTf/XVV0hNTcX777+PBg0aYOrUqWjevDnmzZunS/Piiy8iOTkZMTExiI+Px+zZs5Gfn4+TJ08CAM6dO4dNmzbhhx9+QGJiItq3b49vvvkGK1euxM2bNw3KCwkJQUREhO7H3Z2mBPQRW4HQ8DRn6F8ltqFIJdfQ2nrYmloTY3Ue37Yrx97bKv9WEZbGNQKx7JXWUovBCSHbqKq/p8VzMjYWV1q8hYo0Xpl9okpKSnD06FEkJyfrjimVSiQnJyMtLc3sNWlpaQbpASAlJcVi+pKSEixatAiBgYFo0qSJLo+goCC0bNlSly45ORlKpdJk2u+ZZ55BWFgY2rdvj7///ttqfYqLi5Gfn2/w4/KI/ADzHYc/SKlvV7lcOndnGKxtOWdyrQSbKUwNA1Tx9eCWsR5yjljuKGqH8o/4Xtno17IGnkqI0P0d5OOcH7yV4bHnWkc53xNJlajc3Fyo1WqEh4cbHA8PD0dWVpbZa7KyslilX7duHfz8/ODl5YU5c+Zg69atCA0N1eURFhZmkN7NzQ1VqlTR5ePn54cvv/wSq1evxvr169G+fXv07t3bqiI1ffp0BAYG6n6ioqLY3QgnRmzHcr5TQu3qhtpVLqfou3aV5BhUSgViqloekMXoozQMg/AA/tHcheg4zbWN1HFluMDlFohhbani64HP+yQInzGAn4cJazVTKhToXK+iXw+xQ4EneMDBgdz4WbXnnZT6fZZ8Ok8sunTpgvT0dOzfvx+pqano16+fRT8rc4SGhmLs2LFITExEq1atMGPGDLz00kuYNWuWxWvGjx+P+/fv636uXbsmRFVkja2O29rAzQZ7/WocgROICMD6gMzV/4hNne32ibJTtXOSZrGOxF/gfp5uaFFLnG03mtUMdgn/S7mwcUwHDO/I3s9In1bRwQJLIyxyfkokVaJCQ0OhUqmQnZ1tcDw7OxsRERFmr4mIiGCV3tfXF3Xr1kWbNm3w448/ws3NDT/++KMuD2OFqqysDHfv3rVYLgAkJibi4sWLFs97enoiICDA4MeVUcD2QOXv6YbNb/MP6mfvMnm+yPmlNUaKFWesVuc99mXv1jDcekILiOVqJmfHcGPEmNLksus9l7RcEbpm2v5IOtXZ3gUL9tIgMsAguCwX+IaS4YuQj7XUH7GSKlEeHh5o0aIFtm/frjum0Wiwfft2JCUlmb0mKSnJID0AbN261WJ6/XyLi4t1eeTl5eHo0aO68zt27IBGo0FiYqLFPNLT0xEZKf/9st59sp7UIhhgzwsj9QvCBqlDHHzYPc7uPNi0UaA3Nx+TckVr3ovNEV+N+weFvQqEpavtHmidRwczy59vtLOZpk1MFfh4qDDz+caCDngTn24oXGYCM+M5+6YtnWB9iVnWv9Xe4WU6Q7/OFsmn88aOHYvvv/8ey5Ytw7lz5zBy5EgUFhZi6NChAIBBgwZh/PjxuvRjxozBpk2b8OWXXyIjIwOTJ0/GkSNHMHr0aABAYWEhPvroIxw4cABXr17F0aNH8corr+DGjRvo27cvAKBBgwZITU3Fa6+9hkOHDmHfvn0YPXo0XnjhBVSrpo2QvWzZMqxYsQIZGRnIyMjAZ599hsWLF+PNN9908B3izptdYx1TkEIhugLhqOm8uAjD6M3OMssg1A7nbKqrPzXLbjpP+7+Hm5KXEuUsbSAmXAZmNsphTFVf1I+wHan81fYxODU5BY1rBLEXgAX6exnKrX1faF1TahEkwcfDzer5qb0bscrHHguvrf7E2rSv1PqY9bvnAPr374/bt29j4sSJyMrKQtOmTbFp0yad83hmZiaUygpdr23btli+fDk+/vhjfPTRR4iNjcXatWvRqJG2oVUqFTIyMrBs2TLk5uYiJCQErVq1wp49exAfX7EHz6+//orRo0eja9euUCqV6NOnD77++msD2aZOnYqrV6/Czc0NcXFxWLVqFZ5//nkH3BXnwdYD3Lelfc71jprOc1MZvqSctn0RWhgOeLoJ8x1krpNqFR2Mw1fuVaTRO8cqxIEM40Q5G1JOPYoRusP4iRC6BEuPnCPeUaEeVz75rBzexq4yPd0sT9vaWy1LwTZdBcmVKAAYPXq0zpJkzK5du0yO9e3bV2dVMsbLywtr1qyxWWaVKlWwfPlyi+cHDx6MwYMH28ynsmOp0+oQG4q3k+uhWVQQSmwEerSGo1yixPyKkgvWlBLOcaIcsO2LEDhL21hC8MGGx/0Qa7xzJt80NkhZn/JglHwf9+QGYRbPGT+D3u4qVPH1wI28RzxL4/5eyvlJkXw6j3BNvNxVaFErGEqlAl7uKtYmYWMcNZ1n3FFwi1ju5CM1L9jEiaqM90VYhLbGsW0Rp7QUGAmtX1dHVMcp79lj3FSWVQG5r5KV2ieVlChCFIyjVQd48TN6OkyJckgp8oXrAMCmWVxVh3Lks+Jqz6X+M6FQCKt4+Hsa9jH6ZTnXdJ68Wp2tOFzENk7rzH0FKVEEb6y9M8bKD9+XRA5TQjZxAhFtY7sHZCz8bgn9tpNiqqNGsLftRDxw5BinFLiHlvqrXUxeTqpl8Fw62hIqN+VHKIxrNe1ZfrMK+nCezrNya6V+okmJcgHeeqKu1CKYIJTuI1Wfz7Y/HJcaJ/lLLAXstn2R5s6sGt4GPRIiMaNPY1GmWh2pEApdFp+7IZVy4M/Bet2+bii83A2do119OrlmFR+TY0IpyfobWRs3/3Mc42G5eDPIw7GcsI9mNeUXbdbX07BD49sPO8oSZTxQsBm8PNyUGNm5DvZeyBVLLIfBeTqPTRoJOs+4CH8kxoQgUYBd32NCffFfbqHJcUfqFJx885xssFIozL9nibWrwE2lwEdPNbB6fXSID67ceWjxvIb/epZKTfu6oXDXW61sryJf3YxFmO1znRJvO1Cv1M89WaIIUfjEKKietQfdWqRfqRzL2RAs8AanA1qLu9eikGM/m2YxVqTZEuDlhh6NuQW1HdI2GuEBnvh5mOVguVzxtxBc1KFKlMD5ST3gsKFpVBB+fbUN4qsFWk33agfrW5w4fDrPwfmYs7KKUmM7K9Y0KghuRuEy2DbN7H5NH4sg36lSUqIIDGkbLWh+H6TWR2Qge38U/UHp02fiDc7ZCgQnFMavqBSr8wYmct96YVj72oKUba661jouNjWe0qvCd4Lt/Xy9UwxOTOqG+S82Z3fBYyY/E48D47uiqr8np+v44NDpPMFX57F7VvWLlWuIA3O3Rn9wdvXpPHGfQ4WZ3yrgOm14ZkoKr21xfD3lP1lGShQhyLYhtrA2FuifGmyk0KXEh6NHQqSJZUtoTKfzWFzzOJWUfXXn+tr4LtWD7HOi5r46z3qlX+8YgygzPhvsZOEmTLnVytx1ch5HlwxtZTONq/kqO9Kx3Y7wdE5Bw0jtLgDGVh4hMFCiWT6E1lJ5uqnQVS8WFefnWsbvgfzVPEK2WHoRgrw9TI5Z6zutvVBuKiXmD9RaJaauO2s2TaifB3ILSixnIjJyGKdf7xSDiX+dETxfD5USJWoN7xAVXOH6dX14QjJC/UyfNzERQrEJ8HJDl/qWAxzqyuKQp7OFnbA3xIGtZ0VfYZNTvW3B9p4EeLvh+CdPwtPdPluIl43r/XhOyxvDtan/j0NsQYZhJFsAQZYoQnCeb8HNbGu/WVqMLzHHv5DuVgLeiY2lNvhjZFt0rFcVK4cbbvAtl0HJ11MlXltZqKQQ5bHNw95NmG3Rto79DvjWMJ6eZwWPKpffJv3pSlefzgOAYF8PA5cHPlU253qhb91KbmDbuZsNXB/ll9pwd2+QAlKiCMGnDDwE2s+NLULIb+ITxaFcoaYo6oX7CZKPkCTUCMRPr7RGw2oBBh30O09y2+RajIB9rsbmtzuaHBP6fhg/qmx8yIxlOPhRV6x/qz2r8nw8xNuTzda94bOw9/2U+vyEkQAhfKKq+JpacRUK4KOnGiAy0AsfPRUHN5XSZIN2fljxsbTRh9pqayn1ZVKiCMmxN6CgEOOMPYOVUNYCKYP1cS26Ra0qNjLkKQfn9NavMFsvOztcsVqpvpmBqmYVX5FK0/JeN/NKg7X7GuTjLtjG18YEertjWDthFksY75rgLNijHHF9jy0lj6rig/0fPoHhHevwKjsm1PS5ddUPJFKiCN4vrXDvhPRvl/E94PLCJ4k8JSIUbJ37rR/kXbqQmbFmZKc6qOrviTc6sx8MbOGowaBvixqcFn2wURnCAgwtT1FVfDD9uQSOkrH/8rcWMNPcR8OxT55EWIAXq7zNrxqr+L0yTOcZI2QkcHs+6mb3b2qaH+/czF+r76cpZUuTElXJGNOV2zRMOR4qJX56pbXA0giDGIMalw7EXaXEDJYDUZgDluALhqA9E/el9UKkDwvwwqGPuuKDVD1lxM7nxVGWz1l9myBIoFhky19NRIfYUHzVv5mpLDauNfnAgMJma07u2RC9mlbDkw0jkPQ48Cmb6WqVgCvN+Bii7HJ0d/B3grnyuN8+dhdwVs7MHRP4BrWMtmENdxCkRFUyIgLZfeUZUyvEBx31tgIQEq4vPtclvV/0bQIA+Ogp8UM52OK315NsJ5IAV933CzBTN3un85zwXrWtG4qfhyWiZoiZrUJ45Gdrte2QdrXx1QvNoFIqMO/FZng/pb5JIFQF7FM8fGzEEFLzsESZs8oPSnKsg7M996Rz/TBd6AMhsRVfzFjZN1cHa9XitR0Rj2vEgJQogvdLK9RgwvXr8/M+jQ2mZ2z5JD3fogZOTe5mdX5/aLtoTjIAhi8x205ArPE3xFcEC5cE03lyjkxsji/6NkGbGPG+iPncjR8HtxRcDn0UCuuDqsroIQ/x88SoLnURHuAlmHGzWc0gPNUowuS4wSbZfJQoMzf8neR6nPNxBOZk9XBTYsOYDujXkt0Kabb9kbXtt/6vdyNseKuDwTFPN9MFBfpl9WxcjV3BumvZh7NwNKREEZLTIyEStUN98UIrdtueVPH1MJieYdMP+HtZnxZpWyeUVdn2IpaSkGpmQBEaR3RTzmDk0df5n29RAwsGtpBOGDN0bRBudVUcKwyCLXK7lO1CC675+utZnr57qQXcbIQEMRz3+T29beuEOMUzyRe2VbOmo7zUphaqGQX7rRfuh74tahh87Orfx1eMdlpwZvc1CrZJSI63hwo73u2k+9ro1bQa/kq/yfr6VrWrcEpvFjs7Sqk7AXt9SeQyUHBenSeJ3JYLVSikexYcFVxSYSN/9uEsBFpKZgE+juXGRSwZ2gqPStSc87EH9tW0FjJACEkqML6X5rLX/0BUKBSY9diNwtx5IX3fLMnjKMgSVQkx7rscMQ7ZmlPX71CNpwNMExv+yWWfPovwckKtEESo/fOEpFV0sNQicEcu2hwH9EXuGidMYEJ7eaV9NADgyYbiyGNOQekQq7XmWvMhsmdwZ2XhslORNC7C3LSUK8H2dRMkWoQ9TvvmjsmkqyBLVCVk9/td0GHmTrPnHLGBqzHGU1xc31e5vExyoXP9qujZuJrBXlWA9alEoe+hPSEj7CnHETjyeeMbg+yd5HroXD8MCdUDBZbIsgXp24HNceLafSSK5CPmiPtuV4wmvWujQ3xw5c5Dq+kjAryQlV/EvzwrorL20WS7Ok+Aj0Qxm4+CbRL2weHpTImPMNkYVr9T/GaA6RJoIRBzsBMkZwGn817vFGNfZnbi6+GGPi1qIMjHMBpxfDXLq3bYtI8jdAdn0Ietych6KotlWUqlAuvfao81b7RleYUWN5USraKrwMtdHEuKuUHL212F9rGhjtm+yIEPCp++y1wkcGN2vd9ZtJAngk/nCbCZs7HflD62ZyrMHrVPIIEgJcrJqervqYvDwgZbL3eABQdsrktWjRFyuis2zDDejNj7i7FBv3bjuzdAVBXzHYaUok7qyW0fM2NR7WlBc9Ue+djp1J5AmI66n/phNaxaAET4Io6vFojmNR07Ncvntood+oHre15uhQsPYK+oCFUFu+6F9N2ZCWz8y2xVuV64P77o2wS/GIW64Eti7Sp4r1s9vNetHo/4WMJBSpQTE+jtjrQPnxD0a9OSsiOqo6pxGB8Lhe35oAv+Ht0ONYKNLWliScYfOS7VD/RxtxjKQYp7+EFKfWx/t5PBfmVybEsAeOfJimXu5oJPVmD+2Z3Us6EYYgkCn0CKQvUHXPLh+mgsGtQCr7Sr7bDYbA4PtmnlHNuPVnMytzYTxJKNEuXGYv+u51vUQPtY+1dCf5BaH0PbRWP0E7EY/USszZWaYkJKlJMjxMPjmGka+0uJquKDxjWCzOTNn68HNMNfo9rZkYN55KoM6NO8ZpDudynEVSgUqFPVz66vdlH9LCyVyaPQtnVCcWFad7vk+biHZQunmJirrxQLKdhsUaIvVWSgNyb2bIhaIb72KX1G5cZUtb2foRO8/gAM5dz1XmdM7d0Ir3cytQwbO5anxGtDqujvkTekbTTqVPXlvSuGdTkN7+hLbWpJqjjpQ47lBCvsVQq4dLqc+zuFwmBpOZed2J9pog36dv9RKddSDZE6xoE+LKeb1rzRDtEfrhdfHg7I0YInBAoF7PYVerVDDIa1r43a4zcIJJVlrCm2UoVx0JdJrOdEqClJ+2bzpHkHokN9EW1m42DAdHbgw+5xSKgeiE71K3axCPRxx/Z3O/MqW4htZaRCHqocwQvh5u+FyUcqFDB8qUZ1qetwGWSkQvGCz+DRwYpZ3iSMho3sezWtBneVAgNaswu4KiUmvjl6f7IdDJxx6xh9zMcJEhd78hfa4d92PmxXvdlRhvX5PJZ5sJPT2BLl5a5CnxY1EOrnmNXccn5dSIlyYjSCBO8wRLQvPDFX5ymA7wdpt7qY2aexaOWYK9fiOYdJwQ0hO6OX2wi3p9jc/k1xdkoqwgK47e3IRxmx+62RaeMKaR2K0GsH43tsjwJozzQgxzBRrI7zKYNV7S0kSm7ALW7Xopf5RcMXemTgE7hUSIyLl9NHCE3nOTFSWz+4PMdi+lAooEDXBuG4OK27ZPPk9rzk373cAvXD/VmlDfR2t3/q0Qx8uiQhAzkqFAq4qxzfMcZF+CMj64Ho5Qhm4XDA4DHz+caoH2H9eZRirzKpprmE3L/6k6cbYNu5bNbl1Qv3R2yYHy7kFHAqR+j2EeOD3VUgS5QTI9R7wqZjdmQHxnl+/LFoUjoaGndaXO5WSnyERV8EfZa/lojUeJH2yOPRvNaeG0eNsbyW4otYpisMNf1a2p5SFWNMtRV+xS4/I5vL77VhU+yaMrTwu8X0LAuzuMBBgD6ZtQwSP9jGH+HysUOREuXUCGFi9XAzfAQshjgQcXiIMgpZwBWpXigxjAJLh7ZCy1rmYwK1rRNq93SDXY+M1D2pQLCtxf/1bgR3lQLj9Da7BsxNbwkkmJNj733400ZAUX1fNEtlWbLAWHt0D4zvinVvdnicr7iO5foBcFUKhc1XyvqKRMvnWEcsZ1ldsafzbOUu566HpvOcGDk/WGx5rll1BPqYD/DJFqWUkdYswVOkzvXD0Ll+GDacuoX/W3cWN+/z3xaCC+bEFfPLXyjELKdxjSCcm5IKN5US83derChTvCLtgu+Hjs1o0RauEhrjCPuOIiJQ3//L9LyQ7R3o7Y7VI5LgrlJatJwbWrTk8bTRbJ5lyBLlxIhhHbL00po7LsQLPrt/U5Njzvi+Gsts7515KiES+8d3NTlur9Jg6Xo5OWqKDZeamhvo+NwqV7u9/hZ2NrCJM77cRrCaqrOSqlV0FTSNCmJdnhT+Z8ZI7lhu9Lec3idSopwYMb4OQv2l+RqUGsE34BXpLQ/xrVhSzKcIS32h+MvT5RPXR/8W8Lne+Ar9v9kOeDIaA3hRL9wf7z5ZD0PaRguWp6WmKA9u2btZNcvXPv7f3i6RTbuwKSM23M92Iha58V0BzHo1IttQDBLrcXKcbCiHlCgnRsgvlN9HJGHZK60R5q81bXPZb0pqZLF3nvHqPJHKGaG3z5yQZcjgFjoNVh3qHSiHo7BU3Te7xho4ofNSaFncsL9GtcMfI5PwXPManPPnijnXAHP1GpxkPbxH3TA/zO7XhJcMQnyACe0TpRbbJ8pG9j4ebgbb0chlmhMgJcqpEdIS1TK6CjrVq4g+y+qdkclzLIQC4O/J3T2wWmDFFhxCd1qW8GMhZ80q9jnqi4ErKWlyrYo0UcQFzMvCcX8vd7SoVQUqg4jl3GB7a3o3rW4zjQLAp70a4fz/pWLGcwkW03XU60/tQQ6KudTTeQAw/qk424kkgJQoJ0bMuXIpXxmu9RKiH+f69VcrxMesP1dFfuaPB4voPLv81US81KYmRj/BPWI7my876btR4WHb6j0b600lyUSL6t8yCqF+0k6/O1I5tifYJlt8OXxMebqp8ELrmqLIwQbrIUaEnVaWgQ5lgJw+ykiJcmLMWaKqBXKL+GwJti/NWzwGbKER64X69dVEhPp54ofH0dD1WfRyS1QP0rNEmcSJMhRq+7udsPntjpw6aVsYd6Jt64bi/3onwMeDexnmVyXxv7Ey6uOswvbZqRli2brHRgF/WKJmVU7/x9NjPRIibaZ9ukkkWlgIh8GFQG/+q2OF3PbD1n2U0xSOOUxCXwiSJ7/r2FvG5X1PnQEKceBiCGVCZss7T9ZDv1ZRmL/zIlYcumYxnZhfMmJ1ru3qhuLwhK5mOxpbfY/x+TpV2TqaEnLHmg+epee8oLjM4G9LWXzaKx5PNY5EYu0q5hOIQPdGkQCOWzxv7f0K9fPE8lcT4eWhYlWWaHvFiQifYs1ZghpEBvArTwZWoNFd6mLezovo11IsvzTblZTBbTALKVGVHHtdZBUKBWoE+4g6TWVbBjHzdo7VK/ZSI9hb1O1P5Pq9yytcAY9y3FlG0/dyVxn4JtpCiOdOZefSp7Z1LW9EzQVbUjiT0YRts9gOtilupdnmPvbJekiJj0CDSHbbU1UmaDqvkmPpHebqtD6ycx08EReGuRb8hLjts0ewQYjudeXwNuiREInPnrXsIEtYh007WIpCby/hehsFf5AqT8dbMZB71HjBtuSyds5qjAMBCtBDqVQgoUagpFtryRWyRBGssBXJ19/LHYuHtLJ4PadOhfPeeTLrQSGcTANa18SKQ5l4OzlWkPyMaRMTgjYxIaLk7aqw3W5j4tMNMWXdWXz3cgvRntH3utXH3cISPBEXJuiG0PrI5fViE8qES9fxfkp9dIy1bfUzLtaPRaDRqv6evNpcpVQIuuGxOZrXDMKxzDyBc3UscnkmAVKiKj2WnkU5RMllixzeJ+Po8W8nx+L1n4/ane//9W6EwW1roX64qRnd0R1Jnap+OHn9vmMLFRk+/nTWrtE/80r72ngxsSa83Nn5C/Eh0Mcd8wc2Fy1/oYmLsDwdxNXPkAvm+rPhHWNYT7OW4+/pZjX+04KBzXHk6j30SIhE3qNSTnnveLcTQvw8TWS11Bdbew6t7Wax5o12iP5wPSfZxMaJhhsTSIkizCL0My3mgC/HaLYp8RF4oVUUVh627GzPBpVSgbgIdg6pbHi9Uwx+P3odz7fg7iA68emG8PFQoQ+Pa+WK2Fu4iKlAOSMhfp7Y9+ET8H3siM5l6yqhF5Dwye1/b7ZHdKivxfPdEyLRncXKynL0ax/zePFJ3sMS3THeq/NYRyx3TuS0UpOUKMIsQn8ZiLo6TwLbrnGJ5uon5PJvoYgM9MaJSd14ORMH+3pgGk/fKTlNudprZTWuiv7fcghKKDRCt5x+aBDDcmyEOGAVJ8qC1UbE58/bXYVHpWp0ri/Mymi2CoLVaWW2SpSM3ktnhbzEXIz4asJYLaSczuO6sbIc+gEp7hbfrzF7V2OZo26Yn0H0Zjm0CVeWv5rowNKc5wbJRS1UWPhdn6r+5j9czPVnbBUI/ffM3CX7PnwCv49IQuf6YUbX8UO//1NAIZv7LzX6TSin/oUsUS7Chrc6IO2/OxhgIYKuMdWDvHEj7xE6xJpfnuxML66M3icDuCqDnBG54lw7qhda18SHa04BAGpVsTzlISf0q8h2qX5l+3p3lHXNtk9URQJLEj3duBrSr+WhVbTj4mxV8fVAFV9xyhP7UZPLk+xM440xpES5CA2rBaAhByvU6hFJ+Cv9Jga0jjKfgMVTLZexRIrVZSYraJy5F7AAn2X5K15rg4OX74jiNxXg5Yb8ojLbCUUmMsBwVwA5+Wc4G1zeG/13znSHAC0qpQKTesazy4990bLEeoQDtnH+hJHF0chJbFKiKinVgrwxsnMdi+edQSc4/smTuF1QjFgzK9cI+5j4dEO8mMjOqglUDGpJdUKQVMe6UvvLsETEVOVuqdK3RIQHeOLV9jGc8zCTKeukPwxqic1nsvBqBwHKFQBHKW9y+UCQauB0tKJhMG0Fkf1JZaKO+Hm64W5hie2EMoR8ogizsPGJkvoFDPb1QL1KrECJefdfaV+b08oyW0+Lvq9e+9hQVLPgXMyWCT0a4rWOjlVmkhuGY1bfJvBmucWJ2Ig+XfwYMafzuCgobKbzxCpbrPzt8T3l4li+4rU2qB7kjSVDLcfyk4IfBrVE/XB/LHypBYvUMtHmjSBLFGEWKR9XuXz5coHLgBZT1Rf/3S4UURr50ad5DRSVqtGiluN8VeSMs06jCA2n6Ty9311xFWQ5BjUTaAPipDoh2PfhEybppH4OkxuGI5lHkFg5+SWSJYowiwv3UaLA5X6tfj1JPEFkilKpwMtJ0Zz89qwhVBcqdFfM9b35ILU+AODzPtxDR1S66Tz96gogk5wGYn1Mgm3K1AJDaCElqhIQG6YN4sZ2F3HA9MW1d/CLCPSynai8bBfvM0IEih8l0zHAIbDZAoQNUt/DNzrXxYlJ3dC/FXv/s8qKPdN5ztSl6MuqgMJifyhXJZAv695szzqtnGpO03mVgOea18ATcWGoFeLD+hr9F3d4xxiM6lLXLhmSXG5/Nhb7eIke4UBGXYmDRqnBSbVw/FoekhuG2U7MggGtauJ4Zh5aiLRBMBsCvW3vxSYlcpk6M1ydZ3zOMe8Cl3fOOK25K23dWWvVsro6Tx5NxolG1QPxVEIENpzKkloUTpASVQkY0jaaszPsokEt8crSw5jWuxFesBB7iqtT6PZ3O6Hrl/9wkkNMFg9pKVhezrTXoDPzaa9GgubXt2UNNIgMQGy4nyD50dQLN7jcLcPZPHb7y5m7VirY1tWRXYncrFnsI62LKwcXSIlycTrEhvJaTdSpXlWcn5oKNysbdDauEcQpzzpVhRmohGBQUi08ESfcrvcqpfPPjHu4KVFSpuF2jUqJErUGLaPFt+SI0XEqFAok1AgUPmMXQi7fB/oDvoajTDKpAmf4hzhgGSeKT9aEAc7f8xOiYU2BAoAxXWNFKdcRX/NCDwwD29REbJgfRnWxHHtLaIRWKla81gb1w/05bX+y+Z2OeD+lPj55uqGwwoiItabvVE+7/1k3DiuGXN36JJfaGViijINtysk0YQHBJRRg7zxnQq51IksUwQt/LzfZxMuRAuM+O8DLHVvHdpJGGIFoUSsYm9/pyOma2qG+dvvLyYlvXmyG7eeykdyAn5WS9XQEr9ylwVFT1bb0IP3FBHIdUA1g0cj9WkZh0e7/DHYHEEIpZ5uDE+ieZpGT0kxKlBPyRFwYdmTkoHnNIKlFcVrseQd9PVSICrbtpC92Py+fbsS5sHbfArzc8Wwz4bescWbEfI693Cus3bactvU3zuYSCFYumLuP73Wrj8TaVdC6dhWzCcVWFmSkizgtpEQ5IXP6N8XfJ26iR0Kk1KKIghy/MjvVq4p//r2NLe90RK0QH3i40Uy4o+jWMBxbzmZjWLvaguQnw8dL1oj5PkYGemN0l7rw9lDZfKc83JSY8VwCikrVqOovTJgQqfFwU6KrkdXTS8/C7+mmRFQV7WbxxshqdW4lhpQoJyTQ2x0vt6kltRiViqVDW6GguAz+XvJeju6KfPNiM5y79QCNq8vfAVyOHwD2ohR5rH4vpT7rtBZXCnMob3BSLYTyjNVmj+WG7aUBXu6Y9XxjKBUK+Hq6YXa/phi0+BAu5hSwLkt/CvbwhGQrMslLEbP2/sj11SIliiBYoFAoZKdAyckvQEw83VRoGhUkWH5i3jVXdDKvHcp9s2hHw+Wu2xMmg9M2NUYPGhcZ+7aM0v1eLcgb3w5sjm5zdrO+/pmm1bDz/G3UDvW1arUTW0GuDMhiTmL+/PmIjo6Gl5cXEhMTcejQIavpV69ejbi4OHh5eSEhIQEbNmwwOD958mTExcXB19cXwcHBSE5OxsGDBw3S3L17FwMHDkRAQACCgoIwbNgwFBQYavonT55Ehw4d4OXlhaioKMycOVOYChOVAle0SrgCYjYL2y97Z9J/FQoFvh7QTGox7MIV30Vrz1DvptXxx8gk/DW6ndnzU3s3QqifBz5/vrFI0vHjrccrvp1ppkVyJWrVqlUYO3YsJk2ahGPHjqFJkyZISUlBTk6O2fT79+/HgAEDMGzYMBw/fhy9e/dG7969cfr0aV2aevXqYd68eTh16hT27t2L6OhodOvWDbdv39alGThwIM6cOYOtW7di3bp12L17N4YPH647n5+fj27duqFWrVo4evQoZs2ahcmTJ2PRokXi3QwCgHzNtgRhC2e1RL2TXA8A8HrHGIkl4YejdFJHTOcJgUKhQItaVRBgwXr+cptaODwhGXERwuxlKRQNqwUgY2oqpvYWNqiumEiuRM2ePRuvvfYahg4dioYNG2LhwoXw8fHB4sWLzab/6quvkJqaivfffx8NGjTA1KlT0bx5c8ybN0+X5sUXX0RycjJiYmIQHx+P2bNnIz8/HydPngQAnDt3Dps2bcIPP/yAxMREtG/fHt988w1WrlyJmzdvAgB+/fVXlJSUYPHixYiPj8cLL7yAt956C7Nnzxb/pjgBTvQhLRliWxuoDeSBt7sKbeuEoGlUEKoHsd9aSU681bUudr3XGR92j5NaFE5EPt6TM6VRhGhl6L/HbirXeevk6g7gbCsvJVWiSkpKcPToUSQnVzi+KZVKJCcnIy0tzew1aWlpBukBICUlxWL6kpISLFq0CIGBgWjSpIkuj6CgILRsWbHtR3JyMpRKpW7aLy0tDR07doSHh4dBOefPn8e9e/fMllVcXIz8/HyDH1fFOb+3K3BE9yH6FII8+8BKh0KhwK+vJuLPN9o6rY+JQqFAdKivbAdWS2wc0wG/vpqI55uLF5bC002F1zvFYFBSLUQGerO+Tuw76VwtZT9ynZKVVInKzc2FWq1GeLjhEs/w8HBkZZnfhDArK4tV+nXr1sHPzw9eXl6YM2cOtm7ditDQUF0eYWGGG5i6ubmhSpUqunwslVN+zhzTp09HYGCg7icqKspsOkfw0VNxCPZxx6Se8ZLJIGfk5iROODcKhQIKhcLpPy6cjSAfD7SrGwqlyNrr+O4NMEXgfRvtxcn0XZdF8uk8sejSpQvS09Oxf/9+pKamol+/fhb9rIRi/PjxuH//vu7n2rVropZnjeEd6+DYJ0+ibpg4+9WJusJJxJFo5vON0SE2FK93Et/3w1n9Ywj+OHbzWMeV5ewbbEsR18257xjBFklDHISGhkKlUiE7O9vgeHZ2NiIizM9xR0REsErv6+uLunXrom7dumjTpg1iY2Px448/Yvz48YiIiDBRqMrKynD37l1dPpbKKT9nDk9PT3h6yicInJim+bhIMR0Sxet++rWMQr+W0lkIhYQ+RCs3Tq7XOJSJTzfEhewHGNZemICtfAgLkM/YQAiHpJYoDw8PtGjRAtu3b9cd02g02L59O5KSksxek5SUZJAeALZu3WoxvX6+xcXFujzy8vJw9OhR3fkdO3ZAo9EgMTFRl2b37t0oLS01KKd+/foIDhZ/x3q5suntDhjQuia+fsG5lzwThJTILcihqxNVxQe73u+Cl5OiJSk/LsIf059LEDTPyvYMydUaKvl03tixY/H9999j2bJlOHfuHEaOHInCwkIMHToUADBo0CCMHz9el37MmDHYtGkTvvzyS2RkZGDy5Mk4cuQIRo8eDQAoLCzERx99hAMHDuDq1as4evQoXnnlFdy4cQN9+/YFADRo0ACpqal47bXXcOjQIezbtw+jR4/GCy+8gGrVqgHQrvDz8PDAsGHDcObMGaxatQpfffUVxo4d6+A7JC/iIgIw/bkERDxeFUNIh7M5AVcGHDmFS83vPCwZ2oqTU7ox5vQHan95IHnE8v79++P27duYOHEisrKy0LRpU2zatEnnxJ2ZmQmlskLXa9u2LZYvX46PP/4YH330EWJjY7F27Vo0aqR1+lOpVMjIyMCyZcuQm5uLkJAQtGrVCnv27EF8fIWT9a+//orRo0eja9euUCqV6NOnD77++mvd+cDAQGzZsgWjRo1CixYtEBoaiokTJxrEkiLsY0oveTq9U+fk2tSP8JdaBKKSIYbVqFO9qoLnSXBHciUKAEaPHq2zJBmza9cuk2N9+/bVWZWM8fLywpo1a2yWWaVKFSxfvtxqmsaNG2PPnj028yK483rHGAyyYFqXymr7/aCW+HjtKczt7xxTlaTs8WNY+9ooKdOgc/0w24k5MrJTHaw5dgP9Woq35J5wPuy1UBq/6+vebI9GTrCXZGVAFkoUUfmQY9C6JxuG48mG4bYTEk6Np5sKbz+O0C00seH+yJia6nQBAwnnIcDLjRQoGSG5TxRBuCzy9IMkRIaNAkVWxMqFkNN55AspL0iJIiShsq0sEQO6g4SjkOnCKFlD96xyQEoUITuo7yEIy/h7ar0wGlWjKR1nQUjjUWU1RMl1XCCfKIJwUkL9KHhfZeTwx8koLtUg0MdxWxdV1oFbKMgq5bqQJYognIxfX01E69pVsOClFlKLQvDEHp3Ey13lUAUKICWAkJ4qvh5Si2AWskQRkmDty1aukWm5IlYt2tUNRbu6oSLlTjgC13jCCbYIOp0nXFZORb1wf3zcowHCAuQV6JmUKEISkmJCpBaBIAiWUIBSQg682kH8jeO5QkoU4VAOftQV/90uRFIdy0pUp3pVsfP8bXhTrB3CRXE2a0KDyAD89EprVAuSlxWAIKSGlCjCoYQHeCHchjn25aRoVPX3QotalXejZ4KQGx1pmxFZQHGi5AUpUYTsUCkV6NE4Umox7MZVfLsIgiAI89DqPIIgCIIQGpG+ocgOJS9IiSIIkSCzO0E4H98PaglPNyW+HdhcalEIJ4Cm8whCJGg6j7AEKdjy5cmG4Tg7JRUqJbURYRuyRBEEQTiI8i1bWteuIrEkhDWEVqCEzI30b3lBliiCIAgHsf6tDvjfyZt4OamW1KIQTgtpUXKClCiCIAgHUTPEB6O61JVaDMIBuLtVKDueFPPOZSEliiBEglyiCKLy4uPhhi/6NoFGwyDQ27F7HRKOg5QogiAIghCB51vUECQf8nGXL+RYThAEQRAypk5VP6lFICxAShRBiMRLbbTOw90ahkssCUEQzgyFxJAvNJ1HECIRHeqLs1NSaCNlgiAIF4WUKIIQER8PesUIgiBcFZrOIwgJ6BAbCgCIi/CXWBKCIJwJmtmTF/SZTBAS8PULzfDbkWt4tll1qUUhCMKJ8HQj24ecoNYgCAkI9vXA653qICzAS2pRCIJwAua/2By1Qnyw8KUWUotC6EGWKIIgCIKQOT0aR6JH40ipxSCMIEsUQRAEQRAED0iJIgiCIAiC4AEpUQRBEARBEDwgJYogCIIgCIIHpEQRBEEQBEHwgJQogiAIgiAIHpASRRAEQRAEwQNSogiCIAiCIHhAShRBEARBEAQPSIkiCIIgCILgASlRBEEQBEEQPCAliiAIgiAIggekRBEEQRAEQfCAlCiCIAiCIAgeuEktgCvDMAwAID8/X2JJCIIgCIJgS/m4XT6OW4KUKBF58OABACAqKkpiSQiCIAiC4MqDBw8QGBho8byCsaVmEbzRaDS4efMm/P39oVAoBMs3Pz8fUVFRuHbtGgICAgTLVy64ev0A16+jq9cPcP06Uv2cH1evo5j1YxgGDx48QLVq1aBUWvZ8IkuUiCiVStSoUUO0/AMCAlzyxSjH1esHuH4dXb1+gOvXkern/Lh6HcWqnzULVDnkWE4QBEEQBMEDUqIIgiAIgiB4QEqUE+Lp6YlJkybB09NTalFEwdXrB7h+HV29foDr15Hq5/y4eh3lUD9yLCcIgiAIguABWaIIgiAIgiB4QEoUQRAEQRAED0iJIgiCIAiC4AEpUQRBEARBEDwgJcoJmT9/PqKjo+Hl5YXExEQcOnRIapFsMn36dLRq1Qr+/v4ICwtD7969cf78eYM0nTt3hkKhMPgZMWKEQZrMzEz06NEDPj4+CAsLw/vvv4+ysjJHVsUikydPNpE/Li5Od76oqAijRo1CSEgI/Pz80KdPH2RnZxvkIef6RUdHm9RPoVBg1KhRAJyz/Xbv3o2ePXuiWrVqUCgUWLt2rcF5hmEwceJEREZGwtvbG8nJybhw4YJBmrt372LgwIEICAhAUFAQhg0bhoKCAoM0J0+eRIcOHeDl5YWoqCjMnDlT7KoBsF6/0tJSjBs3DgkJCfD19UW1atUwaNAg3Lx50yAPc+0+Y8YMgzRyrB8ADBkyxET21NRUgzRybj/Adh3NvZMKhQKzZs3SpZFzG7IZG4TqO3ft2oXmzZvD09MTdevWxdKlS+2vAEM4FStXrmQ8PDyYxYsXM2fOnGFee+01JigoiMnOzpZaNKukpKQwS5YsYU6fPs2kp6czTz31FFOzZk2moKBAl6ZTp07Ma6+9xty6dUv3c//+fd35srIyplGjRkxycjJz/PhxZsOGDUxoaCgzfvx4KapkwqRJk5j4+HgD+W/fvq07P2LECCYqKorZvn07c+TIEaZNmzZM27ZtdeflXr+cnByDum3dupUBwOzcuZNhGOdsvw0bNjATJkxg1qxZwwBg/vzzT4PzM2bMYAIDA5m1a9cyJ06cYJ555hmmdu3azKNHj3RpUlNTmSZNmjAHDhxg9uzZw9StW5cZMGCA7vz9+/eZ8PBwZuDAgczp06eZFStWMN7e3sx3330naf3y8vKY5ORkZtWqVUxGRgaTlpbGtG7dmmnRooVBHrVq1WKmTJli0K76761c68cwDDN48GAmNTXVQPa7d+8apJFz+zGM7Trq1+3WrVvM4sWLGYVCwVy6dEmXRs5tyGZsEKLv/O+//xgfHx9m7NixzNmzZ5lvvvmGUalUzKZNm+ySn5QoJ6N169bMqFGjdH+r1WqmWrVqzPTp0yWUijs5OTkMAOaff/7RHevUqRMzZswYi9ds2LCBUSqVTFZWlu7YggULmICAAKa4uFhMcVkxadIkpkmTJmbP5eXlMe7u7szq1at1x86dO8cAYNLS0hiGkX/9jBkzZgxTp04dRqPRMAzj/O1nPEBpNBomIiKCmTVrlu5YXl4e4+npyaxYsYJhGIY5e/YsA4A5fPiwLs3GjRsZhULB3Lhxg2EYhvn222+Z4OBggzqOGzeOqV+/vsg1MsTcAGzMoUOHGADM1atXdcdq1arFzJkzx+I1cq7f4MGDmV69elm8xpnaj2HYtWGvXr2YJ554wuCYs7Qhw5iODUL1nR988AETHx9vUFb//v2ZlJQUu+Sl6TwnoqSkBEePHkVycrLumFKpRHJyMtLS0iSUjDv3798HAFSpUsXg+K+//orQ0FA0atQI48ePx8OHD3Xn0tLSkJCQgPDwcN2xlJQU5Ofn48yZM44R3AYXLlxAtWrVEBMTg4EDByIzMxMAcPToUZSWlhq0XVxcHGrWrKlrO2eoXzklJSX45Zdf8Morrxhsru3s7afP5cuXkZWVZdBmgYGBSExMNGizoKAgtGzZUpcmOTkZSqUSBw8e1KXp2LEjPDw8dGlSUlJw/vx53Lt3z0G1Ycf9+/ehUCgQFBRkcHzGjBkICQlBs2bNMGvWLINpErnXb9euXQgLC0P9+vUxcuRI3LlzR3fO1dovOzsb69evx7Bhw0zOOUsbGo8NQvWdaWlpBnmUp7F37KQNiJ2I3NxcqNVqgwcFAMLDw5GRkSGRVNzRaDR4++230a5dOzRq1Eh3/MUXX0StWrVQrVo1nDx5EuPGjcP58+exZs0aAEBWVpbZupefk5rExEQsXboU9evXx61bt/Dpp5+iQ4cOOH36NLKysuDh4WEyOIWHh+tkl3v99Fm7di3y8vIwZMgQ3TFnbz9jymUyJ7N+m4WFhRmcd3NzQ5UqVQzS1K5d2ySP8nPBwcGiyM+VoqIijBs3DgMGDDDYzPWtt95C8+bNUaVKFezfvx/jx4/HrVu3MHv2bADyrl9qaiqee+451K5dG5cuXcJHH32E7t27Iy0tDSqVyqXaDwCWLVsGf39/PPfccwbHnaUNzY0NQvWdltLk5+fj0aNH8Pb25iUzKVGEwxk1ahROnz6NvXv3GhwfPny47veEhARERkaia9euuHTpEurUqeNoMTnTvXt33e+NGzdGYmIiatWqhd9++433CypXfvzxR3Tv3h3VqlXTHXP29qvMlJaWol+/fmAYBgsWLDA4N3bsWN3vjRs3hoeHB15//XVMnz5d9tuJvPDCC7rfExIS0LhxY9SpUwe7du1C165dJZRMHBYvXoyBAwfCy8vL4LiztKGlsUHO0HSeExEaGgqVSmWyKiE7OxsRERESScWN0aNHY926ddi5cydq1KhhNW1iYiIA4OLFiwCAiIgIs3UvPyc3goKCUK9ePVy8eBEREREoKSlBXl6eQRr9tnOW+l29ehXbtm3Dq6++ajWds7dfuUzW3reIiAjk5OQYnC8rK8Pdu3edpl3LFairV69i69atBlYocyQmJqKsrAxXrlwBIP/66RMTE4PQ0FCDZ9LZ26+cPXv24Pz58zbfS0CebWhpbBCq77SUJiAgwK6PXFKinAgPDw+0aNEC27dv1x3TaDTYvn07kpKSJJTMNgzDYPTo0fjzzz+xY8cOE9OxOdLT0wEAkZGRAICkpCScOnXKoNMr7/QbNmwoitz2UFBQgEuXLiEyMhItWrSAu7u7QdudP38emZmZurZzlvotWbIEYWFh6NGjh9V0zt5+tWvXRkREhEGb5efn4+DBgwZtlpeXh6NHj+rS7NixAxqNRqdEJiUlYffu3SgtLdWl2bp1K+rXry/5VFC5AnXhwgVs27YNISEhNq9JT0+HUqnUTYPJuX7GXL9+HXfu3DF4Jp25/fT58ccf0aJFCzRp0sRmWjm1oa2xQai+MykpySCP8jR2j512uaUTDmflypWMp6cns3TpUubs2bPM8OHDmaCgIINVCXJk5MiRTGBgILNr1y6DZbYPHz5kGIZhLl68yEyZMoU5cuQIc/nyZeavv/5iYmJimI4dO+ryKF/G2q1bNyY9PZ3ZtGkTU7VqVdmEAHj33XeZXbt2MZcvX2b27dvHJCcnM6GhoUxOTg7DMNplujVr1mR27NjBHDlyhElKSmKSkpJ018u9fgyjXQ1as2ZNZty4cQbHnbX9Hjx4wBw/fpw5fvw4A4CZPXs2c/z4cd3qtBkzZjBBQUHMX3/9xZw8eZLp1auX2RAHzZo1Yw4ePMjs3buXiY2NNVgin5eXx4SHhzMvv/wyc/r0aWblypWMj4+PQ5aPW6tfSUkJ88wzzzA1atRg0tPTDd7L8hVN+/fvZ+bMmcOkp6czly5dYn755RematWqzKBBg2RfvwcPHjDvvfcek5aWxly+fJnZtm0b07x5cyY2NpYpKirS5SHn9rNVx3Lu37/P+Pj4MAsWLDC5Xu5taGtsYBhh+s7yEAfvv/8+c+7cOWb+/PkU4qCy8s033zA1a9ZkPDw8mNatWzMHDhyQWiSbADD7s2TJEoZhGCYzM5Pp2LEjU6VKFcbT05OpW7cu8/777xvEGWIYhrly5QrTvXt3xtvbmwkNDWXeffddprS0VIIamdK/f38mMjKS8fDwYKpXr87079+fuXjxou78o0ePmDfeeIMJDg5mfHx8mGeffZa5deuWQR5yrh/DMMzmzZsZAMz58+cNjjtr++3cudPsczl48GCGYbRhDj755BMmPDyc8fT0ZLp27WpS9zt37jADBgxg/Pz8mICAAGbo0KHMgwcPDNKcOHGCad++PePp6clUr16dmTFjhuT1u3z5ssX3sjz219GjR5nExEQmMDCQ8fLyYho0aMB89tlnBkqIXOv38OFDplu3bkzVqlUZd3d3platWsxrr71m8sEp5/azVcdyvvvuO8bb25vJy8szuV7ubWhrbGAY4frOnTt3Mk2bNmU8PDyYmJgYgzL4onhcCYIgCIIgCIID5BNFEARBEATBA1KiCIIgCIIgeEBKFEEQBEEQBA9IiSIIgiAIguABKVEEQRAEQRA8ICWKIAiCIAiCB6REEQRBEARB8ICUKIIgCIIgCB6QEkUQBOFAFAoF1q5dK7UYBEEIAClRBEFUGoYMGQKFQmHyk5qaKrVoBEE4IW5SC0AQBOFIUlNTsWTJEoNjnp6eEklDEIQzQ5YogiAqFZ6enoiIiDD4CQ4OBqCdaluwYAG6d+8Ob29vxMTE4Pfffze4/tSpU3jiiSfg7e2NkJAQDB8+HAUFBQZpFi9ejPj4eHh6eiIyMhKjR482OJ+bm4tnn30WPj4+iI2Nxd9//y1upQmCEAVSogiCIPT45JNP0KdPH5w4cQIDBw7ECy+8gHPnzgEACgsLkZKSguDgYBw+fBirV6/Gtm3bDJSkBQsWYNSoURg+fDhOnTqFv//+G3Xr1jUo49NPP0W/fv1w8uRJPPXUUxg4cCDu3r3r0HoSBCEADEEQRCVh8ODBjEqlYnx9fQ1+pk2bxjAMwwBgRowYYXBNYmIiM3LkSIZhGGbRokVMcHAwU1BQoDu/fv16RqlUMllZWQzDMEy1atWYCRMmWJQBAPPxxx/r/i4oKGAAMBs3bhSsngRBOAbyiSIIolLRpUsXLFiwwOBYlSpVdL8nJSUZnEtKSkJ6ejoA4Ny5c2jSpAl8fX1159u1aweNRoPz589DoVDg5s2b6Nq1q1UZGjdurPvd19cXAQEByMnJ4VslgiAkgpQogiAqFb6+vibTa0Lh7e3NKp27u7vB3wqFAhqNRgyRCIIQEfKJIgiC0OPAgQMmfzdo0AAA0KBBA5w4cQKFhYW68/v27YNSqUT9+vXh7++P6OhobN++3aEyEwQhDWSJIgiiUlFcXIysrCyDY25ubggNDQUArF69Gi1btkT79u3x66+/4tChQ/jxxx8BAAMHDsSkSZMwePBgTJ48Gbdv38abb76Jl19+GeHh4QCAyZMnY8SIEQgLC0P37t3x4MED7Nu3D2+++aZjK0oQhOiQEkUQRKVi06ZNiIyMNDhWv359ZGRkANCunFu5ciXeeOMNREZGYsWKFWjYsCEAwMfHB5s3b8aYMWPQqlUr+Pj4oE+fPpg9e7Yur8GDB6OoqAhz5szBe++9h9DQUDz//POOqyBBEA5DwTAMI7UQBEEQckChUODPP/9E7969pRaFIAgngHyiCIIgCIIgeEBKFEEQBEEQBA/IJ4ogCOIx5N1AEAQXyBJFEARBEATBA1KiCIIgCIIgeEBKFEEQBEEQBA9IiSIIgiAIguABKVEEQRAEQRA8ICWKIAiCIAiCB6REEQRBEARB8ICUKIIgCIIgCB78P1l1ykgY0Sa5AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 4"
      ],
      "metadata": {
        "id": "NJExqqSw6IdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator4(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator4, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator4(Generator4):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm):\n",
        "          super(DPGenerator4, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.noise_multiplier = noise_multiplier\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "\n",
        "          # Ensure all parameters have requires_grad=True\n",
        "          for param in self.parameters():\n",
        "              param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add noise during forward pass for privacy\n",
        "        with torch.no_grad():\n",
        "            x = super().forward(x)\n",
        "            x += torch.randn_like(x) * self.noise_multiplier\n",
        "        return x"
      ],
      "metadata": {
        "id": "tS7S0E8a6KTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model4 = DPGenerator4(input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer4 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion4 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "CMz0aC9Q62Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "fCCdDGKS6Jsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model4.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer4.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device).float(), deepfake_features.to(device).float()\n",
        "        real_features.requires_grad = True  # Ensure gradients are tracked for inputs\n",
        "        deepfake_features.requires_grad = True\n",
        "        output = model4(real_features)\n",
        "        loss = criterion4(output, deepfake_features)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer4.step()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model4.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model4(real_features)\n",
        "            loss = criterion4(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iUHQ830T67Xp",
        "outputId": "7e5a6040-75ec-42d1-86e3-f28facea5d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [1/1000], Validation Loss: 0.0382\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [2/1000], Validation Loss: 0.0383\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [3/1000], Validation Loss: 0.0383\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [4/1000], Validation Loss: 0.0382\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [5/1000], Validation Loss: 0.0382\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [6/1000], Validation Loss: 0.0382\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [7/1000], Validation Loss: 0.0382\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [8/1000], Validation Loss: 0.0382\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [9/1000], Validation Loss: 0.0382\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [10/1000], Validation Loss: 0.0382\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [11/1000], Validation Loss: 0.0383\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [12/1000], Validation Loss: 0.0383\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [13/1000], Validation Loss: 0.0382\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [14/1000], Validation Loss: 0.0382\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [15/1000], Validation Loss: 0.0382\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [16/1000], Validation Loss: 0.0382\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [17/1000], Validation Loss: 0.0384\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [18/1000], Validation Loss: 0.0383\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [19/1000], Validation Loss: 0.0383\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [20/1000], Validation Loss: 0.0382\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [21/1000], Validation Loss: 0.0383\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [22/1000], Validation Loss: 0.0381\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [23/1000], Validation Loss: 0.0382\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [24/1000], Validation Loss: 0.0381\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [25/1000], Validation Loss: 0.0381\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [26/1000], Validation Loss: 0.0383\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [27/1000], Validation Loss: 0.0382\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [28/1000], Validation Loss: 0.0381\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [29/1000], Validation Loss: 0.0382\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [30/1000], Validation Loss: 0.0382\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [31/1000], Validation Loss: 0.0382\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [32/1000], Validation Loss: 0.0383\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [33/1000], Validation Loss: 0.0383\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [34/1000], Validation Loss: 0.0382\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [35/1000], Validation Loss: 0.0382\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [36/1000], Validation Loss: 0.0383\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [37/1000], Validation Loss: 0.0382\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [38/1000], Validation Loss: 0.0382\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [39/1000], Validation Loss: 0.0382\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [40/1000], Validation Loss: 0.0381\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [41/1000], Validation Loss: 0.0382\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [42/1000], Validation Loss: 0.0383\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [43/1000], Validation Loss: 0.0382\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [44/1000], Validation Loss: 0.0383\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [45/1000], Validation Loss: 0.0382\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [46/1000], Validation Loss: 0.0381\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [47/1000], Validation Loss: 0.0383\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0388\n",
            "Epoch [48/1000], Validation Loss: 0.0383\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [49/1000], Validation Loss: 0.0382\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [50/1000], Validation Loss: 0.0382\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [51/1000], Validation Loss: 0.0382\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [52/1000], Validation Loss: 0.0383\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [53/1000], Validation Loss: 0.0383\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [54/1000], Validation Loss: 0.0383\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [55/1000], Validation Loss: 0.0383\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [56/1000], Validation Loss: 0.0382\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [57/1000], Validation Loss: 0.0382\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [58/1000], Validation Loss: 0.0383\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [59/1000], Validation Loss: 0.0381\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [60/1000], Validation Loss: 0.0382\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [61/1000], Validation Loss: 0.0383\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [62/1000], Validation Loss: 0.0383\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [63/1000], Validation Loss: 0.0383\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [64/1000], Validation Loss: 0.0383\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [65/1000], Validation Loss: 0.0382\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [66/1000], Validation Loss: 0.0383\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [67/1000], Validation Loss: 0.0382\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [68/1000], Validation Loss: 0.0382\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [69/1000], Validation Loss: 0.0382\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [70/1000], Validation Loss: 0.0382\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [71/1000], Validation Loss: 0.0382\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [72/1000], Validation Loss: 0.0382\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [73/1000], Validation Loss: 0.0382\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [74/1000], Validation Loss: 0.0382\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [75/1000], Validation Loss: 0.0382\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [76/1000], Validation Loss: 0.0382\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [77/1000], Validation Loss: 0.0382\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [78/1000], Validation Loss: 0.0382\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [79/1000], Validation Loss: 0.0383\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [80/1000], Validation Loss: 0.0382\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [81/1000], Validation Loss: 0.0383\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [82/1000], Validation Loss: 0.0383\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [83/1000], Validation Loss: 0.0383\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [84/1000], Validation Loss: 0.0383\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [85/1000], Validation Loss: 0.0382\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [86/1000], Validation Loss: 0.0382\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [87/1000], Validation Loss: 0.0383\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [88/1000], Validation Loss: 0.0382\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [89/1000], Validation Loss: 0.0384\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [90/1000], Validation Loss: 0.0383\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [91/1000], Validation Loss: 0.0381\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [92/1000], Validation Loss: 0.0381\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [93/1000], Validation Loss: 0.0383\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [94/1000], Validation Loss: 0.0383\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [95/1000], Validation Loss: 0.0382\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [96/1000], Validation Loss: 0.0382\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [97/1000], Validation Loss: 0.0382\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [98/1000], Validation Loss: 0.0382\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [99/1000], Validation Loss: 0.0383\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [100/1000], Validation Loss: 0.0381\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [101/1000], Validation Loss: 0.0382\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [102/1000], Validation Loss: 0.0382\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [103/1000], Validation Loss: 0.0382\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [104/1000], Validation Loss: 0.0382\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [105/1000], Validation Loss: 0.0382\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [106/1000], Validation Loss: 0.0383\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [107/1000], Validation Loss: 0.0382\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [108/1000], Validation Loss: 0.0382\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [109/1000], Validation Loss: 0.0383\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [110/1000], Validation Loss: 0.0382\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [111/1000], Validation Loss: 0.0381\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [112/1000], Validation Loss: 0.0382\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [113/1000], Validation Loss: 0.0382\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [114/1000], Validation Loss: 0.0383\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [115/1000], Validation Loss: 0.0382\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [116/1000], Validation Loss: 0.0382\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [117/1000], Validation Loss: 0.0383\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [118/1000], Validation Loss: 0.0382\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [119/1000], Validation Loss: 0.0383\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [120/1000], Validation Loss: 0.0382\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [121/1000], Validation Loss: 0.0383\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [122/1000], Validation Loss: 0.0383\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [123/1000], Validation Loss: 0.0383\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [124/1000], Validation Loss: 0.0383\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [125/1000], Validation Loss: 0.0382\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [126/1000], Validation Loss: 0.0382\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [127/1000], Validation Loss: 0.0383\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [128/1000], Validation Loss: 0.0382\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [129/1000], Validation Loss: 0.0382\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [130/1000], Validation Loss: 0.0383\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [131/1000], Validation Loss: 0.0382\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [132/1000], Validation Loss: 0.0383\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [133/1000], Validation Loss: 0.0382\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [134/1000], Validation Loss: 0.0382\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [135/1000], Validation Loss: 0.0382\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [136/1000], Validation Loss: 0.0382\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [137/1000], Validation Loss: 0.0382\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [138/1000], Validation Loss: 0.0381\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [139/1000], Validation Loss: 0.0383\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [140/1000], Validation Loss: 0.0383\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [141/1000], Validation Loss: 0.0382\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [142/1000], Validation Loss: 0.0382\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [143/1000], Validation Loss: 0.0383\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [144/1000], Validation Loss: 0.0382\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [145/1000], Validation Loss: 0.0383\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [146/1000], Validation Loss: 0.0382\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [147/1000], Validation Loss: 0.0382\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [148/1000], Validation Loss: 0.0382\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [149/1000], Validation Loss: 0.0382\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [150/1000], Validation Loss: 0.0382\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [151/1000], Validation Loss: 0.0383\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [152/1000], Validation Loss: 0.0383\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [153/1000], Validation Loss: 0.0383\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [154/1000], Validation Loss: 0.0383\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [155/1000], Validation Loss: 0.0382\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [156/1000], Validation Loss: 0.0382\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [157/1000], Validation Loss: 0.0381\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [158/1000], Validation Loss: 0.0383\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [159/1000], Validation Loss: 0.0382\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [160/1000], Validation Loss: 0.0381\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [161/1000], Validation Loss: 0.0382\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [162/1000], Validation Loss: 0.0383\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [163/1000], Validation Loss: 0.0382\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [164/1000], Validation Loss: 0.0382\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [165/1000], Validation Loss: 0.0383\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [166/1000], Validation Loss: 0.0382\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [167/1000], Validation Loss: 0.0382\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [168/1000], Validation Loss: 0.0382\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [169/1000], Validation Loss: 0.0382\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [170/1000], Validation Loss: 0.0382\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [171/1000], Validation Loss: 0.0382\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [172/1000], Validation Loss: 0.0382\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [173/1000], Validation Loss: 0.0381\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [174/1000], Validation Loss: 0.0381\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [175/1000], Validation Loss: 0.0383\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [176/1000], Validation Loss: 0.0383\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [177/1000], Validation Loss: 0.0382\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [178/1000], Validation Loss: 0.0382\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [179/1000], Validation Loss: 0.0382\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [180/1000], Validation Loss: 0.0382\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [181/1000], Validation Loss: 0.0381\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [182/1000], Validation Loss: 0.0383\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [183/1000], Validation Loss: 0.0382\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [184/1000], Validation Loss: 0.0383\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [185/1000], Validation Loss: 0.0382\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [186/1000], Validation Loss: 0.0382\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [187/1000], Validation Loss: 0.0383\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0387\n",
            "Epoch [188/1000], Validation Loss: 0.0383\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [189/1000], Validation Loss: 0.0381\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [190/1000], Validation Loss: 0.0383\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [191/1000], Validation Loss: 0.0382\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [192/1000], Validation Loss: 0.0382\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [193/1000], Validation Loss: 0.0383\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [194/1000], Validation Loss: 0.0382\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [195/1000], Validation Loss: 0.0383\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [196/1000], Validation Loss: 0.0382\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [197/1000], Validation Loss: 0.0382\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [198/1000], Validation Loss: 0.0382\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [199/1000], Validation Loss: 0.0381\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [200/1000], Validation Loss: 0.0382\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [201/1000], Validation Loss: 0.0382\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [202/1000], Validation Loss: 0.0383\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [203/1000], Validation Loss: 0.0383\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [204/1000], Validation Loss: 0.0382\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [205/1000], Validation Loss: 0.0383\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [206/1000], Validation Loss: 0.0382\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [207/1000], Validation Loss: 0.0383\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [208/1000], Validation Loss: 0.0383\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [209/1000], Validation Loss: 0.0382\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [210/1000], Validation Loss: 0.0381\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [211/1000], Validation Loss: 0.0382\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [212/1000], Validation Loss: 0.0383\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [213/1000], Validation Loss: 0.0382\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [214/1000], Validation Loss: 0.0382\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [215/1000], Validation Loss: 0.0382\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [216/1000], Validation Loss: 0.0382\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [217/1000], Validation Loss: 0.0382\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [218/1000], Validation Loss: 0.0383\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [219/1000], Validation Loss: 0.0382\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [220/1000], Validation Loss: 0.0382\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [221/1000], Validation Loss: 0.0382\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [222/1000], Validation Loss: 0.0382\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [223/1000], Validation Loss: 0.0382\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [224/1000], Validation Loss: 0.0383\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [225/1000], Validation Loss: 0.0383\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [226/1000], Validation Loss: 0.0383\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [227/1000], Validation Loss: 0.0383\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [228/1000], Validation Loss: 0.0382\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [229/1000], Validation Loss: 0.0381\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [230/1000], Validation Loss: 0.0383\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [231/1000], Validation Loss: 0.0383\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [232/1000], Validation Loss: 0.0382\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [233/1000], Validation Loss: 0.0382\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [234/1000], Validation Loss: 0.0382\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [235/1000], Validation Loss: 0.0382\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [236/1000], Validation Loss: 0.0382\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [237/1000], Validation Loss: 0.0382\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [238/1000], Validation Loss: 0.0382\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [239/1000], Validation Loss: 0.0382\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [240/1000], Validation Loss: 0.0383\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [241/1000], Validation Loss: 0.0382\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [242/1000], Validation Loss: 0.0382\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [243/1000], Validation Loss: 0.0382\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [244/1000], Validation Loss: 0.0382\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [245/1000], Validation Loss: 0.0382\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [246/1000], Validation Loss: 0.0382\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [247/1000], Validation Loss: 0.0383\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [248/1000], Validation Loss: 0.0382\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [249/1000], Validation Loss: 0.0383\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [250/1000], Validation Loss: 0.0382\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [251/1000], Validation Loss: 0.0382\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [252/1000], Validation Loss: 0.0383\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [253/1000], Validation Loss: 0.0382\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [254/1000], Validation Loss: 0.0382\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [255/1000], Validation Loss: 0.0382\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [256/1000], Validation Loss: 0.0382\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [257/1000], Validation Loss: 0.0383\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [258/1000], Validation Loss: 0.0382\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [259/1000], Validation Loss: 0.0382\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [260/1000], Validation Loss: 0.0382\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [261/1000], Validation Loss: 0.0382\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [262/1000], Validation Loss: 0.0383\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [263/1000], Validation Loss: 0.0382\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [264/1000], Validation Loss: 0.0382\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [265/1000], Validation Loss: 0.0382\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [266/1000], Validation Loss: 0.0383\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [267/1000], Validation Loss: 0.0382\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [268/1000], Validation Loss: 0.0382\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [269/1000], Validation Loss: 0.0382\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [270/1000], Validation Loss: 0.0382\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [271/1000], Validation Loss: 0.0382\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [272/1000], Validation Loss: 0.0382\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [273/1000], Validation Loss: 0.0381\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [274/1000], Validation Loss: 0.0382\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [275/1000], Validation Loss: 0.0382\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [276/1000], Validation Loss: 0.0383\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [277/1000], Validation Loss: 0.0382\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [278/1000], Validation Loss: 0.0382\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [279/1000], Validation Loss: 0.0383\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [280/1000], Validation Loss: 0.0381\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [281/1000], Validation Loss: 0.0381\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [282/1000], Validation Loss: 0.0383\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [283/1000], Validation Loss: 0.0382\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [284/1000], Validation Loss: 0.0382\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [285/1000], Validation Loss: 0.0383\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [286/1000], Validation Loss: 0.0383\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [287/1000], Validation Loss: 0.0383\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [288/1000], Validation Loss: 0.0382\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [289/1000], Validation Loss: 0.0382\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [290/1000], Validation Loss: 0.0383\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [291/1000], Validation Loss: 0.0382\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [292/1000], Validation Loss: 0.0382\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [293/1000], Validation Loss: 0.0382\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [294/1000], Validation Loss: 0.0382\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [295/1000], Validation Loss: 0.0382\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [296/1000], Validation Loss: 0.0382\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [297/1000], Validation Loss: 0.0381\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [298/1000], Validation Loss: 0.0383\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [299/1000], Validation Loss: 0.0382\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [300/1000], Validation Loss: 0.0382\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [301/1000], Validation Loss: 0.0382\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [302/1000], Validation Loss: 0.0382\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [303/1000], Validation Loss: 0.0382\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [304/1000], Validation Loss: 0.0381\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [305/1000], Validation Loss: 0.0382\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [306/1000], Validation Loss: 0.0382\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [307/1000], Validation Loss: 0.0383\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [308/1000], Validation Loss: 0.0383\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [309/1000], Validation Loss: 0.0382\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [310/1000], Validation Loss: 0.0382\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [311/1000], Validation Loss: 0.0382\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [312/1000], Validation Loss: 0.0381\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [313/1000], Validation Loss: 0.0383\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [314/1000], Validation Loss: 0.0383\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [315/1000], Validation Loss: 0.0381\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [316/1000], Validation Loss: 0.0383\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [317/1000], Validation Loss: 0.0383\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [318/1000], Validation Loss: 0.0382\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [319/1000], Validation Loss: 0.0383\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [320/1000], Validation Loss: 0.0382\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [321/1000], Validation Loss: 0.0383\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [322/1000], Validation Loss: 0.0383\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [323/1000], Validation Loss: 0.0381\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [324/1000], Validation Loss: 0.0383\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [325/1000], Validation Loss: 0.0383\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [326/1000], Validation Loss: 0.0383\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [327/1000], Validation Loss: 0.0382\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [328/1000], Validation Loss: 0.0382\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [329/1000], Validation Loss: 0.0382\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [330/1000], Validation Loss: 0.0383\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [331/1000], Validation Loss: 0.0383\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [332/1000], Validation Loss: 0.0382\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [333/1000], Validation Loss: 0.0383\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [334/1000], Validation Loss: 0.0383\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [335/1000], Validation Loss: 0.0382\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [336/1000], Validation Loss: 0.0382\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [337/1000], Validation Loss: 0.0383\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [338/1000], Validation Loss: 0.0382\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [339/1000], Validation Loss: 0.0382\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [340/1000], Validation Loss: 0.0382\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [341/1000], Validation Loss: 0.0382\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [342/1000], Validation Loss: 0.0382\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [343/1000], Validation Loss: 0.0382\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [344/1000], Validation Loss: 0.0382\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [345/1000], Validation Loss: 0.0382\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [346/1000], Validation Loss: 0.0382\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [347/1000], Validation Loss: 0.0384\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [348/1000], Validation Loss: 0.0383\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [349/1000], Validation Loss: 0.0382\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [350/1000], Validation Loss: 0.0382\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [351/1000], Validation Loss: 0.0382\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [352/1000], Validation Loss: 0.0382\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [353/1000], Validation Loss: 0.0382\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [354/1000], Validation Loss: 0.0382\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [355/1000], Validation Loss: 0.0383\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [356/1000], Validation Loss: 0.0382\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [357/1000], Validation Loss: 0.0382\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [358/1000], Validation Loss: 0.0383\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [359/1000], Validation Loss: 0.0383\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [360/1000], Validation Loss: 0.0382\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [361/1000], Validation Loss: 0.0382\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [362/1000], Validation Loss: 0.0382\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [363/1000], Validation Loss: 0.0381\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [364/1000], Validation Loss: 0.0381\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [365/1000], Validation Loss: 0.0382\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [366/1000], Validation Loss: 0.0383\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [367/1000], Validation Loss: 0.0382\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [368/1000], Validation Loss: 0.0383\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [369/1000], Validation Loss: 0.0383\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [370/1000], Validation Loss: 0.0382\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [371/1000], Validation Loss: 0.0383\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [372/1000], Validation Loss: 0.0383\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [373/1000], Validation Loss: 0.0382\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [374/1000], Validation Loss: 0.0382\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [375/1000], Validation Loss: 0.0382\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [376/1000], Validation Loss: 0.0382\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [377/1000], Validation Loss: 0.0382\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [378/1000], Validation Loss: 0.0383\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [379/1000], Validation Loss: 0.0383\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [380/1000], Validation Loss: 0.0383\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [381/1000], Validation Loss: 0.0382\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [382/1000], Validation Loss: 0.0382\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [383/1000], Validation Loss: 0.0382\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [384/1000], Validation Loss: 0.0382\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [385/1000], Validation Loss: 0.0382\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [386/1000], Validation Loss: 0.0382\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [387/1000], Validation Loss: 0.0382\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [388/1000], Validation Loss: 0.0383\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [389/1000], Validation Loss: 0.0382\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [390/1000], Validation Loss: 0.0383\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [391/1000], Validation Loss: 0.0382\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [392/1000], Validation Loss: 0.0382\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [393/1000], Validation Loss: 0.0382\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [394/1000], Validation Loss: 0.0383\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [395/1000], Validation Loss: 0.0382\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [396/1000], Validation Loss: 0.0383\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [397/1000], Validation Loss: 0.0383\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [398/1000], Validation Loss: 0.0383\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [399/1000], Validation Loss: 0.0382\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [400/1000], Validation Loss: 0.0382\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [401/1000], Validation Loss: 0.0383\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [402/1000], Validation Loss: 0.0383\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [403/1000], Validation Loss: 0.0382\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [404/1000], Validation Loss: 0.0382\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [405/1000], Validation Loss: 0.0382\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [406/1000], Validation Loss: 0.0382\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [407/1000], Validation Loss: 0.0383\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [408/1000], Validation Loss: 0.0382\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [409/1000], Validation Loss: 0.0382\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [410/1000], Validation Loss: 0.0383\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [411/1000], Validation Loss: 0.0383\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [412/1000], Validation Loss: 0.0383\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [413/1000], Validation Loss: 0.0381\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [414/1000], Validation Loss: 0.0382\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [415/1000], Validation Loss: 0.0382\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [416/1000], Validation Loss: 0.0382\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [417/1000], Validation Loss: 0.0382\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [418/1000], Validation Loss: 0.0382\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [419/1000], Validation Loss: 0.0383\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [420/1000], Validation Loss: 0.0383\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [421/1000], Validation Loss: 0.0383\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [422/1000], Validation Loss: 0.0382\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [423/1000], Validation Loss: 0.0382\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [424/1000], Validation Loss: 0.0382\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [425/1000], Validation Loss: 0.0383\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [426/1000], Validation Loss: 0.0382\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [427/1000], Validation Loss: 0.0383\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [428/1000], Validation Loss: 0.0382\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [429/1000], Validation Loss: 0.0381\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [430/1000], Validation Loss: 0.0382\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [431/1000], Validation Loss: 0.0381\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [432/1000], Validation Loss: 0.0382\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [433/1000], Validation Loss: 0.0382\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [434/1000], Validation Loss: 0.0383\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [435/1000], Validation Loss: 0.0382\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [436/1000], Validation Loss: 0.0383\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [437/1000], Validation Loss: 0.0382\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [438/1000], Validation Loss: 0.0382\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [439/1000], Validation Loss: 0.0383\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [440/1000], Validation Loss: 0.0382\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [441/1000], Validation Loss: 0.0382\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [442/1000], Validation Loss: 0.0382\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [443/1000], Validation Loss: 0.0382\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [444/1000], Validation Loss: 0.0383\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [445/1000], Validation Loss: 0.0382\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [446/1000], Validation Loss: 0.0383\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [447/1000], Validation Loss: 0.0381\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [448/1000], Validation Loss: 0.0382\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [449/1000], Validation Loss: 0.0382\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [450/1000], Validation Loss: 0.0382\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [451/1000], Validation Loss: 0.0382\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [452/1000], Validation Loss: 0.0382\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [453/1000], Validation Loss: 0.0382\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [454/1000], Validation Loss: 0.0383\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [455/1000], Validation Loss: 0.0382\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [456/1000], Validation Loss: 0.0382\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [457/1000], Validation Loss: 0.0382\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [458/1000], Validation Loss: 0.0382\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [459/1000], Validation Loss: 0.0382\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [460/1000], Validation Loss: 0.0383\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [461/1000], Validation Loss: 0.0382\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [462/1000], Validation Loss: 0.0382\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [463/1000], Validation Loss: 0.0382\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [464/1000], Validation Loss: 0.0382\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [465/1000], Validation Loss: 0.0383\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [466/1000], Validation Loss: 0.0383\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [467/1000], Validation Loss: 0.0382\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [468/1000], Validation Loss: 0.0383\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [469/1000], Validation Loss: 0.0382\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [470/1000], Validation Loss: 0.0382\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [471/1000], Validation Loss: 0.0382\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [472/1000], Validation Loss: 0.0382\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [473/1000], Validation Loss: 0.0382\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [474/1000], Validation Loss: 0.0381\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [475/1000], Validation Loss: 0.0382\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [476/1000], Validation Loss: 0.0382\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [477/1000], Validation Loss: 0.0383\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [478/1000], Validation Loss: 0.0382\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [479/1000], Validation Loss: 0.0382\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [480/1000], Validation Loss: 0.0382\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [481/1000], Validation Loss: 0.0382\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [482/1000], Validation Loss: 0.0383\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [483/1000], Validation Loss: 0.0381\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [484/1000], Validation Loss: 0.0382\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [485/1000], Validation Loss: 0.0382\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [486/1000], Validation Loss: 0.0382\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [487/1000], Validation Loss: 0.0383\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [488/1000], Validation Loss: 0.0382\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [489/1000], Validation Loss: 0.0382\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [490/1000], Validation Loss: 0.0383\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [491/1000], Validation Loss: 0.0382\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [492/1000], Validation Loss: 0.0381\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [493/1000], Validation Loss: 0.0382\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [494/1000], Validation Loss: 0.0383\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [495/1000], Validation Loss: 0.0382\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [496/1000], Validation Loss: 0.0382\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [497/1000], Validation Loss: 0.0382\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [498/1000], Validation Loss: 0.0383\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [499/1000], Validation Loss: 0.0382\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [500/1000], Validation Loss: 0.0382\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [501/1000], Validation Loss: 0.0383\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [502/1000], Validation Loss: 0.0382\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [503/1000], Validation Loss: 0.0381\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [504/1000], Validation Loss: 0.0382\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [505/1000], Validation Loss: 0.0382\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [506/1000], Validation Loss: 0.0382\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [507/1000], Validation Loss: 0.0383\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [508/1000], Validation Loss: 0.0382\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [509/1000], Validation Loss: 0.0382\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [510/1000], Validation Loss: 0.0383\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [511/1000], Validation Loss: 0.0382\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [512/1000], Validation Loss: 0.0383\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [513/1000], Validation Loss: 0.0382\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [514/1000], Validation Loss: 0.0382\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [515/1000], Validation Loss: 0.0383\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [516/1000], Validation Loss: 0.0382\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [517/1000], Validation Loss: 0.0381\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [518/1000], Validation Loss: 0.0382\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [519/1000], Validation Loss: 0.0383\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [520/1000], Validation Loss: 0.0382\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [521/1000], Validation Loss: 0.0383\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [522/1000], Validation Loss: 0.0382\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [523/1000], Validation Loss: 0.0382\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [524/1000], Validation Loss: 0.0383\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [525/1000], Validation Loss: 0.0382\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [526/1000], Validation Loss: 0.0383\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [527/1000], Validation Loss: 0.0383\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [528/1000], Validation Loss: 0.0382\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [529/1000], Validation Loss: 0.0383\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [530/1000], Validation Loss: 0.0383\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [531/1000], Validation Loss: 0.0383\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0387\n",
            "Epoch [532/1000], Validation Loss: 0.0382\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [533/1000], Validation Loss: 0.0383\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [534/1000], Validation Loss: 0.0382\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [535/1000], Validation Loss: 0.0382\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [536/1000], Validation Loss: 0.0383\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [537/1000], Validation Loss: 0.0383\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [538/1000], Validation Loss: 0.0382\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [539/1000], Validation Loss: 0.0383\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [540/1000], Validation Loss: 0.0382\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [541/1000], Validation Loss: 0.0382\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [542/1000], Validation Loss: 0.0383\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [543/1000], Validation Loss: 0.0383\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [544/1000], Validation Loss: 0.0382\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [545/1000], Validation Loss: 0.0382\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [546/1000], Validation Loss: 0.0382\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [547/1000], Validation Loss: 0.0383\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [548/1000], Validation Loss: 0.0382\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [549/1000], Validation Loss: 0.0382\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [550/1000], Validation Loss: 0.0382\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [551/1000], Validation Loss: 0.0382\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [552/1000], Validation Loss: 0.0382\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [553/1000], Validation Loss: 0.0382\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [554/1000], Validation Loss: 0.0382\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [555/1000], Validation Loss: 0.0383\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [556/1000], Validation Loss: 0.0383\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0366\n",
            "Epoch [557/1000], Validation Loss: 0.0383\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [558/1000], Validation Loss: 0.0383\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [559/1000], Validation Loss: 0.0383\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [560/1000], Validation Loss: 0.0382\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [561/1000], Validation Loss: 0.0382\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [562/1000], Validation Loss: 0.0383\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [563/1000], Validation Loss: 0.0382\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [564/1000], Validation Loss: 0.0382\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [565/1000], Validation Loss: 0.0381\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [566/1000], Validation Loss: 0.0383\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [567/1000], Validation Loss: 0.0382\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [568/1000], Validation Loss: 0.0383\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [569/1000], Validation Loss: 0.0383\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [570/1000], Validation Loss: 0.0383\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [571/1000], Validation Loss: 0.0382\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [572/1000], Validation Loss: 0.0382\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [573/1000], Validation Loss: 0.0383\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [574/1000], Validation Loss: 0.0382\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [575/1000], Validation Loss: 0.0382\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [576/1000], Validation Loss: 0.0383\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [577/1000], Validation Loss: 0.0382\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [578/1000], Validation Loss: 0.0383\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [579/1000], Validation Loss: 0.0383\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [580/1000], Validation Loss: 0.0381\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [581/1000], Validation Loss: 0.0383\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [582/1000], Validation Loss: 0.0381\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [583/1000], Validation Loss: 0.0383\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [584/1000], Validation Loss: 0.0383\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [585/1000], Validation Loss: 0.0382\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [586/1000], Validation Loss: 0.0383\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [587/1000], Validation Loss: 0.0383\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [588/1000], Validation Loss: 0.0382\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [589/1000], Validation Loss: 0.0382\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [590/1000], Validation Loss: 0.0383\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [591/1000], Validation Loss: 0.0381\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [592/1000], Validation Loss: 0.0382\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [593/1000], Validation Loss: 0.0382\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [594/1000], Validation Loss: 0.0382\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [595/1000], Validation Loss: 0.0382\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [596/1000], Validation Loss: 0.0383\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [597/1000], Validation Loss: 0.0382\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [598/1000], Validation Loss: 0.0382\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [599/1000], Validation Loss: 0.0383\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [600/1000], Validation Loss: 0.0382\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [601/1000], Validation Loss: 0.0383\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [602/1000], Validation Loss: 0.0382\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [603/1000], Validation Loss: 0.0382\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [604/1000], Validation Loss: 0.0382\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [605/1000], Validation Loss: 0.0382\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [606/1000], Validation Loss: 0.0382\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [607/1000], Validation Loss: 0.0383\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [608/1000], Validation Loss: 0.0382\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [609/1000], Validation Loss: 0.0382\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [610/1000], Validation Loss: 0.0383\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [611/1000], Validation Loss: 0.0383\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [612/1000], Validation Loss: 0.0382\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [613/1000], Validation Loss: 0.0383\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [614/1000], Validation Loss: 0.0382\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [615/1000], Validation Loss: 0.0381\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [616/1000], Validation Loss: 0.0382\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [617/1000], Validation Loss: 0.0382\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [618/1000], Validation Loss: 0.0382\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [619/1000], Validation Loss: 0.0382\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [620/1000], Validation Loss: 0.0382\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [621/1000], Validation Loss: 0.0383\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [622/1000], Validation Loss: 0.0382\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [623/1000], Validation Loss: 0.0383\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [624/1000], Validation Loss: 0.0382\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [625/1000], Validation Loss: 0.0382\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [626/1000], Validation Loss: 0.0382\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [627/1000], Validation Loss: 0.0383\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [628/1000], Validation Loss: 0.0382\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [629/1000], Validation Loss: 0.0383\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [630/1000], Validation Loss: 0.0382\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [631/1000], Validation Loss: 0.0383\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [632/1000], Validation Loss: 0.0382\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [633/1000], Validation Loss: 0.0382\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [634/1000], Validation Loss: 0.0382\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [635/1000], Validation Loss: 0.0382\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [636/1000], Validation Loss: 0.0383\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [637/1000], Validation Loss: 0.0382\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [638/1000], Validation Loss: 0.0382\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [639/1000], Validation Loss: 0.0382\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [640/1000], Validation Loss: 0.0382\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [641/1000], Validation Loss: 0.0383\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [642/1000], Validation Loss: 0.0383\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [643/1000], Validation Loss: 0.0382\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [644/1000], Validation Loss: 0.0382\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [645/1000], Validation Loss: 0.0383\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [646/1000], Validation Loss: 0.0382\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [647/1000], Validation Loss: 0.0382\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [648/1000], Validation Loss: 0.0383\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [649/1000], Validation Loss: 0.0382\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [650/1000], Validation Loss: 0.0381\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [651/1000], Validation Loss: 0.0382\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [652/1000], Validation Loss: 0.0381\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [653/1000], Validation Loss: 0.0382\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [654/1000], Validation Loss: 0.0381\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [655/1000], Validation Loss: 0.0382\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [656/1000], Validation Loss: 0.0383\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [657/1000], Validation Loss: 0.0382\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [658/1000], Validation Loss: 0.0382\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [659/1000], Validation Loss: 0.0383\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [660/1000], Validation Loss: 0.0382\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [661/1000], Validation Loss: 0.0383\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0388\n",
            "Epoch [662/1000], Validation Loss: 0.0382\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [663/1000], Validation Loss: 0.0383\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [664/1000], Validation Loss: 0.0382\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [665/1000], Validation Loss: 0.0382\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [666/1000], Validation Loss: 0.0382\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [667/1000], Validation Loss: 0.0382\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [668/1000], Validation Loss: 0.0382\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [669/1000], Validation Loss: 0.0382\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [670/1000], Validation Loss: 0.0382\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [671/1000], Validation Loss: 0.0382\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [672/1000], Validation Loss: 0.0382\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [673/1000], Validation Loss: 0.0383\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [674/1000], Validation Loss: 0.0382\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [675/1000], Validation Loss: 0.0382\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [676/1000], Validation Loss: 0.0382\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [677/1000], Validation Loss: 0.0382\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [678/1000], Validation Loss: 0.0382\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [679/1000], Validation Loss: 0.0382\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [680/1000], Validation Loss: 0.0382\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [681/1000], Validation Loss: 0.0382\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [682/1000], Validation Loss: 0.0383\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [683/1000], Validation Loss: 0.0383\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [684/1000], Validation Loss: 0.0382\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [685/1000], Validation Loss: 0.0382\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [686/1000], Validation Loss: 0.0382\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [687/1000], Validation Loss: 0.0382\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [688/1000], Validation Loss: 0.0381\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [689/1000], Validation Loss: 0.0383\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [690/1000], Validation Loss: 0.0382\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [691/1000], Validation Loss: 0.0381\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [692/1000], Validation Loss: 0.0382\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [693/1000], Validation Loss: 0.0382\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [694/1000], Validation Loss: 0.0382\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [695/1000], Validation Loss: 0.0382\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [696/1000], Validation Loss: 0.0383\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [697/1000], Validation Loss: 0.0383\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [698/1000], Validation Loss: 0.0383\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [699/1000], Validation Loss: 0.0382\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [700/1000], Validation Loss: 0.0382\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [701/1000], Validation Loss: 0.0382\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [702/1000], Validation Loss: 0.0383\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [703/1000], Validation Loss: 0.0382\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [704/1000], Validation Loss: 0.0382\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [705/1000], Validation Loss: 0.0383\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [706/1000], Validation Loss: 0.0382\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [707/1000], Validation Loss: 0.0382\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [708/1000], Validation Loss: 0.0381\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [709/1000], Validation Loss: 0.0383\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [710/1000], Validation Loss: 0.0383\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [711/1000], Validation Loss: 0.0382\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [712/1000], Validation Loss: 0.0383\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [713/1000], Validation Loss: 0.0382\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [714/1000], Validation Loss: 0.0381\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [715/1000], Validation Loss: 0.0383\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [716/1000], Validation Loss: 0.0382\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [717/1000], Validation Loss: 0.0382\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [718/1000], Validation Loss: 0.0383\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [719/1000], Validation Loss: 0.0383\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [720/1000], Validation Loss: 0.0383\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [721/1000], Validation Loss: 0.0382\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [722/1000], Validation Loss: 0.0382\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [723/1000], Validation Loss: 0.0382\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [724/1000], Validation Loss: 0.0382\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [725/1000], Validation Loss: 0.0383\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [726/1000], Validation Loss: 0.0382\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [727/1000], Validation Loss: 0.0383\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [728/1000], Validation Loss: 0.0382\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [729/1000], Validation Loss: 0.0382\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [730/1000], Validation Loss: 0.0383\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [731/1000], Validation Loss: 0.0382\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [732/1000], Validation Loss: 0.0382\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [733/1000], Validation Loss: 0.0382\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [734/1000], Validation Loss: 0.0383\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [735/1000], Validation Loss: 0.0382\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [736/1000], Validation Loss: 0.0382\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [737/1000], Validation Loss: 0.0382\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [738/1000], Validation Loss: 0.0383\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [739/1000], Validation Loss: 0.0382\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [740/1000], Validation Loss: 0.0382\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [741/1000], Validation Loss: 0.0383\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [742/1000], Validation Loss: 0.0383\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [743/1000], Validation Loss: 0.0383\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [744/1000], Validation Loss: 0.0383\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [745/1000], Validation Loss: 0.0383\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [746/1000], Validation Loss: 0.0383\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [747/1000], Validation Loss: 0.0382\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [748/1000], Validation Loss: 0.0383\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [749/1000], Validation Loss: 0.0383\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [750/1000], Validation Loss: 0.0381\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [751/1000], Validation Loss: 0.0381\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [752/1000], Validation Loss: 0.0382\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [753/1000], Validation Loss: 0.0382\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [754/1000], Validation Loss: 0.0382\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [755/1000], Validation Loss: 0.0382\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [756/1000], Validation Loss: 0.0382\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [757/1000], Validation Loss: 0.0382\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [758/1000], Validation Loss: 0.0383\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [759/1000], Validation Loss: 0.0382\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [760/1000], Validation Loss: 0.0382\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [761/1000], Validation Loss: 0.0382\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [762/1000], Validation Loss: 0.0383\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [763/1000], Validation Loss: 0.0382\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [764/1000], Validation Loss: 0.0382\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [765/1000], Validation Loss: 0.0382\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [766/1000], Validation Loss: 0.0382\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [767/1000], Validation Loss: 0.0382\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [768/1000], Validation Loss: 0.0382\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [769/1000], Validation Loss: 0.0382\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [770/1000], Validation Loss: 0.0383\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [771/1000], Validation Loss: 0.0382\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [772/1000], Validation Loss: 0.0382\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [773/1000], Validation Loss: 0.0382\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [774/1000], Validation Loss: 0.0383\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [775/1000], Validation Loss: 0.0382\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [776/1000], Validation Loss: 0.0382\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [777/1000], Validation Loss: 0.0383\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [778/1000], Validation Loss: 0.0383\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [779/1000], Validation Loss: 0.0383\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [780/1000], Validation Loss: 0.0383\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [781/1000], Validation Loss: 0.0382\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [782/1000], Validation Loss: 0.0382\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [783/1000], Validation Loss: 0.0382\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [784/1000], Validation Loss: 0.0383\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [785/1000], Validation Loss: 0.0383\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [786/1000], Validation Loss: 0.0382\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [787/1000], Validation Loss: 0.0382\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [788/1000], Validation Loss: 0.0381\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [789/1000], Validation Loss: 0.0382\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [790/1000], Validation Loss: 0.0383\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [791/1000], Validation Loss: 0.0381\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [792/1000], Validation Loss: 0.0382\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [793/1000], Validation Loss: 0.0382\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [794/1000], Validation Loss: 0.0383\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [795/1000], Validation Loss: 0.0383\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [796/1000], Validation Loss: 0.0381\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [797/1000], Validation Loss: 0.0381\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [798/1000], Validation Loss: 0.0381\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [799/1000], Validation Loss: 0.0383\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [800/1000], Validation Loss: 0.0382\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [801/1000], Validation Loss: 0.0382\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [802/1000], Validation Loss: 0.0382\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [803/1000], Validation Loss: 0.0381\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [804/1000], Validation Loss: 0.0383\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [805/1000], Validation Loss: 0.0383\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [806/1000], Validation Loss: 0.0381\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [807/1000], Validation Loss: 0.0382\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [808/1000], Validation Loss: 0.0383\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [809/1000], Validation Loss: 0.0382\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [810/1000], Validation Loss: 0.0383\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [811/1000], Validation Loss: 0.0383\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [812/1000], Validation Loss: 0.0382\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [813/1000], Validation Loss: 0.0382\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [814/1000], Validation Loss: 0.0382\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [815/1000], Validation Loss: 0.0382\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [816/1000], Validation Loss: 0.0381\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [817/1000], Validation Loss: 0.0382\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [818/1000], Validation Loss: 0.0382\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [819/1000], Validation Loss: 0.0382\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [820/1000], Validation Loss: 0.0382\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [821/1000], Validation Loss: 0.0382\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [822/1000], Validation Loss: 0.0383\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [823/1000], Validation Loss: 0.0382\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [824/1000], Validation Loss: 0.0383\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [825/1000], Validation Loss: 0.0383\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [826/1000], Validation Loss: 0.0382\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [827/1000], Validation Loss: 0.0382\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [828/1000], Validation Loss: 0.0382\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [829/1000], Validation Loss: 0.0382\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [830/1000], Validation Loss: 0.0383\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [831/1000], Validation Loss: 0.0382\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [832/1000], Validation Loss: 0.0382\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [833/1000], Validation Loss: 0.0382\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [834/1000], Validation Loss: 0.0383\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [835/1000], Validation Loss: 0.0382\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [836/1000], Validation Loss: 0.0381\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [837/1000], Validation Loss: 0.0382\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [838/1000], Validation Loss: 0.0381\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [839/1000], Validation Loss: 0.0382\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [840/1000], Validation Loss: 0.0383\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [841/1000], Validation Loss: 0.0382\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [842/1000], Validation Loss: 0.0383\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [843/1000], Validation Loss: 0.0382\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [844/1000], Validation Loss: 0.0382\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [845/1000], Validation Loss: 0.0382\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [846/1000], Validation Loss: 0.0382\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [847/1000], Validation Loss: 0.0383\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [848/1000], Validation Loss: 0.0383\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [849/1000], Validation Loss: 0.0383\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [850/1000], Validation Loss: 0.0382\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [851/1000], Validation Loss: 0.0382\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [852/1000], Validation Loss: 0.0382\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [853/1000], Validation Loss: 0.0381\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [854/1000], Validation Loss: 0.0382\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [855/1000], Validation Loss: 0.0383\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [856/1000], Validation Loss: 0.0382\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [857/1000], Validation Loss: 0.0383\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [858/1000], Validation Loss: 0.0382\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [859/1000], Validation Loss: 0.0383\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [860/1000], Validation Loss: 0.0382\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [861/1000], Validation Loss: 0.0381\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [862/1000], Validation Loss: 0.0382\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [863/1000], Validation Loss: 0.0383\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [864/1000], Validation Loss: 0.0383\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [865/1000], Validation Loss: 0.0383\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [866/1000], Validation Loss: 0.0381\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [867/1000], Validation Loss: 0.0382\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [868/1000], Validation Loss: 0.0383\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [869/1000], Validation Loss: 0.0383\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [870/1000], Validation Loss: 0.0382\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [871/1000], Validation Loss: 0.0383\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [872/1000], Validation Loss: 0.0383\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [873/1000], Validation Loss: 0.0383\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [874/1000], Validation Loss: 0.0382\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [875/1000], Validation Loss: 0.0382\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [876/1000], Validation Loss: 0.0383\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [877/1000], Validation Loss: 0.0382\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [878/1000], Validation Loss: 0.0383\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [879/1000], Validation Loss: 0.0382\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [880/1000], Validation Loss: 0.0382\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [881/1000], Validation Loss: 0.0382\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [882/1000], Validation Loss: 0.0382\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [883/1000], Validation Loss: 0.0382\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [884/1000], Validation Loss: 0.0382\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [885/1000], Validation Loss: 0.0383\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [886/1000], Validation Loss: 0.0382\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [887/1000], Validation Loss: 0.0383\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [888/1000], Validation Loss: 0.0383\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [889/1000], Validation Loss: 0.0383\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [890/1000], Validation Loss: 0.0383\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [891/1000], Validation Loss: 0.0383\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [892/1000], Validation Loss: 0.0382\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [893/1000], Validation Loss: 0.0382\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [894/1000], Validation Loss: 0.0382\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [895/1000], Validation Loss: 0.0382\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [896/1000], Validation Loss: 0.0383\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [897/1000], Validation Loss: 0.0382\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [898/1000], Validation Loss: 0.0382\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [899/1000], Validation Loss: 0.0382\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [900/1000], Validation Loss: 0.0382\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [901/1000], Validation Loss: 0.0382\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [902/1000], Validation Loss: 0.0383\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [903/1000], Validation Loss: 0.0383\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [904/1000], Validation Loss: 0.0383\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [905/1000], Validation Loss: 0.0382\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [906/1000], Validation Loss: 0.0382\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [907/1000], Validation Loss: 0.0383\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [908/1000], Validation Loss: 0.0382\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [909/1000], Validation Loss: 0.0382\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [910/1000], Validation Loss: 0.0382\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [911/1000], Validation Loss: 0.0381\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [912/1000], Validation Loss: 0.0383\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [913/1000], Validation Loss: 0.0382\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [914/1000], Validation Loss: 0.0382\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [915/1000], Validation Loss: 0.0383\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [916/1000], Validation Loss: 0.0383\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [917/1000], Validation Loss: 0.0383\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [918/1000], Validation Loss: 0.0382\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [919/1000], Validation Loss: 0.0382\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [920/1000], Validation Loss: 0.0383\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [921/1000], Validation Loss: 0.0382\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [922/1000], Validation Loss: 0.0382\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [923/1000], Validation Loss: 0.0382\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [924/1000], Validation Loss: 0.0383\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [925/1000], Validation Loss: 0.0382\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [926/1000], Validation Loss: 0.0382\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [927/1000], Validation Loss: 0.0382\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [928/1000], Validation Loss: 0.0382\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [929/1000], Validation Loss: 0.0382\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [930/1000], Validation Loss: 0.0382\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [931/1000], Validation Loss: 0.0382\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [932/1000], Validation Loss: 0.0382\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [933/1000], Validation Loss: 0.0382\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [934/1000], Validation Loss: 0.0382\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [935/1000], Validation Loss: 0.0382\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [936/1000], Validation Loss: 0.0382\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [937/1000], Validation Loss: 0.0381\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [938/1000], Validation Loss: 0.0382\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [939/1000], Validation Loss: 0.0382\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [940/1000], Validation Loss: 0.0383\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [941/1000], Validation Loss: 0.0382\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [942/1000], Validation Loss: 0.0383\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [943/1000], Validation Loss: 0.0382\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [944/1000], Validation Loss: 0.0382\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [945/1000], Validation Loss: 0.0382\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [946/1000], Validation Loss: 0.0382\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [947/1000], Validation Loss: 0.0382\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [948/1000], Validation Loss: 0.0382\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [949/1000], Validation Loss: 0.0382\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [950/1000], Validation Loss: 0.0382\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [951/1000], Validation Loss: 0.0382\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [952/1000], Validation Loss: 0.0383\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [953/1000], Validation Loss: 0.0382\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [954/1000], Validation Loss: 0.0382\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [955/1000], Validation Loss: 0.0383\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [956/1000], Validation Loss: 0.0382\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [957/1000], Validation Loss: 0.0382\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [958/1000], Validation Loss: 0.0383\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [959/1000], Validation Loss: 0.0382\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [960/1000], Validation Loss: 0.0383\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [961/1000], Validation Loss: 0.0383\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [962/1000], Validation Loss: 0.0382\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [963/1000], Validation Loss: 0.0383\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [964/1000], Validation Loss: 0.0383\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [965/1000], Validation Loss: 0.0383\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [966/1000], Validation Loss: 0.0382\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [967/1000], Validation Loss: 0.0382\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [968/1000], Validation Loss: 0.0382\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [969/1000], Validation Loss: 0.0382\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [970/1000], Validation Loss: 0.0383\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [971/1000], Validation Loss: 0.0382\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [972/1000], Validation Loss: 0.0382\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [973/1000], Validation Loss: 0.0381\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [974/1000], Validation Loss: 0.0383\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [975/1000], Validation Loss: 0.0382\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [976/1000], Validation Loss: 0.0381\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [977/1000], Validation Loss: 0.0382\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [978/1000], Validation Loss: 0.0382\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [979/1000], Validation Loss: 0.0383\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [980/1000], Validation Loss: 0.0382\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [981/1000], Validation Loss: 0.0383\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [982/1000], Validation Loss: 0.0383\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [983/1000], Validation Loss: 0.0382\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [984/1000], Validation Loss: 0.0382\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [985/1000], Validation Loss: 0.0383\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [986/1000], Validation Loss: 0.0382\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [987/1000], Validation Loss: 0.0383\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [988/1000], Validation Loss: 0.0382\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [989/1000], Validation Loss: 0.0383\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [990/1000], Validation Loss: 0.0382\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [991/1000], Validation Loss: 0.0382\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [992/1000], Validation Loss: 0.0382\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [993/1000], Validation Loss: 0.0382\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [994/1000], Validation Loss: 0.0382\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [995/1000], Validation Loss: 0.0382\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [996/1000], Validation Loss: 0.0382\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [997/1000], Validation Loss: 0.0383\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [998/1000], Validation Loss: 0.0381\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [999/1000], Validation Loss: 0.0382\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [1000/1000], Validation Loss: 0.0382\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPFAW-kJL9dV",
        "outputId": "15967133-b68b-495c-c8c9-2cf6adb3e8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.037904392927885056,\n",
              " 0.037195563316345215,\n",
              " 0.03758431226015091,\n",
              " 0.03771628439426422,\n",
              " 0.03793232515454292,\n",
              " 0.03719206154346466,\n",
              " 0.037802327424287796,\n",
              " 0.03734620288014412,\n",
              " 0.03778769075870514,\n",
              " 0.037410397082567215,\n",
              " 0.03770967572927475,\n",
              " 0.03752969577908516,\n",
              " 0.03786255419254303,\n",
              " 0.03727363795042038,\n",
              " 0.03767665475606918,\n",
              " 0.0376417450606823,\n",
              " 0.03785935789346695,\n",
              " 0.03729652985930443,\n",
              " 0.03719864413142204,\n",
              " 0.0380912646651268,\n",
              " 0.03798770159482956,\n",
              " 0.03724668174982071,\n",
              " 0.03755659982562065,\n",
              " 0.03776998817920685,\n",
              " 0.0375327467918396,\n",
              " 0.037792056798934937,\n",
              " 0.03748596832156181,\n",
              " 0.03795449063181877,\n",
              " 0.03781898319721222,\n",
              " 0.0373639352619648,\n",
              " 0.03734074532985687,\n",
              " 0.03803573176264763,\n",
              " 0.037850067019462585,\n",
              " 0.037272557616233826,\n",
              " 0.03770868107676506,\n",
              " 0.0375395193696022,\n",
              " 0.037011295557022095,\n",
              " 0.03863564878702164,\n",
              " 0.03709288686513901,\n",
              " 0.03843695670366287,\n",
              " 0.037963394075632095,\n",
              " 0.03722498193383217,\n",
              " 0.03755880892276764,\n",
              " 0.03769954293966293,\n",
              " 0.03772813081741333,\n",
              " 0.03755708411335945,\n",
              " 0.03760956972837448,\n",
              " 0.03762303665280342,\n",
              " 0.03765060380101204,\n",
              " 0.03755282610654831,\n",
              " 0.03740273416042328,\n",
              " 0.038011584430933,\n",
              " 0.03766823932528496,\n",
              " 0.03742051497101784,\n",
              " 0.037915267050266266,\n",
              " 0.037161704152822495,\n",
              " 0.03764345869421959,\n",
              " 0.03753802180290222,\n",
              " 0.03753620386123657,\n",
              " 0.03777606785297394,\n",
              " 0.03771766647696495,\n",
              " 0.03731240704655647,\n",
              " 0.037656284868717194,\n",
              " 0.03758618235588074,\n",
              " 0.037402331829071045,\n",
              " 0.038016177713871,\n",
              " 0.03768832981586456,\n",
              " 0.037511225789785385,\n",
              " 0.03747820854187012,\n",
              " 0.03777703270316124,\n",
              " 0.03770747780799866,\n",
              " 0.037525177001953125,\n",
              " 0.03768777474761009,\n",
              " 0.03753969445824623,\n",
              " 0.038090433925390244,\n",
              " 0.03693054988980293,\n",
              " 0.03769424557685852,\n",
              " 0.03759271278977394,\n",
              " 0.03722045570611954,\n",
              " 0.0383058562874794,\n",
              " 0.03759842738509178,\n",
              " 0.03780968487262726,\n",
              " 0.03754114359617233,\n",
              " 0.037684280425310135,\n",
              " 0.037851374596357346,\n",
              " 0.03729468956589699,\n",
              " 0.038211286067962646,\n",
              " 0.036723095923662186,\n",
              " 0.03774191066622734,\n",
              " 0.03735692426562309,\n",
              " 0.03735368326306343,\n",
              " 0.0381055623292923,\n",
              " 0.03741328418254852,\n",
              " 0.037910763174295425,\n",
              " 0.036882348358631134,\n",
              " 0.03875010460615158,\n",
              " 0.03780025243759155,\n",
              " 0.03746131807565689,\n",
              " 0.037381429225206375,\n",
              " 0.037942446768283844,\n",
              " 0.037344302982091904,\n",
              " 0.038034189492464066,\n",
              " 0.037724532186985016,\n",
              " 0.037480223923921585,\n",
              " 0.037937361747026443,\n",
              " 0.03708522021770477,\n",
              " 0.03769679740071297,\n",
              " 0.03751630708575249,\n",
              " 0.03751230239868164,\n",
              " 0.037909820675849915,\n",
              " 0.03737097978591919,\n",
              " 0.03803499788045883,\n",
              " 0.037376902997493744,\n",
              " 0.038065649569034576,\n",
              " 0.03801684454083443,\n",
              " 0.037116751074790955,\n",
              " 0.037405770272016525,\n",
              " 0.038000959903001785,\n",
              " 0.037215668708086014,\n",
              " 0.03827577456831932,\n",
              " 0.03809899464249611,\n",
              " 0.03699593245983124,\n",
              " 0.03773021325469017,\n",
              " 0.03740520030260086,\n",
              " 0.03793872147798538,\n",
              " 0.03709324821829796,\n",
              " 0.03752371296286583,\n",
              " 0.037886135280132294,\n",
              " 0.03769815340638161,\n",
              " 0.0375201478600502,\n",
              " 0.03756813332438469,\n",
              " 0.03763763606548309,\n",
              " 0.03759470209479332,\n",
              " 0.037574950605630875,\n",
              " 0.03736724331974983,\n",
              " 0.0380733422935009,\n",
              " 0.03783133625984192,\n",
              " 0.03730729594826698,\n",
              " 0.03805193305015564,\n",
              " 0.03703521937131882,\n",
              " 0.03762310743331909,\n",
              " 0.03765656799077988,\n",
              " 0.03781744837760925,\n",
              " 0.037325575947761536,\n",
              " 0.03797318413853645,\n",
              " 0.03701115772128105,\n",
              " 0.03748495504260063,\n",
              " 0.03788638487458229,\n",
              " 0.03754574432969093,\n",
              " 0.037740930914878845,\n",
              " 0.03787226974964142,\n",
              " 0.0372408963739872,\n",
              " 0.037739742547273636,\n",
              " 0.037385351955890656,\n",
              " 0.03784732520580292,\n",
              " 0.037310972809791565,\n",
              " 0.03739144653081894,\n",
              " 0.037986576557159424,\n",
              " 0.03722769394516945,\n",
              " 0.03828496113419533,\n",
              " 0.03753090277314186,\n",
              " 0.03777339309453964,\n",
              " 0.037400223314762115,\n",
              " 0.03800049051642418,\n",
              " 0.038010336458683014,\n",
              " 0.03704051300883293,\n",
              " 0.03751254826784134,\n",
              " 0.03790725767612457,\n",
              " 0.03812795132398605,\n",
              " 0.0369560532271862,\n",
              " 0.03774178400635719,\n",
              " 0.03744189813733101,\n",
              " 0.037633225321769714,\n",
              " 0.03758976235985756,\n",
              " 0.03720178082585335,\n",
              " 0.03829988092184067,\n",
              " 0.037837572395801544,\n",
              " 0.03737550973892212,\n",
              " 0.03731232509016991,\n",
              " 0.03821192681789398,\n",
              " 0.037875112146139145,\n",
              " 0.037129029631614685,\n",
              " 0.03796787187457085,\n",
              " 0.037247899919748306,\n",
              " 0.03758363425731659,\n",
              " 0.03763749450445175,\n",
              " 0.0378846749663353,\n",
              " 0.03731613606214523,\n",
              " 0.03729037195444107,\n",
              " 0.03816170617938042,\n",
              " 0.03763184696435928,\n",
              " 0.03767160326242447,\n",
              " 0.03784298151731491,\n",
              " 0.03727483004331589,\n",
              " 0.037644512951374054,\n",
              " 0.037592556327581406,\n",
              " 0.03758244216442108,\n",
              " 0.037647996097803116,\n",
              " 0.03717551380395889,\n",
              " 0.038278140127658844,\n",
              " 0.03715813532471657,\n",
              " 0.03845914080739021,\n",
              " 0.037550076842308044,\n",
              " 0.03788469731807709,\n",
              " 0.037524621933698654,\n",
              " 0.03783510997891426,\n",
              " 0.037364277988672256,\n",
              " 0.03802766650915146,\n",
              " 0.037805814296007156,\n",
              " 0.03745291382074356,\n",
              " 0.037916965782642365,\n",
              " 0.03723287954926491,\n",
              " 0.03765163943171501,\n",
              " 0.03759611397981644,\n",
              " 0.03745773434638977,\n",
              " 0.03778970614075661,\n",
              " 0.037735339254140854,\n",
              " 0.03748799115419388,\n",
              " 0.03755062073469162,\n",
              " 0.03775455430150032,\n",
              " 0.0374419130384922,\n",
              " 0.037928659468889236,\n",
              " 0.03742784261703491,\n",
              " 0.03787560015916824,\n",
              " 0.037694044411182404,\n",
              " 0.037522949278354645,\n",
              " 0.03773244842886925,\n",
              " 0.03743862733244896,\n",
              " 0.03802989050745964,\n",
              " 0.03696113079786301,\n",
              " 0.037662338465452194,\n",
              " 0.03763822093605995,\n",
              " 0.03768393397331238,\n",
              " 0.03753599897027016,\n",
              " 0.03764231503009796,\n",
              " 0.03765714913606644,\n",
              " 0.03737948462367058,\n",
              " 0.03801703453063965,\n",
              " 0.037840958684682846,\n",
              " 0.03734859079122543,\n",
              " 0.037859559059143066,\n",
              " 0.03736790642142296,\n",
              " 0.03765874728560448,\n",
              " 0.03760072961449623,\n",
              " 0.03799058869481087,\n",
              " 0.0371461845934391,\n",
              " 0.037749797105789185,\n",
              " 0.03750895336270332,\n",
              " 0.037994544953107834,\n",
              " 0.03710244968533516,\n",
              " 0.0376264862716198,\n",
              " 0.0376175232231617,\n",
              " 0.037425681948661804,\n",
              " 0.03785640001296997,\n",
              " 0.03754037991166115,\n",
              " 0.037931889295578,\n",
              " 0.03712058439850807,\n",
              " 0.03831639140844345,\n",
              " 0.037583332508802414,\n",
              " 0.03773929178714752,\n",
              " 0.03761164844036102,\n",
              " 0.03768695518374443,\n",
              " 0.037667710334062576,\n",
              " 0.037617165595293045,\n",
              " 0.03750668093562126,\n",
              " 0.037797246128320694,\n",
              " 0.03788655996322632,\n",
              " 0.03722810372710228,\n",
              " 0.037569161504507065,\n",
              " 0.03773186355829239,\n",
              " 0.03767084702849388,\n",
              " 0.037672847509384155,\n",
              " 0.037809714674949646,\n",
              " 0.037284985184669495,\n",
              " 0.037782590836286545,\n",
              " 0.03748700022697449,\n",
              " 0.03799613192677498,\n",
              " 0.03712257742881775,\n",
              " 0.037957437336444855,\n",
              " 0.03706654533743858,\n",
              " 0.03807083144783974,\n",
              " 0.03702197223901749,\n",
              " 0.03745047003030777,\n",
              " 0.03785422816872597,\n",
              " 0.037509262561798096,\n",
              " 0.037742506712675095,\n",
              " 0.037653952836990356,\n",
              " 0.03756820783019066,\n",
              " 0.03750777617096901,\n",
              " 0.03786575794219971,\n",
              " 0.037673935294151306,\n",
              " 0.03766100853681564,\n",
              " 0.037634193897247314,\n",
              " 0.037517134100198746,\n",
              " 0.037729501724243164,\n",
              " 0.037577297538518906,\n",
              " 0.03749329596757889,\n",
              " 0.03780435025691986,\n",
              " 0.03749673813581467,\n",
              " 0.0379444882273674,\n",
              " 0.03793645277619362,\n",
              " 0.03712541237473488,\n",
              " 0.03724682331085205,\n",
              " 0.03819785267114639,\n",
              " 0.037730902433395386,\n",
              " 0.03754657134413719,\n",
              " 0.03791683539748192,\n",
              " 0.037158966064453125,\n",
              " 0.03770497813820839,\n",
              " 0.03757505491375923,\n",
              " 0.03792527690529823,\n",
              " 0.037254516035318375,\n",
              " 0.037473320960998535,\n",
              " 0.03781332075595856,\n",
              " 0.03735698014497757,\n",
              " 0.03808387368917465,\n",
              " 0.037753209471702576,\n",
              " 0.03744006156921387,\n",
              " 0.0377742275595665,\n",
              " 0.03743637353181839,\n",
              " 0.038061756640672684,\n",
              " 0.036971498280763626,\n",
              " 0.03761583939194679,\n",
              " 0.03774658590555191,\n",
              " 0.03760687634348869,\n",
              " 0.037728194147348404,\n",
              " 0.03730412945151329,\n",
              " 0.03808068484067917,\n",
              " 0.03754572197794914,\n",
              " 0.037700194865465164,\n",
              " 0.03769812360405922,\n",
              " 0.0374615378677845,\n",
              " 0.03810218721628189,\n",
              " 0.03701365366578102,\n",
              " 0.03776496648788452,\n",
              " 0.03740861266851425,\n",
              " 0.03801523521542549,\n",
              " 0.037044208496809006,\n",
              " 0.03751145303249359,\n",
              " 0.037868741899728775,\n",
              " 0.03760183975100517,\n",
              " 0.03779161721467972,\n",
              " 0.037353403866291046,\n",
              " 0.03815165162086487,\n",
              " 0.03748820722103119,\n",
              " 0.03788483515381813,\n",
              " 0.0374918095767498,\n",
              " 0.03775787726044655,\n",
              " 0.038057830184698105,\n",
              " 0.037011802196502686,\n",
              " 0.037418268620967865,\n",
              " 0.03799081966280937,\n",
              " 0.03769080713391304,\n",
              " 0.03758411109447479,\n",
              " 0.0376519151031971,\n",
              " 0.037636347115039825,\n",
              " 0.037685178220272064,\n",
              " 0.03763173520565033,\n",
              " 0.03801517188549042,\n",
              " 0.037216369062662125,\n",
              " 0.03740597143769264,\n",
              " 0.03787181153893471,\n",
              " 0.037465035915374756,\n",
              " 0.03788842633366585,\n",
              " 0.03787396103143692,\n",
              " 0.037187933921813965,\n",
              " 0.03775571659207344,\n",
              " 0.03749817982316017,\n",
              " 0.03788318112492561,\n",
              " 0.037315499037504196,\n",
              " 0.03773101791739464,\n",
              " 0.03745449334383011,\n",
              " 0.0374738834798336,\n",
              " 0.03788738325238228,\n",
              " 0.03696904331445694,\n",
              " 0.03865745663642883,\n",
              " 0.037688449025154114,\n",
              " 0.03755943849682808,\n",
              " 0.03745080530643463,\n",
              " 0.03789931908249855,\n",
              " 0.03771807625889778,\n",
              " 0.037474341690540314,\n",
              " 0.037847429513931274,\n",
              " 0.03735899180173874,\n",
              " 0.037545643746852875,\n",
              " 0.03779461979866028,\n",
              " 0.0377873033285141,\n",
              " 0.037395115941762924,\n",
              " 0.037257712334394455,\n",
              " 0.03812884911894798,\n",
              " 0.03785323351621628,\n",
              " 0.03742946311831474,\n",
              " 0.03788980096578598,\n",
              " 0.03716028481721878,\n",
              " 0.037109117954969406,\n",
              " 0.03850777819752693,\n",
              " 0.037203725427389145,\n",
              " 0.03826265409588814,\n",
              " 0.03761059418320656,\n",
              " 0.037657734006643295,\n",
              " 0.037976063787937164,\n",
              " 0.037254225462675095,\n",
              " 0.03751136362552643,\n",
              " 0.03777902573347092,\n",
              " 0.037719011306762695,\n",
              " 0.03755754977464676,\n",
              " 0.037797048687934875,\n",
              " 0.03734862059354782,\n",
              " 0.037541139870882034,\n",
              " 0.037776101380586624,\n",
              " 0.03782278671860695,\n",
              " 0.037235405296087265,\n",
              " 0.03755933791399002,\n",
              " 0.037727102637290955,\n",
              " 0.03790000453591347,\n",
              " 0.03722761943936348,\n",
              " 0.03775107488036156,\n",
              " 0.0375402458012104,\n",
              " 0.037590451538562775,\n",
              " 0.03773973882198334,\n",
              " 0.03784635663032532,\n",
              " 0.03732689470052719,\n",
              " 0.03740924596786499,\n",
              " 0.03803178668022156,\n",
              " 0.03772308677434921,\n",
              " 0.03743438795208931,\n",
              " 0.038252972066402435,\n",
              " 0.036785244941711426,\n",
              " 0.03805038705468178,\n",
              " 0.03702416270971298,\n",
              " 0.03757694736123085,\n",
              " 0.037753865122795105,\n",
              " 0.03769681975245476,\n",
              " 0.03754749521613121,\n",
              " 0.03782421350479126,\n",
              " 0.03736009821295738,\n",
              " 0.03758449852466583,\n",
              " 0.03763207048177719,\n",
              " 0.037624605000019073,\n",
              " 0.037680577486753464,\n",
              " 0.03733443096280098,\n",
              " 0.03805161267518997,\n",
              " 0.03758722171187401,\n",
              " 0.0376831516623497,\n",
              " 0.037810977548360825,\n",
              " 0.03742142766714096,\n",
              " 0.037638258188962936,\n",
              " 0.037651143968105316,\n",
              " 0.037859562784433365,\n",
              " 0.03719744086265564,\n",
              " 0.03787888586521149,\n",
              " 0.03722313046455383,\n",
              " 0.037956949323415756,\n",
              " 0.03714142367243767,\n",
              " 0.037360578775405884,\n",
              " 0.03812602534890175,\n",
              " 0.03742978721857071,\n",
              " 0.03793705627322197,\n",
              " 0.0377759113907814,\n",
              " 0.037325065582990646,\n",
              " 0.03745757415890694,\n",
              " 0.03790157288312912,\n",
              " 0.037756871432065964,\n",
              " 0.03758465498685837,\n",
              " 0.03798028454184532,\n",
              " 0.03715852275490761,\n",
              " 0.037762414664030075,\n",
              " 0.037454813718795776,\n",
              " 0.03776432201266289,\n",
              " 0.03735501319169998,\n",
              " 0.037428393959999084,\n",
              " 0.03787660971283913,\n",
              " 0.03718569874763489,\n",
              " 0.038441598415374756,\n",
              " 0.03793925791978836,\n",
              " 0.037123970687389374,\n",
              " 0.03753823786973953,\n",
              " 0.0376744419336319,\n",
              " 0.03781770169734955,\n",
              " 0.03732487931847572,\n",
              " 0.03771868720650673,\n",
              " 0.0375383086502552,\n",
              " 0.03826781362295151,\n",
              " 0.036687757819890976,\n",
              " 0.03734873607754707,\n",
              " 0.03795670345425606,\n",
              " 0.03747139498591423,\n",
              " 0.03788437694311142,\n",
              " 0.03803957253694534,\n",
              " 0.03695794194936752,\n",
              " 0.03803836181759834,\n",
              " 0.03704468905925751,\n",
              " 0.037488337606191635,\n",
              " 0.03785095736384392,\n",
              " 0.03807177022099495,\n",
              " 0.03707965090870857,\n",
              " 0.037809308618307114,\n",
              " 0.03732916712760925,\n",
              " 0.037454236298799515,\n",
              " 0.03794172406196594,\n",
              " 0.03751898184418678,\n",
              " 0.037751395255327225,\n",
              " 0.03721673786640167,\n",
              " 0.03824726119637489,\n",
              " 0.03763306140899658,\n",
              " 0.0376870259642601,\n",
              " 0.03772642835974693,\n",
              " 0.03756598010659218,\n",
              " 0.03781167045235634,\n",
              " 0.03733948618173599,\n",
              " 0.03783789649605751,\n",
              " 0.037497226148843765,\n",
              " 0.03790139779448509,\n",
              " 0.0371687225997448,\n",
              " 0.03717314079403877,\n",
              " 0.038352418690919876,\n",
              " 0.037477705627679825,\n",
              " 0.037816017866134644,\n",
              " 0.037397004663944244,\n",
              " 0.037958551198244095,\n",
              " 0.037757664918899536,\n",
              " 0.03735680878162384,\n",
              " 0.037683919072151184,\n",
              " 0.037462420761585236,\n",
              " 0.03745906427502632,\n",
              " 0.03790479525923729,\n",
              " 0.03806772455573082,\n",
              " 0.03711540624499321,\n",
              " 0.037845224142074585,\n",
              " 0.0372602753341198,\n",
              " 0.03778010979294777,\n",
              " 0.03734264150261879,\n",
              " 0.037451088428497314,\n",
              " 0.03796420991420746,\n",
              " 0.03762710094451904,\n",
              " 0.037717923521995544,\n",
              " 0.03791368007659912,\n",
              " 0.037227727472782135,\n",
              " 0.03769952058792114,\n",
              " 0.037566520273685455,\n",
              " 0.03760021552443504,\n",
              " 0.03773070499300957,\n",
              " 0.03695487603545189,\n",
              " 0.03862696886062622,\n",
              " 0.03816882148385048,\n",
              " 0.03676611930131912,\n",
              " 0.037751730531454086,\n",
              " 0.037458471953868866,\n",
              " 0.037245526909828186,\n",
              " 0.03810805082321167,\n",
              " 0.03737218305468559,\n",
              " 0.03795359656214714,\n",
              " 0.037542082369327545,\n",
              " 0.03776797279715538,\n",
              " 0.037270840257406235,\n",
              " 0.038137082010507584,\n",
              " 0.037272240966558456,\n",
              " 0.038209158927202225,\n",
              " 0.03711854666471481,\n",
              " 0.03841467946767807,\n",
              " 0.037449609488248825,\n",
              " 0.037920817732810974,\n",
              " 0.03753930702805519,\n",
              " 0.03772779181599617,\n",
              " 0.037440769374370575,\n",
              " 0.037877097725868225,\n",
              " 0.03761639446020126,\n",
              " 0.03763223811984062,\n",
              " 0.037310779094696045,\n",
              " 0.037977512925863266,\n",
              " 0.03780221939086914,\n",
              " 0.03728143498301506,\n",
              " 0.03751711919903755,\n",
              " 0.03784932568669319,\n",
              " 0.037939876317977905,\n",
              " 0.03719901666045189,\n",
              " 0.03785531222820282,\n",
              " 0.037213362753391266,\n",
              " 0.0375509113073349,\n",
              " 0.037779491394758224,\n",
              " 0.03784932196140289,\n",
              " 0.03726871684193611,\n",
              " 0.03740227594971657,\n",
              " 0.03794121369719505,\n",
              " 0.037696849554777145,\n",
              " 0.0375078022480011,\n",
              " 0.03705506771802902,\n",
              " 0.0384649857878685,\n",
              " 0.03754468634724617,\n",
              " 0.037688832730054855,\n",
              " 0.03794889897108078,\n",
              " 0.03707245737314224,\n",
              " 0.03744564577937126,\n",
              " 0.03787316754460335,\n",
              " 0.037898845970630646,\n",
              " 0.03730959817767143,\n",
              " 0.03801116719841957,\n",
              " 0.03717270493507385,\n",
              " 0.03743312507867813,\n",
              " 0.03788834065198898,\n",
              " 0.037558816373348236,\n",
              " 0.037759482860565186,\n",
              " 0.03744928166270256,\n",
              " 0.037843506783246994,\n",
              " 0.03709395229816437,\n",
              " 0.038458507508039474,\n",
              " 0.03758906200528145,\n",
              " 0.037568312138319016,\n",
              " 0.03779253363609314,\n",
              " 0.03738008067011833,\n",
              " 0.03784219175577164,\n",
              " 0.03741665557026863,\n",
              " 0.037583231925964355,\n",
              " 0.03767526149749756,\n",
              " 0.03758889064192772,\n",
              " 0.037712518125772476,\n",
              " 0.03725240379571915,\n",
              " 0.03813367709517479,\n",
              " 0.03777444735169411,\n",
              " 0.037386372685432434,\n",
              " 0.037908460944890976,\n",
              " 0.03710818663239479,\n",
              " 0.038055505603551865,\n",
              " 0.036986541002988815,\n",
              " 0.03775176778435707,\n",
              " 0.0374605692923069,\n",
              " 0.03712946176528931,\n",
              " 0.03836098313331604,\n",
              " 0.037452857941389084,\n",
              " 0.03790541738271713,\n",
              " 0.037963803857564926,\n",
              " 0.03715577721595764,\n",
              " 0.03731662780046463,\n",
              " 0.038048937916755676,\n",
              " 0.03798074647784233,\n",
              " 0.037069592624902725,\n",
              " 0.03814839571714401,\n",
              " 0.03684879094362259,\n",
              " 0.037748560309410095,\n",
              " 0.0374973826110363,\n",
              " 0.0374273844063282,\n",
              " 0.03792807459831238,\n",
              " 0.0377938449382782,\n",
              " 0.03736314922571182,\n",
              " 0.037922248244285583,\n",
              " 0.03727676719427109,\n",
              " 0.037340644747018814,\n",
              " 0.038094617426395416,\n",
              " 0.03754090145230293,\n",
              " 0.037689607590436935,\n",
              " 0.03805287554860115,\n",
              " 0.03704031929373741,\n",
              " 0.0373678058385849,\n",
              " 0.03809374198317528,\n",
              " 0.03732402250170708,\n",
              " 0.03813571110367775,\n",
              " 0.037483345717191696,\n",
              " 0.03786667436361313,\n",
              " 0.03754400834441185,\n",
              " 0.037611231207847595,\n",
              " 0.037831712514162064,\n",
              " 0.03725864365696907,\n",
              " 0.037514373660087585,\n",
              " 0.03774517774581909,\n",
              " 0.03722678869962692,\n",
              " 0.03821505233645439,\n",
              " 0.03709283843636513,\n",
              " 0.038435015827417374,\n",
              " 0.037701722234487534,\n",
              " 0.037587009370326996,\n",
              " 0.03724096715450287,\n",
              " 0.038148973137140274,\n",
              " 0.03787907958030701,\n",
              " 0.03720957785844803,\n",
              " 0.037673838436603546,\n",
              " 0.03758164867758751,\n",
              " 0.03758896887302399,\n",
              " 0.037690382450819016,\n",
              " 0.03772721812129021,\n",
              " 0.037580106407403946,\n",
              " 0.0376955009996891,\n",
              " 0.03754330053925514,\n",
              " 0.03737952560186386,\n",
              " 0.038010574877262115,\n",
              " 0.03766190633177757,\n",
              " 0.03763147071003914,\n",
              " 0.037625957280397415,\n",
              " 0.03766251355409622,\n",
              " 0.03730596601963043,\n",
              " 0.038086868822574615,\n",
              " 0.03782830014824867,\n",
              " 0.03728068619966507,\n",
              " 0.037817101925611496,\n",
              " 0.03730299323797226,\n",
              " 0.03766227886080742,\n",
              " 0.037620462477207184,\n",
              " 0.037877801805734634,\n",
              " 0.03724602237343788,\n",
              " 0.037983160465955734,\n",
              " 0.03715400770306587,\n",
              " 0.03762809559702873,\n",
              " 0.03766750171780586,\n",
              " 0.03721414506435394,\n",
              " 0.038197387009859085,\n",
              " 0.03751834109425545,\n",
              " 0.03779520094394684,\n",
              " 0.0374000184237957,\n",
              " 0.037986401468515396,\n",
              " 0.0374981164932251,\n",
              " 0.037800271064043045,\n",
              " 0.0374348945915699,\n",
              " 0.03794087842106819,\n",
              " 0.037757690995931625,\n",
              " 0.037370435893535614,\n",
              " 0.037710174918174744,\n",
              " 0.037591636180877686,\n",
              " 0.037212446331977844,\n",
              " 0.038316451013088226,\n",
              " 0.03710830211639404,\n",
              " 0.038406092673540115,\n",
              " 0.03754587098956108,\n",
              " 0.03780645877122879,\n",
              " 0.03789478540420532,\n",
              " 0.03726763278245926,\n",
              " 0.037729959934949875,\n",
              " 0.037422072142362595,\n",
              " 0.03766140714287758,\n",
              " 0.037660468369722366,\n",
              " 0.03811214119195938,\n",
              " 0.03690425679087639,\n",
              " 0.03764517232775688,\n",
              " 0.037578921765089035,\n",
              " 0.03780948370695114,\n",
              " 0.03738468885421753,\n",
              " 0.037895720452070236,\n",
              " 0.03722652420401573,\n",
              " 0.03757777810096741,\n",
              " 0.037718888372182846,\n",
              " 0.036998264491558075,\n",
              " 0.03847833350300789,\n",
              " 0.03766384720802307,\n",
              " 0.037612415850162506,\n",
              " 0.037522684782743454,\n",
              " 0.0378083698451519,\n",
              " 0.037515003234148026,\n",
              " 0.03778056055307388,\n",
              " 0.037407997995615005,\n",
              " 0.038015030324459076,\n",
              " 0.037540044635534286,\n",
              " 0.037820957601070404,\n",
              " 0.03768739849328995,\n",
              " 0.03765449672937393,\n",
              " 0.03813721239566803,\n",
              " 0.03684866800904274,\n",
              " 0.03775961324572563,\n",
              " 0.03740280494093895,\n",
              " 0.03784602880477905,\n",
              " 0.03738068416714668,\n",
              " 0.03783021867275238,\n",
              " 0.037349551916122437,\n",
              " 0.038044486194849014,\n",
              " 0.037113260477781296,\n",
              " 0.03803912177681923,\n",
              " 0.03703615069389343,\n",
              " 0.037476785480976105,\n",
              " 0.037884894758462906,\n",
              " 0.03741982579231262,\n",
              " 0.03796956688165665,\n",
              " 0.03748134896159172,\n",
              " 0.03779028356075287,\n",
              " 0.037981029599905014,\n",
              " 0.03713458776473999,\n",
              " 0.037915416061878204,\n",
              " 0.03725718334317207,\n",
              " 0.037353821098804474,\n",
              " 0.03812916949391365,\n",
              " 0.03765458986163139,\n",
              " 0.037605009973049164,\n",
              " 0.03749215230345726,\n",
              " 0.03789692372083664,\n",
              " 0.037509310990571976,\n",
              " 0.037759650498628616,\n",
              " 0.037474896758794785,\n",
              " 0.03784765303134918,\n",
              " 0.037574879825115204,\n",
              " 0.03770527243614197,\n",
              " 0.03759815916419029,\n",
              " 0.03770521655678749,\n",
              " 0.037711773067712784,\n",
              " 0.037578243762254715,\n",
              " 0.03762652724981308,\n",
              " 0.03759552165865898,\n",
              " 0.03766549006104469,\n",
              " 0.03761754184961319,\n",
              " 0.037403132766485214,\n",
              " 0.03798547759652138,\n",
              " 0.03784115985035896,\n",
              " 0.037226490676403046,\n",
              " 0.03784790262579918,\n",
              " 0.03730632737278938,\n",
              " 0.03769707679748535,\n",
              " 0.037603382021188736,\n",
              " 0.037701912224292755,\n",
              " 0.03747517243027687,\n",
              " 0.037751153111457825,\n",
              " 0.037420064210891724,\n",
              " 0.03781191632151604,\n",
              " 0.03740160912275314,\n",
              " 0.03773198276758194,\n",
              " 0.03730550780892372,\n",
              " 0.03757351636886597,\n",
              " 0.0377669632434845,\n",
              " 0.03726513311266899,\n",
              " 0.038272466510534286,\n",
              " 0.03793516382575035,\n",
              " 0.03732016310095787,\n",
              " 0.03736773878335953,\n",
              " 0.03804919123649597,\n",
              " 0.038128964602947235,\n",
              " 0.0368371307849884,\n",
              " 0.03780146315693855,\n",
              " 0.037529878318309784,\n",
              " 0.037861697375774384,\n",
              " 0.037223149091005325,\n",
              " 0.038052208721637726,\n",
              " 0.03714181110262871,\n",
              " 0.03752010315656662,\n",
              " 0.03772801533341408,\n",
              " 0.03768541291356087,\n",
              " 0.03750383108854294,\n",
              " 0.03791764751076698,\n",
              " 0.03723223879933357,\n",
              " 0.03799033537507057,\n",
              " 0.03707129880785942,\n",
              " 0.03790968656539917,\n",
              " 0.03733225166797638,\n",
              " 0.03760269284248352,\n",
              " 0.03774480149149895,\n",
              " 0.037670377641916275,\n",
              " 0.037546854466199875,\n",
              " 0.03765007480978966,\n",
              " 0.037570200860500336,\n",
              " 0.03750862926244736,\n",
              " 0.03781742975115776,\n",
              " 0.03764454647898674,\n",
              " 0.03765609860420227,\n",
              " 0.037621766328811646,\n",
              " 0.0377255342900753,\n",
              " 0.03751856088638306,\n",
              " 0.03775697946548462,\n",
              " 0.0378105603158474,\n",
              " 0.037413064390420914,\n",
              " 0.03765273466706276,\n",
              " 0.03771787881851196,\n",
              " 0.038131795823574066,\n",
              " 0.03690456598997116,\n",
              " 0.0380614697933197,\n",
              " 0.037101320922374725,\n",
              " 0.037703581154346466,\n",
              " 0.037527862936258316,\n",
              " 0.037745337933301926,\n",
              " 0.037471186369657516,\n",
              " 0.03780703991651535,\n",
              " 0.03736655041575432,\n",
              " 0.03791021183133125,\n",
              " 0.03717151656746864,\n",
              " 0.03787475451827049,\n",
              " 0.03724949061870575,\n",
              " 0.037797801196575165,\n",
              " 0.03731519356369972,\n",
              " 0.037628356367349625,\n",
              " 0.03761562332510948,\n",
              " 0.037689849734306335,\n",
              " 0.037592533975839615,\n",
              " 0.03767462074756622,\n",
              " 0.037577491253614426,\n",
              " 0.03747357800602913,\n",
              " 0.03793850168585777,\n",
              " 0.03777036815881729,\n",
              " 0.03743208572268486,\n",
              " 0.03772687539458275,\n",
              " 0.03743397071957588,\n",
              " 0.03739629313349724,\n",
              " 0.03787316754460335,\n",
              " 0.037944111973047256,\n",
              " 0.037152960896492004,\n",
              " 0.037909768521785736,\n",
              " 0.03723993897438049,\n",
              " 0.03774071857333183,\n",
              " 0.037434954196214676,\n",
              " 0.03755269944667816,\n",
              " 0.037806879729032516,\n",
              " 0.03788537532091141,\n",
              " 0.037251487374305725,\n",
              " 0.03753053396940231,\n",
              " 0.037717945873737335,\n",
              " 0.037630967795848846,\n",
              " 0.0376020148396492,\n",
              " 0.037315238267183304,\n",
              " 0.038011450320482254,\n",
              " 0.03786161541938782,\n",
              " 0.0372931994497776,\n",
              " 0.03741760179400444,\n",
              " 0.03787918761372566,\n",
              " 0.03738988935947418,\n",
              " 0.03794483840465546,\n",
              " 0.03729219734668732,\n",
              " 0.03808792680501938,\n",
              " 0.03747854009270668,\n",
              " 0.037811294198036194,\n",
              " 0.037305980920791626,\n",
              " 0.038060735911130905,\n",
              " 0.0373457632958889,\n",
              " 0.03797163814306259,\n",
              " 0.03697850927710533,\n",
              " 0.03845110535621643,\n",
              " 0.03743531182408333,\n",
              " 0.03804284706711769,\n",
              " 0.03783722594380379,\n",
              " 0.03736007213592529,\n",
              " 0.0371951200067997,\n",
              " 0.038210466504096985,\n",
              " 0.03738521412014961,\n",
              " 0.03788354992866516,\n",
              " 0.03759103640913963,\n",
              " 0.037774037569761276,\n",
              " 0.037408750504255295,\n",
              " 0.03801474720239639,\n",
              " 0.03778219223022461,\n",
              " 0.037476930767297745,\n",
              " 0.037340033799409866,\n",
              " 0.0380224883556366,\n",
              " 0.03731851279735565,\n",
              " 0.038028817623853683,\n",
              " 0.037586286664009094,\n",
              " 0.037650056183338165,\n",
              " 0.03728253021836281,\n",
              " 0.03814937174320221,\n",
              " 0.03794505447149277,\n",
              " 0.037173978984355927,\n",
              " 0.03783472627401352,\n",
              " 0.03738349303603172,\n",
              " 0.038061100989580154,\n",
              " 0.037003349512815475,\n",
              " 0.037156447768211365,\n",
              " 0.038409534841775894,\n",
              " 0.0378095880150795,\n",
              " 0.0374535396695137,\n",
              " 0.037871986627578735,\n",
              " 0.03722439706325531,\n",
              " 0.03756186366081238,\n",
              " 0.03774131089448929,\n",
              " 0.03812677040696144,\n",
              " 0.036866601556539536,\n",
              " 0.03750462830066681,\n",
              " 0.0378461591899395,\n",
              " 0.03756510093808174,\n",
              " 0.03767108917236328,\n",
              " 0.03745702654123306,\n",
              " 0.037911541759967804,\n",
              " 0.03765679895877838,\n",
              " 0.037542469799518585,\n",
              " 0.037574488669633865,\n",
              " 0.03789626806974411,\n",
              " 0.03766950964927673,\n",
              " 0.03760390728712082,\n",
              " 0.037876859307289124,\n",
              " 0.03727057948708534,\n",
              " 0.03729305788874626,\n",
              " 0.038133908063173294,\n",
              " 0.0376061275601387,\n",
              " 0.03769614174962044,\n",
              " 0.037799250334501266,\n",
              " 0.03751256689429283,\n",
              " 0.037823766469955444,\n",
              " 0.037351660430431366,\n",
              " 0.037500444799661636,\n",
              " 0.03784826770424843,\n",
              " 0.037187978625297546,\n",
              " 0.03838752210140228,\n",
              " 0.03769898787140846,\n",
              " 0.03744786977767944,\n",
              " 0.03761877119541168,\n",
              " 0.03766242787241936,\n",
              " 0.03765276074409485,\n",
              " 0.037535205483436584,\n",
              " 0.03740246221423149,\n",
              " 0.03789272904396057,\n",
              " 0.037935271859169006,\n",
              " 0.03724105656147003,\n",
              " 0.037870366126298904,\n",
              " 0.03722260892391205,\n",
              " 0.03710548207163811,\n",
              " 0.03843086212873459,\n",
              " 0.03751621022820473,\n",
              " 0.0377199724316597,\n",
              " 0.03778911381959915,\n",
              " 0.037418097257614136,\n",
              " 0.03804324194788933,\n",
              " 0.037042830139398575,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 5"
      ],
      "metadata": {
        "id": "1rFGA6jp68mP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gVVKr6m2xRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCmvF6iP22JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model1.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model1(real_features)\n",
        "        loss = criterion(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model1.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model1(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Plot losses\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RNjbZgQK28lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RA5IWHFd2orR",
        "outputId": "bdd44f1d-d6c3-4e3c-8cf7-54fb83c7ac34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVTvuJJ3onsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(generated_features)"
      ],
      "metadata": {
        "id": "_v2NSflfy4ww",
        "outputId": "b7a67862-7b38-49d1-95b5-e6535e7f508b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_features"
      ],
      "metadata": {
        "id": "UqsEt9K34vkW",
        "outputId": "2fabe951-cd0f-46c9-b12d-ba22acb5cf05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[-0.1050486 ,  0.0592591 , -0.04588313, ...,  0.0681432 ,\n",
              "           0.05616908, -0.07822345],\n",
              "         [-0.09180458,  0.10368504, -0.02269186, ...,  0.080788  ,\n",
              "           0.09603249, -0.21644062],\n",
              "         [-0.10137026,  0.10495242, -0.0299967 , ...,  0.05484535,\n",
              "           0.10793833, -0.20948854],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10067847,  0.06771937, -0.04842731, ...,  0.06707394,\n",
              "           0.06730863, -0.09654537],\n",
              "         [-0.09655349,  0.09838504, -0.02307442, ...,  0.08135854,\n",
              "           0.08672763, -0.19937101],\n",
              "         [-0.10654895,  0.09703689, -0.01857823, ...,  0.06867893,\n",
              "           0.08792984, -0.19429311],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10461126,  0.06491963, -0.04714095, ...,  0.06867933,\n",
              "           0.05878128, -0.08669724],\n",
              "         [-0.09168521,  0.10055253, -0.02711318, ...,  0.07499073,\n",
              "           0.08861582, -0.20904362],\n",
              "         [-0.09862316,  0.10182767, -0.02230792, ...,  0.05916616,\n",
              "           0.09867103, -0.19508171],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10567412,  0.05970036, -0.0457128 , ...,  0.06949127,\n",
              "           0.05475235, -0.07977843],\n",
              "         [-0.09103884,  0.10447767, -0.02107649, ...,  0.0839594 ,\n",
              "           0.09703785, -0.2204105 ],\n",
              "         [-0.10220198,  0.10541014, -0.02933083, ...,  0.05980863,\n",
              "           0.11038655, -0.21552387],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10587838,  0.06364392, -0.04662772, ...,  0.06931551,\n",
              "           0.05758016, -0.08501776],\n",
              "         [-0.09029065,  0.10178299, -0.02609139, ...,  0.07634075,\n",
              "           0.09259861, -0.21383733],\n",
              "         [-0.09743474,  0.10364555, -0.02699101, ...,  0.05627059,\n",
              "           0.103205  , -0.20043904],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10188438,  0.06664818, -0.04957206, ...,  0.06674416,\n",
              "           0.06584059, -0.09433237],\n",
              "         [-0.09617442,  0.09826225, -0.02421855, ...,  0.08071016,\n",
              "           0.08580558, -0.20495132],\n",
              "         [-0.10612684,  0.09734742, -0.01805115, ...,  0.06859252,\n",
              "           0.08892216, -0.19750145],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10556963,  0.05969381, -0.04585102, ...,  0.06787232,\n",
              "           0.05477924, -0.07744896],\n",
              "         [-0.08869904,  0.1045911 , -0.02704651, ...,  0.07364191,\n",
              "           0.09365421, -0.21564516],\n",
              "         [-0.09705819,  0.10819812, -0.03152626, ...,  0.04942324,\n",
              "           0.1049196 , -0.20521861],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10582155,  0.05991479, -0.0458133 , ...,  0.06958824,\n",
              "           0.05552268, -0.08061987],\n",
              "         [-0.09252742,  0.10327734, -0.02175931, ...,  0.08419533,\n",
              "           0.09732684, -0.21971416],\n",
              "         [-0.10221012,  0.10384014, -0.02982329, ...,  0.06046731,\n",
              "           0.10918272, -0.21513468],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10498567,  0.06084574, -0.04646   , ...,  0.06743783,\n",
              "           0.05708665, -0.07927202],\n",
              "         [-0.09149438,  0.10337675, -0.02478732, ...,  0.07807736,\n",
              "           0.09423691, -0.2126596 ],\n",
              "         [-0.09883602,  0.10553637, -0.02922338, ...,  0.05268945,\n",
              "           0.10484164, -0.2027598 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10525143,  0.06419624, -0.04678965, ...,  0.06967433,\n",
              "           0.05895508, -0.08661169],\n",
              "         [-0.09203865,  0.09973094, -0.02616289, ...,  0.07775043,\n",
              "           0.09246886, -0.20965868],\n",
              "         [-0.09862547,  0.10100862, -0.02491973, ...,  0.05857493,\n",
              "           0.10214853, -0.19876865],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10578583,  0.05946093, -0.04552498, ...,  0.07047829,\n",
              "           0.05377477, -0.08051266],\n",
              "         [-0.09148811,  0.10638367, -0.01878802, ...,  0.08661988,\n",
              "           0.09852628, -0.22083333],\n",
              "         [-0.10219447,  0.10180168, -0.02874239, ...,  0.07195383,\n",
              "           0.10838732, -0.21930853],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10583545,  0.06362793, -0.04656396, ...,  0.06933975,\n",
              "           0.05758755, -0.08498275],\n",
              "         [-0.09086217,  0.10108474, -0.02632103, ...,  0.07696924,\n",
              "           0.09276228, -0.21251005],\n",
              "         [-0.09768687,  0.10289387, -0.02770893, ...,  0.05669699,\n",
              "           0.10248467, -0.2011539 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10539092,  0.06411511, -0.04699079, ...,  0.06876518,\n",
              "           0.05829835, -0.08558521],\n",
              "         [-0.09094317,  0.1000571 , -0.02704116, ...,  0.07571211,\n",
              "           0.09165069, -0.20984814],\n",
              "         [-0.09769921,  0.10245599, -0.02513464, ...,  0.05692976,\n",
              "           0.10189627, -0.1975829 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10517174,  0.06115534, -0.04620913, ...,  0.06804135,\n",
              "           0.05699155, -0.0799896 ],\n",
              "         [-0.09195904,  0.10299502, -0.02486687, ...,  0.0783838 ,\n",
              "           0.09471983, -0.21206379],\n",
              "         [-0.09890297,  0.10512158, -0.02940559, ...,  0.05275025,\n",
              "           0.10466412, -0.20251232],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.1050486 ,  0.0592591 , -0.04588313, ...,  0.0681432 ,\n",
              "           0.05616908, -0.07822345],\n",
              "         [-0.09180458,  0.10368504, -0.02269186, ...,  0.080788  ,\n",
              "           0.09603249, -0.21644062],\n",
              "         [-0.10137026,  0.10495242, -0.0299967 , ...,  0.05484535,\n",
              "           0.10793833, -0.20948854],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10067847,  0.06771937, -0.04842731, ...,  0.06707394,\n",
              "           0.06730863, -0.09654537],\n",
              "         [-0.09655349,  0.09838504, -0.02307442, ...,  0.08135854,\n",
              "           0.08672763, -0.19937101],\n",
              "         [-0.10654895,  0.09703689, -0.01857823, ...,  0.06867893,\n",
              "           0.08792984, -0.19429311],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10461126,  0.06491963, -0.04714095, ...,  0.06867933,\n",
              "           0.05878128, -0.08669724],\n",
              "         [-0.09168521,  0.10055253, -0.02711318, ...,  0.07499073,\n",
              "           0.08861582, -0.20904362],\n",
              "         [-0.09862316,  0.10182767, -0.02230792, ...,  0.05916616,\n",
              "           0.09867103, -0.19508171],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10567412,  0.05970036, -0.0457128 , ...,  0.06949127,\n",
              "           0.05475235, -0.07977843],\n",
              "         [-0.09103884,  0.10447767, -0.02107649, ...,  0.0839594 ,\n",
              "           0.09703785, -0.2204105 ],\n",
              "         [-0.10220198,  0.10541014, -0.02933083, ...,  0.05980863,\n",
              "           0.11038655, -0.21552387],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10587838,  0.06364392, -0.04662772, ...,  0.06931551,\n",
              "           0.05758016, -0.08501776],\n",
              "         [-0.09029065,  0.10178299, -0.02609139, ...,  0.07634075,\n",
              "           0.09259861, -0.21383733],\n",
              "         [-0.09743474,  0.10364555, -0.02699101, ...,  0.05627059,\n",
              "           0.103205  , -0.20043904],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10188438,  0.06664818, -0.04957206, ...,  0.06674416,\n",
              "           0.06584059, -0.09433237],\n",
              "         [-0.09617442,  0.09826225, -0.02421855, ...,  0.08071016,\n",
              "           0.08580558, -0.20495132],\n",
              "         [-0.10612684,  0.09734742, -0.01805115, ...,  0.06859252,\n",
              "           0.08892216, -0.19750145],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10556963,  0.05969381, -0.04585102, ...,  0.06787232,\n",
              "           0.05477924, -0.07744896],\n",
              "         [-0.08869904,  0.1045911 , -0.02704651, ...,  0.07364191,\n",
              "           0.09365421, -0.21564516],\n",
              "         [-0.09705819,  0.10819812, -0.03152626, ...,  0.04942324,\n",
              "           0.1049196 , -0.20521861],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10582155,  0.05991479, -0.0458133 , ...,  0.06958824,\n",
              "           0.05552268, -0.08061987],\n",
              "         [-0.09252742,  0.10327734, -0.02175931, ...,  0.08419533,\n",
              "           0.09732684, -0.21971416],\n",
              "         [-0.10221012,  0.10384014, -0.02982329, ...,  0.06046731,\n",
              "           0.10918272, -0.21513468],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10498567,  0.06084574, -0.04646   , ...,  0.06743783,\n",
              "           0.05708665, -0.07927202],\n",
              "         [-0.09149438,  0.10337675, -0.02478732, ...,  0.07807736,\n",
              "           0.09423691, -0.2126596 ],\n",
              "         [-0.09883602,  0.10553637, -0.02922338, ...,  0.05268945,\n",
              "           0.10484164, -0.2027598 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10525143,  0.06419624, -0.04678965, ...,  0.06967433,\n",
              "           0.05895508, -0.08661169],\n",
              "         [-0.09203865,  0.09973094, -0.02616289, ...,  0.07775043,\n",
              "           0.09246886, -0.20965868],\n",
              "         [-0.09862547,  0.10100862, -0.02491973, ...,  0.05857493,\n",
              "           0.10214853, -0.19876865],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10578583,  0.05946093, -0.04552498, ...,  0.07047829,\n",
              "           0.05377477, -0.08051266],\n",
              "         [-0.09148811,  0.10638367, -0.01878802, ...,  0.08661988,\n",
              "           0.09852628, -0.22083333],\n",
              "         [-0.10219447,  0.10180168, -0.02874239, ...,  0.07195383,\n",
              "           0.10838732, -0.21930853],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10583545,  0.06362793, -0.04656396, ...,  0.06933975,\n",
              "           0.05758755, -0.08498275],\n",
              "         [-0.09086217,  0.10108474, -0.02632103, ...,  0.07696924,\n",
              "           0.09276228, -0.21251005],\n",
              "         [-0.09768687,  0.10289387, -0.02770893, ...,  0.05669699,\n",
              "           0.10248467, -0.2011539 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10539092,  0.06411511, -0.04699079, ...,  0.06876518,\n",
              "           0.05829835, -0.08558521],\n",
              "         [-0.09094317,  0.1000571 , -0.02704116, ...,  0.07571211,\n",
              "           0.09165069, -0.20984814],\n",
              "         [-0.09769921,  0.10245599, -0.02513464, ...,  0.05692976,\n",
              "           0.10189627, -0.1975829 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10517174,  0.06115534, -0.04620913, ...,  0.06804135,\n",
              "           0.05699155, -0.0799896 ],\n",
              "         [-0.09195904,  0.10299502, -0.02486687, ...,  0.0783838 ,\n",
              "           0.09471983, -0.21206379],\n",
              "         [-0.09890297,  0.10512158, -0.02940559, ...,  0.05275025,\n",
              "           0.10466412, -0.20251232],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[ 0.14715578, -0.16542408,  0.18437177, ..., -0.06599808,\n",
              "          -0.194534  , -0.10618176],\n",
              "         [ 0.10362137, -0.14128314,  0.09954125, ..., -0.05560563,\n",
              "          -0.1580073 , -0.10774528],\n",
              "         [ 0.16606233, -0.15659708,  0.18928455, ..., -0.05213925,\n",
              "          -0.24475367, -0.05628156],\n",
              "         ...,\n",
              "         [ 0.13541538, -0.26515076,  0.13885772, ..., -0.04544246,\n",
              "          -0.16899347, -0.14278817],\n",
              "         [ 0.1359779 , -0.22044528, -0.00206409, ..., -0.10156794,\n",
              "          -0.19889742, -0.11590512],\n",
              "         [ 0.21420138, -0.21500239,  0.00319653, ..., -0.13956453,\n",
              "          -0.24934407, -0.05588746]],\n",
              " \n",
              "        [[ 0.16477555, -0.06135626,  0.09290937, ..., -0.05219459,\n",
              "          -0.1713922 ,  0.0260768 ],\n",
              "         [ 0.09882579, -0.16578633,  0.18301982, ..., -0.11404131,\n",
              "          -0.2243915 , -0.15205419],\n",
              "         [ 0.18069947, -0.08873253,  0.14884457, ..., -0.13759555,\n",
              "          -0.11434382, -0.08739879],\n",
              "         ...,\n",
              "         [ 0.08101115, -0.17590156,  0.14645568, ..., -0.07591494,\n",
              "          -0.14537112, -0.15541542],\n",
              "         [ 0.02297843, -0.16046882,  0.07823843, ...,  0.01271709,\n",
              "          -0.15709174, -0.09212461],\n",
              "         [ 0.15350382, -0.11757664,  0.11475099, ..., -0.08773544,\n",
              "          -0.15228795, -0.15729983]],\n",
              " \n",
              "        [[ 0.19625607, -0.10513404,  0.1720267 , ..., -0.14063212,\n",
              "          -0.10676042, -0.11211985],\n",
              "         [ 0.08202307, -0.15279388,  0.17499691, ..., -0.07344791,\n",
              "          -0.14854023, -0.17358261],\n",
              "         [ 0.13362864, -0.11295694,  0.04033468, ...,  0.0136869 ,\n",
              "          -0.15564333, -0.11587361],\n",
              "         ...,\n",
              "         [ 0.18760253, -0.14409575,  0.15215302, ...,  0.04425725,\n",
              "          -0.10952446, -0.07489967],\n",
              "         [ 0.22584888, -0.02724155,  0.09378228, ..., -0.12253709,\n",
              "          -0.12001681, -0.10705646],\n",
              "         [ 0.14477237, -0.1313594 ,  0.09489768, ..., -0.14119436,\n",
              "          -0.18217444, -0.05178448]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.09340491, -0.09403218,  0.21313003, ..., -0.12483843,\n",
              "          -0.04272227, -0.19625601],\n",
              "         [ 0.12872902, -0.13311672,  0.07659397, ..., -0.07318188,\n",
              "          -0.11709195, -0.15438503],\n",
              "         [ 0.09382847, -0.16081762,  0.05277772, ...,  0.01932165,\n",
              "          -0.11158763, -0.02525219],\n",
              "         ...,\n",
              "         [ 0.18025437, -0.16214299,  0.13609508, ...,  0.01245904,\n",
              "          -0.14663109,  0.01791615],\n",
              "         [ 0.14156541,  0.03468968,  0.12890586, ..., -0.05683227,\n",
              "          -0.06136257, -0.12050888],\n",
              "         [ 0.14283742, -0.21240726,  0.11469093, ..., -0.00893003,\n",
              "          -0.13280156, -0.09480312]],\n",
              " \n",
              "        [[ 0.16953275, -0.11783055,  0.14098072, ..., -0.0295395 ,\n",
              "          -0.13129282, -0.0034175 ],\n",
              "         [ 0.17784333, -0.13633081,  0.12348992, ..., -0.0726242 ,\n",
              "          -0.16142902,  0.14812173],\n",
              "         [ 0.14779486, -0.1364724 ,  0.19508633, ..., -0.20535518,\n",
              "          -0.1571775 ,  0.02822113],\n",
              "         ...,\n",
              "         [ 0.16721046, -0.1335326 ,  0.19241719, ..., -0.10516556,\n",
              "          -0.06357863, -0.07939464],\n",
              "         [ 0.11449449, -0.13916475,  0.26342067, ..., -0.13299777,\n",
              "          -0.10400392, -0.01540275],\n",
              "         [ 0.06741031, -0.10182379,  0.13750848, ..., -0.05598905,\n",
              "          -0.0533461 , -0.04988701]],\n",
              " \n",
              "        [[ 0.09741934, -0.09081461,  0.15483874, ...,  0.07099883,\n",
              "          -0.13650566, -0.09407285],\n",
              "         [ 0.09512539, -0.07514334,  0.13394026, ..., -0.02968398,\n",
              "          -0.11161713, -0.16142334],\n",
              "         [ 0.1698519 , -0.14753851,  0.12901248, ..., -0.07503626,\n",
              "          -0.26054138, -0.04621893],\n",
              "         ...,\n",
              "         [ 0.20279577, -0.1324355 ,  0.19178489, ..., -0.19024551,\n",
              "          -0.25114793, -0.00553855],\n",
              "         [ 0.07407718,  0.03096376,  0.11774819, ..., -0.17163305,\n",
              "           0.0090298 , -0.09045789],\n",
              "         [ 0.04222431, -0.16743204,  0.13460493, ..., -0.09836864,\n",
              "          -0.1803602 , -0.09732246]]], dtype=float32),\n",
              " array([[[ 0.09859009, -0.12221009,  0.10438082, ...,  0.05168626,\n",
              "          -0.11093855,  0.0316366 ],\n",
              "         [ 0.09690251, -0.15892488,  0.17384452, ..., -0.07588841,\n",
              "          -0.08055864, -0.04981975],\n",
              "         [ 0.05540636, -0.16284174,  0.17199364, ..., -0.0532384 ,\n",
              "          -0.1435321 , -0.07243399],\n",
              "         ...,\n",
              "         [ 0.16484535, -0.11541061,  0.07327206, ..., -0.07473288,\n",
              "          -0.15268669, -0.1597471 ],\n",
              "         [ 0.04455029, -0.16593178,  0.01671304, ...,  0.0784879 ,\n",
              "          -0.23621544, -0.06983378],\n",
              "         [ 0.12499263, -0.10027614,  0.23247331, ..., -0.0391896 ,\n",
              "          -0.05232021, -0.10222663]],\n",
              " \n",
              "        [[ 0.23625532, -0.26840812,  0.11314578, ..., -0.03401785,\n",
              "          -0.21604602, -0.1191306 ],\n",
              "         [ 0.14213544, -0.1648449 ,  0.11525565, ..., -0.10953651,\n",
              "          -0.07117928, -0.08638676],\n",
              "         [ 0.06117982, -0.1188499 ,  0.09721801, ..., -0.10393904,\n",
              "          -0.24736364, -0.03515124],\n",
              "         ...,\n",
              "         [ 0.08321212, -0.13384283,  0.23481178, ..., -0.07691306,\n",
              "          -0.03393253, -0.05554521],\n",
              "         [ 0.04809693, -0.12210578,  0.22281578, ...,  0.13761748,\n",
              "          -0.09077245, -0.14999679],\n",
              "         [ 0.13876693, -0.22333488,  0.1518335 , ..., -0.09222537,\n",
              "          -0.18308783, -0.17359829]],\n",
              " \n",
              "        [[ 0.21860178, -0.11732185,  0.1639662 , ..., -0.07501517,\n",
              "          -0.19077758, -0.02103924],\n",
              "         [ 0.20359543, -0.17416131,  0.2434921 , ...,  0.03530541,\n",
              "          -0.17072576, -0.12023363],\n",
              "         [ 0.11417441, -0.08362407,  0.023023  , ..., -0.05230832,\n",
              "          -0.16447605, -0.08625148],\n",
              "         ...,\n",
              "         [ 0.11105423, -0.24224234,  0.06367321, ..., -0.07651259,\n",
              "          -0.20676728,  0.07138773],\n",
              "         [ 0.12582484, -0.02890772,  0.17771897, ..., -0.08823619,\n",
              "          -0.05700698, -0.01358998],\n",
              "         [ 0.11530294, -0.1878736 ,  0.04136715, ..., -0.02722251,\n",
              "          -0.18016127, -0.09424595]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.12150389, -0.10948928,  0.1579941 , ..., -0.01886582,\n",
              "          -0.11819112, -0.10213214],\n",
              "         [ 0.14074248, -0.26773828,  0.22466078, ..., -0.05589716,\n",
              "          -0.22287123, -0.16726924],\n",
              "         [ 0.21268275, -0.15023687,  0.14524569, ..., -0.0579217 ,\n",
              "          -0.1155322 , -0.04548989],\n",
              "         ...,\n",
              "         [ 0.0845108 , -0.07205016,  0.10612622, ..., -0.02651654,\n",
              "          -0.18062365, -0.05875786],\n",
              "         [ 0.1488199 , -0.12312657,  0.16547874, ..., -0.06496854,\n",
              "          -0.11662549,  0.01651549],\n",
              "         [ 0.15713155, -0.178224  ,  0.13025862, ..., -0.02825943,\n",
              "          -0.17415348, -0.01818267]],\n",
              " \n",
              "        [[ 0.0579743 , -0.13146478,  0.20982063, ..., -0.02747923,\n",
              "          -0.14882183, -0.08131647],\n",
              "         [ 0.14483455, -0.12426993,  0.17519495, ..., -0.00328925,\n",
              "          -0.05499515,  0.06566026],\n",
              "         [ 0.1653795 , -0.11508633,  0.08758555, ..., -0.20125914,\n",
              "          -0.12312807, -0.1167995 ],\n",
              "         ...,\n",
              "         [ 0.09202421, -0.09167731,  0.15862745, ..., -0.06211166,\n",
              "          -0.05562861, -0.0888616 ],\n",
              "         [ 0.08484212, -0.07429229,  0.01402993, ..., -0.06260588,\n",
              "          -0.06882398,  0.01344069],\n",
              "         [ 0.01009945, -0.1126553 ,  0.06583668, ...,  0.03019221,\n",
              "          -0.08266883, -0.09070651]],\n",
              " \n",
              "        [[ 0.18001196, -0.14028913,  0.10361789, ..., -0.05694345,\n",
              "          -0.12395208, -0.16387458],\n",
              "         [ 0.099671  , -0.16487148,  0.09311263, ..., -0.19454059,\n",
              "          -0.11937958, -0.08517902],\n",
              "         [ 0.20242554, -0.15035892,  0.12220028, ..., -0.05459357,\n",
              "          -0.14679062, -0.13384148],\n",
              "         ...,\n",
              "         [ 0.03903284, -0.15435494,  0.16050708, ...,  0.00494498,\n",
              "          -0.08751711, -0.12477131],\n",
              "         [ 0.07555862, -0.09049684,  0.09123808, ..., -0.03423328,\n",
              "          -0.11625986, -0.06019301],\n",
              "         [ 0.26732945, -0.18132299,  0.22932678, ..., -0.11349286,\n",
              "          -0.12816544, -0.0749723 ]]], dtype=float32),\n",
              " array([[[ 0.17835227, -0.08346188, -0.03256889, ..., -0.03542718,\n",
              "          -0.13308851, -0.1185603 ],\n",
              "         [ 0.13203472, -0.16974166,  0.09284371, ..., -0.02423416,\n",
              "          -0.18465737, -0.09102242],\n",
              "         [ 0.03339614, -0.09404212,  0.177804  , ..., -0.01341219,\n",
              "          -0.11608868, -0.04646755],\n",
              "         ...,\n",
              "         [ 0.1296753 , -0.10580334,  0.08381587, ..., -0.07480372,\n",
              "          -0.14453068, -0.12506771],\n",
              "         [ 0.05660401, -0.13598913,  0.26875946, ..., -0.08263001,\n",
              "          -0.17877366, -0.0584752 ],\n",
              "         [ 0.25951666, -0.16769794,  0.10125215, ..., -0.14056993,\n",
              "          -0.23172234,  0.01593791]],\n",
              " \n",
              "        [[ 0.11258861, -0.02969231,  0.19633389, ..., -0.1661731 ,\n",
              "          -0.05118945,  0.01293334],\n",
              "         [ 0.09374955, -0.16301638,  0.13102797, ..., -0.0297424 ,\n",
              "          -0.11291413, -0.03768634],\n",
              "         [ 0.07236898, -0.13268651,  0.1048707 , ...,  0.02383941,\n",
              "          -0.24088015, -0.05180275],\n",
              "         ...,\n",
              "         [ 0.08997104, -0.11158589,  0.1869407 , ..., -0.02697894,\n",
              "          -0.10911778, -0.09567507],\n",
              "         [ 0.2010136 , -0.02228302,  0.17669356, ..., -0.10965112,\n",
              "          -0.08982457, -0.0670266 ],\n",
              "         [ 0.09230851, -0.24835476,  0.09801034, ...,  0.01556832,\n",
              "          -0.18170244, -0.09904482]]], dtype=float32),\n",
              " array([[[ 0.17182344, -0.10472631,  0.15874888, ..., -0.02016097,\n",
              "          -0.09651285, -0.06014703],\n",
              "         [ 0.14946869, -0.08265976,  0.04533787, ..., -0.13072701,\n",
              "          -0.10499927, -0.01437055],\n",
              "         [ 0.20935027, -0.11396149,  0.14526904, ..., -0.12531559,\n",
              "          -0.14707106, -0.00748096],\n",
              "         ...,\n",
              "         [ 0.03614266, -0.06195904,  0.07545969, ..., -0.06788902,\n",
              "          -0.07240257, -0.07878032],\n",
              "         [ 0.06778947, -0.17793491,  0.041425  , ..., -0.10014933,\n",
              "          -0.19330001, -0.06514876],\n",
              "         [ 0.11152744, -0.10890283,  0.08568069, ...,  0.04344854,\n",
              "          -0.15475321, -0.08883182]],\n",
              " \n",
              "        [[ 0.01213784, -0.09151769,  0.13004567, ..., -0.0574597 ,\n",
              "          -0.15106596, -0.06517816],\n",
              "         [ 0.1445654 , -0.11037904,  0.02668735, ...,  0.01977268,\n",
              "          -0.1495124 , -0.08659804],\n",
              "         [ 0.22781456, -0.15147367,  0.1523857 , ..., -0.05145472,\n",
              "          -0.25945514, -0.01980021],\n",
              "         ...,\n",
              "         [ 0.10677317, -0.13028926,  0.08802798, ..., -0.12198092,\n",
              "          -0.15922382, -0.13677545],\n",
              "         [ 0.17587592, -0.09712883,  0.13740863, ..., -0.19407296,\n",
              "          -0.12130795, -0.0969681 ],\n",
              "         [ 0.1290344 , -0.10371993,  0.07113956, ..., -0.1110704 ,\n",
              "          -0.13978171, -0.05078616]],\n",
              " \n",
              "        [[ 0.0698506 , -0.09013566,  0.09387176, ...,  0.043043  ,\n",
              "          -0.06869738, -0.19708818],\n",
              "         [ 0.17732151, -0.00455306,  0.18940744, ..., -0.08097533,\n",
              "          -0.07768755, -0.00924706],\n",
              "         [ 0.11482947, -0.07289544,  0.15419456, ..., -0.01826634,\n",
              "          -0.19479054, -0.17501934],\n",
              "         ...,\n",
              "         [ 0.19911611, -0.16262697,  0.18187408, ..., -0.03464466,\n",
              "          -0.1311762 , -0.08888538],\n",
              "         [ 0.13807999,  0.02485246,  0.1049337 , ..., -0.06393988,\n",
              "           0.05035236, -0.00030493],\n",
              "         [ 0.06356546, -0.07063062,  0.05671132, ...,  0.00242703,\n",
              "          -0.11095642,  0.0527093 ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.11342735, -0.0946094 ,  0.05695271, ..., -0.0027043 ,\n",
              "          -0.16674924, -0.05827061],\n",
              "         [ 0.08525057, -0.19867972,  0.1251979 , ..., -0.08924025,\n",
              "          -0.20702551, -0.03779582],\n",
              "         [ 0.12602009, -0.05075734,  0.1112495 , ..., -0.04048313,\n",
              "          -0.06139991, -0.05069529],\n",
              "         ...,\n",
              "         [ 0.16118076, -0.21940872,  0.17665395, ..., -0.08984384,\n",
              "          -0.07469676,  0.03886586],\n",
              "         [ 0.06427282, -0.11525099,  0.16793677, ..., -0.07812503,\n",
              "          -0.09745117, -0.08289573],\n",
              "         [ 0.02395882, -0.12653017,  0.10797857, ..., -0.12128692,\n",
              "          -0.13390137, -0.04323853]],\n",
              " \n",
              "        [[ 0.09642562, -0.11588772,  0.14489186, ..., -0.0179599 ,\n",
              "          -0.11108953, -0.02550048],\n",
              "         [ 0.12938392, -0.17905763,  0.10191969, ..., -0.01670669,\n",
              "          -0.17418   ,  0.00761053],\n",
              "         [ 0.16319832, -0.1396579 ,  0.14445007, ..., -0.05689876,\n",
              "          -0.09382012, -0.05942697],\n",
              "         ...,\n",
              "         [ 0.08647691, -0.04735997,  0.13708186, ..., -0.02488779,\n",
              "          -0.12004843, -0.0267514 ],\n",
              "         [ 0.1430286 , -0.09834951,  0.0796072 , ..., -0.05833963,\n",
              "          -0.1416513 , -0.07063184],\n",
              "         [ 0.09546408, -0.04677101,  0.0974915 , ..., -0.04684762,\n",
              "          -0.098603  , -0.03453708]],\n",
              " \n",
              "        [[ 0.15098517, -0.03184438,  0.22227597, ..., -0.08952178,\n",
              "          -0.01322219, -0.08001678],\n",
              "         [ 0.10745783, -0.14638449,  0.19524223, ..., -0.02689057,\n",
              "          -0.16289434,  0.02321913],\n",
              "         [ 0.10469677, -0.14057212,  0.15694618, ..., -0.11441819,\n",
              "          -0.1641827 , -0.08383467],\n",
              "         ...,\n",
              "         [-0.00282828, -0.10012202,  0.20510733, ..., -0.01689058,\n",
              "          -0.10235155,  0.04311837],\n",
              "         [ 0.2459613 , -0.13236359,  0.11051647, ..., -0.08554365,\n",
              "          -0.18860072, -0.10005952],\n",
              "         [ 0.17496127, -0.2607332 ,  0.19843951, ..., -0.15901092,\n",
              "          -0.20932546, -0.18640335]]], dtype=float32),\n",
              " array([[[ 0.23413976, -0.09397621,  0.21521291, ..., -0.01962303,\n",
              "          -0.09570497, -0.15967093],\n",
              "         [ 0.06479259, -0.19592059,  0.06345567, ..., -0.04483773,\n",
              "          -0.17927071, -0.10579144],\n",
              "         [ 0.15743008, -0.01892035,  0.07855554, ..., -0.08313142,\n",
              "          -0.09493808, -0.08945026],\n",
              "         ...,\n",
              "         [ 0.12588899, -0.09800266, -0.00303846, ..., -0.13116573,\n",
              "          -0.20837706, -0.19006719],\n",
              "         [ 0.07214468, -0.04481093,  0.14991246, ..., -0.14542508,\n",
              "          -0.01617915, -0.01035834],\n",
              "         [ 0.17212826, -0.24291253,  0.25922182, ..., -0.04312539,\n",
              "          -0.20084941, -0.09877289]],\n",
              " \n",
              "        [[ 0.14776477, -0.06429984,  0.2645673 , ...,  0.04025875,\n",
              "          -0.04691679, -0.03748563],\n",
              "         [ 0.21426123, -0.12616867,  0.17227486, ..., -0.08091119,\n",
              "          -0.14091419, -0.01834335],\n",
              "         [ 0.15646368, -0.12676133, -0.03090966, ..., -0.2034134 ,\n",
              "          -0.11094412, -0.06357023],\n",
              "         ...,\n",
              "         [ 0.20149659, -0.06215745,  0.13229744, ..., -0.11155528,\n",
              "          -0.01211721, -0.00874422],\n",
              "         [ 0.12833494, -0.1120006 ,  0.08084871, ..., -0.19283196,\n",
              "          -0.15835007, -0.06467672],\n",
              "         [ 0.20402706, -0.12926266,  0.14368434, ..., -0.04711966,\n",
              "          -0.16774571, -0.08283971]],\n",
              " \n",
              "        [[ 0.14978728, -0.13294676,  0.09633046, ...,  0.05549805,\n",
              "          -0.19051296, -0.06623498],\n",
              "         [ 0.1500722 , -0.11870874,  0.20834872, ..., -0.10817613,\n",
              "          -0.06147897,  0.02690414],\n",
              "         [ 0.16572827, -0.15809879,  0.18727654, ..., -0.1252226 ,\n",
              "          -0.15423849, -0.02753153],\n",
              "         ...,\n",
              "         [ 0.22504589, -0.24592876,  0.08160219, ..., -0.09885668,\n",
              "          -0.20837487, -0.0078943 ],\n",
              "         [-0.0309482 , -0.1786705 ,  0.1139391 , ...,  0.00758974,\n",
              "          -0.13212077,  0.03428467],\n",
              "         [ 0.09815492, -0.08677042,  0.07437263, ...,  0.00813185,\n",
              "          -0.17407665, -0.10015067]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.19023128, -0.09691342,  0.15567774, ..., -0.11052855,\n",
              "          -0.12590079, -0.0163616 ],\n",
              "         [ 0.05137437, -0.12249256,  0.12794988, ..., -0.05043689,\n",
              "          -0.10890789, -0.11437398],\n",
              "         [ 0.0906591 , -0.11646323,  0.04947168, ..., -0.01996741,\n",
              "          -0.08444505, -0.06291138],\n",
              "         ...,\n",
              "         [ 0.17842701, -0.19086182,  0.10482999, ..., -0.20855108,\n",
              "          -0.15805888, -0.12607867],\n",
              "         [ 0.06347732, -0.03257599,  0.09946884, ..., -0.00572381,\n",
              "          -0.07597449, -0.00660505],\n",
              "         [ 0.16626748, -0.1427186 ,  0.08187509, ..., -0.07914829,\n",
              "          -0.19089143, -0.12387828]],\n",
              " \n",
              "        [[ 0.14376779, -0.1623626 ,  0.05868319, ..., -0.05850179,\n",
              "          -0.15608993,  0.01501451],\n",
              "         [ 0.12482509, -0.10135555,  0.08180384, ..., -0.03385772,\n",
              "          -0.18709579, -0.05621662],\n",
              "         [ 0.19653365, -0.23903155,  0.18698819, ..., -0.03043757,\n",
              "          -0.0941631 , -0.09284016],\n",
              "         ...,\n",
              "         [ 0.153306  , -0.14609572,  0.12852658, ..., -0.10441029,\n",
              "          -0.15168966, -0.2026215 ],\n",
              "         [ 0.10944012, -0.20366392,  0.17919964, ..., -0.02466101,\n",
              "          -0.12972575, -0.10877305],\n",
              "         [ 0.26014364, -0.02032997,  0.18487643, ..., -0.06472355,\n",
              "          -0.132086  , -0.03730564]],\n",
              " \n",
              "        [[ 0.03902753, -0.13409778,  0.16751513, ..., -0.09863975,\n",
              "          -0.08659345, -0.1226683 ],\n",
              "         [ 0.02500464,  0.03390354,  0.13960543, ..., -0.02090924,\n",
              "          -0.0678618 , -0.13678421],\n",
              "         [ 0.18685244, -0.12976569,  0.13593946, ..., -0.14548415,\n",
              "          -0.12013298, -0.15940899],\n",
              "         ...,\n",
              "         [ 0.06635512, -0.11523379,  0.1509304 , ..., -0.05091722,\n",
              "          -0.01695318, -0.08135004],\n",
              "         [ 0.19969569, -0.1436018 ,  0.09810222, ..., -0.09655841,\n",
              "          -0.11856742, -0.05741444],\n",
              "         [ 0.1175875 , -0.06830283,  0.04793407, ..., -0.01640657,\n",
              "          -0.12554874, -0.10781009]]], dtype=float32),\n",
              " array([[[ 0.20608893, -0.25116912,  0.22925049, ..., -0.10066096,\n",
              "          -0.18375486, -0.08366905],\n",
              "         [ 0.06536619, -0.15623716,  0.16333228, ..., -0.0745257 ,\n",
              "          -0.15543246, -0.05161423],\n",
              "         [ 0.04304234, -0.00421196,  0.04644145, ...,  0.04611573,\n",
              "          -0.02298844, -0.16432598],\n",
              "         ...,\n",
              "         [ 0.11069582, -0.15486774,  0.21111193, ...,  0.0029071 ,\n",
              "          -0.12811255, -0.12044531],\n",
              "         [ 0.16789642, -0.14073642,  0.19700998, ..., -0.09486002,\n",
              "          -0.0838227 , -0.10618814],\n",
              "         [ 0.06156185, -0.09484993,  0.22884989, ..., -0.11341338,\n",
              "          -0.02193877, -0.09014407]],\n",
              " \n",
              "        [[ 0.17756048, -0.1087626 ,  0.14236873, ..., -0.06465074,\n",
              "          -0.05503491,  0.01848963],\n",
              "         [ 0.05905094, -0.16331407,  0.2237868 , ...,  0.0350264 ,\n",
              "          -0.20565417, -0.17643717],\n",
              "         [ 0.06645425, -0.10145439,  0.03438872, ...,  0.02043489,\n",
              "          -0.15575397, -0.07754795],\n",
              "         ...,\n",
              "         [ 0.19726817,  0.01838776,  0.06628577, ..., -0.03358784,\n",
              "          -0.09921418, -0.11673091],\n",
              "         [ 0.17675698, -0.18348426,  0.04967086, ..., -0.15177307,\n",
              "          -0.19784085, -0.23520054],\n",
              "         [ 0.01676503, -0.03706936,  0.116296  , ..., -0.0271126 ,\n",
              "          -0.09817945, -0.03757925]]], dtype=float32),\n",
              " array([[[ 0.07350589,  0.08540292, -0.11814226, ...,  0.07254045,\n",
              "           0.10022938,  0.12509671],\n",
              "         [ 0.06197687,  0.0440864 , -0.12928753, ...,  0.05345668,\n",
              "           0.10260555,  0.08218579],\n",
              "         [ 0.0617439 ,  0.02928242, -0.114475  , ...,  0.03918806,\n",
              "           0.11854063,  0.06712128],\n",
              "         ...,\n",
              "         [ 0.04968875,  0.07407567, -0.10933887, ...,  0.03510791,\n",
              "           0.11972811,  0.04435126],\n",
              "         [ 0.0494776 ,  0.07397258, -0.10940602, ...,  0.03513123,\n",
              "           0.11959815,  0.04437465],\n",
              "         [ 0.04923359,  0.07373656, -0.10966905, ...,  0.03528228,\n",
              "           0.11963189,  0.04407893]],\n",
              " \n",
              "        [[ 0.08110552,  0.08818956, -0.12014478, ...,  0.07110269,\n",
              "           0.10148961,  0.12481384],\n",
              "         [ 0.06622841,  0.04439364, -0.1290985 , ...,  0.05297282,\n",
              "           0.10818507,  0.08813566],\n",
              "         [ 0.06152562,  0.03142786, -0.11106625, ...,  0.04060686,\n",
              "           0.12266526,  0.06806123],\n",
              "         ...,\n",
              "         [ 0.0516622 ,  0.07252083, -0.11078314, ...,  0.03243639,\n",
              "           0.12366618,  0.0512844 ],\n",
              "         [ 0.05148285,  0.07257087, -0.11048897, ...,  0.03257896,\n",
              "           0.12322013,  0.05132347],\n",
              "         [ 0.05137869,  0.0726167 , -0.11019023, ...,  0.03288185,\n",
              "           0.12302458,  0.05142491]],\n",
              " \n",
              "        [[ 0.07295825,  0.0851263 , -0.11750502, ...,  0.07229646,\n",
              "           0.10103384,  0.12507787],\n",
              "         [ 0.06177049,  0.04417582, -0.1292926 , ...,  0.05297437,\n",
              "           0.10244097,  0.08185343],\n",
              "         [ 0.06188989,  0.02947162, -0.11486745, ...,  0.03868882,\n",
              "           0.11859605,  0.06668917],\n",
              "         ...,\n",
              "         [ 0.04946782,  0.07380189, -0.11048818, ...,  0.03539971,\n",
              "           0.1196399 ,  0.04317548],\n",
              "         [ 0.04916313,  0.0736221 , -0.110658  , ...,  0.03569021,\n",
              "           0.11962245,  0.04301934],\n",
              "         [ 0.04895076,  0.07355638, -0.11086187, ...,  0.0360806 ,\n",
              "           0.11970088,  0.04281446]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.07233965,  0.08486711, -0.11737864, ...,  0.07080016,\n",
              "           0.10197553,  0.12578629],\n",
              "         [ 0.06061181,  0.04308593, -0.12918828, ...,  0.05143397,\n",
              "           0.10102016,  0.08004651],\n",
              "         [ 0.06150599,  0.02713346, -0.11698038, ...,  0.03833746,\n",
              "           0.11697918,  0.06505089],\n",
              "         ...,\n",
              "         [ 0.05278318,  0.07565871, -0.10961752, ...,  0.03766758,\n",
              "           0.12235188,  0.04297913],\n",
              "         [ 0.05259652,  0.07562643, -0.10967648, ...,  0.03802252,\n",
              "           0.12251695,  0.04270146],\n",
              "         [ 0.05241788,  0.07555313, -0.10957758, ...,  0.03828842,\n",
              "           0.12247432,  0.0426279 ]],\n",
              " \n",
              "        [[ 0.06990384,  0.08634295, -0.11764519, ...,  0.07082616,\n",
              "           0.1056544 ,  0.12758787],\n",
              "         [ 0.06418891,  0.04725418, -0.13023831, ...,  0.05140411,\n",
              "           0.10283002,  0.07573909],\n",
              "         [ 0.06467666,  0.03327619, -0.12058782, ...,  0.03840179,\n",
              "           0.11833635,  0.05751907],\n",
              "         ...,\n",
              "         [ 0.06221844,  0.09086054, -0.10306732, ...,  0.04717466,\n",
              "           0.1198059 ,  0.0396966 ],\n",
              "         [ 0.06269441,  0.09110143, -0.10304302, ...,  0.04722216,\n",
              "           0.11983277,  0.03997777],\n",
              "         [ 0.06289172,  0.09130751, -0.10281429, ...,  0.04725643,\n",
              "           0.11980474,  0.03989404]],\n",
              " \n",
              "        [[ 0.08483134,  0.09061311, -0.1188971 , ...,  0.06909028,\n",
              "           0.10140397,  0.12531014],\n",
              "         [ 0.07370955,  0.04591142, -0.13369885, ...,  0.04970519,\n",
              "           0.10968024,  0.09530636],\n",
              "         [ 0.0604308 ,  0.03257699, -0.12132096, ...,  0.04244225,\n",
              "           0.11727296,  0.07656477],\n",
              "         ...,\n",
              "         [ 0.06285052,  0.08728807, -0.13838129, ...,  0.06245077,\n",
              "           0.09377725,  0.03822213],\n",
              "         [ 0.07003292,  0.08336292, -0.14801049, ...,  0.06256022,\n",
              "           0.0935294 ,  0.03964213],\n",
              "         [ 0.07235759,  0.07706353, -0.15249136, ...,  0.05959873,\n",
              "           0.0938057 ,  0.04304297]]], dtype=float32),\n",
              " array([[[ 0.0727218 ,  0.08480687, -0.11723716, ...,  0.07212423,\n",
              "           0.10114763,  0.12508804],\n",
              "         [ 0.06173581,  0.04399473, -0.12944925, ...,  0.05269828,\n",
              "           0.10220062,  0.08159378],\n",
              "         [ 0.0616764 ,  0.02895632, -0.11532217, ...,  0.0387369 ,\n",
              "           0.11829841,  0.06645567],\n",
              "         ...,\n",
              "         [ 0.04933172,  0.07358862, -0.11040686, ...,  0.03568832,\n",
              "           0.12000135,  0.04263116],\n",
              "         [ 0.04906313,  0.07328737, -0.11075093, ...,  0.03586263,\n",
              "           0.12000898,  0.04241762],\n",
              "         [ 0.04889193,  0.072974  , -0.11116786, ...,  0.03593157,\n",
              "           0.1200259 ,  0.04226675]],\n",
              " \n",
              "        [[ 0.08189404,  0.08942689, -0.12035061, ...,  0.07158051,\n",
              "           0.10237537,  0.1252409 ],\n",
              "         [ 0.06787037,  0.04474747, -0.1291291 , ...,  0.05305888,\n",
              "           0.10993835,  0.08959989],\n",
              "         [ 0.06055618,  0.03079783, -0.11110297, ...,  0.04178498,\n",
              "           0.12401915,  0.06759123],\n",
              "         ...,\n",
              "         [ 0.05243253,  0.07053378, -0.11069429, ...,  0.03482747,\n",
              "           0.12670857,  0.05174694],\n",
              "         [ 0.0524004 ,  0.07041875, -0.11060771, ...,  0.03506003,\n",
              "           0.12655371,  0.05171335],\n",
              "         [ 0.05204282,  0.07024039, -0.11026684, ...,  0.03532423,\n",
              "           0.12610714,  0.05154842]],\n",
              " \n",
              "        [[ 0.06603621,  0.08476046, -0.11649495, ...,  0.07170529,\n",
              "           0.11091743,  0.13073516],\n",
              "         [ 0.06995063,  0.05432592, -0.13010935, ...,  0.05052177,\n",
              "           0.10810201,  0.076179  ],\n",
              "         [ 0.07030486,  0.04105988, -0.12371233, ...,  0.04241265,\n",
              "           0.12175079,  0.05286368],\n",
              "         ...,\n",
              "         [ 0.07491899,  0.09603543, -0.10235459, ...,  0.05234284,\n",
              "           0.12692755,  0.04209303],\n",
              "         [ 0.07554228,  0.09624199, -0.10205707, ...,  0.05235577,\n",
              "           0.12738957,  0.04185977],\n",
              "         [ 0.07585385,  0.09631054, -0.10164355, ...,  0.05250722,\n",
              "           0.12762687,  0.04160228]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.08181033,  0.08973382, -0.1201372 , ...,  0.07145228,\n",
              "           0.10174948,  0.12506397],\n",
              "         [ 0.0694163 ,  0.0457495 , -0.12980883, ...,  0.05295496,\n",
              "           0.11028538,  0.09005424],\n",
              "         [ 0.06071762,  0.03142795, -0.11202428, ...,  0.04183044,\n",
              "           0.12364637,  0.06674632],\n",
              "         ...,\n",
              "         [ 0.05248371,  0.07143859, -0.10937146, ...,  0.03657286,\n",
              "           0.12668194,  0.05223943],\n",
              "         [ 0.05224296,  0.07131155, -0.10898827, ...,  0.03680187,\n",
              "           0.12577951,  0.05200994],\n",
              "         [ 0.05216816,  0.07125093, -0.10854112, ...,  0.03715418,\n",
              "           0.12519115,  0.05167744]],\n",
              " \n",
              "        [[ 0.07306269,  0.08535964, -0.11764509, ...,  0.0717776 ,\n",
              "           0.10091959,  0.12580535],\n",
              "         [ 0.06150617,  0.04337137, -0.12898318, ...,  0.05268841,\n",
              "           0.10241353,  0.08088554],\n",
              "         [ 0.06143083,  0.02832611, -0.11550541, ...,  0.0390805 ,\n",
              "           0.11800689,  0.06581895],\n",
              "         ...,\n",
              "         [ 0.05201986,  0.0753033 , -0.10934083, ...,  0.0357906 ,\n",
              "           0.12195551,  0.04401145],\n",
              "         [ 0.05190253,  0.07516053, -0.10926931, ...,  0.03565246,\n",
              "           0.12177624,  0.04420912],\n",
              "         [ 0.05178403,  0.07509346, -0.10922699, ...,  0.0356693 ,\n",
              "           0.12172776,  0.04434417]],\n",
              " \n",
              "        [[ 0.08182983,  0.0897546 , -0.11996727, ...,  0.07159978,\n",
              "           0.10132486,  0.125003  ],\n",
              "         [ 0.06994963,  0.04615651, -0.13035363, ...,  0.05303719,\n",
              "           0.11019199,  0.0904945 ],\n",
              "         [ 0.06047156,  0.03148489, -0.11285411, ...,  0.0420592 ,\n",
              "           0.12307081,  0.06683465],\n",
              "         ...,\n",
              "         [ 0.0523467 ,  0.0716006 , -0.10818477, ...,  0.03698853,\n",
              "           0.12510268,  0.05256998],\n",
              "         [ 0.05191868,  0.07150029, -0.10762212, ...,  0.03744889,\n",
              "           0.12466727,  0.05199569],\n",
              "         [ 0.05166977,  0.07150793, -0.10704714, ...,  0.03793942,\n",
              "           0.12427592,  0.05149204]]], dtype=float32),\n",
              " array([[[ 0.08268864,  0.0896084 , -0.12055501, ...,  0.07145537,\n",
              "           0.10249516,  0.12491141],\n",
              "         [ 0.06801009,  0.04488804, -0.12925248, ...,  0.05311379,\n",
              "           0.11016087,  0.08958603],\n",
              "         [ 0.06003444,  0.03121123, -0.11149111, ...,  0.04212456,\n",
              "           0.12381293,  0.066465  ],\n",
              "         ...,\n",
              "         [ 0.05231944,  0.07067563, -0.11015736, ...,  0.03552641,\n",
              "           0.1266408 ,  0.0513733 ],\n",
              "         [ 0.05219718,  0.0704812 , -0.11015511, ...,  0.03571337,\n",
              "           0.12611221,  0.05131946],\n",
              "         [ 0.05215535,  0.07016012, -0.11005185, ...,  0.03586804,\n",
              "           0.12545586,  0.05104086]],\n",
              " \n",
              "        [[ 0.07058845,  0.08538083, -0.1169364 , ...,  0.07016842,\n",
              "           0.10468835,  0.12656318],\n",
              "         [ 0.06263614,  0.04561147, -0.13040674, ...,  0.05119948,\n",
              "           0.10165679,  0.07830936],\n",
              "         [ 0.06471206,  0.03030997, -0.11969639, ...,  0.0375765 ,\n",
              "           0.117753  ,  0.06221066],\n",
              "         ...,\n",
              "         [ 0.06066427,  0.08580551, -0.10898127, ...,  0.04364588,\n",
              "           0.12275478,  0.04270075],\n",
              "         [ 0.06066652,  0.08590461, -0.1088026 , ...,  0.04383294,\n",
              "           0.1226497 ,  0.04263385],\n",
              "         [ 0.06059234,  0.08578143, -0.10876054, ...,  0.04412516,\n",
              "           0.12252538,  0.04254567]]], dtype=float32),\n",
              " array([[[-0.16506526,  0.20539798,  0.09006439, ..., -0.01518673,\n",
              "          -0.06237338, -0.1120986 ],\n",
              "         [-0.04242339,  0.18857169,  0.07289365, ...,  0.16407612,\n",
              "          -0.13501185, -0.03998402],\n",
              "         [-0.22376104,  0.14630446, -0.03631448, ...,  0.01733238,\n",
              "          -0.11798351, -0.00712513],\n",
              "         ...,\n",
              "         [-0.0013925 ,  0.23903154,  0.02676418, ...,  0.1518349 ,\n",
              "          -0.13168164, -0.05198951],\n",
              "         [-0.16954885,  0.10771735,  0.00625686, ...,  0.17380673,\n",
              "          -0.1089369 , -0.03524779],\n",
              "         [-0.05463796,  0.22484198,  0.04632217, ...,  0.10015103,\n",
              "          -0.07226235, -0.06173892]],\n",
              " \n",
              "        [[-0.13023496,  0.24692836,  0.12751439, ...,  0.05892333,\n",
              "          -0.04483313, -0.110017  ],\n",
              "         [ 0.02381375,  0.20175755,  0.03325775, ...,  0.18479395,\n",
              "          -0.04947454, -0.07114042],\n",
              "         [-0.06691057,  0.2024353 ,  0.01167967, ...,  0.17032915,\n",
              "          -0.05524456, -0.07242762],\n",
              "         ...,\n",
              "         [-0.09349818,  0.3180068 , -0.00886151, ...,  0.05821716,\n",
              "          -0.14485012, -0.11133884],\n",
              "         [-0.01067051,  0.24662976,  0.03530306, ...,  0.1839861 ,\n",
              "          -0.12257318, -0.03193236],\n",
              "         [-0.18435255,  0.32155776,  0.10004552, ...,  0.18058363,\n",
              "          -0.13589731, -0.0821469 ]],\n",
              " \n",
              "        [[-0.1551105 ,  0.22366416,  0.01991571, ...,  0.17691323,\n",
              "          -0.03867662, -0.09314706],\n",
              "         [-0.00849995,  0.2493576 ,  0.03878835, ...,  0.11372554,\n",
              "          -0.14491329,  0.03167394],\n",
              "         [-0.1600903 ,  0.2598812 , -0.0090397 , ...,  0.12859279,\n",
              "          -0.04887685, -0.04801562],\n",
              "         ...,\n",
              "         [-0.13944341,  0.16754504,  0.09757032, ...,  0.20030591,\n",
              "          -0.03350966, -0.16403148],\n",
              "         [-0.18908754,  0.09480138,  0.1311637 , ...,  0.10438014,\n",
              "          -0.1346974 , -0.12908064],\n",
              "         [-0.05762665,  0.2124691 , -0.01423747, ...,  0.10169112,\n",
              "          -0.10190539, -0.15804726]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.16108897,  0.27523562,  0.01253062, ...,  0.0620516 ,\n",
              "          -0.0684005 ,  0.07604842],\n",
              "         [-0.02193987,  0.14786132,  0.02365585, ...,  0.20999548,\n",
              "          -0.15677616, -0.0096595 ],\n",
              "         [-0.09815997,  0.20818253,  0.07823659, ...,  0.20199512,\n",
              "          -0.03793336,  0.02366715],\n",
              "         ...,\n",
              "         [-0.12554944,  0.16963896, -0.02431893, ...,  0.11810724,\n",
              "          -0.16470607, -0.02912222],\n",
              "         [-0.1141832 ,  0.33226317, -0.03655076, ..., -0.00169495,\n",
              "          -0.10212121, -0.03014355],\n",
              "         [-0.14218752,  0.09065378, -0.00673495, ...,  0.15375163,\n",
              "          -0.03060561, -0.03152971]],\n",
              " \n",
              "        [[-0.06933299,  0.29965132,  0.04888276, ...,  0.08633128,\n",
              "          -0.09005368,  0.03173055],\n",
              "         [-0.09824765,  0.15487015, -0.05250108, ...,  0.02894789,\n",
              "          -0.11409768, -0.0483125 ],\n",
              "         [-0.14299345,  0.15234178,  0.11807069, ...,  0.17602718,\n",
              "          -0.03525663,  0.07583968],\n",
              "         ...,\n",
              "         [-0.10871083,  0.16983977,  0.05172712, ...,  0.16053727,\n",
              "          -0.06201909, -0.0395555 ],\n",
              "         [-0.11186669,  0.18972707,  0.09067345, ...,  0.13806237,\n",
              "          -0.0868312 , -0.10789086],\n",
              "         [-0.13546236,  0.16688386,  0.10515251, ...,  0.06403796,\n",
              "          -0.11714996,  0.03220667]],\n",
              " \n",
              "        [[ 0.05266681,  0.21490574,  0.07020059, ...,  0.06364991,\n",
              "          -0.0581899 , -0.09547883],\n",
              "         [-0.14602098,  0.17291853,  0.01084864, ...,  0.17176741,\n",
              "          -0.10035472, -0.06332954],\n",
              "         [-0.10626693,  0.22793338,  0.05879866, ...,  0.15403855,\n",
              "          -0.11216967, -0.1679845 ],\n",
              "         ...,\n",
              "         [-0.06730375,  0.17621058,  0.11020979, ...,  0.19400375,\n",
              "          -0.19977951, -0.01643385],\n",
              "         [-0.20252603,  0.1284414 ,  0.06674216, ...,  0.17163879,\n",
              "          -0.08844489, -0.12170526],\n",
              "         [ 0.0084456 ,  0.29494846,  0.05896871, ...,  0.07355595,\n",
              "          -0.07656398, -0.0080778 ]]], dtype=float32),\n",
              " array([[[-1.00552216e-02,  2.44766712e-01,  7.14123845e-02, ...,\n",
              "           9.54396576e-02, -9.13544968e-02, -8.00447464e-02],\n",
              "         [-1.93945244e-02,  2.62669086e-01,  9.96799618e-02, ...,\n",
              "           1.62010789e-01, -1.05934925e-01, -7.18212426e-02],\n",
              "         [-1.10436842e-01,  1.13598667e-01,  1.63139496e-02, ...,\n",
              "           3.31799090e-02, -1.41079918e-01, -2.63464078e-02],\n",
              "         ...,\n",
              "         [-4.63873334e-02,  2.36228496e-01,  1.24679236e-02, ...,\n",
              "           9.48345363e-02, -1.04941525e-01, -1.30600393e-01],\n",
              "         [-6.17261454e-02,  1.99792147e-01,  3.93899120e-02, ...,\n",
              "           1.01013027e-01, -4.90884334e-02, -1.82538211e-01],\n",
              "         [-1.77431062e-01,  2.56680399e-01,  3.51257510e-02, ...,\n",
              "           9.31093842e-03, -9.74476337e-02, -8.68018046e-02]],\n",
              " \n",
              "        [[-8.42577145e-02,  2.10660875e-01,  1.83530226e-02, ...,\n",
              "           1.57758996e-01, -4.26387042e-02, -1.49473995e-01],\n",
              "         [-3.06269228e-02,  1.67767629e-01,  5.31523116e-02, ...,\n",
              "           1.16008535e-01, -1.80179864e-01, -1.00894824e-01],\n",
              "         [-1.53197423e-01,  1.33808896e-01,  7.43233636e-02, ...,\n",
              "           1.31095961e-01, -4.11070734e-02,  3.95690836e-02],\n",
              "         ...,\n",
              "         [-3.39869857e-02,  2.10949540e-01,  3.77599262e-02, ...,\n",
              "           9.42763984e-02, -1.15239099e-01, -1.45578086e-01],\n",
              "         [ 6.00309819e-02,  1.79349601e-01, -3.00052743e-02, ...,\n",
              "           1.49356037e-01, -1.32494003e-01, -1.42751023e-01],\n",
              "         [-1.06861927e-01,  1.80129781e-01, -4.52007353e-03, ...,\n",
              "           2.06041843e-01, -9.70836803e-02, -1.90606847e-01]],\n",
              " \n",
              "        [[-1.39247403e-01,  2.46429026e-01,  5.14721572e-02, ...,\n",
              "           1.35997623e-01, -1.28317699e-01, -4.29522991e-02],\n",
              "         [-3.37525085e-02,  2.70216584e-01, -6.43392801e-02, ...,\n",
              "           1.55541554e-01, -1.48128226e-01, -1.11298703e-01],\n",
              "         [-8.22464079e-02,  7.70917535e-02,  1.82376796e-04, ...,\n",
              "           1.99139431e-01, -1.88347518e-01, -9.91910845e-02],\n",
              "         ...,\n",
              "         [-9.46259424e-02,  1.05758242e-01, -1.23919053e-02, ...,\n",
              "           2.11932525e-01, -6.20118417e-02, -2.55262107e-03],\n",
              "         [-2.04924494e-01,  2.37124473e-01,  1.73767097e-03, ...,\n",
              "           1.52299583e-01, -2.20575958e-01, -8.96909684e-02],\n",
              "         [-8.91295746e-02,  1.66091397e-01, -3.16449441e-02, ...,\n",
              "           1.02736026e-01, -1.52306646e-01, -2.72391923e-02]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-6.84290081e-02,  9.73446071e-02,  5.28997146e-02, ...,\n",
              "           1.80161223e-01, -5.99373356e-02, -2.55147256e-02],\n",
              "         [-1.20136112e-01,  2.95713127e-01,  7.56732747e-02, ...,\n",
              "           8.20279717e-02, -3.28140408e-02, -8.70313644e-02],\n",
              "         [-1.30956799e-01,  2.30204090e-01, -2.05946416e-02, ...,\n",
              "           1.39709473e-01, -1.16356254e-01, -1.19701773e-01],\n",
              "         ...,\n",
              "         [-1.42757311e-01,  2.12830424e-01, -2.78534275e-02, ...,\n",
              "           1.42460316e-01, -1.39020398e-01, -7.68853575e-02],\n",
              "         [-1.78898692e-01,  2.65978366e-01,  1.11033514e-01, ...,\n",
              "           8.33697915e-02, -1.82362050e-01, -8.35666955e-02],\n",
              "         [-1.43631324e-02,  2.53323793e-01,  3.45522016e-02, ...,\n",
              "           1.47399902e-01, -1.25309780e-01, -1.27955563e-02]],\n",
              " \n",
              "        [[-5.81567287e-02,  2.62430698e-01,  4.91079278e-02, ...,\n",
              "          -1.34258494e-02, -2.82362178e-02, -1.39148265e-01],\n",
              "         [-1.22467250e-01,  2.89830089e-01,  1.61025487e-02, ...,\n",
              "           2.25195840e-01, -7.44714960e-02, -9.55333263e-02],\n",
              "         [ 3.06332856e-03,  3.27725053e-01, -6.65829331e-02, ...,\n",
              "           5.54547310e-02, -8.15373957e-02, -4.74035256e-02],\n",
              "         ...,\n",
              "         [-1.01734936e-01,  2.78893590e-01,  4.76836897e-02, ...,\n",
              "           1.16022348e-01, -1.23044074e-01, -3.31377797e-02],\n",
              "         [-3.74753810e-02,  2.86735654e-01,  7.61380419e-02, ...,\n",
              "           1.71115041e-01, -1.30790174e-01, -1.37274429e-01],\n",
              "         [ 4.37450558e-02,  2.53863275e-01, -9.70986485e-03, ...,\n",
              "           1.90116078e-01, -5.63038252e-02, -2.08551139e-02]],\n",
              " \n",
              "        [[-1.60765946e-01,  2.61925429e-01,  1.14860870e-01, ...,\n",
              "           8.87803733e-04, -1.26908258e-01, -4.95050102e-02],\n",
              "         [-1.62229419e-01,  2.66925871e-01,  2.42935084e-02, ...,\n",
              "           9.73536074e-02, -1.33184969e-01, -7.48549998e-02],\n",
              "         [-6.72388822e-02,  2.54152626e-01, -3.40330116e-02, ...,\n",
              "           1.04065754e-01, -6.52506948e-03, -1.83004022e-01],\n",
              "         ...,\n",
              "         [-6.33759648e-02,  2.30234504e-01,  1.63366228e-01, ...,\n",
              "           1.61964655e-01, -7.03815371e-02, -4.05168235e-02],\n",
              "         [-1.45485982e-01,  2.43004963e-01, -4.39126603e-02, ...,\n",
              "           9.18498561e-02, -1.34548232e-01, -6.07015193e-03],\n",
              "         [-1.41090333e-01,  2.69794226e-01,  2.50102766e-02, ...,\n",
              "           1.95029825e-02,  1.48273110e-02, -6.61521330e-02]]],\n",
              "       dtype=float32),\n",
              " array([[[-0.06306498,  0.2357633 ,  0.144539  , ...,  0.1357031 ,\n",
              "          -0.09911857,  0.09618473],\n",
              "         [-0.14687234,  0.30779004,  0.00588021, ...,  0.16924319,\n",
              "          -0.06753041, -0.07706532],\n",
              "         [-0.16453269,  0.29638508,  0.08602589, ...,  0.15735018,\n",
              "          -0.05467541,  0.03099373],\n",
              "         ...,\n",
              "         [-0.19145605,  0.24275292,  0.04047006, ...,  0.21319613,\n",
              "          -0.02150712, -0.10966603],\n",
              "         [-0.04635255,  0.27446842,  0.02762482, ...,  0.00848101,\n",
              "          -0.15750366, -0.14887078],\n",
              "         [ 0.01567935,  0.23598482,  0.06742214, ...,  0.12729636,\n",
              "          -0.02759198, -0.06032167]],\n",
              " \n",
              "        [[-0.10864505,  0.27250472,  0.14442421, ...,  0.14416002,\n",
              "          -0.02521717,  0.04579343],\n",
              "         [-0.12852946,  0.177228  ,  0.05093628, ...,  0.04232198,\n",
              "          -0.10973053, -0.0735005 ],\n",
              "         [-0.07448094,  0.31467092,  0.09003263, ...,  0.08882602,\n",
              "          -0.11992939, -0.09374761],\n",
              "         ...,\n",
              "         [ 0.02111204,  0.271545  , -0.0316524 , ...,  0.06560164,\n",
              "          -0.21040925, -0.01104302],\n",
              "         [-0.13335523,  0.29249942,  0.08202957, ...,  0.16549507,\n",
              "          -0.07120378, -0.00369573],\n",
              "         [-0.17500308,  0.21583441,  0.02990662, ...,  0.08052534,\n",
              "          -0.01698747,  0.00153136]]], dtype=float32),\n",
              " array([[[ 0.07350589,  0.08540292, -0.11814226, ...,  0.07254045,\n",
              "           0.10022938,  0.12509671],\n",
              "         [ 0.06197687,  0.0440864 , -0.12928753, ...,  0.05345668,\n",
              "           0.10260555,  0.08218579],\n",
              "         [ 0.0617439 ,  0.02928242, -0.114475  , ...,  0.03918806,\n",
              "           0.11854063,  0.06712128],\n",
              "         ...,\n",
              "         [ 0.04968875,  0.07407567, -0.10933887, ...,  0.03510791,\n",
              "           0.11972811,  0.04435126],\n",
              "         [ 0.0494776 ,  0.07397258, -0.10940602, ...,  0.03513123,\n",
              "           0.11959815,  0.04437465],\n",
              "         [ 0.04923359,  0.07373656, -0.10966905, ...,  0.03528228,\n",
              "           0.11963189,  0.04407893]],\n",
              " \n",
              "        [[ 0.08110552,  0.08818956, -0.12014478, ...,  0.07110269,\n",
              "           0.10148961,  0.12481384],\n",
              "         [ 0.06622841,  0.04439364, -0.1290985 , ...,  0.05297282,\n",
              "           0.10818507,  0.08813566],\n",
              "         [ 0.06152562,  0.03142786, -0.11106625, ...,  0.04060686,\n",
              "           0.12266526,  0.06806123],\n",
              "         ...,\n",
              "         [ 0.0516622 ,  0.07252083, -0.11078314, ...,  0.03243639,\n",
              "           0.12366618,  0.0512844 ],\n",
              "         [ 0.05148285,  0.07257087, -0.11048897, ...,  0.03257896,\n",
              "           0.12322013,  0.05132347],\n",
              "         [ 0.05137869,  0.0726167 , -0.11019023, ...,  0.03288185,\n",
              "           0.12302458,  0.05142491]],\n",
              " \n",
              "        [[ 0.07295825,  0.0851263 , -0.11750502, ...,  0.07229646,\n",
              "           0.10103384,  0.12507787],\n",
              "         [ 0.06177049,  0.04417582, -0.1292926 , ...,  0.05297437,\n",
              "           0.10244097,  0.08185343],\n",
              "         [ 0.06188989,  0.02947162, -0.11486745, ...,  0.03868882,\n",
              "           0.11859605,  0.06668917],\n",
              "         ...,\n",
              "         [ 0.04946782,  0.07380189, -0.11048818, ...,  0.03539971,\n",
              "           0.1196399 ,  0.04317548],\n",
              "         [ 0.04916313,  0.0736221 , -0.110658  , ...,  0.03569021,\n",
              "           0.11962245,  0.04301934],\n",
              "         [ 0.04895076,  0.07355638, -0.11086187, ...,  0.0360806 ,\n",
              "           0.11970088,  0.04281446]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.07233965,  0.08486711, -0.11737864, ...,  0.07080016,\n",
              "           0.10197553,  0.12578629],\n",
              "         [ 0.06061181,  0.04308593, -0.12918828, ...,  0.05143397,\n",
              "           0.10102016,  0.08004651],\n",
              "         [ 0.06150599,  0.02713346, -0.11698038, ...,  0.03833746,\n",
              "           0.11697918,  0.06505089],\n",
              "         ...,\n",
              "         [ 0.05278318,  0.07565871, -0.10961752, ...,  0.03766758,\n",
              "           0.12235188,  0.04297913],\n",
              "         [ 0.05259652,  0.07562643, -0.10967648, ...,  0.03802252,\n",
              "           0.12251695,  0.04270146],\n",
              "         [ 0.05241788,  0.07555313, -0.10957758, ...,  0.03828842,\n",
              "           0.12247432,  0.0426279 ]],\n",
              " \n",
              "        [[ 0.06990384,  0.08634295, -0.11764519, ...,  0.07082616,\n",
              "           0.1056544 ,  0.12758787],\n",
              "         [ 0.06418891,  0.04725418, -0.13023831, ...,  0.05140411,\n",
              "           0.10283002,  0.07573909],\n",
              "         [ 0.06467666,  0.03327619, -0.12058782, ...,  0.03840179,\n",
              "           0.11833635,  0.05751907],\n",
              "         ...,\n",
              "         [ 0.06221844,  0.09086054, -0.10306732, ...,  0.04717466,\n",
              "           0.1198059 ,  0.0396966 ],\n",
              "         [ 0.06269441,  0.09110143, -0.10304302, ...,  0.04722216,\n",
              "           0.11983277,  0.03997777],\n",
              "         [ 0.06289172,  0.09130751, -0.10281429, ...,  0.04725643,\n",
              "           0.11980474,  0.03989404]],\n",
              " \n",
              "        [[ 0.08483134,  0.09061311, -0.1188971 , ...,  0.06909028,\n",
              "           0.10140397,  0.12531014],\n",
              "         [ 0.07370955,  0.04591142, -0.13369885, ...,  0.04970519,\n",
              "           0.10968024,  0.09530636],\n",
              "         [ 0.0604308 ,  0.03257699, -0.12132096, ...,  0.04244225,\n",
              "           0.11727296,  0.07656477],\n",
              "         ...,\n",
              "         [ 0.06285052,  0.08728807, -0.13838129, ...,  0.06245077,\n",
              "           0.09377725,  0.03822213],\n",
              "         [ 0.07003292,  0.08336292, -0.14801049, ...,  0.06256022,\n",
              "           0.0935294 ,  0.03964213],\n",
              "         [ 0.07235759,  0.07706353, -0.15249136, ...,  0.05959873,\n",
              "           0.0938057 ,  0.04304297]]], dtype=float32),\n",
              " array([[[ 0.0727218 ,  0.08480687, -0.11723716, ...,  0.07212423,\n",
              "           0.10114763,  0.12508804],\n",
              "         [ 0.06173581,  0.04399473, -0.12944925, ...,  0.05269828,\n",
              "           0.10220062,  0.08159378],\n",
              "         [ 0.0616764 ,  0.02895632, -0.11532217, ...,  0.0387369 ,\n",
              "           0.11829841,  0.06645567],\n",
              "         ...,\n",
              "         [ 0.04933172,  0.07358862, -0.11040686, ...,  0.03568832,\n",
              "           0.12000135,  0.04263116],\n",
              "         [ 0.04906313,  0.07328737, -0.11075093, ...,  0.03586263,\n",
              "           0.12000898,  0.04241762],\n",
              "         [ 0.04889193,  0.072974  , -0.11116786, ...,  0.03593157,\n",
              "           0.1200259 ,  0.04226675]],\n",
              " \n",
              "        [[ 0.08189404,  0.08942689, -0.12035061, ...,  0.07158051,\n",
              "           0.10237537,  0.1252409 ],\n",
              "         [ 0.06787037,  0.04474747, -0.1291291 , ...,  0.05305888,\n",
              "           0.10993835,  0.08959989],\n",
              "         [ 0.06055618,  0.03079783, -0.11110297, ...,  0.04178498,\n",
              "           0.12401915,  0.06759123],\n",
              "         ...,\n",
              "         [ 0.05243253,  0.07053378, -0.11069429, ...,  0.03482747,\n",
              "           0.12670857,  0.05174694],\n",
              "         [ 0.0524004 ,  0.07041875, -0.11060771, ...,  0.03506003,\n",
              "           0.12655371,  0.05171335],\n",
              "         [ 0.05204282,  0.07024039, -0.11026684, ...,  0.03532423,\n",
              "           0.12610714,  0.05154842]],\n",
              " \n",
              "        [[ 0.06603621,  0.08476046, -0.11649495, ...,  0.07170529,\n",
              "           0.11091743,  0.13073516],\n",
              "         [ 0.06995063,  0.05432592, -0.13010935, ...,  0.05052177,\n",
              "           0.10810201,  0.076179  ],\n",
              "         [ 0.07030486,  0.04105988, -0.12371233, ...,  0.04241265,\n",
              "           0.12175079,  0.05286368],\n",
              "         ...,\n",
              "         [ 0.07491899,  0.09603543, -0.10235459, ...,  0.05234284,\n",
              "           0.12692755,  0.04209303],\n",
              "         [ 0.07554228,  0.09624199, -0.10205707, ...,  0.05235577,\n",
              "           0.12738957,  0.04185977],\n",
              "         [ 0.07585385,  0.09631054, -0.10164355, ...,  0.05250722,\n",
              "           0.12762687,  0.04160228]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.08181033,  0.08973382, -0.1201372 , ...,  0.07145228,\n",
              "           0.10174948,  0.12506397],\n",
              "         [ 0.0694163 ,  0.0457495 , -0.12980883, ...,  0.05295496,\n",
              "           0.11028538,  0.09005424],\n",
              "         [ 0.06071762,  0.03142795, -0.11202428, ...,  0.04183044,\n",
              "           0.12364637,  0.06674632],\n",
              "         ...,\n",
              "         [ 0.05248371,  0.07143859, -0.10937146, ...,  0.03657286,\n",
              "           0.12668194,  0.05223943],\n",
              "         [ 0.05224296,  0.07131155, -0.10898827, ...,  0.03680187,\n",
              "           0.12577951,  0.05200994],\n",
              "         [ 0.05216816,  0.07125093, -0.10854112, ...,  0.03715418,\n",
              "           0.12519115,  0.05167744]],\n",
              " \n",
              "        [[ 0.07306269,  0.08535964, -0.11764509, ...,  0.0717776 ,\n",
              "           0.10091959,  0.12580535],\n",
              "         [ 0.06150617,  0.04337137, -0.12898318, ...,  0.05268841,\n",
              "           0.10241353,  0.08088554],\n",
              "         [ 0.06143083,  0.02832611, -0.11550541, ...,  0.0390805 ,\n",
              "           0.11800689,  0.06581895],\n",
              "         ...,\n",
              "         [ 0.05201986,  0.0753033 , -0.10934083, ...,  0.0357906 ,\n",
              "           0.12195551,  0.04401145],\n",
              "         [ 0.05190253,  0.07516053, -0.10926931, ...,  0.03565246,\n",
              "           0.12177624,  0.04420912],\n",
              "         [ 0.05178403,  0.07509346, -0.10922699, ...,  0.0356693 ,\n",
              "           0.12172776,  0.04434417]],\n",
              " \n",
              "        [[ 0.08182983,  0.0897546 , -0.11996727, ...,  0.07159978,\n",
              "           0.10132486,  0.125003  ],\n",
              "         [ 0.06994963,  0.04615651, -0.13035363, ...,  0.05303719,\n",
              "           0.11019199,  0.0904945 ],\n",
              "         [ 0.06047156,  0.03148489, -0.11285411, ...,  0.0420592 ,\n",
              "           0.12307081,  0.06683465],\n",
              "         ...,\n",
              "         [ 0.0523467 ,  0.0716006 , -0.10818477, ...,  0.03698853,\n",
              "           0.12510268,  0.05256998],\n",
              "         [ 0.05191868,  0.07150029, -0.10762212, ...,  0.03744889,\n",
              "           0.12466727,  0.05199569],\n",
              "         [ 0.05166977,  0.07150793, -0.10704714, ...,  0.03793942,\n",
              "           0.12427592,  0.05149204]]], dtype=float32),\n",
              " array([[[ 0.08268864,  0.0896084 , -0.12055501, ...,  0.07145537,\n",
              "           0.10249516,  0.12491141],\n",
              "         [ 0.06801009,  0.04488804, -0.12925248, ...,  0.05311379,\n",
              "           0.11016087,  0.08958603],\n",
              "         [ 0.06003444,  0.03121123, -0.11149111, ...,  0.04212456,\n",
              "           0.12381293,  0.066465  ],\n",
              "         ...,\n",
              "         [ 0.05231944,  0.07067563, -0.11015736, ...,  0.03552641,\n",
              "           0.1266408 ,  0.0513733 ],\n",
              "         [ 0.05219718,  0.0704812 , -0.11015511, ...,  0.03571337,\n",
              "           0.12611221,  0.05131946],\n",
              "         [ 0.05215535,  0.07016012, -0.11005185, ...,  0.03586804,\n",
              "           0.12545586,  0.05104086]],\n",
              " \n",
              "        [[ 0.07058845,  0.08538083, -0.1169364 , ...,  0.07016842,\n",
              "           0.10468835,  0.12656318],\n",
              "         [ 0.06263614,  0.04561147, -0.13040674, ...,  0.05119948,\n",
              "           0.10165679,  0.07830936],\n",
              "         [ 0.06471206,  0.03030997, -0.11969639, ...,  0.0375765 ,\n",
              "           0.117753  ,  0.06221066],\n",
              "         ...,\n",
              "         [ 0.06066427,  0.08580551, -0.10898127, ...,  0.04364588,\n",
              "           0.12275478,  0.04270075],\n",
              "         [ 0.06066652,  0.08590461, -0.1088026 , ...,  0.04383294,\n",
              "           0.1226497 ,  0.04263385],\n",
              "         [ 0.06059234,  0.08578143, -0.10876054, ...,  0.04412516,\n",
              "           0.12252538,  0.04254567]]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch):\n",
        "    \"\"\"Adjusts the learning rate of the optimizer.\"\"\"\n",
        "    lr = initial_lr * (0.1 ** (epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, initial_lr=0.001, lr_decay_epoch=3, device='cuda'):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    scheduler = StepLR(optimizer, step_size=lr_decay_epoch, gamma=0.1)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch)\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
        "\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "                real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "                output = model(real_features)\n",
        "                val_loss += criterion(output, deepfake_features).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "def evaluate_model(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    criterion = nn.MSELoss()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for real_features, deepfake_features in loader:\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model(real_features)\n",
        "            total_loss += criterion(output, deepfake_features).item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "BllmtizSJkaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, 1000)\n",
        "evaluate_model(model, val_loader)"
      ],
      "metadata": {
        "id": "4P7JfXv4JpxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emotion Recognition"
      ],
      "metadata": {
        "id": "DyYz4-9352xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b7pskfUbEyvu",
        "outputId": "3456f6ca-c0f3-435f-b938-c3c24a0fdde5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/session1.zip\n",
        "!unzip /content/drive/MyDrive/session1_video.zip"
      ],
      "metadata": {
        "id": "_Ua795v4wDUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94470cb-4ea0-4c09-9a89-43fbe522eead"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/session1.zip\n",
            "   creating: session1/\n",
            "   creating: session1/S01A/\n",
            "   creating: session1/S01A/P/\n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.wav  \n",
            "   creating: session1/S01A/R/\n",
            "  inflating: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.wav  \n",
            "   creating: session1/S01A/S/\n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.wav  \n",
            "   creating: session1/S01A/T/\n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.wav  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.wav  \n",
            "   creating: session1/S01H/\n",
            "   creating: session1/S01H/P/\n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav  \n",
            "   creating: session1/S01H/R/\n",
            "  inflating: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav  \n",
            "   creating: session1/S01H/S/\n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav  \n",
            "   creating: session1/S01H/T/\n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav  \n",
            "   creating: session1/S01N/\n",
            "   creating: session1/S01N/P/\n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.wav  \n",
            "   creating: session1/S01N/R/\n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.wav  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.wav  \n",
            "   creating: session1/S01N/S/\n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.wav  \n",
            "   creating: session1/S01N/T/\n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.wav  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.wav  \n",
            "   creating: session1/S01S/\n",
            "   creating: session1/S01S/P/\n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav  \n",
            "   creating: session1/S01S/R/\n",
            "  inflating: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav  \n",
            "   creating: session1/S01S/S/\n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav  \n",
            "   creating: session1/S01S/T/\n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav  \n",
            "   creating: session1/S02A/\n",
            "   creating: session1/S02A/P/\n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.wav  \n",
            "   creating: session1/S02A/R/\n",
            "  inflating: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.wav  \n",
            "   creating: session1/S02A/S/\n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.wav  \n",
            "   creating: session1/S02A/T/\n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.wav  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.wav  \n",
            "   creating: session1/S02H/\n",
            "   creating: session1/S02H/P/\n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.wav  \n",
            "   creating: session1/S02H/R/\n",
            "  inflating: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.wav  \n",
            "   creating: session1/S02H/S/\n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.wav  \n",
            "   creating: session1/S02H/T/\n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.wav  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.wav  \n",
            "   creating: session1/S02N/\n",
            "   creating: session1/S02N/P/\n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.wav  \n",
            "   creating: session1/S02N/R/\n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.wav  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.wav  \n",
            "   creating: session1/S02N/S/\n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.wav  \n",
            "   creating: session1/S02N/T/\n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.wav  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.wav  \n",
            "   creating: session1/S02S/\n",
            "   creating: session1/S02S/P/\n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav  \n",
            "   creating: session1/S02S/R/\n",
            "  inflating: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav  \n",
            "   creating: session1/S02S/S/\n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav  \n",
            "   creating: session1/S02S/T/\n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav  \n",
            "   creating: session1/S03A/\n",
            "   creating: session1/S03A/P/\n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav  \n",
            "   creating: session1/S03A/R/\n",
            "  inflating: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav  \n",
            "   creating: session1/S03A/S/\n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav  \n",
            "   creating: session1/S03A/T/\n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav  \n",
            "   creating: session1/S03H/\n",
            "   creating: session1/S03H/P/\n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.wav  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.wav  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.wav  \n",
            "   creating: session1/S03H/R/\n",
            "  inflating: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav  \n",
            "   creating: session1/S03H/S/\n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav  \n",
            "   creating: session1/S03H/T/\n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav  \n",
            "   creating: session1/S03N/\n",
            "   creating: session1/S03N/P/\n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.wav  \n",
            "   creating: session1/S03N/R/\n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.wav  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.wav  \n",
            "   creating: session1/S03N/S/\n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.wav  \n",
            "   creating: session1/S03N/T/\n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.wav  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.wav  \n",
            "   creating: session1/S03S/\n",
            "   creating: session1/S03S/P/\n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.wav  \n",
            "   creating: session1/S03S/R/\n",
            "  inflating: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.wav  \n",
            "   creating: session1/S03S/S/\n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.wav  \n",
            "   creating: session1/S03S/T/\n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.wav  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.wav  \n",
            "   creating: session1/S04A/\n",
            "   creating: session1/S04A/P/\n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.wav  \n",
            "   creating: session1/S04A/R/\n",
            "  inflating: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.wav  \n",
            "   creating: session1/S04A/S/\n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.wav  \n",
            "   creating: session1/S04A/T/\n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.wav  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.wav  \n",
            "   creating: session1/S04H/\n",
            "   creating: session1/S04H/P/\n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav  \n",
            "   creating: session1/S04H/R/\n",
            "  inflating: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav  \n",
            "   creating: session1/S04H/S/\n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav  \n",
            "   creating: session1/S04H/T/\n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav  \n",
            "   creating: session1/S04N/\n",
            "   creating: session1/S04N/P/\n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.wav  \n",
            "   creating: session1/S04N/R/\n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.wav  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.wav  \n",
            "   creating: session1/S04N/S/\n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.wav  \n",
            "   creating: session1/S04N/T/\n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.wav  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.wav  \n",
            "   creating: session1/S04S/\n",
            "   creating: session1/S04S/P/\n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav  \n",
            "   creating: session1/S04S/R/\n",
            "  inflating: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav  \n",
            "   creating: session1/S04S/S/\n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav  \n",
            "   creating: session1/S04S/T/\n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav  \n",
            "   creating: session1/S05A/\n",
            "   creating: session1/S05A/P/\n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.wav  \n",
            "   creating: session1/S05A/R/\n",
            "  inflating: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.wav  \n",
            "   creating: session1/S05A/S/\n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.wav  \n",
            "   creating: session1/S05A/T/\n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.wav  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.wav  \n",
            "   creating: session1/S05H/\n",
            "   creating: session1/S05H/P/\n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.wav  \n",
            "   creating: session1/S05H/R/\n",
            "  inflating: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.wav  \n",
            "   creating: session1/S05H/S/\n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.wav  \n",
            "   creating: session1/S05H/T/\n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.wav  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.wav  \n",
            "   creating: session1/S05N/\n",
            "   creating: session1/S05N/P/\n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav  \n",
            "   creating: session1/S05N/R/\n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav  \n",
            "   creating: session1/S05N/S/\n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav  \n",
            "   creating: session1/S05N/T/\n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav  \n",
            "   creating: session1/S05S/\n",
            "   creating: session1/S05S/P/\n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.wav  \n",
            "   creating: session1/S05S/R/\n",
            "  inflating: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.wav  \n",
            "   creating: session1/S05S/S/\n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.wav  \n",
            "   creating: session1/S05S/T/\n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.wav  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.wav  \n",
            "   creating: session1/S06A/\n",
            "   creating: session1/S06A/P/\n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.wav  \n",
            "   creating: session1/S06A/R/\n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.wav  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.wav  \n",
            "   creating: session1/S06A/S/\n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.wav  \n",
            "   creating: session1/S06A/T/\n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.wav  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.wav  \n",
            "   creating: session1/S06H/\n",
            "   creating: session1/S06H/P/\n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.wav  \n",
            "   creating: session1/S06H/R/\n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.wav  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.wav  \n",
            "   creating: session1/S06H/S/\n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.wav  \n",
            "   creating: session1/S06H/T/\n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.wav  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.wav  \n",
            "   creating: session1/S06N/\n",
            "   creating: session1/S06N/P/\n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.wav  \n",
            "   creating: session1/S06N/R/\n",
            "  inflating: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.wav  \n",
            "   creating: session1/S06N/S/\n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.wav  \n",
            "   creating: session1/S06N/T/\n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.wav  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.wav  \n",
            "   creating: session1/S06S/\n",
            "   creating: session1/S06S/P/\n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav  \n",
            "   creating: session1/S06S/R/\n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav  \n",
            "   creating: session1/S06S/S/\n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav  \n",
            "   creating: session1/S06S/T/\n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav  \n",
            "   creating: session1/S07A/\n",
            "   creating: session1/S07A/P/\n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav  \n",
            "   creating: session1/S07A/R/\n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav  \n",
            "   creating: session1/S07A/S/\n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav  \n",
            "   creating: session1/S07A/T/\n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav  \n",
            "   creating: session1/S07H/\n",
            "   creating: session1/S07H/P/\n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav  \n",
            "   creating: session1/S07H/R/\n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav  \n",
            "   creating: session1/S07H/S/\n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav  \n",
            "   creating: session1/S07H/T/\n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav  \n",
            "   creating: session1/S07N/\n",
            "   creating: session1/S07N/P/\n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.wav  \n",
            "   creating: session1/S07N/R/\n",
            "  inflating: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.wav  \n",
            "   creating: session1/S07N/S/\n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.wav  \n",
            "   creating: session1/S07N/T/\n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.wav  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.wav  \n",
            "   creating: session1/S07S/\n",
            "   creating: session1/S07S/P/\n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav  \n",
            "   creating: session1/S07S/R/\n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav  \n",
            "   creating: session1/S07S/S/\n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav  \n",
            "   creating: session1/S07S/T/\n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav  \n",
            "   creating: session1/S08A/\n",
            "   creating: session1/S08A/P/\n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav  \n",
            "   creating: session1/S08A/R/\n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav  \n",
            "   creating: session1/S08A/S/\n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav  \n",
            "   creating: session1/S08A/T/\n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav  \n",
            "   creating: session1/S08H/\n",
            "   creating: session1/S08H/P/\n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav  \n",
            "   creating: session1/S08H/R/\n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav  \n",
            "   creating: session1/S08H/S/\n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav  \n",
            "   creating: session1/S08H/T/\n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav  \n",
            "   creating: session1/S08N/\n",
            "   creating: session1/S08N/P/\n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.wav  \n",
            "   creating: session1/S08N/R/\n",
            "  inflating: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.wav  \n",
            "   creating: session1/S08N/S/\n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.wav  \n",
            "   creating: session1/S08N/T/\n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.wav  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.wav  \n",
            "   creating: session1/S08S/\n",
            "   creating: session1/S08S/P/\n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav  \n",
            "   creating: session1/S08S/R/\n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav  \n",
            "   creating: session1/S08S/S/\n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav  \n",
            "   creating: session1/S08S/T/\n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav  \n",
            "   creating: session1/S09A/\n",
            "   creating: session1/S09A/P/\n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.wav  \n",
            "   creating: session1/S09A/R/\n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.wav  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.wav  \n",
            "   creating: session1/S09A/S/\n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.wav  \n",
            "   creating: session1/S09A/T/\n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.wav  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.wav  \n",
            "   creating: session1/S09H/\n",
            "   creating: session1/S09H/P/\n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav  \n",
            "   creating: session1/S09H/R/\n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav  \n",
            "   creating: session1/S09H/S/\n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav  \n",
            "   creating: session1/S09H/T/\n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav  \n",
            "   creating: session1/S09N/\n",
            "   creating: session1/S09N/P/\n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav  \n",
            "   creating: session1/S09N/R/\n",
            "  inflating: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav  \n",
            "   creating: session1/S09N/S/\n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav  \n",
            "   creating: session1/S09N/T/\n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav  \n",
            "   creating: session1/S09S/\n",
            "   creating: session1/S09S/P/\n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.wav  \n",
            "   creating: session1/S09S/R/\n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.wav  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.wav  \n",
            "   creating: session1/S09S/S/\n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.wav  \n",
            "   creating: session1/S09S/T/\n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.wav  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.wav  \n",
            "   creating: session1/S10A/\n",
            "   creating: session1/S10A/P/\n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.wav  \n",
            "   creating: session1/S10A/R/\n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.wav  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.wav  \n",
            "   creating: session1/S10A/S/\n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.wav  \n",
            "   creating: session1/S10A/T/\n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.wav  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.wav  \n",
            "   creating: session1/S10H/\n",
            "   creating: session1/S10H/P/\n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav  \n",
            "   creating: session1/S10H/R/\n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav  \n",
            "   creating: session1/S10H/S/\n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav  \n",
            "   creating: session1/S10H/T/\n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav  \n",
            "   creating: session1/S10N/\n",
            "   creating: session1/S10N/P/\n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav  \n",
            "   creating: session1/S10N/R/\n",
            "  inflating: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav  \n",
            "   creating: session1/S10N/S/\n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav  \n",
            "   creating: session1/S10N/T/\n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav  \n",
            "   creating: session1/S10S/\n",
            "   creating: session1/S10S/P/\n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.wav  \n",
            "   creating: session1/S10S/R/\n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.wav  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.wav  \n",
            "   creating: session1/S10S/S/\n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.wav  \n",
            "   creating: session1/S10S/T/\n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.wav  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.wav  \n",
            "   creating: session1/S11A/\n",
            "   creating: session1/S11A/R/\n",
            "  inflating: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.wav  \n",
            "   creating: session1/S11H/\n",
            "   creating: session1/S11H/R/\n",
            "  inflating: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav  \n",
            "   creating: session1/S11N/\n",
            "   creating: session1/S11N/R/\n",
            "  inflating: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.wav  \n",
            "   creating: session1/S11S/\n",
            "   creating: session1/S11S/R/\n",
            "  inflating: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav  \n",
            "   creating: session1/S12A/\n",
            "   creating: session1/S12A/R/\n",
            "  inflating: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav  \n",
            "   creating: session1/S12H/\n",
            "   creating: session1/S12H/R/\n",
            "  inflating: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav  \n",
            "   creating: session1/S12N/\n",
            "   creating: session1/S12N/R/\n",
            "  inflating: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.wav  \n",
            "   creating: session1/S12S/\n",
            "   creating: session1/S12S/R/\n",
            "  inflating: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.wav  \n",
            "   creating: session1/S13A/\n",
            "   creating: session1/S13A/R/\n",
            "  inflating: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.wav  \n",
            "   creating: session1/S13H/\n",
            "   creating: session1/S13H/R/\n",
            "  inflating: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav  \n",
            "   creating: session1/S13N/\n",
            "   creating: session1/S13N/R/\n",
            "  inflating: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav  \n",
            "   creating: session1/S13S/\n",
            "   creating: session1/S13S/R/\n",
            "  inflating: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav  \n",
            "   creating: session1/S14A/\n",
            "   creating: session1/S14A/R/\n",
            "  inflating: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.wav  \n",
            "   creating: session1/S14H/\n",
            "   creating: session1/S14H/R/\n",
            "  inflating: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav  \n",
            "   creating: session1/S14N/\n",
            "   creating: session1/S14N/R/\n",
            "  inflating: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav  \n",
            "   creating: session1/S14S/\n",
            "   creating: session1/S14S/R/\n",
            "  inflating: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav  \n",
            "   creating: session1/S15A/\n",
            "   creating: session1/S15A/R/\n",
            "  inflating: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav  \n",
            "   creating: session1/S15H/\n",
            "   creating: session1/S15H/R/\n",
            "  inflating: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.wav  \n",
            "   creating: session1/S15N/\n",
            "   creating: session1/S15N/R/\n",
            "  inflating: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.wav  \n",
            "   creating: session1/S15S/\n",
            "   creating: session1/S15S/R/\n",
            "  inflating: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav  \n",
            "   creating: session1/S16A/\n",
            "   creating: session1/S16A/R/\n",
            "  inflating: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.wav  \n",
            "   creating: session1/S16H/\n",
            "   creating: session1/S16H/R/\n",
            "  inflating: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav  \n",
            "   creating: session1/S16N/\n",
            "   creating: session1/S16N/R/\n",
            "  inflating: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav  \n",
            "   creating: session1/S16S/\n",
            "   creating: session1/S16S/R/\n",
            "  inflating: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav  \n",
            "   creating: session1/S17A/\n",
            "   creating: session1/S17A/R/\n",
            "  inflating: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.wav  \n",
            "   creating: session1/S17H/\n",
            "   creating: session1/S17H/R/\n",
            "  inflating: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav  \n",
            "   creating: session1/S17N/\n",
            "   creating: session1/S17N/R/\n",
            "  inflating: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav  \n",
            "   creating: session1/S17S/\n",
            "   creating: session1/S17S/R/\n",
            "  inflating: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav  \n",
            "   creating: session1/S18A/\n",
            "   creating: session1/S18A/R/\n",
            "  inflating: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.wav  \n",
            "   creating: session1/S18H/\n",
            "   creating: session1/S18H/R/\n",
            "  inflating: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.wav  \n",
            "   creating: session1/S18N/\n",
            "   creating: session1/S18N/R/\n",
            "  inflating: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.wav  \n",
            "   creating: session1/S18S/\n",
            "   creating: session1/S18S/R/\n",
            "  inflating: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav  \n",
            "   creating: session1/S19A/\n",
            "   creating: session1/S19A/R/\n",
            "  inflating: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav  \n",
            "   creating: session1/S19H/\n",
            "   creating: session1/S19H/R/\n",
            "  inflating: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav  \n",
            "   creating: session1/S19N/\n",
            "   creating: session1/S19N/R/\n",
            "  inflating: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.wav  \n",
            "   creating: session1/S19S/\n",
            "   creating: session1/S19S/R/\n",
            "  inflating: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav  \n",
            "   creating: session1/S20A/\n",
            "   creating: session1/S20A/R/\n",
            "  inflating: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav  \n",
            "   creating: session1/S20H/\n",
            "   creating: session1/S20H/R/\n",
            "  inflating: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.wav  \n",
            "   creating: session1/S20N/\n",
            "   creating: session1/S20N/R/\n",
            "  inflating: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav  \n",
            "   creating: session1/S20S/\n",
            "   creating: session1/S20S/R/\n",
            "  inflating: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav  \n",
            "Archive:  /content/drive/MyDrive/session1_video.zip\n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.avi  \n",
            "  inflating: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.avi  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.avi  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.avi  \n",
            "  inflating: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.avi  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.avi  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.avi  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.avi  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.avi  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.avi  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.avi  \n",
            "  inflating: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.avi  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.avi  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.avi  \n",
            "  inflating: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.avi  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.avi  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.avi  \n",
            "  inflating: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.avi  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.avi  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.avi  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.avi  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.avi  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.avi  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.avi  \n",
            "  inflating: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.avi  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.avi  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.avi  \n",
            "  inflating: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.avi  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.avi  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.avi  \n",
            "  inflating: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.avi  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.avi  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.avi  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.avi  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.avi  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.avi  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.avi  \n",
            "  inflating: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.avi  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.avi  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.avi  \n",
            "  inflating: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.avi  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.avi  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.avi  \n",
            "  inflating: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.avi  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.avi  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.avi  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.avi  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.avi  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.avi  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.avi  \n",
            "  inflating: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.avi  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.avi  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.avi  \n",
            "  inflating: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.avi  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.avi  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.avi  \n",
            "  inflating: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.avi  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.avi  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.avi  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.avi  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.avi  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.avi  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.avi  \n",
            "  inflating: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.avi  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.avi  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.avi  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.avi  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.avi  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.avi  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.avi  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.avi  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.avi  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.avi  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.avi  \n",
            "  inflating: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.avi  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.avi  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.avi  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.avi  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.avi  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.avi  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.avi  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.avi  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.avi  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.avi  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.avi  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.avi  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.avi  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.avi  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.avi  \n",
            "  inflating: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.avi  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.avi  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.avi  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.avi  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.avi  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.avi  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.avi  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.avi  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.avi  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.avi  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.avi  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.avi  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.avi  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.avi  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.avi  \n",
            "  inflating: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.avi  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.avi  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.avi  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.avi  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.avi  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.avi  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.avi  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.avi  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.avi  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.avi  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.avi  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.avi  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.avi  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.avi  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.avi  \n",
            "  inflating: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.avi  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.avi  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.avi  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.avi  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.avi  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.avi  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.avi  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.avi  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.avi  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.avi  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.avi  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.avi  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.avi  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.avi  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.avi  \n",
            "  inflating: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.avi  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.avi  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.avi  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.avi  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.avi  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.avi  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.avi  \n",
            "  inflating: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.avi  \n",
            "  inflating: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.avi  \n",
            "  inflating: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.avi  \n",
            "  inflating: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.avi  \n",
            "  inflating: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.avi  \n",
            "  inflating: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.avi  \n",
            "  inflating: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.avi  \n",
            "  inflating: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.avi  \n",
            "  inflating: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.avi  \n",
            "  inflating: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.avi  \n",
            "  inflating: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.avi  \n",
            "  inflating: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.avi  \n",
            "  inflating: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.avi  \n",
            "  inflating: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.avi  \n",
            "  inflating: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.avi  \n",
            "  inflating: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.avi  \n",
            "  inflating: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.avi  \n",
            "  inflating: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.avi  \n",
            "  inflating: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.avi  \n",
            "  inflating: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.avi  \n",
            "  inflating: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.avi  \n",
            "  inflating: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.avi  \n",
            "  inflating: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.avi  \n",
            "  inflating: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.avi  \n",
            "  inflating: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.avi  \n",
            "  inflating: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.avi  \n",
            "  inflating: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.avi  \n",
            "  inflating: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.avi  \n",
            "  inflating: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.avi  \n",
            "  inflating: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.avi  \n",
            "  inflating: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.avi  \n",
            "  inflating: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.avi  \n",
            "  inflating: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.avi  \n",
            "  inflating: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.avi  \n",
            "  inflating: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.avi  \n",
            "  inflating: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.avi  \n",
            "  inflating: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.avi  \n",
            "  inflating: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.avi  \n",
            "  inflating: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.avi  \n",
            "  inflating: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.avi  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RvsXPF5Y9ChI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_features = []"
      ],
      "metadata": {
        "id": "ajbUG-T8sFrq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory containing video and audio files\n",
        "directory = \"session1\"\n",
        "\n",
        "# Initialize an empty dictionary to store video-audio pairs\n",
        "video_audio_mapping = {}\n",
        "\n",
        "# Iterate through the directory and its subdirectories\n",
        "for root, dirs, files in os.walk(directory):\n",
        "    for file in files:\n",
        "        if file.endswith(\".avi\"):\n",
        "            video_path = os.path.join(root, file)\n",
        "            # Replace .avi with .wav to get corresponding audio path\n",
        "            audio_path = os.path.join(root, file[:-4] + \".wav\")\n",
        "            # Check if corresponding audio file exists\n",
        "            if os.path.exists(audio_path):\n",
        "                video_audio_mapping[video_path] = audio_path\n",
        "\n",
        "# Print the video-audio mapping\n",
        "for video_path, audio_path in video_audio_mapping.items():\n",
        "    print(f\"Video: {video_path}, Audio: {audio_path}\")"
      ],
      "metadata": {
        "id": "IPROVaNy5cxs",
        "outputId": "3c36e29b-9a16-466d-dab7-5ccb71fc6b98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav\n",
            "Video: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.avi, Audio: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav\n",
            "Video: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.avi, Audio: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav\n",
            "Video: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.avi, Audio: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav\n",
            "Video: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.avi, Audio: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav\n",
            "Video: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.avi, Audio: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav\n",
            "Video: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.avi, Audio: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav\n",
            "Video: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.avi, Audio: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav\n",
            "Video: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.avi, Audio: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav\n",
            "Video: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.avi, Audio: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav\n",
            "Video: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.avi, Audio: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav\n",
            "Video: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.avi, Audio: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav\n",
            "Video: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.avi, Audio: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav\n",
            "Video: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.avi, Audio: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav\n",
            "Video: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.avi, Audio: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav\n",
            "Video: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.avi, Audio: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav\n",
            "Video: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.avi, Audio: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav\n",
            "Video: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.avi, Audio: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav\n",
            "Video: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.avi, Audio: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav\n",
            "Video: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.avi, Audio: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav\n",
            "Video: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.avi, Audio: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav\n",
            "Video: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.avi, Audio: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav\n",
            "Video: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.avi, Audio: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav\n",
            "Video: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.avi, Audio: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav\n",
            "Video: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.avi, Audio: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav\n",
            "Video: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.avi, Audio: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav\n",
            "Video: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.avi, Audio: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav\n",
            "Video: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.avi, Audio: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav\n",
            "Video: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.avi, Audio: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav\n",
            "Video: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.avi, Audio: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav\n",
            "Video: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.avi, Audio: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav\n",
            "Video: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.avi, Audio: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav\n",
            "Video: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.avi, Audio: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav\n",
            "Video: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.avi, Audio: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav\n",
            "Video: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.avi, Audio: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav\n",
            "Video: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.avi, Audio: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav\n",
            "Video: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.avi, Audio: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav\n",
            "Video: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.avi, Audio: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav\n",
            "Video: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.avi, Audio: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav\n",
            "Video: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.avi, Audio: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav\n",
            "Video: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.avi, Audio: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav\n",
            "Video: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.avi, Audio: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav\n",
            "Video: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.avi, Audio: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav\n",
            "Video: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.avi, Audio: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav\n",
            "Video: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.avi, Audio: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav\n",
            "Video: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.avi, Audio: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav\n",
            "Video: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.avi, Audio: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav\n",
            "Video: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.avi, Audio: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav\n",
            "Video: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.avi, Audio: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav\n",
            "Video: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.avi, Audio: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav\n",
            "Video: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.avi, Audio: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav\n",
            "Video: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.avi, Audio: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav\n",
            "Video: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.avi, Audio: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav\n",
            "Video: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.avi, Audio: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav\n",
            "Video: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.avi, Audio: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav\n",
            "Video: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.avi, Audio: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav\n",
            "Video: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.avi, Audio: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav\n",
            "Video: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.avi, Audio: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav\n",
            "Video: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.avi, Audio: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav\n",
            "Video: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.avi, Audio: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav\n",
            "Video: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.avi, Audio: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav\n",
            "Video: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.avi, Audio: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav\n",
            "Video: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.avi, Audio: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav\n",
            "Video: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.avi, Audio: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav\n",
            "Video: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.avi, Audio: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav\n",
            "Video: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.avi, Audio: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav\n",
            "Video: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.avi, Audio: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav\n",
            "Video: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.avi, Audio: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav\n",
            "Video: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.avi, Audio: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav\n",
            "Video: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.avi, Audio: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav\n",
            "Video: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.avi, Audio: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav\n",
            "Video: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.avi, Audio: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav\n",
            "Video: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.avi, Audio: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav\n",
            "Video: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.avi, Audio: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav\n",
            "Video: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.avi, Audio: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav\n",
            "Video: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.avi, Audio: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav\n",
            "Video: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.avi, Audio: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav\n",
            "Video: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.avi, Audio: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav\n",
            "Video: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.avi, Audio: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav\n",
            "Video: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.avi, Audio: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav\n",
            "Video: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.avi, Audio: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav\n",
            "Video: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.avi, Audio: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav\n",
            "Video: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.avi, Audio: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav\n",
            "Video: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.avi, Audio: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav\n",
            "Video: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.avi, Audio: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav\n",
            "Video: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.avi, Audio: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav\n",
            "Video: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.avi, Audio: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav\n",
            "Video: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.avi, Audio: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav\n",
            "Video: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.avi, Audio: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav\n",
            "Video: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.avi, Audio: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav\n",
            "Video: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.avi, Audio: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav\n",
            "Video: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.avi, Audio: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav\n",
            "Video: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.avi, Audio: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav\n",
            "Video: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.avi, Audio: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav\n",
            "Video: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.avi, Audio: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav\n",
            "Video: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.avi, Audio: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav\n",
            "Video: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.avi, Audio: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav\n",
            "Video: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.avi, Audio: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav\n",
            "Video: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.avi, Audio: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav\n",
            "Video: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.avi, Audio: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav\n",
            "Video: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.avi, Audio: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav\n",
            "Video: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.avi, Audio: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav\n",
            "Video: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.avi, Audio: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav\n",
            "Video: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.avi, Audio: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.wav\n",
            "Video: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.avi, Audio: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.wav\n",
            "Video: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.avi, Audio: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.wav\n",
            "Video: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.avi, Audio: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.wav\n",
            "Video: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.avi, Audio: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.wav\n",
            "Video: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.avi, Audio: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.wav\n",
            "Video: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.avi, Audio: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.wav\n",
            "Video: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.avi, Audio: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.wav\n",
            "Video: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.avi, Audio: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.wav\n",
            "Video: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.avi, Audio: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.wav\n",
            "Video: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.avi, Audio: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.wav\n",
            "Video: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.avi, Audio: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.wav\n",
            "Video: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.avi, Audio: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.wav\n",
            "Video: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.avi, Audio: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.wav\n",
            "Video: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.avi, Audio: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.wav\n",
            "Video: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.avi, Audio: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.wav\n",
            "Video: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.avi, Audio: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.wav\n",
            "Video: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.avi, Audio: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.wav\n",
            "Video: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.avi, Audio: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.wav\n",
            "Video: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.avi, Audio: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.wav\n",
            "Video: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.avi, Audio: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.wav\n",
            "Video: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.avi, Audio: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.wav\n",
            "Video: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.avi, Audio: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.wav\n",
            "Video: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.avi, Audio: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.wav\n",
            "Video: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.avi, Audio: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.wav\n",
            "Video: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.avi, Audio: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.wav\n",
            "Video: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.avi, Audio: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.wav\n",
            "Video: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.avi, Audio: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.wav\n",
            "Video: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.avi, Audio: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.wav\n",
            "Video: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.avi, Audio: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.wav\n",
            "Video: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.avi, Audio: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.wav\n",
            "Video: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.avi, Audio: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.wav\n",
            "Video: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.avi, Audio: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.wav\n",
            "Video: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.avi, Audio: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.wav\n",
            "Video: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.avi, Audio: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.wav\n",
            "Video: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.avi, Audio: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.wav\n",
            "Video: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.avi, Audio: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.wav\n",
            "Video: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.avi, Audio: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.wav\n",
            "Video: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.avi, Audio: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.wav\n",
            "Video: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.avi, Audio: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.wav\n",
            "Video: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.avi, Audio: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.wav\n",
            "Video: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.avi, Audio: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.wav\n",
            "Video: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.avi, Audio: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.wav\n",
            "Video: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.avi, Audio: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.wav\n",
            "Video: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.avi, Audio: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.wav\n",
            "Video: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.avi, Audio: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.wav\n",
            "Video: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.avi, Audio: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.wav\n",
            "Video: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.avi, Audio: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.wav\n",
            "Video: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.avi, Audio: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.wav\n",
            "Video: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.avi, Audio: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.wav\n",
            "Video: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.avi, Audio: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.wav\n",
            "Video: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.avi, Audio: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.wav\n",
            "Video: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.avi, Audio: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.wav\n",
            "Video: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.avi, Audio: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.wav\n",
            "Video: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.avi, Audio: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.wav\n",
            "Video: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.avi, Audio: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.wav\n",
            "Video: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.avi, Audio: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.wav\n",
            "Video: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.avi, Audio: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.wav\n",
            "Video: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.avi, Audio: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.wav\n",
            "Video: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.avi, Audio: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.wav\n",
            "Video: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.avi, Audio: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.wav\n",
            "Video: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.avi, Audio: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.wav\n",
            "Video: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.avi, Audio: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.wav\n",
            "Video: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.avi, Audio: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.wav\n",
            "Video: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.avi, Audio: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.wav\n",
            "Video: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.avi, Audio: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.wav\n",
            "Video: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.avi, Audio: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.wav\n",
            "Video: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.avi, Audio: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.wav\n",
            "Video: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.avi, Audio: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.wav\n",
            "Video: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.avi, Audio: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.wav\n",
            "Video: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.avi, Audio: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.wav\n",
            "Video: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.avi, Audio: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.wav\n",
            "Video: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.avi, Audio: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.wav\n",
            "Video: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.avi, Audio: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.wav\n",
            "Video: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.avi, Audio: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.wav\n",
            "Video: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.avi, Audio: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.wav\n",
            "Video: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.avi, Audio: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.wav\n",
            "Video: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.avi, Audio: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.wav\n",
            "Video: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.avi, Audio: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.wav\n",
            "Video: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.avi, Audio: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.wav\n",
            "Video: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.avi, Audio: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.wav\n",
            "Video: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.avi, Audio: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.wav\n",
            "Video: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.avi, Audio: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.wav\n",
            "Video: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.avi, Audio: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.wav\n",
            "Video: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.avi, Audio: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.wav\n",
            "Video: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.avi, Audio: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.wav\n",
            "Video: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.avi, Audio: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.wav\n",
            "Video: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.avi, Audio: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.wav\n",
            "Video: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.avi, Audio: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.wav\n",
            "Video: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.avi, Audio: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.wav\n",
            "Video: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.avi, Audio: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.wav\n",
            "Video: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.avi, Audio: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.wav\n",
            "Video: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.avi, Audio: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.wav\n",
            "Video: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.avi, Audio: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.wav\n",
            "Video: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.avi, Audio: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def resize_video(video_path, output_path, width=320, height=240):\n",
        "    # Open the video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        return\n",
        "\n",
        "    # Get original video properties\n",
        "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change this to match your video codec\n",
        "\n",
        "    # Create a VideoWriter object to write the resized video\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        # Resize the frame to the specified dimensions\n",
        "        resized_frame = cv2.resize(frame, (width, height))\n",
        "        out.write(resized_frame)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "ap1oGYNyBwGh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ckpt_path = \"/content/data/finetune-model.pt\"\n",
        "user_dir = \"/content/av_hubert/avhubert\"\n",
        "files = {}\n",
        "for video_path, audio_path in video_audio_mapping.items():\n",
        "  files[video_path] = audio_path\n",
        "  label = video_path.split(\"/\")[-3][-1]  # Extract the last character from the third last part of the path\n",
        "  if label == 'A':\n",
        "    label = 0\n",
        "  elif label == 'H':\n",
        "    label = 1\n",
        "  elif label == 'S':\n",
        "    label = 2\n",
        "  else:\n",
        "    label = 3\n",
        "  # Resize the video\n",
        "  output_path = \"resized_video.avi\"\n",
        "  resize_video(video_path, output_path, width=320, height=240)\n",
        "\n",
        "  # Extract visual features\n",
        "  layer_features, feature = extract_visual_feature(output_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "  # Create a tensor for the label\n",
        "  label_tensor = torch.tensor([label] * feature.size(0), dtype=torch.float).unsqueeze(1)  # Repeat the label for each row in feature\n",
        "\n",
        "  # Concatenate the label tensor with the feature tensor along the second dimension (columns)\n",
        "  label_tensor = label_tensor.to(feature.device)\n",
        "  feature_with_label = torch.cat((feature, label_tensor), dim=1)\n",
        "  final_features.append(feature_with_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SDLYlMN5gm5E",
        "outputId": "3db36079-be21-445e-89b0-40e36625d1d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (48, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 48, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav: shape torch.Size([1, 104, 48])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([48, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (47, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 47, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav: shape torch.Size([1, 104, 47])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([47, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (131, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 131, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav: shape torch.Size([1, 104, 131])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([131, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (46, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav: shape (39, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 46, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav: shape torch.Size([1, 104, 46])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([46, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (139, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav: shape (116, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 139, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav: shape torch.Size([1, 104, 139])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([139, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (159, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 159, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav: shape torch.Size([1, 104, 159])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([159, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (66, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav: shape (56, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 66, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav: shape torch.Size([1, 104, 66])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([66, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (123, 240, 320)\n",
            "Load audio session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav: shape (103, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 123, 240, 320])\n",
            "Load audio session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (146, 240, 320)\n",
            "Load audio session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav: shape (122, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 146, 240, 320])\n",
            "Load audio session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav: shape torch.Size([1, 104, 146])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([146, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (56, 240, 320)\n",
            "Load audio session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav: shape (47, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 56, 240, 320])\n",
            "Load audio session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav: shape torch.Size([1, 104, 56])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([56, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (42, 240, 320)\n",
            "Load audio session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav: shape (36, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 42, 240, 320])\n",
            "Load audio session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav: shape torch.Size([1, 104, 42])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([42, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav: shape (127, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (148, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 148, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav: shape torch.Size([1, 104, 148])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([148, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (92, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav: shape (77, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 92, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (148, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 148, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav: shape torch.Size([1, 104, 148])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([148, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (242, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav: shape (203, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 242, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav: shape torch.Size([1, 104, 242])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([242, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (230, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav: shape (192, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 230, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav: shape torch.Size([1, 104, 230])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([230, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (110, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav: shape (92, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 110, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (223, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav: shape (186, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 223, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav: shape torch.Size([1, 104, 223])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([223, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (43, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav: shape (36, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 43, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav: shape torch.Size([1, 104, 43])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([43, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (89, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav: shape (74, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 89, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (140, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav: shape (117, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 140, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav: shape torch.Size([1, 104, 140])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([140, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (159, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 159, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav: shape torch.Size([1, 104, 159])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([159, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (130, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 130, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav: shape torch.Size([1, 104, 130])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([130, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (82, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav: shape (69, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 82, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (76, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav: shape (64, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 76, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav: shape torch.Size([1, 104, 76])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([76, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (225, 240, 320)\n",
            "Load audio session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav: shape (188, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 225, 240, 320])\n",
            "Load audio session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav: shape torch.Size([1, 104, 225])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([225, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (172, 240, 320)\n",
            "Load audio session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav: shape (144, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 172, 240, 320])\n",
            "Load audio session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav: shape torch.Size([1, 104, 172])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([172, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (124, 240, 320)\n",
            "Load audio session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav: shape (104, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 124, 240, 320])\n",
            "Load audio session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav: shape torch.Size([1, 104, 124])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([124, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (186, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav: shape (155, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 186, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav: shape torch.Size([1, 104, 186])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([186, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (247, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav: shape (206, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 247, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav: shape torch.Size([1, 104, 247])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([247, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (117, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav: shape (98, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 117, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (148, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 148, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav: shape torch.Size([1, 104, 148])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([148, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (355, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav: shape (296, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 355, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav: shape torch.Size([1, 104, 355])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([355, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (104, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav: shape (87, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 104, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (143, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav: shape (120, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 143, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav: shape torch.Size([1, 104, 143])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([143, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (134, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 134, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav: shape torch.Size([1, 104, 134])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([134, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (162, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 162, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav: shape torch.Size([1, 104, 162])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([162, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (193, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 193, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav: shape torch.Size([1, 104, 193])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([193, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (193, 240, 320)\n",
            "Load audio session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 193, 240, 320])\n",
            "Load audio session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav: shape torch.Size([1, 104, 193])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([193, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (169, 240, 320)\n",
            "Load audio session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav: shape (141, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 169, 240, 320])\n",
            "Load audio session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav: shape torch.Size([1, 104, 169])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([169, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (114, 240, 320)\n",
            "Load audio session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav: shape (95, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 114, 240, 320])\n",
            "Load audio session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (146, 240, 320)\n",
            "Load audio session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav: shape (123, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 146, 240, 320])\n",
            "Load audio session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav: shape torch.Size([1, 104, 146])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([146, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (116, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav: shape (97, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 116, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (207, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav: shape (173, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 207, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav: shape torch.Size([1, 104, 207])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([207, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (53, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav: shape (45, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 53, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav: shape torch.Size([1, 104, 53])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([53, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (136, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav: shape (114, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 136, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (265, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav: shape (221, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 265, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav: shape torch.Size([1, 104, 265])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([265, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (184, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav: shape (154, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 184, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav: shape torch.Size([1, 104, 184])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([184, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (280, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav: shape (234, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 280, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav: shape torch.Size([1, 104, 280])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([280, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (168, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 168, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav: shape torch.Size([1, 104, 168])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([168, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (70, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 70, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav: shape torch.Size([1, 104, 70])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([70, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (189, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav: shape (158, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 189, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav: shape torch.Size([1, 104, 189])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([189, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (378, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav: shape (315, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 378, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav: shape torch.Size([1, 104, 378])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([378, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (240, 240, 320)\n",
            "Load audio session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav: shape (201, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 240, 240, 320])\n",
            "Load audio session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav: shape torch.Size([1, 104, 240])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([240, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (196, 240, 320)\n",
            "Load audio session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav: shape (164, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 196, 240, 320])\n",
            "Load audio session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav: shape torch.Size([1, 104, 196])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([196, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav: shape (122, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (161, 240, 320)\n",
            "Load audio session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav: shape (135, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 161, 240, 320])\n",
            "Load audio session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav: shape torch.Size([1, 104, 161])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([161, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (115, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav: shape (96, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 115, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (70, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 70, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav: shape torch.Size([1, 104, 70])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([70, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (132, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav: shape (111, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 132, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav: shape torch.Size([1, 104, 132])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([132, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (45, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav: shape (38, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 45, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav: shape torch.Size([1, 104, 45])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([45, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (36, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav: shape (30, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 36, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav: shape torch.Size([1, 104, 36])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([36, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (179, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav: shape (150, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 179, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav: shape torch.Size([1, 104, 179])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([179, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (224, 240, 320)\n",
            "Load audio session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav: shape (187, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 224, 240, 320])\n",
            "Load audio session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav: shape torch.Size([1, 104, 224])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([224, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (176, 240, 320)\n",
            "Load audio session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav: shape (147, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 176, 240, 320])\n",
            "Load audio session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav: shape torch.Size([1, 104, 176])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([176, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (98, 240, 320)\n",
            "Load audio session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 98, 240, 320])\n",
            "Load audio session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (71, 240, 320)\n",
            "Load audio session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 71, 240, 320])\n",
            "Load audio session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav: shape torch.Size([1, 104, 71])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([71, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (135, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 135, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav: shape torch.Size([1, 104, 135])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([135, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (117, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav: shape (98, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 117, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (124, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav: shape (104, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 124, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav: shape torch.Size([1, 104, 124])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([124, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (127, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 127, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav: shape torch.Size([1, 104, 127])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([127, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (335, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav: shape (280, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 335, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav: shape torch.Size([1, 104, 335])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([335, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (155, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav: shape (130, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 155, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (82, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav: shape (69, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 82, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (220, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav: shape (184, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 220, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav: shape torch.Size([1, 104, 220])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([220, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (137, 240, 320)\n",
            "Load audio session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav: shape (115, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 137, 240, 320])\n",
            "Load audio session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (94, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav: shape (79, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 94, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav: shape torch.Size([1, 104, 94])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([94, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav: shape (137, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (239, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav: shape (200, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 239, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav: shape torch.Size([1, 104, 239])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([239, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (91, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 91, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav: shape torch.Size([1, 104, 91])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([91, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (139, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav: shape (117, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 139, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav: shape torch.Size([1, 104, 139])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([139, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (183, 240, 320)\n",
            "Load audio session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 183, 240, 320])\n",
            "Load audio session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav: shape torch.Size([1, 104, 183])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([183, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (95, 240, 320)\n",
            "Load audio session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav: shape (80, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 95, 240, 320])\n",
            "Load audio session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (57, 240, 320)\n",
            "Load audio session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav: shape (48, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 57, 240, 320])\n",
            "Load audio session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav: shape torch.Size([1, 104, 57])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([57, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (144, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav: shape (121, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 144, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav: shape torch.Size([1, 104, 144])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([144, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (71, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav: shape (60, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 71, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav: shape torch.Size([1, 104, 71])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([71, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (32, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav: shape (27, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 32, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav: shape torch.Size([1, 104, 32])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([32, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (91, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 91, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav: shape torch.Size([1, 104, 91])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([91, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (355, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav: shape (297, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 355, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav: shape torch.Size([1, 104, 355])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([355, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav: shape (66, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (109, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav: shape (91, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 109, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (132, 240, 320)\n",
            "Load audio session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav: shape (111, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 132, 240, 320])\n",
            "Load audio session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav: shape torch.Size([1, 104, 132])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([132, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (171, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav: shape (144, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 171, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav: shape torch.Size([1, 104, 171])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([171, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (344, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav: shape (287, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 344, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav: shape torch.Size([1, 104, 344])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([344, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (109, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav: shape (92, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 109, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (106, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 106, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (141, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav: shape (118, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 141, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav: shape torch.Size([1, 104, 141])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([141, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (90, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 90, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav: shape (121, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav: shape (125, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (342, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav: shape (286, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 342, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav: shape torch.Size([1, 104, 342])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([342, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav: shape (126, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (288, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav: shape (241, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 288, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav: shape torch.Size([1, 104, 288])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([288, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (74, 240, 320)\n",
            "Load audio session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 74, 240, 320])\n",
            "Load audio session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav: shape torch.Size([1, 104, 74])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([74, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (120, 240, 320)\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 120, 240, 320])\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav: shape torch.Size([1, 104, 120])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([120, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (124, 240, 320)\n",
            "Load audio session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav: shape (104, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 124, 240, 320])\n",
            "Load audio session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav: shape torch.Size([1, 104, 124])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([124, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (226, 240, 320)\n",
            "Load audio session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav: shape (189, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 226, 240, 320])\n",
            "Load audio session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav: shape torch.Size([1, 104, 226])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([226, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (93, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav: shape (78, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 93, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (87, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav: shape (73, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 87, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (37, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav: shape (32, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 37, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav: shape torch.Size([1, 104, 37])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([37, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (57, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav: shape (48, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 57, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav: shape torch.Size([1, 104, 57])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([57, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (97, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav: shape (82, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 97, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (67, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav: shape (56, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 67, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav: shape torch.Size([1, 104, 67])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([67, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav: shape (58, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (120, 240, 320)\n",
            "Load audio session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 120, 240, 320])\n",
            "Load audio session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav: shape torch.Size([1, 104, 120])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([120, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (41, 240, 320)\n",
            "Load audio session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav: shape (35, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 41, 240, 320])\n",
            "Load audio session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav: shape torch.Size([1, 104, 41])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([41, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (167, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 167, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav: shape torch.Size([1, 104, 167])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([167, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (45, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav: shape (38, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 45, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav: shape torch.Size([1, 104, 45])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([45, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (193, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 193, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav: shape torch.Size([1, 104, 193])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([193, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (64, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (196, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav: shape (164, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 196, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav: shape torch.Size([1, 104, 196])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([196, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (111, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav: shape (93, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 111, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav: shape torch.Size([1, 104, 111])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([111, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (47, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 47, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav: shape torch.Size([1, 104, 47])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([47, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (173, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav: shape (145, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 173, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav: shape torch.Size([1, 104, 173])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([173, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (58, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav: shape (49, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 58, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav: shape torch.Size([1, 104, 58])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([58, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (162, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 162, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav: shape torch.Size([1, 104, 162])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([162, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (41, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav: shape (35, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 41, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav: shape torch.Size([1, 104, 41])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([41, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav: shape (126, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav: shape (66, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (342, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav: shape (286, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 342, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav: shape torch.Size([1, 104, 342])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([342, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (91, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 91, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav: shape torch.Size([1, 104, 91])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([91, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (39, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav: shape (33, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 39, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav: shape torch.Size([1, 104, 39])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([39, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (177, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav: shape (148, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 177, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav: shape torch.Size([1, 104, 177])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([177, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (90, 240, 320)\n",
            "Load audio session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 90, 240, 320])\n",
            "Load audio session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (180, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav: shape (151, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 180, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav: shape torch.Size([1, 104, 180])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([180, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (164, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 164, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav: shape torch.Size([1, 104, 164])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([164, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (220, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav: shape (184, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 220, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav: shape torch.Size([1, 104, 220])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([220, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (135, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 135, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav: shape torch.Size([1, 104, 135])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([135, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (172, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav: shape (144, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 172, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav: shape torch.Size([1, 104, 172])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([172, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (228, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav: shape (190, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 228, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav: shape torch.Size([1, 104, 228])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([228, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (142, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav: shape (119, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 142, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav: shape torch.Size([1, 104, 142])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([142, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (39, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav: shape (33, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 39, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav: shape torch.Size([1, 104, 39])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([39, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (140, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav: shape (118, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 140, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav: shape torch.Size([1, 104, 140])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([140, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (48, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 48, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav: shape torch.Size([1, 104, 48])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([48, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (111, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 111, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav: shape torch.Size([1, 104, 111])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([111, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (188, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav: shape (158, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 188, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav: shape torch.Size([1, 104, 188])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([188, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (94, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav: shape (79, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 94, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav: shape torch.Size([1, 104, 94])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([94, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (236, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav: shape (198, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 236, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav: shape torch.Size([1, 104, 236])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([236, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (64, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (78, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav: shape (65, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 78, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav: shape torch.Size([1, 104, 78])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([78, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (190, 240, 320)\n",
            "Load audio session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav: shape (159, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 190, 240, 320])\n",
            "Load audio session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav: shape torch.Size([1, 104, 190])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([190, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (78, 240, 320)\n",
            "Load audio session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav: shape (66, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 78, 240, 320])\n",
            "Load audio session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav: shape torch.Size([1, 104, 78])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([78, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (594, 240, 320)\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav: shape (496, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 594, 240, 320])\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav: shape torch.Size([1, 104, 594])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([594, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (241, 240, 320)\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav: shape (201, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 241, 240, 320])\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav: shape torch.Size([1, 104, 241])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([241, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav: shape (121, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav: shape (90, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (191, 240, 320)\n",
            "Load audio session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav: shape (160, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 191, 240, 320])\n",
            "Load audio session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav: shape torch.Size([1, 104, 191])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([191, 768])\n",
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav: shape (61, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n",
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (113, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav: shape (95, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 113, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav: shape torch.Size([1, 104, 113])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([113, 768])\n",
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav: shape (47, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (136, 240, 320)\n",
            "Load audio session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav: shape (114, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 136, 240, 320])\n",
            "Load audio session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (34, 240, 320)\n",
            "Load audio session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav: shape (29, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 34, 240, 320])\n",
            "Load audio session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav: shape torch.Size([1, 104, 34])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([34, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (45, 240, 320)\n",
            "Load audio session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav: shape (38, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 45, 240, 320])\n",
            "Load audio session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav: shape torch.Size([1, 104, 45])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([45, 768])\n",
            "Load video resized_video.avi: shape (235, 240, 320)\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav: shape (196, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 235, 240, 320])\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav: shape torch.Size([1, 104, 235])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([235, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (51, 240, 320)\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav: shape (43, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 51, 240, 320])\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav: shape torch.Size([1, 104, 51])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([51, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (206, 240, 320)\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav: shape (173, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 206, 240, 320])\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav: shape torch.Size([1, 104, 206])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([206, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (89, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav: shape (74, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 89, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (49, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav: shape (41, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 49, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav: shape torch.Size([1, 104, 49])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([49, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (84, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 84, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav: shape torch.Size([1, 104, 84])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([84, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (127, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 127, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav: shape torch.Size([1, 104, 127])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([127, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (64, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (75, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav: shape (63, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 75, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav: shape torch.Size([1, 104, 75])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([75, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (93, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav: shape (78, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 93, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (23, 240, 320)\n",
            "Load audio session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav: shape (20, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 23, 240, 320])\n",
            "Load audio session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav: shape torch.Size([1, 104, 23])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([23, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (30, 240, 320)\n",
            "Load audio session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav: shape (26, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 30, 240, 320])\n",
            "Load audio session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav: shape torch.Size([1, 104, 30])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([30, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (111, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav: shape (93, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 111, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav: shape torch.Size([1, 104, 111])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([111, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav: shape (132, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (98, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 98, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (66, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 66, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav: shape torch.Size([1, 104, 66])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([66, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (36, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav: shape (30, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 36, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav: shape torch.Size([1, 104, 36])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([36, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (104, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav: shape (87, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 104, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (147, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav: shape (123, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 147, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav: shape torch.Size([1, 104, 147])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([147, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (173, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav: shape (145, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 173, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav: shape torch.Size([1, 104, 173])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([173, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (76, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav: shape (64, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 76, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav: shape torch.Size([1, 104, 76])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([76, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (262, 240, 320)\n",
            "Load audio session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav: shape (219, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 262, 240, 320])\n",
            "Load audio session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav: shape torch.Size([1, 104, 262])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([262, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (92, 240, 320)\n",
            "Load audio session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav: shape (77, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 92, 240, 320])\n",
            "Load audio session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (209, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav: shape (175, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 209, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav: shape torch.Size([1, 104, 209])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([209, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (157, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav: shape (132, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 157, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav: shape torch.Size([1, 104, 157])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([157, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (86, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav: shape (72, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 86, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (88, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav: shape (74, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 88, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (144, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav: shape (120, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 144, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav: shape torch.Size([1, 104, 144])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([144, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (151, 240, 320)\n",
            "Load audio session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav: shape (127, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 151, 240, 320])\n",
            "Load audio session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav: shape torch.Size([1, 104, 151])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([151, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (123, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav: shape (103, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 123, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav: shape (91, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (114, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav: shape (96, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 114, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav: shape (72, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (138, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav: shape (116, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 138, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (127, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 127, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav: shape torch.Size([1, 104, 127])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([127, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (187, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav: shape (157, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 187, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav: shape torch.Size([1, 104, 187])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([187, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav: shape (47, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (171, 240, 320)\n",
            "Load audio session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav: shape (143, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 171, 240, 320])\n",
            "Load audio session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav: shape torch.Size([1, 104, 171])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([171, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (86, 240, 320)\n",
            "Load audio session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav: shape (72, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 86, 240, 320])\n",
            "Load audio session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (175, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav: shape (146, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 175, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav: shape torch.Size([1, 104, 175])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([175, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (117, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav: shape (98, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 117, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (423, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav: shape (354, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 423, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav: shape torch.Size([1, 104, 423])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([423, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (268, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav: shape (224, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 268, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav: shape torch.Size([1, 104, 268])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([268, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (166, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav: shape (139, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 166, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav: shape torch.Size([1, 104, 166])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([166, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (147, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 147, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav: shape torch.Size([1, 104, 147])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([147, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (218, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav: shape (183, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 218, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav: shape torch.Size([1, 104, 218])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([218, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (180, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav: shape (151, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 180, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav: shape torch.Size([1, 104, 180])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([180, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav: shape (152, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (134, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 134, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav: shape torch.Size([1, 104, 134])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([134, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (251, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav: shape (210, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 251, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav: shape torch.Size([1, 104, 251])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([251, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (162, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 162, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav: shape torch.Size([1, 104, 162])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([162, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (168, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav: shape (141, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 168, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav: shape torch.Size([1, 104, 168])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([168, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (111, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav: shape (93, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 111, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav: shape torch.Size([1, 104, 111])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([111, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (151, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav: shape (126, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 151, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav: shape torch.Size([1, 104, 151])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([151, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (77, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav: shape (65, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 77, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav: shape torch.Size([1, 104, 77])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([77, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (209, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav: shape (175, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 209, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav: shape torch.Size([1, 104, 209])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([209, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (198, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav: shape (165, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 198, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav: shape torch.Size([1, 104, 198])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([198, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (132, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav: shape (110, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 132, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav: shape torch.Size([1, 104, 132])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([132, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (125, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 125, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (259, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav: shape (217, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 259, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav: shape torch.Size([1, 104, 259])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([259, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (311, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav: shape (260, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 311, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav: shape torch.Size([1, 104, 311])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([311, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (247, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav: shape (207, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 247, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav: shape torch.Size([1, 104, 247])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([247, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav: shape (52, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (530, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav: shape (442, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 530, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav: shape torch.Size([1, 104, 530])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([530, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (239, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav: shape (200, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 239, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav: shape torch.Size([1, 104, 239])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([239, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (167, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 167, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav: shape torch.Size([1, 104, 167])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([167, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav: shape (61, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (332, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav: shape (278, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 332, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav: shape torch.Size([1, 104, 332])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([332, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (294, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav: shape (245, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 294, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav: shape torch.Size([1, 104, 294])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([294, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (130, 240, 320)\n",
            "Load audio session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 130, 240, 320])\n",
            "Load audio session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav: shape torch.Size([1, 104, 130])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([130, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav: shape (90, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (104, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav: shape (87, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 104, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (191, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav: shape (160, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 191, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav: shape torch.Size([1, 104, 191])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([191, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (48, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 48, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav: shape torch.Size([1, 104, 48])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([48, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (117, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav: shape (98, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 117, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (95, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav: shape (80, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 95, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (253, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav: shape (212, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 253, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav: shape torch.Size([1, 104, 253])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([253, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (123, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav: shape (103, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 123, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (77, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav: shape (65, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 77, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav: shape torch.Size([1, 104, 77])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([77, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (176, 240, 320)\n",
            "Load audio session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav: shape (147, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 176, 240, 320])\n",
            "Load audio session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav: shape torch.Size([1, 104, 176])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([176, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (243, 240, 320)\n",
            "Load audio session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav: shape (203, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 243, 240, 320])\n",
            "Load audio session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav: shape torch.Size([1, 104, 243])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([243, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (135, 240, 320)\n",
            "Load audio session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 135, 240, 320])\n",
            "Load audio session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav: shape torch.Size([1, 104, 135])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([135, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (487, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav: shape (407, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 487, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav: shape torch.Size([1, 104, 487])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([487, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav: shape (132, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (147, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav: shape (123, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 147, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav: shape torch.Size([1, 104, 147])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([147, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (350, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav: shape (292, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 350, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav: shape torch.Size([1, 104, 350])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([350, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (194, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 194, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav: shape torch.Size([1, 104, 194])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([194, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (262, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav: shape (219, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 262, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav: shape torch.Size([1, 104, 262])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([262, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav: shape (125, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (230, 240, 320)\n",
            "Load audio session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav: shape (193, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 230, 240, 320])\n",
            "Load audio session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav: shape torch.Size([1, 104, 230])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([230, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav: shape (122, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav: shape (45, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (105, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav: shape (88, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 105, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav: shape torch.Size([1, 104, 105])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([105, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (93, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav: shape (78, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 93, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav: shape (129, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav: shape (45, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (125, 240, 320)\n",
            "Load audio session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 125, 240, 320])\n",
            "Load audio session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (170, 240, 320)\n",
            "Load audio session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav: shape (143, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 170, 240, 320])\n",
            "Load audio session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav: shape torch.Size([1, 104, 170])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([170, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (63, 240, 320)\n",
            "Load audio session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 63, 240, 320])\n",
            "Load audio session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav: shape torch.Size([1, 104, 63])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([63, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (47, 240, 320)\n",
            "Load audio session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 47, 240, 320])\n",
            "Load audio session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav: shape torch.Size([1, 104, 47])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([47, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (107, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 107, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav: shape torch.Size([1, 104, 107])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([107, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (168, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 168, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav: shape torch.Size([1, 104, 168])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([168, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (197, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav: shape (165, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 197, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav: shape torch.Size([1, 104, 197])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([197, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (84, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 84, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav: shape torch.Size([1, 104, 84])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([84, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (75, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav: shape (63, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 75, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav: shape torch.Size([1, 104, 75])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([75, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (162, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 162, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav: shape torch.Size([1, 104, 162])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([162, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav: shape (127, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (155, 240, 320)\n",
            "Load audio session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav: shape (130, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 155, 240, 320])\n",
            "Load audio session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (136, 240, 320)\n",
            "Load audio session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav: shape (114, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 136, 240, 320])\n",
            "Load audio session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (205, 240, 320)\n",
            "Load audio session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav: shape (172, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 205, 240, 320])\n",
            "Load audio session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav: shape torch.Size([1, 104, 205])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([205, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (155, 240, 320)\n",
            "Load audio session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav: shape (130, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 155, 240, 320])\n",
            "Load audio session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (130, 240, 320)\n",
            "Load audio session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 130, 240, 320])\n",
            "Load audio session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav: shape torch.Size([1, 104, 130])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([130, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (148, 240, 320)\n",
            "Load audio session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 148, 240, 320])\n",
            "Load audio session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav: shape torch.Size([1, 104, 148])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([148, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (212, 240, 320)\n",
            "Load audio session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav: shape (177, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 212, 240, 320])\n",
            "Load audio session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav: shape torch.Size([1, 104, 212])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([212, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (138, 240, 320)\n",
            "Load audio session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav: shape (116, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 138, 240, 320])\n",
            "Load audio session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (260, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav: shape (218, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 260, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav: shape torch.Size([1, 104, 260])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([260, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (51, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav: shape (43, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 51, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav: shape torch.Size([1, 104, 51])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([51, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (76, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav: shape (64, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 76, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav: shape torch.Size([1, 104, 76])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([76, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (116, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav: shape (97, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 116, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (174, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav: shape (146, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 174, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav: shape torch.Size([1, 104, 174])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([174, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (120, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 120, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav: shape torch.Size([1, 104, 120])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([120, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (191, 240, 320)\n",
            "Load audio session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav: shape (160, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 191, 240, 320])\n",
            "Load audio session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav: shape torch.Size([1, 104, 191])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([191, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (159, 240, 320)\n",
            "Load audio session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 159, 240, 320])\n",
            "Load audio session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav: shape torch.Size([1, 104, 159])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([159, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (87, 240, 320)\n",
            "Load audio session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav: shape (73, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 87, 240, 320])\n",
            "Load audio session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (493, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav: shape (412, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 493, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav: shape torch.Size([1, 104, 493])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([493, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (114, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav: shape (96, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 114, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (133, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav: shape (112, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 133, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav: shape torch.Size([1, 104, 133])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([133, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (435, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav: shape (363, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 435, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav: shape torch.Size([1, 104, 435])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([435, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (177, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav: shape (148, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 177, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav: shape torch.Size([1, 104, 177])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([177, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (170, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav: shape (142, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 170, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav: shape torch.Size([1, 104, 170])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([170, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (106, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 106, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (137, 240, 320)\n",
            "Load audio session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav: shape (115, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 137, 240, 320])\n",
            "Load audio session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (110, 240, 320)\n",
            "Load audio session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav: shape (92, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 110, 240, 320])\n",
            "Load audio session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (59, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav: shape (50, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 59, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav: shape torch.Size([1, 104, 59])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([59, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (173, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav: shape (145, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 173, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav: shape torch.Size([1, 104, 173])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([173, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (137, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav: shape (114, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 137, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (107, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav: shape (90, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 107, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav: shape torch.Size([1, 104, 107])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([107, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (227, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav: shape (190, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 227, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav: shape torch.Size([1, 104, 227])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([227, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav: shape (127, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (74, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 74, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav: shape torch.Size([1, 104, 74])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([74, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (233, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav: shape (195, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 233, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav: shape torch.Size([1, 104, 233])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([233, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n",
            "Load video resized_video.avi: shape (89, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav: shape (75, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 89, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (110, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav: shape (93, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 110, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (84, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 84, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav: shape torch.Size([1, 104, 84])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([84, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n",
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (92, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav: shape (77, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 92, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (134, 240, 320)\n",
            "Load audio session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 134, 240, 320])\n",
            "Load audio session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav: shape torch.Size([1, 104, 134])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([134, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (60, 240, 320)\n",
            "Load audio session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav: shape (50, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 60, 240, 320])\n",
            "Load audio session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav: shape torch.Size([1, 104, 60])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([60, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (38, 240, 320)\n",
            "Load audio session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav: shape (39, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 38, 240, 320])\n",
            "Load audio session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav: shape torch.Size([1, 104, 39])\n",
            "Checkpoint: fine-tuned\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Expected size 39 but got size 38 for tensor number 1 in the list.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1b85f0e335ff>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Extract visual features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mlayer_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_visual_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m# Create a tensor for the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6693a1088c1b>\u001b[0m in \u001b[0;36mextract_visual_feature\u001b[0;34m(video_path, audio_path, ckpt_path, user_dir, is_finetune_ckpt)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlayer_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_finetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0mlayer_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_finetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/av_hubert/avhubert/hubert.py\u001b[0m in \u001b[0;36mextract_finetune\u001b[0;34m(self, source, padding_mask, mask, ret_conv, output_layer)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodality_fuse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'concat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_video\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodality_fuse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_audio\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeatures_video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 39 but got size 38 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_features"
      ],
      "metadata": {
        "id": "JwmnXEf5w3ub",
        "outputId": "bfb15596-49bb-4038-d3ae-8d3aab0c69b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.0237, -0.1337, -0.0260,  ...,  0.0476,  0.2147,  0.0000],\n",
              "         [ 0.1372, -0.0432, -0.0024,  ...,  0.2401,  0.1341,  0.0000],\n",
              "         [ 0.1313,  0.0069,  0.0210,  ...,  0.3173,  0.0016,  0.0000],\n",
              "         ...,\n",
              "         [-0.1168,  0.1427,  0.2446,  ...,  0.0558, -0.0104,  0.0000],\n",
              "         [-0.2561,  0.1333,  0.3373,  ...,  0.0529, -0.0353,  0.0000],\n",
              "         [-0.2929,  0.1004,  0.3020,  ...,  0.0544, -0.0063,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0354, -0.1537, -0.0573,  ...,  0.0593,  0.2086,  0.0000],\n",
              "         [ 0.1363, -0.1162, -0.0760,  ...,  0.2857,  0.1616,  0.0000],\n",
              "         [ 0.0801, -0.1173, -0.0804,  ...,  0.3853,  0.0899,  0.0000],\n",
              "         ...,\n",
              "         [-0.1873,  0.0221,  0.2003,  ...,  0.1090, -0.0396,  0.0000],\n",
              "         [-0.2609,  0.0400,  0.2025,  ...,  0.0870, -0.0689,  0.0000],\n",
              "         [-0.2753,  0.0167,  0.2380,  ...,  0.0235, -0.0379,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0361, -0.1555, -0.0575,  ...,  0.0632,  0.2039,  0.0000],\n",
              "         [ 0.1258, -0.1223, -0.0707,  ...,  0.2859,  0.1542,  0.0000],\n",
              "         [ 0.0615, -0.1171, -0.0765,  ...,  0.3893,  0.0800,  0.0000],\n",
              "         ...,\n",
              "         [-0.2086,  0.0352,  0.1976,  ...,  0.0907, -0.0613,  0.0000],\n",
              "         [-0.2636,  0.0546,  0.1962,  ...,  0.0774, -0.0791,  0.0000],\n",
              "         [-0.2629,  0.0250,  0.2316,  ...,  0.0215, -0.0427,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0250, -0.1242, -0.0231,  ...,  0.0393,  0.2073,  0.0000],\n",
              "         [ 0.1197, -0.0378,  0.0058,  ...,  0.2303,  0.1220,  0.0000],\n",
              "         [ 0.1140,  0.0201,  0.0285,  ...,  0.3092, -0.0142,  0.0000],\n",
              "         ...,\n",
              "         [-0.0854,  0.1339,  0.2422,  ...,  0.0512,  0.0004,  0.0000],\n",
              "         [-0.2525,  0.1309,  0.3621,  ...,  0.0451, -0.0277,  0.0000],\n",
              "         [-0.3028,  0.0978,  0.3151,  ...,  0.0418, -0.0061,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0249, -0.1241, -0.0246,  ...,  0.0384,  0.2066,  0.0000],\n",
              "         [ 0.1184, -0.0353,  0.0084,  ...,  0.2283,  0.1179,  0.0000],\n",
              "         [ 0.1160,  0.0251,  0.0300,  ...,  0.3035, -0.0184,  0.0000],\n",
              "         ...,\n",
              "         [-0.0725,  0.1360,  0.2371,  ...,  0.0460,  0.0070,  0.0000],\n",
              "         [-0.2477,  0.1296,  0.3639,  ...,  0.0405, -0.0234,  0.0000],\n",
              "         [-0.3015,  0.1007,  0.3144,  ...,  0.0364, -0.0042,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0343, -0.1485, -0.0528,  ...,  0.0635,  0.2066,  0.0000],\n",
              "         [ 0.1357, -0.1099, -0.0633,  ...,  0.2780,  0.1643,  0.0000],\n",
              "         [ 0.0723, -0.1003, -0.0633,  ...,  0.3904,  0.0785,  0.0000],\n",
              "         ...,\n",
              "         [-0.2091,  0.0298,  0.2052,  ...,  0.0818, -0.0496,  0.0000],\n",
              "         [-0.2787,  0.0671,  0.2126,  ...,  0.0758, -0.0745,  0.0000],\n",
              "         [-0.2698,  0.0397,  0.2410,  ...,  0.0246, -0.0409,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1285, -0.0322,  ...,  0.0482,  0.2176,  0.0000],\n",
              "         [ 0.1360, -0.0325, -0.0082,  ...,  0.2332,  0.1302,  0.0000],\n",
              "         [ 0.1355,  0.0295,  0.0142,  ...,  0.3111, -0.0152,  0.0000],\n",
              "         ...,\n",
              "         [-0.0516,  0.1437,  0.1949,  ...,  0.0447,  0.0201,  0.0000],\n",
              "         [-0.2334,  0.1454,  0.3280,  ...,  0.0520, -0.0163,  0.0000],\n",
              "         [-0.2830,  0.1018,  0.2986,  ...,  0.0625,  0.0019,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0291, -0.1289, -0.0283,  ...,  0.0516,  0.2128,  0.0000],\n",
              "         [ 0.1365, -0.0401, -0.0061,  ...,  0.2603,  0.1243,  0.0000],\n",
              "         [ 0.1347,  0.0190,  0.0126,  ...,  0.3394, -0.0173,  0.0000],\n",
              "         ...,\n",
              "         [-0.1019,  0.1377,  0.2476,  ...,  0.0721, -0.0202,  0.0000],\n",
              "         [-0.2522,  0.1379,  0.3437,  ...,  0.0637, -0.0398,  0.0000],\n",
              "         [-0.2918,  0.1014,  0.3074,  ...,  0.0579, -0.0040,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0200, -0.1223, -0.0361,  ...,  0.0490,  0.2147,  0.0000],\n",
              "         [ 0.1350, -0.0269, -0.0139,  ...,  0.2515,  0.1138,  0.0000],\n",
              "         [ 0.1420,  0.0441,  0.0055,  ...,  0.3255, -0.0400,  0.0000],\n",
              "         ...,\n",
              "         [-0.0417,  0.1342,  0.1924,  ...,  0.0625,  0.0089,  0.0000],\n",
              "         [-0.2297,  0.1416,  0.3322,  ...,  0.0701, -0.0144,  0.0000],\n",
              "         [-0.2769,  0.1062,  0.3001,  ...,  0.0692,  0.0090,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0328, -0.1324, -0.0324,  ...,  0.0544,  0.2087,  0.0000],\n",
              "         [ 0.1457, -0.0615, -0.0395,  ...,  0.2647,  0.1423,  0.0000],\n",
              "         [ 0.1161, -0.0391, -0.0341,  ...,  0.3546,  0.0374,  0.0000],\n",
              "         ...,\n",
              "         [-0.1300,  0.0716,  0.2228,  ...,  0.0878,  0.0144,  0.0000],\n",
              "         [-0.2499,  0.0681,  0.2849,  ...,  0.0658, -0.0316,  0.0000],\n",
              "         [-0.2984,  0.0725,  0.2800,  ...,  0.0390, -0.0179,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0247, -0.1302, -0.0321,  ...,  0.0554,  0.2143,  0.0000],\n",
              "         [ 0.1482, -0.0377, -0.0143,  ...,  0.2596,  0.1262,  0.0000],\n",
              "         [ 0.1403,  0.0220,  0.0020,  ...,  0.3467, -0.0186,  0.0000],\n",
              "         ...,\n",
              "         [-0.0890,  0.1485,  0.2224,  ...,  0.0796, -0.0016,  0.0000],\n",
              "         [-0.2486,  0.1373,  0.3217,  ...,  0.0742, -0.0273,  0.0000],\n",
              "         [-0.2854,  0.1008,  0.2906,  ...,  0.0719,  0.0030,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1551, -0.0450,  ...,  0.0541,  0.2144,  0.0000],\n",
              "         [ 0.1482, -0.0951, -0.0669,  ...,  0.2824,  0.1572,  0.0000],\n",
              "         [ 0.1025, -0.0870, -0.0704,  ...,  0.3765,  0.0618,  0.0000],\n",
              "         ...,\n",
              "         [-0.1392,  0.0171,  0.2059,  ...,  0.0984,  0.0159,  0.0000],\n",
              "         [-0.2313,  0.0260,  0.2385,  ...,  0.0787, -0.0308,  0.0000],\n",
              "         [-0.2788,  0.0229,  0.2529,  ...,  0.0349, -0.0208,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0191, -0.1301, -0.0271,  ...,  0.0477,  0.2119,  0.0000],\n",
              "         [ 0.1458, -0.0420, -0.0045,  ...,  0.2657,  0.1275,  0.0000],\n",
              "         [ 0.1434,  0.0124,  0.0079,  ...,  0.3454, -0.0004,  0.0000],\n",
              "         ...,\n",
              "         [-0.0703,  0.1238,  0.2317,  ...,  0.0889,  0.0063,  0.0000],\n",
              "         [-0.2333,  0.1247,  0.3360,  ...,  0.0794, -0.0217,  0.0000],\n",
              "         [-0.2801,  0.1019,  0.2960,  ...,  0.0567,  0.0015,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0124, -0.1247, -0.0298,  ...,  0.0475,  0.2116,  0.0000],\n",
              "         [ 0.1578, -0.0259, -0.0103,  ...,  0.2655,  0.1217,  0.0000],\n",
              "         [ 0.1608,  0.0390,  0.0044,  ...,  0.3409, -0.0192,  0.0000],\n",
              "         ...,\n",
              "         [-0.0082,  0.1203,  0.1805,  ...,  0.0807,  0.0337,  0.0000],\n",
              "         [-0.2099,  0.1247,  0.3276,  ...,  0.0835, -0.0040,  0.0000],\n",
              "         [-0.2633,  0.1077,  0.2931,  ...,  0.0621,  0.0078,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0361, -0.1473, -0.0486,  ...,  0.0626,  0.2159,  0.0000],\n",
              "         [ 0.1493, -0.0962, -0.0674,  ...,  0.2875,  0.1645,  0.0000],\n",
              "         [ 0.0968, -0.0918, -0.0690,  ...,  0.3929,  0.0744,  0.0000],\n",
              "         ...,\n",
              "         [-0.1620,  0.0216,  0.2133,  ...,  0.1032, -0.0063,  0.0000],\n",
              "         [-0.2669,  0.0427,  0.2306,  ...,  0.0807, -0.0501,  0.0000],\n",
              "         [-0.2841,  0.0342,  0.2510,  ...,  0.0284, -0.0225,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0321, -0.1531, -0.0583,  ...,  0.0585,  0.1961,  0.0000],\n",
              "         [ 0.1166, -0.1245, -0.0653,  ...,  0.2661,  0.1508,  0.0000],\n",
              "         [ 0.0532, -0.1238, -0.0739,  ...,  0.3622,  0.0891,  0.0000],\n",
              "         ...,\n",
              "         [-0.2312,  0.0484,  0.2015,  ...,  0.0557, -0.0801,  0.0000],\n",
              "         [-0.2720,  0.0626,  0.2069,  ...,  0.0516, -0.0805,  0.0000],\n",
              "         [-0.2533,  0.0353,  0.2381,  ...,  0.0038, -0.0464,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0309, -0.1529, -0.0453,  ...,  0.0562,  0.2145,  0.0000],\n",
              "         [ 0.1507, -0.0932, -0.0734,  ...,  0.2918,  0.1548,  0.0000],\n",
              "         [ 0.1074, -0.0875, -0.0804,  ...,  0.3868,  0.0594,  0.0000],\n",
              "         ...,\n",
              "         [-0.1264,  0.0165,  0.1950,  ...,  0.1084,  0.0187,  0.0000],\n",
              "         [-0.2263,  0.0164,  0.2422,  ...,  0.0827, -0.0239,  0.0000],\n",
              "         [-0.2796,  0.0258,  0.2559,  ...,  0.0380, -0.0177,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0153, -0.1276, -0.0361,  ...,  0.0534,  0.2155,  0.0000],\n",
              "         [ 0.1420, -0.0324, -0.0112,  ...,  0.2497,  0.1276,  0.0000],\n",
              "         [ 0.1437,  0.0344,  0.0084,  ...,  0.3276, -0.0213,  0.0000],\n",
              "         ...,\n",
              "         [-0.0396,  0.1462,  0.1931,  ...,  0.0566,  0.0252,  0.0000],\n",
              "         [-0.2167,  0.1338,  0.3152,  ...,  0.0667, -0.0068,  0.0000],\n",
              "         [-0.2660,  0.1076,  0.2881,  ...,  0.0682,  0.0087,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0202, -0.1632, -0.0508,  ...,  0.0656,  0.2112,  0.0000],\n",
              "         [ 0.1573, -0.1006, -0.0781,  ...,  0.2997,  0.1413,  0.0000],\n",
              "         [ 0.1198, -0.0946, -0.0895,  ...,  0.3907,  0.0476,  0.0000],\n",
              "         ...,\n",
              "         [-0.0912, -0.0010,  0.1614,  ...,  0.1093,  0.0278,  0.0000],\n",
              "         [-0.1890,  0.0061,  0.2076,  ...,  0.0856, -0.0112,  0.0000],\n",
              "         [-0.2444,  0.0065,  0.2274,  ...,  0.0531, -0.0187,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0198, -0.1207, -0.0292,  ...,  0.0363,  0.2076,  0.0000],\n",
              "         [ 0.1248, -0.0244,  0.0018,  ...,  0.2311,  0.1127,  0.0000],\n",
              "         [ 0.1241,  0.0399,  0.0227,  ...,  0.3063, -0.0306,  0.0000],\n",
              "         ...,\n",
              "         [-0.0327,  0.1374,  0.1998,  ...,  0.0444,  0.0210,  0.0000],\n",
              "         [-0.2297,  0.1315,  0.3481,  ...,  0.0471, -0.0156,  0.0000],\n",
              "         [-0.2911,  0.0998,  0.3069,  ...,  0.0435, -0.0055,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0306, -0.1226, -0.0307,  ...,  0.0555,  0.2069,  0.0000],\n",
              "         [ 0.1398, -0.0551, -0.0291,  ...,  0.2579,  0.1410,  0.0000],\n",
              "         [ 0.1216, -0.0240, -0.0148,  ...,  0.3528,  0.0223,  0.0000],\n",
              "         ...,\n",
              "         [-0.1419,  0.1178,  0.2438,  ...,  0.0909, -0.0045,  0.0000],\n",
              "         [-0.2637,  0.1051,  0.3128,  ...,  0.0709, -0.0348,  0.0000],\n",
              "         [-0.3057,  0.0878,  0.2894,  ...,  0.0424, -0.0194,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.0542e-02, -1.3064e-01, -3.2894e-02,  ...,  4.9485e-02,\n",
              "           2.1786e-01,  0.0000e+00],\n",
              "         [ 1.3816e-01, -3.8975e-02, -7.9147e-03,  ...,  2.3706e-01,\n",
              "           1.4166e-01,  0.0000e+00],\n",
              "         [ 1.3443e-01,  1.7652e-02,  1.5984e-02,  ...,  3.1943e-01,\n",
              "          -6.5525e-05,  0.0000e+00],\n",
              "         ...,\n",
              "         [-6.3779e-02,  1.4532e-01,  2.0912e-01,  ...,  6.0059e-02,\n",
              "           2.2322e-02,  0.0000e+00],\n",
              "         [-2.3852e-01,  1.3917e-01,  3.2561e-01,  ...,  5.8596e-02,\n",
              "          -1.8167e-02,  0.0000e+00],\n",
              "         [-2.8478e-01,  9.6209e-02,  2.9193e-01,  ...,  6.1186e-02,\n",
              "          -2.5306e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1263, -0.0329,  ...,  0.0494,  0.2154,  0.0000],\n",
              "         [ 0.1313, -0.0312, -0.0069,  ...,  0.2354,  0.1284,  0.0000],\n",
              "         [ 0.1333,  0.0291,  0.0164,  ...,  0.3109, -0.0212,  0.0000],\n",
              "         ...,\n",
              "         [-0.0418,  0.1381,  0.2005,  ...,  0.0448,  0.0148,  0.0000],\n",
              "         [-0.2305,  0.1431,  0.3354,  ...,  0.0559, -0.0142,  0.0000],\n",
              "         [-0.2790,  0.1052,  0.3024,  ...,  0.0632,  0.0059,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0037, -0.1102, -0.0521,  ...,  0.0341,  0.1952,  0.0000],\n",
              "         [ 0.1669, -0.0027, -0.0375,  ...,  0.2380,  0.0424,  0.0000],\n",
              "         [ 0.1723,  0.0510, -0.0344,  ...,  0.3010, -0.0933,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0642,  0.0870,  0.0605,  ...,  0.0245,  0.0434,  0.0000],\n",
              "         [-0.1615,  0.1197,  0.3084,  ...,  0.0784, -0.0198,  0.0000],\n",
              "         [-0.2613,  0.0885,  0.2943,  ...,  0.0534, -0.0070,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0020, -0.1113, -0.0548,  ...,  0.0375,  0.2088,  0.0000],\n",
              "         [ 0.1487, -0.0012, -0.0341,  ...,  0.2239,  0.0890,  0.0000],\n",
              "         [ 0.1637,  0.0585, -0.0218,  ...,  0.2979, -0.0711,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0502,  0.0987,  0.0710,  ...,  0.0267,  0.0559,  0.0000],\n",
              "         [-0.1649,  0.1369,  0.3017,  ...,  0.0711, -0.0065,  0.0000],\n",
              "         [-0.2574,  0.0966,  0.2936,  ...,  0.0604,  0.0023,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0247, -0.1354, -0.0293,  ...,  0.0497,  0.2111,  0.0000],\n",
              "         [ 0.1430, -0.0474, -0.0189,  ...,  0.2751,  0.1327,  0.0000],\n",
              "         [ 0.1270, -0.0065, -0.0014,  ...,  0.3634,  0.0128,  0.0000],\n",
              "         ...,\n",
              "         [-0.1054,  0.1112,  0.2259,  ...,  0.0882,  0.0043,  0.0000],\n",
              "         [-0.2364,  0.1037,  0.3096,  ...,  0.0749, -0.0304,  0.0000],\n",
              "         [-0.2921,  0.0810,  0.2906,  ...,  0.0578, -0.0135,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0232, -0.1365, -0.0286,  ...,  0.0509,  0.2171,  0.0000],\n",
              "         [ 0.1434, -0.0449, -0.0110,  ...,  0.2471,  0.1420,  0.0000],\n",
              "         [ 0.1339,  0.0032,  0.0142,  ...,  0.3309,  0.0056,  0.0000],\n",
              "         ...,\n",
              "         [-0.1004,  0.1433,  0.2253,  ...,  0.0586,  0.0034,  0.0000],\n",
              "         [-0.2468,  0.1328,  0.3212,  ...,  0.0596, -0.0289,  0.0000],\n",
              "         [-0.2892,  0.0932,  0.2926,  ...,  0.0602, -0.0045,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0088, -0.1126, -0.0463,  ...,  0.0345,  0.1983,  0.0000],\n",
              "         [ 0.1515, -0.0055, -0.0287,  ...,  0.2350,  0.0598,  0.0000],\n",
              "         [ 0.1580,  0.0541, -0.0215,  ...,  0.3032, -0.0802,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0481,  0.0951,  0.0814,  ...,  0.0274,  0.0440,  0.0000],\n",
              "         [-0.1751,  0.1193,  0.3160,  ...,  0.0726, -0.0149,  0.0000],\n",
              "         [-0.2659,  0.0890,  0.2987,  ...,  0.0555, -0.0053,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0326, -0.1582, -0.0613,  ...,  0.0622,  0.1995,  1.0000],\n",
              "         [ 0.1202, -0.1303, -0.0709,  ...,  0.2791,  0.1539,  1.0000],\n",
              "         [ 0.0572, -0.1284, -0.0777,  ...,  0.3761,  0.0896,  1.0000],\n",
              "         ...,\n",
              "         [-0.2129,  0.0401,  0.1906,  ...,  0.0768, -0.0767,  1.0000],\n",
              "         [-0.2602,  0.0483,  0.1909,  ...,  0.0655, -0.0805,  1.0000],\n",
              "         [-0.2536,  0.0182,  0.2288,  ...,  0.0121, -0.0477,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1222, -0.0309,  ...,  0.0557,  0.2066,  1.0000],\n",
              "         [ 0.1367, -0.0576, -0.0351,  ...,  0.2659,  0.1407,  1.0000],\n",
              "         [ 0.1179, -0.0261, -0.0231,  ...,  0.3586,  0.0273,  1.0000],\n",
              "         ...,\n",
              "         [-0.1446,  0.1066,  0.2457,  ...,  0.0940, -0.0048,  1.0000],\n",
              "         [-0.2623,  0.0915,  0.3093,  ...,  0.0744, -0.0348,  1.0000],\n",
              "         [-0.3055,  0.0851,  0.2886,  ...,  0.0390, -0.0175,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0177, -0.1275, -0.0327,  ...,  0.0530,  0.2171,  1.0000],\n",
              "         [ 0.1558, -0.0309, -0.0095,  ...,  0.2654,  0.1264,  1.0000],\n",
              "         [ 0.1533,  0.0374,  0.0122,  ...,  0.3410, -0.0198,  1.0000],\n",
              "         ...,\n",
              "         [-0.0346,  0.1376,  0.1940,  ...,  0.0646,  0.0164,  1.0000],\n",
              "         [-0.2165,  0.1374,  0.3142,  ...,  0.0691, -0.0111,  1.0000],\n",
              "         [-0.2677,  0.1062,  0.2917,  ...,  0.0732,  0.0091,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0137, -0.1219, -0.0336,  ...,  0.0489,  0.2158,  1.0000],\n",
              "         [ 0.1461, -0.0301, -0.0141,  ...,  0.2473,  0.1207,  1.0000],\n",
              "         [ 0.1419,  0.0444,  0.0055,  ...,  0.3200, -0.0318,  1.0000],\n",
              "         ...,\n",
              "         [-0.0218,  0.1426,  0.1831,  ...,  0.0522,  0.0253,  1.0000],\n",
              "         [-0.2148,  0.1392,  0.3211,  ...,  0.0653, -0.0053,  1.0000],\n",
              "         [-0.2638,  0.1097,  0.2939,  ...,  0.0720,  0.0081,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0228, -0.1267, -0.0260,  ...,  0.0398,  0.2074,  1.0000],\n",
              "         [ 0.1241, -0.0335,  0.0032,  ...,  0.2383,  0.1185,  1.0000],\n",
              "         [ 0.1213,  0.0249,  0.0245,  ...,  0.3152, -0.0155,  1.0000],\n",
              "         ...,\n",
              "         [-0.0736,  0.1328,  0.2295,  ...,  0.0573,  0.0050,  1.0000],\n",
              "         [-0.2459,  0.1266,  0.3548,  ...,  0.0500, -0.0254,  1.0000],\n",
              "         [-0.2976,  0.0972,  0.3094,  ...,  0.0425, -0.0083,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0353, -0.1380, -0.0354,  ...,  0.0509,  0.2127,  1.0000],\n",
              "         [ 0.1388, -0.0734, -0.0497,  ...,  0.2633,  0.1588,  1.0000],\n",
              "         [ 0.0975, -0.0595, -0.0464,  ...,  0.3554,  0.0602,  1.0000],\n",
              "         ...,\n",
              "         [-0.1503,  0.0607,  0.2322,  ...,  0.0962,  0.0243,  1.0000],\n",
              "         [-0.2676,  0.0566,  0.2884,  ...,  0.0714, -0.0329,  1.0000],\n",
              "         [-0.3080,  0.0577,  0.2837,  ...,  0.0309, -0.0214,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0357, -0.1312, -0.0325,  ...,  0.0616,  0.2114,  1.0000],\n",
              "         [ 0.1498, -0.0563, -0.0362,  ...,  0.2641,  0.1446,  1.0000],\n",
              "         [ 0.1192, -0.0308, -0.0194,  ...,  0.3550,  0.0385,  1.0000],\n",
              "         ...,\n",
              "         [-0.1629,  0.1013,  0.2586,  ...,  0.0801, -0.0198,  1.0000],\n",
              "         [-0.2721,  0.0827,  0.2998,  ...,  0.0710, -0.0473,  1.0000],\n",
              "         [-0.2957,  0.0840,  0.2810,  ...,  0.0433, -0.0141,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1408, -0.0383,  ...,  0.0630,  0.2154,  1.0000],\n",
              "         [ 0.1719, -0.0628, -0.0424,  ...,  0.2851,  0.1531,  1.0000],\n",
              "         [ 0.1319, -0.0451, -0.0354,  ...,  0.3762,  0.0477,  1.0000],\n",
              "         ...,\n",
              "         [-0.1304,  0.0610,  0.2152,  ...,  0.0905,  0.0011,  1.0000],\n",
              "         [-0.2435,  0.0611,  0.2590,  ...,  0.0769, -0.0385,  1.0000],\n",
              "         [-0.2806,  0.0654,  0.2649,  ...,  0.0460, -0.0114,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0011, -0.1092, -0.0453,  ...,  0.0424,  0.2054,  1.0000],\n",
              "         [ 0.1761, -0.0057, -0.0362,  ...,  0.2539,  0.0712,  1.0000],\n",
              "         [ 0.1870,  0.0583, -0.0331,  ...,  0.3124, -0.0677,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0895,  0.0901,  0.0544,  ...,  0.0536,  0.0659,  1.0000],\n",
              "         [-0.1453,  0.1245,  0.3026,  ...,  0.1113,  0.0016,  1.0000],\n",
              "         [-0.2438,  0.1066,  0.2909,  ...,  0.0677,  0.0089,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.3262e-02, -1.1815e-01, -3.3851e-02,  ...,  4.4813e-02,\n",
              "           2.0823e-01,  1.0000e+00],\n",
              "         [ 1.4425e-01, -2.0388e-02, -1.5973e-02,  ...,  2.5690e-01,\n",
              "           1.0093e-01,  1.0000e+00],\n",
              "         [ 1.5438e-01,  5.0312e-02, -2.8536e-03,  ...,  3.2606e-01,\n",
              "          -4.4117e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 2.4285e-02,  1.1882e-01,  1.4265e-01,  ...,  6.0135e-02,\n",
              "           4.1443e-02,  1.0000e+00],\n",
              "         [-1.9290e-01,  1.2555e-01,  3.2522e-01,  ...,  8.6629e-02,\n",
              "           7.0710e-04,  1.0000e+00],\n",
              "         [-2.5984e-01,  1.0930e-01,  2.9458e-01,  ...,  5.8374e-02,\n",
              "           1.0020e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0224, -0.1319, -0.0300,  ...,  0.0519,  0.2153,  1.0000],\n",
              "         [ 0.1421, -0.0398, -0.0100,  ...,  0.2521,  0.1291,  1.0000],\n",
              "         [ 0.1379,  0.0205,  0.0116,  ...,  0.3329, -0.0157,  1.0000],\n",
              "         ...,\n",
              "         [-0.0849,  0.1389,  0.2282,  ...,  0.0605, -0.0042,  1.0000],\n",
              "         [-0.2396,  0.1339,  0.3316,  ...,  0.0602, -0.0275,  1.0000],\n",
              "         [-0.2814,  0.1007,  0.2976,  ...,  0.0654,  0.0019,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0237, -0.1322, -0.0267,  ...,  0.0456,  0.2089,  1.0000],\n",
              "         [ 0.1333, -0.0495, -0.0099,  ...,  0.2577,  0.1324,  1.0000],\n",
              "         [ 0.1172, -0.0083,  0.0081,  ...,  0.3444,  0.0110,  1.0000],\n",
              "         ...,\n",
              "         [-0.1163,  0.1279,  0.2406,  ...,  0.0860, -0.0052,  1.0000],\n",
              "         [-0.2539,  0.1176,  0.3318,  ...,  0.0674, -0.0362,  1.0000],\n",
              "         [-0.3017,  0.0885,  0.2981,  ...,  0.0479, -0.0181,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0033, -0.1211, -0.0477,  ...,  0.0564,  0.2152,  1.0000],\n",
              "         [ 0.1769, -0.0101, -0.0354,  ...,  0.2632,  0.1106,  1.0000],\n",
              "         [ 0.1747,  0.0506, -0.0208,  ...,  0.3422, -0.0452,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0746,  0.1257,  0.0949,  ...,  0.0444,  0.0414,  1.0000],\n",
              "         [-0.1468,  0.1390,  0.2734,  ...,  0.0747, -0.0015,  1.0000],\n",
              "         [-0.2436,  0.1082,  0.2701,  ...,  0.0765,  0.0046,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0305, -0.1544, -0.0602,  ...,  0.0581,  0.1929,  1.0000],\n",
              "         [ 0.1155, -0.1270, -0.0675,  ...,  0.2580,  0.1505,  1.0000],\n",
              "         [ 0.0492, -0.1228, -0.0770,  ...,  0.3577,  0.0859,  1.0000],\n",
              "         ...,\n",
              "         [-0.2316,  0.0493,  0.1983,  ...,  0.0374, -0.0804,  1.0000],\n",
              "         [-0.2725,  0.0672,  0.2105,  ...,  0.0382, -0.0787,  1.0000],\n",
              "         [-0.2464,  0.0282,  0.2371,  ..., -0.0015, -0.0496,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0217, -0.1310, -0.0279,  ...,  0.0438,  0.2095,  1.0000],\n",
              "         [ 0.1380, -0.0396, -0.0033,  ...,  0.2555,  0.1277,  1.0000],\n",
              "         [ 0.1315,  0.0104,  0.0191,  ...,  0.3365, -0.0018,  1.0000],\n",
              "         ...,\n",
              "         [-0.0828,  0.1302,  0.2253,  ...,  0.0767,  0.0023,  1.0000],\n",
              "         [-0.2397,  0.1242,  0.3326,  ...,  0.0628, -0.0268,  1.0000],\n",
              "         [-0.2931,  0.0944,  0.2970,  ...,  0.0496, -0.0104,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0122, -0.1060, -0.0699,  ...,  0.0392,  0.2070,  1.0000],\n",
              "         [ 0.1633, -0.0081, -0.0524,  ...,  0.2023,  0.0947,  1.0000],\n",
              "         [ 0.1565,  0.0392, -0.0430,  ...,  0.2897, -0.0681,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0784,  0.0920,  0.0507,  ...,  0.0272,  0.0604,  1.0000],\n",
              "         [-0.1464,  0.1351,  0.2700,  ...,  0.0825, -0.0040,  1.0000],\n",
              "         [-0.2538,  0.0865,  0.2819,  ...,  0.0693, -0.0041,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2088e-02, -1.3961e-01, -2.9675e-02,  ...,  5.2898e-02,\n",
              "           2.1755e-01,  1.0000e+00],\n",
              "         [ 1.4421e-01, -4.5334e-02, -1.3991e-02,  ...,  2.4915e-01,\n",
              "           1.3811e-01,  1.0000e+00],\n",
              "         [ 1.3870e-01,  2.8501e-03,  1.0093e-02,  ...,  3.2877e-01,\n",
              "          -3.6414e-04,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.0914e-01,  1.5644e-01,  2.3228e-01,  ...,  5.3608e-02,\n",
              "           5.5486e-04,  1.0000e+00],\n",
              "         [-2.4652e-01,  1.3036e-01,  3.2304e-01,  ...,  5.5969e-02,\n",
              "          -3.0124e-02,  1.0000e+00],\n",
              "         [-2.7765e-01,  9.5361e-02,  2.8860e-01,  ...,  6.7538e-02,\n",
              "          -1.3505e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-8.4661e-03, -1.2919e-01, -3.9027e-02,  ...,  5.8417e-02,\n",
              "           2.2067e-01,  1.0000e+00],\n",
              "         [ 1.7880e-01, -1.8392e-02, -2.3510e-02,  ...,  2.7242e-01,\n",
              "           1.3005e-01,  1.0000e+00],\n",
              "         [ 1.7471e-01,  4.3337e-02, -2.9711e-04,  ...,  3.5223e-01,\n",
              "          -1.5201e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 2.4183e-02,  1.3209e-01,  1.4221e-01,  ...,  4.9197e-02,\n",
              "           1.8376e-02,  1.0000e+00],\n",
              "         [-1.6784e-01,  1.3415e-01,  2.7452e-01,  ...,  6.2237e-02,\n",
              "          -8.1488e-03,  1.0000e+00],\n",
              "         [-2.4097e-01,  1.0654e-01,  2.7321e-01,  ...,  8.1630e-02,\n",
              "           1.0257e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 4.3085e-02, -1.3929e-01, -6.9975e-02,  ...,  1.5390e-02,\n",
              "           1.6877e-01,  1.0000e+00],\n",
              "         [ 2.5271e-01, -2.7825e-02, -6.3207e-02,  ...,  1.9023e-01,\n",
              "           9.1742e-05,  1.0000e+00],\n",
              "         [ 2.5835e-01,  4.1692e-03, -5.7162e-02,  ...,  2.3771e-01,\n",
              "          -1.1812e-01,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4420e-01, -1.1500e-03, -4.6610e-02,  ...,  5.5794e-02,\n",
              "           5.4258e-02,  1.0000e+00],\n",
              "         [-7.2530e-02,  8.0088e-02,  2.5594e-01,  ...,  1.1825e-01,\n",
              "          -4.3181e-02,  1.0000e+00],\n",
              "         [-2.4358e-01,  5.4176e-02,  3.0385e-01,  ...,  7.5914e-02,\n",
              "          -2.7099e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0173, -0.1205, -0.0327,  ...,  0.0368,  0.2065,  1.0000],\n",
              "         [ 0.1285, -0.0185, -0.0048,  ...,  0.2375,  0.1042,  1.0000],\n",
              "         [ 0.1325,  0.0493,  0.0147,  ...,  0.3108, -0.0414,  1.0000],\n",
              "         ...,\n",
              "         [-0.0058,  0.1282,  0.1627,  ...,  0.0447,  0.0320,  1.0000],\n",
              "         [-0.2124,  0.1286,  0.3335,  ...,  0.0581, -0.0092,  1.0000],\n",
              "         [-0.2797,  0.0966,  0.3025,  ...,  0.0478, -0.0036,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0181, -0.1318, -0.0277,  ...,  0.0466,  0.2110,  0.0000],\n",
              "         [ 0.1485, -0.0449, -0.0043,  ...,  0.2636,  0.1281,  0.0000],\n",
              "         [ 0.1437,  0.0052,  0.0083,  ...,  0.3448,  0.0028,  0.0000],\n",
              "         ...,\n",
              "         [-0.0762,  0.1257,  0.2266,  ...,  0.0866,  0.0069,  0.0000],\n",
              "         [-0.2351,  0.1254,  0.3291,  ...,  0.0771, -0.0235,  0.0000],\n",
              "         [-0.2814,  0.1029,  0.2940,  ...,  0.0563, -0.0006,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.5086e-02, -1.3449e-01, -3.0260e-02,  ...,  5.3696e-02,\n",
              "           2.1507e-01,  2.0000e+00],\n",
              "         [ 1.5289e-01, -4.2678e-02, -1.2234e-02,  ...,  2.7263e-01,\n",
              "           1.3531e-01,  2.0000e+00],\n",
              "         [ 1.4037e-01,  1.7184e-03,  1.0744e-02,  ...,  3.5720e-01,\n",
              "           6.9345e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.2240e-01,  1.3046e-01,  2.4647e-01,  ...,  7.6501e-02,\n",
              "          -1.7960e-02,  2.0000e+00],\n",
              "         [-2.4551e-01,  1.2028e-01,  3.1522e-01,  ...,  6.9669e-02,\n",
              "          -3.8634e-02,  2.0000e+00],\n",
              "         [-2.8974e-01,  9.3302e-02,  2.9383e-01,  ...,  5.9886e-02,\n",
              "          -8.8332e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5635e-02, -1.3163e-01, -2.3491e-02,  ...,  4.3845e-02,\n",
              "           2.0827e-01,  2.0000e+00],\n",
              "         [ 1.3166e-01, -4.6823e-02, -1.6898e-03,  ...,  2.4102e-01,\n",
              "           1.3345e-01,  2.0000e+00],\n",
              "         [ 1.1691e-01, -1.6295e-03,  2.2124e-02,  ...,  3.2463e-01,\n",
              "           8.7878e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1909e-01,  1.3493e-01,  2.5349e-01,  ...,  6.4304e-02,\n",
              "           1.1643e-03,  2.0000e+00],\n",
              "         [-2.5898e-01,  1.2534e-01,  3.4155e-01,  ...,  5.5190e-02,\n",
              "          -3.1563e-02,  2.0000e+00],\n",
              "         [-3.0505e-01,  9.3072e-02,  3.0301e-01,  ...,  4.3980e-02,\n",
              "          -1.3878e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0209, -0.1228, -0.0269,  ...,  0.0369,  0.2066,  2.0000],\n",
              "         [ 0.1258, -0.0245,  0.0053,  ...,  0.2310,  0.1104,  2.0000],\n",
              "         [ 0.1247,  0.0386,  0.0244,  ...,  0.3051, -0.0284,  2.0000],\n",
              "         ...,\n",
              "         [-0.0462,  0.1365,  0.2058,  ...,  0.0445,  0.0151,  2.0000],\n",
              "         [-0.2360,  0.1300,  0.3475,  ...,  0.0447, -0.0190,  2.0000],\n",
              "         [-0.2925,  0.1008,  0.3090,  ...,  0.0410, -0.0041,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0247, -0.1312, -0.0300,  ...,  0.0509,  0.2163,  2.0000],\n",
              "         [ 0.1392, -0.0425, -0.0060,  ...,  0.2381,  0.1345,  2.0000],\n",
              "         [ 0.1279,  0.0148,  0.0153,  ...,  0.3140, -0.0095,  2.0000],\n",
              "         ...,\n",
              "         [-0.0672,  0.1616,  0.2074,  ...,  0.0398,  0.0144,  2.0000],\n",
              "         [-0.2409,  0.1459,  0.3193,  ...,  0.0482, -0.0174,  2.0000],\n",
              "         [-0.2795,  0.1079,  0.2907,  ...,  0.0633,  0.0024,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0205, -0.1245, -0.0291,  ...,  0.0465,  0.2141,  2.0000],\n",
              "         [ 0.1501, -0.0265, -0.0032,  ...,  0.2547,  0.1215,  2.0000],\n",
              "         [ 0.1481,  0.0367,  0.0206,  ...,  0.3268, -0.0215,  2.0000],\n",
              "         ...,\n",
              "         [-0.0369,  0.1383,  0.1967,  ...,  0.0522,  0.0128,  2.0000],\n",
              "         [-0.2220,  0.1441,  0.3225,  ...,  0.0545, -0.0200,  2.0000],\n",
              "         [-0.2763,  0.1058,  0.2981,  ...,  0.0590,  0.0023,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.3797e-02, -1.2016e-01, -3.5416e-02,  ...,  4.8263e-02,\n",
              "           2.1311e-01,  2.0000e+00],\n",
              "         [ 1.5868e-01, -1.6915e-02, -1.5069e-02,  ...,  2.6067e-01,\n",
              "           1.1473e-01,  2.0000e+00],\n",
              "         [ 1.6256e-01,  5.0980e-02,  7.5780e-03,  ...,  3.3115e-01,\n",
              "          -3.6620e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 6.0953e-04,  1.3095e-01,  1.6228e-01,  ...,  5.9984e-02,\n",
              "           2.5581e-02,  2.0000e+00],\n",
              "         [-2.0264e-01,  1.3979e-01,  3.1296e-01,  ...,  7.0381e-02,\n",
              "          -9.0336e-03,  2.0000e+00],\n",
              "         [-2.6286e-01,  1.0844e-01,  2.9245e-01,  ...,  6.8445e-02,\n",
              "           7.9985e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-7.9735e-03, -1.1285e-01, -4.4578e-02,  ...,  4.2524e-02,\n",
              "           2.1325e-01,  2.0000e+00],\n",
              "         [ 1.4162e-01, -1.9695e-02, -2.1904e-02,  ...,  2.1681e-01,\n",
              "           1.1504e-01,  2.0000e+00],\n",
              "         [ 1.3837e-01,  4.0215e-02, -6.2585e-03,  ...,  2.8975e-01,\n",
              "          -4.4446e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4959e-02,  1.3840e-01,  1.3266e-01,  ...,  2.0345e-02,\n",
              "           4.3889e-02,  2.0000e+00],\n",
              "         [-1.9478e-01,  1.4935e-01,  3.1308e-01,  ...,  5.5812e-02,\n",
              "           4.4131e-03,  2.0000e+00],\n",
              "         [-2.6969e-01,  1.0017e-01,  2.9795e-01,  ...,  6.3834e-02,\n",
              "          -3.6355e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0167, -0.1199, -0.0336,  ...,  0.0505,  0.2153,  2.0000],\n",
              "         [ 0.1433, -0.0264, -0.0096,  ...,  0.2398,  0.1196,  2.0000],\n",
              "         [ 0.1424,  0.0403,  0.0068,  ...,  0.3093, -0.0314,  2.0000],\n",
              "         ...,\n",
              "         [-0.0128,  0.1468,  0.1755,  ...,  0.0462,  0.0245,  2.0000],\n",
              "         [-0.2198,  0.1479,  0.3215,  ...,  0.0622, -0.0090,  2.0000],\n",
              "         [-0.2721,  0.1136,  0.2989,  ...,  0.0679,  0.0091,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0169, -0.1230, -0.0326,  ...,  0.0378,  0.2065,  2.0000],\n",
              "         [ 0.1330, -0.0177, -0.0064,  ...,  0.2382,  0.1021,  2.0000],\n",
              "         [ 0.1348,  0.0466,  0.0103,  ...,  0.3143, -0.0392,  2.0000],\n",
              "         ...,\n",
              "         [-0.0114,  0.1271,  0.1673,  ...,  0.0471,  0.0265,  2.0000],\n",
              "         [-0.2153,  0.1214,  0.3342,  ...,  0.0584, -0.0106,  2.0000],\n",
              "         [-0.2769,  0.0965,  0.3001,  ...,  0.0475, -0.0043,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.0930e-02, -1.2844e-01, -2.9158e-02,  ...,  4.8414e-02,\n",
              "           2.1772e-01,  2.0000e+00],\n",
              "         [ 1.3872e-01, -3.9547e-02, -1.3350e-03,  ...,  2.2751e-01,\n",
              "           1.3536e-01,  2.0000e+00],\n",
              "         [ 1.3083e-01,  1.9625e-02,  2.4295e-02,  ...,  3.0812e-01,\n",
              "          -1.1761e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.1379e-02,  1.5531e-01,  2.3377e-01,  ...,  3.6299e-02,\n",
              "           1.1029e-02,  2.0000e+00],\n",
              "         [-2.4063e-01,  1.3735e-01,  3.3702e-01,  ...,  4.5994e-02,\n",
              "          -1.7062e-02,  2.0000e+00],\n",
              "         [-2.8299e-01,  1.0349e-01,  2.9873e-01,  ...,  6.1494e-02,\n",
              "           2.3445e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.4223e-02, -1.3116e-01, -2.4558e-02,  ...,  4.3534e-02,\n",
              "           2.0857e-01,  2.0000e+00],\n",
              "         [ 1.2941e-01, -4.3349e-02, -1.2762e-03,  ...,  2.4837e-01,\n",
              "           1.2952e-01,  2.0000e+00],\n",
              "         [ 1.1862e-01,  5.2254e-03,  2.1685e-02,  ...,  3.3014e-01,\n",
              "           5.7044e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1547e-01,  1.3405e-01,  2.5347e-01,  ...,  7.1653e-02,\n",
              "          -5.7646e-03,  2.0000e+00],\n",
              "         [-2.5666e-01,  1.2104e-01,  3.4493e-01,  ...,  6.0746e-02,\n",
              "          -3.2359e-02,  2.0000e+00],\n",
              "         [-3.0159e-01,  9.3421e-02,  3.0522e-01,  ...,  4.7145e-02,\n",
              "          -1.2352e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.9652e-02, -1.2333e-01, -3.0581e-02,  ...,  3.8117e-02,\n",
              "           2.0610e-01,  2.0000e+00],\n",
              "         [ 1.2736e-01, -2.1686e-02, -1.0798e-03,  ...,  2.3913e-01,\n",
              "           1.0617e-01,  2.0000e+00],\n",
              "         [ 1.2626e-01,  4.2886e-02,  1.6070e-02,  ...,  3.1456e-01,\n",
              "          -3.4864e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.4095e-02,  1.3235e-01,  1.8088e-01,  ...,  5.1248e-02,\n",
              "           1.9495e-02,  2.0000e+00],\n",
              "         [-2.2351e-01,  1.2640e-01,  3.3717e-01,  ...,  5.2281e-02,\n",
              "          -1.5423e-02,  2.0000e+00],\n",
              "         [-2.8424e-01,  9.7859e-02,  3.0399e-01,  ...,  4.1581e-02,\n",
              "          -4.8548e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0276, -0.1540, -0.0451,  ...,  0.0576,  0.2099,  2.0000],\n",
              "         [ 0.1509, -0.0910, -0.0679,  ...,  0.2852,  0.1412,  2.0000],\n",
              "         [ 0.1151, -0.0803, -0.0781,  ...,  0.3718,  0.0461,  2.0000],\n",
              "         ...,\n",
              "         [-0.1130,  0.0157,  0.1773,  ...,  0.0959,  0.0256,  2.0000],\n",
              "         [-0.2127,  0.0161,  0.2316,  ...,  0.0726, -0.0162,  2.0000],\n",
              "         [-0.2676,  0.0265,  0.2463,  ...,  0.0416, -0.0189,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-9.4262e-03, -1.1513e-01, -3.6138e-02,  ...,  4.2046e-02,\n",
              "           2.0671e-01,  2.0000e+00],\n",
              "         [ 1.5568e-01, -8.0163e-03, -1.8442e-02,  ...,  2.4968e-01,\n",
              "           8.6938e-02,  2.0000e+00],\n",
              "         [ 1.7083e-01,  6.0994e-02, -1.1455e-02,  ...,  3.1126e-01,\n",
              "          -6.0813e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 4.8484e-02,  1.1477e-01,  1.0883e-01,  ...,  4.5905e-02,\n",
              "           5.1428e-02,  2.0000e+00],\n",
              "         [-1.7460e-01,  1.2905e-01,  3.1988e-01,  ...,  8.8291e-02,\n",
              "          -9.3299e-04,  2.0000e+00],\n",
              "         [-2.5373e-01,  1.0863e-01,  2.9499e-01,  ...,  5.6250e-02,\n",
              "           6.4060e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.6194e-02, -1.1701e-01, -3.3029e-02,  ...,  4.2723e-02,\n",
              "           2.0949e-01,  2.0000e+00],\n",
              "         [ 1.3676e-01, -1.8800e-02, -1.2942e-02,  ...,  2.5243e-01,\n",
              "           1.0177e-01,  2.0000e+00],\n",
              "         [ 1.4855e-01,  5.1985e-02, -1.6112e-04,  ...,  3.2149e-01,\n",
              "          -4.4691e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 3.9199e-03,  1.2074e-01,  1.5953e-01,  ...,  5.7587e-02,\n",
              "           3.4109e-02,  2.0000e+00],\n",
              "         [-2.0438e-01,  1.2526e-01,  3.3438e-01,  ...,  7.8237e-02,\n",
              "          -7.8774e-04,  2.0000e+00],\n",
              "         [-2.6628e-01,  1.0636e-01,  2.9727e-01,  ...,  5.6360e-02,\n",
              "           1.0942e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5308e-02, -1.2975e-01, -2.3012e-02,  ...,  4.2080e-02,\n",
              "           2.0778e-01,  2.0000e+00],\n",
              "         [ 1.2591e-01, -4.5399e-02,  2.6206e-03,  ...,  2.4024e-01,\n",
              "           1.2753e-01,  2.0000e+00],\n",
              "         [ 1.1656e-01,  5.5530e-03,  2.4635e-02,  ...,  3.2155e-01,\n",
              "          -4.0071e-04,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0345e-01,  1.3599e-01,  2.5156e-01,  ...,  6.5069e-02,\n",
              "           5.8878e-04,  2.0000e+00],\n",
              "         [-2.5564e-01,  1.2747e-01,  3.5412e-01,  ...,  5.5925e-02,\n",
              "          -2.6403e-02,  2.0000e+00],\n",
              "         [-3.0359e-01,  9.8206e-02,  3.0831e-01,  ...,  4.3604e-02,\n",
              "          -9.3119e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0213, -0.1241, -0.0330,  ...,  0.0447,  0.2148,  2.0000],\n",
              "         [ 0.1306, -0.0349, -0.0117,  ...,  0.2292,  0.1245,  2.0000],\n",
              "         [ 0.1298,  0.0289,  0.0089,  ...,  0.3060, -0.0313,  2.0000],\n",
              "         ...,\n",
              "         [-0.0405,  0.1459,  0.1929,  ...,  0.0351,  0.0188,  2.0000],\n",
              "         [-0.2313,  0.1454,  0.3298,  ...,  0.0483, -0.0122,  2.0000],\n",
              "         [-0.2839,  0.1083,  0.3004,  ...,  0.0582,  0.0037,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4271e-02, -1.3404e-01, -3.0652e-02,  ...,  5.5746e-02,\n",
              "           2.1675e-01,  2.0000e+00],\n",
              "         [ 1.5485e-01, -3.7665e-02, -1.1799e-02,  ...,  2.6708e-01,\n",
              "           1.3584e-01,  2.0000e+00],\n",
              "         [ 1.4795e-01,  1.6902e-02,  1.1779e-02,  ...,  3.5180e-01,\n",
              "          -1.1204e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-7.7883e-02,  1.3646e-01,  2.2015e-01,  ...,  6.6412e-02,\n",
              "           3.9791e-03,  2.0000e+00],\n",
              "         [-2.3109e-01,  1.2978e-01,  3.1052e-01,  ...,  6.8364e-02,\n",
              "          -2.4345e-02,  2.0000e+00],\n",
              "         [-2.7796e-01,  9.7977e-02,  2.8788e-01,  ...,  6.8832e-02,\n",
              "           3.2928e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0251, -0.1335, -0.0262,  ...,  0.0478,  0.2095,  2.0000],\n",
              "         [ 0.1373, -0.0461, -0.0128,  ...,  0.2627,  0.1345,  2.0000],\n",
              "         [ 0.1217, -0.0061,  0.0054,  ...,  0.3484,  0.0149,  2.0000],\n",
              "         ...,\n",
              "         [-0.1293,  0.1244,  0.2468,  ...,  0.0830, -0.0073,  2.0000],\n",
              "         [-0.2553,  0.1087,  0.3247,  ...,  0.0679, -0.0348,  2.0000],\n",
              "         [-0.3022,  0.0882,  0.2983,  ...,  0.0508, -0.0150,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 1.0437e-03, -1.1255e-01, -5.1275e-02,  ...,  4.9589e-02,\n",
              "           2.1487e-01,  2.0000e+00],\n",
              "         [ 1.6975e-01,  4.8154e-03, -3.6161e-02,  ...,  2.4463e-01,\n",
              "           1.0965e-01,  2.0000e+00],\n",
              "         [ 1.7430e-01,  6.4587e-02, -1.5531e-02,  ...,  3.2472e-01,\n",
              "          -4.8860e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 8.7188e-02,  1.1455e-01,  7.8357e-02,  ...,  4.1148e-02,\n",
              "           5.2270e-02,  2.0000e+00],\n",
              "         [-1.3412e-01,  1.4246e-01,  2.7243e-01,  ...,  7.1054e-02,\n",
              "           9.9147e-05,  2.0000e+00],\n",
              "         [-2.3606e-01,  1.1012e-01,  2.7517e-01,  ...,  7.3812e-02,\n",
              "           4.3841e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0367, -0.1585, -0.0588,  ...,  0.0616,  0.2068,  2.0000],\n",
              "         [ 0.1312, -0.1252, -0.0768,  ...,  0.2977,  0.1532,  2.0000],\n",
              "         [ 0.0720, -0.1230, -0.0835,  ...,  0.3941,  0.0815,  2.0000],\n",
              "         ...,\n",
              "         [-0.1832,  0.0179,  0.1901,  ...,  0.1035, -0.0444,  2.0000],\n",
              "         [-0.2387,  0.0344,  0.1920,  ...,  0.0893, -0.0695,  2.0000],\n",
              "         [-0.2627,  0.0043,  0.2284,  ...,  0.0295, -0.0381,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0226, -0.1272, -0.0265,  ...,  0.0441,  0.2121,  2.0000],\n",
              "         [ 0.1280, -0.0331,  0.0049,  ...,  0.2305,  0.1220,  2.0000],\n",
              "         [ 0.1293,  0.0208,  0.0311,  ...,  0.3016, -0.0170,  2.0000],\n",
              "         ...,\n",
              "         [-0.0617,  0.1437,  0.2248,  ...,  0.0379,  0.0072,  2.0000],\n",
              "         [-0.2395,  0.1405,  0.3516,  ...,  0.0421, -0.0221,  2.0000],\n",
              "         [-0.2928,  0.1035,  0.3088,  ...,  0.0450, -0.0031,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0234, -0.1052, -0.0808,  ...,  0.0393,  0.2043,  2.0000],\n",
              "         [ 0.1702, -0.0184, -0.0657,  ...,  0.2051,  0.0915,  2.0000],\n",
              "         [ 0.1604,  0.0336, -0.0544,  ...,  0.2928, -0.0750,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0910,  0.0911,  0.0432,  ...,  0.0393,  0.0705,  2.0000],\n",
              "         [-0.1314,  0.1354,  0.2537,  ...,  0.0960, -0.0045,  2.0000],\n",
              "         [-0.2422,  0.0752,  0.2790,  ...,  0.0804, -0.0061,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0152, -0.1189, -0.0376,  ...,  0.0368,  0.2017,  2.0000],\n",
              "         [ 0.1375, -0.0107, -0.0150,  ...,  0.2385,  0.0852,  2.0000],\n",
              "         [ 0.1391,  0.0536, -0.0024,  ...,  0.3118, -0.0559,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0127,  0.1280,  0.1395,  ...,  0.0383,  0.0258,  2.0000],\n",
              "         [-0.2031,  0.1214,  0.3264,  ...,  0.0604, -0.0159,  2.0000],\n",
              "         [-0.2706,  0.0921,  0.2989,  ...,  0.0470, -0.0078,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0070, -0.1086, -0.0649,  ...,  0.0216,  0.1958,  2.0000],\n",
              "         [ 0.1717, -0.0076, -0.0419,  ...,  0.2160,  0.0409,  2.0000],\n",
              "         [ 0.1748,  0.0452, -0.0414,  ...,  0.2806, -0.0999,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0743,  0.0569,  0.0337,  ...,  0.0190,  0.0772,  2.0000],\n",
              "         [-0.1405,  0.1195,  0.3078,  ...,  0.0711, -0.0075,  2.0000],\n",
              "         [-0.2632,  0.0847,  0.2979,  ...,  0.0588, -0.0080,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0242, -0.1333, -0.0258,  ...,  0.0460,  0.2114,  2.0000],\n",
              "         [ 0.1370, -0.0456, -0.0093,  ...,  0.2560,  0.1355,  2.0000],\n",
              "         [ 0.1211, -0.0027,  0.0117,  ...,  0.3399,  0.0156,  2.0000],\n",
              "         ...,\n",
              "         [-0.1101,  0.1279,  0.2357,  ...,  0.0696,  0.0031,  2.0000],\n",
              "         [-0.2506,  0.1146,  0.3240,  ...,  0.0588, -0.0272,  2.0000],\n",
              "         [-0.3002,  0.0884,  0.2954,  ...,  0.0496, -0.0133,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0171, -0.1227, -0.0369,  ...,  0.0498,  0.2148,  2.0000],\n",
              "         [ 0.1448, -0.0251, -0.0144,  ...,  0.2351,  0.1248,  2.0000],\n",
              "         [ 0.1351,  0.0338,  0.0079,  ...,  0.3112, -0.0244,  2.0000],\n",
              "         ...,\n",
              "         [-0.0040,  0.1445,  0.1584,  ...,  0.0360,  0.0357,  2.0000],\n",
              "         [-0.2037,  0.1439,  0.3124,  ...,  0.0583, -0.0026,  2.0000],\n",
              "         [-0.2628,  0.1110,  0.2871,  ...,  0.0665,  0.0056,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0191, -0.1323, -0.0317,  ...,  0.0444,  0.2100,  2.0000],\n",
              "         [ 0.1465, -0.0318, -0.0098,  ...,  0.2639,  0.1237,  2.0000],\n",
              "         [ 0.1435,  0.0218,  0.0101,  ...,  0.3442, -0.0102,  2.0000],\n",
              "         ...,\n",
              "         [-0.0477,  0.1265,  0.1908,  ...,  0.0829,  0.0163,  2.0000],\n",
              "         [-0.2219,  0.1190,  0.3159,  ...,  0.0717, -0.0186,  2.0000],\n",
              "         [-0.2798,  0.0921,  0.2893,  ...,  0.0571, -0.0092,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0300, -0.1562, -0.0480,  ...,  0.0555,  0.2128,  2.0000],\n",
              "         [ 0.1482, -0.0973, -0.0748,  ...,  0.2859,  0.1526,  2.0000],\n",
              "         [ 0.1061, -0.0912, -0.0827,  ...,  0.3795,  0.0571,  2.0000],\n",
              "         ...,\n",
              "         [-0.1236,  0.0095,  0.1847,  ...,  0.1068,  0.0234,  2.0000],\n",
              "         [-0.2237,  0.0123,  0.2346,  ...,  0.0789, -0.0224,  2.0000],\n",
              "         [-0.2758,  0.0213,  0.2499,  ...,  0.0369, -0.0185,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0022, -0.1233, -0.0498,  ...,  0.0558,  0.2153,  2.0000],\n",
              "         [ 0.1602, -0.0253, -0.0347,  ...,  0.2327,  0.1212,  2.0000],\n",
              "         [ 0.1522,  0.0314, -0.0132,  ...,  0.3194, -0.0362,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0483,  0.1110,  0.0890,  ...,  0.0431,  0.0647,  2.0000],\n",
              "         [-0.1576,  0.1278,  0.2668,  ...,  0.0701,  0.0107,  2.0000],\n",
              "         [-0.2480,  0.1005,  0.2662,  ...,  0.0738,  0.0063,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0414, -0.1519, -0.0875,  ...,  0.0275,  0.1978,  2.0000],\n",
              "         [ 0.2537, -0.0520, -0.0896,  ...,  0.1934,  0.0316,  2.0000],\n",
              "         [ 0.2416, -0.0105, -0.0818,  ...,  0.2535, -0.1026,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1954, -0.0208, -0.0394,  ...,  0.0500,  0.0328,  2.0000],\n",
              "         [-0.0299,  0.0462,  0.2090,  ...,  0.1033, -0.0431,  2.0000],\n",
              "         [-0.2318,  0.0367,  0.2837,  ...,  0.0798, -0.0204,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.0927e-03, -1.1004e-01, -4.6651e-02,  ...,  4.0331e-02,\n",
              "           2.0486e-01,  3.0000e+00],\n",
              "         [ 1.6821e-01, -4.9000e-03, -3.3103e-02,  ...,  2.5185e-01,\n",
              "           6.7321e-02,  3.0000e+00],\n",
              "         [ 1.8028e-01,  5.5705e-02, -2.8895e-02,  ...,  3.0979e-01,\n",
              "          -7.1985e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 8.9481e-02,  8.1970e-02,  4.6947e-02,  ...,  4.3503e-02,\n",
              "           6.5127e-02,  3.0000e+00],\n",
              "         [-1.4431e-01,  1.2616e-01,  3.0579e-01,  ...,  9.7263e-02,\n",
              "           7.3646e-04,  3.0000e+00],\n",
              "         [-2.4929e-01,  1.0779e-01,  2.9013e-01,  ...,  6.3018e-02,\n",
              "           8.1485e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-8.1504e-03, -1.1439e-01, -3.8759e-02,  ...,  4.1602e-02,\n",
              "           2.0823e-01,  2.0000e+00],\n",
              "         [ 1.5362e-01, -1.0182e-02, -2.1244e-02,  ...,  2.4510e-01,\n",
              "           8.9432e-02,  2.0000e+00],\n",
              "         [ 1.6762e-01,  5.7939e-02, -1.3737e-02,  ...,  3.1199e-01,\n",
              "          -5.9535e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 4.5512e-02,  1.1014e-01,  1.0622e-01,  ...,  4.2231e-02,\n",
              "           5.4060e-02,  2.0000e+00],\n",
              "         [-1.7896e-01,  1.2461e-01,  3.1835e-01,  ...,  8.5544e-02,\n",
              "           1.8733e-03,  2.0000e+00],\n",
              "         [-2.5501e-01,  1.0917e-01,  2.9149e-01,  ...,  5.7722e-02,\n",
              "           7.8117e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0131, -0.1244, -0.0297,  ...,  0.0444,  0.2104,  2.0000],\n",
              "         [ 0.1527, -0.0252, -0.0060,  ...,  0.2632,  0.1173,  2.0000],\n",
              "         [ 0.1576,  0.0388,  0.0076,  ...,  0.3346, -0.0208,  2.0000],\n",
              "         ...,\n",
              "         [-0.0080,  0.1250,  0.1792,  ...,  0.0788,  0.0286,  2.0000],\n",
              "         [-0.2110,  0.1309,  0.3296,  ...,  0.0792, -0.0076,  2.0000],\n",
              "         [-0.2676,  0.1080,  0.2977,  ...,  0.0577,  0.0042,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1957e-02, -1.2129e-01, -3.0159e-02,  ...,  4.2738e-02,\n",
              "           2.1124e-01,  1.0000e+00],\n",
              "         [ 1.5203e-01, -2.1684e-02, -8.5178e-03,  ...,  2.5829e-01,\n",
              "           1.1466e-01,  1.0000e+00],\n",
              "         [ 1.5935e-01,  5.0240e-02,  8.0978e-03,  ...,  3.2774e-01,\n",
              "          -2.9703e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 1.6962e-02,  1.2065e-01,  1.5807e-01,  ...,  6.2185e-02,\n",
              "           3.9500e-02,  1.0000e+00],\n",
              "         [-1.9768e-01,  1.2540e-01,  3.2775e-01,  ...,  7.9300e-02,\n",
              "          -2.3081e-04,  1.0000e+00],\n",
              "         [-2.6102e-01,  1.0925e-01,  2.9696e-01,  ...,  5.8657e-02,\n",
              "           8.6142e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0242, -0.1291, -0.0249,  ...,  0.0434,  0.2080,  1.0000],\n",
              "         [ 0.1255, -0.0453,  0.0014,  ...,  0.2394,  0.1285,  1.0000],\n",
              "         [ 0.1167,  0.0053,  0.0228,  ...,  0.3221, -0.0030,  1.0000],\n",
              "         ...,\n",
              "         [-0.1034,  0.1364,  0.2516,  ...,  0.0687,  0.0011,  1.0000],\n",
              "         [-0.2558,  0.1278,  0.3543,  ...,  0.0564, -0.0280,  1.0000],\n",
              "         [-0.3036,  0.0972,  0.3079,  ...,  0.0429, -0.0110,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0305, -0.1566, -0.0394,  ...,  0.0599,  0.2150,  1.0000],\n",
              "         [ 0.1673, -0.0860, -0.0494,  ...,  0.2919,  0.1549,  1.0000],\n",
              "         [ 0.1254, -0.0736, -0.0472,  ...,  0.3835,  0.0572,  1.0000],\n",
              "         ...,\n",
              "         [-0.1274,  0.0318,  0.2137,  ...,  0.0899,  0.0057,  1.0000],\n",
              "         [-0.2294,  0.0350,  0.2467,  ...,  0.0765, -0.0320,  1.0000],\n",
              "         [-0.2721,  0.0451,  0.2573,  ...,  0.0439, -0.0138,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0187, -0.1315, -0.0322,  ...,  0.0545,  0.2169,  1.0000],\n",
              "         [ 0.1622, -0.0364, -0.0163,  ...,  0.2750,  0.1325,  1.0000],\n",
              "         [ 0.1558,  0.0244,  0.0046,  ...,  0.3626, -0.0117,  1.0000],\n",
              "         ...,\n",
              "         [-0.0615,  0.1324,  0.2068,  ...,  0.0769,  0.0036,  1.0000],\n",
              "         [-0.2202,  0.1302,  0.3062,  ...,  0.0755, -0.0232,  1.0000],\n",
              "         [-0.2706,  0.1000,  0.2875,  ...,  0.0727,  0.0023,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0241, -0.1321, -0.0268,  ...,  0.0449,  0.2097,  1.0000],\n",
              "         [ 0.1337, -0.0476, -0.0089,  ...,  0.2563,  0.1325,  1.0000],\n",
              "         [ 0.1184, -0.0070,  0.0092,  ...,  0.3420,  0.0112,  1.0000],\n",
              "         ...,\n",
              "         [-0.1169,  0.1276,  0.2407,  ...,  0.0839, -0.0029,  1.0000],\n",
              "         [-0.2529,  0.1164,  0.3302,  ...,  0.0649, -0.0332,  1.0000],\n",
              "         [-0.3012,  0.0886,  0.2986,  ...,  0.0477, -0.0167,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0237, -0.1380, -0.0285,  ...,  0.0540,  0.2157,  1.0000],\n",
              "         [ 0.1516, -0.0465, -0.0099,  ...,  0.2576,  0.1387,  1.0000],\n",
              "         [ 0.1364, -0.0012,  0.0135,  ...,  0.3392,  0.0102,  1.0000],\n",
              "         ...,\n",
              "         [-0.1190,  0.1420,  0.2297,  ...,  0.0608, -0.0110,  1.0000],\n",
              "         [-0.2500,  0.1215,  0.3104,  ...,  0.0589, -0.0363,  1.0000],\n",
              "         [-0.2840,  0.0969,  0.2873,  ...,  0.0620, -0.0075,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0201, -0.1275, -0.0279,  ...,  0.0397,  0.2064,  1.0000],\n",
              "         [ 0.1322, -0.0333, -0.0013,  ...,  0.2441,  0.1174,  1.0000],\n",
              "         [ 0.1266,  0.0254,  0.0185,  ...,  0.3250, -0.0171,  1.0000],\n",
              "         ...,\n",
              "         [-0.0567,  0.1315,  0.2083,  ...,  0.0705,  0.0124,  1.0000],\n",
              "         [-0.2351,  0.1251,  0.3405,  ...,  0.0617, -0.0198,  1.0000],\n",
              "         [-0.2894,  0.0976,  0.3030,  ...,  0.0451, -0.0090,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0317, -0.1543, -0.0619,  ...,  0.0683,  0.2048,  1.0000],\n",
              "         [ 0.1537, -0.1161, -0.0619,  ...,  0.2951,  0.1677,  1.0000],\n",
              "         [ 0.0881, -0.1060, -0.0619,  ...,  0.4114,  0.0835,  1.0000],\n",
              "         ...,\n",
              "         [-0.1913,  0.0401,  0.1863,  ...,  0.0898, -0.0565,  1.0000],\n",
              "         [-0.2518,  0.0642,  0.1947,  ...,  0.0779, -0.0665,  1.0000],\n",
              "         [-0.2453,  0.0361,  0.2260,  ...,  0.0243, -0.0356,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0248, -0.1577, -0.0635,  ...,  0.0535,  0.1851,  1.0000],\n",
              "         [ 0.1082, -0.1339, -0.0629,  ...,  0.2433,  0.1504,  1.0000],\n",
              "         [ 0.0413, -0.1344, -0.0802,  ...,  0.3379,  0.0916,  1.0000],\n",
              "         ...,\n",
              "         [-0.2244,  0.0482,  0.2032,  ..., -0.0081, -0.0892,  1.0000],\n",
              "         [-0.2622,  0.0632,  0.2083,  ...,  0.0031, -0.0840,  1.0000],\n",
              "         [-0.2249,  0.0372,  0.2347,  ..., -0.0262, -0.0544,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0153, -0.1184, -0.0391,  ...,  0.0501,  0.2126,  1.0000],\n",
              "         [ 0.1525, -0.0073, -0.0153,  ...,  0.2561,  0.1064,  1.0000],\n",
              "         [ 0.1582,  0.0613,  0.0038,  ...,  0.3272, -0.0486,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0014,  0.1300,  0.1626,  ...,  0.0507,  0.0173,  1.0000],\n",
              "         [-0.1982,  0.1391,  0.3184,  ...,  0.0660, -0.0107,  1.0000],\n",
              "         [-0.2610,  0.1086,  0.2949,  ...,  0.0698,  0.0073,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.6433e-04, -1.1041e-01, -4.3400e-02,  ...,  4.1458e-02,\n",
              "           2.0604e-01,  1.0000e+00],\n",
              "         [ 1.7342e-01, -3.7893e-03, -3.1296e-02,  ...,  2.5113e-01,\n",
              "           7.8199e-02,  1.0000e+00],\n",
              "         [ 1.8435e-01,  6.0367e-02, -2.6252e-02,  ...,  3.1197e-01,\n",
              "          -6.5265e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 8.7696e-02,  8.9452e-02,  5.6419e-02,  ...,  4.6256e-02,\n",
              "           6.6938e-02,  1.0000e+00],\n",
              "         [-1.4948e-01,  1.2462e-01,  3.0494e-01,  ...,  1.0082e-01,\n",
              "           3.0720e-03,  1.0000e+00],\n",
              "         [-2.4475e-01,  1.0899e-01,  2.8915e-01,  ...,  6.3175e-02,\n",
              "           7.3012e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0086, -0.1178, -0.0368,  ...,  0.0457,  0.2085,  1.0000],\n",
              "         [ 0.1571, -0.0141, -0.0217,  ...,  0.2572,  0.1017,  1.0000],\n",
              "         [ 0.1654,  0.0553, -0.0109,  ...,  0.3307, -0.0433,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0320,  0.1196,  0.1339,  ...,  0.0662,  0.0433,  1.0000],\n",
              "         [-0.1896,  0.1208,  0.3189,  ...,  0.0903, -0.0020,  1.0000],\n",
              "         [-0.2548,  0.1079,  0.2879,  ...,  0.0613,  0.0061,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0168, -0.1381, -0.0250,  ...,  0.0546,  0.2138,  1.0000],\n",
              "         [ 0.1549, -0.0597, -0.0155,  ...,  0.2498,  0.1579,  1.0000],\n",
              "         [ 0.1225, -0.0347,  0.0023,  ...,  0.3408,  0.0524,  1.0000],\n",
              "         ...,\n",
              "         [-0.0784,  0.1062,  0.2214,  ...,  0.0968,  0.0397,  1.0000],\n",
              "         [-0.2360,  0.1041,  0.3243,  ...,  0.1053,  0.0043,  1.0000],\n",
              "         [-0.3104,  0.0831,  0.2948,  ...,  0.0743, -0.0033,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0321, -0.1468, -0.0400,  ...,  0.0622,  0.2172,  1.0000],\n",
              "         [ 0.1739, -0.0735, -0.0581,  ...,  0.2955,  0.1548,  1.0000],\n",
              "         [ 0.1321, -0.0630, -0.0538,  ...,  0.3917,  0.0538,  1.0000],\n",
              "         ...,\n",
              "         [-0.1110,  0.0437,  0.1943,  ...,  0.0976,  0.0141,  1.0000],\n",
              "         [-0.2344,  0.0470,  0.2527,  ...,  0.0790, -0.0325,  1.0000],\n",
              "         [-0.2826,  0.0564,  0.2629,  ...,  0.0449, -0.0122,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9687e-02, -1.2634e-01, -2.7777e-02,  ...,  3.9950e-02,\n",
              "           2.0780e-01,  1.0000e+00],\n",
              "         [ 1.3208e-01, -3.1068e-02,  4.3082e-04,  ...,  2.4519e-01,\n",
              "           1.1897e-01,  1.0000e+00],\n",
              "         [ 1.2775e-01,  2.9660e-02,  2.2497e-02,  ...,  3.2357e-01,\n",
              "          -1.9003e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-4.0919e-02,  1.3258e-01,  1.9831e-01,  ...,  6.3558e-02,\n",
              "           1.8096e-02,  1.0000e+00],\n",
              "         [-2.3190e-01,  1.3066e-01,  3.3888e-01,  ...,  5.7592e-02,\n",
              "          -1.5127e-02,  1.0000e+00],\n",
              "         [-2.8986e-01,  9.9407e-02,  3.0165e-01,  ...,  4.7016e-02,\n",
              "          -8.3321e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0230, -0.1283, -0.0251,  ...,  0.0410,  0.2074,  1.0000],\n",
              "         [ 0.1289, -0.0417,  0.0045,  ...,  0.2365,  0.1234,  1.0000],\n",
              "         [ 0.1196,  0.0106,  0.0272,  ...,  0.3162, -0.0058,  1.0000],\n",
              "         ...,\n",
              "         [-0.0978,  0.1400,  0.2423,  ...,  0.0631,  0.0045,  1.0000],\n",
              "         [-0.2518,  0.1344,  0.3476,  ...,  0.0536, -0.0284,  1.0000],\n",
              "         [-0.3006,  0.1001,  0.3062,  ...,  0.0434, -0.0102,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0180, -0.1408, -0.0340,  ...,  0.0518,  0.2161,  1.0000],\n",
              "         [ 0.1497, -0.0443, -0.0124,  ...,  0.2519,  0.1387,  1.0000],\n",
              "         [ 0.1398,  0.0030,  0.0110,  ...,  0.3329,  0.0038,  1.0000],\n",
              "         ...,\n",
              "         [-0.0490,  0.1419,  0.1787,  ...,  0.0473,  0.0315,  1.0000],\n",
              "         [-0.2136,  0.1271,  0.2911,  ...,  0.0572, -0.0090,  1.0000],\n",
              "         [-0.2731,  0.0974,  0.2738,  ...,  0.0657, -0.0034,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0197, -0.1302, -0.0275,  ...,  0.0440,  0.2101,  1.0000],\n",
              "         [ 0.1385, -0.0351, -0.0042,  ...,  0.2534,  0.1273,  1.0000],\n",
              "         [ 0.1355,  0.0203,  0.0172,  ...,  0.3332, -0.0058,  1.0000],\n",
              "         ...,\n",
              "         [-0.0629,  0.1323,  0.2200,  ...,  0.0767,  0.0124,  1.0000],\n",
              "         [-0.2347,  0.1227,  0.3385,  ...,  0.0681, -0.0176,  1.0000],\n",
              "         [-0.2881,  0.0939,  0.2994,  ...,  0.0546, -0.0082,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 3.1198e-02, -1.2628e-01, -8.5836e-02,  ...,  3.7206e-02,\n",
              "           2.0670e-01,  1.0000e+00],\n",
              "         [ 2.2862e-01,  3.3384e-03, -7.0829e-02,  ...,  2.4482e-01,\n",
              "           6.0517e-02,  1.0000e+00],\n",
              "         [ 2.1550e-01,  3.5638e-02, -6.1865e-02,  ...,  3.2317e-01,\n",
              "          -7.5345e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 2.0032e-01,  1.7645e-02, -4.9614e-02,  ...,  5.8436e-02,\n",
              "           8.6401e-02,  1.0000e+00],\n",
              "         [-4.1354e-02,  9.2401e-02,  2.2400e-01,  ...,  1.0432e-01,\n",
              "           5.9990e-03,  1.0000e+00],\n",
              "         [-2.2762e-01,  7.8340e-02,  2.7112e-01,  ...,  7.9205e-02,\n",
              "          -7.9715e-05,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0140, -0.1212, -0.0353,  ...,  0.0480,  0.2185,  1.0000],\n",
              "         [ 0.1475, -0.0240, -0.0134,  ...,  0.2459,  0.1203,  1.0000],\n",
              "         [ 0.1477,  0.0414,  0.0075,  ...,  0.3205, -0.0328,  1.0000],\n",
              "         ...,\n",
              "         [-0.0012,  0.1390,  0.1626,  ...,  0.0508,  0.0309,  1.0000],\n",
              "         [-0.2088,  0.1455,  0.3154,  ...,  0.0677, -0.0093,  1.0000],\n",
              "         [-0.2662,  0.1086,  0.2949,  ...,  0.0712,  0.0048,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0198, -0.1221, -0.0313,  ...,  0.0380,  0.2067,  1.0000],\n",
              "         [ 0.1260, -0.0182, -0.0030,  ...,  0.2361,  0.1047,  1.0000],\n",
              "         [ 0.1287,  0.0488,  0.0164,  ...,  0.3095, -0.0374,  1.0000],\n",
              "         ...,\n",
              "         [-0.0166,  0.1274,  0.1744,  ...,  0.0401,  0.0250,  1.0000],\n",
              "         [-0.2210,  0.1232,  0.3391,  ...,  0.0492, -0.0126,  1.0000],\n",
              "         [-0.2816,  0.0960,  0.3045,  ...,  0.0436, -0.0023,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0254, -0.1477, -0.0439,  ...,  0.0674,  0.2134,  1.0000],\n",
              "         [ 0.1895, -0.0709, -0.0559,  ...,  0.2979,  0.1456,  1.0000],\n",
              "         [ 0.1536, -0.0571, -0.0508,  ...,  0.3899,  0.0424,  1.0000],\n",
              "         ...,\n",
              "         [-0.0908,  0.0345,  0.1849,  ...,  0.0853,  0.0049,  1.0000],\n",
              "         [-0.2047,  0.0477,  0.2256,  ...,  0.0792, -0.0306,  1.0000],\n",
              "         [-0.2516,  0.0513,  0.2440,  ...,  0.0541, -0.0127,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0066, -0.1194, -0.0609,  ...,  0.0528,  0.2090,  1.0000],\n",
              "         [ 0.1695, -0.0108, -0.0515,  ...,  0.2395,  0.1040,  1.0000],\n",
              "         [ 0.1629,  0.0419, -0.0341,  ...,  0.3264, -0.0572,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0685,  0.1003,  0.0837,  ...,  0.0492,  0.0385,  1.0000],\n",
              "         [-0.1381,  0.1342,  0.2607,  ...,  0.0718, -0.0054,  1.0000],\n",
              "         [-0.2400,  0.0983,  0.2613,  ...,  0.0746,  0.0022,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7683e-02, -1.2676e-01, -2.7238e-02,  ...,  4.3559e-02,\n",
              "           2.0887e-01,  2.0000e+00],\n",
              "         [ 1.4465e-01, -3.2036e-02, -9.9876e-04,  ...,  2.5889e-01,\n",
              "           1.1587e-01,  2.0000e+00],\n",
              "         [ 1.4781e-01,  2.7253e-02,  1.2480e-02,  ...,  3.3126e-01,\n",
              "          -1.9285e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.9758e-02,  1.2371e-01,  1.9834e-01,  ...,  7.4788e-02,\n",
              "           1.6878e-02,  2.0000e+00],\n",
              "         [-2.2442e-01,  1.3049e-01,  3.3906e-01,  ...,  7.2767e-02,\n",
              "          -1.4340e-02,  2.0000e+00],\n",
              "         [-2.7424e-01,  1.0867e-01,  2.9856e-01,  ...,  5.1032e-02,\n",
              "           3.8592e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.4253e-02, -1.6101e-01, -4.5420e-02,  ...,  6.5142e-02,\n",
              "           2.1401e-01,  3.0000e+00],\n",
              "         [ 1.7437e-01, -9.7166e-02, -5.5298e-02,  ...,  2.9873e-01,\n",
              "           1.6300e-01,  3.0000e+00],\n",
              "         [ 1.2659e-01, -9.1387e-02, -5.1716e-02,  ...,  3.9249e-01,\n",
              "           7.0780e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3550e-01,  2.8410e-02,  2.0113e-01,  ...,  9.5090e-02,\n",
              "          -2.3947e-03,  3.0000e+00],\n",
              "         [-2.3596e-01,  4.2226e-02,  2.2069e-01,  ...,  7.8525e-02,\n",
              "          -3.9154e-02,  3.0000e+00],\n",
              "         [-2.6465e-01,  3.1058e-02,  2.4167e-01,  ...,  3.9928e-02,\n",
              "          -1.9196e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.9015e-02, -1.2915e-01, -3.1290e-02,  ...,  6.3854e-02,\n",
              "           2.1243e-01,  3.0000e+00],\n",
              "         [ 1.6759e-01, -5.0361e-02, -2.3400e-02,  ...,  2.6735e-01,\n",
              "           1.4466e-01,  3.0000e+00],\n",
              "         [ 1.4375e-01, -1.6144e-02, -2.3081e-03,  ...,  3.6119e-01,\n",
              "           2.5044e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.1283e-01,  1.2245e-01,  2.2500e-01,  ...,  7.7161e-02,\n",
              "          -7.8132e-03,  3.0000e+00],\n",
              "         [-2.4994e-01,  1.0480e-01,  2.9515e-01,  ...,  7.0926e-02,\n",
              "          -3.6025e-02,  3.0000e+00],\n",
              "         [-2.8507e-01,  9.4286e-02,  2.7777e-01,  ...,  5.9934e-02,\n",
              "          -7.6208e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0212, -0.1245, -0.0361,  ...,  0.0507,  0.2120,  3.0000],\n",
              "         [ 0.1342, -0.0207, -0.0107,  ...,  0.2486,  0.1086,  3.0000],\n",
              "         [ 0.1419,  0.0469,  0.0059,  ...,  0.3177, -0.0437,  3.0000],\n",
              "         ...,\n",
              "         [-0.0286,  0.1398,  0.1876,  ...,  0.0480,  0.0058,  3.0000],\n",
              "         [-0.2257,  0.1441,  0.3339,  ...,  0.0604, -0.0197,  3.0000],\n",
              "         [-0.2765,  0.1069,  0.3030,  ...,  0.0675,  0.0054,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.0476e-03, -1.0948e-01, -5.3098e-02,  ...,  2.9424e-02,\n",
              "           1.9743e-01,  3.0000e+00],\n",
              "         [ 1.5029e-01, -8.5247e-03, -2.4856e-02,  ...,  2.2546e-01,\n",
              "           5.3960e-02,  3.0000e+00],\n",
              "         [ 1.5994e-01,  5.3957e-02, -2.1106e-02,  ...,  2.9125e-01,\n",
              "          -8.7839e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 5.2135e-02,  8.2200e-02,  6.7081e-02,  ...,  1.9493e-02,\n",
              "           7.2071e-02,  3.0000e+00],\n",
              "         [-1.6496e-01,  1.2415e-01,  3.1512e-01,  ...,  6.9024e-02,\n",
              "          -4.4335e-04,  3.0000e+00],\n",
              "         [-2.6857e-01,  8.9169e-02,  3.0039e-01,  ...,  5.3649e-02,\n",
              "          -2.2873e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.4525e-02, -1.3999e-01, -3.2226e-02,  ...,  5.3931e-02,\n",
              "           2.1626e-01,  3.0000e+00],\n",
              "         [ 1.6062e-01, -4.3791e-02, -1.4467e-02,  ...,  2.7206e-01,\n",
              "           1.2966e-01,  3.0000e+00],\n",
              "         [ 1.4947e-01,  1.0853e-02,  4.1110e-03,  ...,  3.5141e-01,\n",
              "          -9.2601e-04,  3.0000e+00],\n",
              "         ...,\n",
              "         [-6.9716e-02,  1.3530e-01,  1.9298e-01,  ...,  6.0753e-02,\n",
              "           7.7014e-03,  3.0000e+00],\n",
              "         [-2.2845e-01,  1.2738e-01,  2.9197e-01,  ...,  6.3430e-02,\n",
              "          -2.1261e-02,  3.0000e+00],\n",
              "         [-2.7466e-01,  9.7822e-02,  2.7995e-01,  ...,  6.7880e-02,\n",
              "           2.0904e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0320, -0.1217, -0.0297,  ...,  0.0560,  0.2061,  3.0000],\n",
              "         [ 0.1363, -0.0542, -0.0292,  ...,  0.2577,  0.1413,  3.0000],\n",
              "         [ 0.1171, -0.0234, -0.0150,  ...,  0.3509,  0.0257,  3.0000],\n",
              "         ...,\n",
              "         [-0.1483,  0.1118,  0.2488,  ...,  0.0884, -0.0073,  3.0000],\n",
              "         [-0.2660,  0.0990,  0.3138,  ...,  0.0691, -0.0375,  3.0000],\n",
              "         [-0.3075,  0.0874,  0.2911,  ...,  0.0392, -0.0178,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0346, -0.1396, -0.0361,  ...,  0.0610,  0.2122,  3.0000],\n",
              "         [ 0.1629, -0.0599, -0.0376,  ...,  0.2712,  0.1477,  3.0000],\n",
              "         [ 0.1266, -0.0371, -0.0279,  ...,  0.3569,  0.0428,  3.0000],\n",
              "         ...,\n",
              "         [-0.1360,  0.0757,  0.2232,  ...,  0.0762, -0.0046,  3.0000],\n",
              "         [-0.2576,  0.0661,  0.2678,  ...,  0.0632, -0.0431,  3.0000],\n",
              "         [-0.2854,  0.0704,  0.2680,  ...,  0.0441, -0.0161,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0218, -0.1388, -0.0294,  ...,  0.0483,  0.2106,  3.0000],\n",
              "         [ 0.1481, -0.0498, -0.0182,  ...,  0.2730,  0.1336,  3.0000],\n",
              "         [ 0.1308, -0.0132, -0.0064,  ...,  0.3601,  0.0192,  3.0000],\n",
              "         ...,\n",
              "         [-0.0993,  0.0994,  0.2135,  ...,  0.0877,  0.0070,  3.0000],\n",
              "         [-0.2332,  0.0873,  0.2991,  ...,  0.0692, -0.0262,  3.0000],\n",
              "         [-0.2899,  0.0810,  0.2889,  ...,  0.0553, -0.0139,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.5261e-02, -1.3973e-01, -2.8351e-02,  ...,  5.6229e-02,\n",
              "           2.1721e-01,  3.0000e+00],\n",
              "         [ 1.5506e-01, -4.8734e-02, -1.1684e-02,  ...,  2.5771e-01,\n",
              "           1.4262e-01,  3.0000e+00],\n",
              "         [ 1.4042e-01,  3.4423e-05,  1.0359e-02,  ...,  3.4190e-01,\n",
              "           1.0542e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0371e-01,  1.4230e-01,  2.2241e-01,  ...,  6.3237e-02,\n",
              "          -1.1730e-03,  3.0000e+00],\n",
              "         [-2.4958e-01,  1.2452e-01,  3.0895e-01,  ...,  6.1731e-02,\n",
              "          -2.9106e-02,  3.0000e+00],\n",
              "         [-2.8343e-01,  9.5526e-02,  2.8509e-01,  ...,  6.3509e-02,\n",
              "          -1.9630e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1634e-02, -1.2312e-01, -2.8403e-02,  ...,  3.7666e-02,\n",
              "           2.0537e-01,  3.0000e+00],\n",
              "         [ 1.2429e-01, -3.0135e-02,  2.5529e-03,  ...,  2.3096e-01,\n",
              "           1.1311e-01,  3.0000e+00],\n",
              "         [ 1.1954e-01,  3.0528e-02,  2.0979e-02,  ...,  3.0850e-01,\n",
              "          -2.4331e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-5.0361e-02,  1.3739e-01,  2.0802e-01,  ...,  4.8455e-02,\n",
              "           1.7226e-02,  3.0000e+00],\n",
              "         [-2.3659e-01,  1.3775e-01,  3.4356e-01,  ...,  4.5903e-02,\n",
              "          -1.6156e-02,  3.0000e+00],\n",
              "         [-2.9276e-01,  1.0356e-01,  3.0553e-01,  ...,  3.9527e-02,\n",
              "          -4.7374e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.0075e-02, -1.1768e-01, -3.3948e-02,  ...,  4.3578e-02,\n",
              "           2.0890e-01,  3.0000e+00],\n",
              "         [ 1.5425e-01, -1.1454e-02, -1.3261e-02,  ...,  2.5030e-01,\n",
              "           1.0145e-01,  3.0000e+00],\n",
              "         [ 1.6341e-01,  5.8988e-02, -2.4668e-03,  ...,  3.1795e-01,\n",
              "          -4.5226e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 2.6058e-02,  1.1750e-01,  1.3733e-01,  ...,  4.9546e-02,\n",
              "           4.3086e-02,  3.0000e+00],\n",
              "         [-1.9122e-01,  1.2367e-01,  3.2417e-01,  ...,  7.9467e-02,\n",
              "          -4.3320e-05,  3.0000e+00],\n",
              "         [-2.5601e-01,  1.1117e-01,  2.9205e-01,  ...,  5.5952e-02,\n",
              "           8.1746e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.8699e-02, -1.2608e-01, -2.7833e-02,  ...,  4.7080e-02,\n",
              "           2.0544e-01,  3.0000e+00],\n",
              "         [ 1.3463e-01, -5.3443e-02, -1.7754e-02,  ...,  2.3906e-01,\n",
              "           1.3422e-01,  3.0000e+00],\n",
              "         [ 1.1403e-01, -2.2546e-02,  1.2557e-03,  ...,  3.3101e-01,\n",
              "           1.7095e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3377e-01,  1.2383e-01,  2.3966e-01,  ...,  6.8747e-02,\n",
              "           1.1916e-03,  3.0000e+00],\n",
              "         [-2.6077e-01,  1.1318e-01,  3.1840e-01,  ...,  5.4679e-02,\n",
              "          -3.5782e-02,  3.0000e+00],\n",
              "         [-3.0484e-01,  9.5075e-02,  2.9406e-01,  ...,  3.8459e-02,\n",
              "          -1.7722e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0363, -0.1515, -0.0508,  ...,  0.0661,  0.2128,  3.0000],\n",
              "         [ 0.1603, -0.0983, -0.0691,  ...,  0.3076,  0.1579,  3.0000],\n",
              "         [ 0.1118, -0.0963, -0.0696,  ...,  0.4122,  0.0694,  3.0000],\n",
              "         ...,\n",
              "         [-0.1465,  0.0169,  0.2055,  ...,  0.1171, -0.0104,  3.0000],\n",
              "         [-0.2466,  0.0287,  0.2189,  ...,  0.0893, -0.0439,  3.0000],\n",
              "         [-0.2705,  0.0382,  0.2437,  ...,  0.0377, -0.0182,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4213e-02, -1.3964e-01, -3.1101e-02,  ...,  5.6221e-02,\n",
              "           2.1698e-01,  3.0000e+00],\n",
              "         [ 1.5943e-01, -4.4364e-02, -1.9042e-02,  ...,  2.7151e-01,\n",
              "           1.3747e-01,  3.0000e+00],\n",
              "         [ 1.4533e-01,  3.0791e-04,  4.5246e-03,  ...,  3.5638e-01,\n",
              "           9.0078e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-8.4312e-02,  1.1738e-01,  2.0914e-01,  ...,  6.3467e-02,\n",
              "          -1.6029e-03,  3.0000e+00],\n",
              "         [-2.2802e-01,  1.1191e-01,  2.9549e-01,  ...,  6.5052e-02,\n",
              "          -2.9830e-02,  3.0000e+00],\n",
              "         [-2.7844e-01,  9.0141e-02,  2.8256e-01,  ...,  6.4114e-02,\n",
              "          -3.7446e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1268e-02, -1.2491e-01, -3.8485e-02,  ...,  5.3172e-02,\n",
              "           2.1401e-01,  3.0000e+00],\n",
              "         [ 1.4195e-01, -1.5551e-02, -1.4163e-02,  ...,  2.5241e-01,\n",
              "           1.1551e-01,  3.0000e+00],\n",
              "         [ 1.4647e-01,  4.8173e-02,  2.6318e-03,  ...,  3.2683e-01,\n",
              "          -3.1230e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.7706e-02,  1.3413e-01,  1.7171e-01,  ...,  5.7400e-02,\n",
              "           1.8402e-02,  3.0000e+00],\n",
              "         [-2.1961e-01,  1.3799e-01,  3.2441e-01,  ...,  7.0726e-02,\n",
              "          -1.6185e-02,  3.0000e+00],\n",
              "         [-2.7799e-01,  1.0267e-01,  2.9800e-01,  ...,  6.9232e-02,\n",
              "           4.8588e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0193, -0.1303, -0.0358,  ...,  0.0521,  0.2150,  3.0000],\n",
              "         [ 0.1439, -0.0287, -0.0137,  ...,  0.2509,  0.1260,  3.0000],\n",
              "         [ 0.1420,  0.0349,  0.0076,  ...,  0.3271, -0.0210,  3.0000],\n",
              "         ...,\n",
              "         [-0.0424,  0.1464,  0.1865,  ...,  0.0484,  0.0184,  3.0000],\n",
              "         [-0.2217,  0.1449,  0.3076,  ...,  0.0578, -0.0141,  3.0000],\n",
              "         [-0.2734,  0.1047,  0.2891,  ...,  0.0672,  0.0037,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1592, -0.0561,  ...,  0.0650,  0.2125,  3.0000],\n",
              "         [ 0.1520, -0.1086, -0.0697,  ...,  0.2976,  0.1569,  3.0000],\n",
              "         [ 0.1014, -0.1027, -0.0717,  ...,  0.3963,  0.0654,  3.0000],\n",
              "         ...,\n",
              "         [-0.1516,  0.0079,  0.1981,  ...,  0.0910, -0.0212,  3.0000],\n",
              "         [-0.2269,  0.0347,  0.1975,  ...,  0.0803, -0.0474,  3.0000],\n",
              "         [-0.2519,  0.0147,  0.2272,  ...,  0.0407, -0.0263,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0268, -0.1594, -0.0476,  ...,  0.0570,  0.2125,  3.0000],\n",
              "         [ 0.1516, -0.0993, -0.0759,  ...,  0.2889,  0.1501,  3.0000],\n",
              "         [ 0.1100, -0.0940, -0.0834,  ...,  0.3819,  0.0568,  3.0000],\n",
              "         ...,\n",
              "         [-0.1081,  0.0122,  0.1789,  ...,  0.1061,  0.0280,  3.0000],\n",
              "         [-0.2101,  0.0149,  0.2271,  ...,  0.0790, -0.0159,  3.0000],\n",
              "         [-0.2653,  0.0146,  0.2434,  ...,  0.0434, -0.0226,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0190, -0.1545, -0.0637,  ...,  0.0489,  0.1783,  3.0000],\n",
              "         [ 0.1046, -0.1311, -0.0556,  ...,  0.2294,  0.1457,  3.0000],\n",
              "         [ 0.0381, -0.1336, -0.0758,  ...,  0.3233,  0.0925,  3.0000],\n",
              "         ...,\n",
              "         [-0.2137,  0.0494,  0.2325,  ..., -0.0435, -0.0948,  3.0000],\n",
              "         [-0.2477,  0.0743,  0.2356,  ..., -0.0317, -0.0921,  3.0000],\n",
              "         [-0.2024,  0.0564,  0.2436,  ..., -0.0436, -0.0647,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0316, -0.1262, -0.0310,  ...,  0.0578,  0.2077,  3.0000],\n",
              "         [ 0.1456, -0.0572, -0.0351,  ...,  0.2732,  0.1401,  3.0000],\n",
              "         [ 0.1255, -0.0282, -0.0264,  ...,  0.3679,  0.0286,  3.0000],\n",
              "         ...,\n",
              "         [-0.1224,  0.0919,  0.2270,  ...,  0.0947,  0.0048,  3.0000],\n",
              "         [-0.2491,  0.0799,  0.2957,  ...,  0.0730, -0.0303,  3.0000],\n",
              "         [-0.2994,  0.0810,  0.2854,  ...,  0.0467, -0.0170,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0309, -0.1323, -0.0748,  ...,  0.0095,  0.1781,  3.0000],\n",
              "         [ 0.2250, -0.0183, -0.0606,  ...,  0.1861,  0.0120,  3.0000],\n",
              "         [ 0.2270,  0.0232, -0.0531,  ...,  0.2415, -0.1081,  3.0000],\n",
              "         ...,\n",
              "         [ 0.1246,  0.0036, -0.0373,  ...,  0.0415,  0.0732,  3.0000],\n",
              "         [-0.0834,  0.0928,  0.2606,  ...,  0.1061, -0.0291,  3.0000],\n",
              "         [-0.2611,  0.0638,  0.3033,  ...,  0.0743, -0.0211,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0337, -0.1445, -0.0367,  ...,  0.0623,  0.2158,  3.0000],\n",
              "         [ 0.1719, -0.0666, -0.0443,  ...,  0.2844,  0.1518,  3.0000],\n",
              "         [ 0.1325, -0.0480, -0.0394,  ...,  0.3717,  0.0506,  3.0000],\n",
              "         ...,\n",
              "         [-0.1119,  0.0706,  0.2015,  ...,  0.0868,  0.0129,  3.0000],\n",
              "         [-0.2400,  0.0722,  0.2573,  ...,  0.0743, -0.0328,  3.0000],\n",
              "         [-0.2825,  0.0622,  0.2611,  ...,  0.0495, -0.0172,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2795e-02, -1.3024e-01, -2.7186e-02,  ...,  4.3405e-02,\n",
              "           2.0809e-01,  3.0000e+00],\n",
              "         [ 1.3365e-01, -3.7172e-02, -3.4643e-03,  ...,  2.5278e-01,\n",
              "           1.2426e-01,  3.0000e+00],\n",
              "         [ 1.2673e-01,  1.5627e-02,  1.6685e-02,  ...,  3.3280e-01,\n",
              "          -4.5404e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-8.6425e-02,  1.3408e-01,  2.2706e-01,  ...,  7.8631e-02,\n",
              "           2.3306e-03,  3.0000e+00],\n",
              "         [-2.4403e-01,  1.2292e-01,  3.3969e-01,  ...,  6.4484e-02,\n",
              "          -2.7148e-02,  3.0000e+00],\n",
              "         [-2.9422e-01,  9.5582e-02,  3.0144e-01,  ...,  4.8599e-02,\n",
              "          -1.2111e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.2827e-02, -1.3163e-01, -2.5025e-02,  ...,  4.4901e-02,\n",
              "           2.0993e-01,  3.0000e+00],\n",
              "         [ 1.3657e-01, -4.2842e-02, -5.2258e-03,  ...,  2.5540e-01,\n",
              "           1.3249e-01,  3.0000e+00],\n",
              "         [ 1.2525e-01,  4.1192e-03,  1.6684e-02,  ...,  3.3789e-01,\n",
              "           7.8762e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0421e-01,  1.3221e-01,  2.4400e-01,  ...,  7.9788e-02,\n",
              "          -6.2423e-04,  3.0000e+00],\n",
              "         [-2.5007e-01,  1.2317e-01,  3.3827e-01,  ...,  6.5228e-02,\n",
              "          -2.9376e-02,  3.0000e+00],\n",
              "         [-2.9922e-01,  9.0742e-02,  3.0064e-01,  ...,  5.1766e-02,\n",
              "          -1.4720e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.7651e-02, -1.2788e-01, -2.6913e-02,  ...,  4.5298e-02,\n",
              "           2.1065e-01,  1.0000e+00],\n",
              "         [ 1.4599e-01, -3.4739e-02, -6.1564e-04,  ...,  2.5833e-01,\n",
              "           1.2184e-01,  1.0000e+00],\n",
              "         [ 1.4626e-01,  2.1845e-02,  1.3054e-02,  ...,  3.3289e-01,\n",
              "          -9.6568e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-4.4198e-02,  1.2669e-01,  2.1342e-01,  ...,  7.7864e-02,\n",
              "           1.5560e-02,  1.0000e+00],\n",
              "         [-2.2788e-01,  1.3059e-01,  3.4088e-01,  ...,  7.4922e-02,\n",
              "          -1.6448e-02,  1.0000e+00],\n",
              "         [-2.7630e-01,  1.0688e-01,  2.9991e-01,  ...,  5.3463e-02,\n",
              "           3.6642e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0163, -0.1209, -0.0364,  ...,  0.0371,  0.2042,  2.0000],\n",
              "         [ 0.1337, -0.0162, -0.0095,  ...,  0.2387,  0.0955,  2.0000],\n",
              "         [ 0.1346,  0.0488,  0.0060,  ...,  0.3122, -0.0495,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0055,  0.1254,  0.1484,  ...,  0.0440,  0.0259,  2.0000],\n",
              "         [-0.2074,  0.1233,  0.3240,  ...,  0.0583, -0.0140,  2.0000],\n",
              "         [-0.2761,  0.0934,  0.2971,  ...,  0.0464, -0.0057,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0362, -0.1333, -0.0900,  ...,  0.0385,  0.2058,  2.0000],\n",
              "         [ 0.2320, -0.0456, -0.0890,  ...,  0.2308,  0.0485,  2.0000],\n",
              "         [ 0.2043, -0.0074, -0.0825,  ...,  0.3113, -0.0919,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1987, -0.0029, -0.0021,  ...,  0.0717,  0.0488,  2.0000],\n",
              "         [-0.0360,  0.0553,  0.2147,  ...,  0.1213, -0.0204,  2.0000],\n",
              "         [-0.2290,  0.0531,  0.2678,  ...,  0.0955, -0.0075,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2560e-02, -1.3166e-01, -2.6897e-02,  ...,  4.3019e-02,\n",
              "           2.0855e-01,  2.0000e+00],\n",
              "         [ 1.3778e-01, -4.1344e-02, -5.8061e-03,  ...,  2.4990e-01,\n",
              "           1.2892e-01,  2.0000e+00],\n",
              "         [ 1.2390e-01,  3.5513e-03,  1.5436e-02,  ...,  3.3211e-01,\n",
              "           4.8670e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0793e-01,  1.3183e-01,  2.3164e-01,  ...,  7.1271e-02,\n",
              "          -1.9537e-03,  2.0000e+00],\n",
              "         [-2.5075e-01,  1.1846e-01,  3.2736e-01,  ...,  5.7074e-02,\n",
              "          -3.0976e-02,  2.0000e+00],\n",
              "         [-2.9698e-01,  9.2465e-02,  2.9673e-01,  ...,  4.6778e-02,\n",
              "          -1.5875e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.2766e-02, -1.3413e-01, -2.4521e-02,  ...,  4.5747e-02,\n",
              "           2.0930e-01,  2.0000e+00],\n",
              "         [ 1.3720e-01, -4.5894e-02, -4.7639e-03,  ...,  2.5762e-01,\n",
              "           1.3152e-01,  2.0000e+00],\n",
              "         [ 1.2388e-01,  1.2587e-04,  1.5106e-02,  ...,  3.4184e-01,\n",
              "           1.0979e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0612e-01,  1.2726e-01,  2.3917e-01,  ...,  7.8521e-02,\n",
              "           1.8038e-03,  2.0000e+00],\n",
              "         [-2.4977e-01,  1.1662e-01,  3.3026e-01,  ...,  6.5364e-02,\n",
              "          -2.9447e-02,  2.0000e+00],\n",
              "         [-2.9790e-01,  8.9117e-02,  2.9867e-01,  ...,  5.0005e-02,\n",
              "          -1.3957e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0211, -0.1288, -0.0321,  ...,  0.0490,  0.2160,  2.0000],\n",
              "         [ 0.1406, -0.0325, -0.0106,  ...,  0.2428,  0.1245,  2.0000],\n",
              "         [ 0.1375,  0.0317,  0.0097,  ...,  0.3182, -0.0226,  2.0000],\n",
              "         ...,\n",
              "         [-0.0481,  0.1439,  0.2010,  ...,  0.0468,  0.0124,  2.0000],\n",
              "         [-0.2333,  0.1397,  0.3307,  ...,  0.0560, -0.0176,  2.0000],\n",
              "         [-0.2779,  0.1059,  0.2978,  ...,  0.0669,  0.0046,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1267, -0.0310,  ...,  0.0546,  0.2079,  2.0000],\n",
              "         [ 0.1417, -0.0545, -0.0336,  ...,  0.2617,  0.1396,  2.0000],\n",
              "         [ 0.1199, -0.0271, -0.0230,  ...,  0.3554,  0.0261,  2.0000],\n",
              "         ...,\n",
              "         [-0.1311,  0.0942,  0.2297,  ...,  0.0840,  0.0055,  2.0000],\n",
              "         [-0.2541,  0.0830,  0.2971,  ...,  0.0641, -0.0327,  2.0000],\n",
              "         [-0.3023,  0.0811,  0.2861,  ...,  0.0422, -0.0190,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9021e-02, -1.2923e-01, -2.7758e-02,  ...,  3.7909e-02,\n",
              "           2.0823e-01,  2.0000e+00],\n",
              "         [ 1.3137e-01, -2.6107e-02, -3.2612e-04,  ...,  2.4896e-01,\n",
              "           1.1185e-01,  2.0000e+00],\n",
              "         [ 1.3286e-01,  3.9283e-02,  2.0128e-02,  ...,  3.2355e-01,\n",
              "          -2.1107e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.6038e-02,  1.2899e-01,  1.8877e-01,  ...,  6.1093e-02,\n",
              "           2.5850e-02,  2.0000e+00],\n",
              "         [-2.2116e-01,  1.2436e-01,  3.3565e-01,  ...,  6.0197e-02,\n",
              "          -1.1308e-02,  2.0000e+00],\n",
              "         [-2.8066e-01,  9.7210e-02,  3.0026e-01,  ...,  5.0231e-02,\n",
              "          -7.4003e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0171, -0.1232, -0.0353,  ...,  0.0502,  0.2166,  2.0000],\n",
              "         [ 0.1416, -0.0323, -0.0132,  ...,  0.2407,  0.1272,  2.0000],\n",
              "         [ 0.1350,  0.0337,  0.0106,  ...,  0.3175, -0.0255,  2.0000],\n",
              "         ...,\n",
              "         [-0.0296,  0.1454,  0.1880,  ...,  0.0452,  0.0297,  2.0000],\n",
              "         [-0.2198,  0.1428,  0.3226,  ...,  0.0603, -0.0062,  2.0000],\n",
              "         [-0.2717,  0.1103,  0.2940,  ...,  0.0694,  0.0070,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0290, -0.1250, -0.0859,  ...,  0.0251,  0.2024,  2.0000],\n",
              "         [ 0.2174, -0.0145, -0.0750,  ...,  0.2076,  0.0533,  2.0000],\n",
              "         [ 0.2076,  0.0217, -0.0709,  ...,  0.2859, -0.0882,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1581,  0.0106, -0.0391,  ...,  0.0451,  0.0688,  2.0000],\n",
              "         [-0.0750,  0.0910,  0.2355,  ...,  0.0965, -0.0164,  2.0000],\n",
              "         [-0.2501,  0.0740,  0.2822,  ...,  0.0821, -0.0066,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0189, -0.1232, -0.0316,  ...,  0.0386,  0.2070,  2.0000],\n",
              "         [ 0.1308, -0.0238, -0.0055,  ...,  0.2426,  0.1101,  2.0000],\n",
              "         [ 0.1283,  0.0403,  0.0131,  ...,  0.3182, -0.0305,  2.0000],\n",
              "         ...,\n",
              "         [-0.0226,  0.1299,  0.1834,  ...,  0.0538,  0.0194,  2.0000],\n",
              "         [-0.2243,  0.1251,  0.3377,  ...,  0.0569, -0.0147,  2.0000],\n",
              "         [-0.2836,  0.0945,  0.3017,  ...,  0.0460, -0.0051,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0132, -0.1250, -0.0639,  ...,  0.0586,  0.2124,  2.0000],\n",
              "         [ 0.1993, -0.0521, -0.0744,  ...,  0.2364,  0.0648,  2.0000],\n",
              "         [ 0.1662, -0.0177, -0.0664,  ...,  0.3301, -0.0789,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1573,  0.0352,  0.0701,  ...,  0.0546,  0.0107,  2.0000],\n",
              "         [-0.0750,  0.0766,  0.2629,  ...,  0.0982, -0.0431,  2.0000],\n",
              "         [-0.2265,  0.0744,  0.2791,  ...,  0.0852, -0.0055,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1318e-02, -1.1868e-01, -4.0237e-02,  ...,  5.3455e-02,\n",
              "           2.1968e-01,  2.0000e+00],\n",
              "         [ 1.3110e-01, -3.0719e-02, -1.4011e-02,  ...,  2.1109e-01,\n",
              "           1.3537e-01,  2.0000e+00],\n",
              "         [ 1.1837e-01,  3.0246e-02,  3.5626e-03,  ...,  2.9685e-01,\n",
              "          -2.8865e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.8748e-02,  1.6133e-01,  1.8530e-01,  ...,  2.9623e-02,\n",
              "           3.3347e-02,  2.0000e+00],\n",
              "         [-2.1712e-01,  1.5489e-01,  3.2685e-01,  ...,  5.1605e-02,\n",
              "           1.2756e-03,  2.0000e+00],\n",
              "         [-2.6642e-01,  1.0771e-01,  2.9688e-01,  ...,  7.0202e-02,\n",
              "           4.8998e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0127, -0.1216, -0.0311,  ...,  0.0438,  0.2089,  2.0000],\n",
              "         [ 0.1544, -0.0210, -0.0091,  ...,  0.2595,  0.1122,  2.0000],\n",
              "         [ 0.1589,  0.0466,  0.0046,  ...,  0.3298, -0.0326,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0073,  0.1242,  0.1661,  ...,  0.0684,  0.0336,  2.0000],\n",
              "         [-0.2021,  0.1277,  0.3278,  ...,  0.0777, -0.0038,  2.0000],\n",
              "         [-0.2620,  0.1096,  0.2945,  ...,  0.0564,  0.0066,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1366, -0.0376,  ...,  0.0578,  0.2110,  2.0000],\n",
              "         [ 0.1455, -0.0681, -0.0559,  ...,  0.2840,  0.1445,  2.0000],\n",
              "         [ 0.1158, -0.0514, -0.0587,  ...,  0.3762,  0.0388,  2.0000],\n",
              "         ...,\n",
              "         [-0.1248,  0.0545,  0.2064,  ...,  0.1038,  0.0150,  2.0000],\n",
              "         [-0.2412,  0.0536,  0.2682,  ...,  0.0792, -0.0297,  2.0000],\n",
              "         [-0.2936,  0.0585,  0.2711,  ...,  0.0445, -0.0180,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0300, -0.1513, -0.0372,  ...,  0.0610,  0.2128,  2.0000],\n",
              "         [ 0.1779, -0.0807, -0.0490,  ...,  0.2867,  0.1520,  2.0000],\n",
              "         [ 0.1363, -0.0630, -0.0432,  ...,  0.3796,  0.0521,  2.0000],\n",
              "         ...,\n",
              "         [-0.1143,  0.0528,  0.2006,  ...,  0.0960,  0.0105,  2.0000],\n",
              "         [-0.2329,  0.0535,  0.2520,  ...,  0.0794, -0.0352,  2.0000],\n",
              "         [-0.2758,  0.0568,  0.2587,  ...,  0.0473, -0.0159,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9414e-02, -1.4073e-01, -3.5082e-02,  ...,  5.9848e-02,\n",
              "           2.1916e-01,  2.0000e+00],\n",
              "         [ 1.5785e-01, -4.3787e-02, -1.6448e-02,  ...,  2.6331e-01,\n",
              "           1.4113e-01,  2.0000e+00],\n",
              "         [ 1.5155e-01,  1.1739e-03,  6.7312e-03,  ...,  3.4524e-01,\n",
              "           6.0516e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-5.0785e-02,  1.3751e-01,  1.8169e-01,  ...,  4.9754e-02,\n",
              "           1.8641e-02,  2.0000e+00],\n",
              "         [-2.1173e-01,  1.2433e-01,  2.8827e-01,  ...,  5.7694e-02,\n",
              "          -1.6036e-02,  2.0000e+00],\n",
              "         [-2.6769e-01,  1.0080e-01,  2.7465e-01,  ...,  7.1708e-02,\n",
              "           1.0296e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0206, -0.1327, -0.0287,  ...,  0.0440,  0.2095,  2.0000],\n",
              "         [ 0.1412, -0.0410, -0.0064,  ...,  0.2558,  0.1276,  2.0000],\n",
              "         [ 0.1354,  0.0097,  0.0134,  ...,  0.3367, -0.0029,  2.0000],\n",
              "         ...,\n",
              "         [-0.0781,  0.1298,  0.2233,  ...,  0.0835,  0.0035,  2.0000],\n",
              "         [-0.2412,  0.1224,  0.3346,  ...,  0.0697, -0.0252,  2.0000],\n",
              "         [-0.2895,  0.0938,  0.2960,  ...,  0.0543, -0.0101,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.4145e-03, -1.2167e-01, -4.7680e-02,  ...,  6.0639e-02,\n",
              "           2.1816e-01,  2.0000e+00],\n",
              "         [ 1.5121e-01, -2.3073e-02, -2.3102e-02,  ...,  2.3384e-01,\n",
              "           1.2366e-01,  2.0000e+00],\n",
              "         [ 1.4249e-01,  3.9092e-02, -7.7623e-03,  ...,  3.1643e-01,\n",
              "          -3.7366e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 3.3381e-03,  1.5160e-01,  1.5183e-01,  ...,  4.5814e-02,\n",
              "           3.2058e-02,  2.0000e+00],\n",
              "         [-1.9351e-01,  1.4528e-01,  3.0571e-01,  ...,  6.9021e-02,\n",
              "          -7.8032e-03,  2.0000e+00],\n",
              "         [-2.5202e-01,  1.0123e-01,  2.8372e-01,  ...,  7.6615e-02,\n",
              "           1.3154e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0169, -0.1306, -0.0265,  ...,  0.0463,  0.2116,  1.0000],\n",
              "         [ 0.1487, -0.0393, -0.0026,  ...,  0.2638,  0.1262,  1.0000],\n",
              "         [ 0.1475,  0.0152,  0.0110,  ...,  0.3431, -0.0022,  1.0000],\n",
              "         ...,\n",
              "         [-0.0660,  0.1252,  0.2275,  ...,  0.0887,  0.0104,  1.0000],\n",
              "         [-0.2335,  0.1251,  0.3372,  ...,  0.0812, -0.0204,  1.0000],\n",
              "         [-0.2788,  0.1031,  0.2975,  ...,  0.0584,  0.0015,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.2131e-03, -1.1010e-01, -4.5651e-02,  ...,  4.0397e-02,\n",
              "           2.0484e-01,  0.0000e+00],\n",
              "         [ 1.6480e-01, -5.8393e-03, -3.3269e-02,  ...,  2.5311e-01,\n",
              "           7.0650e-02,  0.0000e+00],\n",
              "         [ 1.7694e-01,  5.8720e-02, -2.8135e-02,  ...,  3.1287e-01,\n",
              "          -7.0608e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 8.2056e-02,  8.8127e-02,  5.3565e-02,  ...,  5.0242e-02,\n",
              "           6.4516e-02,  0.0000e+00],\n",
              "         [-1.5230e-01,  1.2416e-01,  3.0677e-01,  ...,  1.0338e-01,\n",
              "          -1.0906e-04,  0.0000e+00],\n",
              "         [-2.5094e-01,  1.0480e-01,  2.9222e-01,  ...,  6.6992e-02,\n",
              "           7.4237e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0166, -0.1299, -0.0275,  ...,  0.0469,  0.2115,  2.0000],\n",
              "         [ 0.1516, -0.0353, -0.0050,  ...,  0.2701,  0.1242,  2.0000],\n",
              "         [ 0.1524,  0.0225,  0.0089,  ...,  0.3481, -0.0054,  2.0000],\n",
              "         ...,\n",
              "         [-0.0456,  0.1198,  0.2098,  ...,  0.0914,  0.0180,  2.0000],\n",
              "         [-0.2248,  0.1236,  0.3310,  ...,  0.0839, -0.0149,  2.0000],\n",
              "         [-0.2750,  0.1024,  0.2955,  ...,  0.0608,  0.0031,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0279, -0.1305, -0.0314,  ...,  0.0625,  0.2110,  1.0000],\n",
              "         [ 0.1677, -0.0512, -0.0256,  ...,  0.2810,  0.1412,  1.0000],\n",
              "         [ 0.1479, -0.0127, -0.0044,  ...,  0.3760,  0.0161,  1.0000],\n",
              "         ...,\n",
              "         [-0.1183,  0.1124,  0.2322,  ...,  0.0892, -0.0101,  1.0000],\n",
              "         [-0.2453,  0.1016,  0.2894,  ...,  0.0799, -0.0352,  1.0000],\n",
              "         [-0.2852,  0.0908,  0.2784,  ...,  0.0606, -0.0093,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0337, -0.1300, -0.0319,  ...,  0.0661,  0.2121,  1.0000],\n",
              "         [ 0.1642, -0.0506, -0.0302,  ...,  0.2748,  0.1430,  1.0000],\n",
              "         [ 0.1374, -0.0194, -0.0096,  ...,  0.3668,  0.0327,  1.0000],\n",
              "         ...,\n",
              "         [-0.1425,  0.1085,  0.2468,  ...,  0.0787, -0.0160,  1.0000],\n",
              "         [-0.2580,  0.0933,  0.2913,  ...,  0.0731, -0.0401,  1.0000],\n",
              "         [-0.2866,  0.0886,  0.2777,  ...,  0.0514, -0.0104,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0343, -0.1551, -0.0518,  ...,  0.0668,  0.2112,  1.0000],\n",
              "         [ 0.1635, -0.1083, -0.0609,  ...,  0.3058,  0.1657,  1.0000],\n",
              "         [ 0.1089, -0.1012, -0.0603,  ...,  0.4115,  0.0765,  1.0000],\n",
              "         ...,\n",
              "         [-0.1695,  0.0325,  0.2091,  ...,  0.1072, -0.0197,  1.0000],\n",
              "         [-0.2513,  0.0533,  0.2124,  ...,  0.0892, -0.0501,  1.0000],\n",
              "         [-0.2630,  0.0339,  0.2376,  ...,  0.0363, -0.0249,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0292, -0.1532, -0.0586,  ...,  0.0533,  0.1885,  1.0000],\n",
              "         [ 0.0991, -0.1273, -0.0626,  ...,  0.2390,  0.1454,  1.0000],\n",
              "         [ 0.0313, -0.1271, -0.0772,  ...,  0.3359,  0.0844,  1.0000],\n",
              "         ...,\n",
              "         [-0.2386,  0.0591,  0.2185,  ..., -0.0057, -0.0878,  1.0000],\n",
              "         [-0.2699,  0.0752,  0.2247,  ...,  0.0018, -0.0813,  1.0000],\n",
              "         [-0.2310,  0.0390,  0.2450,  ..., -0.0189, -0.0555,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0331, -0.1567, -0.0530,  ...,  0.0678,  0.2119,  1.0000],\n",
              "         [ 0.1717, -0.1066, -0.0629,  ...,  0.3148,  0.1650,  1.0000],\n",
              "         [ 0.1159, -0.1017, -0.0618,  ...,  0.4224,  0.0793,  1.0000],\n",
              "         ...,\n",
              "         [-0.1570,  0.0167,  0.2001,  ...,  0.1062, -0.0243,  1.0000],\n",
              "         [-0.2323,  0.0398,  0.2011,  ...,  0.0879, -0.0477,  1.0000],\n",
              "         [-0.2534,  0.0244,  0.2306,  ...,  0.0359, -0.0218,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0274, -0.1298, -0.0245,  ...,  0.0416,  0.2078,  1.0000],\n",
              "         [ 0.1235, -0.0506, -0.0032,  ...,  0.2377,  0.1328,  1.0000],\n",
              "         [ 0.1070, -0.0097,  0.0176,  ...,  0.3214,  0.0120,  1.0000],\n",
              "         ...,\n",
              "         [-0.1413,  0.1364,  0.2633,  ...,  0.0664, -0.0038,  1.0000],\n",
              "         [-0.2646,  0.1256,  0.3408,  ...,  0.0531, -0.0372,  1.0000],\n",
              "         [-0.3062,  0.0923,  0.3045,  ...,  0.0395, -0.0197,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0299, -0.1539, -0.0448,  ...,  0.0519,  0.2112,  1.0000],\n",
              "         [ 0.1462, -0.0936, -0.0666,  ...,  0.2780,  0.1492,  1.0000],\n",
              "         [ 0.1049, -0.0846, -0.0747,  ...,  0.3689,  0.0527,  1.0000],\n",
              "         ...,\n",
              "         [-0.1212,  0.0211,  0.1895,  ...,  0.1018,  0.0291,  1.0000],\n",
              "         [-0.2223,  0.0196,  0.2453,  ...,  0.0751, -0.0182,  1.0000],\n",
              "         [-0.2772,  0.0250,  0.2560,  ...,  0.0352, -0.0192,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0336, -0.1436, -0.0383,  ...,  0.0527,  0.2136,  1.0000],\n",
              "         [ 0.1444, -0.0806, -0.0551,  ...,  0.2711,  0.1578,  1.0000],\n",
              "         [ 0.1019, -0.0693, -0.0573,  ...,  0.3659,  0.0634,  1.0000],\n",
              "         ...,\n",
              "         [-0.1473,  0.0543,  0.2218,  ...,  0.0988,  0.0227,  1.0000],\n",
              "         [-0.2548,  0.0487,  0.2765,  ...,  0.0756, -0.0296,  1.0000],\n",
              "         [-0.3016,  0.0480,  0.2774,  ...,  0.0322, -0.0201,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0231, -0.1281, -0.0284,  ...,  0.0538,  0.2167,  1.0000],\n",
              "         [ 0.1456, -0.0386, -0.0062,  ...,  0.2574,  0.1332,  1.0000],\n",
              "         [ 0.1423,  0.0195,  0.0141,  ...,  0.3359, -0.0072,  1.0000],\n",
              "         ...,\n",
              "         [-0.0871,  0.1418,  0.2389,  ...,  0.0655,  0.0021,  1.0000],\n",
              "         [-0.2440,  0.1363,  0.3348,  ...,  0.0627, -0.0256,  1.0000],\n",
              "         [-0.2848,  0.1035,  0.2991,  ...,  0.0634,  0.0028,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1191, -0.0325,  ...,  0.0475,  0.2147,  1.0000],\n",
              "         [ 0.1286, -0.0291, -0.0081,  ...,  0.2329,  0.1224,  1.0000],\n",
              "         [ 0.1309,  0.0361,  0.0141,  ...,  0.3060, -0.0274,  1.0000],\n",
              "         ...,\n",
              "         [-0.0543,  0.1385,  0.2137,  ...,  0.0440,  0.0146,  1.0000],\n",
              "         [-0.2345,  0.1372,  0.3463,  ...,  0.0522, -0.0088,  1.0000],\n",
              "         [-0.2808,  0.1047,  0.3078,  ...,  0.0563,  0.0100,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.6696e-02, -1.6541e-01, -5.1131e-02,  ...,  5.7619e-02,\n",
              "           2.1149e-01,  1.0000e+00],\n",
              "         [ 1.4382e-01, -1.1364e-01, -7.6276e-02,  ...,  2.9033e-01,\n",
              "           1.5253e-01,  1.0000e+00],\n",
              "         [ 9.7758e-02, -1.1011e-01, -8.5728e-02,  ...,  3.8092e-01,\n",
              "           6.6300e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1388e-01,  2.2965e-03,  1.8245e-01,  ...,  1.0755e-01,\n",
              "           1.7556e-02,  1.0000e+00],\n",
              "         [-2.0440e-01,  4.8180e-03,  2.1598e-01,  ...,  7.9929e-02,\n",
              "          -2.1813e-02,  1.0000e+00],\n",
              "         [-2.5630e-01, -3.1329e-04,  2.3727e-01,  ...,  3.9413e-02,\n",
              "          -2.3884e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0191, -0.1383, -0.0306,  ...,  0.0541,  0.2136,  1.0000],\n",
              "         [ 0.1592, -0.0516, -0.0204,  ...,  0.2867,  0.1361,  1.0000],\n",
              "         [ 0.1463, -0.0163, -0.0149,  ...,  0.3738,  0.0251,  1.0000],\n",
              "         ...,\n",
              "         [-0.0906,  0.1003,  0.2126,  ...,  0.1030,  0.0057,  1.0000],\n",
              "         [-0.2274,  0.0945,  0.2937,  ...,  0.0870, -0.0238,  1.0000],\n",
              "         [-0.2777,  0.0888,  0.2814,  ...,  0.0620, -0.0033,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6523e-02, -1.3222e-01, -2.7395e-02,  ...,  4.7982e-02,\n",
              "           2.1117e-01,  1.0000e+00],\n",
              "         [ 1.5347e-01, -3.9929e-02, -4.4112e-03,  ...,  2.7143e-01,\n",
              "           1.2739e-01,  1.0000e+00],\n",
              "         [ 1.5178e-01,  1.1739e-02,  8.4930e-03,  ...,  3.5086e-01,\n",
              "           2.5353e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-6.7650e-02,  1.2357e-01,  2.2321e-01,  ...,  9.4973e-02,\n",
              "           8.3041e-03,  1.0000e+00],\n",
              "         [-2.2989e-01,  1.2257e-01,  3.2909e-01,  ...,  8.3137e-02,\n",
              "          -2.2678e-02,  1.0000e+00],\n",
              "         [-2.7687e-01,  1.0197e-01,  2.9493e-01,  ...,  5.9376e-02,\n",
              "          -8.4860e-05,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0350, -0.1399, -0.0370,  ...,  0.0569,  0.2130,  1.0000],\n",
              "         [ 0.1524, -0.0655, -0.0409,  ...,  0.2675,  0.1480,  1.0000],\n",
              "         [ 0.1203, -0.0440, -0.0325,  ...,  0.3542,  0.0402,  1.0000],\n",
              "         ...,\n",
              "         [-0.1398,  0.0759,  0.2281,  ...,  0.0804,  0.0075,  1.0000],\n",
              "         [-0.2579,  0.0644,  0.2804,  ...,  0.0661, -0.0368,  1.0000],\n",
              "         [-0.2920,  0.0714,  0.2744,  ...,  0.0427, -0.0137,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.3328e-02, -1.5626e-01, -5.9978e-02,  ...,  5.7159e-02,\n",
              "           1.9439e-01,  1.0000e+00],\n",
              "         [ 1.0895e-01, -1.2957e-01, -6.8535e-02,  ...,  2.5934e-01,\n",
              "           1.4805e-01,  1.0000e+00],\n",
              "         [ 4.3156e-02, -1.2530e-01, -7.9347e-02,  ...,  3.5849e-01,\n",
              "           7.8263e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-2.2392e-01,  4.4601e-02,  1.9500e-01,  ...,  3.5661e-02,\n",
              "          -7.9435e-02,  1.0000e+00],\n",
              "         [-2.6788e-01,  6.4107e-02,  2.0860e-01,  ...,  4.1396e-02,\n",
              "          -7.9675e-02,  1.0000e+00],\n",
              "         [-2.4929e-01,  2.5005e-02,  2.3824e-01,  ...,  9.5191e-05,\n",
              "          -5.0961e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0095, -0.1275, -0.0427,  ...,  0.0560,  0.2169,  1.0000],\n",
              "         [ 0.1528, -0.0228, -0.0198,  ...,  0.2488,  0.1198,  1.0000],\n",
              "         [ 0.1564,  0.0439, -0.0074,  ...,  0.3262, -0.0352,  1.0000],\n",
              "         ...,\n",
              "         [-0.0105,  0.1456,  0.1674,  ...,  0.0515,  0.0199,  1.0000],\n",
              "         [-0.1986,  0.1494,  0.3089,  ...,  0.0638, -0.0122,  1.0000],\n",
              "         [-0.2601,  0.1081,  0.2896,  ...,  0.0729,  0.0049,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0346, -0.1547, -0.0585,  ...,  0.0617,  0.2043,  1.0000],\n",
              "         [ 0.1248, -0.1200, -0.0703,  ...,  0.2789,  0.1564,  1.0000],\n",
              "         [ 0.0612, -0.1165, -0.0757,  ...,  0.3842,  0.0815,  1.0000],\n",
              "         ...,\n",
              "         [-0.2091,  0.0383,  0.1981,  ...,  0.0898, -0.0607,  1.0000],\n",
              "         [-0.2651,  0.0518,  0.1993,  ...,  0.0762, -0.0783,  1.0000],\n",
              "         [-0.2652,  0.0204,  0.2349,  ...,  0.0214, -0.0456,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0314, -0.1554, -0.0479,  ...,  0.0629,  0.2142,  1.0000],\n",
              "         [ 0.1714, -0.0928, -0.0604,  ...,  0.2918,  0.1602,  1.0000],\n",
              "         [ 0.1231, -0.0903, -0.0583,  ...,  0.3927,  0.0658,  1.0000],\n",
              "         ...,\n",
              "         [-0.1422,  0.0175,  0.2096,  ...,  0.0903, -0.0095,  1.0000],\n",
              "         [-0.2351,  0.0349,  0.2223,  ...,  0.0778, -0.0413,  1.0000],\n",
              "         [-0.2624,  0.0336,  0.2433,  ...,  0.0396, -0.0177,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0146, -0.1222, -0.0455,  ...,  0.0520,  0.2118,  1.0000],\n",
              "         [ 0.1518, -0.0020, -0.0223,  ...,  0.2501,  0.1041,  1.0000],\n",
              "         [ 0.1609,  0.0581, -0.0091,  ...,  0.3220, -0.0485,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0136,  0.1329,  0.1370,  ...,  0.0512,  0.0106,  1.0000],\n",
              "         [-0.1939,  0.1395,  0.3059,  ...,  0.0681, -0.0175,  1.0000],\n",
              "         [-0.2592,  0.1070,  0.2877,  ...,  0.0711,  0.0096,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.1026e-02, -1.3103e-01, -2.8167e-02,  ...,  5.0617e-02,\n",
              "           2.1748e-01,  1.0000e+00],\n",
              "         [ 1.4529e-01, -4.0043e-02, -9.2392e-03,  ...,  2.5473e-01,\n",
              "           1.3721e-01,  1.0000e+00],\n",
              "         [ 1.3975e-01,  1.2278e-02,  1.6940e-02,  ...,  3.3400e-01,\n",
              "          -2.6381e-05,  1.0000e+00],\n",
              "         ...,\n",
              "         [-7.6460e-02,  1.3616e-01,  2.2697e-01,  ...,  6.3197e-02,\n",
              "           3.0261e-03,  1.0000e+00],\n",
              "         [-2.3608e-01,  1.3349e-01,  3.2723e-01,  ...,  6.2308e-02,\n",
              "          -2.5806e-02,  1.0000e+00],\n",
              "         [-2.8561e-01,  9.8338e-02,  2.9817e-01,  ...,  6.0455e-02,\n",
              "          -3.0898e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0359, -0.1521, -0.0462,  ...,  0.0555,  0.2134,  1.0000],\n",
              "         [ 0.1444, -0.0947, -0.0696,  ...,  0.2905,  0.1564,  1.0000],\n",
              "         [ 0.1010, -0.0983, -0.0756,  ...,  0.3787,  0.0827,  1.0000],\n",
              "         ...,\n",
              "         [-0.1538,  0.0228,  0.2128,  ...,  0.1036,  0.0071,  1.0000],\n",
              "         [-0.2439,  0.0207,  0.2417,  ...,  0.0810, -0.0325,  1.0000],\n",
              "         [-0.2860,  0.0220,  0.2574,  ...,  0.0339, -0.0241,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.3385e-03, -1.1578e-01, -4.7484e-02,  ...,  4.4507e-02,\n",
              "           2.1443e-01,  1.0000e+00],\n",
              "         [ 1.4462e-01, -1.4231e-02, -2.5859e-02,  ...,  2.2055e-01,\n",
              "           1.1745e-01,  1.0000e+00],\n",
              "         [ 1.5034e-01,  4.7062e-02, -8.8807e-03,  ...,  3.0102e-01,\n",
              "          -4.4745e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 2.0952e-02,  1.2637e-01,  1.1913e-01,  ...,  3.6991e-02,\n",
              "           4.1455e-02,  1.0000e+00],\n",
              "         [-1.8404e-01,  1.4338e-01,  3.0185e-01,  ...,  6.2631e-02,\n",
              "           7.5482e-04,  1.0000e+00],\n",
              "         [-2.5896e-01,  9.9830e-02,  2.9071e-01,  ...,  6.6234e-02,\n",
              "           2.7202e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0242, -0.1304, -0.0259,  ...,  0.0448,  0.2100,  1.0000],\n",
              "         [ 0.1329, -0.0427, -0.0051,  ...,  0.2549,  0.1314,  1.0000],\n",
              "         [ 0.1218,  0.0065,  0.0173,  ...,  0.3376,  0.0056,  1.0000],\n",
              "         ...,\n",
              "         [-0.1066,  0.1330,  0.2426,  ...,  0.0787, -0.0014,  1.0000],\n",
              "         [-0.2518,  0.1246,  0.3373,  ...,  0.0642, -0.0297,  1.0000],\n",
              "         [-0.3010,  0.0922,  0.3007,  ...,  0.0508, -0.0128,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1297, -0.0320,  ...,  0.0602,  0.2127,  1.0000],\n",
              "         [ 0.1504, -0.0538, -0.0285,  ...,  0.2534,  0.1538,  1.0000],\n",
              "         [ 0.1219, -0.0275, -0.0093,  ...,  0.3464,  0.0436,  1.0000],\n",
              "         ...,\n",
              "         [-0.1449,  0.1117,  0.2424,  ...,  0.0640, -0.0045,  1.0000],\n",
              "         [-0.2640,  0.0896,  0.2999,  ...,  0.0577, -0.0383,  1.0000],\n",
              "         [-0.2941,  0.0810,  0.2800,  ...,  0.0471, -0.0133,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.5071e-02, -1.2282e-01, -4.0168e-02,  ...,  5.2793e-02,\n",
              "           2.1252e-01,  1.0000e+00],\n",
              "         [ 1.5500e-01, -7.5142e-03, -1.4603e-02,  ...,  2.5368e-01,\n",
              "           1.0721e-01,  1.0000e+00],\n",
              "         [ 1.6214e-01,  6.0011e-02, -3.1024e-04,  ...,  3.2260e-01,\n",
              "          -4.6217e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-9.3618e-03,  1.3699e-01,  1.6625e-01,  ...,  5.1106e-02,\n",
              "           1.3161e-02,  1.0000e+00],\n",
              "         [-2.0509e-01,  1.4008e-01,  3.1328e-01,  ...,  6.5253e-02,\n",
              "          -1.7372e-02,  1.0000e+00],\n",
              "         [-2.6455e-01,  1.1029e-01,  2.8798e-01,  ...,  7.2578e-02,\n",
              "           1.0673e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0365, -0.1569, -0.0588,  ...,  0.0650,  0.2015,  1.0000],\n",
              "         [ 0.1190, -0.1246, -0.0702,  ...,  0.2929,  0.1489,  1.0000],\n",
              "         [ 0.0536, -0.1198, -0.0785,  ...,  0.3926,  0.0793,  1.0000],\n",
              "         ...,\n",
              "         [-0.2111,  0.0399,  0.1959,  ...,  0.0866, -0.0755,  1.0000],\n",
              "         [-0.2577,  0.0523,  0.1930,  ...,  0.0741, -0.0820,  1.0000],\n",
              "         [-0.2559,  0.0239,  0.2290,  ...,  0.0200, -0.0448,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6256e-02, -1.2161e-01, -3.7984e-02,  ...,  3.8554e-02,\n",
              "           2.0470e-01,  1.0000e+00],\n",
              "         [ 1.3729e-01, -1.2842e-02, -1.4170e-02,  ...,  2.4340e-01,\n",
              "           9.4996e-02,  1.0000e+00],\n",
              "         [ 1.3982e-01,  4.9073e-02, -3.8791e-04,  ...,  3.1733e-01,\n",
              "          -4.5886e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 7.3176e-03,  1.2901e-01,  1.4277e-01,  ...,  4.8720e-02,\n",
              "           2.6581e-02,  1.0000e+00],\n",
              "         [-2.0645e-01,  1.2010e-01,  3.2379e-01,  ...,  6.4577e-02,\n",
              "          -1.5529e-02,  1.0000e+00],\n",
              "         [-2.7200e-01,  9.5134e-02,  2.9535e-01,  ...,  4.9895e-02,\n",
              "          -6.5187e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0352, -0.1564, -0.0547,  ...,  0.0585,  0.2126,  1.0000],\n",
              "         [ 0.1380, -0.1107, -0.0788,  ...,  0.2973,  0.1555,  1.0000],\n",
              "         [ 0.0871, -0.1131, -0.0859,  ...,  0.3945,  0.0786,  1.0000],\n",
              "         ...,\n",
              "         [-0.1423,  0.0100,  0.1969,  ...,  0.1129, -0.0040,  1.0000],\n",
              "         [-0.2281,  0.0186,  0.2110,  ...,  0.0905, -0.0422,  1.0000],\n",
              "         [-0.2710,  0.0025,  0.2398,  ...,  0.0351, -0.0313,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0208, -0.1334, -0.0269,  ...,  0.0444,  0.2091,  1.0000],\n",
              "         [ 0.1413, -0.0421, -0.0061,  ...,  0.2583,  0.1287,  1.0000],\n",
              "         [ 0.1297,  0.0078,  0.0142,  ...,  0.3410,  0.0045,  1.0000],\n",
              "         ...,\n",
              "         [-0.0946,  0.1272,  0.2237,  ...,  0.0791,  0.0035,  1.0000],\n",
              "         [-0.2434,  0.1158,  0.3246,  ...,  0.0647, -0.0277,  1.0000],\n",
              "         [-0.2933,  0.0914,  0.2975,  ...,  0.0512, -0.0131,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.0133e-02, -1.1921e-01, -3.3439e-02,  ...,  4.3928e-02,\n",
              "           2.0861e-01,  2.0000e+00],\n",
              "         [ 1.5277e-01, -1.4220e-02, -1.2712e-02,  ...,  2.5586e-01,\n",
              "           1.0270e-01,  2.0000e+00],\n",
              "         [ 1.6249e-01,  5.5318e-02, -2.4052e-03,  ...,  3.2524e-01,\n",
              "          -4.1395e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 2.9333e-02,  1.1887e-01,  1.3880e-01,  ...,  5.4067e-02,\n",
              "           4.1468e-02,  2.0000e+00],\n",
              "         [-1.9090e-01,  1.2427e-01,  3.2428e-01,  ...,  8.1373e-02,\n",
              "          -1.6119e-03,  2.0000e+00],\n",
              "         [-2.5579e-01,  1.0987e-01,  2.9267e-01,  ...,  5.6394e-02,\n",
              "           7.3016e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0182e-02, -1.1906e-01, -3.0874e-02,  ...,  3.6401e-02,\n",
              "           2.0510e-01,  2.0000e+00],\n",
              "         [ 1.2488e-01, -2.0762e-02,  3.0539e-04,  ...,  2.3219e-01,\n",
              "           1.0172e-01,  2.0000e+00],\n",
              "         [ 1.2544e-01,  4.6820e-02,  2.0333e-02,  ...,  3.0480e-01,\n",
              "          -4.1127e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1954e-02,  1.3155e-01,  1.7603e-01,  ...,  3.5523e-02,\n",
              "           3.2140e-02,  2.0000e+00],\n",
              "         [-2.2045e-01,  1.3058e-01,  3.4237e-01,  ...,  4.7130e-02,\n",
              "          -9.6722e-03,  2.0000e+00],\n",
              "         [-2.8630e-01,  9.9680e-02,  3.0685e-01,  ...,  4.2495e-02,\n",
              "          -1.7347e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0331, -0.1557, -0.0582,  ...,  0.0589,  0.1923,  2.0000],\n",
              "         [ 0.1120, -0.1289, -0.0648,  ...,  0.2601,  0.1477,  2.0000],\n",
              "         [ 0.0449, -0.1246, -0.0760,  ...,  0.3577,  0.0833,  2.0000],\n",
              "         ...,\n",
              "         [-0.2409,  0.0532,  0.2040,  ...,  0.0351, -0.0865,  2.0000],\n",
              "         [-0.2758,  0.0682,  0.2113,  ...,  0.0344, -0.0820,  2.0000],\n",
              "         [-0.2464,  0.0339,  0.2387,  ..., -0.0057, -0.0505,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0204, -0.1215, -0.0275,  ...,  0.0365,  0.2061,  2.0000],\n",
              "         [ 0.1271, -0.0220,  0.0062,  ...,  0.2330,  0.1078,  2.0000],\n",
              "         [ 0.1277,  0.0426,  0.0278,  ...,  0.3061, -0.0312,  2.0000],\n",
              "         ...,\n",
              "         [-0.0328,  0.1330,  0.1946,  ...,  0.0397,  0.0219,  2.0000],\n",
              "         [-0.2266,  0.1285,  0.3462,  ...,  0.0422, -0.0140,  2.0000],\n",
              "         [-0.2887,  0.1022,  0.3076,  ...,  0.0382, -0.0025,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0314, -0.1569, -0.0594,  ...,  0.0568,  0.1916,  2.0000],\n",
              "         [ 0.1137, -0.1309, -0.0645,  ...,  0.2578,  0.1487,  2.0000],\n",
              "         [ 0.0456, -0.1256, -0.0745,  ...,  0.3575,  0.0833,  2.0000],\n",
              "         ...,\n",
              "         [-0.2220,  0.0472,  0.1923,  ...,  0.0258, -0.0834,  2.0000],\n",
              "         [-0.2673,  0.0708,  0.2098,  ...,  0.0311, -0.0791,  2.0000],\n",
              "         [-0.2435,  0.0317,  0.2360,  ..., -0.0065, -0.0515,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0354, -0.1353, -0.0333,  ...,  0.0622,  0.2128,  2.0000],\n",
              "         [ 0.1623, -0.0603, -0.0299,  ...,  0.2753,  0.1537,  2.0000],\n",
              "         [ 0.1254, -0.0332, -0.0182,  ...,  0.3673,  0.0443,  2.0000],\n",
              "         ...,\n",
              "         [-0.1647,  0.0993,  0.2531,  ...,  0.0863, -0.0185,  2.0000],\n",
              "         [-0.2673,  0.0842,  0.2858,  ...,  0.0762, -0.0419,  2.0000],\n",
              "         [-0.2931,  0.0784,  0.2762,  ...,  0.0485, -0.0123,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0211, -0.1289, -0.0795,  ...,  0.0327,  0.1896,  2.0000],\n",
              "         [ 0.2157,  0.0091, -0.0632,  ...,  0.2325,  0.0455,  2.0000],\n",
              "         [ 0.1987,  0.0422, -0.0591,  ...,  0.3093, -0.0915,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1631,  0.0109, -0.0027,  ...,  0.0726,  0.0357,  2.0000],\n",
              "         [-0.0731,  0.0813,  0.2595,  ...,  0.1191, -0.0249,  2.0000],\n",
              "         [-0.2481,  0.0764,  0.2872,  ...,  0.0831, -0.0225,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1346, -0.0323,  ...,  0.0686,  0.2115,  2.0000],\n",
              "         [ 0.1743, -0.0526, -0.0304,  ...,  0.2801,  0.1439,  2.0000],\n",
              "         [ 0.1467, -0.0213, -0.0112,  ...,  0.3723,  0.0304,  2.0000],\n",
              "         ...,\n",
              "         [-0.1322,  0.1185,  0.2355,  ...,  0.0869, -0.0153,  2.0000],\n",
              "         [-0.2602,  0.0962,  0.2890,  ...,  0.0765, -0.0382,  2.0000],\n",
              "         [-0.2838,  0.0934,  0.2736,  ...,  0.0636, -0.0078,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0276, -0.1486, -0.0605,  ...,  0.0586,  0.1974,  2.0000],\n",
              "         [ 0.1316, -0.1209, -0.0616,  ...,  0.2521,  0.1648,  2.0000],\n",
              "         [ 0.0636, -0.1088, -0.0662,  ...,  0.3631,  0.0824,  2.0000],\n",
              "         ...,\n",
              "         [-0.2266,  0.0528,  0.1876,  ...,  0.0327, -0.0748,  2.0000],\n",
              "         [-0.2760,  0.0719,  0.2121,  ...,  0.0441, -0.0762,  2.0000],\n",
              "         [-0.2485,  0.0387,  0.2365,  ...,  0.0060, -0.0520,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0173, -0.1180, -0.0384,  ...,  0.0461,  0.2117,  2.0000],\n",
              "         [ 0.1406, -0.0105, -0.0117,  ...,  0.2457,  0.1058,  2.0000],\n",
              "         [ 0.1517,  0.0585,  0.0077,  ...,  0.3146, -0.0492,  2.0000],\n",
              "         ...,\n",
              "         [-0.0057,  0.1345,  0.1621,  ...,  0.0389,  0.0251,  2.0000],\n",
              "         [-0.2045,  0.1424,  0.3281,  ...,  0.0604, -0.0109,  2.0000],\n",
              "         [-0.2697,  0.1062,  0.2995,  ...,  0.0629,  0.0044,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-9.5237e-03, -1.2093e-01, -3.2614e-02,  ...,  4.7070e-02,\n",
              "           2.1186e-01,  2.0000e+00],\n",
              "         [ 1.5748e-01, -1.8730e-02, -1.4563e-02,  ...,  2.6256e-01,\n",
              "           1.1626e-01,  2.0000e+00],\n",
              "         [ 1.6440e-01,  5.0777e-02, -1.1762e-03,  ...,  3.3539e-01,\n",
              "          -2.6076e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.5188e-02,  1.1900e-01,  1.5543e-01,  ...,  7.3396e-02,\n",
              "           4.0777e-02,  2.0000e+00],\n",
              "         [-1.9608e-01,  1.2173e-01,  3.2399e-01,  ...,  8.8040e-02,\n",
              "           8.6427e-04,  2.0000e+00],\n",
              "         [-2.5671e-01,  1.0759e-01,  2.9277e-01,  ...,  6.3280e-02,\n",
              "           8.8380e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3606e-02, -1.2205e-01, -3.0467e-02,  ...,  4.6560e-02,\n",
              "           2.1192e-01,  2.0000e+00],\n",
              "         [ 1.5123e-01, -2.2259e-02, -9.8322e-03,  ...,  2.6271e-01,\n",
              "           1.1838e-01,  2.0000e+00],\n",
              "         [ 1.5652e-01,  4.4932e-02,  4.2715e-03,  ...,  3.3490e-01,\n",
              "          -2.3295e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.7384e-03,  1.2186e-01,  1.7576e-01,  ...,  7.3139e-02,\n",
              "           3.2754e-02,  2.0000e+00],\n",
              "         [-2.0785e-01,  1.2519e-01,  3.3087e-01,  ...,  8.0411e-02,\n",
              "          -2.4656e-03,  2.0000e+00],\n",
              "         [-2.6274e-01,  1.0844e-01,  2.9496e-01,  ...,  5.9403e-02,\n",
              "           9.9570e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0321, -0.1302, -0.0296,  ...,  0.0530,  0.2055,  2.0000],\n",
              "         [ 0.1445, -0.0562, -0.0257,  ...,  0.2550,  0.1388,  2.0000],\n",
              "         [ 0.1225, -0.0271, -0.0117,  ...,  0.3450,  0.0282,  2.0000],\n",
              "         ...,\n",
              "         [-0.1200,  0.0997,  0.2201,  ...,  0.0723,  0.0120,  2.0000],\n",
              "         [-0.2514,  0.0928,  0.2948,  ...,  0.0587, -0.0309,  2.0000],\n",
              "         [-0.2975,  0.0876,  0.2845,  ...,  0.0394, -0.0177,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0278, -0.1421, -0.0371,  ...,  0.0675,  0.2163,  2.0000],\n",
              "         [ 0.1844, -0.0704, -0.0441,  ...,  0.2824,  0.1631,  2.0000],\n",
              "         [ 0.1428, -0.0472, -0.0360,  ...,  0.3812,  0.0557,  2.0000],\n",
              "         ...,\n",
              "         [-0.0980,  0.0833,  0.2039,  ...,  0.1138,  0.0079,  2.0000],\n",
              "         [-0.2389,  0.0806,  0.2736,  ...,  0.0941, -0.0255,  2.0000],\n",
              "         [-0.2832,  0.0777,  0.2629,  ...,  0.0700, -0.0089,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0294, -0.1475, -0.0426,  ...,  0.0623,  0.2125,  2.0000],\n",
              "         [ 0.1569, -0.0769, -0.0648,  ...,  0.2986,  0.1437,  2.0000],\n",
              "         [ 0.1256, -0.0653, -0.0710,  ...,  0.3890,  0.0429,  2.0000],\n",
              "         ...,\n",
              "         [-0.1092,  0.0301,  0.1855,  ...,  0.0998,  0.0231,  2.0000],\n",
              "         [-0.2155,  0.0311,  0.2419,  ...,  0.0830, -0.0190,  2.0000],\n",
              "         [-0.2740,  0.0395,  0.2535,  ...,  0.0535, -0.0172,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0188, -0.1189, -0.0331,  ...,  0.0360,  0.2038,  2.0000],\n",
              "         [ 0.1271, -0.0114, -0.0031,  ...,  0.2320,  0.0904,  2.0000],\n",
              "         [ 0.1346,  0.0566,  0.0125,  ...,  0.3030, -0.0533,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0027,  0.1259,  0.1487,  ...,  0.0273,  0.0336,  2.0000],\n",
              "         [-0.2095,  0.1228,  0.3369,  ...,  0.0488, -0.0134,  2.0000],\n",
              "         [-0.2778,  0.0964,  0.3046,  ...,  0.0423, -0.0036,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0183, -0.1229, -0.0384,  ...,  0.0498,  0.2140,  2.0000],\n",
              "         [ 0.1386, -0.0240, -0.0109,  ...,  0.2317,  0.1220,  2.0000],\n",
              "         [ 0.1357,  0.0434,  0.0083,  ...,  0.3100, -0.0291,  2.0000],\n",
              "         ...,\n",
              "         [-0.0355,  0.1498,  0.1886,  ...,  0.0446,  0.0196,  2.0000],\n",
              "         [-0.2276,  0.1413,  0.3252,  ...,  0.0586, -0.0109,  2.0000],\n",
              "         [-0.2714,  0.1069,  0.2925,  ...,  0.0700,  0.0088,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7766e-03, -1.0828e-01, -5.7397e-02,  ...,  4.3883e-02,\n",
              "           2.1150e-01,  2.0000e+00],\n",
              "         [ 1.4394e-01, -1.5603e-03, -2.9774e-02,  ...,  2.2204e-01,\n",
              "           9.8536e-02,  2.0000e+00],\n",
              "         [ 1.5350e-01,  5.4808e-02, -1.9417e-02,  ...,  2.9737e-01,\n",
              "          -6.3422e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 3.6797e-02,  1.2707e-01,  1.1575e-01,  ...,  2.2642e-02,\n",
              "           4.0440e-02,  2.0000e+00],\n",
              "         [-1.7509e-01,  1.4473e-01,  3.1112e-01,  ...,  6.1675e-02,\n",
              "          -9.9694e-03,  2.0000e+00],\n",
              "         [-2.5923e-01,  9.9434e-02,  2.9439e-01,  ...,  6.5401e-02,\n",
              "          -2.7272e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0480e-02, -1.3206e-01, -3.3850e-02,  ...,  5.3427e-02,\n",
              "           2.1492e-01,  2.0000e+00],\n",
              "         [ 1.4095e-01, -3.4104e-02, -1.2636e-02,  ...,  2.5200e-01,\n",
              "           1.2735e-01,  2.0000e+00],\n",
              "         [ 1.4076e-01,  3.0157e-02,  7.1172e-03,  ...,  3.3444e-01,\n",
              "          -2.0593e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-6.0958e-02,  1.4041e-01,  2.0808e-01,  ...,  6.7428e-02,\n",
              "           8.9350e-03,  2.0000e+00],\n",
              "         [-2.3238e-01,  1.4156e-01,  3.2480e-01,  ...,  6.8771e-02,\n",
              "          -2.0778e-02,  2.0000e+00],\n",
              "         [-2.8188e-01,  1.0170e-01,  2.9643e-01,  ...,  6.8373e-02,\n",
              "           1.3287e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0189, -0.1494, -0.0344,  ...,  0.0628,  0.2212,  2.0000],\n",
              "         [ 0.1779, -0.0496, -0.0307,  ...,  0.2824,  0.1431,  2.0000],\n",
              "         [ 0.1598, -0.0125, -0.0086,  ...,  0.3689,  0.0216,  2.0000],\n",
              "         ...,\n",
              "         [-0.0660,  0.0961,  0.1838,  ...,  0.0748,  0.0084,  2.0000],\n",
              "         [-0.2067,  0.0887,  0.2664,  ...,  0.0745, -0.0260,  2.0000],\n",
              "         [-0.2670,  0.0808,  0.2661,  ...,  0.0732, -0.0054,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7641e-02, -1.1689e-01, -3.0395e-02,  ...,  3.3185e-02,\n",
              "           2.0425e-01,  2.0000e+00],\n",
              "         [ 1.2676e-01, -1.5169e-02, -8.8881e-04,  ...,  2.2432e-01,\n",
              "           9.7902e-02,  2.0000e+00],\n",
              "         [ 1.3022e-01,  5.1865e-02,  1.9130e-02,  ...,  2.9601e-01,\n",
              "          -5.0081e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1041e-02,  1.3217e-01,  1.7239e-01,  ...,  1.9780e-02,\n",
              "           3.2907e-02,  2.0000e+00],\n",
              "         [-2.1649e-01,  1.3611e-01,  3.4205e-01,  ...,  3.8540e-02,\n",
              "          -1.0245e-02,  2.0000e+00],\n",
              "         [-2.8335e-01,  9.9604e-02,  3.0914e-01,  ...,  4.1974e-02,\n",
              "          -6.2849e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-9.8420e-03, -1.0931e-01, -4.7014e-02,  ...,  2.9070e-02,\n",
              "           1.9950e-01,  2.0000e+00],\n",
              "         [ 1.3874e-01, -5.3800e-03, -1.6613e-02,  ...,  2.2245e-01,\n",
              "           6.8134e-02,  2.0000e+00],\n",
              "         [ 1.5082e-01,  5.6004e-02, -7.8898e-03,  ...,  2.9096e-01,\n",
              "          -7.7944e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 3.7561e-02,  9.2704e-02,  8.6146e-02,  ...,  1.1380e-02,\n",
              "           6.2928e-02,  2.0000e+00],\n",
              "         [-1.7834e-01,  1.3126e-01,  3.2465e-01,  ...,  5.3703e-02,\n",
              "          -1.1417e-03,  2.0000e+00],\n",
              "         [-2.7345e-01,  9.6321e-02,  3.0470e-01,  ...,  4.7671e-02,\n",
              "          -4.4984e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0233, -0.1322, -0.0290,  ...,  0.0474,  0.2166,  2.0000],\n",
              "         [ 0.1420, -0.0388, -0.0057,  ...,  0.2510,  0.1315,  2.0000],\n",
              "         [ 0.1422,  0.0217,  0.0194,  ...,  0.3242, -0.0056,  2.0000],\n",
              "         ...,\n",
              "         [-0.0892,  0.1484,  0.2343,  ...,  0.0535, -0.0099,  2.0000],\n",
              "         [-0.2390,  0.1375,  0.3330,  ...,  0.0531, -0.0310,  2.0000],\n",
              "         [-0.2852,  0.0999,  0.3014,  ...,  0.0574, -0.0062,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.3879e-02, -1.2151e-01, -3.7799e-02,  ...,  4.9614e-02,\n",
              "           2.1951e-01,  0.0000e+00],\n",
              "         [ 1.3172e-01, -3.8523e-02, -1.3612e-02,  ...,  2.2842e-01,\n",
              "           1.4104e-01,  0.0000e+00],\n",
              "         [ 1.3200e-01,  2.5007e-02,  5.8169e-03,  ...,  3.0963e-01,\n",
              "          -1.6314e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [-5.8885e-02,  1.4851e-01,  2.0884e-01,  ...,  5.7920e-02,\n",
              "           1.1769e-02,  0.0000e+00],\n",
              "         [-2.3365e-01,  1.3986e-01,  3.3589e-01,  ...,  6.1363e-02,\n",
              "          -1.6435e-02,  0.0000e+00],\n",
              "         [-2.8083e-01,  1.0071e-01,  3.0285e-01,  ...,  6.0071e-02,\n",
              "          -1.5618e-04,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0275, -0.1481, -0.0588,  ...,  0.0618,  0.2020,  0.0000],\n",
              "         [ 0.1369, -0.1174, -0.0624,  ...,  0.2624,  0.1660,  0.0000],\n",
              "         [ 0.0705, -0.1075, -0.0649,  ...,  0.3749,  0.0884,  0.0000],\n",
              "         ...,\n",
              "         [-0.2117,  0.0496,  0.1904,  ...,  0.0513, -0.0649,  0.0000],\n",
              "         [-0.2719,  0.0597,  0.2104,  ...,  0.0625, -0.0695,  0.0000],\n",
              "         [-0.2568,  0.0423,  0.2404,  ...,  0.0131, -0.0430,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0172, -0.1285, -0.0317,  ...,  0.0395,  0.2059,  0.0000],\n",
              "         [ 0.1336, -0.0329, -0.0071,  ...,  0.2486,  0.1120,  0.0000],\n",
              "         [ 0.1302,  0.0277,  0.0130,  ...,  0.3285, -0.0280,  0.0000],\n",
              "         ...,\n",
              "         [-0.0294,  0.1289,  0.1851,  ...,  0.0727,  0.0180,  0.0000],\n",
              "         [-0.2223,  0.1273,  0.3303,  ...,  0.0626, -0.0141,  0.0000],\n",
              "         [-0.2789,  0.0965,  0.2944,  ...,  0.0463, -0.0077,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0362, -0.1545, -0.0566,  ...,  0.0608,  0.2081,  0.0000],\n",
              "         [ 0.1375, -0.1180, -0.0785,  ...,  0.2888,  0.1611,  0.0000],\n",
              "         [ 0.0758, -0.1153, -0.0831,  ...,  0.3956,  0.0826,  0.0000],\n",
              "         ...,\n",
              "         [-0.1858,  0.0223,  0.1973,  ...,  0.1095, -0.0385,  0.0000],\n",
              "         [-0.2598,  0.0437,  0.1987,  ...,  0.0872, -0.0691,  0.0000],\n",
              "         [-0.2721,  0.0195,  0.2364,  ...,  0.0235, -0.0380,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1362, -0.0289,  ...,  0.0495,  0.2163,  0.0000],\n",
              "         [ 0.1506, -0.0484, -0.0107,  ...,  0.2488,  0.1374,  0.0000],\n",
              "         [ 0.1383,  0.0046,  0.0124,  ...,  0.3310, -0.0051,  0.0000],\n",
              "         ...,\n",
              "         [-0.0895,  0.1520,  0.2159,  ...,  0.0488,  0.0023,  0.0000],\n",
              "         [-0.2354,  0.1327,  0.3086,  ...,  0.0537, -0.0274,  0.0000],\n",
              "         [-0.2758,  0.0979,  0.2858,  ...,  0.0648, -0.0055,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.0883e-04, -1.1717e-01, -4.6158e-02,  ...,  5.7584e-02,\n",
              "           2.1865e-01,  0.0000e+00],\n",
              "         [ 1.4678e-01, -2.8229e-02, -2.8800e-02,  ...,  2.2544e-01,\n",
              "           1.2648e-01,  0.0000e+00],\n",
              "         [ 1.3577e-01,  3.2728e-02, -1.1863e-02,  ...,  3.1247e-01,\n",
              "          -3.8442e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2534e-02,  1.4765e-01,  1.3062e-01,  ...,  4.5345e-02,\n",
              "           4.0157e-02,  0.0000e+00],\n",
              "         [-1.8987e-01,  1.4854e-01,  2.9651e-01,  ...,  7.1456e-02,\n",
              "           2.8959e-03,  0.0000e+00],\n",
              "         [-2.4815e-01,  1.0712e-01,  2.8137e-01,  ...,  7.5892e-02,\n",
              "           5.3222e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0320, -0.1362, -0.0391,  ...,  0.0547,  0.2097,  0.0000],\n",
              "         [ 0.1443, -0.0725, -0.0530,  ...,  0.2704,  0.1395,  0.0000],\n",
              "         [ 0.1180, -0.0534, -0.0554,  ...,  0.3644,  0.0279,  0.0000],\n",
              "         ...,\n",
              "         [-0.1234,  0.0584,  0.2015,  ...,  0.0995,  0.0172,  0.0000],\n",
              "         [-0.2416,  0.0537,  0.2710,  ...,  0.0719, -0.0274,  0.0000],\n",
              "         [-0.2910,  0.0593,  0.2699,  ...,  0.0381, -0.0196,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0338, -0.1606, -0.0518,  ...,  0.0577,  0.2122,  0.0000],\n",
              "         [ 0.1419, -0.1097, -0.0736,  ...,  0.2911,  0.1528,  0.0000],\n",
              "         [ 0.0932, -0.1134, -0.0801,  ...,  0.3803,  0.0774,  0.0000],\n",
              "         ...,\n",
              "         [-0.1393,  0.0056,  0.1971,  ...,  0.1083,  0.0055,  0.0000],\n",
              "         [-0.2330,  0.0209,  0.2135,  ...,  0.0869, -0.0418,  0.0000],\n",
              "         [-0.2708,  0.0080,  0.2409,  ...,  0.0343, -0.0281,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0282, -0.1239, -0.0316,  ...,  0.0516,  0.2072,  0.0000],\n",
              "         [ 0.1371, -0.0618, -0.0343,  ...,  0.2624,  0.1375,  0.0000],\n",
              "         [ 0.1196, -0.0295, -0.0238,  ...,  0.3620,  0.0147,  0.0000],\n",
              "         ...,\n",
              "         [-0.1283,  0.1030,  0.2354,  ...,  0.0938, -0.0028,  0.0000],\n",
              "         [-0.2527,  0.0944,  0.3068,  ...,  0.0705, -0.0316,  0.0000],\n",
              "         [-0.2997,  0.0828,  0.2886,  ...,  0.0449, -0.0185,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0139, -0.1103, -0.0614,  ...,  0.0538,  0.2072,  0.0000],\n",
              "         [ 0.1674, -0.0143, -0.0544,  ...,  0.2175,  0.0998,  0.0000],\n",
              "         [ 0.1565,  0.0394, -0.0437,  ...,  0.3000, -0.0630,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0718,  0.1139,  0.0745,  ...,  0.0459,  0.0487,  0.0000],\n",
              "         [-0.1503,  0.1326,  0.2699,  ...,  0.0862, -0.0023,  0.0000],\n",
              "         [-0.2419,  0.0966,  0.2715,  ...,  0.0696,  0.0006,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0342, -0.1471, -0.0382,  ...,  0.0611,  0.2155,  0.0000],\n",
              "         [ 0.1653, -0.0831, -0.0491,  ...,  0.2877,  0.1609,  0.0000],\n",
              "         [ 0.1170, -0.0792, -0.0449,  ...,  0.3840,  0.0712,  0.0000],\n",
              "         ...,\n",
              "         [-0.1512,  0.0549,  0.2242,  ...,  0.1001,  0.0026,  0.0000],\n",
              "         [-0.2636,  0.0533,  0.2578,  ...,  0.0805, -0.0440,  0.0000],\n",
              "         [-0.2897,  0.0542,  0.2642,  ...,  0.0384, -0.0213,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0333, -0.1400, -0.0366,  ...,  0.0549,  0.2113,  0.0000],\n",
              "         [ 0.1483, -0.0713, -0.0500,  ...,  0.2789,  0.1475,  0.0000],\n",
              "         [ 0.1144, -0.0565, -0.0522,  ...,  0.3697,  0.0469,  0.0000],\n",
              "         ...,\n",
              "         [-0.1416,  0.0571,  0.2242,  ...,  0.0868,  0.0100,  0.0000],\n",
              "         [-0.2452,  0.0558,  0.2706,  ...,  0.0698, -0.0260,  0.0000],\n",
              "         [-0.2935,  0.0561,  0.2751,  ...,  0.0394, -0.0181,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0083, -0.1145, -0.0347,  ...,  0.0433,  0.2079,  0.0000],\n",
              "         [ 0.1606, -0.0110, -0.0163,  ...,  0.2575,  0.0965,  0.0000],\n",
              "         [ 0.1723,  0.0599, -0.0057,  ...,  0.3212, -0.0509,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0522,  0.1133,  0.1084,  ...,  0.0530,  0.0549,  0.0000],\n",
              "         [-0.1732,  0.1249,  0.3137,  ...,  0.0910,  0.0030,  0.0000],\n",
              "         [-0.2530,  0.1119,  0.2926,  ...,  0.0602,  0.0095,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0326, -0.1438, -0.0353,  ...,  0.0629,  0.2147,  0.0000],\n",
              "         [ 0.1669, -0.0710, -0.0383,  ...,  0.2783,  0.1527,  0.0000],\n",
              "         [ 0.1234, -0.0516, -0.0292,  ...,  0.3707,  0.0508,  0.0000],\n",
              "         ...,\n",
              "         [-0.1408,  0.0754,  0.2336,  ...,  0.0946, -0.0009,  0.0000],\n",
              "         [-0.2556,  0.0622,  0.2768,  ...,  0.0767, -0.0418,  0.0000],\n",
              "         [-0.2823,  0.0708,  0.2691,  ...,  0.0485, -0.0170,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0339, -0.1354, -0.0362,  ...,  0.0526,  0.2099,  0.0000],\n",
              "         [ 0.1371, -0.0674, -0.0421,  ...,  0.2685,  0.1467,  0.0000],\n",
              "         [ 0.1081, -0.0477, -0.0410,  ...,  0.3593,  0.0411,  0.0000],\n",
              "         ...,\n",
              "         [-0.1604,  0.0699,  0.2474,  ...,  0.0889,  0.0023,  0.0000],\n",
              "         [-0.2605,  0.0660,  0.2881,  ...,  0.0702, -0.0332,  0.0000],\n",
              "         [-0.3013,  0.0660,  0.2831,  ...,  0.0346, -0.0194,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0625, -0.2272, -0.1456,  ..., -0.0333,  0.1875,  0.0000],\n",
              "         [ 0.2969,  0.0071, -0.0937,  ..., -0.0363,  0.0344,  0.0000],\n",
              "         [ 0.3230,  0.0223, -0.0766,  ...,  0.0126, -0.0026,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1850, -0.0193, -0.1481,  ...,  0.0253,  0.0927,  0.0000],\n",
              "         [ 0.0839,  0.0330,  0.0438,  ...,  0.0960,  0.0184,  0.0000],\n",
              "         [-0.0987, -0.0140,  0.2586,  ...,  0.0200,  0.0381,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0077, -0.1099, -0.0512,  ...,  0.0300,  0.1974,  0.0000],\n",
              "         [ 0.1473, -0.0045, -0.0249,  ...,  0.2294,  0.0530,  0.0000],\n",
              "         [ 0.1592,  0.0555, -0.0205,  ...,  0.2982, -0.0912,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0513,  0.0868,  0.0702,  ...,  0.0170,  0.0557,  0.0000],\n",
              "         [-0.1681,  0.1239,  0.3209,  ...,  0.0639, -0.0087,  0.0000],\n",
              "         [-0.2676,  0.0931,  0.2998,  ...,  0.0503, -0.0040,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0189, -0.1235, -0.0322,  ...,  0.0473,  0.2173,  0.0000],\n",
              "         [ 0.1288, -0.0347, -0.0071,  ...,  0.2384,  0.1342,  0.0000],\n",
              "         [ 0.1265,  0.0262,  0.0147,  ...,  0.3136, -0.0160,  0.0000],\n",
              "         ...,\n",
              "         [-0.0348,  0.1400,  0.1950,  ...,  0.0470,  0.0283,  0.0000],\n",
              "         [-0.2229,  0.1448,  0.3309,  ...,  0.0561, -0.0061,  0.0000],\n",
              "         [-0.2844,  0.1004,  0.3012,  ...,  0.0566,  0.0003,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4243e-02, -1.3168e-01, -2.5890e-02,  ...,  4.3192e-02,\n",
              "           2.0882e-01,  0.0000e+00],\n",
              "         [ 1.3033e-01, -4.5713e-02, -2.2975e-04,  ...,  2.4609e-01,\n",
              "           1.3186e-01,  0.0000e+00],\n",
              "         [ 1.1984e-01,  1.7142e-04,  1.9868e-02,  ...,  3.2859e-01,\n",
              "           5.5061e-03,  0.0000e+00],\n",
              "         ...,\n",
              "         [-1.0918e-01,  1.3348e-01,  2.5376e-01,  ...,  8.0832e-02,\n",
              "          -4.0907e-03,  0.0000e+00],\n",
              "         [-2.5441e-01,  1.2491e-01,  3.4788e-01,  ...,  6.2181e-02,\n",
              "          -3.2565e-02,  0.0000e+00],\n",
              "         [-3.0228e-01,  9.1507e-02,  3.0338e-01,  ...,  4.7431e-02,\n",
              "          -1.5735e-02,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0086, -0.1154, -0.0358,  ...,  0.0434,  0.2093,  1.0000],\n",
              "         [ 0.1586, -0.0104, -0.0188,  ...,  0.2569,  0.0966,  1.0000],\n",
              "         [ 0.1705,  0.0608, -0.0075,  ...,  0.3206, -0.0513,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0550,  0.1120,  0.1072,  ...,  0.0519,  0.0531,  1.0000],\n",
              "         [-0.1733,  0.1246,  0.3171,  ...,  0.0910,  0.0020,  1.0000],\n",
              "         [-0.2525,  0.1092,  0.2935,  ...,  0.0624,  0.0092,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0305, -0.1552, -0.0607,  ...,  0.0580,  0.1912,  1.0000],\n",
              "         [ 0.1091, -0.1294, -0.0685,  ...,  0.2616,  0.1454,  1.0000],\n",
              "         [ 0.0406, -0.1277, -0.0828,  ...,  0.3602,  0.0818,  1.0000],\n",
              "         ...,\n",
              "         [-0.2322,  0.0524,  0.1981,  ...,  0.0335, -0.0855,  1.0000],\n",
              "         [-0.2681,  0.0613,  0.2041,  ...,  0.0336, -0.0821,  1.0000],\n",
              "         [-0.2425,  0.0306,  0.2365,  ..., -0.0061, -0.0507,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0314, -0.1325, -0.0361,  ...,  0.0548,  0.2159,  1.0000],\n",
              "         [ 0.1443, -0.0666, -0.0418,  ...,  0.2619,  0.1601,  1.0000],\n",
              "         [ 0.1083, -0.0456, -0.0334,  ...,  0.3583,  0.0486,  1.0000],\n",
              "         ...,\n",
              "         [-0.1723,  0.0822,  0.2538,  ...,  0.0821, -0.0121,  1.0000],\n",
              "         [-0.2733,  0.0709,  0.2908,  ...,  0.0698, -0.0447,  1.0000],\n",
              "         [-0.3016,  0.0724,  0.2816,  ...,  0.0401, -0.0176,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1399, -0.0436,  ...,  0.0745,  0.2111,  1.0000],\n",
              "         [ 0.1913, -0.0826, -0.0724,  ...,  0.3104,  0.1602,  1.0000],\n",
              "         [ 0.1606, -0.0701, -0.0795,  ...,  0.4165,  0.0620,  1.0000],\n",
              "         ...,\n",
              "         [-0.0610,  0.0310,  0.1492,  ...,  0.1700,  0.0293,  1.0000],\n",
              "         [-0.2097,  0.0506,  0.2574,  ...,  0.1393, -0.0053,  1.0000],\n",
              "         [-0.2830,  0.0569,  0.2500,  ...,  0.0730, -0.0086,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0328, -0.1350, -0.0310,  ...,  0.0646,  0.2140,  1.0000],\n",
              "         [ 0.1687, -0.0602, -0.0278,  ...,  0.2684,  0.1501,  1.0000],\n",
              "         [ 0.1372, -0.0309, -0.0154,  ...,  0.3635,  0.0417,  1.0000],\n",
              "         ...,\n",
              "         [-0.1260,  0.1120,  0.2290,  ...,  0.0819, -0.0019,  1.0000],\n",
              "         [-0.2546,  0.0920,  0.2861,  ...,  0.0684, -0.0344,  1.0000],\n",
              "         [-0.2847,  0.0875,  0.2728,  ...,  0.0534, -0.0108,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0315, -0.1609, -0.0497,  ...,  0.0565,  0.2115,  1.0000],\n",
              "         [ 0.1458, -0.1076, -0.0718,  ...,  0.2930,  0.1552,  1.0000],\n",
              "         [ 0.1097, -0.1125, -0.0765,  ...,  0.3717,  0.0943,  1.0000],\n",
              "         ...,\n",
              "         [-0.1389,  0.0057,  0.1988,  ...,  0.1088,  0.0054,  1.0000],\n",
              "         [-0.2241,  0.0082,  0.2227,  ...,  0.0853, -0.0303,  1.0000],\n",
              "         [-0.2712,  0.0081,  0.2448,  ...,  0.0369, -0.0218,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0227, -0.1368, -0.0304,  ...,  0.0579,  0.2173,  1.0000],\n",
              "         [ 0.1527, -0.0453, -0.0143,  ...,  0.2615,  0.1365,  1.0000],\n",
              "         [ 0.1411,  0.0070,  0.0038,  ...,  0.3461, -0.0064,  1.0000],\n",
              "         ...,\n",
              "         [-0.0967,  0.1533,  0.2261,  ...,  0.0719, -0.0045,  1.0000],\n",
              "         [-0.2437,  0.1341,  0.3155,  ...,  0.0672, -0.0315,  1.0000],\n",
              "         [-0.2791,  0.1026,  0.2887,  ...,  0.0724, -0.0013,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0024, -0.1822, -0.0832,  ...,  0.0868,  0.2113,  1.0000],\n",
              "         [ 0.2184, -0.1499, -0.1397,  ...,  0.3405,  0.1578,  1.0000],\n",
              "         [ 0.1883, -0.1481, -0.1563,  ...,  0.4455,  0.0864,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0028, -0.0693,  0.0537,  ...,  0.2012,  0.0220,  1.0000],\n",
              "         [-0.1268, -0.0352,  0.1391,  ...,  0.1672, -0.0112,  1.0000],\n",
              "         [-0.2258, -0.0357,  0.1806,  ...,  0.0807, -0.0199,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0223, -0.1391, -0.0300,  ...,  0.0485,  0.2101,  1.0000],\n",
              "         [ 0.1472, -0.0494, -0.0206,  ...,  0.2751,  0.1305,  1.0000],\n",
              "         [ 0.1304, -0.0094, -0.0060,  ...,  0.3630,  0.0120,  1.0000],\n",
              "         ...,\n",
              "         [-0.0866,  0.0957,  0.2034,  ...,  0.0898,  0.0071,  1.0000],\n",
              "         [-0.2261,  0.0884,  0.2986,  ...,  0.0714, -0.0269,  1.0000],\n",
              "         [-0.2880,  0.0811,  0.2898,  ...,  0.0562, -0.0147,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0230, -0.1291, -0.0295,  ...,  0.0492,  0.2164,  1.0000],\n",
              "         [ 0.1270, -0.0475, -0.0078,  ...,  0.2306,  0.1382,  1.0000],\n",
              "         [ 0.1229,  0.0083,  0.0151,  ...,  0.3108, -0.0091,  1.0000],\n",
              "         ...,\n",
              "         [-0.1200,  0.1552,  0.2584,  ...,  0.0524, -0.0062,  1.0000],\n",
              "         [-0.2531,  0.1388,  0.3468,  ...,  0.0529, -0.0309,  1.0000],\n",
              "         [-0.2921,  0.1007,  0.3056,  ...,  0.0550, -0.0032,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0178, -0.1265, -0.0266,  ...,  0.0445,  0.2115,  1.0000],\n",
              "         [ 0.1455, -0.0351, -0.0019,  ...,  0.2597,  0.1222,  1.0000],\n",
              "         [ 0.1481,  0.0259,  0.0130,  ...,  0.3342, -0.0134,  1.0000],\n",
              "         ...,\n",
              "         [-0.0408,  0.1226,  0.2110,  ...,  0.0780,  0.0154,  1.0000],\n",
              "         [-0.2269,  0.1282,  0.3409,  ...,  0.0770, -0.0132,  1.0000],\n",
              "         [-0.2758,  0.1076,  0.2997,  ...,  0.0560,  0.0055,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0244, -0.1548, -0.0607,  ...,  0.0491,  0.1810,  1.0000],\n",
              "         [ 0.1004, -0.1331, -0.0546,  ...,  0.2349,  0.1448,  1.0000],\n",
              "         [ 0.0311, -0.1349, -0.0766,  ...,  0.3291,  0.0884,  1.0000],\n",
              "         ...,\n",
              "         [-0.2164,  0.0547,  0.2233,  ..., -0.0354, -0.0913,  1.0000],\n",
              "         [-0.2482,  0.0744,  0.2285,  ..., -0.0276, -0.0877,  1.0000],\n",
              "         [-0.2098,  0.0558,  0.2460,  ..., -0.0406, -0.0598,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1501, -0.0529,  ...,  0.0615,  0.2065,  1.0000],\n",
              "         [ 0.1365, -0.1111, -0.0617,  ...,  0.2790,  0.1637,  1.0000],\n",
              "         [ 0.0751, -0.1082, -0.0590,  ...,  0.3839,  0.0878,  1.0000],\n",
              "         ...,\n",
              "         [-0.1943,  0.0303,  0.2049,  ...,  0.0939, -0.0393,  1.0000],\n",
              "         [-0.2709,  0.0517,  0.2116,  ...,  0.0804, -0.0661,  1.0000],\n",
              "         [-0.2716,  0.0433,  0.2423,  ...,  0.0249, -0.0347,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0090, -0.1089, -0.0491,  ...,  0.0296,  0.1976,  1.0000],\n",
              "         [ 0.1476, -0.0013, -0.0242,  ...,  0.2312,  0.0548,  1.0000],\n",
              "         [ 0.1607,  0.0584, -0.0205,  ...,  0.2955, -0.0869,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0485,  0.0933,  0.0717,  ...,  0.0200,  0.0449,  1.0000],\n",
              "         [-0.1706,  0.1285,  0.3241,  ...,  0.0633, -0.0167,  1.0000],\n",
              "         [-0.2690,  0.0923,  0.3049,  ...,  0.0510, -0.0070,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0367, -0.1583, -0.0618,  ...,  0.0636,  0.2067,  1.0000],\n",
              "         [ 0.1261, -0.1288, -0.0805,  ...,  0.2977,  0.1514,  1.0000],\n",
              "         [ 0.0664, -0.1263, -0.0899,  ...,  0.3986,  0.0772,  1.0000],\n",
              "         ...,\n",
              "         [-0.1823,  0.0181,  0.1853,  ...,  0.1065, -0.0486,  1.0000],\n",
              "         [-0.2371,  0.0323,  0.1856,  ...,  0.0898, -0.0704,  1.0000],\n",
              "         [-0.2600,  0.0048,  0.2252,  ...,  0.0274, -0.0372,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0045, -0.1181, -0.0528,  ...,  0.0487,  0.2133,  1.0000],\n",
              "         [ 0.1482, -0.0078, -0.0335,  ...,  0.2257,  0.1095,  1.0000],\n",
              "         [ 0.1523,  0.0480, -0.0192,  ...,  0.3086, -0.0531,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0482,  0.1221,  0.0952,  ...,  0.0288,  0.0465,  1.0000],\n",
              "         [-0.1746,  0.1430,  0.2963,  ...,  0.0665, -0.0037,  1.0000],\n",
              "         [-0.2580,  0.1045,  0.2846,  ...,  0.0669,  0.0025,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.2556e-02, -1.2572e-01, -2.8697e-02,  ...,  6.1144e-02,\n",
              "           2.1114e-01,  1.0000e+00],\n",
              "         [ 1.4668e-01, -5.2171e-02, -2.2656e-02,  ...,  2.5333e-01,\n",
              "           1.4532e-01,  1.0000e+00],\n",
              "         [ 1.2513e-01, -2.1004e-02, -1.7909e-04,  ...,  3.4524e-01,\n",
              "           3.1612e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.5078e-01,  1.2665e-01,  2.5810e-01,  ...,  6.8863e-02,\n",
              "          -1.7656e-02,  1.0000e+00],\n",
              "         [-2.6117e-01,  1.0680e-01,  3.1330e-01,  ...,  6.5198e-02,\n",
              "          -4.1195e-02,  1.0000e+00],\n",
              "         [-2.9526e-01,  9.1232e-02,  2.8735e-01,  ...,  4.3076e-02,\n",
              "          -1.3017e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0334, -0.1465, -0.0411,  ...,  0.0550,  0.2145,  1.0000],\n",
              "         [ 0.1485, -0.0831, -0.0655,  ...,  0.2836,  0.1563,  1.0000],\n",
              "         [ 0.1065, -0.0750, -0.0708,  ...,  0.3785,  0.0592,  1.0000],\n",
              "         ...,\n",
              "         [-0.1342,  0.0370,  0.2058,  ...,  0.1069,  0.0242,  1.0000],\n",
              "         [-0.2447,  0.0356,  0.2605,  ...,  0.0804, -0.0276,  1.0000],\n",
              "         [-0.2945,  0.0401,  0.2669,  ...,  0.0372, -0.0197,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0372, -0.1549, -0.0543,  ...,  0.0600,  0.2101,  1.0000],\n",
              "         [ 0.1409, -0.1159, -0.0748,  ...,  0.2889,  0.1629,  1.0000],\n",
              "         [ 0.0826, -0.1147, -0.0787,  ...,  0.3913,  0.0874,  1.0000],\n",
              "         ...,\n",
              "         [-0.1773,  0.0184,  0.2040,  ...,  0.1133, -0.0253,  1.0000],\n",
              "         [-0.2584,  0.0415,  0.2086,  ...,  0.0889, -0.0639,  1.0000],\n",
              "         [-0.2762,  0.0198,  0.2422,  ...,  0.0258, -0.0345,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0336, -0.1254, -0.0315,  ...,  0.0548,  0.2075,  1.0000],\n",
              "         [ 0.1357, -0.0615, -0.0373,  ...,  0.2708,  0.1400,  1.0000],\n",
              "         [ 0.1087, -0.0377, -0.0329,  ...,  0.3665,  0.0333,  1.0000],\n",
              "         ...,\n",
              "         [-0.1454,  0.0873,  0.2399,  ...,  0.0965, -0.0022,  1.0000],\n",
              "         [-0.2609,  0.0772,  0.2986,  ...,  0.0747, -0.0360,  1.0000],\n",
              "         [-0.3053,  0.0795,  0.2850,  ...,  0.0366, -0.0173,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0310, -0.1498, -0.0573,  ...,  0.0567,  0.1979,  1.0000],\n",
              "         [ 0.1198, -0.1199, -0.0638,  ...,  0.2464,  0.1587,  1.0000],\n",
              "         [ 0.0539, -0.1103, -0.0673,  ...,  0.3558,  0.0816,  1.0000],\n",
              "         ...,\n",
              "         [-0.2261,  0.0461,  0.1938,  ...,  0.0379, -0.0726,  1.0000],\n",
              "         [-0.2788,  0.0647,  0.2129,  ...,  0.0472, -0.0738,  1.0000],\n",
              "         [-0.2569,  0.0443,  0.2424,  ...,  0.0039, -0.0473,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0208, -0.1330, -0.0281,  ...,  0.0510,  0.2134,  1.0000],\n",
              "         [ 0.1399, -0.0439, -0.0074,  ...,  0.2460,  0.1304,  1.0000],\n",
              "         [ 0.1381,  0.0175,  0.0126,  ...,  0.3249, -0.0153,  1.0000],\n",
              "         ...,\n",
              "         [-0.0768,  0.1485,  0.2203,  ...,  0.0572,  0.0109,  1.0000],\n",
              "         [-0.2410,  0.1381,  0.3311,  ...,  0.0599, -0.0164,  1.0000],\n",
              "         [-0.2815,  0.1036,  0.2963,  ...,  0.0633,  0.0040,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.1872e-02, -1.3559e-01, -2.8791e-02,  ...,  5.0659e-02,\n",
              "           2.1625e-01,  1.0000e+00],\n",
              "         [ 1.3820e-01, -3.6319e-02, -3.9881e-05,  ...,  2.3540e-01,\n",
              "           1.2789e-01,  1.0000e+00],\n",
              "         [ 1.3594e-01,  2.2483e-02,  2.3177e-02,  ...,  3.0771e-01,\n",
              "          -9.7790e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-6.3691e-02,  1.5105e-01,  2.1280e-01,  ...,  4.6792e-02,\n",
              "           8.4836e-03,  1.0000e+00],\n",
              "         [-2.3571e-01,  1.4274e-01,  3.2911e-01,  ...,  5.1271e-02,\n",
              "          -2.3928e-02,  1.0000e+00],\n",
              "         [-2.7759e-01,  1.0504e-01,  2.9768e-01,  ...,  5.9459e-02,\n",
              "          -6.6379e-04,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0275, -0.1390, -0.0277,  ...,  0.0535,  0.2159,  1.0000],\n",
              "         [ 0.1460, -0.0490, -0.0114,  ...,  0.2495,  0.1433,  1.0000],\n",
              "         [ 0.1335, -0.0046,  0.0137,  ...,  0.3302,  0.0135,  1.0000],\n",
              "         ...,\n",
              "         [-0.1264,  0.1450,  0.2406,  ...,  0.0515, -0.0068,  1.0000],\n",
              "         [-0.2508,  0.1221,  0.3149,  ...,  0.0531, -0.0331,  1.0000],\n",
              "         [-0.2885,  0.0951,  0.2906,  ...,  0.0557, -0.0074,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0382, -0.1490, -0.0448,  ...,  0.0611,  0.2163,  1.0000],\n",
              "         [ 0.1509, -0.0978, -0.0582,  ...,  0.2817,  0.1693,  1.0000],\n",
              "         [ 0.0978, -0.0879, -0.0572,  ...,  0.3811,  0.0800,  1.0000],\n",
              "         ...,\n",
              "         [-0.1681,  0.0284,  0.2265,  ...,  0.0939, -0.0029,  1.0000],\n",
              "         [-0.2686,  0.0415,  0.2412,  ...,  0.0739, -0.0453,  1.0000],\n",
              "         [-0.2865,  0.0434,  0.2580,  ...,  0.0290, -0.0224,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.7631e-02, -1.6313e-01, -5.4386e-02,  ...,  5.9113e-02,\n",
              "           2.1107e-01,  1.0000e+00],\n",
              "         [ 1.4845e-01, -1.1357e-01, -7.9745e-02,  ...,  2.9588e-01,\n",
              "           1.5301e-01,  1.0000e+00],\n",
              "         [ 1.0435e-01, -1.1743e-01, -8.5544e-02,  ...,  3.8766e-01,\n",
              "           7.9048e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1741e-01, -2.5597e-03,  1.8525e-01,  ...,  1.2008e-01,\n",
              "           1.0535e-02,  1.0000e+00],\n",
              "         [-2.1244e-01,  6.5126e-03,  2.0720e-01,  ...,  9.1751e-02,\n",
              "          -3.2471e-02,  1.0000e+00],\n",
              "         [-2.5996e-01,  8.8598e-04,  2.3458e-01,  ...,  3.9577e-02,\n",
              "          -2.5760e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0341, -0.1385, -0.0351,  ...,  0.0512,  0.2098,  1.0000],\n",
              "         [ 0.1426, -0.0741, -0.0521,  ...,  0.2703,  0.1489,  1.0000],\n",
              "         [ 0.1040, -0.0607, -0.0546,  ...,  0.3604,  0.0540,  1.0000],\n",
              "         ...,\n",
              "         [-0.1448,  0.0603,  0.2246,  ...,  0.0931,  0.0176,  1.0000],\n",
              "         [-0.2528,  0.0478,  0.2784,  ...,  0.0681, -0.0274,  1.0000],\n",
              "         [-0.3013,  0.0568,  0.2780,  ...,  0.0349, -0.0195,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0289, -0.1245, -0.0304,  ...,  0.0563,  0.2067,  1.0000],\n",
              "         [ 0.1412, -0.0602, -0.0324,  ...,  0.2699,  0.1371,  1.0000],\n",
              "         [ 0.1213, -0.0302, -0.0217,  ...,  0.3695,  0.0191,  1.0000],\n",
              "         ...,\n",
              "         [-0.1177,  0.0991,  0.2218,  ...,  0.0999,  0.0052,  1.0000],\n",
              "         [-0.2507,  0.0938,  0.3013,  ...,  0.0774, -0.0306,  1.0000],\n",
              "         [-0.3003,  0.0856,  0.2855,  ...,  0.0473, -0.0166,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0222, -0.1439, -0.0277,  ...,  0.0542,  0.2187,  1.0000],\n",
              "         [ 0.1599, -0.0516, -0.0135,  ...,  0.2564,  0.1436,  1.0000],\n",
              "         [ 0.1396, -0.0090,  0.0112,  ...,  0.3399,  0.0165,  1.0000],\n",
              "         ...,\n",
              "         [-0.0906,  0.1315,  0.2102,  ...,  0.0537,  0.0078,  1.0000],\n",
              "         [-0.2304,  0.1147,  0.2950,  ...,  0.0550, -0.0279,  1.0000],\n",
              "         [-0.2772,  0.0922,  0.2806,  ...,  0.0647, -0.0071,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6255e-02, -1.3116e-01, -2.7601e-02,  ...,  4.9364e-02,\n",
              "           2.1231e-01,  1.0000e+00],\n",
              "         [ 1.5492e-01, -3.9901e-02, -8.4701e-03,  ...,  2.7334e-01,\n",
              "           1.2969e-01,  1.0000e+00],\n",
              "         [ 1.5339e-01,  1.4719e-02,  4.6807e-03,  ...,  3.5616e-01,\n",
              "           4.8762e-04,  1.0000e+00],\n",
              "         ...,\n",
              "         [-6.1114e-02,  1.2092e-01,  2.1708e-01,  ...,  9.6013e-02,\n",
              "           1.5194e-02,  1.0000e+00],\n",
              "         [-2.2612e-01,  1.1956e-01,  3.2569e-01,  ...,  8.7038e-02,\n",
              "          -1.8172e-02,  1.0000e+00],\n",
              "         [-2.7562e-01,  1.0075e-01,  2.9283e-01,  ...,  6.3019e-02,\n",
              "           2.0946e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0020, -0.1443, -0.0725,  ...,  0.0365,  0.1673,  1.0000],\n",
              "         [ 0.0961, -0.1222, -0.0700,  ...,  0.1959,  0.1386,  1.0000],\n",
              "         [ 0.0358, -0.1201, -0.0961,  ...,  0.2737,  0.0952,  1.0000],\n",
              "         ...,\n",
              "         [-0.1293,  0.0280,  0.2881,  ..., -0.0491, -0.1084,  1.0000],\n",
              "         [-0.2231,  0.0918,  0.2523,  ..., -0.0457, -0.0988,  1.0000],\n",
              "         [-0.1706,  0.1142,  0.2579,  ..., -0.0724, -0.0784,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0170, -0.1470, -0.0685,  ...,  0.0464,  0.1808,  1.0000],\n",
              "         [ 0.1044, -0.1260, -0.0627,  ...,  0.2152,  0.1498,  1.0000],\n",
              "         [ 0.0360, -0.1248, -0.0772,  ...,  0.3229,  0.0883,  1.0000],\n",
              "         ...,\n",
              "         [-0.2056,  0.0468,  0.2363,  ..., -0.0484, -0.0927,  1.0000],\n",
              "         [-0.2479,  0.0743,  0.2416,  ..., -0.0393, -0.0891,  1.0000],\n",
              "         [-0.1976,  0.0782,  0.2526,  ..., -0.0404, -0.0650,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0325, -0.1484, -0.0352,  ...,  0.0600,  0.2168,  1.0000],\n",
              "         [ 0.1653, -0.0729, -0.0410,  ...,  0.2721,  0.1664,  1.0000],\n",
              "         [ 0.1194, -0.0532, -0.0307,  ...,  0.3618,  0.0675,  1.0000],\n",
              "         ...,\n",
              "         [-0.1319,  0.0783,  0.2223,  ...,  0.0823,  0.0140,  1.0000],\n",
              "         [-0.2573,  0.0649,  0.2716,  ...,  0.0656, -0.0382,  1.0000],\n",
              "         [-0.2907,  0.0575,  0.2693,  ...,  0.0427, -0.0213,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0236, -0.1296, -0.0244,  ...,  0.0434,  0.2087,  1.0000],\n",
              "         [ 0.1329, -0.0411, -0.0029,  ...,  0.2525,  0.1281,  1.0000],\n",
              "         [ 0.1222,  0.0094,  0.0204,  ...,  0.3345,  0.0034,  1.0000],\n",
              "         ...,\n",
              "         [-0.1073,  0.1306,  0.2461,  ...,  0.0741, -0.0050,  1.0000],\n",
              "         [-0.2543,  0.1203,  0.3426,  ...,  0.0613, -0.0324,  1.0000],\n",
              "         [-0.3015,  0.0928,  0.3051,  ...,  0.0480, -0.0136,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0148, -0.1228, -0.0357,  ...,  0.0455,  0.2155,  1.0000],\n",
              "         [ 0.1363, -0.0211, -0.0144,  ...,  0.2330,  0.1247,  1.0000],\n",
              "         [ 0.1411,  0.0406,  0.0081,  ...,  0.3128, -0.0300,  1.0000],\n",
              "         ...,\n",
              "         [-0.0137,  0.1322,  0.1655,  ...,  0.0429,  0.0233,  1.0000],\n",
              "         [-0.2080,  0.1377,  0.3220,  ...,  0.0526, -0.0106,  1.0000],\n",
              "         [-0.2691,  0.0997,  0.2953,  ...,  0.0606, -0.0037,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0188, -0.1476, -0.0345,  ...,  0.0568,  0.2204,  1.0000],\n",
              "         [ 0.1673, -0.0487, -0.0293,  ...,  0.2723,  0.1422,  1.0000],\n",
              "         [ 0.1469, -0.0138, -0.0092,  ...,  0.3558,  0.0170,  1.0000],\n",
              "         ...,\n",
              "         [-0.0514,  0.1012,  0.1589,  ...,  0.0611,  0.0227,  1.0000],\n",
              "         [-0.2069,  0.0970,  0.2656,  ...,  0.0599, -0.0292,  1.0000],\n",
              "         [-0.2666,  0.0747,  0.2689,  ...,  0.0672, -0.0141,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.2078e-02, -1.5022e-01, -4.0993e-02,  ...,  6.1971e-02,\n",
              "           2.1797e-01,  1.0000e+00],\n",
              "         [ 1.6834e-01, -7.9375e-02, -5.4503e-02,  ...,  2.8697e-01,\n",
              "           1.6514e-01,  1.0000e+00],\n",
              "         [ 1.2340e-01, -6.6018e-02, -4.8858e-02,  ...,  3.8119e-01,\n",
              "           6.7405e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.4040e-01,  4.8622e-02,  2.1850e-01,  ...,  8.2022e-02,\n",
              "           2.5784e-04,  1.0000e+00],\n",
              "         [-2.4322e-01,  5.2371e-02,  2.5003e-01,  ...,  7.3669e-02,\n",
              "          -3.8192e-02,  1.0000e+00],\n",
              "         [-2.8261e-01,  4.0713e-02,  2.5855e-01,  ...,  3.8048e-02,\n",
              "          -2.0552e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.1726e-02, -1.2283e-01, -3.0922e-02,  ...,  4.5595e-02,\n",
              "           2.1106e-01,  2.0000e+00],\n",
              "         [ 1.5588e-01, -2.3347e-02, -1.1526e-02,  ...,  2.6295e-01,\n",
              "           1.1734e-01,  2.0000e+00],\n",
              "         [ 1.6154e-01,  4.3036e-02,  2.1518e-03,  ...,  3.3611e-01,\n",
              "          -2.4011e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.7558e-03,  1.2030e-01,  1.7112e-01,  ...,  7.5577e-02,\n",
              "           3.3277e-02,  2.0000e+00],\n",
              "         [-2.0500e-01,  1.2425e-01,  3.2863e-01,  ...,  8.2974e-02,\n",
              "          -2.3121e-03,  2.0000e+00],\n",
              "         [-2.6202e-01,  1.0717e-01,  2.9384e-01,  ...,  6.0992e-02,\n",
              "           7.0301e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0245, -0.1581, -0.0633,  ...,  0.0535,  0.1844,  2.0000],\n",
              "         [ 0.1113, -0.1333, -0.0628,  ...,  0.2435,  0.1495,  2.0000],\n",
              "         [ 0.0436, -0.1337, -0.0792,  ...,  0.3411,  0.0898,  2.0000],\n",
              "         ...,\n",
              "         [-0.2242,  0.0497,  0.2027,  ..., -0.0074, -0.0887,  2.0000],\n",
              "         [-0.2627,  0.0676,  0.2095,  ...,  0.0041, -0.0833,  2.0000],\n",
              "         [-0.2258,  0.0374,  0.2347,  ..., -0.0252, -0.0555,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0363, -0.1516, -0.0490,  ...,  0.0653,  0.2116,  2.0000],\n",
              "         [ 0.1587, -0.1027, -0.0586,  ...,  0.2983,  0.1659,  2.0000],\n",
              "         [ 0.1050, -0.0955, -0.0567,  ...,  0.4015,  0.0779,  2.0000],\n",
              "         ...,\n",
              "         [-0.1647,  0.0344,  0.2158,  ...,  0.1075, -0.0112,  2.0000],\n",
              "         [-0.2610,  0.0564,  0.2225,  ...,  0.0865, -0.0522,  2.0000],\n",
              "         [-0.2709,  0.0403,  0.2441,  ...,  0.0338, -0.0255,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4939e-02, -1.3293e-01, -2.4407e-02,  ...,  4.4255e-02,\n",
              "           2.0842e-01,  2.0000e+00],\n",
              "         [ 1.3504e-01, -4.5279e-02, -2.4269e-03,  ...,  2.4952e-01,\n",
              "           1.3071e-01,  2.0000e+00],\n",
              "         [ 1.2007e-01, -8.3314e-04,  2.0618e-02,  ...,  3.3244e-01,\n",
              "           9.1180e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1248e-01,  1.2969e-01,  2.4567e-01,  ...,  7.3087e-02,\n",
              "          -2.1623e-03,  2.0000e+00],\n",
              "         [-2.5572e-01,  1.2217e-01,  3.3721e-01,  ...,  5.9610e-02,\n",
              "          -3.2654e-02,  2.0000e+00],\n",
              "         [-3.0304e-01,  9.3343e-02,  3.0124e-01,  ...,  4.5532e-02,\n",
              "          -1.4060e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5712e-02, -1.3768e-01, -2.7582e-02,  ...,  5.2898e-02,\n",
              "           2.1514e-01,  2.0000e+00],\n",
              "         [ 1.5153e-01, -4.7089e-02, -8.1242e-03,  ...,  2.5808e-01,\n",
              "           1.3593e-01,  2.0000e+00],\n",
              "         [ 1.3576e-01,  5.8730e-04,  1.7075e-02,  ...,  3.3903e-01,\n",
              "           9.9539e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.2469e-01,  1.4247e-01,  2.4638e-01,  ...,  6.1758e-02,\n",
              "          -1.1523e-02,  2.0000e+00],\n",
              "         [-2.5020e-01,  1.2549e-01,  3.2038e-01,  ...,  5.9976e-02,\n",
              "          -3.7186e-02,  2.0000e+00],\n",
              "         [-2.9029e-01,  9.3792e-02,  2.9537e-01,  ...,  5.7936e-02,\n",
              "          -1.1005e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0208, -0.1245, -0.0265,  ...,  0.0375,  0.2076,  2.0000],\n",
              "         [ 0.1236, -0.0242,  0.0064,  ...,  0.2285,  0.1129,  2.0000],\n",
              "         [ 0.1225,  0.0363,  0.0272,  ...,  0.3028, -0.0225,  2.0000],\n",
              "         ...,\n",
              "         [-0.0438,  0.1359,  0.2087,  ...,  0.0391,  0.0234,  2.0000],\n",
              "         [-0.2319,  0.1269,  0.3518,  ...,  0.0439, -0.0129,  2.0000],\n",
              "         [-0.2912,  0.0990,  0.3094,  ...,  0.0406, -0.0039,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0165, -0.1161, -0.0378,  ...,  0.0473,  0.2129,  2.0000],\n",
              "         [ 0.1355, -0.0204, -0.0156,  ...,  0.2428,  0.1123,  2.0000],\n",
              "         [ 0.1435,  0.0484,  0.0052,  ...,  0.3124, -0.0454,  2.0000],\n",
              "         ...,\n",
              "         [-0.0217,  0.1364,  0.1818,  ...,  0.0481,  0.0100,  2.0000],\n",
              "         [-0.2190,  0.1376,  0.3357,  ...,  0.0658, -0.0150,  2.0000],\n",
              "         [-0.2717,  0.1078,  0.3050,  ...,  0.0680,  0.0067,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0340, -0.1445, -0.0332,  ...,  0.0588,  0.2117,  2.0000],\n",
              "         [ 0.1643, -0.0691, -0.0358,  ...,  0.2685,  0.1522,  2.0000],\n",
              "         [ 0.1224, -0.0481, -0.0234,  ...,  0.3540,  0.0519,  2.0000],\n",
              "         ...,\n",
              "         [-0.1478,  0.0856,  0.2391,  ...,  0.0732, -0.0036,  2.0000],\n",
              "         [-0.2619,  0.0680,  0.2791,  ...,  0.0639, -0.0417,  2.0000],\n",
              "         [-0.2877,  0.0714,  0.2710,  ...,  0.0457, -0.0191,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0066, -0.1093, -0.0544,  ...,  0.0396,  0.2051,  2.0000],\n",
              "         [ 0.1857, -0.0024, -0.0463,  ...,  0.2552,  0.0565,  2.0000],\n",
              "         [ 0.1981,  0.0563, -0.0450,  ...,  0.3148, -0.0784,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1131,  0.0679,  0.0157,  ...,  0.0641,  0.0724,  2.0000],\n",
              "         [-0.1241,  0.1211,  0.2882,  ...,  0.1128, -0.0050,  2.0000],\n",
              "         [-0.2370,  0.1029,  0.2821,  ...,  0.0684,  0.0050,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1984e-02, -1.2134e-01, -3.2038e-02,  ...,  4.6397e-02,\n",
              "           2.0974e-01,  2.0000e+00],\n",
              "         [ 1.4985e-01, -2.2323e-02, -1.3322e-02,  ...,  2.5942e-01,\n",
              "           1.1283e-01,  2.0000e+00],\n",
              "         [ 1.5735e-01,  4.6191e-02, -8.2761e-04,  ...,  3.3204e-01,\n",
              "          -3.0997e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 5.1403e-03,  1.2272e-01,  1.6690e-01,  ...,  6.9443e-02,\n",
              "           3.3369e-02,  2.0000e+00],\n",
              "         [-2.0625e-01,  1.2513e-01,  3.2933e-01,  ...,  8.2635e-02,\n",
              "          -1.0463e-03,  2.0000e+00],\n",
              "         [-2.6111e-01,  1.0775e-01,  2.9328e-01,  ...,  6.0071e-02,\n",
              "           8.6579e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.4596e-02, -1.3074e-01, -2.8557e-02,  ...,  5.7997e-02,\n",
              "           2.1015e-01,  2.0000e+00],\n",
              "         [ 1.5636e-01, -5.4878e-02, -2.4236e-02,  ...,  2.5508e-01,\n",
              "           1.4573e-01,  2.0000e+00],\n",
              "         [ 1.2734e-01, -2.3958e-02, -9.5521e-04,  ...,  3.4167e-01,\n",
              "           3.8848e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.6026e-01,  1.2411e-01,  2.5883e-01,  ...,  6.5361e-02,\n",
              "          -9.2375e-03,  2.0000e+00],\n",
              "         [-2.6896e-01,  1.0609e-01,  3.0502e-01,  ...,  6.3294e-02,\n",
              "          -3.9318e-02,  2.0000e+00],\n",
              "         [-2.9957e-01,  8.8913e-02,  2.8474e-01,  ...,  4.2924e-02,\n",
              "          -1.6787e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.0829e-02, -1.2323e-01, -2.8626e-02,  ...,  5.4743e-02,\n",
              "           2.0678e-01,  2.0000e+00],\n",
              "         [ 1.3885e-01, -5.5296e-02, -2.8257e-02,  ...,  2.5526e-01,\n",
              "           1.4201e-01,  2.0000e+00],\n",
              "         [ 1.1861e-01, -2.5559e-02, -1.3235e-02,  ...,  3.5060e-01,\n",
              "           2.4364e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.3116e-01,  1.1082e-01,  2.3713e-01,  ...,  8.3624e-02,\n",
              "           1.7482e-03,  2.0000e+00],\n",
              "         [-2.6023e-01,  1.0017e-01,  3.1038e-01,  ...,  6.7005e-02,\n",
              "          -3.2659e-02,  2.0000e+00],\n",
              "         [-3.0487e-01,  8.8763e-02,  2.8856e-01,  ...,  4.4172e-02,\n",
              "          -1.7646e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-5.0604e-03, -1.1046e-01, -5.2190e-02,  ...,  4.6181e-02,\n",
              "           2.1384e-01,  2.0000e+00],\n",
              "         [ 1.5506e-01, -2.1549e-03, -3.6107e-02,  ...,  2.3563e-01,\n",
              "           1.0781e-01,  2.0000e+00],\n",
              "         [ 1.6190e-01,  5.4964e-02, -1.7825e-02,  ...,  3.1288e-01,\n",
              "          -5.5066e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 5.7091e-02,  1.1605e-01,  9.1366e-02,  ...,  3.2839e-02,\n",
              "           4.4908e-02,  2.0000e+00],\n",
              "         [-1.6714e-01,  1.4378e-01,  2.9216e-01,  ...,  6.8425e-02,\n",
              "          -1.2240e-03,  2.0000e+00],\n",
              "         [-2.5569e-01,  1.0733e-01,  2.8324e-01,  ...,  7.0209e-02,\n",
              "           8.0639e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0188, -0.1235, -0.0316,  ...,  0.0387,  0.2053,  2.0000],\n",
              "         [ 0.1335, -0.0177, -0.0033,  ...,  0.2401,  0.1035,  2.0000],\n",
              "         [ 0.1339,  0.0447,  0.0137,  ...,  0.3126, -0.0375,  2.0000],\n",
              "         ...,\n",
              "         [-0.0108,  0.1307,  0.1687,  ...,  0.0460,  0.0268,  2.0000],\n",
              "         [-0.2173,  0.1243,  0.3334,  ...,  0.0538, -0.0134,  2.0000],\n",
              "         [-0.2807,  0.0978,  0.3019,  ...,  0.0435, -0.0040,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3231e-02, -1.2982e-01, -2.4877e-02,  ...,  4.2592e-02,\n",
              "           2.0886e-01,  2.0000e+00],\n",
              "         [ 1.3311e-01, -3.9097e-02,  6.7494e-04,  ...,  2.4580e-01,\n",
              "           1.2721e-01,  2.0000e+00],\n",
              "         [ 1.2548e-01,  1.4029e-02,  2.4024e-02,  ...,  3.2486e-01,\n",
              "          -1.4632e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.8011e-02,  1.3423e-01,  2.3489e-01,  ...,  6.7458e-02,\n",
              "           3.4733e-03,  2.0000e+00],\n",
              "         [-2.4968e-01,  1.2661e-01,  3.4450e-01,  ...,  5.5368e-02,\n",
              "          -2.5290e-02,  2.0000e+00],\n",
              "         [-2.9829e-01,  9.5765e-02,  3.0265e-01,  ...,  4.5720e-02,\n",
              "          -9.8562e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0252, -0.1448, -0.0445,  ...,  0.0673,  0.2117,  2.0000],\n",
              "         [ 0.1598, -0.0789, -0.0687,  ...,  0.3030,  0.1385,  2.0000],\n",
              "         [ 0.1357, -0.0655, -0.0760,  ...,  0.3957,  0.0339,  2.0000],\n",
              "         ...,\n",
              "         [-0.0898,  0.0206,  0.1698,  ...,  0.1085,  0.0313,  2.0000],\n",
              "         [-0.2009,  0.0267,  0.2392,  ...,  0.0909, -0.0147,  2.0000],\n",
              "         [-0.2649,  0.0370,  0.2491,  ...,  0.0599, -0.0158,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4922e-02, -1.3081e-01, -2.6352e-02,  ...,  4.6255e-02,\n",
              "           2.1583e-01,  2.0000e+00],\n",
              "         [ 1.3070e-01, -3.8605e-02,  1.3306e-03,  ...,  2.2448e-01,\n",
              "           1.3563e-01,  2.0000e+00],\n",
              "         [ 1.2452e-01,  1.4932e-02,  2.5047e-02,  ...,  3.0116e-01,\n",
              "          -3.6785e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-7.2134e-02,  1.4919e-01,  2.2002e-01,  ...,  2.7902e-02,\n",
              "           1.6318e-02,  2.0000e+00],\n",
              "         [-2.4213e-01,  1.4129e-01,  3.3572e-01,  ...,  3.9758e-02,\n",
              "          -1.5150e-02,  2.0000e+00],\n",
              "         [-2.9299e-01,  1.0035e-01,  2.9963e-01,  ...,  5.0832e-02,\n",
              "           1.0510e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.2962e-02, -1.2390e-01, -3.0649e-02,  ...,  5.5100e-02,\n",
              "           2.0648e-01,  2.0000e+00],\n",
              "         [ 1.3820e-01, -5.5824e-02, -2.8857e-02,  ...,  2.6068e-01,\n",
              "           1.3870e-01,  2.0000e+00],\n",
              "         [ 1.1663e-01, -2.5453e-02, -1.4355e-02,  ...,  3.5409e-01,\n",
              "           2.5178e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.3713e-01,  1.0337e-01,  2.3865e-01,  ...,  8.7545e-02,\n",
              "          -1.2755e-03,  2.0000e+00],\n",
              "         [-2.5957e-01,  9.2517e-02,  3.0815e-01,  ...,  6.7634e-02,\n",
              "          -3.6932e-02,  2.0000e+00],\n",
              "         [-3.0457e-01,  8.7668e-02,  2.8941e-01,  ...,  3.7361e-02,\n",
              "          -1.6185e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.7306e-02, -1.2980e-01, -3.8083e-02,  ...,  5.0144e-02,\n",
              "           2.1947e-01,  2.0000e+00],\n",
              "         [ 1.4095e-01, -3.1096e-02, -1.2579e-02,  ...,  2.4793e-01,\n",
              "           1.3041e-01,  2.0000e+00],\n",
              "         [ 1.4303e-01,  3.1507e-02,  7.9717e-03,  ...,  3.2391e-01,\n",
              "          -1.7213e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-3.3926e-02,  1.4427e-01,  1.7871e-01,  ...,  5.6713e-02,\n",
              "           2.7999e-02,  2.0000e+00],\n",
              "         [-2.1521e-01,  1.4332e-01,  3.1769e-01,  ...,  6.6155e-02,\n",
              "          -1.3734e-02,  2.0000e+00],\n",
              "         [-2.7182e-01,  1.0166e-01,  2.9328e-01,  ...,  7.1439e-02,\n",
              "          -8.7512e-05,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3148e-02, -1.2475e-01, -3.1023e-02,  ...,  4.4498e-02,\n",
              "           2.0978e-01,  2.0000e+00],\n",
              "         [ 1.5402e-01, -2.2239e-02, -9.3845e-03,  ...,  2.6601e-01,\n",
              "           1.1311e-01,  2.0000e+00],\n",
              "         [ 1.5964e-01,  4.1097e-02,  3.5404e-03,  ...,  3.3764e-01,\n",
              "          -2.4569e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.5522e-04,  1.2109e-01,  1.6885e-01,  ...,  7.9213e-02,\n",
              "           3.0084e-02,  2.0000e+00],\n",
              "         [-2.0465e-01,  1.2581e-01,  3.2465e-01,  ...,  8.1333e-02,\n",
              "          -5.2720e-03,  2.0000e+00],\n",
              "         [-2.6283e-01,  1.0673e-01,  2.9270e-01,  ...,  5.8748e-02,\n",
              "           5.9541e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0222, -0.1284, -0.0255,  ...,  0.0410,  0.2073,  2.0000],\n",
              "         [ 0.1360, -0.0347,  0.0028,  ...,  0.2486,  0.1203,  2.0000],\n",
              "         [ 0.1294,  0.0196,  0.0241,  ...,  0.3273, -0.0086,  2.0000],\n",
              "         ...,\n",
              "         [-0.0746,  0.1308,  0.2241,  ...,  0.0682,  0.0060,  2.0000],\n",
              "         [-0.2441,  0.1282,  0.3411,  ...,  0.0565, -0.0247,  2.0000],\n",
              "         [-0.2956,  0.0998,  0.3022,  ...,  0.0445, -0.0078,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2339e-02, -1.3110e-01, -2.5337e-02,  ...,  4.1697e-02,\n",
              "           2.0757e-01,  2.0000e+00],\n",
              "         [ 1.3233e-01, -4.4484e-02,  2.1060e-03,  ...,  2.4623e-01,\n",
              "           1.2548e-01,  2.0000e+00],\n",
              "         [ 1.1824e-01,  2.6403e-04,  2.2444e-02,  ...,  3.2792e-01,\n",
              "           3.6892e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0991e-01,  1.2991e-01,  2.4036e-01,  ...,  6.7970e-02,\n",
              "          -3.8002e-03,  2.0000e+00],\n",
              "         [-2.5257e-01,  1.2724e-01,  3.3676e-01,  ...,  5.5437e-02,\n",
              "          -3.3992e-02,  2.0000e+00],\n",
              "         [-2.9851e-01,  9.6625e-02,  3.0338e-01,  ...,  4.3106e-02,\n",
              "          -1.2182e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3413e-02, -1.2490e-01, -4.0770e-02,  ...,  4.9924e-02,\n",
              "           2.1406e-01,  2.0000e+00],\n",
              "         [ 1.4806e-01, -2.7620e-02, -1.9114e-02,  ...,  2.4698e-01,\n",
              "           1.1850e-01,  2.0000e+00],\n",
              "         [ 1.5002e-01,  4.1256e-02,  6.6162e-04,  ...,  3.2726e-01,\n",
              "          -3.9629e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.6199e-02,  1.3264e-01,  1.6590e-01,  ...,  5.7536e-02,\n",
              "           2.6442e-02,  2.0000e+00],\n",
              "         [-2.0870e-01,  1.3474e-01,  3.0956e-01,  ...,  7.0885e-02,\n",
              "          -6.9911e-03,  2.0000e+00],\n",
              "         [-2.6709e-01,  1.0661e-01,  2.8726e-01,  ...,  7.5745e-02,\n",
              "           9.0951e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0722e-02, -1.3747e-01, -3.1743e-02,  ...,  5.7660e-02,\n",
              "           2.1764e-01,  2.0000e+00],\n",
              "         [ 1.4835e-01, -4.6859e-02, -9.9836e-03,  ...,  2.4558e-01,\n",
              "           1.4118e-01,  2.0000e+00],\n",
              "         [ 1.3866e-01,  4.4170e-04,  1.0193e-02,  ...,  3.2885e-01,\n",
              "           3.8390e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1326e-01,  1.5543e-01,  2.3918e-01,  ...,  6.7616e-02,\n",
              "          -5.3251e-03,  2.0000e+00],\n",
              "         [-2.4819e-01,  1.3277e-01,  3.2345e-01,  ...,  6.3906e-02,\n",
              "          -3.2443e-02,  2.0000e+00],\n",
              "         [-2.7730e-01,  1.0432e-01,  2.8786e-01,  ...,  6.9137e-02,\n",
              "          -2.5377e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0203, -0.1292, -0.0285,  ...,  0.0428,  0.2080,  2.0000],\n",
              "         [ 0.1376, -0.0356, -0.0065,  ...,  0.2515,  0.1227,  2.0000],\n",
              "         [ 0.1319,  0.0208,  0.0146,  ...,  0.3342, -0.0148,  2.0000],\n",
              "         ...,\n",
              "         [-0.0526,  0.1271,  0.2034,  ...,  0.0752,  0.0145,  2.0000],\n",
              "         [-0.2332,  0.1246,  0.3337,  ...,  0.0659, -0.0175,  2.0000],\n",
              "         [-0.2886,  0.0945,  0.2977,  ...,  0.0516, -0.0085,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.0038e-02, -1.1978e-01, -3.0170e-02,  ...,  3.5418e-02,\n",
              "           2.0429e-01,  2.0000e+00],\n",
              "         [ 1.2174e-01, -2.5462e-02,  2.1717e-03,  ...,  2.2962e-01,\n",
              "           1.0187e-01,  2.0000e+00],\n",
              "         [ 1.2630e-01,  4.3784e-02,  2.3069e-02,  ...,  3.0228e-01,\n",
              "          -4.4056e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.9575e-02,  1.3173e-01,  1.9335e-01,  ...,  3.7330e-02,\n",
              "           2.3410e-02,  2.0000e+00],\n",
              "         [-2.2570e-01,  1.3060e-01,  3.4722e-01,  ...,  4.5026e-02,\n",
              "          -1.2066e-02,  2.0000e+00],\n",
              "         [-2.8838e-01,  9.9009e-02,  3.0709e-01,  ...,  3.9304e-02,\n",
              "          -1.5556e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5140e-02, -1.2950e-01, -2.3249e-02,  ...,  4.0600e-02,\n",
              "           2.0807e-01,  2.0000e+00],\n",
              "         [ 1.2812e-01, -4.5036e-02, -1.5362e-04,  ...,  2.3949e-01,\n",
              "           1.3001e-01,  2.0000e+00],\n",
              "         [ 1.1218e-01, -1.1442e-03,  2.2888e-02,  ...,  3.2011e-01,\n",
              "           9.2831e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.2808e-01,  1.3241e-01,  2.5897e-01,  ...,  6.0271e-02,\n",
              "          -7.9105e-03,  2.0000e+00],\n",
              "         [-2.6024e-01,  1.2853e-01,  3.4525e-01,  ...,  5.0657e-02,\n",
              "          -3.7894e-02,  2.0000e+00],\n",
              "         [-3.0402e-01,  9.4691e-02,  3.0927e-01,  ...,  4.1007e-02,\n",
              "          -1.6148e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.1330e-02, -1.3249e-01, -3.6487e-02,  ...,  6.9723e-02,\n",
              "           2.1432e-01,  2.0000e+00],\n",
              "         [ 1.7167e-01, -5.2387e-02, -3.9597e-02,  ...,  2.9093e-01,\n",
              "           1.4308e-01,  2.0000e+00],\n",
              "         [ 1.4459e-01, -2.7026e-02, -2.7210e-02,  ...,  3.8596e-01,\n",
              "           3.4624e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1478e-01,  9.5964e-02,  2.2172e-01,  ...,  9.5825e-02,\n",
              "          -1.1568e-03,  2.0000e+00],\n",
              "         [-2.5147e-01,  8.2127e-02,  2.8214e-01,  ...,  7.9910e-02,\n",
              "          -3.8357e-02,  2.0000e+00],\n",
              "         [-2.8393e-01,  8.6258e-02,  2.7468e-01,  ...,  5.6678e-02,\n",
              "          -1.4903e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.3716e-02, -1.3651e-01, -2.7361e-02,  ...,  4.7711e-02,\n",
              "           2.0980e-01,  2.0000e+00],\n",
              "         [ 1.4140e-01, -4.7996e-02, -1.2587e-02,  ...,  2.6462e-01,\n",
              "           1.3506e-01,  2.0000e+00],\n",
              "         [ 1.2449e-01, -8.8251e-03,  4.8812e-03,  ...,  3.5186e-01,\n",
              "           1.3921e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0908e-01,  1.1869e-01,  2.3137e-01,  ...,  8.6558e-02,\n",
              "          -1.8466e-03,  2.0000e+00],\n",
              "         [-2.4555e-01,  1.0760e-01,  3.1717e-01,  ...,  6.8155e-02,\n",
              "          -3.1597e-02,  2.0000e+00],\n",
              "         [-2.9704e-01,  8.5623e-02,  2.9229e-01,  ...,  5.1454e-02,\n",
              "          -1.6154e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0168, -0.1324, -0.0327,  ...,  0.0526,  0.2189,  2.0000],\n",
              "         [ 0.1489, -0.0421, -0.0079,  ...,  0.2280,  0.1362,  2.0000],\n",
              "         [ 0.1342,  0.0154,  0.0143,  ...,  0.3078, -0.0168,  2.0000],\n",
              "         ...,\n",
              "         [-0.0318,  0.1654,  0.1808,  ...,  0.0304,  0.0264,  2.0000],\n",
              "         [-0.2139,  0.1436,  0.3080,  ...,  0.0432, -0.0078,  2.0000],\n",
              "         [-0.2628,  0.1078,  0.2841,  ...,  0.0695,  0.0033,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0232, -0.1311, -0.0296,  ...,  0.0506,  0.2178,  2.0000],\n",
              "         [ 0.1350, -0.0428, -0.0060,  ...,  0.2415,  0.1334,  2.0000],\n",
              "         [ 0.1327,  0.0151,  0.0152,  ...,  0.3206, -0.0091,  2.0000],\n",
              "         ...,\n",
              "         [-0.0849,  0.1437,  0.2286,  ...,  0.0548,  0.0048,  2.0000],\n",
              "         [-0.2472,  0.1374,  0.3402,  ...,  0.0560, -0.0229,  2.0000],\n",
              "         [-0.2875,  0.1026,  0.3005,  ...,  0.0633,  0.0034,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-7.7940e-03, -1.1644e-01, -4.3583e-02,  ...,  5.3988e-02,\n",
              "           2.1529e-01,  2.0000e+00],\n",
              "         [ 1.4510e-01, -2.8724e-02, -2.1688e-02,  ...,  2.2320e-01,\n",
              "           1.2777e-01,  2.0000e+00],\n",
              "         [ 1.3413e-01,  3.0275e-02, -3.5851e-03,  ...,  3.0367e-01,\n",
              "          -3.3799e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.8159e-03,  1.5033e-01,  1.5748e-01,  ...,  4.3064e-02,\n",
              "           3.6916e-02,  2.0000e+00],\n",
              "         [-1.9866e-01,  1.4177e-01,  3.1284e-01,  ...,  7.0267e-02,\n",
              "           2.0794e-03,  2.0000e+00],\n",
              "         [-2.6059e-01,  1.0730e-01,  2.8934e-01,  ...,  7.2476e-02,\n",
              "           6.2500e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1546, -0.0549,  ...,  0.0676,  0.2118,  2.0000],\n",
              "         [ 0.1550, -0.1088, -0.0716,  ...,  0.3008,  0.1534,  2.0000],\n",
              "         [ 0.0998, -0.1045, -0.0717,  ...,  0.4085,  0.0659,  2.0000],\n",
              "         ...,\n",
              "         [-0.1523,  0.0220,  0.2003,  ...,  0.1122, -0.0119,  2.0000],\n",
              "         [-0.2452,  0.0473,  0.2093,  ...,  0.0946, -0.0532,  2.0000],\n",
              "         [-0.2646,  0.0296,  0.2369,  ...,  0.0357, -0.0292,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.0961e-02, -1.1829e-01, -3.2807e-02,  ...,  4.4311e-02,\n",
              "           2.0977e-01,  2.0000e+00],\n",
              "         [ 1.4979e-01, -1.9967e-02, -1.3982e-02,  ...,  2.5453e-01,\n",
              "           1.0565e-01,  2.0000e+00],\n",
              "         [ 1.6013e-01,  5.0606e-02, -1.6476e-03,  ...,  3.2396e-01,\n",
              "          -4.1054e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.7676e-02,  1.2082e-01,  1.5175e-01,  ...,  6.2007e-02,\n",
              "           3.9840e-02,  2.0000e+00],\n",
              "         [-1.9552e-01,  1.2543e-01,  3.2777e-01,  ...,  8.4084e-02,\n",
              "           9.3515e-04,  2.0000e+00],\n",
              "         [-2.5974e-01,  1.0983e-01,  2.9543e-01,  ...,  5.8481e-02,\n",
              "           8.4541e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1232, -0.0305,  ...,  0.0530,  0.2052,  2.0000],\n",
              "         [ 0.1313, -0.0592, -0.0301,  ...,  0.2544,  0.1392,  2.0000],\n",
              "         [ 0.1099, -0.0305, -0.0187,  ...,  0.3472,  0.0252,  2.0000],\n",
              "         ...,\n",
              "         [-0.1538,  0.1074,  0.2495,  ...,  0.0962, -0.0082,  2.0000],\n",
              "         [-0.2704,  0.1008,  0.3127,  ...,  0.0733, -0.0401,  2.0000],\n",
              "         [-0.3086,  0.0884,  0.2907,  ...,  0.0343, -0.0195,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0219, -0.1414, -0.0350,  ...,  0.0599,  0.2181,  2.0000],\n",
              "         [ 0.1617, -0.0477, -0.0246,  ...,  0.2805,  0.1385,  2.0000],\n",
              "         [ 0.1474, -0.0059, -0.0042,  ...,  0.3728,  0.0086,  2.0000],\n",
              "         ...,\n",
              "         [-0.0876,  0.1180,  0.2035,  ...,  0.0837,  0.0038,  2.0000],\n",
              "         [-0.2271,  0.1099,  0.2867,  ...,  0.0785, -0.0296,  2.0000],\n",
              "         [-0.2783,  0.0937,  0.2781,  ...,  0.0718, -0.0057,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7028e-02, -1.1831e-01, -3.5715e-02,  ...,  3.4030e-02,\n",
              "           2.0591e-01,  2.0000e+00],\n",
              "         [ 1.2871e-01, -1.4642e-02, -6.8186e-03,  ...,  2.3101e-01,\n",
              "           9.6917e-02,  2.0000e+00],\n",
              "         [ 1.3247e-01,  5.2233e-02,  8.5223e-03,  ...,  3.0200e-01,\n",
              "          -4.9011e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4099e-03,  1.2597e-01,  1.5044e-01,  ...,  3.3086e-02,\n",
              "           3.1827e-02,  2.0000e+00],\n",
              "         [-2.1058e-01,  1.2719e-01,  3.3521e-01,  ...,  4.9593e-02,\n",
              "          -9.6608e-03,  2.0000e+00],\n",
              "         [-2.7849e-01,  9.3981e-02,  3.0178e-01,  ...,  4.5628e-02,\n",
              "          -5.0128e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1031e-02, -1.3325e-01, -2.7742e-02,  ...,  4.5719e-02,\n",
              "           2.0959e-01,  2.0000e+00],\n",
              "         [ 1.4122e-01, -3.8571e-02, -5.7447e-03,  ...,  2.6215e-01,\n",
              "           1.2744e-01,  2.0000e+00],\n",
              "         [ 1.3642e-01,  1.2067e-02,  1.4370e-02,  ...,  3.4108e-01,\n",
              "           2.0093e-04,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.8149e-02,  1.2823e-01,  2.3427e-01,  ...,  9.0642e-02,\n",
              "           9.2994e-04,  2.0000e+00],\n",
              "         [-2.4301e-01,  1.1623e-01,  3.3800e-01,  ...,  7.5918e-02,\n",
              "          -2.7880e-02,  2.0000e+00],\n",
              "         [-2.9056e-01,  9.2302e-02,  2.9836e-01,  ...,  5.4757e-02,\n",
              "          -1.0007e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 4.5428e-02, -1.6993e-01, -9.3658e-02,  ..., -7.8688e-04,\n",
              "           1.8093e-01,  2.0000e+00],\n",
              "         [ 2.7410e-01, -2.7278e-03, -8.5768e-02,  ...,  1.3621e-01,\n",
              "           1.3454e-02,  2.0000e+00],\n",
              "         [ 2.7260e-01,  4.0870e-02, -6.9693e-02,  ...,  1.8284e-01,\n",
              "          -1.0142e-01,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.3804e-01,  5.9146e-03, -1.1371e-01,  ...,  5.2360e-02,\n",
              "           7.0726e-02,  2.0000e+00],\n",
              "         [-3.3494e-02,  8.6783e-02,  1.8364e-01,  ...,  1.1102e-01,\n",
              "          -3.5677e-02,  2.0000e+00],\n",
              "         [-2.2920e-01,  4.2773e-02,  2.9708e-01,  ...,  6.8888e-02,\n",
              "          -1.8977e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0078, -0.1099, -0.0583,  ...,  0.0303,  0.1914,  2.0000],\n",
              "         [ 0.1847, -0.0022, -0.0439,  ...,  0.2320,  0.0345,  2.0000],\n",
              "         [ 0.1867,  0.0452, -0.0421,  ...,  0.2945, -0.1002,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0857,  0.0643,  0.0410,  ...,  0.0333,  0.0589,  2.0000],\n",
              "         [-0.1344,  0.1189,  0.3021,  ...,  0.0888, -0.0166,  2.0000],\n",
              "         [-0.2508,  0.0884,  0.2915,  ...,  0.0576, -0.0114,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1572e-02, -1.2247e-01, -4.0037e-02,  ...,  4.9952e-02,\n",
              "           2.1378e-01,  2.0000e+00],\n",
              "         [ 1.3534e-01, -2.5063e-02, -1.7213e-02,  ...,  2.3468e-01,\n",
              "           1.2515e-01,  2.0000e+00],\n",
              "         [ 1.3789e-01,  3.6888e-02,  1.7329e-03,  ...,  3.1211e-01,\n",
              "          -3.0578e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1464e-02,  1.4188e-01,  1.5880e-01,  ...,  4.3698e-02,\n",
              "           3.8517e-02,  2.0000e+00],\n",
              "         [-2.0999e-01,  1.4381e-01,  3.1989e-01,  ...,  6.1799e-02,\n",
              "          -4.4498e-03,  2.0000e+00],\n",
              "         [-2.6768e-01,  1.0274e-01,  2.9668e-01,  ...,  6.4014e-02,\n",
              "          -1.6516e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0173, -0.1301, -0.0378,  ...,  0.0536,  0.2165,  2.0000],\n",
              "         [ 0.1526, -0.0236, -0.0165,  ...,  0.2579,  0.1245,  2.0000],\n",
              "         [ 0.1562,  0.0424,  0.0041,  ...,  0.3369, -0.0253,  2.0000],\n",
              "         ...,\n",
              "         [-0.0429,  0.1470,  0.1831,  ...,  0.0536,  0.0133,  2.0000],\n",
              "         [-0.2110,  0.1376,  0.2997,  ...,  0.0581, -0.0163,  2.0000],\n",
              "         [-0.2643,  0.1041,  0.2835,  ...,  0.0708,  0.0053,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 2.5490e-03, -1.0965e-01, -5.5241e-02,  ...,  5.1992e-02,\n",
              "           2.1344e-01,  2.0000e+00],\n",
              "         [ 1.5691e-01, -1.5913e-02, -4.4943e-02,  ...,  2.1470e-01,\n",
              "           1.0983e-01,  2.0000e+00],\n",
              "         [ 1.4194e-01,  3.4917e-02, -2.8971e-02,  ...,  3.0597e-01,\n",
              "          -5.5129e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 4.6027e-02,  1.2864e-01,  1.0077e-01,  ...,  3.5889e-02,\n",
              "           4.5141e-02,  2.0000e+00],\n",
              "         [-1.7029e-01,  1.3945e-01,  2.8464e-01,  ...,  8.3933e-02,\n",
              "           1.4604e-04,  2.0000e+00],\n",
              "         [-2.5175e-01,  1.0465e-01,  2.8016e-01,  ...,  6.9823e-02,\n",
              "           1.0412e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.4290e-02, -1.2287e-01, -2.3046e-02,  ...,  3.6889e-02,\n",
              "           2.0695e-01,  2.0000e+00],\n",
              "         [ 1.2150e-01, -3.4252e-02,  7.6022e-03,  ...,  2.2980e-01,\n",
              "           1.1759e-01,  2.0000e+00],\n",
              "         [ 1.1703e-01,  2.6899e-02,  3.1514e-02,  ...,  3.0478e-01,\n",
              "          -1.7810e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.0579e-02,  1.3730e-01,  2.4167e-01,  ...,  4.5756e-02,\n",
              "           7.9500e-04,  2.0000e+00],\n",
              "         [-2.4896e-01,  1.3533e-01,  3.6338e-01,  ...,  3.8714e-02,\n",
              "          -2.7157e-02,  2.0000e+00],\n",
              "         [-3.0220e-01,  1.0099e-01,  3.1705e-01,  ...,  4.0998e-02,\n",
              "          -7.5018e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3810e-02, -1.1889e-01, -3.9098e-02,  ...,  4.8548e-02,\n",
              "           2.1145e-01,  2.0000e+00],\n",
              "         [ 1.4557e-01, -1.8813e-02, -1.3514e-02,  ...,  2.2778e-01,\n",
              "           1.1437e-01,  2.0000e+00],\n",
              "         [ 1.4174e-01,  4.4162e-02,  5.5522e-04,  ...,  2.9854e-01,\n",
              "          -3.7994e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2443e-02,  1.5231e-01,  1.4814e-01,  ...,  3.3390e-02,\n",
              "           2.9892e-02,  2.0000e+00],\n",
              "         [-2.0692e-01,  1.5662e-01,  3.1663e-01,  ...,  6.2999e-02,\n",
              "          -7.5167e-03,  2.0000e+00],\n",
              "         [-2.6943e-01,  1.1167e-01,  2.9508e-01,  ...,  7.2192e-02,\n",
              "           4.0485e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0087, -0.1169, -0.0425,  ...,  0.0559,  0.2180,  2.0000],\n",
              "         [ 0.1378, -0.0338, -0.0233,  ...,  0.2228,  0.1329,  2.0000],\n",
              "         [ 0.1213,  0.0265, -0.0043,  ...,  0.3072, -0.0315,  2.0000],\n",
              "         ...,\n",
              "         [-0.0068,  0.1493,  0.1648,  ...,  0.0371,  0.0358,  2.0000],\n",
              "         [-0.1974,  0.1464,  0.3121,  ...,  0.0635,  0.0044,  2.0000],\n",
              "         [-0.2605,  0.1058,  0.2906,  ...,  0.0782,  0.0090,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0185, -0.1376, -0.0360,  ...,  0.0605,  0.2218,  2.0000],\n",
              "         [ 0.1494, -0.0479, -0.0140,  ...,  0.2416,  0.1404,  2.0000],\n",
              "         [ 0.1302,  0.0039,  0.0040,  ...,  0.3248, -0.0127,  2.0000],\n",
              "         ...,\n",
              "         [-0.0262,  0.1666,  0.1727,  ...,  0.0355,  0.0323,  2.0000],\n",
              "         [-0.2023,  0.1423,  0.2961,  ...,  0.0462, -0.0059,  2.0000],\n",
              "         [-0.2557,  0.1039,  0.2727,  ...,  0.0767,  0.0039,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0035, -0.1080, -0.0525,  ...,  0.0250,  0.1935,  2.0000],\n",
              "         [ 0.1602, -0.0037, -0.0275,  ...,  0.2220,  0.0456,  2.0000],\n",
              "         [ 0.1666,  0.0519, -0.0244,  ...,  0.2875, -0.0950,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0526,  0.0837,  0.0751,  ...,  0.0143,  0.0571,  2.0000],\n",
              "         [-0.1616,  0.1253,  0.3225,  ...,  0.0597, -0.0087,  2.0000],\n",
              "         [-0.2652,  0.0906,  0.3036,  ...,  0.0472, -0.0075,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0163, -0.1196, -0.0373,  ...,  0.0468,  0.2148,  2.0000],\n",
              "         [ 0.1356, -0.0192, -0.0116,  ...,  0.2346,  0.1154,  2.0000],\n",
              "         [ 0.1417,  0.0477,  0.0065,  ...,  0.3069, -0.0388,  2.0000],\n",
              "         ...,\n",
              "         [-0.0375,  0.1368,  0.1811,  ...,  0.0484,  0.0167,  2.0000],\n",
              "         [-0.2237,  0.1447,  0.3277,  ...,  0.0586, -0.0131,  2.0000],\n",
              "         [-0.2757,  0.1066,  0.3009,  ...,  0.0625,  0.0080,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7690e-02, -1.2181e-01, -3.2545e-02,  ...,  3.5468e-02,\n",
              "           2.0617e-01,  2.0000e+00],\n",
              "         [ 1.2637e-01, -1.9489e-02,  1.0287e-03,  ...,  2.2450e-01,\n",
              "           9.9126e-02,  2.0000e+00],\n",
              "         [ 1.3061e-01,  4.5677e-02,  1.9239e-02,  ...,  2.9434e-01,\n",
              "          -4.7298e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-9.9646e-03,  1.3373e-01,  1.7011e-01,  ...,  2.6888e-02,\n",
              "           3.7022e-02,  2.0000e+00],\n",
              "         [-2.1454e-01,  1.3413e-01,  3.3880e-01,  ...,  4.1748e-02,\n",
              "          -4.6949e-03,  2.0000e+00],\n",
              "         [-2.8085e-01,  9.9306e-02,  3.0357e-01,  ...,  3.9221e-02,\n",
              "           7.7687e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1205e-02, -1.3972e-01, -3.0338e-02,  ...,  5.3432e-02,\n",
              "           2.1527e-01,  2.0000e+00],\n",
              "         [ 1.5428e-01, -5.0313e-02, -1.3504e-02,  ...,  2.6827e-01,\n",
              "           1.3207e-01,  2.0000e+00],\n",
              "         [ 1.4423e-01,  2.8957e-03,  7.1141e-03,  ...,  3.5667e-01,\n",
              "          -9.1216e-04,  2.0000e+00],\n",
              "         ...,\n",
              "         [-9.0625e-02,  1.3788e-01,  2.1999e-01,  ...,  7.2307e-02,\n",
              "          -3.6512e-03,  2.0000e+00],\n",
              "         [-2.3623e-01,  1.2528e-01,  3.0821e-01,  ...,  7.1654e-02,\n",
              "          -3.0164e-02,  2.0000e+00],\n",
              "         [-2.7840e-01,  9.8382e-02,  2.8577e-01,  ...,  7.0395e-02,\n",
              "          -3.6510e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.8464e-02, -1.2514e-01, -2.9122e-02,  ...,  3.7433e-02,\n",
              "           2.0785e-01,  2.0000e+00],\n",
              "         [ 1.2785e-01, -2.4001e-02,  1.9812e-03,  ...,  2.2785e-01,\n",
              "           1.0980e-01,  2.0000e+00],\n",
              "         [ 1.2988e-01,  3.8749e-02,  2.2096e-02,  ...,  2.9983e-01,\n",
              "          -3.1654e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-3.1614e-02,  1.3289e-01,  1.9568e-01,  ...,  4.1008e-02,\n",
              "           2.8233e-02,  2.0000e+00],\n",
              "         [-2.2535e-01,  1.2887e-01,  3.4664e-01,  ...,  4.6783e-02,\n",
              "          -7.7082e-03,  2.0000e+00],\n",
              "         [-2.8447e-01,  9.8042e-02,  3.0432e-01,  ...,  4.2053e-02,\n",
              "          -9.7061e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0179, -0.1229, -0.0373,  ...,  0.0560,  0.2197,  2.0000],\n",
              "         [ 0.1394, -0.0372, -0.0163,  ...,  0.2190,  0.1370,  2.0000],\n",
              "         [ 0.1215,  0.0182,  0.0045,  ...,  0.3053, -0.0212,  2.0000],\n",
              "         ...,\n",
              "         [-0.0178,  0.1562,  0.1643,  ...,  0.0365,  0.0404,  2.0000],\n",
              "         [-0.2096,  0.1484,  0.3087,  ...,  0.0569,  0.0027,  2.0000],\n",
              "         [-0.2659,  0.1089,  0.2843,  ...,  0.0762,  0.0079,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0337, -0.1349, -0.0330,  ...,  0.0518,  0.2088,  2.0000],\n",
              "         [ 0.1418, -0.0673, -0.0406,  ...,  0.2670,  0.1453,  2.0000],\n",
              "         [ 0.1071, -0.0471, -0.0375,  ...,  0.3556,  0.0443,  2.0000],\n",
              "         ...,\n",
              "         [-0.1389,  0.0724,  0.2294,  ...,  0.0936,  0.0134,  2.0000],\n",
              "         [-0.2559,  0.0629,  0.2891,  ...,  0.0704, -0.0344,  2.0000],\n",
              "         [-0.3032,  0.0704,  0.2857,  ...,  0.0349, -0.0172,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-6.7493e-03, -1.1480e-01, -4.2911e-02,  ...,  3.9044e-02,\n",
              "           2.0293e-01,  2.0000e+00],\n",
              "         [ 1.5185e-01, -9.5941e-03, -2.3678e-02,  ...,  2.2730e-01,\n",
              "           8.0150e-02,  2.0000e+00],\n",
              "         [ 1.5488e-01,  5.1056e-02, -1.3971e-02,  ...,  3.0234e-01,\n",
              "          -6.7802e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 4.3428e-02,  1.0975e-01,  1.0019e-01,  ...,  2.2119e-02,\n",
              "           5.9476e-02,  2.0000e+00],\n",
              "         [-1.8133e-01,  1.2128e-01,  3.1275e-01,  ...,  6.3963e-02,\n",
              "           2.2175e-03,  2.0000e+00],\n",
              "         [-2.6029e-01,  9.4994e-02,  2.8864e-01,  ...,  4.9347e-02,\n",
              "          -1.5888e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.2105e-02, -1.1883e-01, -3.9811e-02,  ...,  5.5059e-02,\n",
              "           2.1786e-01,  2.0000e+00],\n",
              "         [ 1.3777e-01, -3.3254e-02, -1.8441e-02,  ...,  2.1038e-01,\n",
              "           1.3194e-01,  2.0000e+00],\n",
              "         [ 1.1775e-01,  2.3548e-02, -1.9077e-03,  ...,  2.9811e-01,\n",
              "          -2.8714e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-3.6912e-03,  1.5432e-01,  1.5920e-01,  ...,  2.7145e-02,\n",
              "           4.2476e-02,  2.0000e+00],\n",
              "         [-1.9672e-01,  1.5245e-01,  3.1455e-01,  ...,  5.5940e-02,\n",
              "           5.4145e-03,  2.0000e+00],\n",
              "         [-2.5936e-01,  1.0915e-01,  2.8944e-01,  ...,  7.3259e-02,\n",
              "           5.2172e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0175, -0.1130, -0.0363,  ...,  0.0288,  0.2000,  2.0000],\n",
              "         [ 0.1291, -0.0073, -0.0045,  ...,  0.2228,  0.0769,  2.0000],\n",
              "         [ 0.1432,  0.0608,  0.0101,  ...,  0.2881, -0.0720,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0050,  0.1180,  0.1420,  ...,  0.0126,  0.0360,  2.0000],\n",
              "         [-0.2019,  0.1319,  0.3471,  ...,  0.0403, -0.0112,  2.0000],\n",
              "         [-0.2786,  0.0957,  0.3152,  ...,  0.0385, -0.0046,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0243, -0.1233, -0.0241,  ...,  0.0377,  0.2076,  2.0000],\n",
              "         [ 0.1204, -0.0354,  0.0040,  ...,  0.2300,  0.1178,  2.0000],\n",
              "         [ 0.1166,  0.0242,  0.0273,  ...,  0.3095, -0.0201,  2.0000],\n",
              "         ...,\n",
              "         [-0.0747,  0.1330,  0.2354,  ...,  0.0471,  0.0050,  2.0000],\n",
              "         [-0.2475,  0.1345,  0.3616,  ...,  0.0413, -0.0231,  2.0000],\n",
              "         [-0.3006,  0.1004,  0.3147,  ...,  0.0399, -0.0044,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0238, -0.1297, -0.0246,  ...,  0.0400,  0.2083,  2.0000],\n",
              "         [ 0.1276, -0.0370,  0.0067,  ...,  0.2336,  0.1237,  2.0000],\n",
              "         [ 0.1237,  0.0180,  0.0296,  ...,  0.3095, -0.0111,  2.0000],\n",
              "         ...,\n",
              "         [-0.0872,  0.1401,  0.2455,  ...,  0.0560,  0.0035,  2.0000],\n",
              "         [-0.2492,  0.1304,  0.3575,  ...,  0.0482, -0.0247,  2.0000],\n",
              "         [-0.2969,  0.0974,  0.3075,  ...,  0.0414, -0.0072,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0087, -0.1160, -0.0581,  ...,  0.0459,  0.2102,  2.0000],\n",
              "         [ 0.1858, -0.0180, -0.0478,  ...,  0.2281,  0.0789,  2.0000],\n",
              "         [ 0.1705,  0.0332, -0.0399,  ...,  0.3090, -0.0673,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0936,  0.0829,  0.0805,  ...,  0.0289,  0.0430,  2.0000],\n",
              "         [-0.1346,  0.1198,  0.2907,  ...,  0.0837, -0.0131,  2.0000],\n",
              "         [-0.2419,  0.1053,  0.2813,  ...,  0.0600, -0.0038,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0165, -0.1295, -0.0272,  ...,  0.0472,  0.2114,  2.0000],\n",
              "         [ 0.1533, -0.0356, -0.0056,  ...,  0.2681,  0.1264,  2.0000],\n",
              "         [ 0.1525,  0.0215,  0.0088,  ...,  0.3473, -0.0023,  2.0000],\n",
              "         ...,\n",
              "         [-0.0480,  0.1225,  0.2101,  ...,  0.0872,  0.0201,  2.0000],\n",
              "         [-0.2258,  0.1229,  0.3310,  ...,  0.0816, -0.0143,  2.0000],\n",
              "         [-0.2751,  0.1021,  0.2953,  ...,  0.0604,  0.0033,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0308, -0.1519, -0.0584,  ...,  0.0569,  0.1935,  2.0000],\n",
              "         [ 0.1203, -0.1203, -0.0611,  ...,  0.2601,  0.1541,  2.0000],\n",
              "         [ 0.0536, -0.1170, -0.0694,  ...,  0.3623,  0.0879,  2.0000],\n",
              "         ...,\n",
              "         [-0.2323,  0.0487,  0.1988,  ...,  0.0368, -0.0775,  2.0000],\n",
              "         [-0.2752,  0.0650,  0.2113,  ...,  0.0378, -0.0770,  2.0000],\n",
              "         [-0.2460,  0.0413,  0.2389,  ..., -0.0054, -0.0472,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.9280e-02, -1.5122e-01, -5.9372e-02,  ...,  6.2077e-02,\n",
              "           1.9499e-01,  2.0000e+00],\n",
              "         [ 1.2925e-01, -1.2245e-01, -6.3685e-02,  ...,  2.7155e-01,\n",
              "           1.5743e-01,  2.0000e+00],\n",
              "         [ 5.9785e-02, -1.1626e-01, -6.7772e-02,  ...,  3.7841e-01,\n",
              "           8.8319e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.1433e-01,  5.3360e-02,  1.8225e-01,  ...,  3.0329e-02,\n",
              "          -7.5391e-02,  2.0000e+00],\n",
              "         [-2.6526e-01,  6.8738e-02,  2.0451e-01,  ...,  4.0626e-02,\n",
              "          -6.9451e-02,  2.0000e+00],\n",
              "         [-2.4212e-01,  4.5409e-02,  2.3320e-01,  ..., -2.5430e-04,\n",
              "          -4.2872e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0259, -0.1326, -0.0796,  ...,  0.0560,  0.2064,  2.0000],\n",
              "         [ 0.2101, -0.0069, -0.0705,  ...,  0.2409,  0.0608,  2.0000],\n",
              "         [ 0.1807,  0.0252, -0.0664,  ...,  0.3348, -0.0938,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1643,  0.0467,  0.0411,  ...,  0.0580,  0.0425,  2.0000],\n",
              "         [-0.0804,  0.1157,  0.2504,  ...,  0.0996, -0.0086,  2.0000],\n",
              "         [-0.2105,  0.0748,  0.2647,  ...,  0.0787, -0.0103,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.5702e-03, -1.0781e-01, -5.6410e-02,  ...,  2.4482e-02,\n",
              "           1.9899e-01,  2.0000e+00],\n",
              "         [ 1.5230e-01, -6.6181e-03, -2.8903e-02,  ...,  2.1732e-01,\n",
              "           6.0890e-02,  2.0000e+00],\n",
              "         [ 1.6242e-01,  5.0100e-02, -2.5909e-02,  ...,  2.8655e-01,\n",
              "          -8.7928e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 5.6397e-02,  8.5168e-02,  6.7812e-02,  ...,  1.5956e-02,\n",
              "           6.6211e-02,  2.0000e+00],\n",
              "         [-1.6055e-01,  1.2702e-01,  3.0842e-01,  ...,  6.2838e-02,\n",
              "          -2.1741e-03,  2.0000e+00],\n",
              "         [-2.6350e-01,  8.7669e-02,  3.0036e-01,  ...,  5.3290e-02,\n",
              "          -4.6338e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0306, -0.1608, -0.0560,  ...,  0.0654,  0.2162,  2.0000],\n",
              "         [ 0.1555, -0.1060, -0.0763,  ...,  0.3045,  0.1575,  2.0000],\n",
              "         [ 0.1062, -0.1053, -0.0830,  ...,  0.4059,  0.0690,  2.0000],\n",
              "         ...,\n",
              "         [-0.1242,  0.0021,  0.1917,  ...,  0.0994, -0.0085,  2.0000],\n",
              "         [-0.2160,  0.0239,  0.2007,  ...,  0.0866, -0.0409,  2.0000],\n",
              "         [-0.2557,  0.0100,  0.2297,  ...,  0.0413, -0.0223,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 5.1773e-02, -2.1937e-01, -1.1740e-01,  ..., -1.6688e-02,\n",
              "           1.9865e-01,  2.0000e+00],\n",
              "         [ 3.1094e-01,  2.5892e-02, -9.5518e-02,  ...,  2.8491e-02,\n",
              "           1.0018e-02,  2.0000e+00],\n",
              "         [ 3.2185e-01,  5.9332e-02, -7.9205e-02,  ...,  8.7513e-02,\n",
              "          -6.4950e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.7097e-01, -7.2549e-03, -1.3598e-01,  ...,  5.0914e-02,\n",
              "           5.9646e-02,  2.0000e+00],\n",
              "         [ 3.3077e-02,  5.8913e-02,  1.0115e-01,  ...,  1.1072e-01,\n",
              "          -9.1227e-03,  2.0000e+00],\n",
              "         [-1.4379e-01,  1.6279e-02,  2.8412e-01,  ...,  4.6764e-02,\n",
              "           1.6116e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0119, -0.1113, -0.0602,  ...,  0.0541,  0.2099,  2.0000],\n",
              "         [ 0.1680, -0.0161, -0.0550,  ...,  0.2268,  0.0944,  2.0000],\n",
              "         [ 0.1598,  0.0333, -0.0427,  ...,  0.3074, -0.0662,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0911,  0.1039,  0.0559,  ...,  0.0321,  0.0576,  2.0000],\n",
              "         [-0.1420,  0.1344,  0.2700,  ...,  0.0881, -0.0044,  2.0000],\n",
              "         [-0.2425,  0.0958,  0.2793,  ...,  0.0682, -0.0040,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7437e-02, -1.1978e-01, -3.3694e-02,  ...,  3.7298e-02,\n",
              "           2.0646e-01,  2.0000e+00],\n",
              "         [ 1.3302e-01, -1.7104e-02, -2.1081e-03,  ...,  2.2806e-01,\n",
              "           1.0216e-01,  2.0000e+00],\n",
              "         [ 1.3106e-01,  4.6633e-02,  1.5624e-02,  ...,  3.0166e-01,\n",
              "          -4.1645e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.3698e-02,  1.3226e-01,  1.7164e-01,  ...,  3.5925e-02,\n",
              "           3.4884e-02,  2.0000e+00],\n",
              "         [-2.1978e-01,  1.2691e-01,  3.3781e-01,  ...,  4.9526e-02,\n",
              "          -5.3309e-03,  2.0000e+00],\n",
              "         [-2.7924e-01,  9.8086e-02,  2.9809e-01,  ...,  4.1989e-02,\n",
              "           1.7447e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0298, -0.1466, -0.0357,  ...,  0.0604,  0.2158,  2.0000],\n",
              "         [ 0.1645, -0.0760, -0.0424,  ...,  0.2738,  0.1583,  2.0000],\n",
              "         [ 0.1207, -0.0588, -0.0352,  ...,  0.3685,  0.0563,  2.0000],\n",
              "         ...,\n",
              "         [-0.1172,  0.0535,  0.2167,  ...,  0.0854,  0.0087,  2.0000],\n",
              "         [-0.2357,  0.0499,  0.2646,  ...,  0.0696, -0.0347,  2.0000],\n",
              "         [-0.2773,  0.0610,  0.2631,  ...,  0.0441, -0.0121,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0361, -0.1267, -0.0867,  ...,  0.0285,  0.1934,  2.0000],\n",
              "         [ 0.2119, -0.0331, -0.0793,  ...,  0.2088,  0.0619,  2.0000],\n",
              "         [ 0.1999,  0.0071, -0.0645,  ...,  0.2908, -0.0872,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1620,  0.0251,  0.0031,  ...,  0.0635,  0.0652,  2.0000],\n",
              "         [-0.0632,  0.0795,  0.2345,  ...,  0.1159, -0.0179,  2.0000],\n",
              "         [-0.2290,  0.0624,  0.2816,  ...,  0.0874, -0.0150,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0175, -0.1163, -0.0628,  ...,  0.0227,  0.1893,  2.0000],\n",
              "         [ 0.1956, -0.0138, -0.0462,  ...,  0.2216,  0.0280,  2.0000],\n",
              "         [ 0.1914,  0.0315, -0.0437,  ...,  0.2802, -0.1022,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0943,  0.0379,  0.0357,  ...,  0.0415,  0.0726,  2.0000],\n",
              "         [-0.1219,  0.1062,  0.3042,  ...,  0.0919, -0.0104,  2.0000],\n",
              "         [-0.2503,  0.0772,  0.3020,  ...,  0.0578, -0.0130,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0330, -0.1302, -0.0327,  ...,  0.0557,  0.2105,  2.0000],\n",
              "         [ 0.1457, -0.0549, -0.0297,  ...,  0.2558,  0.1488,  2.0000],\n",
              "         [ 0.1141, -0.0326, -0.0117,  ...,  0.3443,  0.0456,  2.0000],\n",
              "         ...,\n",
              "         [-0.1586,  0.0914,  0.2613,  ...,  0.0783, -0.0116,  2.0000],\n",
              "         [-0.2688,  0.0770,  0.3045,  ...,  0.0675, -0.0477,  2.0000],\n",
              "         [-0.3001,  0.0850,  0.2844,  ...,  0.0379, -0.0186,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0164, -0.1289, -0.0273,  ...,  0.0466,  0.2111,  3.0000],\n",
              "         [ 0.1497, -0.0377, -0.0059,  ...,  0.2625,  0.1258,  3.0000],\n",
              "         [ 0.1495,  0.0208,  0.0103,  ...,  0.3421, -0.0113,  3.0000],\n",
              "         ...,\n",
              "         [-0.0404,  0.1206,  0.2044,  ...,  0.0816,  0.0198,  3.0000],\n",
              "         [-0.2248,  0.1260,  0.3333,  ...,  0.0773, -0.0144,  3.0000],\n",
              "         [-0.2746,  0.1054,  0.2956,  ...,  0.0560,  0.0035,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0224, -0.1379, -0.0285,  ...,  0.0546,  0.2170,  0.0000],\n",
              "         [ 0.1473, -0.0489, -0.0107,  ...,  0.2529,  0.1395,  0.0000],\n",
              "         [ 0.1360,  0.0012,  0.0110,  ...,  0.3382,  0.0071,  0.0000],\n",
              "         ...,\n",
              "         [-0.0906,  0.1423,  0.2212,  ...,  0.0659,  0.0017,  0.0000],\n",
              "         [-0.2468,  0.1325,  0.3204,  ...,  0.0654, -0.0289,  0.0000],\n",
              "         [-0.2872,  0.0974,  0.2923,  ...,  0.0652, -0.0029,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4256e-02, -1.3307e-01, -2.5236e-02,  ...,  4.6853e-02,\n",
              "           2.0928e-01,  0.0000e+00],\n",
              "         [ 1.3533e-01, -4.8141e-02, -1.0653e-02,  ...,  2.5765e-01,\n",
              "           1.3190e-01,  0.0000e+00],\n",
              "         [ 1.2112e-01, -2.6900e-03,  8.1858e-03,  ...,  3.4413e-01,\n",
              "           9.8992e-03,  0.0000e+00],\n",
              "         ...,\n",
              "         [-1.1674e-01,  1.2686e-01,  2.4206e-01,  ...,  8.1840e-02,\n",
              "          -3.1412e-04,  0.0000e+00],\n",
              "         [-2.5419e-01,  1.1399e-01,  3.2987e-01,  ...,  6.7813e-02,\n",
              "          -2.9945e-02,  0.0000e+00],\n",
              "         [-2.9978e-01,  9.0953e-02,  2.9832e-01,  ...,  4.8419e-02,\n",
              "          -1.1663e-02,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.8644e-02, -1.1440e-01, -3.6687e-02,  ...,  3.4454e-02,\n",
              "           2.0254e-01,  0.0000e+00],\n",
              "         [ 1.2894e-01, -1.3468e-02, -7.2628e-03,  ...,  2.3262e-01,\n",
              "           7.8771e-02,  0.0000e+00],\n",
              "         [ 1.3821e-01,  5.7225e-02,  7.1747e-03,  ...,  3.0166e-01,\n",
              "          -6.7157e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4627e-02,  1.1876e-01,  1.2776e-01,  ...,  2.6344e-02,\n",
              "           5.1717e-02,  0.0000e+00],\n",
              "         [-2.0250e-01,  1.2849e-01,  3.3314e-01,  ...,  5.4244e-02,\n",
              "          -4.6622e-03,  0.0000e+00],\n",
              "         [-2.8052e-01,  9.7224e-02,  3.0364e-01,  ...,  4.7005e-02,\n",
              "           2.8506e-04,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0352, -0.1527, -0.0564,  ...,  0.0595,  0.2096,  0.0000],\n",
              "         [ 0.1377, -0.1137, -0.0760,  ...,  0.2843,  0.1625,  0.0000],\n",
              "         [ 0.0798, -0.1138, -0.0803,  ...,  0.3898,  0.0853,  0.0000],\n",
              "         ...,\n",
              "         [-0.1852,  0.0225,  0.2020,  ...,  0.1069, -0.0376,  0.0000],\n",
              "         [-0.2602,  0.0372,  0.2051,  ...,  0.0858, -0.0675,  0.0000],\n",
              "         [-0.2766,  0.0196,  0.2411,  ...,  0.0224, -0.0363,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0220, -0.1344, -0.0289,  ...,  0.0507,  0.2175,  0.0000],\n",
              "         [ 0.1423, -0.0464, -0.0077,  ...,  0.2442,  0.1361,  0.0000],\n",
              "         [ 0.1329,  0.0096,  0.0165,  ...,  0.3242, -0.0022,  0.0000],\n",
              "         ...,\n",
              "         [-0.0777,  0.1487,  0.2150,  ...,  0.0527,  0.0110,  0.0000],\n",
              "         [-0.2380,  0.1417,  0.3174,  ...,  0.0590, -0.0224,  0.0000],\n",
              "         [-0.2837,  0.1011,  0.2917,  ...,  0.0650, -0.0019,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0250, -0.1293, -0.0236,  ...,  0.0435,  0.2070,  0.0000],\n",
              "         [ 0.1287, -0.0418,  0.0007,  ...,  0.2469,  0.1265,  0.0000],\n",
              "         [ 0.1165,  0.0050,  0.0217,  ...,  0.3276,  0.0035,  0.0000],\n",
              "         ...,\n",
              "         [-0.1118,  0.1337,  0.2523,  ...,  0.0702, -0.0032,  0.0000],\n",
              "         [-0.2562,  0.1223,  0.3491,  ...,  0.0583, -0.0322,  0.0000],\n",
              "         [-0.3024,  0.0949,  0.3072,  ...,  0.0428, -0.0119,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0291, -0.1234, -0.0262,  ...,  0.0490,  0.2048,  0.0000],\n",
              "         [ 0.1328, -0.0539, -0.0161,  ...,  0.2471,  0.1366,  0.0000],\n",
              "         [ 0.1141, -0.0196,  0.0032,  ...,  0.3404,  0.0139,  0.0000],\n",
              "         ...,\n",
              "         [-0.1464,  0.1237,  0.2553,  ...,  0.0826, -0.0092,  0.0000],\n",
              "         [-0.2667,  0.1103,  0.3268,  ...,  0.0654, -0.0394,  0.0000],\n",
              "         [-0.3082,  0.0938,  0.2971,  ...,  0.0397, -0.0175,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0233, -0.1300, -0.0298,  ...,  0.0492,  0.2133,  0.0000],\n",
              "         [ 0.1383, -0.0414, -0.0063,  ...,  0.2477,  0.1277,  0.0000],\n",
              "         [ 0.1349,  0.0170,  0.0177,  ...,  0.3262, -0.0144,  0.0000],\n",
              "         ...,\n",
              "         [-0.0945,  0.1465,  0.2368,  ...,  0.0639, -0.0016,  0.0000],\n",
              "         [-0.2505,  0.1384,  0.3396,  ...,  0.0582, -0.0319,  0.0000],\n",
              "         [-0.2894,  0.1031,  0.3011,  ...,  0.0587, -0.0039,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0031, -0.1035, -0.0643,  ...,  0.0337,  0.2023,  0.0000],\n",
              "         [ 0.1641,  0.0082, -0.0370,  ...,  0.2244,  0.0757,  0.0000],\n",
              "         [ 0.1686,  0.0625, -0.0276,  ...,  0.3052, -0.0809,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0783,  0.0856,  0.0495,  ...,  0.0434,  0.0562,  0.0000],\n",
              "         [-0.1463,  0.1371,  0.3006,  ...,  0.0813, -0.0070,  0.0000],\n",
              "         [-0.2540,  0.0985,  0.2927,  ...,  0.0630, -0.0027,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0341, -0.1246, -0.0312,  ...,  0.0520,  0.2074,  0.0000],\n",
              "         [ 0.1340, -0.0559, -0.0325,  ...,  0.2553,  0.1470,  0.0000],\n",
              "         [ 0.1056, -0.0313, -0.0217,  ...,  0.3465,  0.0391,  0.0000],\n",
              "         ...,\n",
              "         [-0.1580,  0.0970,  0.2501,  ...,  0.0876,  0.0005,  0.0000],\n",
              "         [-0.2715,  0.0825,  0.3075,  ...,  0.0661, -0.0379,  0.0000],\n",
              "         [-0.3113,  0.0830,  0.2901,  ...,  0.0311, -0.0193,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0232, -0.1283, -0.0248,  ...,  0.0404,  0.2083,  0.0000],\n",
              "         [ 0.1264, -0.0383,  0.0034,  ...,  0.2400,  0.1227,  0.0000],\n",
              "         [ 0.1215,  0.0183,  0.0261,  ...,  0.3170, -0.0109,  0.0000],\n",
              "         ...,\n",
              "         [-0.0813,  0.1367,  0.2388,  ...,  0.0615,  0.0078,  0.0000],\n",
              "         [-0.2469,  0.1305,  0.3531,  ...,  0.0531, -0.0246,  0.0000],\n",
              "         [-0.2990,  0.0971,  0.3077,  ...,  0.0445, -0.0086,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0219, -0.1695, -0.0467,  ...,  0.0680,  0.2112,  0.0000],\n",
              "         [ 0.1901, -0.0971, -0.0590,  ...,  0.3103,  0.1469,  0.0000],\n",
              "         [ 0.1486, -0.0918, -0.0605,  ...,  0.3985,  0.0616,  0.0000],\n",
              "         ...,\n",
              "         [-0.0805,  0.0067,  0.1612,  ...,  0.0992,  0.0149,  0.0000],\n",
              "         [-0.1906,  0.0227,  0.1989,  ...,  0.0859, -0.0205,  0.0000],\n",
              "         [-0.2409,  0.0220,  0.2274,  ...,  0.0570, -0.0145,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.4400e-02, -1.1612e-01, -3.4176e-02,  ...,  4.3112e-02,\n",
              "           2.0755e-01,  0.0000e+00],\n",
              "         [ 1.3994e-01, -2.0908e-02, -1.4896e-02,  ...,  2.4936e-01,\n",
              "           9.8451e-02,  0.0000e+00],\n",
              "         [ 1.5063e-01,  4.8895e-02, -2.9921e-03,  ...,  3.1883e-01,\n",
              "          -4.9630e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2370e-02,  1.2092e-01,  1.5319e-01,  ...,  5.5114e-02,\n",
              "           3.8253e-02,  0.0000e+00],\n",
              "         [-1.9987e-01,  1.2629e-01,  3.3233e-01,  ...,  8.0706e-02,\n",
              "           2.2220e-04,  0.0000e+00],\n",
              "         [-2.6457e-01,  1.0794e-01,  2.9638e-01,  ...,  5.5214e-02,\n",
              "           9.5783e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 2.4156e-05, -1.0934e-01, -5.0658e-02,  ...,  4.1157e-02,\n",
              "           2.0335e-01,  0.0000e+00],\n",
              "         [ 1.8036e-01, -3.9352e-03, -4.2006e-02,  ...,  2.5587e-01,\n",
              "           5.7387e-02,  0.0000e+00],\n",
              "         [ 1.9044e-01,  5.6964e-02, -3.9533e-02,  ...,  3.1345e-01,\n",
              "          -7.7240e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 9.6291e-02,  7.9824e-02,  3.8125e-02,  ...,  5.7790e-02,\n",
              "           6.1378e-02,  0.0000e+00],\n",
              "         [-1.3779e-01,  1.2347e-01,  3.0012e-01,  ...,  1.1301e-01,\n",
              "          -6.5573e-03,  0.0000e+00],\n",
              "         [-2.4416e-01,  1.0363e-01,  2.8937e-01,  ...,  6.7810e-02,\n",
              "           5.9282e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0235, -0.1304, -0.0298,  ...,  0.0471,  0.2147,  0.0000],\n",
              "         [ 0.1260, -0.0382, -0.0084,  ...,  0.2424,  0.1240,  0.0000],\n",
              "         [ 0.1307,  0.0253,  0.0150,  ...,  0.3206, -0.0206,  0.0000],\n",
              "         ...,\n",
              "         [-0.0672,  0.1402,  0.2185,  ...,  0.0514,  0.0038,  0.0000],\n",
              "         [-0.2417,  0.1413,  0.3408,  ...,  0.0534, -0.0226,  0.0000],\n",
              "         [-0.2872,  0.1006,  0.3039,  ...,  0.0590,  0.0011,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0213, -0.1221, -0.0295,  ...,  0.0389,  0.2065,  0.0000],\n",
              "         [ 0.1225, -0.0244, -0.0022,  ...,  0.2341,  0.1076,  0.0000],\n",
              "         [ 0.1225,  0.0402,  0.0159,  ...,  0.3083, -0.0327,  0.0000],\n",
              "         ...,\n",
              "         [-0.0283,  0.1320,  0.1909,  ...,  0.0388,  0.0280,  0.0000],\n",
              "         [-0.2298,  0.1298,  0.3467,  ...,  0.0468, -0.0094,  0.0000],\n",
              "         [-0.2890,  0.1003,  0.3063,  ...,  0.0438, -0.0009,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0535, -0.2047, -0.1066,  ..., -0.0114,  0.1881,  0.0000],\n",
              "         [ 0.3147,  0.0192, -0.0984,  ...,  0.0740,  0.0099,  0.0000],\n",
              "         [ 0.3124,  0.0551, -0.0798,  ...,  0.1220, -0.0947,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1642, -0.0119, -0.1623,  ...,  0.0352,  0.0770,  0.0000],\n",
              "         [ 0.0181,  0.0531,  0.1295,  ...,  0.1096, -0.0213,  0.0000],\n",
              "         [-0.1744,  0.0257,  0.2822,  ...,  0.0539, -0.0138,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0075, -0.1179, -0.0457,  ...,  0.0496,  0.2136,  0.0000],\n",
              "         [ 0.1457, -0.0153, -0.0263,  ...,  0.2389,  0.1168,  0.0000],\n",
              "         [ 0.1504,  0.0503, -0.0098,  ...,  0.3195, -0.0466,  0.0000],\n",
              "         ...,\n",
              "         [-0.0015,  0.1400,  0.1429,  ...,  0.0489,  0.0231,  0.0000],\n",
              "         [-0.1992,  0.1496,  0.3064,  ...,  0.0682, -0.0096,  0.0000],\n",
              "         [-0.2611,  0.1047,  0.2895,  ...,  0.0709,  0.0033,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0167, -0.1187, -0.0353,  ...,  0.0441,  0.2155,  0.0000],\n",
              "         [ 0.1271, -0.0228, -0.0081,  ...,  0.2276,  0.1253,  0.0000],\n",
              "         [ 0.1316,  0.0400,  0.0164,  ...,  0.2996, -0.0267,  0.0000],\n",
              "         ...,\n",
              "         [-0.0368,  0.1425,  0.1974,  ...,  0.0462,  0.0193,  0.0000],\n",
              "         [-0.2223,  0.1394,  0.3401,  ...,  0.0561, -0.0109,  0.0000],\n",
              "         [-0.2815,  0.0987,  0.3087,  ...,  0.0559, -0.0013,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0012, -0.1246, -0.0471,  ...,  0.0552,  0.2146,  0.0000],\n",
              "         [ 0.1636, -0.0111, -0.0261,  ...,  0.2388,  0.1176,  0.0000],\n",
              "         [ 0.1647,  0.0520, -0.0074,  ...,  0.3215, -0.0404,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0417,  0.1274,  0.1119,  ...,  0.0366,  0.0380,  0.0000],\n",
              "         [-0.1661,  0.1372,  0.2792,  ...,  0.0567, -0.0065,  0.0000],\n",
              "         [-0.2454,  0.1086,  0.2738,  ...,  0.0709,  0.0024,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0214, -0.1212, -0.0280,  ...,  0.0383,  0.2062,  0.0000],\n",
              "         [ 0.1223, -0.0290,  0.0007,  ...,  0.2336,  0.1112,  0.0000],\n",
              "         [ 0.1220,  0.0358,  0.0214,  ...,  0.3095, -0.0313,  0.0000],\n",
              "         ...,\n",
              "         [-0.0362,  0.1298,  0.2035,  ...,  0.0451,  0.0156,  0.0000],\n",
              "         [-0.2274,  0.1283,  0.3484,  ...,  0.0519, -0.0185,  0.0000],\n",
              "         [-0.2912,  0.1006,  0.3136,  ...,  0.0450, -0.0021,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0292, -0.1303, -0.0739,  ...,  0.0116,  0.1807,  0.0000],\n",
              "         [ 0.2226, -0.0191, -0.0643,  ...,  0.1910,  0.0146,  0.0000],\n",
              "         [ 0.2259,  0.0220, -0.0560,  ...,  0.2429, -0.1098,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1309, -0.0015, -0.0549,  ...,  0.0395,  0.0710,  0.0000],\n",
              "         [-0.0787,  0.0953,  0.2607,  ...,  0.1044, -0.0320,  0.0000],\n",
              "         [-0.2603,  0.0647,  0.3039,  ...,  0.0720, -0.0182,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0150, -0.1265, -0.0364,  ...,  0.0475,  0.2172,  0.0000],\n",
              "         [ 0.1352, -0.0277, -0.0156,  ...,  0.2356,  0.1275,  0.0000],\n",
              "         [ 0.1349,  0.0369,  0.0056,  ...,  0.3131, -0.0264,  0.0000],\n",
              "         ...,\n",
              "         [-0.0198,  0.1400,  0.1591,  ...,  0.0466,  0.0377,  0.0000],\n",
              "         [-0.2146,  0.1437,  0.3136,  ...,  0.0576, -0.0051,  0.0000],\n",
              "         [-0.2718,  0.1045,  0.2905,  ...,  0.0627,  0.0043,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0051, -0.1169, -0.0483,  ...,  0.0530,  0.2169,  0.0000],\n",
              "         [ 0.1465, -0.0135, -0.0324,  ...,  0.2353,  0.1190,  0.0000],\n",
              "         [ 0.1536,  0.0467, -0.0157,  ...,  0.3156, -0.0406,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0409,  0.1203,  0.0968,  ...,  0.0460,  0.0460,  0.0000],\n",
              "         [-0.1738,  0.1355,  0.2867,  ...,  0.0762,  0.0005,  0.0000],\n",
              "         [-0.2549,  0.1085,  0.2849,  ...,  0.0754,  0.0105,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1282, -0.0324,  ...,  0.0549,  0.2091,  0.0000],\n",
              "         [ 0.1386, -0.0597, -0.0388,  ...,  0.2703,  0.1470,  0.0000],\n",
              "         [ 0.1098, -0.0368, -0.0308,  ...,  0.3621,  0.0419,  0.0000],\n",
              "         ...,\n",
              "         [-0.1434,  0.0886,  0.2388,  ...,  0.0936, -0.0022,  0.0000],\n",
              "         [-0.2618,  0.0742,  0.2982,  ...,  0.0710, -0.0371,  0.0000],\n",
              "         [-0.3074,  0.0799,  0.2869,  ...,  0.0367, -0.0176,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0154, -0.1119, -0.0671,  ...,  0.0388,  0.2088,  0.0000],\n",
              "         [ 0.1798, -0.0051, -0.0553,  ...,  0.2187,  0.0765,  0.0000],\n",
              "         [ 0.1821,  0.0411, -0.0446,  ...,  0.2990, -0.0781,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1076,  0.0687,  0.0225,  ...,  0.0395,  0.0732,  0.0000],\n",
              "         [-0.1280,  0.1276,  0.2704,  ...,  0.0832,  0.0008,  0.0000],\n",
              "         [-0.2412,  0.0966,  0.2793,  ...,  0.0638, -0.0003,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0177, -0.1260, -0.0295,  ...,  0.0384,  0.2076,  0.0000],\n",
              "         [ 0.1330, -0.0238, -0.0025,  ...,  0.2429,  0.1106,  0.0000],\n",
              "         [ 0.1318,  0.0403,  0.0183,  ...,  0.3215, -0.0251,  0.0000],\n",
              "         ...,\n",
              "         [-0.0185,  0.1264,  0.1792,  ...,  0.0543,  0.0300,  0.0000],\n",
              "         [-0.2192,  0.1251,  0.3350,  ...,  0.0588, -0.0073,  0.0000],\n",
              "         [-0.2808,  0.0982,  0.2994,  ...,  0.0502, -0.0050,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0161, -0.1319, -0.0355,  ...,  0.0544,  0.2199,  0.0000],\n",
              "         [ 0.1476, -0.0460, -0.0292,  ...,  0.2617,  0.1428,  0.0000],\n",
              "         [ 0.1402,  0.0093, -0.0097,  ...,  0.3563, -0.0064,  0.0000],\n",
              "         ...,\n",
              "         [-0.0474,  0.1297,  0.1732,  ...,  0.0653,  0.0188,  0.0000],\n",
              "         [-0.2127,  0.1276,  0.2878,  ...,  0.0696, -0.0128,  0.0000],\n",
              "         [-0.2699,  0.0939,  0.2770,  ...,  0.0741, -0.0017,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.4112e-03, -1.0944e-01, -4.5478e-02,  ...,  4.0911e-02,\n",
              "           2.0352e-01,  0.0000e+00],\n",
              "         [ 1.6268e-01, -4.2804e-03, -2.8469e-02,  ...,  2.5074e-01,\n",
              "           7.0833e-02,  0.0000e+00],\n",
              "         [ 1.7561e-01,  6.2414e-02, -2.2814e-02,  ...,  3.1190e-01,\n",
              "          -7.2397e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 7.8194e-02,  9.0089e-02,  5.8105e-02,  ...,  4.0209e-02,\n",
              "           6.1770e-02,  0.0000e+00],\n",
              "         [-1.5522e-01,  1.2608e-01,  3.0857e-01,  ...,  9.5037e-02,\n",
              "           2.9690e-04,  0.0000e+00],\n",
              "         [-2.5203e-01,  1.1048e-01,  2.9003e-01,  ...,  5.8311e-02,\n",
              "           6.4105e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0148, -0.1240, -0.0291,  ...,  0.0449,  0.2120,  3.0000],\n",
              "         [ 0.1515, -0.0254, -0.0060,  ...,  0.2607,  0.1217,  3.0000],\n",
              "         [ 0.1545,  0.0382,  0.0086,  ...,  0.3315, -0.0161,  3.0000],\n",
              "         ...,\n",
              "         [-0.0127,  0.1240,  0.1863,  ...,  0.0741,  0.0272,  3.0000],\n",
              "         [-0.2127,  0.1259,  0.3338,  ...,  0.0766, -0.0065,  3.0000],\n",
              "         [-0.2668,  0.1063,  0.2968,  ...,  0.0561,  0.0071,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9664e-02, -1.3145e-01, -3.2571e-02,  ...,  5.1461e-02,\n",
              "           2.1638e-01,  1.0000e+00],\n",
              "         [ 1.4737e-01, -3.7810e-02, -1.9346e-02,  ...,  2.5276e-01,\n",
              "           1.3345e-01,  1.0000e+00],\n",
              "         [ 1.4332e-01,  2.0879e-02,  2.5516e-03,  ...,  3.3811e-01,\n",
              "          -1.4501e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-6.5361e-02,  1.4596e-01,  1.9768e-01,  ...,  5.5706e-02,\n",
              "           7.6979e-03,  1.0000e+00],\n",
              "         [-2.3336e-01,  1.3565e-01,  3.1647e-01,  ...,  5.9482e-02,\n",
              "          -2.3942e-02,  1.0000e+00],\n",
              "         [-2.7526e-01,  9.9644e-02,  2.8983e-01,  ...,  6.7294e-02,\n",
              "           5.3237e-04,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0334, -0.1595, -0.0520,  ...,  0.0654,  0.2107,  1.0000],\n",
              "         [ 0.1732, -0.1171, -0.0657,  ...,  0.3178,  0.1696,  1.0000],\n",
              "         [ 0.1207, -0.1099, -0.0656,  ...,  0.4220,  0.0854,  1.0000],\n",
              "         ...,\n",
              "         [-0.1525,  0.0225,  0.1976,  ...,  0.1164, -0.0133,  1.0000],\n",
              "         [-0.2391,  0.0387,  0.2044,  ...,  0.0912, -0.0409,  1.0000],\n",
              "         [-0.2612,  0.0262,  0.2341,  ...,  0.0364, -0.0205,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0226, -0.1334, -0.0300,  ...,  0.0553,  0.2168,  1.0000],\n",
              "         [ 0.1531, -0.0459, -0.0139,  ...,  0.2652,  0.1403,  1.0000],\n",
              "         [ 0.1421,  0.0039,  0.0090,  ...,  0.3546,  0.0016,  1.0000],\n",
              "         ...,\n",
              "         [-0.1219,  0.1323,  0.2507,  ...,  0.0823, -0.0206,  1.0000],\n",
              "         [-0.2484,  0.1217,  0.3233,  ...,  0.0741, -0.0385,  1.0000],\n",
              "         [-0.2854,  0.0954,  0.2947,  ...,  0.0644, -0.0053,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0237, -0.1322, -0.0252,  ...,  0.0459,  0.2090,  1.0000],\n",
              "         [ 0.1337, -0.0490, -0.0053,  ...,  0.2574,  0.1338,  1.0000],\n",
              "         [ 0.1172, -0.0080,  0.0147,  ...,  0.3398,  0.0175,  1.0000],\n",
              "         ...,\n",
              "         [-0.1266,  0.1295,  0.2551,  ...,  0.0782, -0.0059,  1.0000],\n",
              "         [-0.2562,  0.1146,  0.3371,  ...,  0.0653, -0.0325,  1.0000],\n",
              "         [-0.3038,  0.0894,  0.3022,  ...,  0.0472, -0.0141,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.7890e-02, -1.2406e-01, -3.1280e-02,  ...,  5.3790e-02,\n",
              "           2.0561e-01,  1.0000e+00],\n",
              "         [ 1.4015e-01, -5.5312e-02, -2.5742e-02,  ...,  2.6102e-01,\n",
              "           1.3800e-01,  1.0000e+00],\n",
              "         [ 1.2219e-01, -2.4567e-02, -1.3632e-02,  ...,  3.5716e-01,\n",
              "           1.9122e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.2463e-01,  1.0392e-01,  2.2411e-01,  ...,  9.7227e-02,\n",
              "          -2.3523e-04,  1.0000e+00],\n",
              "         [-2.5289e-01,  1.0061e-01,  3.0596e-01,  ...,  7.2027e-02,\n",
              "          -3.5059e-02,  1.0000e+00],\n",
              "         [-3.0133e-01,  8.7991e-02,  2.8772e-01,  ...,  4.4313e-02,\n",
              "          -1.8574e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0175, -0.1239, -0.0343,  ...,  0.0509,  0.2140,  1.0000],\n",
              "         [ 0.1483, -0.0219, -0.0135,  ...,  0.2542,  0.1169,  1.0000],\n",
              "         [ 0.1522,  0.0443,  0.0062,  ...,  0.3268, -0.0348,  1.0000],\n",
              "         ...,\n",
              "         [-0.0389,  0.1380,  0.1959,  ...,  0.0579,  0.0022,  1.0000],\n",
              "         [-0.2235,  0.1388,  0.3236,  ...,  0.0640, -0.0202,  1.0000],\n",
              "         [-0.2697,  0.1094,  0.2959,  ...,  0.0706,  0.0088,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4567e-02, -1.3431e-01, -2.7553e-02,  ...,  4.6845e-02,\n",
              "           2.0861e-01,  1.0000e+00],\n",
              "         [ 1.3687e-01, -4.7448e-02, -1.1938e-02,  ...,  2.6672e-01,\n",
              "           1.3105e-01,  1.0000e+00],\n",
              "         [ 1.1786e-01, -8.1432e-03,  4.6420e-03,  ...,  3.5136e-01,\n",
              "           1.7723e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1732e-01,  1.1975e-01,  2.3599e-01,  ...,  8.4581e-02,\n",
              "          -7.6023e-04,  1.0000e+00],\n",
              "         [-2.4946e-01,  1.0518e-01,  3.2167e-01,  ...,  6.8490e-02,\n",
              "          -3.1764e-02,  1.0000e+00],\n",
              "         [-2.9911e-01,  8.6555e-02,  2.9626e-01,  ...,  4.8950e-02,\n",
              "          -1.5008e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0338, -0.1574, -0.0585,  ...,  0.0621,  0.2109,  1.0000],\n",
              "         [ 0.1391, -0.1191, -0.0816,  ...,  0.3050,  0.1552,  1.0000],\n",
              "         [ 0.0852, -0.1194, -0.0892,  ...,  0.4072,  0.0801,  1.0000],\n",
              "         ...,\n",
              "         [-0.1575,  0.0094,  0.1916,  ...,  0.1134, -0.0277,  1.0000],\n",
              "         [-0.2279,  0.0225,  0.1927,  ...,  0.0923, -0.0544,  1.0000],\n",
              "         [-0.2637,  0.0042,  0.2289,  ...,  0.0319, -0.0327,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0205, -0.1326, -0.0341,  ...,  0.0566,  0.2176,  1.0000],\n",
              "         [ 0.1595, -0.0342, -0.0144,  ...,  0.2680,  0.1289,  1.0000],\n",
              "         [ 0.1517,  0.0246,  0.0047,  ...,  0.3479, -0.0131,  1.0000],\n",
              "         ...,\n",
              "         [-0.0485,  0.1467,  0.2051,  ...,  0.0733,  0.0094,  1.0000],\n",
              "         [-0.2256,  0.1367,  0.3135,  ...,  0.0724, -0.0180,  1.0000],\n",
              "         [-0.2708,  0.1042,  0.2886,  ...,  0.0742,  0.0040,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0244, -0.1318, -0.0263,  ...,  0.0433,  0.2100,  1.0000],\n",
              "         [ 0.1307, -0.0480, -0.0039,  ...,  0.2473,  0.1329,  1.0000],\n",
              "         [ 0.1157, -0.0040,  0.0180,  ...,  0.3318,  0.0082,  1.0000],\n",
              "         ...,\n",
              "         [-0.1212,  0.1315,  0.2473,  ...,  0.0709, -0.0035,  1.0000],\n",
              "         [-0.2560,  0.1216,  0.3359,  ...,  0.0566, -0.0342,  1.0000],\n",
              "         [-0.3024,  0.0921,  0.3011,  ...,  0.0441, -0.0159,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6471e-02, -1.2901e-01, -3.0476e-02,  ...,  4.9564e-02,\n",
              "           2.1028e-01,  1.0000e+00],\n",
              "         [ 1.5126e-01, -3.8261e-02, -1.3206e-02,  ...,  2.7598e-01,\n",
              "           1.2491e-01,  1.0000e+00],\n",
              "         [ 1.5028e-01,  1.4688e-02, -8.8313e-04,  ...,  3.5979e-01,\n",
              "          -7.4569e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-4.7852e-02,  1.1868e-01,  1.9786e-01,  ...,  1.0035e-01,\n",
              "           1.6160e-02,  1.0000e+00],\n",
              "         [-2.2367e-01,  1.1934e-01,  3.2165e-01,  ...,  8.7382e-02,\n",
              "          -1.7734e-02,  1.0000e+00],\n",
              "         [-2.7250e-01,  1.0222e-01,  2.8911e-01,  ...,  5.9059e-02,\n",
              "           1.9843e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-9.2304e-03, -1.1847e-01, -3.3539e-02,  ...,  4.3784e-02,\n",
              "           2.0902e-01,  1.0000e+00],\n",
              "         [ 1.5776e-01, -1.7370e-02, -1.4774e-02,  ...,  2.5961e-01,\n",
              "           1.0696e-01,  1.0000e+00],\n",
              "         [ 1.6547e-01,  5.2687e-02, -2.1852e-04,  ...,  3.2864e-01,\n",
              "          -3.9927e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 3.1178e-02,  1.2141e-01,  1.4081e-01,  ...,  6.3977e-02,\n",
              "           4.2776e-02,  1.0000e+00],\n",
              "         [-1.8793e-01,  1.2622e-01,  3.1939e-01,  ...,  8.4126e-02,\n",
              "          -8.8949e-08,  1.0000e+00],\n",
              "         [-2.5644e-01,  1.1001e-01,  2.9264e-01,  ...,  5.9298e-02,\n",
              "           7.1333e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0322, -0.1582, -0.0438,  ...,  0.0602,  0.2117,  1.0000],\n",
              "         [ 0.1659, -0.0961, -0.0540,  ...,  0.3027,  0.1570,  1.0000],\n",
              "         [ 0.1190, -0.0946, -0.0540,  ...,  0.3878,  0.0853,  1.0000],\n",
              "         ...,\n",
              "         [-0.1320,  0.0197,  0.2087,  ...,  0.1140,  0.0100,  1.0000],\n",
              "         [-0.2346,  0.0332,  0.2335,  ...,  0.0940, -0.0381,  1.0000],\n",
              "         [-0.2743,  0.0333,  0.2526,  ...,  0.0390, -0.0182,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0378, -0.1529, -0.0574,  ...,  0.0612,  0.2040,  1.0000],\n",
              "         [ 0.1194, -0.1214, -0.0739,  ...,  0.2833,  0.1513,  1.0000],\n",
              "         [ 0.0541, -0.1178, -0.0813,  ...,  0.3870,  0.0783,  1.0000],\n",
              "         ...,\n",
              "         [-0.2085,  0.0345,  0.1997,  ...,  0.0924, -0.0580,  1.0000],\n",
              "         [-0.2631,  0.0509,  0.1988,  ...,  0.0783, -0.0788,  1.0000],\n",
              "         [-0.2677,  0.0228,  0.2344,  ...,  0.0210, -0.0429,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3038e-02, -1.3275e-01, -2.4410e-02,  ...,  4.5871e-02,\n",
              "           2.0883e-01,  1.0000e+00],\n",
              "         [ 1.3580e-01, -4.5902e-02, -3.2553e-03,  ...,  2.5413e-01,\n",
              "           1.3302e-01,  1.0000e+00],\n",
              "         [ 1.2124e-01, -2.9262e-03,  1.6434e-02,  ...,  3.3625e-01,\n",
              "           1.6171e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1661e-01,  1.3043e-01,  2.5291e-01,  ...,  7.8278e-02,\n",
              "          -7.7681e-04,  1.0000e+00],\n",
              "         [-2.5582e-01,  1.1685e-01,  3.3968e-01,  ...,  6.5751e-02,\n",
              "          -2.9008e-02,  1.0000e+00],\n",
              "         [-3.0165e-01,  9.1063e-02,  3.0190e-01,  ...,  4.8656e-02,\n",
              "          -1.2671e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0246, -0.1302, -0.0248,  ...,  0.0444,  0.2077,  1.0000],\n",
              "         [ 0.1271, -0.0508, -0.0034,  ...,  0.2466,  0.1328,  1.0000],\n",
              "         [ 0.1108, -0.0087,  0.0163,  ...,  0.3334,  0.0080,  1.0000],\n",
              "         ...,\n",
              "         [-0.1276,  0.1341,  0.2630,  ...,  0.0794, -0.0071,  1.0000],\n",
              "         [-0.2633,  0.1243,  0.3478,  ...,  0.0622, -0.0356,  1.0000],\n",
              "         [-0.3080,  0.0929,  0.3059,  ...,  0.0451, -0.0178,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0162, -0.1177, -0.0352,  ...,  0.0436,  0.2142,  1.0000],\n",
              "         [ 0.1408, -0.0222, -0.0149,  ...,  0.2424,  0.1210,  1.0000],\n",
              "         [ 0.1456,  0.0483,  0.0110,  ...,  0.3173, -0.0336,  1.0000],\n",
              "         ...,\n",
              "         [-0.0174,  0.1293,  0.1786,  ...,  0.0490,  0.0208,  1.0000],\n",
              "         [-0.2084,  0.1397,  0.3281,  ...,  0.0629, -0.0076,  1.0000],\n",
              "         [-0.2690,  0.1045,  0.3028,  ...,  0.0632,  0.0073,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0142, -0.1202, -0.0381,  ...,  0.0465,  0.2153,  1.0000],\n",
              "         [ 0.1317, -0.0195, -0.0113,  ...,  0.2262,  0.1226,  1.0000],\n",
              "         [ 0.1348,  0.0457,  0.0044,  ...,  0.3019, -0.0346,  1.0000],\n",
              "         ...,\n",
              "         [-0.0232,  0.1435,  0.1623,  ...,  0.0308,  0.0319,  1.0000],\n",
              "         [-0.2167,  0.1494,  0.3256,  ...,  0.0477, -0.0046,  1.0000],\n",
              "         [-0.2713,  0.1016,  0.2974,  ...,  0.0629,  0.0033,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0126, -0.1167, -0.0407,  ...,  0.0371,  0.2004,  1.0000],\n",
              "         [ 0.1472, -0.0093, -0.0192,  ...,  0.2394,  0.0726,  1.0000],\n",
              "         [ 0.1504,  0.0555, -0.0094,  ...,  0.3101, -0.0688,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0378,  0.1157,  0.1053,  ...,  0.0330,  0.0401,  1.0000],\n",
              "         [-0.1915,  0.1196,  0.3167,  ...,  0.0662, -0.0134,  1.0000],\n",
              "         [-0.2682,  0.0917,  0.2960,  ...,  0.0466, -0.0061,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.4119e-02, -1.2610e-01, -3.2122e-02,  ...,  5.3747e-02,\n",
              "           2.0741e-01,  1.0000e+00],\n",
              "         [ 1.3607e-01, -5.7571e-02, -3.5891e-02,  ...,  2.5657e-01,\n",
              "           1.4182e-01,  1.0000e+00],\n",
              "         [ 1.1186e-01, -3.0388e-02, -2.5419e-02,  ...,  3.5008e-01,\n",
              "           3.0079e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.4986e-01,  9.2534e-02,  2.4263e-01,  ...,  9.1341e-02,\n",
              "           9.5852e-04,  1.0000e+00],\n",
              "         [-2.6687e-01,  8.6919e-02,  3.0241e-01,  ...,  7.0062e-02,\n",
              "          -3.9380e-02,  1.0000e+00],\n",
              "         [-3.0663e-01,  8.3335e-02,  2.8769e-01,  ...,  3.4783e-02,\n",
              "          -1.9950e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.2608e-02, -1.3059e-01, -2.5755e-02,  ...,  4.3271e-02,\n",
              "           2.0921e-01,  1.0000e+00],\n",
              "         [ 1.3325e-01, -4.5270e-02, -4.3164e-03,  ...,  2.5233e-01,\n",
              "           1.2839e-01,  1.0000e+00],\n",
              "         [ 1.2333e-01,  6.4068e-03,  1.5882e-02,  ...,  3.3775e-01,\n",
              "          -9.0039e-04,  1.0000e+00],\n",
              "         ...,\n",
              "         [-9.7444e-02,  1.3516e-01,  2.3558e-01,  ...,  7.8424e-02,\n",
              "           6.2723e-03,  1.0000e+00],\n",
              "         [-2.4839e-01,  1.2595e-01,  3.3849e-01,  ...,  6.5060e-02,\n",
              "          -2.6763e-02,  1.0000e+00],\n",
              "         [-2.9806e-01,  9.4082e-02,  3.0059e-01,  ...,  4.9112e-02,\n",
              "          -1.1457e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0294, -0.1505, -0.0435,  ...,  0.0578,  0.2136,  1.0000],\n",
              "         [ 0.1540, -0.0829, -0.0681,  ...,  0.2949,  0.1483,  1.0000],\n",
              "         [ 0.1191, -0.0732, -0.0741,  ...,  0.3877,  0.0488,  1.0000],\n",
              "         ...,\n",
              "         [-0.1194,  0.0270,  0.1920,  ...,  0.0999,  0.0234,  1.0000],\n",
              "         [-0.2193,  0.0264,  0.2420,  ...,  0.0793, -0.0179,  1.0000],\n",
              "         [-0.2762,  0.0340,  0.2537,  ...,  0.0460, -0.0173,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0155, -0.1164, -0.0374,  ...,  0.0441,  0.2170,  1.0000],\n",
              "         [ 0.1389, -0.0225, -0.0168,  ...,  0.2408,  0.1225,  1.0000],\n",
              "         [ 0.1454,  0.0459,  0.0071,  ...,  0.3151, -0.0334,  1.0000],\n",
              "         ...,\n",
              "         [-0.0177,  0.1304,  0.1688,  ...,  0.0497,  0.0288,  1.0000],\n",
              "         [-0.2075,  0.1446,  0.3180,  ...,  0.0612, -0.0046,  1.0000],\n",
              "         [-0.2729,  0.1067,  0.2980,  ...,  0.0632,  0.0086,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0367, -0.1552, -0.0556,  ...,  0.0616,  0.2114,  1.0000],\n",
              "         [ 0.1399, -0.1118, -0.0786,  ...,  0.3021,  0.1575,  1.0000],\n",
              "         [ 0.0860, -0.1121, -0.0859,  ...,  0.4009,  0.0815,  1.0000],\n",
              "         ...,\n",
              "         [-0.1689,  0.0162,  0.2008,  ...,  0.1056, -0.0315,  1.0000],\n",
              "         [-0.2367,  0.0230,  0.2045,  ...,  0.0875, -0.0534,  1.0000],\n",
              "         [-0.2713,  0.0096,  0.2374,  ...,  0.0298, -0.0329,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6870e-02, -1.2340e-01, -3.6243e-02,  ...,  4.5904e-02,\n",
              "           2.1689e-01,  1.0000e+00],\n",
              "         [ 1.3711e-01, -2.3872e-02, -1.5155e-02,  ...,  2.4206e-01,\n",
              "           1.2592e-01,  1.0000e+00],\n",
              "         [ 1.3922e-01,  3.9824e-02,  5.6119e-03,  ...,  3.1896e-01,\n",
              "          -2.1928e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-3.0807e-02,  1.3593e-01,  1.7692e-01,  ...,  5.0101e-02,\n",
              "           2.4297e-02,  1.0000e+00],\n",
              "         [-2.1536e-01,  1.3658e-01,  3.1885e-01,  ...,  5.6071e-02,\n",
              "          -9.8005e-03,  1.0000e+00],\n",
              "         [-2.7425e-01,  9.7145e-02,  2.9468e-01,  ...,  5.9895e-02,\n",
              "          -5.4130e-04,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0222, -0.1491, -0.0440,  ...,  0.0735,  0.2157,  1.0000],\n",
              "         [ 0.1951, -0.0683, -0.0582,  ...,  0.3007,  0.1509,  1.0000],\n",
              "         [ 0.1602, -0.0562, -0.0509,  ...,  0.3967,  0.0486,  1.0000],\n",
              "         ...,\n",
              "         [-0.0809,  0.0357,  0.1769,  ...,  0.0854,  0.0110,  1.0000],\n",
              "         [-0.1935,  0.0499,  0.2245,  ...,  0.0835, -0.0241,  1.0000],\n",
              "         [-0.2467,  0.0524,  0.2395,  ...,  0.0638, -0.0104,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0133, -0.1225, -0.0306,  ...,  0.0441,  0.2102,  1.0000],\n",
              "         [ 0.1470, -0.0244, -0.0106,  ...,  0.2613,  0.1121,  1.0000],\n",
              "         [ 0.1554,  0.0433,  0.0035,  ...,  0.3330, -0.0308,  1.0000],\n",
              "         ...,\n",
              "         [-0.0027,  0.1226,  0.1744,  ...,  0.0737,  0.0277,  1.0000],\n",
              "         [-0.2079,  0.1269,  0.3336,  ...,  0.0811, -0.0049,  1.0000],\n",
              "         [-0.2656,  0.1071,  0.2978,  ...,  0.0594,  0.0063,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0152, -0.1274, -0.0280,  ...,  0.0463,  0.2108,  1.0000],\n",
              "         [ 0.1498, -0.0318, -0.0038,  ...,  0.2631,  0.1212,  1.0000],\n",
              "         [ 0.1521,  0.0274,  0.0094,  ...,  0.3386, -0.0134,  1.0000],\n",
              "         ...,\n",
              "         [-0.0330,  0.1241,  0.2018,  ...,  0.0824,  0.0215,  1.0000],\n",
              "         [-0.2215,  0.1277,  0.3359,  ...,  0.0812, -0.0118,  1.0000],\n",
              "         [-0.2712,  0.1074,  0.2975,  ...,  0.0580,  0.0052,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0039, -0.1130, -0.0418,  ...,  0.0414,  0.2050,  0.0000],\n",
              "         [ 0.1620, -0.0053, -0.0257,  ...,  0.2439,  0.0849,  0.0000],\n",
              "         [ 0.1726,  0.0608, -0.0182,  ...,  0.3116, -0.0623,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0587,  0.1072,  0.0900,  ...,  0.0395,  0.0580,  0.0000],\n",
              "         [-0.1735,  0.1236,  0.3100,  ...,  0.0842, -0.0017,  0.0000],\n",
              "         [-0.2512,  0.1087,  0.2865,  ...,  0.0538,  0.0015,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.4219e-02, -1.2175e-01, -2.9181e-02,  ...,  4.3344e-02,\n",
              "           2.1078e-01,  3.0000e+00],\n",
              "         [ 1.4834e-01, -2.5468e-02, -5.5164e-03,  ...,  2.5455e-01,\n",
              "           1.1507e-01,  3.0000e+00],\n",
              "         [ 1.5480e-01,  4.3260e-02,  9.9949e-03,  ...,  3.2512e-01,\n",
              "          -2.9679e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0345e-03,  1.2299e-01,  1.7566e-01,  ...,  6.1047e-02,\n",
              "           3.4322e-02,  3.0000e+00],\n",
              "         [-2.0815e-01,  1.2842e-01,  3.3401e-01,  ...,  7.3798e-02,\n",
              "          -2.1062e-03,  3.0000e+00],\n",
              "         [-2.6619e-01,  1.0981e-01,  2.9750e-01,  ...,  5.4964e-02,\n",
              "           8.8542e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0163, -0.1292, -0.0274,  ...,  0.0471,  0.2123,  3.0000],\n",
              "         [ 0.1528, -0.0349, -0.0049,  ...,  0.2672,  0.1261,  3.0000],\n",
              "         [ 0.1535,  0.0243,  0.0097,  ...,  0.3445, -0.0060,  3.0000],\n",
              "         ...,\n",
              "         [-0.0398,  0.1207,  0.2052,  ...,  0.0879,  0.0195,  3.0000],\n",
              "         [-0.2229,  0.1240,  0.3319,  ...,  0.0820, -0.0137,  3.0000],\n",
              "         [-0.2727,  0.1044,  0.2953,  ...,  0.0592,  0.0038,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1244e-02, -1.2388e-01, -3.1590e-02,  ...,  4.6442e-02,\n",
              "           2.1178e-01,  2.0000e+00],\n",
              "         [ 1.6004e-01, -2.5183e-02, -1.3287e-02,  ...,  2.6863e-01,\n",
              "           1.2068e-01,  2.0000e+00],\n",
              "         [ 1.6377e-01,  3.9865e-02,  1.0767e-03,  ...,  3.4389e-01,\n",
              "          -2.0728e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-3.8820e-05,  1.1779e-01,  1.6473e-01,  ...,  8.4437e-02,\n",
              "           3.4670e-02,  2.0000e+00],\n",
              "         [-2.0279e-01,  1.2246e-01,  3.1819e-01,  ...,  8.5033e-02,\n",
              "          -2.8407e-03,  2.0000e+00],\n",
              "         [-2.6161e-01,  1.0688e-01,  2.8986e-01,  ...,  6.2090e-02,\n",
              "           7.8389e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.6948e-03, -1.1182e-01, -4.3777e-02,  ...,  4.2017e-02,\n",
              "           2.0616e-01,  2.0000e+00],\n",
              "         [ 1.6692e-01, -5.2793e-03, -3.2044e-02,  ...,  2.5161e-01,\n",
              "           7.5452e-02,  2.0000e+00],\n",
              "         [ 1.8099e-01,  6.1328e-02, -2.7214e-02,  ...,  3.1572e-01,\n",
              "          -6.6988e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 7.4787e-02,  9.8017e-02,  7.0732e-02,  ...,  5.3158e-02,\n",
              "           6.0429e-02,  2.0000e+00],\n",
              "         [-1.5940e-01,  1.2447e-01,  3.0593e-01,  ...,  1.0162e-01,\n",
              "          -5.5901e-04,  2.0000e+00],\n",
              "         [-2.4758e-01,  1.0698e-01,  2.8904e-01,  ...,  6.4208e-02,\n",
              "           6.4128e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0157, -0.1253, -0.0289,  ...,  0.0459,  0.2113,  1.0000],\n",
              "         [ 0.1497, -0.0295, -0.0065,  ...,  0.2626,  0.1213,  1.0000],\n",
              "         [ 0.1524,  0.0322,  0.0082,  ...,  0.3377, -0.0174,  1.0000],\n",
              "         ...,\n",
              "         [-0.0292,  0.1231,  0.1981,  ...,  0.0828,  0.0203,  1.0000],\n",
              "         [-0.2228,  0.1268,  0.3370,  ...,  0.0799, -0.0116,  1.0000],\n",
              "         [-0.2713,  0.1074,  0.2975,  ...,  0.0572,  0.0053,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 2.2371e-02, -1.1991e-01, -7.3738e-02,  ...,  5.9432e-02,\n",
              "           2.1319e-01,  3.0000e+00],\n",
              "         [ 1.8996e-01, -6.0434e-03, -6.3577e-02,  ...,  2.3767e-01,\n",
              "           8.0129e-02,  3.0000e+00],\n",
              "         [ 1.8640e-01,  4.5667e-02, -5.4642e-02,  ...,  3.2559e-01,\n",
              "          -8.1245e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2682e-01,  8.6782e-02,  3.1183e-02,  ...,  4.7552e-02,\n",
              "           5.8178e-02,  3.0000e+00],\n",
              "         [-1.1126e-01,  1.3227e-01,  2.4113e-01,  ...,  8.6950e-02,\n",
              "          -1.9247e-03,  3.0000e+00],\n",
              "         [-2.1966e-01,  9.2953e-02,  2.6023e-01,  ...,  7.7063e-02,\n",
              "           2.0106e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0358, -0.1484, -0.0447,  ...,  0.0634,  0.2124,  3.0000],\n",
              "         [ 0.1512, -0.1016, -0.0531,  ...,  0.2825,  0.1746,  3.0000],\n",
              "         [ 0.0962, -0.0886, -0.0520,  ...,  0.3856,  0.0830,  3.0000],\n",
              "         ...,\n",
              "         [-0.1800,  0.0418,  0.2277,  ...,  0.0882, -0.0161,  3.0000],\n",
              "         [-0.2772,  0.0680,  0.2352,  ...,  0.0712, -0.0552,  3.0000],\n",
              "         [-0.2798,  0.0487,  0.2535,  ...,  0.0276, -0.0304,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0304, -0.1456, -0.0420,  ...,  0.0537,  0.2118,  3.0000],\n",
              "         [ 0.1500, -0.0793, -0.0626,  ...,  0.2811,  0.1459,  3.0000],\n",
              "         [ 0.1155, -0.0675, -0.0679,  ...,  0.3744,  0.0433,  3.0000],\n",
              "         ...,\n",
              "         [-0.1175,  0.0414,  0.1888,  ...,  0.1012,  0.0241,  3.0000],\n",
              "         [-0.2305,  0.0382,  0.2532,  ...,  0.0743, -0.0238,  3.0000],\n",
              "         [-0.2854,  0.0435,  0.2612,  ...,  0.0398, -0.0206,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.1627e-02, -1.3172e-01, -2.6288e-02,  ...,  4.3969e-02,\n",
              "           2.0898e-01,  3.0000e+00],\n",
              "         [ 1.3300e-01, -4.3993e-02, -2.9461e-03,  ...,  2.5160e-01,\n",
              "           1.2983e-01,  3.0000e+00],\n",
              "         [ 1.2326e-01,  5.0390e-03,  1.6760e-02,  ...,  3.3316e-01,\n",
              "           1.3758e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-9.1378e-02,  1.3080e-01,  2.3385e-01,  ...,  7.9772e-02,\n",
              "           3.1774e-03,  3.0000e+00],\n",
              "         [-2.4769e-01,  1.2437e-01,  3.3977e-01,  ...,  6.6058e-02,\n",
              "          -2.8038e-02,  3.0000e+00],\n",
              "         [-2.9532e-01,  9.2913e-02,  2.9995e-01,  ...,  4.9302e-02,\n",
              "          -1.1177e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.7994e-02, -1.1825e-01, -3.3485e-02,  ...,  3.6057e-02,\n",
              "           2.0291e-01,  3.0000e+00],\n",
              "         [ 1.2742e-01, -1.4870e-02, -5.1988e-03,  ...,  2.3581e-01,\n",
              "           9.3139e-02,  3.0000e+00],\n",
              "         [ 1.2897e-01,  5.2035e-02,  1.0208e-02,  ...,  3.1012e-01,\n",
              "          -4.7779e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 8.4958e-05,  1.2821e-01,  1.5704e-01,  ...,  3.4265e-02,\n",
              "           3.0449e-02,  3.0000e+00],\n",
              "         [-2.1336e-01,  1.2317e-01,  3.3690e-01,  ...,  5.1978e-02,\n",
              "          -1.2413e-02,  3.0000e+00],\n",
              "         [-2.7951e-01,  9.5463e-02,  3.0481e-01,  ...,  4.2471e-02,\n",
              "          -4.2152e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5128e-02, -1.3240e-01, -2.5378e-02,  ...,  4.5786e-02,\n",
              "           2.0891e-01,  3.0000e+00],\n",
              "         [ 1.3484e-01, -4.4367e-02, -8.5357e-03,  ...,  2.5421e-01,\n",
              "           1.3238e-01,  3.0000e+00],\n",
              "         [ 1.1862e-01, -1.7318e-03,  1.1974e-02,  ...,  3.3871e-01,\n",
              "           1.1563e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.2464e-01,  1.2765e-01,  2.4528e-01,  ...,  7.6957e-02,\n",
              "          -7.5911e-03,  3.0000e+00],\n",
              "         [-2.5711e-01,  1.1278e-01,  3.3198e-01,  ...,  6.0573e-02,\n",
              "          -3.5985e-02,  3.0000e+00],\n",
              "         [-3.0272e-01,  8.9220e-02,  3.0084e-01,  ...,  4.4763e-02,\n",
              "          -1.6630e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0323e-02, -1.3773e-01, -2.9961e-02,  ...,  5.5056e-02,\n",
              "           2.1913e-01,  3.0000e+00],\n",
              "         [ 1.4841e-01, -4.4756e-02, -8.8664e-03,  ...,  2.4057e-01,\n",
              "           1.4160e-01,  3.0000e+00],\n",
              "         [ 1.3593e-01,  4.1494e-03,  1.2184e-02,  ...,  3.2485e-01,\n",
              "          -8.5827e-05,  3.0000e+00],\n",
              "         ...,\n",
              "         [-5.9595e-02,  1.5465e-01,  2.0001e-01,  ...,  4.6890e-02,\n",
              "           2.1218e-02,  3.0000e+00],\n",
              "         [-2.2963e-01,  1.4431e-01,  3.0870e-01,  ...,  5.3202e-02,\n",
              "          -1.4656e-02,  3.0000e+00],\n",
              "         [-2.7719e-01,  1.0699e-01,  2.8687e-01,  ...,  7.1913e-02,\n",
              "           2.0159e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-9.6663e-03, -1.1324e-01, -3.4764e-02,  ...,  4.2411e-02,\n",
              "           2.0851e-01,  3.0000e+00],\n",
              "         [ 1.5299e-01, -1.0524e-02, -1.3203e-02,  ...,  2.4594e-01,\n",
              "           1.0086e-01,  3.0000e+00],\n",
              "         [ 1.6282e-01,  6.0498e-02, -2.8194e-04,  ...,  3.1144e-01,\n",
              "          -4.9245e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 3.5228e-02,  1.1680e-01,  1.2289e-01,  ...,  3.8100e-02,\n",
              "           5.0202e-02,  3.0000e+00],\n",
              "         [-1.8547e-01,  1.2706e-01,  3.2413e-01,  ...,  7.6058e-02,\n",
              "           3.4856e-03,  3.0000e+00],\n",
              "         [-2.5680e-01,  1.1157e-01,  2.9449e-01,  ...,  5.4932e-02,\n",
              "           7.3290e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3215e-02, -1.2043e-01, -3.1706e-02,  ...,  4.4977e-02,\n",
              "           2.1061e-01,  3.0000e+00],\n",
              "         [ 1.4992e-01, -2.2157e-02, -1.2832e-02,  ...,  2.5777e-01,\n",
              "           1.1213e-01,  3.0000e+00],\n",
              "         [ 1.5634e-01,  4.6152e-02,  1.4670e-03,  ...,  3.2888e-01,\n",
              "          -3.2741e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 7.4715e-03,  1.2219e-01,  1.6499e-01,  ...,  6.6342e-02,\n",
              "           3.5533e-02,  3.0000e+00],\n",
              "         [-2.0301e-01,  1.2664e-01,  3.2963e-01,  ...,  8.0326e-02,\n",
              "          -9.3541e-04,  3.0000e+00],\n",
              "         [-2.6309e-01,  1.0916e-01,  2.9554e-01,  ...,  5.8799e-02,\n",
              "           9.0280e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0377, -0.1262, -0.0391,  ...,  0.0675,  0.2068,  3.0000],\n",
              "         [ 0.1743,  0.0179, -0.0315,  ...,  0.2917,  0.1234,  3.0000],\n",
              "         [ 0.1868,  0.0567, -0.0086,  ...,  0.3595,  0.0546,  3.0000],\n",
              "         ...,\n",
              "         [-0.0846,  0.1027,  0.2275,  ...,  0.1402, -0.0142,  3.0000],\n",
              "         [-0.2140,  0.0975,  0.3091,  ...,  0.1120, -0.0385,  3.0000],\n",
              "         [-0.2786,  0.0857,  0.2803,  ...,  0.0578, -0.0188,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0372, -0.1406, -0.0314,  ...,  0.0615,  0.2144,  3.0000],\n",
              "         [ 0.1582, -0.0616, -0.0362,  ...,  0.2622,  0.1514,  3.0000],\n",
              "         [ 0.1211, -0.0406, -0.0206,  ...,  0.3530,  0.0504,  3.0000],\n",
              "         ...,\n",
              "         [-0.1288,  0.1011,  0.2290,  ...,  0.0666,  0.0096,  3.0000],\n",
              "         [-0.2609,  0.0886,  0.2866,  ...,  0.0582, -0.0350,  3.0000],\n",
              "         [-0.2952,  0.0801,  0.2768,  ...,  0.0465, -0.0149,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0561, -0.2066, -0.1145,  ..., -0.0132,  0.1891,  3.0000],\n",
              "         [ 0.3201,  0.0222, -0.1070,  ...,  0.0609,  0.0181,  3.0000],\n",
              "         [ 0.3167,  0.0574, -0.0884,  ...,  0.1153, -0.0830,  3.0000],\n",
              "         ...,\n",
              "         [ 0.1674, -0.0213, -0.1772,  ...,  0.0360,  0.0796,  3.0000],\n",
              "         [ 0.0270,  0.0436,  0.1019,  ...,  0.1178, -0.0152,  3.0000],\n",
              "         [-0.1685,  0.0225,  0.2783,  ...,  0.0568, -0.0096,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9721e-02, -1.3122e-01, -3.3558e-02,  ...,  5.5476e-02,\n",
              "           2.1867e-01,  3.0000e+00],\n",
              "         [ 1.3666e-01, -4.3382e-02, -9.6612e-03,  ...,  2.4290e-01,\n",
              "           1.4167e-01,  3.0000e+00],\n",
              "         [ 1.3261e-01,  1.4724e-02,  1.4606e-02,  ...,  3.2238e-01,\n",
              "          -7.5058e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-6.0629e-02,  1.4186e-01,  2.2085e-01,  ...,  6.6256e-02,\n",
              "           8.5436e-03,  3.0000e+00],\n",
              "         [-2.3723e-01,  1.3362e-01,  3.3586e-01,  ...,  6.7132e-02,\n",
              "          -2.1998e-02,  3.0000e+00],\n",
              "         [-2.7940e-01,  1.0054e-01,  2.9655e-01,  ...,  6.7259e-02,\n",
              "           1.2493e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.9286e-02, -1.3475e-01, -3.3612e-02,  ...,  5.3176e-02,\n",
              "           2.2093e-01,  3.0000e+00],\n",
              "         [ 1.4775e-01, -4.0117e-02, -1.2729e-02,  ...,  2.6014e-01,\n",
              "           1.4269e-01,  3.0000e+00],\n",
              "         [ 1.4002e-01,  1.5891e-02,  1.1442e-02,  ...,  3.4370e-01,\n",
              "           2.5741e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-7.5331e-02,  1.4801e-01,  2.1302e-01,  ...,  7.5469e-02,\n",
              "           5.4081e-03,  3.0000e+00],\n",
              "         [-2.3136e-01,  1.3398e-01,  3.1465e-01,  ...,  6.7555e-02,\n",
              "          -3.0757e-02,  3.0000e+00],\n",
              "         [-2.8190e-01,  9.0157e-02,  2.8920e-01,  ...,  6.8510e-02,\n",
              "          -1.3500e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0175, -0.1303, -0.0322,  ...,  0.0430,  0.2096,  3.0000],\n",
              "         [ 0.1455, -0.0308, -0.0084,  ...,  0.2599,  0.1221,  3.0000],\n",
              "         [ 0.1421,  0.0251,  0.0108,  ...,  0.3397, -0.0135,  3.0000],\n",
              "         ...,\n",
              "         [-0.0361,  0.1265,  0.1864,  ...,  0.0831,  0.0170,  3.0000],\n",
              "         [-0.2189,  0.1229,  0.3203,  ...,  0.0726, -0.0171,  3.0000],\n",
              "         [-0.2798,  0.0924,  0.2909,  ...,  0.0557, -0.0098,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 6.0791e-02, -1.7408e-01, -1.0676e-01,  ...,  5.6695e-02,\n",
              "           2.0970e-01,  3.0000e+00],\n",
              "         [ 2.8853e-01, -3.8610e-03, -1.1436e-01,  ...,  1.9058e-01,\n",
              "           3.1892e-02,  3.0000e+00],\n",
              "         [ 2.6733e-01,  2.0961e-02, -8.5681e-02,  ...,  2.6974e-01,\n",
              "          -9.2270e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 2.1513e-01, -8.2696e-03, -1.1079e-02,  ...,  9.3773e-02,\n",
              "          -5.0770e-03,  3.0000e+00],\n",
              "         [-1.0343e-03,  3.2727e-02,  1.6716e-01,  ...,  1.4075e-01,\n",
              "          -5.0802e-02,  3.0000e+00],\n",
              "         [-1.4433e-01,  2.0009e-02,  2.6709e-01,  ...,  8.1126e-02,\n",
              "          -1.4698e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0164, -0.1193, -0.0357,  ...,  0.0368,  0.2033,  3.0000],\n",
              "         [ 0.1347, -0.0095, -0.0088,  ...,  0.2391,  0.0879,  3.0000],\n",
              "         [ 0.1404,  0.0586,  0.0058,  ...,  0.3106, -0.0555,  3.0000],\n",
              "         ...,\n",
              "         [ 0.0123,  0.1262,  0.1377,  ...,  0.0375,  0.0294,  3.0000],\n",
              "         [-0.2026,  0.1229,  0.3268,  ...,  0.0575, -0.0141,  3.0000],\n",
              "         [-0.2725,  0.0961,  0.2998,  ...,  0.0456, -0.0049,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-6.4763e-03, -1.2219e-01, -4.6383e-02,  ...,  5.1405e-02,\n",
              "           2.1882e-01,  3.0000e+00],\n",
              "         [ 1.4130e-01, -2.0348e-02, -1.9490e-02,  ...,  2.3117e-01,\n",
              "           1.2408e-01,  3.0000e+00],\n",
              "         [ 1.4063e-01,  4.3200e-02, -2.1278e-04,  ...,  3.1301e-01,\n",
              "          -3.9623e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3793e-02,  1.6009e-01,  1.6358e-01,  ...,  2.9728e-02,\n",
              "           2.7345e-02,  3.0000e+00],\n",
              "         [-1.9604e-01,  1.5173e-01,  3.0936e-01,  ...,  4.5174e-02,\n",
              "          -1.1982e-02,  3.0000e+00],\n",
              "         [-2.5160e-01,  9.5183e-02,  2.8646e-01,  ...,  6.8294e-02,\n",
              "          -6.4460e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0158, -0.1188, -0.0353,  ...,  0.0461,  0.2151,  3.0000],\n",
              "         [ 0.1343, -0.0172, -0.0111,  ...,  0.2336,  0.1170,  3.0000],\n",
              "         [ 0.1394,  0.0523,  0.0087,  ...,  0.3036, -0.0364,  3.0000],\n",
              "         ...,\n",
              "         [-0.0163,  0.1429,  0.1667,  ...,  0.0344,  0.0266,  3.0000],\n",
              "         [-0.2161,  0.1499,  0.3287,  ...,  0.0562, -0.0047,  3.0000],\n",
              "         [-0.2722,  0.1080,  0.3016,  ...,  0.0663,  0.0079,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3998e-02, -1.3364e-01, -2.6830e-02,  ...,  5.1873e-02,\n",
              "           2.1704e-01,  3.0000e+00],\n",
              "         [ 1.3587e-01, -4.6482e-02, -2.3429e-03,  ...,  2.4037e-01,\n",
              "           1.3885e-01,  3.0000e+00],\n",
              "         [ 1.2833e-01,  7.7182e-03,  2.0040e-02,  ...,  3.1846e-01,\n",
              "          -2.1702e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0650e-01,  1.5271e-01,  2.4588e-01,  ...,  4.9637e-02,\n",
              "          -1.0513e-03,  3.0000e+00],\n",
              "         [-2.5036e-01,  1.3690e-01,  3.3493e-01,  ...,  5.5419e-02,\n",
              "          -2.7272e-02,  3.0000e+00],\n",
              "         [-2.8558e-01,  1.0478e-01,  2.9731e-01,  ...,  6.2726e-02,\n",
              "           1.0776e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.4364e-02, -1.3286e-01, -2.4839e-02,  ...,  4.4475e-02,\n",
              "           2.0864e-01,  3.0000e+00],\n",
              "         [ 1.3264e-01, -4.5923e-02, -3.7947e-03,  ...,  2.5445e-01,\n",
              "           1.3248e-01,  3.0000e+00],\n",
              "         [ 1.1780e-01, -2.3134e-03,  1.4644e-02,  ...,  3.3672e-01,\n",
              "           1.3868e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.2228e-01,  1.3263e-01,  2.4992e-01,  ...,  7.8226e-02,\n",
              "          -3.8005e-03,  3.0000e+00],\n",
              "         [-2.5722e-01,  1.1711e-01,  3.3677e-01,  ...,  6.5320e-02,\n",
              "          -3.1647e-02,  3.0000e+00],\n",
              "         [-3.0188e-01,  9.1062e-02,  3.0186e-01,  ...,  4.8232e-02,\n",
              "          -1.5337e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0326, -0.1486, -0.0363,  ...,  0.0620,  0.2163,  3.0000],\n",
              "         [ 0.1662, -0.0790, -0.0490,  ...,  0.2794,  0.1594,  3.0000],\n",
              "         [ 0.1211, -0.0636, -0.0434,  ...,  0.3736,  0.0596,  3.0000],\n",
              "         ...,\n",
              "         [-0.1352,  0.0595,  0.2230,  ...,  0.0846,  0.0031,  3.0000],\n",
              "         [-0.2518,  0.0554,  0.2623,  ...,  0.0702, -0.0392,  3.0000],\n",
              "         [-0.2843,  0.0563,  0.2662,  ...,  0.0413, -0.0181,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0240, -0.1318, -0.0270,  ...,  0.0451,  0.2102,  3.0000],\n",
              "         [ 0.1342, -0.0482, -0.0102,  ...,  0.2522,  0.1357,  3.0000],\n",
              "         [ 0.1182, -0.0058,  0.0107,  ...,  0.3389,  0.0107,  3.0000],\n",
              "         ...,\n",
              "         [-0.1230,  0.1294,  0.2456,  ...,  0.0825, -0.0034,  3.0000],\n",
              "         [-0.2550,  0.1192,  0.3301,  ...,  0.0645, -0.0344,  3.0000],\n",
              "         [-0.3039,  0.0874,  0.2982,  ...,  0.0474, -0.0177,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0345, -0.1324, -0.0335,  ...,  0.0548,  0.2084,  3.0000],\n",
              "         [ 0.1429, -0.0633, -0.0438,  ...,  0.2717,  0.1434,  3.0000],\n",
              "         [ 0.1123, -0.0419, -0.0396,  ...,  0.3617,  0.0409,  3.0000],\n",
              "         ...,\n",
              "         [-0.1424,  0.0716,  0.2285,  ...,  0.0879,  0.0089,  3.0000],\n",
              "         [-0.2539,  0.0610,  0.2847,  ...,  0.0671, -0.0318,  3.0000],\n",
              "         [-0.3020,  0.0717,  0.2811,  ...,  0.0365, -0.0179,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0156, -0.1258, -0.0289,  ...,  0.0446,  0.2109,  3.0000],\n",
              "         [ 0.1507, -0.0322, -0.0065,  ...,  0.2601,  0.1217,  3.0000],\n",
              "         [ 0.1525,  0.0284,  0.0093,  ...,  0.3363, -0.0178,  3.0000],\n",
              "         ...,\n",
              "         [-0.0263,  0.1228,  0.1912,  ...,  0.0788,  0.0226,  3.0000],\n",
              "         [-0.2208,  0.1273,  0.3308,  ...,  0.0759, -0.0106,  3.0000],\n",
              "         [-0.2716,  0.1080,  0.2946,  ...,  0.0554,  0.0053,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4310e-02, -1.3009e-01, -2.4987e-02,  ...,  4.1997e-02,\n",
              "           2.0871e-01,  3.0000e+00],\n",
              "         [ 1.2828e-01, -4.5904e-02, -2.2938e-03,  ...,  2.3934e-01,\n",
              "           1.3285e-01,  3.0000e+00],\n",
              "         [ 1.1580e-01,  1.7489e-03,  1.9784e-02,  ...,  3.2264e-01,\n",
              "           5.1778e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.1411e-01,  1.3883e-01,  2.5377e-01,  ...,  7.0265e-02,\n",
              "           1.7180e-03,  3.0000e+00],\n",
              "         [-2.5895e-01,  1.2621e-01,  3.4691e-01,  ...,  5.7236e-02,\n",
              "          -2.9413e-02,  3.0000e+00],\n",
              "         [-3.0536e-01,  9.1187e-02,  3.0351e-01,  ...,  4.6030e-02,\n",
              "          -1.5327e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0330, -0.1557, -0.0381,  ...,  0.0603,  0.2150,  3.0000],\n",
              "         [ 0.1702, -0.0849, -0.0499,  ...,  0.2766,  0.1529,  3.0000],\n",
              "         [ 0.1253, -0.0672, -0.0457,  ...,  0.3638,  0.0520,  3.0000],\n",
              "         ...,\n",
              "         [-0.1062,  0.0617,  0.2007,  ...,  0.0765,  0.0170,  3.0000],\n",
              "         [-0.2307,  0.0622,  0.2486,  ...,  0.0621, -0.0327,  3.0000],\n",
              "         [-0.2735,  0.0526,  0.2576,  ...,  0.0454, -0.0191,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.2111e-02, -1.5866e-01, -5.6272e-02,  ...,  6.0367e-02,\n",
              "           2.1104e-01,  3.0000e+00],\n",
              "         [ 1.4067e-01, -1.1448e-01, -7.7314e-02,  ...,  3.0453e-01,\n",
              "           1.5274e-01,  3.0000e+00],\n",
              "         [ 8.9430e-02, -1.1576e-01, -8.4571e-02,  ...,  4.0139e-01,\n",
              "           7.7006e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.4446e-01,  8.3808e-03,  1.9559e-01,  ...,  1.1467e-01,\n",
              "          -1.4623e-02,  3.0000e+00],\n",
              "         [-2.2110e-01,  1.7425e-02,  2.0098e-01,  ...,  9.3214e-02,\n",
              "          -4.5059e-02,  3.0000e+00],\n",
              "         [-2.6194e-01,  1.7050e-03,  2.3219e-01,  ...,  3.7674e-02,\n",
              "          -2.9915e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.6702e-02, -1.1914e-01, -3.4183e-02,  ...,  3.4926e-02,\n",
              "           2.0414e-01,  3.0000e+00],\n",
              "         [ 1.3140e-01, -1.4045e-02, -3.9802e-03,  ...,  2.3261e-01,\n",
              "           9.4971e-02,  3.0000e+00],\n",
              "         [ 1.3270e-01,  5.0988e-02,  1.1913e-02,  ...,  3.0392e-01,\n",
              "          -4.8162e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 2.9067e-03,  1.2873e-01,  1.5135e-01,  ...,  3.3766e-02,\n",
              "           3.4194e-02,  3.0000e+00],\n",
              "         [-2.1156e-01,  1.2527e-01,  3.3241e-01,  ...,  5.0294e-02,\n",
              "          -1.1998e-02,  3.0000e+00],\n",
              "         [-2.8082e-01,  9.6174e-02,  3.0452e-01,  ...,  4.2615e-02,\n",
              "          -3.9451e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1396e-02, -1.2506e-01, -2.6745e-02,  ...,  3.9018e-02,\n",
              "           2.0785e-01,  3.0000e+00],\n",
              "         [ 1.2667e-01, -3.1451e-02,  2.7752e-04,  ...,  2.3245e-01,\n",
              "           1.1869e-01,  3.0000e+00],\n",
              "         [ 1.2329e-01,  2.8911e-02,  2.0697e-02,  ...,  3.0932e-01,\n",
              "          -1.9827e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-5.3940e-02,  1.3436e-01,  2.1559e-01,  ...,  4.9713e-02,\n",
              "           2.0290e-02,  3.0000e+00],\n",
              "         [-2.3744e-01,  1.3071e-01,  3.5054e-01,  ...,  4.8844e-02,\n",
              "          -1.3905e-02,  3.0000e+00],\n",
              "         [-2.9443e-01,  9.7564e-02,  3.0894e-01,  ...,  4.2614e-02,\n",
              "          -5.5649e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0265, -0.1358, -0.0262,  ...,  0.0513,  0.2144,  3.0000],\n",
              "         [ 0.1437, -0.0461, -0.0065,  ...,  0.2459,  0.1361,  3.0000],\n",
              "         [ 0.1320,  0.0060,  0.0193,  ...,  0.3238,  0.0045,  3.0000],\n",
              "         ...,\n",
              "         [-0.1275,  0.1507,  0.2511,  ...,  0.0586, -0.0119,  3.0000],\n",
              "         [-0.2604,  0.1309,  0.3314,  ...,  0.0550, -0.0358,  3.0000],\n",
              "         [-0.2917,  0.0949,  0.2984,  ...,  0.0590, -0.0075,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 5.0999e-03, -1.1186e-01, -5.7125e-02,  ...,  5.0795e-02,\n",
              "           2.1115e-01,  3.0000e+00],\n",
              "         [ 1.5807e-01, -1.8330e-02, -4.7397e-02,  ...,  2.1432e-01,\n",
              "           1.1152e-01,  3.0000e+00],\n",
              "         [ 1.4636e-01,  2.9186e-02, -3.2059e-02,  ...,  3.0116e-01,\n",
              "          -5.1060e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 7.1943e-02,  1.1100e-01,  7.6417e-02,  ...,  3.1494e-02,\n",
              "           5.4771e-02,  3.0000e+00],\n",
              "         [-1.5250e-01,  1.4285e-01,  2.7436e-01,  ...,  7.6558e-02,\n",
              "           1.3761e-03,  3.0000e+00],\n",
              "         [-2.5300e-01,  9.4362e-02,  2.7620e-01,  ...,  6.9654e-02,\n",
              "          -1.1768e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0311e-02, -1.2581e-01, -2.8642e-02,  ...,  3.5458e-02,\n",
              "           2.0701e-01,  3.0000e+00],\n",
              "         [ 1.2231e-01, -2.7709e-02,  1.0738e-03,  ...,  2.3894e-01,\n",
              "           1.0830e-01,  3.0000e+00],\n",
              "         [ 1.2804e-01,  4.1664e-02,  2.3461e-02,  ...,  3.1473e-01,\n",
              "          -3.3459e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-2.6617e-02,  1.2958e-01,  1.8790e-01,  ...,  4.7080e-02,\n",
              "           3.1141e-02,  3.0000e+00],\n",
              "         [-2.2262e-01,  1.2875e-01,  3.4144e-01,  ...,  5.2259e-02,\n",
              "          -7.8532e-03,  3.0000e+00],\n",
              "         [-2.8459e-01,  9.7861e-02,  3.0253e-01,  ...,  4.4318e-02,\n",
              "          -4.7737e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1417, -0.0386,  ...,  0.0542,  0.2126,  3.0000],\n",
              "         [ 0.1481, -0.0737, -0.0591,  ...,  0.2800,  0.1520,  3.0000],\n",
              "         [ 0.1118, -0.0615, -0.0615,  ...,  0.3728,  0.0504,  3.0000],\n",
              "         ...,\n",
              "         [-0.1317,  0.0499,  0.2118,  ...,  0.0972,  0.0198,  3.0000],\n",
              "         [-0.2418,  0.0441,  0.2668,  ...,  0.0726, -0.0253,  3.0000],\n",
              "         [-0.2935,  0.0500,  0.2695,  ...,  0.0385, -0.0186,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 6.6921e-06, -1.0930e-01, -5.8084e-02,  ...,  4.3424e-02,\n",
              "           2.1007e-01,  3.0000e+00],\n",
              "         [ 1.5179e-01, -6.2386e-03, -4.0219e-02,  ...,  2.1846e-01,\n",
              "           9.1796e-02,  3.0000e+00],\n",
              "         [ 1.5764e-01,  4.8820e-02, -2.9057e-02,  ...,  2.9691e-01,\n",
              "          -6.8260e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 5.1278e-02,  1.0718e-01,  8.1310e-02,  ...,  2.2210e-02,\n",
              "           3.9378e-02,  3.0000e+00],\n",
              "         [-1.7112e-01,  1.3738e-01,  3.0061e-01,  ...,  7.0909e-02,\n",
              "          -1.1220e-02,  3.0000e+00],\n",
              "         [-2.6196e-01,  1.0321e-01,  2.9061e-01,  ...,  6.1537e-02,\n",
              "           3.0911e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0317, -0.1404, -0.0387,  ...,  0.0587,  0.2100,  1.0000],\n",
              "         [ 0.1490, -0.0741, -0.0580,  ...,  0.2870,  0.1399,  1.0000],\n",
              "         [ 0.1208, -0.0572, -0.0624,  ...,  0.3760,  0.0370,  1.0000],\n",
              "         ...,\n",
              "         [-0.1154,  0.0419,  0.1951,  ...,  0.0964,  0.0219,  1.0000],\n",
              "         [-0.2290,  0.0391,  0.2591,  ...,  0.0748, -0.0233,  1.0000],\n",
              "         [-0.2839,  0.0521,  0.2651,  ...,  0.0431, -0.0168,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.9671e-02, -1.6565e-01, -5.4881e-02,  ...,  5.8644e-02,\n",
              "           2.0933e-01,  1.0000e+00],\n",
              "         [ 1.4092e-01, -1.2349e-01, -7.3862e-02,  ...,  2.9936e-01,\n",
              "           1.5091e-01,  1.0000e+00],\n",
              "         [ 9.6781e-02, -1.2497e-01, -8.1546e-02,  ...,  3.8225e-01,\n",
              "           8.7865e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.2778e-01,  4.8147e-04,  1.8947e-01,  ...,  1.1494e-01,\n",
              "           1.3039e-03,  1.0000e+00],\n",
              "         [-2.1135e-01,  9.7101e-03,  2.0280e-01,  ...,  9.2157e-02,\n",
              "          -3.7781e-02,  1.0000e+00],\n",
              "         [-2.5840e-01, -2.5433e-03,  2.3244e-01,  ...,  3.5913e-02,\n",
              "          -2.8575e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0352, -0.1569, -0.0586,  ...,  0.0621,  0.2108,  1.0000],\n",
              "         [ 0.1359, -0.1175, -0.0816,  ...,  0.3035,  0.1556,  1.0000],\n",
              "         [ 0.0820, -0.1173, -0.0906,  ...,  0.4032,  0.0793,  1.0000],\n",
              "         ...,\n",
              "         [-0.1613,  0.0093,  0.1914,  ...,  0.1085, -0.0322,  1.0000],\n",
              "         [-0.2277,  0.0188,  0.1947,  ...,  0.0882, -0.0544,  1.0000],\n",
              "         [-0.2632,  0.0041,  0.2312,  ...,  0.0306, -0.0318,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0273, -0.1357, -0.0380,  ...,  0.0614,  0.2089,  1.0000],\n",
              "         [ 0.1537, -0.0722, -0.0557,  ...,  0.2865,  0.1346,  1.0000],\n",
              "         [ 0.1351, -0.0506, -0.0593,  ...,  0.3789,  0.0233,  1.0000],\n",
              "         ...,\n",
              "         [-0.0962,  0.0554,  0.1871,  ...,  0.1052,  0.0188,  1.0000],\n",
              "         [-0.2225,  0.0560,  0.2634,  ...,  0.0827, -0.0238,  1.0000],\n",
              "         [-0.2804,  0.0628,  0.2663,  ...,  0.0496, -0.0192,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2219e-02, -1.3671e-01, -3.0924e-02,  ...,  5.4142e-02,\n",
              "           2.1606e-01,  1.0000e+00],\n",
              "         [ 1.4187e-01, -4.8140e-02, -9.7058e-03,  ...,  2.4891e-01,\n",
              "           1.3668e-01,  1.0000e+00],\n",
              "         [ 1.3318e-01, -8.3086e-04,  1.3964e-02,  ...,  3.2744e-01,\n",
              "          -1.0226e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1401e-01,  1.5167e-01,  2.3717e-01,  ...,  5.4468e-02,\n",
              "          -1.0227e-02,  1.0000e+00],\n",
              "         [-2.4387e-01,  1.2755e-01,  3.1924e-01,  ...,  5.5935e-02,\n",
              "          -3.5379e-02,  1.0000e+00],\n",
              "         [-2.7901e-01,  1.0096e-01,  2.8922e-01,  ...,  6.0974e-02,\n",
              "          -6.1557e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0233, -0.1346, -0.0280,  ...,  0.0516,  0.2148,  1.0000],\n",
              "         [ 0.1419, -0.0472, -0.0098,  ...,  0.2527,  0.1371,  1.0000],\n",
              "         [ 0.1293, -0.0027,  0.0162,  ...,  0.3366,  0.0053,  1.0000],\n",
              "         ...,\n",
              "         [-0.1277,  0.1457,  0.2462,  ...,  0.0609, -0.0125,  1.0000],\n",
              "         [-0.2498,  0.1244,  0.3238,  ...,  0.0580, -0.0381,  1.0000],\n",
              "         [-0.2887,  0.0962,  0.2952,  ...,  0.0562, -0.0116,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0325, -0.1262, -0.0314,  ...,  0.0633,  0.2125,  1.0000],\n",
              "         [ 0.1515, -0.0567, -0.0319,  ...,  0.2580,  0.1501,  1.0000],\n",
              "         [ 0.1223, -0.0309, -0.0134,  ...,  0.3532,  0.0379,  1.0000],\n",
              "         ...,\n",
              "         [-0.1698,  0.1108,  0.2665,  ...,  0.0798, -0.0219,  1.0000],\n",
              "         [-0.2766,  0.0955,  0.3094,  ...,  0.0734, -0.0470,  1.0000],\n",
              "         [-0.2964,  0.0905,  0.2823,  ...,  0.0488, -0.0131,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0361, -0.1553, -0.0553,  ...,  0.0582,  0.2129,  1.0000],\n",
              "         [ 0.1407, -0.1133, -0.0799,  ...,  0.2937,  0.1591,  1.0000],\n",
              "         [ 0.0880, -0.1154, -0.0857,  ...,  0.3924,  0.0827,  1.0000],\n",
              "         ...,\n",
              "         [-0.1560,  0.0053,  0.1989,  ...,  0.1138, -0.0095,  1.0000],\n",
              "         [-0.2375,  0.0178,  0.2101,  ...,  0.0905, -0.0479,  1.0000],\n",
              "         [-0.2766,  0.0069,  0.2416,  ...,  0.0291, -0.0296,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1317, -0.0356,  ...,  0.0582,  0.2102,  1.0000],\n",
              "         [ 0.1423, -0.0650, -0.0506,  ...,  0.2802,  0.1440,  1.0000],\n",
              "         [ 0.1137, -0.0456, -0.0507,  ...,  0.3742,  0.0343,  1.0000],\n",
              "         ...,\n",
              "         [-0.1345,  0.0698,  0.2220,  ...,  0.1009,  0.0065,  1.0000],\n",
              "         [-0.2507,  0.0618,  0.2809,  ...,  0.0759, -0.0330,  1.0000],\n",
              "         [-0.2997,  0.0686,  0.2780,  ...,  0.0419, -0.0204,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0310, -0.1339, -0.0280,  ...,  0.0610,  0.2104,  1.0000],\n",
              "         [ 0.1567, -0.0569, -0.0173,  ...,  0.2639,  0.1413,  1.0000],\n",
              "         [ 0.1311, -0.0253, -0.0021,  ...,  0.3546,  0.0384,  1.0000],\n",
              "         ...,\n",
              "         [-0.1307,  0.1239,  0.2411,  ...,  0.0726, -0.0025,  1.0000],\n",
              "         [-0.2589,  0.1010,  0.3050,  ...,  0.0675, -0.0331,  1.0000],\n",
              "         [-0.2905,  0.0927,  0.2823,  ...,  0.0564, -0.0089,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0147, -0.1280, -0.0294,  ...,  0.0462,  0.2116,  1.0000],\n",
              "         [ 0.1544, -0.0318, -0.0075,  ...,  0.2699,  0.1237,  1.0000],\n",
              "         [ 0.1557,  0.0264,  0.0056,  ...,  0.3465, -0.0097,  1.0000],\n",
              "         ...,\n",
              "         [-0.0323,  0.1224,  0.1925,  ...,  0.0879,  0.0206,  1.0000],\n",
              "         [-0.2160,  0.1257,  0.3246,  ...,  0.0814, -0.0132,  1.0000],\n",
              "         [-0.2687,  0.1055,  0.2925,  ...,  0.0599,  0.0035,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0357, -0.1463, -0.0415,  ...,  0.0617,  0.2174,  1.0000],\n",
              "         [ 0.1575, -0.0853, -0.0538,  ...,  0.2866,  0.1671,  1.0000],\n",
              "         [ 0.1069, -0.0783, -0.0534,  ...,  0.3861,  0.0760,  1.0000],\n",
              "         ...,\n",
              "         [-0.1507,  0.0394,  0.2295,  ...,  0.0914, -0.0022,  1.0000],\n",
              "         [-0.2644,  0.0489,  0.2497,  ...,  0.0737, -0.0431,  1.0000],\n",
              "         [-0.2876,  0.0486,  0.2620,  ...,  0.0357, -0.0176,  1.0000]],\n",
              "        device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert the list of tensors to a list of NumPy arrays\n",
        "final_features_numpy = [tensor.cpu().numpy() for tensor in final_features]\n",
        "\n",
        "# Save the list of NumPy arrays using NumPy's save function\n",
        "np.save('/content/session1.npy', final_features_numpy)"
      ],
      "metadata": {
        "id": "jSWYc1yLxVA4",
        "outputId": "aed5250b-a806-4091-ab76-4ca42f2caafb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "id": "zDSXtjMm_bEz",
        "outputId": "63be7153-6875-4085-fc14-f76bb8d09529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav',\n",
              " 'session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.avi': 'session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav',\n",
              " 'session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.avi': 'session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav',\n",
              " 'session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.avi': 'session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav',\n",
              " 'session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.avi': 'session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.avi': 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.avi': 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.avi': 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.avi': 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.avi': 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.avi': 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.avi': 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.avi': 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav',\n",
              " 'session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.avi': 'session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav',\n",
              " 'session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.avi': 'session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav',\n",
              " 'session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.avi': 'session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav',\n",
              " 'session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.avi': 'session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.avi': 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.avi': 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.avi': 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.avi': 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.avi': 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.avi': 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.avi': 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.avi': 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav',\n",
              " 'session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.avi': 'session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav',\n",
              " 'session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.avi': 'session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav',\n",
              " 'session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.avi': 'session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav',\n",
              " 'session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.avi': 'session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav',\n",
              " 'session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.avi': 'session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav',\n",
              " 'session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.avi': 'session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav',\n",
              " 'session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.avi': 'session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav',\n",
              " 'session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.avi': 'session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav',\n",
              " 'session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.avi': 'session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.avi': 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.avi': 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.avi': 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.avi': 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav',\n",
              " 'session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.avi': 'session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav',\n",
              " 'session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.avi': 'session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav',\n",
              " 'session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.avi': 'session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav',\n",
              " 'session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.avi': 'session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.avi': 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.avi': 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.avi': 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.avi': 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav',\n",
              " 'session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.avi': 'session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.avi': 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.avi': 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.avi': 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.avi': 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav',\n",
              " 'session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.avi': 'session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav',\n",
              " 'session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.avi': 'session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav',\n",
              " 'session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.avi': 'session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav',\n",
              " 'session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.avi': 'session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav',\n",
              " 'session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.avi': 'session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav',\n",
              " 'session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.avi': 'session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav',\n",
              " 'session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.avi': 'session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav',\n",
              " 'session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.avi': 'session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav',\n",
              " 'session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.avi': 'session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav',\n",
              " 'session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.avi': 'session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav',\n",
              " 'session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.avi': 'session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav',\n",
              " 'session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.avi': 'session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav',\n",
              " 'session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.avi': 'session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav',\n",
              " 'session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.avi': 'session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav',\n",
              " 'session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.avi': 'session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav',\n",
              " 'session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.avi': 'session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav',\n",
              " 'session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.avi': 'session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav',\n",
              " 'session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.avi': 'session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.avi': 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.avi': 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.avi': 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.avi': 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav',\n",
              " 'session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.avi': 'session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav',\n",
              " 'session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.avi': 'session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav',\n",
              " 'session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.avi': 'session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav',\n",
              " 'session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.avi': 'session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.avi': 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.avi': 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.avi': 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.avi': 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav',\n",
              " 'session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.avi': 'session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav',\n",
              " 'session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.avi': 'session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav',\n",
              " 'session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.avi': 'session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav',\n",
              " 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.avi': 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav',\n",
              " 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.avi': 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav',\n",
              " 'session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.avi': 'session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav',\n",
              " 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.avi': 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav',\n",
              " 'session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.avi': 'session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.avi': 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.avi': 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.avi': 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.avi': 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav',\n",
              " 'session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.avi': 'session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav',\n",
              " 'session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.avi': 'session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav',\n",
              " 'session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.avi': 'session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav',\n",
              " 'session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.avi': 'session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav',\n",
              " 'session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.avi': 'session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav',\n",
              " 'session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.avi': 'session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav',\n",
              " 'session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.avi': 'session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav',\n",
              " 'session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.avi': 'session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav',\n",
              " 'session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.avi': 'session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.avi': 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.avi': 'session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.avi': 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.avi': 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.avi': 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav',\n",
              " 'session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.avi': 'session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.avi': 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.avi': 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.avi': 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.avi': 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.avi': 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.avi': 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.avi': 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav',\n",
              " 'session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.avi': 'session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav',\n",
              " 'session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.avi': 'session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav',\n",
              " 'session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.avi': 'session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav',\n",
              " 'session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.avi': 'session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.avi': 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.avi': 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.avi': 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.avi': 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.avi': 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.avi': 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.avi': 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav',\n",
              " 'session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.avi': 'session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav',\n",
              " 'session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.avi': 'session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav',\n",
              " 'session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.avi': 'session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav',\n",
              " 'session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.avi': 'session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.avi': 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.avi': 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.avi': 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.avi': 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.avi': 'session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.avi': 'session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav',\n",
              " 'session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.avi': 'session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav',\n",
              " 'session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.avi': 'session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav',\n",
              " 'session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.avi': 'session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.avi': 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.avi': 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.avi': 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.avi': 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav',\n",
              " 'session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.avi': 'session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav',\n",
              " 'session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.avi': 'session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav',\n",
              " 'session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.avi': 'session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav',\n",
              " 'session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.avi': 'session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav',\n",
              " 'session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.avi': 'session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav',\n",
              " 'session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.avi': 'session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav',\n",
              " 'session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.avi': 'session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav',\n",
              " 'session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.avi': 'session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav',\n",
              " 'session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.avi': 'session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav',\n",
              " 'session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.avi': 'session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav',\n",
              " 'session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.avi': 'session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav',\n",
              " 'session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.avi': 'session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav',\n",
              " 'session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.avi': 'session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav',\n",
              " 'session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.avi': 'session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav',\n",
              " 'session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.avi': 'session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav',\n",
              " 'session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.avi': 'session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav',\n",
              " 'session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.avi': 'session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav',\n",
              " 'session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.avi': 'session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav',\n",
              " 'session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.avi': 'session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.avi': 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.avi': 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.avi': 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.avi': 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.avi': 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.avi': 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.avi': 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav',\n",
              " 'session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.avi': 'session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav',\n",
              " 'session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.avi': 'session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav',\n",
              " 'session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.avi': 'session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav',\n",
              " 'session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.avi': 'session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.avi': 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.avi': 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.avi': 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.avi': 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.avi': 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.avi': 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.avi': 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.avi': 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.avi': 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.avi': 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.avi': 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.avi': 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.avi': 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav',\n",
              " 'session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.avi': 'session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav',\n",
              " 'session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.avi': 'session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav',\n",
              " 'session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.avi': 'session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.avi': 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.avi': 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.avi': 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.avi': 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.avi': 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.avi': 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.avi': 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav',\n",
              " 'session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.avi': 'session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav',\n",
              " 'session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.avi': 'session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav',\n",
              " 'session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.avi': 'session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(files.items(), columns=['Video File', 'Audio File'])\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "df.to_csv(\"/content/files.csv\", index=False)"
      ],
      "metadata": {
        "id": "ixa-aVSH_Emx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load('/content/session1.npy', allow_pickle=True)\n",
        "data_extra = np.load('/content/extra_data.npy', allow_pickle=True)\n",
        "\n",
        "# Combine both datasets horizontally if they have the same number of samples\n",
        "combined_data = np.hstack((data, data_extra))\n",
        "\n",
        "# Alternatively, if you want to combine them vertically (assuming they have the same number of features)\n",
        "# combined_data = np.vstack((data, data_extra))\n",
        "\n",
        "# Now you can use the combined data\n",
        "print(combined_data)"
      ],
      "metadata": {
        "id": "yy2NdF1ZzuJ5",
        "outputId": "54831725-1417-40f8-9d0e-d753a8ff5e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[-0.02370743, -0.13372436, -0.02600399, ...,  0.04763608,\n",
            "          0.2146651 ,  0.        ],\n",
            "        [ 0.13718703, -0.04317781, -0.0023525 , ...,  0.24006915,\n",
            "          0.13413857,  0.        ],\n",
            "        [ 0.13125321,  0.0069481 ,  0.02102276, ...,  0.31726515,\n",
            "          0.00163406,  0.        ],\n",
            "        ...,\n",
            "        [-0.11683967,  0.14273715,  0.24456276, ...,  0.0557744 ,\n",
            "         -0.01042632,  0.        ],\n",
            "        [-0.25608966,  0.13328592,  0.33725896, ...,  0.05293535,\n",
            "         -0.03525682,  0.        ],\n",
            "        [-0.2928651 ,  0.10035783,  0.30199414, ...,  0.05435017,\n",
            "         -0.00631261,  0.        ]], dtype=float32)\n",
            " array([[-0.03537891, -0.15370318, -0.05731953, ...,  0.05926085,\n",
            "          0.20858468,  0.        ],\n",
            "        [ 0.1362604 , -0.11624897, -0.07601633, ...,  0.2856895 ,\n",
            "          0.16155516,  0.        ],\n",
            "        [ 0.08013933, -0.1172556 , -0.08037224, ...,  0.38533303,\n",
            "          0.089897  ,  0.        ],\n",
            "        ...,\n",
            "        [-0.18725322,  0.02207345,  0.20027992, ...,  0.10902755,\n",
            "         -0.03959378,  0.        ],\n",
            "        [-0.26085004,  0.03997039,  0.20246252, ...,  0.08697025,\n",
            "         -0.06886151,  0.        ],\n",
            "        [-0.27534908,  0.01665409,  0.23802942, ...,  0.02345487,\n",
            "         -0.03786651,  0.        ]], dtype=float32)\n",
            " array([[-0.03607857, -0.15551116, -0.05748026, ...,  0.06323748,\n",
            "          0.20388332,  0.        ],\n",
            "        [ 0.1257649 , -0.12229984, -0.07067903, ...,  0.28593433,\n",
            "          0.1541902 ,  0.        ],\n",
            "        [ 0.06149955, -0.11712244, -0.0765297 , ...,  0.38928068,\n",
            "          0.08003119,  0.        ],\n",
            "        ...,\n",
            "        [-0.20857674,  0.03517333,  0.19763818, ...,  0.09065197,\n",
            "         -0.06127654,  0.        ],\n",
            "        [-0.26356274,  0.05463022,  0.19619335, ...,  0.07742973,\n",
            "         -0.07909571,  0.        ],\n",
            "        [-0.26289034,  0.02500576,  0.2315907 , ...,  0.02149431,\n",
            "         -0.04270244,  0.        ]], dtype=float32)\n",
            " array([[-0.02500229, -0.12419444, -0.0230597 , ...,  0.03925381,\n",
            "          0.20727544,  0.        ],\n",
            "        [ 0.11965357, -0.03784336,  0.00580956, ...,  0.2303323 ,\n",
            "          0.12200487,  0.        ],\n",
            "        [ 0.11399645,  0.02013571,  0.0284889 , ...,  0.30917853,\n",
            "         -0.01423023,  0.        ],\n",
            "        ...,\n",
            "        [-0.08538663,  0.1339196 ,  0.24221587, ...,  0.05124141,\n",
            "          0.00042278,  0.        ],\n",
            "        [-0.25249273,  0.13092214,  0.36210743, ...,  0.04511794,\n",
            "         -0.02770517,  0.        ],\n",
            "        [-0.3028342 ,  0.09778896,  0.3151183 , ...,  0.04178696,\n",
            "         -0.00610329,  0.        ]], dtype=float32)\n",
            " array([[-0.02486484, -0.12405111, -0.02459172, ...,  0.03837623,\n",
            "          0.20661631,  0.        ],\n",
            "        [ 0.11837108, -0.03533713,  0.00842633, ...,  0.22825694,\n",
            "          0.11790617,  0.        ],\n",
            "        [ 0.11600338,  0.02506382,  0.03001561, ...,  0.30349258,\n",
            "         -0.01837688,  0.        ],\n",
            "        ...,\n",
            "        [-0.0724698 ,  0.1359897 ,  0.23710434, ...,  0.04595288,\n",
            "          0.00697935,  0.        ],\n",
            "        [-0.2477171 ,  0.12963073,  0.3639451 , ...,  0.04053193,\n",
            "         -0.02335457,  0.        ],\n",
            "        [-0.30145678,  0.10072804,  0.31437138, ...,  0.03635113,\n",
            "         -0.00419059,  0.        ]], dtype=float32)\n",
            " array([[-0.0342677 , -0.1485397 , -0.05283961, ...,  0.06347413,\n",
            "          0.20657684,  0.        ],\n",
            "        [ 0.13573994, -0.10990519, -0.06330301, ...,  0.2779925 ,\n",
            "          0.16426933,  0.        ],\n",
            "        [ 0.0722834 , -0.10031857, -0.06333723, ...,  0.39043885,\n",
            "          0.07845128,  0.        ],\n",
            "        ...,\n",
            "        [-0.20912988,  0.02982185,  0.20524819, ...,  0.08181554,\n",
            "         -0.0495782 ,  0.        ],\n",
            "        [-0.27874568,  0.06711469,  0.21264425, ...,  0.07579659,\n",
            "         -0.07448984,  0.        ],\n",
            "        [-0.26983225,  0.03973367,  0.24098092, ...,  0.02459843,\n",
            "         -0.04093658,  0.        ]], dtype=float32)\n",
            " array([[-0.01936195, -0.12854984, -0.03222039, ...,  0.04819154,\n",
            "          0.21759753,  0.        ],\n",
            "        [ 0.13602416, -0.03251903, -0.00822826, ...,  0.2332479 ,\n",
            "          0.13016538,  0.        ],\n",
            "        [ 0.13545136,  0.02948571,  0.01420182, ...,  0.31105047,\n",
            "         -0.01524676,  0.        ],\n",
            "        ...,\n",
            "        [-0.05159966,  0.1437097 ,  0.19490585, ...,  0.0447405 ,\n",
            "          0.02013177,  0.        ],\n",
            "        [-0.23339048,  0.14536934,  0.32798404, ...,  0.05195722,\n",
            "         -0.01632947,  0.        ],\n",
            "        [-0.28302354,  0.1018369 ,  0.2985532 , ...,  0.06248601,\n",
            "          0.00189226,  0.        ]], dtype=float32)\n",
            " array([[-0.02909078, -0.12892984, -0.02832657, ...,  0.05164484,\n",
            "          0.21284892,  0.        ],\n",
            "        [ 0.1365296 , -0.04014882, -0.00611087, ...,  0.260288  ,\n",
            "          0.12425833,  0.        ],\n",
            "        [ 0.13472797,  0.01895142,  0.01258548, ...,  0.3393554 ,\n",
            "         -0.01728581,  0.        ],\n",
            "        ...,\n",
            "        [-0.10186689,  0.13771106,  0.24757463, ...,  0.07211117,\n",
            "         -0.02016887,  0.        ],\n",
            "        [-0.2522118 ,  0.13787414,  0.34365144, ...,  0.06368116,\n",
            "         -0.03979816,  0.        ],\n",
            "        [-0.29183123,  0.10136858,  0.3074484 , ...,  0.05786747,\n",
            "         -0.0039948 ,  0.        ]], dtype=float32)\n",
            " array([[-0.01998688, -0.12230202, -0.03606343, ...,  0.04901915,\n",
            "          0.21473281,  0.        ],\n",
            "        [ 0.13497585, -0.02692945, -0.01392958, ...,  0.25147384,\n",
            "          0.11381592,  0.        ],\n",
            "        [ 0.1419937 ,  0.0441057 ,  0.00546781, ...,  0.3255146 ,\n",
            "         -0.04000742,  0.        ],\n",
            "        ...,\n",
            "        [-0.04174446,  0.13415432,  0.19239491, ...,  0.06249314,\n",
            "          0.00891298,  0.        ],\n",
            "        [-0.22972718,  0.14158139,  0.33223408, ...,  0.07012685,\n",
            "         -0.01444812,  0.        ],\n",
            "        [-0.27693197,  0.1062154 ,  0.3001439 , ...,  0.06919002,\n",
            "          0.00900207,  0.        ]], dtype=float32)\n",
            " array([[-0.03275993, -0.13240142, -0.03244612, ...,  0.05441014,\n",
            "          0.20866147,  0.        ],\n",
            "        [ 0.14567772, -0.06152733, -0.03950933, ...,  0.26471788,\n",
            "          0.14231324,  0.        ],\n",
            "        [ 0.11611474, -0.03909332, -0.03413397, ...,  0.35461205,\n",
            "          0.03736826,  0.        ],\n",
            "        ...,\n",
            "        [-0.12995338,  0.07159282,  0.22283736, ...,  0.0877764 ,\n",
            "          0.01435248,  0.        ],\n",
            "        [-0.24987508,  0.06813926,  0.28487584, ...,  0.06579093,\n",
            "         -0.03164354,  0.        ],\n",
            "        [-0.298417  ,  0.07246787,  0.28003508, ...,  0.03900819,\n",
            "         -0.01789999,  0.        ]], dtype=float32)\n",
            " array([[-0.02471368, -0.1302498 , -0.03211069, ...,  0.05541969,\n",
            "          0.21430624,  0.        ],\n",
            "        [ 0.148229  , -0.03773041, -0.01432231, ...,  0.25957337,\n",
            "          0.12618388,  0.        ],\n",
            "        [ 0.14025053,  0.02197483,  0.00197893, ...,  0.34665796,\n",
            "         -0.0186038 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.08897519,  0.14852779,  0.22235043, ...,  0.07964244,\n",
            "         -0.00155162,  0.        ],\n",
            "        [-0.24862608,  0.13729   ,  0.32170087, ...,  0.07415981,\n",
            "         -0.02730865,  0.        ],\n",
            "        [-0.28536677,  0.1008326 ,  0.2906255 , ...,  0.07192295,\n",
            "          0.00300379,  0.        ]], dtype=float32)\n",
            " array([[-0.03285519, -0.15512265, -0.04500385, ...,  0.05413013,\n",
            "          0.21437165,  0.        ],\n",
            "        [ 0.14824706, -0.09511232, -0.06691869, ...,  0.28242385,\n",
            "          0.15723236,  0.        ],\n",
            "        [ 0.10253986, -0.08699975, -0.07040938, ...,  0.37652814,\n",
            "          0.06184779,  0.        ],\n",
            "        ...,\n",
            "        [-0.13924277,  0.01712721,  0.20593965, ...,  0.09839779,\n",
            "          0.01589254,  0.        ],\n",
            "        [-0.23127711,  0.02602274,  0.23852283, ...,  0.07872743,\n",
            "         -0.03075213,  0.        ],\n",
            "        [-0.27879626,  0.02288869,  0.2528794 , ...,  0.03487115,\n",
            "         -0.02079538,  0.        ]], dtype=float32)\n",
            " array([[-0.01906602, -0.13009223, -0.02706281, ...,  0.04767675,\n",
            "          0.2118906 ,  0.        ],\n",
            "        [ 0.14580615, -0.04203974, -0.00449666, ...,  0.26565394,\n",
            "          0.12750556,  0.        ],\n",
            "        [ 0.14338781,  0.01242558,  0.00790131, ...,  0.34543064,\n",
            "         -0.00039325,  0.        ],\n",
            "        ...,\n",
            "        [-0.07034433,  0.12376413,  0.23174264, ...,  0.08885309,\n",
            "          0.00628269,  0.        ],\n",
            "        [-0.23333563,  0.12473761,  0.33598572, ...,  0.07942343,\n",
            "         -0.02165802,  0.        ],\n",
            "        [-0.2801178 ,  0.1019144 ,  0.29603818, ...,  0.05673892,\n",
            "          0.00153079,  0.        ]], dtype=float32)\n",
            " array([[-0.01235101, -0.12472367, -0.02979217, ...,  0.04745331,\n",
            "          0.21162471,  0.        ],\n",
            "        [ 0.15782714, -0.02590524, -0.01027661, ...,  0.26554808,\n",
            "          0.12168368,  0.        ],\n",
            "        [ 0.1607626 ,  0.03902584,  0.00435659, ...,  0.3408557 ,\n",
            "         -0.01924145,  0.        ],\n",
            "        ...,\n",
            "        [-0.00816077,  0.120345  ,  0.18047245, ...,  0.08070648,\n",
            "          0.03370621,  0.        ],\n",
            "        [-0.20994759,  0.12471105,  0.32758752, ...,  0.08345386,\n",
            "         -0.00404729,  0.        ],\n",
            "        [-0.26326737,  0.10769101,  0.29305622, ...,  0.06205046,\n",
            "          0.00784934,  0.        ]], dtype=float32)\n",
            " array([[-0.03608925, -0.14732003, -0.04858997, ...,  0.06263082,\n",
            "          0.21594658,  0.        ],\n",
            "        [ 0.14929947, -0.09621798, -0.06741466, ...,  0.2875161 ,\n",
            "          0.16454837,  0.        ],\n",
            "        [ 0.09676495, -0.09175082, -0.06904788, ...,  0.3928773 ,\n",
            "          0.07440975,  0.        ],\n",
            "        ...,\n",
            "        [-0.16195181,  0.02162874,  0.21331428, ...,  0.1031585 ,\n",
            "         -0.00631178,  0.        ],\n",
            "        [-0.2668666 ,  0.04269142,  0.23056808, ...,  0.08069089,\n",
            "         -0.05009116,  0.        ],\n",
            "        [-0.2841324 ,  0.03422393,  0.25098827, ...,  0.02836863,\n",
            "         -0.02252825,  0.        ]], dtype=float32)\n",
            " array([[-0.03205482, -0.15306607, -0.05826423, ...,  0.05848508,\n",
            "          0.19614592,  0.        ],\n",
            "        [ 0.11661559, -0.12450714, -0.06531183, ...,  0.26613545,\n",
            "          0.15084761,  0.        ],\n",
            "        [ 0.05322564, -0.12378543, -0.0739498 , ...,  0.3622404 ,\n",
            "          0.08909672,  0.        ],\n",
            "        ...,\n",
            "        [-0.2312307 ,  0.04837891,  0.20153731, ...,  0.05571168,\n",
            "         -0.08012091,  0.        ],\n",
            "        [-0.27201587,  0.06263883,  0.20690666, ...,  0.05159755,\n",
            "         -0.080521  ,  0.        ],\n",
            "        [-0.2532705 ,  0.03527553,  0.23813115, ...,  0.00377882,\n",
            "         -0.04639186,  0.        ]], dtype=float32)\n",
            " array([[-0.03089309, -0.15287411, -0.04528369, ...,  0.05617236,\n",
            "          0.21448341,  0.        ],\n",
            "        [ 0.15069826, -0.09315318, -0.07344322, ...,  0.29175413,\n",
            "          0.15483315,  0.        ],\n",
            "        [ 0.10744145, -0.08745669, -0.08037245, ...,  0.38679308,\n",
            "          0.05938616,  0.        ],\n",
            "        ...,\n",
            "        [-0.12635961,  0.01646423,  0.1950022 , ...,  0.10841226,\n",
            "          0.01871312,  0.        ],\n",
            "        [-0.22632542,  0.01638   ,  0.24219747, ...,  0.08266745,\n",
            "         -0.02394507,  0.        ],\n",
            "        [-0.27956867,  0.02582838,  0.25590143, ...,  0.03796278,\n",
            "         -0.01765267,  0.        ]], dtype=float32)\n",
            " array([[-0.01533999, -0.12756176, -0.0361326 , ...,  0.05343474,\n",
            "          0.21554868,  0.        ],\n",
            "        [ 0.14199942, -0.0323571 , -0.01124815, ...,  0.24973369,\n",
            "          0.1275599 ,  0.        ],\n",
            "        [ 0.14367168,  0.03442477,  0.00839356, ...,  0.32762545,\n",
            "         -0.02130736,  0.        ],\n",
            "        ...,\n",
            "        [-0.03964872,  0.14618976,  0.19309682, ...,  0.05660079,\n",
            "          0.02516399,  0.        ],\n",
            "        [-0.21667892,  0.13380995,  0.31521046, ...,  0.06667425,\n",
            "         -0.00678349,  0.        ],\n",
            "        [-0.26600325,  0.10756316,  0.2880768 , ...,  0.06822252,\n",
            "          0.00873954,  0.        ]], dtype=float32)\n",
            " array([[-0.02022413, -0.16317727, -0.05079167, ...,  0.06557695,\n",
            "          0.21120057,  0.        ],\n",
            "        [ 0.15726665, -0.10057273, -0.07805031, ...,  0.29972228,\n",
            "          0.14128405,  0.        ],\n",
            "        [ 0.1198226 , -0.09464654, -0.08947318, ...,  0.39067245,\n",
            "          0.04756651,  0.        ],\n",
            "        ...,\n",
            "        [-0.09118692, -0.00099511,  0.16144465, ...,  0.10929286,\n",
            "          0.02777003,  0.        ],\n",
            "        [-0.18896282,  0.00612904,  0.20760213, ...,  0.08557413,\n",
            "         -0.01123665,  0.        ],\n",
            "        [-0.24439022,  0.00646162,  0.22743171, ...,  0.05313763,\n",
            "         -0.01866156,  0.        ]], dtype=float32)\n",
            " array([[-0.01980905, -0.12069994, -0.02922124, ...,  0.03633877,\n",
            "          0.20762584,  0.        ],\n",
            "        [ 0.12483246, -0.02440695,  0.00181858, ...,  0.23111223,\n",
            "          0.11270539,  0.        ],\n",
            "        [ 0.12405167,  0.03994989,  0.02272075, ...,  0.3063343 ,\n",
            "         -0.03058712,  0.        ],\n",
            "        ...,\n",
            "        [-0.03274182,  0.13735652,  0.19981267, ...,  0.04438953,\n",
            "          0.02102565,  0.        ],\n",
            "        [-0.22966462,  0.1315441 ,  0.3481256 , ...,  0.04707307,\n",
            "         -0.01564007,  0.        ],\n",
            "        [-0.29106396,  0.09983777,  0.30688432, ...,  0.04347785,\n",
            "         -0.00547949,  0.        ]], dtype=float32)\n",
            " array([[-0.03055925, -0.12257066, -0.03068476, ...,  0.05546754,\n",
            "          0.20693664,  0.        ],\n",
            "        [ 0.13982363, -0.05508897, -0.02907486, ...,  0.2579341 ,\n",
            "          0.14098464,  0.        ],\n",
            "        [ 0.12156689, -0.02404101, -0.01475641, ...,  0.35280538,\n",
            "          0.0223201 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.14191394,  0.11778945,  0.24383704, ...,  0.09086558,\n",
            "         -0.00445726,  0.        ],\n",
            "        [-0.26368392,  0.10513282,  0.31284246, ...,  0.07088094,\n",
            "         -0.0347844 ,  0.        ],\n",
            "        [-0.30569008,  0.08776717,  0.28935313, ...,  0.04238304,\n",
            "         -0.01938193,  0.        ]], dtype=float32)\n",
            " array([[-2.0541552e-02, -1.3063507e-01, -3.2893647e-02, ...,\n",
            "          4.9485222e-02,  2.1786214e-01,  0.0000000e+00],\n",
            "        [ 1.3816391e-01, -3.8975421e-02, -7.9147415e-03, ...,\n",
            "          2.3706266e-01,  1.4166018e-01,  0.0000000e+00],\n",
            "        [ 1.3442741e-01,  1.7652432e-02,  1.5983636e-02, ...,\n",
            "          3.1942508e-01, -6.5524742e-05,  0.0000000e+00],\n",
            "        ...,\n",
            "        [-6.3778631e-02,  1.4532018e-01,  2.0911670e-01, ...,\n",
            "          6.0058605e-02,  2.2321848e-02,  0.0000000e+00],\n",
            "        [-2.3852110e-01,  1.3917221e-01,  3.2560501e-01, ...,\n",
            "          5.8596328e-02, -1.8167062e-02,  0.0000000e+00],\n",
            "        [-2.8478220e-01,  9.6209012e-02,  2.9192749e-01, ...,\n",
            "          6.1185848e-02, -2.5306167e-03,  0.0000000e+00]], dtype=float32)\n",
            " array([[-0.01943466, -0.1263244 , -0.03288626, ...,  0.04937792,\n",
            "          0.21540219,  0.        ],\n",
            "        [ 0.13133927, -0.03121322, -0.006899  , ...,  0.23541635,\n",
            "          0.12841716,  0.        ],\n",
            "        [ 0.13329442,  0.02906696,  0.01641291, ...,  0.31086278,\n",
            "         -0.02123962,  0.        ],\n",
            "        ...,\n",
            "        [-0.04178609,  0.13814554,  0.20053902, ...,  0.04476111,\n",
            "          0.01479603,  0.        ],\n",
            "        [-0.23047175,  0.14309408,  0.33537298, ...,  0.05594037,\n",
            "         -0.01419399,  0.        ],\n",
            "        [-0.27899733,  0.10523123,  0.30244032, ...,  0.0632423 ,\n",
            "          0.00588398,  0.        ]], dtype=float32)\n",
            " array([[-0.00369971, -0.11021082, -0.05207145, ...,  0.03411904,\n",
            "          0.19520046,  0.        ],\n",
            "        [ 0.16688249, -0.00273511, -0.03745453, ...,  0.2379519 ,\n",
            "          0.04242001,  0.        ],\n",
            "        [ 0.17234983,  0.05097849, -0.03435622, ...,  0.30104324,\n",
            "         -0.09331148,  0.        ],\n",
            "        ...,\n",
            "        [ 0.06415537,  0.08696893,  0.06047089, ...,  0.02446827,\n",
            "          0.04336442,  0.        ],\n",
            "        [-0.161503  ,  0.1197079 ,  0.30840528, ...,  0.07842164,\n",
            "         -0.01984229,  0.        ],\n",
            "        [-0.26126558,  0.08850439,  0.2943265 , ...,  0.05340436,\n",
            "         -0.00702881,  0.        ]], dtype=float32)\n",
            " array([[-0.00204518, -0.11129654, -0.05481978, ...,  0.03746331,\n",
            "          0.20879734,  0.        ],\n",
            "        [ 0.14869294, -0.00124637, -0.03406644, ...,  0.22390091,\n",
            "          0.08899555,  0.        ],\n",
            "        [ 0.16369486,  0.05853512, -0.02176691, ...,  0.29793814,\n",
            "         -0.07114974,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05018977,  0.09873749,  0.0709693 , ...,  0.0267044 ,\n",
            "          0.05589729,  0.        ],\n",
            "        [-0.16487712,  0.13689528,  0.30173153, ...,  0.07114115,\n",
            "         -0.00645578,  0.        ],\n",
            "        [-0.25744703,  0.09659939,  0.2936369 , ...,  0.06043224,\n",
            "          0.00230177,  0.        ]], dtype=float32)\n",
            " array([[-0.02465201, -0.13539445, -0.02928443, ...,  0.04968604,\n",
            "          0.2111155 ,  0.        ],\n",
            "        [ 0.1430243 , -0.04739876, -0.01889353, ...,  0.27511445,\n",
            "          0.13270545,  0.        ],\n",
            "        [ 0.12699683, -0.00650876, -0.00142878, ...,  0.363395  ,\n",
            "          0.01277842,  0.        ],\n",
            "        ...,\n",
            "        [-0.10536697,  0.11120117,  0.22587137, ...,  0.08821487,\n",
            "          0.00430284,  0.        ],\n",
            "        [-0.23635817,  0.10365931,  0.30956146, ...,  0.07489333,\n",
            "         -0.03041141,  0.        ],\n",
            "        [-0.2921463 ,  0.08100174,  0.29055023, ...,  0.05781195,\n",
            "         -0.01351557,  0.        ]], dtype=float32)\n",
            " array([[-0.02321586, -0.13654824, -0.02862808, ...,  0.05094765,\n",
            "          0.21710886,  0.        ],\n",
            "        [ 0.1434229 , -0.04493428, -0.01097775, ...,  0.24705996,\n",
            "          0.14202821,  0.        ],\n",
            "        [ 0.13388509,  0.00323357,  0.01418124, ...,  0.3308989 ,\n",
            "          0.00555493,  0.        ],\n",
            "        ...,\n",
            "        [-0.10041725,  0.14327902,  0.22528362, ...,  0.05862287,\n",
            "          0.00343368,  0.        ],\n",
            "        [-0.2468183 ,  0.13283043,  0.32118195, ...,  0.05958578,\n",
            "         -0.02893167,  0.        ],\n",
            "        [-0.2892124 ,  0.09324145,  0.2926407 , ...,  0.06023557,\n",
            "         -0.00454462,  0.        ]], dtype=float32)\n",
            " array([[-0.00883939, -0.11259034, -0.04633435, ...,  0.03447646,\n",
            "          0.19829471,  0.        ],\n",
            "        [ 0.15152343, -0.00552464, -0.02866693, ...,  0.23500021,\n",
            "          0.0598394 ,  0.        ],\n",
            "        [ 0.15799075,  0.05407001, -0.02145906, ...,  0.30316103,\n",
            "         -0.08021063,  0.        ],\n",
            "        ...,\n",
            "        [ 0.04805652,  0.09507069,  0.08137623, ...,  0.02738977,\n",
            "          0.04401999,  0.        ],\n",
            "        [-0.17506193,  0.11932431,  0.31600946, ...,  0.07256276,\n",
            "         -0.01485125,  0.        ],\n",
            "        [-0.2659031 ,  0.0889871 ,  0.29866785, ...,  0.05549423,\n",
            "         -0.0052994 ,  0.        ]], dtype=float32)\n",
            " array([[-0.03256929, -0.15820567, -0.0612855 , ...,  0.06223148,\n",
            "          0.19946757,  1.        ],\n",
            "        [ 0.12019391, -0.1302704 , -0.07092186, ...,  0.27907884,\n",
            "          0.15390116,  1.        ],\n",
            "        [ 0.05723717, -0.12839945, -0.07765271, ...,  0.3760536 ,\n",
            "          0.08959586,  1.        ],\n",
            "        ...,\n",
            "        [-0.2128933 ,  0.04011046,  0.1905818 , ...,  0.07679793,\n",
            "         -0.07670555,  1.        ],\n",
            "        [-0.26015922,  0.04834473,  0.19087018, ...,  0.06547613,\n",
            "         -0.08045114,  1.        ],\n",
            "        [-0.25357175,  0.01822538,  0.22883815, ...,  0.01210507,\n",
            "         -0.04766449,  1.        ]], dtype=float32)\n",
            " array([[-0.03236446, -0.12219382, -0.03092641, ...,  0.05571645,\n",
            "          0.20657617,  1.        ],\n",
            "        [ 0.13665263, -0.05756362, -0.0350645 , ...,  0.2658944 ,\n",
            "          0.14066723,  1.        ],\n",
            "        [ 0.1179251 , -0.02614623, -0.02307468, ...,  0.35858145,\n",
            "          0.0273482 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.14460213,  0.10664532,  0.24571252, ...,  0.09400675,\n",
            "         -0.00475643,  1.        ],\n",
            "        [-0.26232868,  0.09145541,  0.30932903, ...,  0.07444217,\n",
            "         -0.03482142,  1.        ],\n",
            "        [-0.30552152,  0.08507799,  0.28858387, ...,  0.03898925,\n",
            "         -0.01751306,  1.        ]], dtype=float32)\n",
            " array([[-0.01770027, -0.12748179, -0.03273603, ...,  0.05304772,\n",
            "          0.21712306,  1.        ],\n",
            "        [ 0.15582527, -0.03085431, -0.00945008, ...,  0.26535472,\n",
            "          0.1264248 ,  1.        ],\n",
            "        [ 0.15326071,  0.03739365,  0.01221053, ...,  0.34095287,\n",
            "         -0.01983763,  1.        ],\n",
            "        ...,\n",
            "        [-0.03458933,  0.13756752,  0.19403382, ...,  0.06455448,\n",
            "          0.01635252,  1.        ],\n",
            "        [-0.21649349,  0.1373541 ,  0.31421885, ...,  0.06909942,\n",
            "         -0.0111075 ,  1.        ],\n",
            "        [-0.26768413,  0.10622293,  0.29171696, ...,  0.07324444,\n",
            "          0.00907299,  1.        ]], dtype=float32)\n",
            " array([[-0.01370875, -0.12192954, -0.03364512, ...,  0.04889206,\n",
            "          0.21577331,  1.        ],\n",
            "        [ 0.1460636 , -0.03013031, -0.01407268, ...,  0.24731469,\n",
            "          0.12066004,  1.        ],\n",
            "        [ 0.1419367 ,  0.04439886,  0.0055397 , ...,  0.32002297,\n",
            "         -0.03181976,  1.        ],\n",
            "        ...,\n",
            "        [-0.02175164,  0.1426235 ,  0.18305549, ...,  0.05222317,\n",
            "          0.02534888,  1.        ],\n",
            "        [-0.2147738 ,  0.13919045,  0.32108474, ...,  0.06528853,\n",
            "         -0.00527688,  1.        ],\n",
            "        [-0.26378644,  0.10971331,  0.2938689 , ...,  0.07197709,\n",
            "          0.00805707,  1.        ]], dtype=float32)\n",
            " array([[-0.02282106, -0.12673539, -0.02595658, ...,  0.03980867,\n",
            "          0.20738333,  1.        ],\n",
            "        [ 0.12405933, -0.03346802,  0.00317804, ...,  0.23829278,\n",
            "          0.11848407,  1.        ],\n",
            "        [ 0.12129702,  0.02489953,  0.02446512, ...,  0.3152366 ,\n",
            "         -0.01554486,  1.        ],\n",
            "        ...,\n",
            "        [-0.07355876,  0.13283579,  0.2294856 , ...,  0.05731845,\n",
            "          0.00497226,  1.        ],\n",
            "        [-0.24587828,  0.12662503,  0.3548033 , ...,  0.05000265,\n",
            "         -0.02544097,  1.        ],\n",
            "        [-0.2975959 ,  0.09724771,  0.30939522, ...,  0.04254349,\n",
            "         -0.00829947,  1.        ]], dtype=float32)\n",
            " array([[-0.035275  , -0.1379718 , -0.03540283, ...,  0.050854  ,\n",
            "          0.21265317,  1.        ],\n",
            "        [ 0.13876995, -0.07340647, -0.04973961, ...,  0.26328057,\n",
            "          0.158806  ,  1.        ],\n",
            "        [ 0.09751339, -0.05949805, -0.04644564, ...,  0.35544884,\n",
            "          0.06018497,  1.        ],\n",
            "        ...,\n",
            "        [-0.1503469 ,  0.0607052 ,  0.23219891, ...,  0.09622222,\n",
            "          0.0242537 ,  1.        ],\n",
            "        [-0.26759213,  0.05659498,  0.28843802, ...,  0.07141783,\n",
            "         -0.03294798,  1.        ],\n",
            "        [-0.30804923,  0.05771742,  0.28369054, ...,  0.03085872,\n",
            "         -0.02139077,  1.        ]], dtype=float32)\n",
            " array([[-0.03574226, -0.13123575, -0.03253333, ...,  0.06157572,\n",
            "          0.21137416,  1.        ],\n",
            "        [ 0.14982127, -0.05629941, -0.03616502, ...,  0.26414132,\n",
            "          0.14463751,  1.        ],\n",
            "        [ 0.11917179, -0.0308212 , -0.01939768, ...,  0.354995  ,\n",
            "          0.03850562,  1.        ],\n",
            "        ...,\n",
            "        [-0.1629272 ,  0.10133585,  0.2585905 , ...,  0.08005543,\n",
            "         -0.01978228,  1.        ],\n",
            "        [-0.27212366,  0.0826789 ,  0.2997555 , ...,  0.07099776,\n",
            "         -0.04731137,  1.        ],\n",
            "        [-0.29565272,  0.0840311 ,  0.2810392 , ...,  0.04326354,\n",
            "         -0.01407775,  1.        ]], dtype=float32)\n",
            " array([[-0.0331554 , -0.14083083, -0.03834435, ...,  0.06303481,\n",
            "          0.21536614,  1.        ],\n",
            "        [ 0.1719152 , -0.06279514, -0.04241801, ...,  0.2851371 ,\n",
            "          0.15313518,  1.        ],\n",
            "        [ 0.13191886, -0.04507287, -0.03541976, ...,  0.3762362 ,\n",
            "          0.04768552,  1.        ],\n",
            "        ...,\n",
            "        [-0.13037908,  0.06095685,  0.21517071, ...,  0.09052511,\n",
            "          0.00106975,  1.        ],\n",
            "        [-0.24352665,  0.06109525,  0.2590143 , ...,  0.07685386,\n",
            "         -0.03850311,  1.        ],\n",
            "        [-0.28064036,  0.06544383,  0.26485246, ...,  0.04599423,\n",
            "         -0.01142908,  1.        ]], dtype=float32)\n",
            " array([[-0.00109148, -0.10924863, -0.04530831, ...,  0.042402  ,\n",
            "          0.20542696,  1.        ],\n",
            "        [ 0.17612067, -0.00565848, -0.03615543, ...,  0.25394398,\n",
            "          0.07120927,  1.        ],\n",
            "        [ 0.18697524,  0.0582815 , -0.03305858, ...,  0.31240276,\n",
            "         -0.06769708,  1.        ],\n",
            "        ...,\n",
            "        [ 0.08945104,  0.09012741,  0.05442204, ...,  0.05357203,\n",
            "          0.06592051,  1.        ],\n",
            "        [-0.1453478 ,  0.1244963 ,  0.30258206, ...,  0.11127009,\n",
            "          0.00163126,  1.        ],\n",
            "        [-0.24379602,  0.10661662,  0.29090348, ...,  0.06773752,\n",
            "          0.00888429,  1.        ]], dtype=float32)\n",
            " array([[-1.32616814e-02, -1.18153974e-01, -3.38514335e-02, ...,\n",
            "          4.48126793e-02,  2.08225965e-01,  1.00000000e+00],\n",
            "        [ 1.44245386e-01, -2.03875788e-02, -1.59726664e-02, ...,\n",
            "          2.56903172e-01,  1.00926176e-01,  1.00000000e+00],\n",
            "        [ 1.54383749e-01,  5.03118001e-02, -2.85359379e-03, ...,\n",
            "          3.26064557e-01, -4.41174582e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.42848117e-02,  1.18815832e-01,  1.42652631e-01, ...,\n",
            "          6.01354539e-02,  4.14428897e-02,  1.00000000e+00],\n",
            "        [-1.92898765e-01,  1.25550807e-01,  3.25224578e-01, ...,\n",
            "          8.66288915e-02,  7.07103231e-04,  1.00000000e+00],\n",
            "        [-2.59841383e-01,  1.09304510e-01,  2.94583529e-01, ...,\n",
            "          5.83743416e-02,  1.00196917e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.0224173 , -0.1318904 , -0.03004837, ...,  0.05190208,\n",
            "          0.21530253,  1.        ],\n",
            "        [ 0.14209704, -0.03980266, -0.00997689, ...,  0.25211552,\n",
            "          0.12907416,  1.        ],\n",
            "        [ 0.13794446,  0.02046023,  0.01160993, ...,  0.33288017,\n",
            "         -0.01565028,  1.        ],\n",
            "        ...,\n",
            "        [-0.08489337,  0.13885608,  0.22823022, ...,  0.06045651,\n",
            "         -0.00419193,  1.        ],\n",
            "        [-0.23961757,  0.13391002,  0.3316041 , ...,  0.06017998,\n",
            "         -0.0274884 ,  1.        ],\n",
            "        [-0.28140518,  0.10074469,  0.29761168, ...,  0.0654041 ,\n",
            "          0.00191413,  1.        ]], dtype=float32)\n",
            " array([[-0.02366355, -0.13216807, -0.02672127, ...,  0.04556489,\n",
            "          0.20886861,  1.        ],\n",
            "        [ 0.13333797, -0.04947613, -0.00994191, ...,  0.25772312,\n",
            "          0.13240115,  1.        ],\n",
            "        [ 0.11717682, -0.00832037,  0.00809623, ...,  0.34444502,\n",
            "          0.01102483,  1.        ],\n",
            "        ...,\n",
            "        [-0.11632805,  0.12788714,  0.24062133, ...,  0.08603922,\n",
            "         -0.00515226,  1.        ],\n",
            "        [-0.25389904,  0.11757035,  0.33179155, ...,  0.06739145,\n",
            "         -0.03616372,  1.        ],\n",
            "        [-0.30167586,  0.08854829,  0.29807973, ...,  0.04787791,\n",
            "         -0.01808902,  1.        ]], dtype=float32)\n",
            " array([[-0.00333244, -0.12105025, -0.04771851, ...,  0.05637505,\n",
            "          0.21519208,  1.        ],\n",
            "        [ 0.17691584, -0.01010354, -0.03543095, ...,  0.26321727,\n",
            "          0.1105582 ,  1.        ],\n",
            "        [ 0.17472422,  0.05062088, -0.02084493, ...,  0.34219876,\n",
            "         -0.04521212,  1.        ],\n",
            "        ...,\n",
            "        [ 0.07458708,  0.12573077,  0.09486032, ...,  0.04439074,\n",
            "          0.04135908,  1.        ],\n",
            "        [-0.14684889,  0.13903436,  0.27337646, ...,  0.07469717,\n",
            "         -0.0014567 ,  1.        ],\n",
            "        [-0.24363534,  0.10821497,  0.27008438, ...,  0.07650939,\n",
            "          0.00457307,  1.        ]], dtype=float32)\n",
            " array([[-0.03054285, -0.15443324, -0.06021101, ...,  0.0580647 ,\n",
            "          0.19292657,  1.        ],\n",
            "        [ 0.11549101, -0.12701768, -0.06748361, ...,  0.25797316,\n",
            "          0.15046225,  1.        ],\n",
            "        [ 0.049212  , -0.1227864 , -0.07704497, ...,  0.35766128,\n",
            "          0.08593395,  1.        ],\n",
            "        ...,\n",
            "        [-0.23157193,  0.04932523,  0.19831753, ...,  0.03738715,\n",
            "         -0.08040414,  1.        ],\n",
            "        [-0.27252495,  0.06716032,  0.2104562 , ...,  0.03822418,\n",
            "         -0.07867909,  1.        ],\n",
            "        [-0.24636945,  0.02822414,  0.2371208 , ..., -0.0014689 ,\n",
            "         -0.04958471,  1.        ]], dtype=float32)\n",
            " array([[-0.02174572, -0.13104524, -0.02787025, ...,  0.04376018,\n",
            "          0.20950074,  1.        ],\n",
            "        [ 0.13800374, -0.03962254, -0.00330898, ...,  0.25553432,\n",
            "          0.12766446,  1.        ],\n",
            "        [ 0.13145235,  0.0104357 ,  0.01909938, ...,  0.33646104,\n",
            "         -0.00180807,  1.        ],\n",
            "        ...,\n",
            "        [-0.08280612,  0.13015264,  0.22534221, ...,  0.07670389,\n",
            "          0.00230004,  1.        ],\n",
            "        [-0.2397473 ,  0.12421504,  0.33261272, ...,  0.0627922 ,\n",
            "         -0.0267709 ,  1.        ],\n",
            "        [-0.29308957,  0.09444033,  0.29701045, ...,  0.04964802,\n",
            "         -0.01041957,  1.        ]], dtype=float32)\n",
            " array([[ 0.01219954, -0.10603727, -0.06992296, ...,  0.03920858,\n",
            "          0.20699082,  1.        ],\n",
            "        [ 0.1632791 , -0.00813134, -0.05242465, ...,  0.20228979,\n",
            "          0.0946877 ,  1.        ],\n",
            "        [ 0.1564506 ,  0.03924131, -0.04299161, ...,  0.2897468 ,\n",
            "         -0.06807008,  1.        ],\n",
            "        ...,\n",
            "        [ 0.07840449,  0.09197326,  0.0506904 , ...,  0.02719782,\n",
            "          0.06043504,  1.        ],\n",
            "        [-0.14635469,  0.1350927 ,  0.26996922, ...,  0.08251295,\n",
            "         -0.00404423,  1.        ],\n",
            "        [-0.2538219 ,  0.08646705,  0.2818717 , ...,  0.06927587,\n",
            "         -0.00407785,  1.        ]], dtype=float32)\n",
            " array([[-2.2087580e-02, -1.3960610e-01, -2.9675173e-02, ...,\n",
            "          5.2897844e-02,  2.1754767e-01,  1.0000000e+00],\n",
            "        [ 1.4420655e-01, -4.5334451e-02, -1.3990562e-02, ...,\n",
            "          2.4915190e-01,  1.3810712e-01,  1.0000000e+00],\n",
            "        [ 1.3869715e-01,  2.8500990e-03,  1.0093464e-02, ...,\n",
            "          3.2876763e-01, -3.6414363e-04,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0914441e-01,  1.5644117e-01,  2.3228431e-01, ...,\n",
            "          5.3607877e-02,  5.5485964e-04,  1.0000000e+00],\n",
            "        [-2.4651736e-01,  1.3035631e-01,  3.2303822e-01, ...,\n",
            "          5.5969097e-02, -3.0123591e-02,  1.0000000e+00],\n",
            "        [-2.7764836e-01,  9.5360965e-02,  2.8860053e-01, ...,\n",
            "          6.7538448e-02, -1.3504790e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-8.4661003e-03, -1.2919293e-01, -3.9027054e-02, ...,\n",
            "          5.8416937e-02,  2.2067195e-01,  1.0000000e+00],\n",
            "        [ 1.7879725e-01, -1.8391808e-02, -2.3510477e-02, ...,\n",
            "          2.7242476e-01,  1.3005345e-01,  1.0000000e+00],\n",
            "        [ 1.7471427e-01,  4.3337140e-02, -2.9711437e-04, ...,\n",
            "          3.5223135e-01, -1.5200656e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [ 2.4183437e-02,  1.3208733e-01,  1.4221331e-01, ...,\n",
            "          4.9197480e-02,  1.8376151e-02,  1.0000000e+00],\n",
            "        [-1.6783790e-01,  1.3414928e-01,  2.7451944e-01, ...,\n",
            "          6.2236544e-02, -8.1488248e-03,  1.0000000e+00],\n",
            "        [-2.4097465e-01,  1.0653738e-01,  2.7320719e-01, ...,\n",
            "          8.1629820e-02,  1.0256815e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[ 4.30854931e-02, -1.39285862e-01, -6.99747652e-02, ...,\n",
            "          1.53903784e-02,  1.68772057e-01,  1.00000000e+00],\n",
            "        [ 2.52713978e-01, -2.78254747e-02, -6.32065311e-02, ...,\n",
            "          1.90229729e-01,  9.17415455e-05,  1.00000000e+00],\n",
            "        [ 2.58350492e-01,  4.16915305e-03, -5.71621992e-02, ...,\n",
            "          2.37708852e-01, -1.18115537e-01,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.44198477e-01, -1.14997942e-03, -4.66095582e-02, ...,\n",
            "          5.57937846e-02,  5.42583279e-02,  1.00000000e+00],\n",
            "        [-7.25303218e-02,  8.00884292e-02,  2.55938411e-01, ...,\n",
            "          1.18248545e-01, -4.31812406e-02,  1.00000000e+00],\n",
            "        [-2.43581116e-01,  5.41764200e-02,  3.03849638e-01, ...,\n",
            "          7.59140998e-02, -2.70987786e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.01729516, -0.12047933, -0.03267742, ...,  0.0367816 ,\n",
            "          0.206478  ,  1.        ],\n",
            "        [ 0.12845252, -0.01845613, -0.00481399, ...,  0.23752125,\n",
            "          0.1041547 ,  1.        ],\n",
            "        [ 0.13251896,  0.04934881,  0.01473251, ...,  0.31075746,\n",
            "         -0.04141886,  1.        ],\n",
            "        ...,\n",
            "        [-0.00584199,  0.12815677,  0.16274002, ...,  0.04468771,\n",
            "          0.03199115,  1.        ],\n",
            "        [-0.21239628,  0.12860303,  0.33349144, ...,  0.05812951,\n",
            "         -0.00920152,  1.        ],\n",
            "        [-0.27966052,  0.09655063,  0.3025141 , ...,  0.0477794 ,\n",
            "         -0.00356048,  1.        ]], dtype=float32)\n",
            " array([[-0.01805556, -0.13180317, -0.02767235, ...,  0.04662737,\n",
            "          0.21098614,  0.        ],\n",
            "        [ 0.14849284, -0.04492218, -0.00431378, ...,  0.2636215 ,\n",
            "          0.12811968,  0.        ],\n",
            "        [ 0.14371268,  0.00517778,  0.00830098, ...,  0.34479228,\n",
            "          0.00280453,  0.        ],\n",
            "        ...,\n",
            "        [-0.07616472,  0.12568815,  0.22658919, ...,  0.08662517,\n",
            "          0.00693537,  0.        ],\n",
            "        [-0.23511018,  0.12539564,  0.32912344, ...,  0.07706248,\n",
            "         -0.02347055,  0.        ],\n",
            "        [-0.28135496,  0.10286187,  0.29403374, ...,  0.05627281,\n",
            "         -0.00062166,  0.        ]], dtype=float32)\n",
            " array([[-2.50864010e-02, -1.34490550e-01, -3.02595049e-02, ...,\n",
            "          5.36964759e-02,  2.15073124e-01,  2.00000000e+00],\n",
            "        [ 1.52894735e-01, -4.26782668e-02, -1.22344196e-02, ...,\n",
            "          2.72626013e-01,  1.35314554e-01,  2.00000000e+00],\n",
            "        [ 1.40372559e-01,  1.71836908e-03,  1.07444394e-02, ...,\n",
            "          3.57202947e-01,  6.93452917e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.22400858e-01,  1.30455643e-01,  2.46471539e-01, ...,\n",
            "          7.65014887e-02, -1.79604646e-02,  2.00000000e+00],\n",
            "        [-2.45506510e-01,  1.20283715e-01,  3.15221339e-01, ...,\n",
            "          6.96687400e-02, -3.86336260e-02,  2.00000000e+00],\n",
            "        [-2.89738089e-01,  9.33017209e-02,  2.93834388e-01, ...,\n",
            "          5.98864183e-02, -8.83322954e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.5635142e-02, -1.3162953e-01, -2.3490729e-02, ...,\n",
            "          4.3844935e-02,  2.0826945e-01,  2.0000000e+00],\n",
            "        [ 1.3165966e-01, -4.6822943e-02, -1.6898044e-03, ...,\n",
            "          2.4101956e-01,  1.3344932e-01,  2.0000000e+00],\n",
            "        [ 1.1691132e-01, -1.6295427e-03,  2.2123661e-02, ...,\n",
            "          3.2463104e-01,  8.7878155e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1909135e-01,  1.3493340e-01,  2.5349087e-01, ...,\n",
            "          6.4304255e-02,  1.1643018e-03,  2.0000000e+00],\n",
            "        [-2.5897941e-01,  1.2533781e-01,  3.4155196e-01, ...,\n",
            "          5.5189595e-02, -3.1562634e-02,  2.0000000e+00],\n",
            "        [-3.0504683e-01,  9.3072385e-02,  3.0301306e-01, ...,\n",
            "          4.3979786e-02, -1.3878147e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02086981, -0.12280907, -0.02687786, ...,  0.03693625,\n",
            "          0.20655414,  2.        ],\n",
            "        [ 0.12580493, -0.02453395,  0.00527673, ...,  0.23096825,\n",
            "          0.11038472,  2.        ],\n",
            "        [ 0.12466186,  0.03859653,  0.0244095 , ...,  0.3051074 ,\n",
            "         -0.02840097,  2.        ],\n",
            "        ...,\n",
            "        [-0.04615949,  0.1364701 ,  0.2057706 , ...,  0.04453343,\n",
            "          0.01511209,  2.        ],\n",
            "        [-0.23603866,  0.13003397,  0.34751773, ...,  0.04474196,\n",
            "         -0.01895364,  2.        ],\n",
            "        [-0.29245317,  0.1008094 ,  0.30895823, ...,  0.04099694,\n",
            "         -0.00408008,  2.        ]], dtype=float32)\n",
            " array([[-0.02468475, -0.13115384, -0.02996864, ...,  0.05092499,\n",
            "          0.21630093,  2.        ],\n",
            "        [ 0.13919991, -0.04251653, -0.00602561, ...,  0.23812099,\n",
            "          0.13446908,  2.        ],\n",
            "        [ 0.1279412 ,  0.01476029,  0.01525749, ...,  0.3139736 ,\n",
            "         -0.00952514,  2.        ],\n",
            "        ...,\n",
            "        [-0.06719918,  0.16163442,  0.20744783, ...,  0.03979082,\n",
            "          0.01437937,  2.        ],\n",
            "        [-0.24087983,  0.14592662,  0.31934744, ...,  0.04822349,\n",
            "         -0.01742687,  2.        ],\n",
            "        [-0.27949527,  0.10793316,  0.2907317 , ...,  0.0633151 ,\n",
            "          0.00238078,  2.        ]], dtype=float32)\n",
            " array([[-0.02046243, -0.12449647, -0.02906084, ...,  0.04651995,\n",
            "          0.21406344,  2.        ],\n",
            "        [ 0.1501483 , -0.02653096, -0.00322749, ...,  0.25469598,\n",
            "          0.12148345,  2.        ],\n",
            "        [ 0.14810379,  0.03671091,  0.02063923, ...,  0.3267985 ,\n",
            "         -0.02149163,  2.        ],\n",
            "        ...,\n",
            "        [-0.03687198,  0.1382799 ,  0.19674854, ...,  0.05220207,\n",
            "          0.01275885,  2.        ],\n",
            "        [-0.22200245,  0.1440537 ,  0.32250032, ...,  0.05454477,\n",
            "         -0.01996895,  2.        ],\n",
            "        [-0.27630898,  0.10581391,  0.29814157, ...,  0.05902356,\n",
            "          0.0022763 ,  2.        ]], dtype=float32)\n",
            " array([[-1.37971705e-02, -1.20156288e-01, -3.54160517e-02, ...,\n",
            "          4.82626446e-02,  2.13107169e-01,  2.00000000e+00],\n",
            "        [ 1.58676401e-01, -1.69154406e-02, -1.50690423e-02, ...,\n",
            "          2.60667980e-01,  1.14728123e-01,  2.00000000e+00],\n",
            "        [ 1.62558898e-01,  5.09799272e-02,  7.57797807e-03, ...,\n",
            "          3.31146449e-01, -3.66201028e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 6.09534036e-04,  1.30945921e-01,  1.62277058e-01, ...,\n",
            "          5.99837378e-02,  2.55806204e-02,  2.00000000e+00],\n",
            "        [-2.02638835e-01,  1.39789730e-01,  3.12963396e-01, ...,\n",
            "          7.03806132e-02, -9.03363712e-03,  2.00000000e+00],\n",
            "        [-2.62864411e-01,  1.08437739e-01,  2.92446107e-01, ...,\n",
            "          6.84446245e-02,  7.99853634e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-7.9734558e-03, -1.1284901e-01, -4.4578090e-02, ...,\n",
            "          4.2524081e-02,  2.1324708e-01,  2.0000000e+00],\n",
            "        [ 1.4161509e-01, -1.9694855e-02, -2.1904245e-02, ...,\n",
            "          2.1681407e-01,  1.1503702e-01,  2.0000000e+00],\n",
            "        [ 1.3836928e-01,  4.0215183e-02, -6.2585478e-03, ...,\n",
            "          2.8974828e-01, -4.4445664e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.4958998e-02,  1.3839643e-01,  1.3266411e-01, ...,\n",
            "          2.0344654e-02,  4.3888845e-02,  2.0000000e+00],\n",
            "        [-1.9478239e-01,  1.4935242e-01,  3.1308183e-01, ...,\n",
            "          5.5811513e-02,  4.4131242e-03,  2.0000000e+00],\n",
            "        [-2.6968914e-01,  1.0017134e-01,  2.9794759e-01, ...,\n",
            "          6.3833602e-02, -3.6354782e-04,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01665699, -0.11992195, -0.03359434, ...,  0.05052188,\n",
            "          0.21526395,  2.        ],\n",
            "        [ 0.14333464, -0.026392  , -0.00961243, ...,  0.23983629,\n",
            "          0.11964289,  2.        ],\n",
            "        [ 0.14244546,  0.04027577,  0.00677012, ...,  0.3093094 ,\n",
            "         -0.03139746,  2.        ],\n",
            "        ...,\n",
            "        [-0.01282837,  0.14676856,  0.17553098, ...,  0.04621662,\n",
            "          0.02450425,  2.        ],\n",
            "        [-0.21975982,  0.14794268,  0.3214675 , ...,  0.06215248,\n",
            "         -0.00900002,  2.        ],\n",
            "        [-0.2720755 ,  0.11362316,  0.2988915 , ...,  0.06789498,\n",
            "          0.0091171 ,  2.        ]], dtype=float32)\n",
            " array([[-0.01693177, -0.12298851, -0.03264012, ...,  0.03776136,\n",
            "          0.20647584,  2.        ],\n",
            "        [ 0.13295913, -0.01765162, -0.00639265, ...,  0.23821014,\n",
            "          0.10209513,  2.        ],\n",
            "        [ 0.1347587 ,  0.04664403,  0.01029339, ...,  0.31426382,\n",
            "         -0.03922923,  2.        ],\n",
            "        ...,\n",
            "        [-0.01144176,  0.12706776,  0.16730855, ...,  0.04712791,\n",
            "          0.02646602,  2.        ],\n",
            "        [-0.2152699 ,  0.12142418,  0.33415818, ...,  0.05836013,\n",
            "         -0.01059105,  2.        ],\n",
            "        [-0.27691814,  0.09654248,  0.30012065, ...,  0.04753436,\n",
            "         -0.00429729,  2.        ]], dtype=float32)\n",
            " array([[-2.0930087e-02, -1.2843703e-01, -2.9157585e-02, ...,\n",
            "          4.8413888e-02,  2.1772239e-01,  2.0000000e+00],\n",
            "        [ 1.3872221e-01, -3.9546657e-02, -1.3349822e-03, ...,\n",
            "          2.2751375e-01,  1.3535909e-01,  2.0000000e+00],\n",
            "        [ 1.3082895e-01,  1.9625127e-02,  2.4294993e-02, ...,\n",
            "          3.0812326e-01, -1.1760524e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-8.1378996e-02,  1.5531430e-01,  2.3377210e-01, ...,\n",
            "          3.6298618e-02,  1.1028898e-02,  2.0000000e+00],\n",
            "        [-2.4063453e-01,  1.3734835e-01,  3.3701974e-01, ...,\n",
            "          4.5994382e-02, -1.7061725e-02,  2.0000000e+00],\n",
            "        [-2.8299385e-01,  1.0348574e-01,  2.9872778e-01, ...,\n",
            "          6.1494090e-02,  2.3444588e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.42230725e-02, -1.31158054e-01, -2.45580859e-02, ...,\n",
            "          4.35336195e-02,  2.08572567e-01,  2.00000000e+00],\n",
            "        [ 1.29406035e-01, -4.33485955e-02, -1.27622695e-03, ...,\n",
            "          2.48368904e-01,  1.29520386e-01,  2.00000000e+00],\n",
            "        [ 1.18618622e-01,  5.22542745e-03,  2.16852836e-02, ...,\n",
            "          3.30137551e-01,  5.70440153e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.15473144e-01,  1.34050071e-01,  2.53471285e-01, ...,\n",
            "          7.16527253e-02, -5.76462084e-03,  2.00000000e+00],\n",
            "        [-2.56663859e-01,  1.21043332e-01,  3.44930083e-01, ...,\n",
            "          6.07462041e-02, -3.23588178e-02,  2.00000000e+00],\n",
            "        [-3.01587731e-01,  9.34205428e-02,  3.05216223e-01, ...,\n",
            "          4.71445769e-02, -1.23515725e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-1.9652234e-02, -1.2333426e-01, -3.0580688e-02, ...,\n",
            "          3.8116828e-02,  2.0610482e-01,  2.0000000e+00],\n",
            "        [ 1.2735710e-01, -2.1686142e-02, -1.0797760e-03, ...,\n",
            "          2.3913208e-01,  1.0617135e-01,  2.0000000e+00],\n",
            "        [ 1.2626356e-01,  4.2886142e-02,  1.6069544e-02, ...,\n",
            "          3.1456286e-01, -3.4864098e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-2.4095327e-02,  1.3235490e-01,  1.8087599e-01, ...,\n",
            "          5.1248476e-02,  1.9495418e-02,  2.0000000e+00],\n",
            "        [-2.2351287e-01,  1.2639754e-01,  3.3717272e-01, ...,\n",
            "          5.2280877e-02, -1.5423256e-02,  2.0000000e+00],\n",
            "        [-2.8423861e-01,  9.7859085e-02,  3.0398709e-01, ...,\n",
            "          4.1581359e-02, -4.8548430e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02763581, -0.15398824, -0.0451188 , ...,  0.05764119,\n",
            "          0.20990318,  2.        ],\n",
            "        [ 0.15088442, -0.09097124, -0.06790076, ...,  0.28515697,\n",
            "          0.14117745,  2.        ],\n",
            "        [ 0.11511979, -0.0803418 , -0.07807099, ...,  0.37182647,\n",
            "          0.04613618,  2.        ],\n",
            "        ...,\n",
            "        [-0.1129981 ,  0.01570019,  0.17728136, ...,  0.09585126,\n",
            "          0.02558456,  2.        ],\n",
            "        [-0.21273832,  0.0161102 ,  0.23156938, ...,  0.07264727,\n",
            "         -0.01623908,  2.        ],\n",
            "        [-0.2676216 ,  0.02649579,  0.24627675, ...,  0.04162537,\n",
            "         -0.01894404,  2.        ]], dtype=float32)\n",
            " array([[-9.42623243e-03, -1.15128055e-01, -3.61380056e-02, ...,\n",
            "          4.20458876e-02,  2.06711099e-01,  2.00000000e+00],\n",
            "        [ 1.55675590e-01, -8.01625941e-03, -1.84418876e-02, ...,\n",
            "          2.49682307e-01,  8.69377404e-02,  2.00000000e+00],\n",
            "        [ 1.70829073e-01,  6.09938428e-02, -1.14551429e-02, ...,\n",
            "          3.11261356e-01, -6.08130805e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 4.84836921e-02,  1.14774957e-01,  1.08833306e-01, ...,\n",
            "          4.59053554e-02,  5.14277332e-02,  2.00000000e+00],\n",
            "        [-1.74599513e-01,  1.29050538e-01,  3.19879472e-01, ...,\n",
            "          8.82911608e-02, -9.32994240e-04,  2.00000000e+00],\n",
            "        [-2.53727466e-01,  1.08628258e-01,  2.94986337e-01, ...,\n",
            "          5.62504455e-02,  6.40603295e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-1.61941871e-02, -1.17012888e-01, -3.30289602e-02, ...,\n",
            "          4.27233391e-02,  2.09487945e-01,  2.00000000e+00],\n",
            "        [ 1.36760011e-01, -1.87996943e-02, -1.29423840e-02, ...,\n",
            "          2.52434790e-01,  1.01767555e-01,  2.00000000e+00],\n",
            "        [ 1.48547083e-01,  5.19850031e-02, -1.61121774e-04, ...,\n",
            "          3.21492732e-01, -4.46910709e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 3.91989388e-03,  1.20740667e-01,  1.59525111e-01, ...,\n",
            "          5.75873926e-02,  3.41088809e-02,  2.00000000e+00],\n",
            "        [-2.04379797e-01,  1.25258222e-01,  3.34379971e-01, ...,\n",
            "          7.82368034e-02, -7.87740108e-04,  2.00000000e+00],\n",
            "        [-2.66284972e-01,  1.06358021e-01,  2.97267616e-01, ...,\n",
            "          5.63602559e-02,  1.09415073e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.53083240e-02, -1.29753679e-01, -2.30115093e-02, ...,\n",
            "          4.20795716e-02,  2.07779929e-01,  2.00000000e+00],\n",
            "        [ 1.25907391e-01, -4.53990549e-02,  2.62056617e-03, ...,\n",
            "          2.40239203e-01,  1.27534524e-01,  2.00000000e+00],\n",
            "        [ 1.16560452e-01,  5.55304624e-03,  2.46354174e-02, ...,\n",
            "          3.21551770e-01, -4.00711811e-04,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.03451416e-01,  1.35992095e-01,  2.51560688e-01, ...,\n",
            "          6.50692508e-02,  5.88775554e-04,  2.00000000e+00],\n",
            "        [-2.55636692e-01,  1.27471983e-01,  3.54119211e-01, ...,\n",
            "          5.59246056e-02, -2.64029186e-02,  2.00000000e+00],\n",
            "        [-3.03588480e-01,  9.82060358e-02,  3.08305532e-01, ...,\n",
            "          4.36040424e-02, -9.31193400e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02131033, -0.12406615, -0.03295069, ...,  0.0446629 ,\n",
            "          0.21479304,  2.        ],\n",
            "        [ 0.13059443, -0.03488443, -0.01166665, ...,  0.22922175,\n",
            "          0.12454776,  2.        ],\n",
            "        [ 0.12980789,  0.02889035,  0.00894474, ...,  0.30599982,\n",
            "         -0.03125336,  2.        ],\n",
            "        ...,\n",
            "        [-0.04045993,  0.14589581,  0.19290972, ...,  0.03512472,\n",
            "          0.01877798,  2.        ],\n",
            "        [-0.23130439,  0.14536838,  0.32980883, ...,  0.04827288,\n",
            "         -0.01222753,  2.        ],\n",
            "        [-0.2839001 ,  0.10830455,  0.30038732, ...,  0.05819999,\n",
            "          0.00366432,  2.        ]], dtype=float32)\n",
            " array([[-2.4271313e-02, -1.3403510e-01, -3.0652337e-02, ...,\n",
            "          5.5746272e-02,  2.1674697e-01,  2.0000000e+00],\n",
            "        [ 1.5485431e-01, -3.7665363e-02, -1.1798745e-02, ...,\n",
            "          2.6708078e-01,  1.3584089e-01,  2.0000000e+00],\n",
            "        [ 1.4794986e-01,  1.6902443e-02,  1.1779260e-02, ...,\n",
            "          3.5179842e-01, -1.1204479e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-7.7883206e-02,  1.3645807e-01,  2.2014776e-01, ...,\n",
            "          6.6412225e-02,  3.9791237e-03,  2.0000000e+00],\n",
            "        [-2.3109302e-01,  1.2978294e-01,  3.1051776e-01, ...,\n",
            "          6.8364486e-02, -2.4345074e-02,  2.0000000e+00],\n",
            "        [-2.7796218e-01,  9.7976558e-02,  2.8787762e-01, ...,\n",
            "          6.8831652e-02,  3.2927974e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02512041, -0.13351387, -0.02615994, ...,  0.04783177,\n",
            "          0.20951653,  2.        ],\n",
            "        [ 0.13731539, -0.04614734, -0.0128152 , ...,  0.26271752,\n",
            "          0.1344693 ,  2.        ],\n",
            "        [ 0.12169291, -0.00606884,  0.0053694 , ...,  0.34839475,\n",
            "          0.01491237,  2.        ],\n",
            "        ...,\n",
            "        [-0.12933049,  0.12439492,  0.24676783, ...,  0.08303677,\n",
            "         -0.00729987,  2.        ],\n",
            "        [-0.25525856,  0.10873847,  0.32472032, ...,  0.06790123,\n",
            "         -0.03483557,  2.        ],\n",
            "        [-0.30217507,  0.08816396,  0.29828736, ...,  0.05081998,\n",
            "         -0.0150269 ,  2.        ]], dtype=float32)\n",
            " array([[ 1.04372762e-03, -1.12547383e-01, -5.12751378e-02, ...,\n",
            "          4.95891385e-02,  2.14868471e-01,  2.00000000e+00],\n",
            "        [ 1.69748902e-01,  4.81536612e-03, -3.61608900e-02, ...,\n",
            "          2.44628102e-01,  1.09654255e-01,  2.00000000e+00],\n",
            "        [ 1.74295112e-01,  6.45870343e-02, -1.55306244e-02, ...,\n",
            "          3.24716508e-01, -4.88598682e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 8.71881545e-02,  1.14550866e-01,  7.83571824e-02, ...,\n",
            "          4.11484689e-02,  5.22697829e-02,  2.00000000e+00],\n",
            "        [-1.34124145e-01,  1.42463773e-01,  2.72425205e-01, ...,\n",
            "          7.10542575e-02,  9.91474371e-05,  2.00000000e+00],\n",
            "        [-2.36060202e-01,  1.10119663e-01,  2.75174201e-01, ...,\n",
            "          7.38117024e-02,  4.38408367e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.03669862, -0.15852164, -0.058846  , ...,  0.06162629,\n",
            "          0.20680659,  2.        ],\n",
            "        [ 0.1312291 , -0.12515533, -0.07678162, ...,  0.29770318,\n",
            "          0.15316664,  2.        ],\n",
            "        [ 0.07199196, -0.12304239, -0.08352604, ...,  0.3940562 ,\n",
            "          0.08153979,  2.        ],\n",
            "        ...,\n",
            "        [-0.18317159,  0.01786101,  0.19014853, ...,  0.10348181,\n",
            "         -0.0443863 ,  2.        ],\n",
            "        [-0.23873025,  0.03438309,  0.19204307, ...,  0.08925876,\n",
            "         -0.06951445,  2.        ],\n",
            "        [-0.2626666 ,  0.00431823,  0.2283926 , ...,  0.02948718,\n",
            "         -0.03806711,  2.        ]], dtype=float32)\n",
            " array([[-0.02260692, -0.12720795, -0.02647803, ...,  0.04412415,\n",
            "          0.21207511,  2.        ],\n",
            "        [ 0.12804738, -0.03307533,  0.00494758, ...,  0.23051837,\n",
            "          0.1219826 ,  2.        ],\n",
            "        [ 0.12927808,  0.02078667,  0.03111829, ...,  0.30155972,\n",
            "         -0.01700123,  2.        ],\n",
            "        ...,\n",
            "        [-0.06170247,  0.1437489 ,  0.22482319, ...,  0.03785556,\n",
            "          0.00719871,  2.        ],\n",
            "        [-0.23947856,  0.14048782,  0.35158285, ...,  0.04213904,\n",
            "         -0.02207141,  2.        ],\n",
            "        [-0.2927518 ,  0.1034609 ,  0.30875963, ...,  0.04498076,\n",
            "         -0.00312805,  2.        ]], dtype=float32)\n",
            " array([[ 0.02338808, -0.10524032, -0.08079462, ...,  0.03928481,\n",
            "          0.20425937,  2.        ],\n",
            "        [ 0.17017317, -0.01840903, -0.06566247, ...,  0.2050972 ,\n",
            "          0.0915125 ,  2.        ],\n",
            "        [ 0.16038924,  0.0336015 , -0.05438394, ...,  0.2927948 ,\n",
            "         -0.07500141,  2.        ],\n",
            "        ...,\n",
            "        [ 0.09100785,  0.09107246,  0.04316654, ...,  0.03934649,\n",
            "          0.07048123,  2.        ],\n",
            "        [-0.1313572 ,  0.13543306,  0.25369057, ...,  0.09604625,\n",
            "         -0.00447163,  2.        ],\n",
            "        [-0.24219453,  0.07521635,  0.27897683, ...,  0.08043882,\n",
            "         -0.00608707,  2.        ]], dtype=float32)\n",
            " array([[-0.0152119 , -0.11893003, -0.0375594 , ...,  0.03679402,\n",
            "          0.20173202,  2.        ],\n",
            "        [ 0.1374733 , -0.01068984, -0.0149699 , ...,  0.23853044,\n",
            "          0.08518166,  2.        ],\n",
            "        [ 0.13905926,  0.05362006, -0.00242417, ...,  0.31175423,\n",
            "         -0.05592344,  2.        ],\n",
            "        ...,\n",
            "        [ 0.0127448 ,  0.12795027,  0.13946977, ...,  0.03827258,\n",
            "          0.02582478,  2.        ],\n",
            "        [-0.20310599,  0.12141425,  0.32638252, ...,  0.06044389,\n",
            "         -0.01587839,  2.        ],\n",
            "        [-0.2706014 ,  0.09208967,  0.2989186 , ...,  0.04698558,\n",
            "         -0.0078114 ,  2.        ]], dtype=float32)\n",
            " array([[ 0.00702813, -0.10856512, -0.06486207, ...,  0.02162768,\n",
            "          0.19582273,  2.        ],\n",
            "        [ 0.17165232, -0.00755903, -0.04188068, ...,  0.2159736 ,\n",
            "          0.04094072,  2.        ],\n",
            "        [ 0.17483114,  0.04516235, -0.04143349, ...,  0.28061107,\n",
            "         -0.09989839,  2.        ],\n",
            "        ...,\n",
            "        [ 0.07428564,  0.0568922 ,  0.03370536, ...,  0.0190456 ,\n",
            "          0.07723999,  2.        ],\n",
            "        [-0.14045383,  0.11948565,  0.30783576, ...,  0.07114816,\n",
            "         -0.00745088,  2.        ],\n",
            "        [-0.26316887,  0.08470055,  0.29787266, ...,  0.05876254,\n",
            "         -0.00799214,  2.        ]], dtype=float32)\n",
            " array([[-0.02422165, -0.13328017, -0.02577398, ...,  0.04600368,\n",
            "          0.21143998,  2.        ],\n",
            "        [ 0.13703065, -0.04564312, -0.00927179, ...,  0.25598794,\n",
            "          0.13554086,  2.        ],\n",
            "        [ 0.12105448, -0.0026872 ,  0.01173084, ...,  0.33987287,\n",
            "          0.0156267 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.11013504,  0.12786727,  0.2356542 , ...,  0.06956733,\n",
            "          0.00307905,  2.        ],\n",
            "        [-0.25061855,  0.11463943,  0.32398078, ...,  0.05879617,\n",
            "         -0.02722378,  2.        ],\n",
            "        [-0.30019638,  0.08841022,  0.2953595 , ...,  0.04956393,\n",
            "         -0.01333781,  2.        ]], dtype=float32)\n",
            " array([[-0.01709444, -0.12273375, -0.03693597, ...,  0.04977351,\n",
            "          0.21478276,  2.        ],\n",
            "        [ 0.14484724, -0.02509551, -0.01438776, ...,  0.23513296,\n",
            "          0.12476983,  2.        ],\n",
            "        [ 0.1351293 ,  0.03381056,  0.00788582, ...,  0.31121832,\n",
            "         -0.0243702 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.00396502,  0.14448938,  0.15841147, ...,  0.03598492,\n",
            "          0.03568929,  2.        ],\n",
            "        [-0.20374571,  0.1438931 ,  0.312422  , ...,  0.05827576,\n",
            "         -0.00258008,  2.        ],\n",
            "        [-0.26284054,  0.1109863 ,  0.28707924, ...,  0.06653699,\n",
            "          0.00564763,  2.        ]], dtype=float32)\n",
            " array([[-0.01905987, -0.1322606 , -0.03169744, ...,  0.04443121,\n",
            "          0.20998108,  2.        ],\n",
            "        [ 0.14651914, -0.03180103, -0.0097834 , ...,  0.26388523,\n",
            "          0.12365079,  2.        ],\n",
            "        [ 0.1435397 ,  0.0217723 ,  0.01012547, ...,  0.34423026,\n",
            "         -0.01018186,  2.        ],\n",
            "        ...,\n",
            "        [-0.04772997,  0.12646335,  0.19077477, ...,  0.08290893,\n",
            "          0.01633483,  2.        ],\n",
            "        [-0.22193299,  0.11895523,  0.31594557, ...,  0.07169359,\n",
            "         -0.01859859,  2.        ],\n",
            "        [-0.27984676,  0.09211747,  0.2893298 , ...,  0.05711078,\n",
            "         -0.009237  ,  2.        ]], dtype=float32)\n",
            " array([[-0.03003889, -0.1562291 , -0.047996  , ...,  0.05551167,\n",
            "          0.21281686,  2.        ],\n",
            "        [ 0.14820088, -0.0973398 , -0.07481848, ...,  0.28588676,\n",
            "          0.15255453,  2.        ],\n",
            "        [ 0.10608859, -0.09116563, -0.08268693, ...,  0.37950835,\n",
            "          0.05708081,  2.        ],\n",
            "        ...,\n",
            "        [-0.12363902,  0.00952206,  0.18472067, ...,  0.10679843,\n",
            "          0.0234344 ,  2.        ],\n",
            "        [-0.22369619,  0.01233073,  0.23461904, ...,  0.07894748,\n",
            "         -0.02235563,  2.        ],\n",
            "        [-0.27581233,  0.02134772,  0.24989647, ...,  0.0368858 ,\n",
            "         -0.01852244,  2.        ]], dtype=float32)\n",
            " array([[-0.00224074, -0.12332524, -0.04982079, ...,  0.05579647,\n",
            "          0.21532133,  2.        ],\n",
            "        [ 0.1601976 , -0.02529858, -0.03469783, ...,  0.23269132,\n",
            "          0.12121435,  2.        ],\n",
            "        [ 0.1521907 ,  0.03135341, -0.01324716, ...,  0.31935555,\n",
            "         -0.03624523,  2.        ],\n",
            "        ...,\n",
            "        [ 0.04832794,  0.11095212,  0.08897997, ...,  0.04306475,\n",
            "          0.06473542,  2.        ],\n",
            "        [-0.15757765,  0.12779838,  0.2667733 , ...,  0.07006112,\n",
            "          0.01068022,  2.        ],\n",
            "        [-0.24804555,  0.10051101,  0.26616785, ...,  0.07384451,\n",
            "          0.00627365,  2.        ]], dtype=float32)\n",
            " array([[ 0.04142078, -0.15193965, -0.08751757, ...,  0.02746982,\n",
            "          0.19781461,  2.        ],\n",
            "        [ 0.25372627, -0.05203114, -0.0896331 , ...,  0.19343358,\n",
            "          0.03159722,  2.        ],\n",
            "        [ 0.24162772, -0.01052091, -0.08179509, ...,  0.25347835,\n",
            "         -0.10262647,  2.        ],\n",
            "        ...,\n",
            "        [ 0.19536394, -0.02075027, -0.03936331, ...,  0.04999527,\n",
            "          0.03277873,  2.        ],\n",
            "        [-0.02987688,  0.0462041 ,  0.20901152, ...,  0.10331404,\n",
            "         -0.04308047,  2.        ],\n",
            "        [-0.23175722,  0.03665546,  0.28370064, ...,  0.07979424,\n",
            "         -0.02043138,  2.        ]], dtype=float32)\n",
            " array([[-3.0927367e-03, -1.1004008e-01, -4.6651494e-02, ...,\n",
            "          4.0331006e-02,  2.0486437e-01,  3.0000000e+00],\n",
            "        [ 1.6820645e-01, -4.9000336e-03, -3.3102844e-02, ...,\n",
            "          2.5185162e-01,  6.7321330e-02,  3.0000000e+00],\n",
            "        [ 1.8028413e-01,  5.5705320e-02, -2.8894583e-02, ...,\n",
            "          3.0978999e-01, -7.1984932e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 8.9480780e-02,  8.1970289e-02,  4.6946980e-02, ...,\n",
            "          4.3502580e-02,  6.5126628e-02,  3.0000000e+00],\n",
            "        [-1.4431259e-01,  1.2616141e-01,  3.0579096e-01, ...,\n",
            "          9.7263120e-02,  7.3645770e-04,  3.0000000e+00],\n",
            "        [-2.4928729e-01,  1.0778715e-01,  2.9012561e-01, ...,\n",
            "          6.3018128e-02,  8.1485063e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-8.1503568e-03, -1.1438914e-01, -3.8759302e-02, ...,\n",
            "          4.1601844e-02,  2.0822543e-01,  2.0000000e+00],\n",
            "        [ 1.5361516e-01, -1.0182058e-02, -2.1243544e-02, ...,\n",
            "          2.4510348e-01,  8.9431584e-02,  2.0000000e+00],\n",
            "        [ 1.6761993e-01,  5.7939477e-02, -1.3736790e-02, ...,\n",
            "          3.1199431e-01, -5.9535321e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 4.5512319e-02,  1.1013599e-01,  1.0621537e-01, ...,\n",
            "          4.2231072e-02,  5.4060478e-02,  2.0000000e+00],\n",
            "        [-1.7895909e-01,  1.2461413e-01,  3.1834993e-01, ...,\n",
            "          8.5544080e-02,  1.8732557e-03,  2.0000000e+00],\n",
            "        [-2.5500646e-01,  1.0917042e-01,  2.9148656e-01, ...,\n",
            "          5.7722233e-02,  7.8117172e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01305525, -0.12435271, -0.02971946, ...,  0.04435587,\n",
            "          0.21044332,  2.        ],\n",
            "        [ 0.15270017, -0.02516587, -0.00598561, ...,  0.2631949 ,\n",
            "          0.11729775,  2.        ],\n",
            "        [ 0.15756384,  0.03882395,  0.00763096, ...,  0.33457258,\n",
            "         -0.0207791 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.0080116 ,  0.1249527 ,  0.1791784 , ...,  0.07883907,\n",
            "          0.02861202,  2.        ],\n",
            "        [-0.21098693,  0.130857  ,  0.32964635, ...,  0.07921249,\n",
            "         -0.00759211,  2.        ],\n",
            "        [-0.26763278,  0.10798343,  0.29768646, ...,  0.05769183,\n",
            "          0.004237  ,  2.        ]], dtype=float32)\n",
            " array([[-1.19571257e-02, -1.21290095e-01, -3.01586855e-02, ...,\n",
            "          4.27377410e-02,  2.11235911e-01,  1.00000000e+00],\n",
            "        [ 1.52028874e-01, -2.16840412e-02, -8.51775240e-03, ...,\n",
            "          2.58287698e-01,  1.14656225e-01,  1.00000000e+00],\n",
            "        [ 1.59349531e-01,  5.02402224e-02,  8.09776224e-03, ...,\n",
            "          3.27742368e-01, -2.97025777e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.69618614e-02,  1.20650105e-01,  1.58066779e-01, ...,\n",
            "          6.21847659e-02,  3.95003296e-02,  1.00000000e+00],\n",
            "        [-1.97683260e-01,  1.25398830e-01,  3.27753961e-01, ...,\n",
            "          7.93002918e-02, -2.30805541e-04,  1.00000000e+00],\n",
            "        [-2.61016101e-01,  1.09250143e-01,  2.96959996e-01, ...,\n",
            "          5.86566180e-02,  8.61420576e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.02416598, -0.12911825, -0.02487905, ...,  0.04336393,\n",
            "          0.2080091 ,  1.        ],\n",
            "        [ 0.12546511, -0.04529824,  0.00140067, ...,  0.23941629,\n",
            "          0.12854043,  1.        ],\n",
            "        [ 0.1167114 ,  0.0052656 ,  0.02280047, ...,  0.32210305,\n",
            "         -0.00296201,  1.        ],\n",
            "        ...,\n",
            "        [-0.10342336,  0.13637449,  0.2516349 , ...,  0.06868761,\n",
            "          0.00108876,  1.        ],\n",
            "        [-0.25581142,  0.12782367,  0.35433102, ...,  0.05635743,\n",
            "         -0.02804439,  1.        ],\n",
            "        [-0.30360568,  0.09721232,  0.30789027, ...,  0.0429152 ,\n",
            "         -0.01096999,  1.        ]], dtype=float32)\n",
            " array([[-0.03051816, -0.15660876, -0.03935686, ...,  0.05994259,\n",
            "          0.2149591 ,  1.        ],\n",
            "        [ 0.16726989, -0.08597576, -0.04935258, ...,  0.29189485,\n",
            "          0.15485162,  1.        ],\n",
            "        [ 0.12540376, -0.07358199, -0.0471856 , ...,  0.38350317,\n",
            "          0.05715147,  1.        ],\n",
            "        ...,\n",
            "        [-0.1273582 ,  0.03178256,  0.21370625, ...,  0.08993953,\n",
            "          0.00571987,  1.        ],\n",
            "        [-0.22942093,  0.03499299,  0.24666576, ...,  0.07645225,\n",
            "         -0.03197614,  1.        ],\n",
            "        [-0.27209508,  0.04511841,  0.25732973, ...,  0.04388255,\n",
            "         -0.01383497,  1.        ]], dtype=float32)\n",
            " array([[-0.01866108, -0.13152252, -0.03219882, ...,  0.05454345,\n",
            "          0.21689297,  1.        ],\n",
            "        [ 0.1621814 , -0.03643352, -0.01625473, ...,  0.27502367,\n",
            "          0.13248576,  1.        ],\n",
            "        [ 0.1558313 ,  0.02444806,  0.00462748, ...,  0.36256444,\n",
            "         -0.01169695,  1.        ],\n",
            "        ...,\n",
            "        [-0.06148899,  0.13244551,  0.20682274, ...,  0.07694167,\n",
            "          0.00362982,  1.        ],\n",
            "        [-0.2201643 ,  0.13018435,  0.30615917, ...,  0.07552738,\n",
            "         -0.02323143,  1.        ],\n",
            "        [-0.2705931 ,  0.09999356,  0.28746477, ...,  0.07268578,\n",
            "          0.00225335,  1.        ]], dtype=float32)\n",
            " array([[-0.02414909, -0.1321085 , -0.02677361, ...,  0.04491766,\n",
            "          0.20967817,  1.        ],\n",
            "        [ 0.1336752 , -0.04759007, -0.00889424, ...,  0.25626853,\n",
            "          0.13250092,  1.        ],\n",
            "        [ 0.11836221, -0.00697925,  0.00924803, ...,  0.34203392,\n",
            "          0.0112126 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.1168997 ,  0.12762216,  0.2406664 , ...,  0.08390073,\n",
            "         -0.00290993,  1.        ],\n",
            "        [-0.25294015,  0.11639191,  0.33019978, ...,  0.06493179,\n",
            "         -0.03316807,  1.        ],\n",
            "        [-0.30116528,  0.08862236,  0.2985599 , ...,  0.04773366,\n",
            "         -0.01667356,  1.        ]], dtype=float32)\n",
            " array([[-0.02367824, -0.13804924, -0.02845543, ...,  0.05396927,\n",
            "          0.21569538,  1.        ],\n",
            "        [ 0.15157725, -0.04653776, -0.00986444, ...,  0.25759044,\n",
            "          0.13874675,  1.        ],\n",
            "        [ 0.1364292 , -0.00121112,  0.01349516, ...,  0.33917946,\n",
            "          0.01017716,  1.        ],\n",
            "        ...,\n",
            "        [-0.11901772,  0.14198998,  0.22966813, ...,  0.06080105,\n",
            "         -0.01103975,  1.        ],\n",
            "        [-0.2500491 ,  0.1215023 ,  0.3103714 , ...,  0.05894112,\n",
            "         -0.03628786,  1.        ],\n",
            "        [-0.2840155 ,  0.09694939,  0.28732195, ...,  0.06202201,\n",
            "         -0.00751969,  1.        ]], dtype=float32)\n",
            " array([[-0.02012238, -0.12753478, -0.02789691, ...,  0.03965099,\n",
            "          0.20636547,  1.        ],\n",
            "        [ 0.13224067, -0.0333072 , -0.00127328, ...,  0.24407019,\n",
            "          0.1173875 ,  1.        ],\n",
            "        [ 0.12659328,  0.02535858,  0.01854509, ...,  0.3249506 ,\n",
            "         -0.01710826,  1.        ],\n",
            "        ...,\n",
            "        [-0.05673496,  0.13154136,  0.20831251, ...,  0.07046223,\n",
            "          0.01237669,  1.        ],\n",
            "        [-0.23513289,  0.12513545,  0.34051055, ...,  0.06169111,\n",
            "         -0.01982948,  1.        ],\n",
            "        [-0.28938875,  0.09757119,  0.30295324, ...,  0.04510697,\n",
            "         -0.00898875,  1.        ]], dtype=float32)\n",
            " array([[-0.03174462, -0.15431237, -0.06185065, ...,  0.06832104,\n",
            "          0.20475599,  1.        ],\n",
            "        [ 0.15374526, -0.1161072 , -0.06192034, ...,  0.2951189 ,\n",
            "          0.16771473,  1.        ],\n",
            "        [ 0.08812717, -0.10599048, -0.06194177, ...,  0.41137084,\n",
            "          0.0835444 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.19131608,  0.04005385,  0.18628483, ...,  0.08983284,\n",
            "         -0.0564911 ,  1.        ],\n",
            "        [-0.2518498 ,  0.06415554,  0.19465578, ...,  0.07788895,\n",
            "         -0.06650759,  1.        ],\n",
            "        [-0.24532227,  0.03613104,  0.22598052, ...,  0.0243051 ,\n",
            "         -0.03556717,  1.        ]], dtype=float32)\n",
            " array([[-0.02476581, -0.1576591 , -0.06347252, ...,  0.05352031,\n",
            "          0.18508328,  1.        ],\n",
            "        [ 0.10820181, -0.13387318, -0.06285698, ...,  0.24330968,\n",
            "          0.15040264,  1.        ],\n",
            "        [ 0.04127723, -0.1344095 , -0.08022538, ...,  0.33794358,\n",
            "          0.09159502,  1.        ],\n",
            "        ...,\n",
            "        [-0.22444254,  0.04823797,  0.2031676 , ..., -0.00805797,\n",
            "         -0.08918613,  1.        ],\n",
            "        [-0.2622058 ,  0.06317966,  0.20834865, ...,  0.00313435,\n",
            "         -0.08402448,  1.        ],\n",
            "        [-0.22490153,  0.03722733,  0.23466903, ..., -0.02623339,\n",
            "         -0.05442889,  1.        ]], dtype=float32)\n",
            " array([[-0.01528339, -0.11841486, -0.03912491, ...,  0.05005169,\n",
            "          0.21262115,  1.        ],\n",
            "        [ 0.15251438, -0.00734508, -0.01531304, ...,  0.25612876,\n",
            "          0.10642391,  1.        ],\n",
            "        [ 0.15820166,  0.06130895,  0.00375342, ...,  0.3272113 ,\n",
            "         -0.04855673,  1.        ],\n",
            "        ...,\n",
            "        [ 0.00144701,  0.13001625,  0.1625887 , ...,  0.05073735,\n",
            "          0.01725862,  1.        ],\n",
            "        [-0.19817184,  0.13905153,  0.3183781 , ...,  0.06604449,\n",
            "         -0.01072684,  1.        ],\n",
            "        [-0.26096758,  0.10860897,  0.29493225, ...,  0.06976932,\n",
            "          0.00731085,  1.        ]], dtype=float32)\n",
            " array([[-5.64333168e-04, -1.10412911e-01, -4.33995128e-02, ...,\n",
            "          4.14584689e-02,  2.06039399e-01,  1.00000000e+00],\n",
            "        [ 1.73416510e-01, -3.78929055e-03, -3.12961675e-02, ...,\n",
            "          2.51132786e-01,  7.81988278e-02,  1.00000000e+00],\n",
            "        [ 1.84345812e-01,  6.03665449e-02, -2.62519419e-02, ...,\n",
            "          3.11967313e-01, -6.52652234e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 8.76961350e-02,  8.94517228e-02,  5.64185306e-02, ...,\n",
            "          4.62557785e-02,  6.69383109e-02,  1.00000000e+00],\n",
            "        [-1.49477512e-01,  1.24624871e-01,  3.04935753e-01, ...,\n",
            "          1.00820281e-01,  3.07201082e-03,  1.00000000e+00],\n",
            "        [-2.44749531e-01,  1.08993754e-01,  2.89151758e-01, ...,\n",
            "          6.31746575e-02,  7.30123604e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.00858529, -0.11776134, -0.03679939, ...,  0.04571396,\n",
            "          0.20850837,  1.        ],\n",
            "        [ 0.15705512, -0.01406227, -0.02168532, ...,  0.25722986,\n",
            "          0.10169929,  1.        ],\n",
            "        [ 0.16538487,  0.0552858 , -0.01094056, ...,  0.33067772,\n",
            "         -0.04330911,  1.        ],\n",
            "        ...,\n",
            "        [ 0.03197657,  0.11962496,  0.13387002, ...,  0.06623937,\n",
            "          0.04325181,  1.        ],\n",
            "        [-0.18955973,  0.12084106,  0.31888992, ...,  0.09031302,\n",
            "         -0.00198644,  1.        ],\n",
            "        [-0.2547895 ,  0.10786854,  0.28789473, ...,  0.06134979,\n",
            "          0.00606501,  1.        ]], dtype=float32)\n",
            " array([[-0.01675859, -0.13813756, -0.02503882, ...,  0.05464143,\n",
            "          0.21378806,  1.        ],\n",
            "        [ 0.15492247, -0.05970743, -0.01545044, ...,  0.24980387,\n",
            "          0.15785418,  1.        ],\n",
            "        [ 0.12253129, -0.03471868,  0.00230279, ...,  0.34076655,\n",
            "          0.05242174,  1.        ],\n",
            "        ...,\n",
            "        [-0.07843053,  0.10623561,  0.22140299, ...,  0.09678608,\n",
            "          0.03969907,  1.        ],\n",
            "        [-0.23600331,  0.10406063,  0.3243211 , ...,  0.10533653,\n",
            "          0.00432019,  1.        ],\n",
            "        [-0.31040618,  0.08309225,  0.29478785, ...,  0.07434549,\n",
            "         -0.0032923 ,  1.        ]], dtype=float32)\n",
            " array([[-0.03206005, -0.14677344, -0.04004591, ...,  0.06221212,\n",
            "          0.21722351,  1.        ],\n",
            "        [ 0.17391762, -0.07346112, -0.05812815, ...,  0.295465  ,\n",
            "          0.15481664,  1.        ],\n",
            "        [ 0.1320788 , -0.06298253, -0.05375155, ...,  0.39174953,\n",
            "          0.05384953,  1.        ],\n",
            "        ...,\n",
            "        [-0.11101098,  0.04365036,  0.19433297, ...,  0.09759468,\n",
            "          0.01413182,  1.        ],\n",
            "        [-0.23438162,  0.04702431,  0.2527165 , ...,  0.07903895,\n",
            "         -0.03253826,  1.        ],\n",
            "        [-0.282568  ,  0.05640779,  0.26291797, ...,  0.04493512,\n",
            "         -0.01222551,  1.        ]], dtype=float32)\n",
            " array([[-1.9687355e-02, -1.2634249e-01, -2.7776903e-02, ...,\n",
            "          3.9949924e-02,  2.0779589e-01,  1.0000000e+00],\n",
            "        [ 1.3208485e-01, -3.1068129e-02,  4.3082226e-04, ...,\n",
            "          2.4518682e-01,  1.1897461e-01,  1.0000000e+00],\n",
            "        [ 1.2775154e-01,  2.9659530e-02,  2.2496674e-02, ...,\n",
            "          3.2357243e-01, -1.9003114e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-4.0919445e-02,  1.3257942e-01,  1.9830537e-01, ...,\n",
            "          6.3558199e-02,  1.8096456e-02,  1.0000000e+00],\n",
            "        [-2.3189616e-01,  1.3066179e-01,  3.3887893e-01, ...,\n",
            "          5.7592347e-02, -1.5127225e-02,  1.0000000e+00],\n",
            "        [-2.8986037e-01,  9.9406779e-02,  3.0165106e-01, ...,\n",
            "          4.7016181e-02, -8.3320886e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02298584, -0.12828435, -0.02507497, ...,  0.04095198,\n",
            "          0.2073586 ,  1.        ],\n",
            "        [ 0.12887941, -0.04166729,  0.0045481 , ...,  0.23654665,\n",
            "          0.12341388,  1.        ],\n",
            "        [ 0.11959025,  0.01056473,  0.02718493, ...,  0.31622452,\n",
            "         -0.00582336,  1.        ],\n",
            "        ...,\n",
            "        [-0.09783309,  0.13999082,  0.2422871 , ...,  0.06313398,\n",
            "          0.00450251,  1.        ],\n",
            "        [-0.25182515,  0.1344238 ,  0.34761226, ...,  0.05362139,\n",
            "         -0.02844182,  1.        ],\n",
            "        [-0.30058128,  0.10008375,  0.30615425, ...,  0.04344015,\n",
            "         -0.01017036,  1.        ]], dtype=float32)\n",
            " array([[-0.01795064, -0.14075959, -0.03395282, ...,  0.0517626 ,\n",
            "          0.21607739,  1.        ],\n",
            "        [ 0.14968476, -0.04428928, -0.01242012, ...,  0.25187758,\n",
            "          0.13869418,  1.        ],\n",
            "        [ 0.13976002,  0.00299863,  0.01101487, ...,  0.33291963,\n",
            "          0.00375311,  1.        ],\n",
            "        ...,\n",
            "        [-0.0489788 ,  0.14186013,  0.17867564, ...,  0.04734629,\n",
            "          0.03146386,  1.        ],\n",
            "        [-0.21359682,  0.12706052,  0.2910571 , ...,  0.05717053,\n",
            "         -0.00903075,  1.        ],\n",
            "        [-0.27313206,  0.09737287,  0.27381787, ...,  0.06569937,\n",
            "         -0.00342167,  1.        ]], dtype=float32)\n",
            " array([[-0.01966288, -0.13024297, -0.02753676, ...,  0.04402677,\n",
            "          0.21006441,  1.        ],\n",
            "        [ 0.13847862, -0.03512032, -0.00422271, ...,  0.2533619 ,\n",
            "          0.1273382 ,  1.        ],\n",
            "        [ 0.13554803,  0.0203068 ,  0.0172416 , ...,  0.3332417 ,\n",
            "         -0.00581053,  1.        ],\n",
            "        ...,\n",
            "        [-0.06289487,  0.13233541,  0.22000149, ...,  0.07666437,\n",
            "          0.0123643 ,  1.        ],\n",
            "        [-0.23465098,  0.12265653,  0.3384678 , ...,  0.06809931,\n",
            "         -0.01757036,  1.        ],\n",
            "        [-0.28812918,  0.09388144,  0.29941463, ...,  0.05457367,\n",
            "         -0.00817961,  1.        ]], dtype=float32)\n",
            " array([[ 3.1197526e-02, -1.2628478e-01, -8.5835859e-02, ...,\n",
            "          3.7205558e-02,  2.0670295e-01,  1.0000000e+00],\n",
            "        [ 2.2861758e-01,  3.3384487e-03, -7.0828885e-02, ...,\n",
            "          2.4482438e-01,  6.0516980e-02,  1.0000000e+00],\n",
            "        [ 2.1549965e-01,  3.5637792e-02, -6.1864704e-02, ...,\n",
            "          3.2316998e-01, -7.5344644e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [ 2.0032175e-01,  1.7644973e-02, -4.9614217e-02, ...,\n",
            "          5.8435790e-02,  8.6401157e-02,  1.0000000e+00],\n",
            "        [-4.1354142e-02,  9.2401423e-02,  2.2400321e-01, ...,\n",
            "          1.0432030e-01,  5.9990291e-03,  1.0000000e+00],\n",
            "        [-2.2761627e-01,  7.8339599e-02,  2.7111864e-01, ...,\n",
            "          7.9205148e-02, -7.9715101e-05,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.013965  , -0.12120335, -0.0353304 , ...,  0.04799291,\n",
            "          0.21845204,  1.        ],\n",
            "        [ 0.14754789, -0.02398829, -0.01336467, ...,  0.24592853,\n",
            "          0.12032609,  1.        ],\n",
            "        [ 0.14767046,  0.04135533,  0.00748582, ...,  0.32054353,\n",
            "         -0.03282656,  1.        ],\n",
            "        ...,\n",
            "        [-0.00123308,  0.13895792,  0.16263558, ...,  0.05078538,\n",
            "          0.03088121,  1.        ],\n",
            "        [-0.20880876,  0.14549166,  0.31535614, ...,  0.06771115,\n",
            "         -0.00928316,  1.        ],\n",
            "        [-0.26623234,  0.10864531,  0.29492807, ...,  0.07117241,\n",
            "          0.00483996,  1.        ]], dtype=float32)\n",
            " array([[-0.01975279, -0.12207877, -0.03127986, ...,  0.03804402,\n",
            "          0.20666   ,  1.        ],\n",
            "        [ 0.12596981, -0.01819715, -0.00300354, ...,  0.23607065,\n",
            "          0.10474312,  1.        ],\n",
            "        [ 0.12866262,  0.04876288,  0.0163925 , ...,  0.30948034,\n",
            "         -0.03741411,  1.        ],\n",
            "        ...,\n",
            "        [-0.01657265,  0.12737077,  0.1743518 , ...,  0.04010146,\n",
            "          0.02502643,  1.        ],\n",
            "        [-0.22096133,  0.12320973,  0.33913985, ...,  0.04922864,\n",
            "         -0.01261027,  1.        ],\n",
            "        [-0.28158817,  0.09598426,  0.30454674, ...,  0.04363429,\n",
            "         -0.00226917,  1.        ]], dtype=float32)\n",
            " array([[-0.02536638, -0.14765482, -0.04391514, ...,  0.06742646,\n",
            "          0.21337278,  1.        ],\n",
            "        [ 0.18948571, -0.07086933, -0.05589253, ...,  0.29788664,\n",
            "          0.14556645,  1.        ],\n",
            "        [ 0.15355237, -0.05713689, -0.05078499, ...,  0.38991022,\n",
            "          0.04237614,  1.        ],\n",
            "        ...,\n",
            "        [-0.09083825,  0.03445011,  0.18490118, ...,  0.08525338,\n",
            "          0.00485741,  1.        ],\n",
            "        [-0.20469499,  0.04772687,  0.22557299, ...,  0.07924498,\n",
            "         -0.03064762,  1.        ],\n",
            "        [-0.2515598 ,  0.05130232,  0.24395779, ...,  0.05412001,\n",
            "         -0.01274569,  1.        ]], dtype=float32)\n",
            " array([[ 0.00659721, -0.11940145, -0.06088507, ...,  0.05279312,\n",
            "          0.20904602,  1.        ],\n",
            "        [ 0.16949534, -0.0107664 , -0.05153409, ...,  0.23945424,\n",
            "          0.10404121,  1.        ],\n",
            "        [ 0.16286547,  0.04194534, -0.03414015, ...,  0.32641804,\n",
            "         -0.05719742,  1.        ],\n",
            "        ...,\n",
            "        [ 0.06847383,  0.10034128,  0.08370105, ...,  0.04924395,\n",
            "          0.03851741,  1.        ],\n",
            "        [-0.13808215,  0.13421024,  0.2607332 , ...,  0.07180519,\n",
            "         -0.00544702,  1.        ],\n",
            "        [-0.2400117 ,  0.09830663,  0.26132244, ...,  0.07456896,\n",
            "          0.00215271,  1.        ]], dtype=float32)\n",
            " array([[-1.76828913e-02, -1.26763672e-01, -2.72378903e-02, ...,\n",
            "          4.35591713e-02,  2.08871499e-01,  2.00000000e+00],\n",
            "        [ 1.44647554e-01, -3.20360102e-02, -9.98761505e-04, ...,\n",
            "          2.58893877e-01,  1.15868963e-01,  2.00000000e+00],\n",
            "        [ 1.47808954e-01,  2.72527877e-02,  1.24799656e-02, ...,\n",
            "          3.31263304e-01, -1.92849226e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-2.97582336e-02,  1.23714246e-01,  1.98341653e-01, ...,\n",
            "          7.47883469e-02,  1.68781690e-02,  2.00000000e+00],\n",
            "        [-2.24421680e-01,  1.30492792e-01,  3.39064956e-01, ...,\n",
            "          7.27665126e-02, -1.43395225e-02,  2.00000000e+00],\n",
            "        [-2.74237514e-01,  1.08672604e-01,  2.98560500e-01, ...,\n",
            "          5.10324575e-02,  3.85916210e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-3.4253232e-02, -1.6100785e-01, -4.5420174e-02, ...,\n",
            "          6.5142393e-02,  2.1401022e-01,  3.0000000e+00],\n",
            "        [ 1.7437236e-01, -9.7165518e-02, -5.5297751e-02, ...,\n",
            "          2.9872647e-01,  1.6299874e-01,  3.0000000e+00],\n",
            "        [ 1.2658887e-01, -9.1386944e-02, -5.1716223e-02, ...,\n",
            "          3.9249408e-01,  7.0780188e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.3550209e-01,  2.8409937e-02,  2.0112504e-01, ...,\n",
            "          9.5090322e-02, -2.3946585e-03,  3.0000000e+00],\n",
            "        [-2.3596127e-01,  4.2225990e-02,  2.2068664e-01, ...,\n",
            "          7.8525469e-02, -3.9154500e-02,  3.0000000e+00],\n",
            "        [-2.6465440e-01,  3.1057507e-02,  2.4166986e-01, ...,\n",
            "          3.9928276e-02, -1.9196108e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.9015409e-02, -1.2915105e-01, -3.1290133e-02, ...,\n",
            "          6.3854218e-02,  2.1242559e-01,  3.0000000e+00],\n",
            "        [ 1.6759254e-01, -5.0361086e-02, -2.3400009e-02, ...,\n",
            "          2.6734862e-01,  1.4465976e-01,  3.0000000e+00],\n",
            "        [ 1.4374729e-01, -1.6144490e-02, -2.3081002e-03, ...,\n",
            "          3.6118814e-01,  2.5044216e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1283331e-01,  1.2244813e-01,  2.2499749e-01, ...,\n",
            "          7.7161096e-02, -7.8131761e-03,  3.0000000e+00],\n",
            "        [-2.4993926e-01,  1.0479943e-01,  2.9515275e-01, ...,\n",
            "          7.0925973e-02, -3.6025498e-02,  3.0000000e+00],\n",
            "        [-2.8506598e-01,  9.4286129e-02,  2.7776885e-01, ...,\n",
            "          5.9933558e-02, -7.6208157e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02124049, -0.12450365, -0.03609015, ...,  0.05065326,\n",
            "          0.21195182,  3.        ],\n",
            "        [ 0.1341717 , -0.0206976 , -0.01072489, ...,  0.24858177,\n",
            "          0.1085953 ,  3.        ],\n",
            "        [ 0.14186315,  0.04691086,  0.00590875, ...,  0.31767198,\n",
            "         -0.04373518,  3.        ],\n",
            "        ...,\n",
            "        [-0.02860326,  0.13976415,  0.18760253, ...,  0.04799777,\n",
            "          0.00578769,  3.        ],\n",
            "        [-0.22574307,  0.14411452,  0.33390683, ...,  0.06043467,\n",
            "         -0.01967489,  3.        ],\n",
            "        [-0.27645227,  0.10692069,  0.30296382, ...,  0.06748039,\n",
            "          0.00535919,  3.        ]], dtype=float32)\n",
            " array([[-5.0476496e-03, -1.0948212e-01, -5.3097840e-02, ...,\n",
            "          2.9424397e-02,  1.9742690e-01,  3.0000000e+00],\n",
            "        [ 1.5029009e-01, -8.5247094e-03, -2.4855912e-02, ...,\n",
            "          2.2546217e-01,  5.3960372e-02,  3.0000000e+00],\n",
            "        [ 1.5994467e-01,  5.3957339e-02, -2.1105714e-02, ...,\n",
            "          2.9125324e-01, -8.7838963e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.2135158e-02,  8.2199857e-02,  6.7081429e-02, ...,\n",
            "          1.9493189e-02,  7.2070837e-02,  3.0000000e+00],\n",
            "        [-1.6496165e-01,  1.2414506e-01,  3.1512219e-01, ...,\n",
            "          6.9023527e-02, -4.4334694e-04,  3.0000000e+00],\n",
            "        [-2.6856771e-01,  8.9168906e-02,  3.0038649e-01, ...,\n",
            "          5.3648774e-02, -2.2872665e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.4524918e-02, -1.3999285e-01, -3.2226358e-02, ...,\n",
            "          5.3931233e-02,  2.1626320e-01,  3.0000000e+00],\n",
            "        [ 1.6062124e-01, -4.3790523e-02, -1.4467308e-02, ...,\n",
            "          2.7206188e-01,  1.2965816e-01,  3.0000000e+00],\n",
            "        [ 1.4947441e-01,  1.0852516e-02,  4.1109915e-03, ...,\n",
            "          3.5141486e-01, -9.2601118e-04,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-6.9716349e-02,  1.3529798e-01,  1.9298369e-01, ...,\n",
            "          6.0752802e-02,  7.7014104e-03,  3.0000000e+00],\n",
            "        [-2.2845152e-01,  1.2738194e-01,  2.9196939e-01, ...,\n",
            "          6.3429534e-02, -2.1260783e-02,  3.0000000e+00],\n",
            "        [-2.7466404e-01,  9.7821929e-02,  2.7994794e-01, ...,\n",
            "          6.7880228e-02,  2.0903971e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03201182, -0.12166312, -0.02970908, ...,  0.05599002,\n",
            "          0.20613495,  3.        ],\n",
            "        [ 0.13633339, -0.05419631, -0.02923264, ...,  0.25774118,\n",
            "          0.14131598,  3.        ],\n",
            "        [ 0.11708938, -0.02341691, -0.01499587, ...,  0.35086071,\n",
            "          0.02568009,  3.        ],\n",
            "        ...,\n",
            "        [-0.14828514,  0.11177809,  0.24883097, ...,  0.08839899,\n",
            "         -0.00734728,  3.        ],\n",
            "        [-0.26598626,  0.09900486,  0.313785  , ...,  0.06911823,\n",
            "         -0.03754996,  3.        ],\n",
            "        [-0.30748665,  0.0874343 ,  0.29105967, ...,  0.03921661,\n",
            "         -0.01775062,  3.        ]], dtype=float32)\n",
            " array([[-0.03464951, -0.13955346, -0.03609059, ...,  0.06102585,\n",
            "          0.21224295,  3.        ],\n",
            "        [ 0.16293135, -0.05985417, -0.03759754, ...,  0.2712158 ,\n",
            "          0.14771023,  3.        ],\n",
            "        [ 0.12657331, -0.03711152, -0.02787862, ...,  0.35694152,\n",
            "          0.04276998,  3.        ],\n",
            "        ...,\n",
            "        [-0.13601044,  0.07567976,  0.22315133, ...,  0.07624772,\n",
            "         -0.00461201,  3.        ],\n",
            "        [-0.25758958,  0.0660684 ,  0.2677926 , ...,  0.06320165,\n",
            "         -0.04309697,  3.        ],\n",
            "        [-0.2853657 ,  0.07037856,  0.26797464, ...,  0.04408112,\n",
            "         -0.0160709 ,  3.        ]], dtype=float32)\n",
            " array([[-0.02180982, -0.13878372, -0.02942616, ...,  0.04827115,\n",
            "          0.21063913,  3.        ],\n",
            "        [ 0.14808908, -0.04976252, -0.01820525, ...,  0.27303478,\n",
            "          0.1335582 ,  3.        ],\n",
            "        [ 0.13083622, -0.01323024, -0.00638919, ...,  0.36011523,\n",
            "          0.01915225,  3.        ],\n",
            "        ...,\n",
            "        [-0.09927853,  0.09942615,  0.2135229 , ...,  0.08773331,\n",
            "          0.00697557,  3.        ],\n",
            "        [-0.23315157,  0.08729264,  0.2991198 , ...,  0.06921618,\n",
            "         -0.02622155,  3.        ],\n",
            "        [-0.28994763,  0.08102592,  0.2889322 , ...,  0.05529799,\n",
            "         -0.01385292,  3.        ]], dtype=float32)\n",
            " array([[-2.52608117e-02, -1.39732614e-01, -2.83513665e-02, ...,\n",
            "          5.62291779e-02,  2.17208222e-01,  3.00000000e+00],\n",
            "        [ 1.55058622e-01, -4.87343632e-02, -1.16838086e-02, ...,\n",
            "          2.57707119e-01,  1.42620817e-01,  3.00000000e+00],\n",
            "        [ 1.40420556e-01,  3.44233704e-05,  1.03590442e-02, ...,\n",
            "          3.41899842e-01,  1.05419289e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.03711806e-01,  1.42297328e-01,  2.22408429e-01, ...,\n",
            "          6.32366538e-02, -1.17298739e-03,  3.00000000e+00],\n",
            "        [-2.49583676e-01,  1.24518409e-01,  3.08948666e-01, ...,\n",
            "          6.17308021e-02, -2.91057937e-02,  3.00000000e+00],\n",
            "        [-2.83431262e-01,  9.55256298e-02,  2.85085917e-01, ...,\n",
            "          6.35089278e-02, -1.96295767e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.16335561e-02, -1.23122990e-01, -2.84031928e-02, ...,\n",
            "          3.76658626e-02,  2.05369756e-01,  3.00000000e+00],\n",
            "        [ 1.24285221e-01, -3.01352162e-02,  2.55292072e-03, ...,\n",
            "          2.30961055e-01,  1.13111876e-01,  3.00000000e+00],\n",
            "        [ 1.19543687e-01,  3.05279717e-02,  2.09789407e-02, ...,\n",
            "          3.08500648e-01, -2.43309103e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-5.03611416e-02,  1.37391791e-01,  2.08017975e-01, ...,\n",
            "          4.84546162e-02,  1.72263514e-02,  3.00000000e+00],\n",
            "        [-2.36594900e-01,  1.37749106e-01,  3.43556136e-01, ...,\n",
            "          4.59029526e-02, -1.61564574e-02,  3.00000000e+00],\n",
            "        [-2.92756855e-01,  1.03559516e-01,  3.05527627e-01, ...,\n",
            "          3.95272262e-02, -4.73741861e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.00746779e-02, -1.17684513e-01, -3.39480191e-02, ...,\n",
            "          4.35776673e-02,  2.08902165e-01,  3.00000000e+00],\n",
            "        [ 1.54248804e-01, -1.14541929e-02, -1.32614700e-02, ...,\n",
            "          2.50301391e-01,  1.01454355e-01,  3.00000000e+00],\n",
            "        [ 1.63407519e-01,  5.89878559e-02, -2.46681483e-03, ...,\n",
            "          3.17951560e-01, -4.52255905e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.60583293e-02,  1.17503241e-01,  1.37326896e-01, ...,\n",
            "          4.95459437e-02,  4.30863723e-02,  3.00000000e+00],\n",
            "        [-1.91217020e-01,  1.23667903e-01,  3.24174643e-01, ...,\n",
            "          7.94674158e-02, -4.33198802e-05,  3.00000000e+00],\n",
            "        [-2.56009489e-01,  1.11170672e-01,  2.92050809e-01, ...,\n",
            "          5.59518784e-02,  8.17464478e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.8699107e-02, -1.2608169e-01, -2.7833357e-02, ...,\n",
            "          4.7079619e-02,  2.0544475e-01,  3.0000000e+00],\n",
            "        [ 1.3463299e-01, -5.3443074e-02, -1.7754082e-02, ...,\n",
            "          2.3905513e-01,  1.3422452e-01,  3.0000000e+00],\n",
            "        [ 1.1402842e-01, -2.2545673e-02,  1.2556590e-03, ...,\n",
            "          3.3100551e-01,  1.7095335e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.3377033e-01,  1.2383160e-01,  2.3966423e-01, ...,\n",
            "          6.8746954e-02,  1.1916382e-03,  3.0000000e+00],\n",
            "        [-2.6077124e-01,  1.1318078e-01,  3.1839755e-01, ...,\n",
            "          5.4679479e-02, -3.5781506e-02,  3.0000000e+00],\n",
            "        [-3.0484137e-01,  9.5075265e-02,  2.9406315e-01, ...,\n",
            "          3.8458936e-02, -1.7722458e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03625703, -0.15152033, -0.05083894, ...,  0.06614945,\n",
            "          0.2127518 ,  3.        ],\n",
            "        [ 0.16028257, -0.09833042, -0.06909859, ...,  0.30761543,\n",
            "          0.15788044,  3.        ],\n",
            "        [ 0.1118403 , -0.09633303, -0.06955121, ...,  0.4122246 ,\n",
            "          0.0693917 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.14645115,  0.01687439,  0.20551595, ...,  0.11712254,\n",
            "         -0.01035408,  3.        ],\n",
            "        [-0.24664377,  0.02867796,  0.21893524, ...,  0.08929678,\n",
            "         -0.04387379,  3.        ],\n",
            "        [-0.27051264,  0.03815155,  0.243725  , ...,  0.03774983,\n",
            "         -0.0182225 ,  3.        ]], dtype=float32)\n",
            " array([[-2.42132153e-02, -1.39642313e-01, -3.11008468e-02, ...,\n",
            "          5.62209412e-02,  2.16984048e-01,  3.00000000e+00],\n",
            "        [ 1.59434423e-01, -4.43637259e-02, -1.90418977e-02, ...,\n",
            "          2.71506518e-01,  1.37471557e-01,  3.00000000e+00],\n",
            "        [ 1.45331100e-01,  3.07905546e-04,  4.52463981e-03, ...,\n",
            "          3.56381804e-01,  9.00775567e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-8.43119621e-02,  1.17379807e-01,  2.09142536e-01, ...,\n",
            "          6.34668544e-02, -1.60290708e-03,  3.00000000e+00],\n",
            "        [-2.28016570e-01,  1.11911304e-01,  2.95490026e-01, ...,\n",
            "          6.50519505e-02, -2.98303608e-02,  3.00000000e+00],\n",
            "        [-2.78439790e-01,  9.01414528e-02,  2.82562345e-01, ...,\n",
            "          6.41142875e-02, -3.74458078e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.12675985e-02, -1.24909192e-01, -3.84846032e-02, ...,\n",
            "          5.31715974e-02,  2.14005351e-01,  3.00000000e+00],\n",
            "        [ 1.41953975e-01, -1.55514646e-02, -1.41628115e-02, ...,\n",
            "          2.52412558e-01,  1.15505196e-01,  3.00000000e+00],\n",
            "        [ 1.46465659e-01,  4.81731929e-02,  2.63184868e-03, ...,\n",
            "          3.26828927e-01, -3.12300678e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.77056175e-02,  1.34126782e-01,  1.71707749e-01, ...,\n",
            "          5.73997460e-02,  1.84016787e-02,  3.00000000e+00],\n",
            "        [-2.19611242e-01,  1.37988999e-01,  3.24407220e-01, ...,\n",
            "          7.07260519e-02, -1.61853060e-02,  3.00000000e+00],\n",
            "        [-2.77985305e-01,  1.02668174e-01,  2.98001021e-01, ...,\n",
            "          6.92316666e-02,  4.85879090e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.01934863, -0.13034862, -0.03575426, ...,  0.05209428,\n",
            "          0.21503146,  3.        ],\n",
            "        [ 0.14391403, -0.02873984, -0.01374783, ...,  0.2509328 ,\n",
            "          0.12600327,  3.        ],\n",
            "        [ 0.14199746,  0.03489854,  0.00759754, ...,  0.32708248,\n",
            "         -0.02100768,  3.        ],\n",
            "        ...,\n",
            "        [-0.04238029,  0.14638297,  0.1865297 , ...,  0.04836432,\n",
            "          0.01842791,  3.        ],\n",
            "        [-0.22173074,  0.14494006,  0.30756065, ...,  0.05781666,\n",
            "         -0.01414434,  3.        ],\n",
            "        [-0.27344733,  0.10474078,  0.2891405 , ...,  0.06715902,\n",
            "          0.00370719,  3.        ]], dtype=float32)\n",
            " array([[-0.03292932, -0.15919405, -0.05608523, ...,  0.06497405,\n",
            "          0.21252722,  3.        ],\n",
            "        [ 0.15203114, -0.10857985, -0.06966903, ...,  0.29757407,\n",
            "          0.15690675,  3.        ],\n",
            "        [ 0.10143917, -0.10272883, -0.07172598, ...,  0.39630947,\n",
            "          0.06538022,  3.        ],\n",
            "        ...,\n",
            "        [-0.15157343,  0.00793051,  0.19808795, ...,  0.09100258,\n",
            "         -0.02118216,  3.        ],\n",
            "        [-0.22687227,  0.03471028,  0.19753781, ...,  0.08034531,\n",
            "         -0.04743684,  3.        ],\n",
            "        [-0.25194904,  0.01472085,  0.22715855, ...,  0.04068865,\n",
            "         -0.02626838,  3.        ]], dtype=float32)\n",
            " array([[-0.02675763, -0.15940662, -0.0475746 , ...,  0.05704852,\n",
            "          0.21247658,  3.        ],\n",
            "        [ 0.15158136, -0.09928057, -0.07590517, ...,  0.28887418,\n",
            "          0.15006353,  3.        ],\n",
            "        [ 0.11003683, -0.09401229, -0.08337735, ...,  0.38189676,\n",
            "          0.05677528,  3.        ],\n",
            "        ...,\n",
            "        [-0.10812002,  0.01215437,  0.17887877, ...,  0.10612138,\n",
            "          0.0279573 ,  3.        ],\n",
            "        [-0.21014397,  0.01489135,  0.22709313, ...,  0.07900816,\n",
            "         -0.01591542,  3.        ],\n",
            "        [-0.26531795,  0.01462107,  0.24335569, ...,  0.04336945,\n",
            "         -0.02258555,  3.        ]], dtype=float32)\n",
            " array([[-0.01904949, -0.1544731 , -0.06369968, ...,  0.04887078,\n",
            "          0.17825001,  3.        ],\n",
            "        [ 0.1046309 , -0.13109083, -0.05556778, ...,  0.22939625,\n",
            "          0.14572155,  3.        ],\n",
            "        [ 0.03808829, -0.13363136, -0.07581625, ...,  0.32327995,\n",
            "          0.0924965 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.21367365,  0.04939011,  0.2325007 , ..., -0.04354977,\n",
            "         -0.09483258,  3.        ],\n",
            "        [-0.24768077,  0.0743373 ,  0.23562276, ..., -0.03171566,\n",
            "         -0.09209391,  3.        ],\n",
            "        [-0.20242648,  0.05641251,  0.24355353, ..., -0.04355041,\n",
            "         -0.06468046,  3.        ]], dtype=float32)\n",
            " array([[-0.03161503, -0.1262314 , -0.03102248, ...,  0.05784568,\n",
            "          0.20769872,  3.        ],\n",
            "        [ 0.14560153, -0.05722874, -0.03510547, ...,  0.2732268 ,\n",
            "          0.1401015 ,  3.        ],\n",
            "        [ 0.12547901, -0.02824308, -0.02640948, ...,  0.36789912,\n",
            "          0.02860104,  3.        ],\n",
            "        ...,\n",
            "        [-0.12239194,  0.0918585 ,  0.22699179, ...,  0.09466986,\n",
            "          0.00477882,  3.        ],\n",
            "        [-0.24911633,  0.07993858,  0.29570758, ...,  0.07301796,\n",
            "         -0.03034311,  3.        ],\n",
            "        [-0.29943252,  0.0809981 ,  0.28543973, ...,  0.04673995,\n",
            "         -0.01696096,  3.        ]], dtype=float32)\n",
            " array([[ 0.03085224, -0.13232635, -0.07475076, ...,  0.0094952 ,\n",
            "          0.17809486,  3.        ],\n",
            "        [ 0.22500956, -0.01832211, -0.06055803, ...,  0.1860754 ,\n",
            "          0.01203757,  3.        ],\n",
            "        [ 0.22699091,  0.02315541, -0.0530851 , ...,  0.24153762,\n",
            "         -0.10810972,  3.        ],\n",
            "        ...,\n",
            "        [ 0.12460442,  0.00364568, -0.03731531, ...,  0.04153555,\n",
            "          0.07323473,  3.        ],\n",
            "        [-0.08339435,  0.09276606,  0.26055112, ...,  0.10614704,\n",
            "         -0.02913628,  3.        ],\n",
            "        [-0.26109204,  0.06379906,  0.30330843, ...,  0.07428612,\n",
            "         -0.02109112,  3.        ]], dtype=float32)\n",
            " array([[-0.03368687, -0.14450713, -0.03668427, ...,  0.06231222,\n",
            "          0.21580045,  3.        ],\n",
            "        [ 0.1719187 , -0.06657369, -0.0442768 , ...,  0.28441137,\n",
            "          0.15184627,  3.        ],\n",
            "        [ 0.13253237, -0.04800586, -0.03935768, ...,  0.37168902,\n",
            "          0.05060734,  3.        ],\n",
            "        ...,\n",
            "        [-0.11190724,  0.07059671,  0.20149015, ...,  0.08676619,\n",
            "          0.01287691,  3.        ],\n",
            "        [-0.23995784,  0.07223263,  0.2573099 , ...,  0.07428747,\n",
            "         -0.03281214,  3.        ],\n",
            "        [-0.28251103,  0.06222625,  0.26107362, ...,  0.04945118,\n",
            "         -0.01716415,  3.        ]], dtype=float32)\n",
            " array([[-2.27952041e-02, -1.30235776e-01, -2.71862615e-02, ...,\n",
            "          4.34051007e-02,  2.08091095e-01,  3.00000000e+00],\n",
            "        [ 1.33645609e-01, -3.71719711e-02, -3.46434535e-03, ...,\n",
            "          2.52784342e-01,  1.24260485e-01,  3.00000000e+00],\n",
            "        [ 1.26732692e-01,  1.56267211e-02,  1.66850388e-02, ...,\n",
            "          3.32799673e-01, -4.54040663e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-8.64253491e-02,  1.34084418e-01,  2.27055416e-01, ...,\n",
            "          7.86311105e-02,  2.33059516e-03,  3.00000000e+00],\n",
            "        [-2.44025856e-01,  1.22918002e-01,  3.39691460e-01, ...,\n",
            "          6.44837096e-02, -2.71481276e-02,  3.00000000e+00],\n",
            "        [-2.94220299e-01,  9.55822393e-02,  3.01443785e-01, ...,\n",
            "          4.85988930e-02, -1.21112140e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.2827249e-02, -1.3163245e-01, -2.5024865e-02, ...,\n",
            "          4.4900890e-02,  2.0992507e-01,  3.0000000e+00],\n",
            "        [ 1.3657361e-01, -4.2841926e-02, -5.2257944e-03, ...,\n",
            "          2.5539574e-01,  1.3248616e-01,  3.0000000e+00],\n",
            "        [ 1.2524675e-01,  4.1192491e-03,  1.6684098e-02, ...,\n",
            "          3.3788893e-01,  7.8761857e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0420532e-01,  1.3221157e-01,  2.4399598e-01, ...,\n",
            "          7.9787567e-02, -6.2423392e-04,  3.0000000e+00],\n",
            "        [-2.5006592e-01,  1.2316789e-01,  3.3827144e-01, ...,\n",
            "          6.5228276e-02, -2.9375827e-02,  3.0000000e+00],\n",
            "        [-2.9921851e-01,  9.0741634e-02,  3.0064392e-01, ...,\n",
            "          5.1765807e-02, -1.4719901e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-1.7650733e-02, -1.2787610e-01, -2.6912784e-02, ...,\n",
            "          4.5297928e-02,  2.1065466e-01,  1.0000000e+00],\n",
            "        [ 1.4599180e-01, -3.4738574e-02, -6.1564118e-04, ...,\n",
            "          2.5832766e-01,  1.2184256e-01,  1.0000000e+00],\n",
            "        [ 1.4626083e-01,  2.1844923e-02,  1.3054026e-02, ...,\n",
            "          3.3289480e-01, -9.6567757e-03,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-4.4198457e-02,  1.2669332e-01,  2.1341521e-01, ...,\n",
            "          7.7863947e-02,  1.5560330e-02,  1.0000000e+00],\n",
            "        [-2.2788124e-01,  1.3059393e-01,  3.4087947e-01, ...,\n",
            "          7.4922368e-02, -1.6448209e-02,  1.0000000e+00],\n",
            "        [-2.7630380e-01,  1.0688209e-01,  2.9990616e-01, ...,\n",
            "          5.3462863e-02,  3.6642386e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.0163116 , -0.120873  , -0.03641046, ...,  0.03713342,\n",
            "          0.20421048,  2.        ],\n",
            "        [ 0.13372654, -0.01623204, -0.00949946, ...,  0.23867367,\n",
            "          0.0955365 ,  2.        ],\n",
            "        [ 0.1345786 ,  0.04884605,  0.00595469, ...,  0.31223464,\n",
            "         -0.04947124,  2.        ],\n",
            "        ...,\n",
            "        [ 0.00552623,  0.12535924,  0.14836705, ...,  0.04395315,\n",
            "          0.02594198,  2.        ],\n",
            "        [-0.20735005,  0.1232936 ,  0.3240161 , ...,  0.05834119,\n",
            "         -0.01395124,  2.        ],\n",
            "        [-0.27612188,  0.0934137 ,  0.29712898, ...,  0.04636434,\n",
            "         -0.00573417,  2.        ]], dtype=float32)\n",
            " array([[ 0.03618673, -0.13331738, -0.09003406, ...,  0.03854427,\n",
            "          0.20579757,  2.        ],\n",
            "        [ 0.23201267, -0.04563585, -0.0890477 , ...,  0.2308043 ,\n",
            "          0.04848106,  2.        ],\n",
            "        [ 0.2043234 , -0.00742076, -0.08249351, ...,  0.31133866,\n",
            "         -0.0919041 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.19874726, -0.00289035, -0.00209471, ...,  0.07165728,\n",
            "          0.04880456,  2.        ],\n",
            "        [-0.0360458 ,  0.05534249,  0.21469446, ...,  0.12128417,\n",
            "         -0.02035928,  2.        ],\n",
            "        [-0.22904208,  0.053097  ,  0.26775628, ...,  0.09553064,\n",
            "         -0.00752706,  2.        ]], dtype=float32)\n",
            " array([[-2.25603655e-02, -1.31659657e-01, -2.68965419e-02, ...,\n",
            "          4.30188440e-02,  2.08546668e-01,  2.00000000e+00],\n",
            "        [ 1.37783542e-01, -4.13436666e-02, -5.80612151e-03, ...,\n",
            "          2.49895319e-01,  1.28916427e-01,  2.00000000e+00],\n",
            "        [ 1.23899244e-01,  3.55131296e-03,  1.54362451e-02, ...,\n",
            "          3.32112253e-01,  4.86704893e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.07932590e-01,  1.31831393e-01,  2.31642917e-01, ...,\n",
            "          7.12711215e-02, -1.95370032e-03,  2.00000000e+00],\n",
            "        [-2.50750482e-01,  1.18463188e-01,  3.27359676e-01, ...,\n",
            "          5.70744760e-02, -3.09756342e-02,  2.00000000e+00],\n",
            "        [-2.96982616e-01,  9.24646035e-02,  2.96728492e-01, ...,\n",
            "          4.67781648e-02, -1.58749837e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.27658860e-02, -1.34133026e-01, -2.45213602e-02, ...,\n",
            "          4.57474589e-02,  2.09300503e-01,  2.00000000e+00],\n",
            "        [ 1.37202203e-01, -4.58938628e-02, -4.76385700e-03, ...,\n",
            "          2.57615566e-01,  1.31516501e-01,  2.00000000e+00],\n",
            "        [ 1.23884305e-01,  1.25867038e-04,  1.51059199e-02, ...,\n",
            "          3.41836095e-01,  1.09787676e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.06121831e-01,  1.27257034e-01,  2.39174575e-01, ...,\n",
            "          7.85214081e-02,  1.80380302e-03,  2.00000000e+00],\n",
            "        [-2.49770284e-01,  1.16616644e-01,  3.30259502e-01, ...,\n",
            "          6.53640777e-02, -2.94465609e-02,  2.00000000e+00],\n",
            "        [-2.97904253e-01,  8.91167521e-02,  2.98672229e-01, ...,\n",
            "          5.00046648e-02, -1.39569212e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02110778, -0.12878668, -0.03208622, ...,  0.04895047,\n",
            "          0.21603024,  2.        ],\n",
            "        [ 0.14056082, -0.03251731, -0.01055853, ...,  0.24278192,\n",
            "          0.12451281,  2.        ],\n",
            "        [ 0.13750648,  0.03166188,  0.00972135, ...,  0.3182082 ,\n",
            "         -0.02262949,  2.        ],\n",
            "        ...,\n",
            "        [-0.04813776,  0.14385866,  0.20104223, ...,  0.04682961,\n",
            "          0.01238929,  2.        ],\n",
            "        [-0.23327933,  0.13968042,  0.33070648, ...,  0.05602377,\n",
            "         -0.01758208,  2.        ],\n",
            "        [-0.27793068,  0.10590541,  0.29781303, ...,  0.06687072,\n",
            "          0.00456118,  2.        ]], dtype=float32)\n",
            " array([[-0.03237474, -0.12667489, -0.03101867, ...,  0.05458902,\n",
            "          0.20792747,  2.        ],\n",
            "        [ 0.14167142, -0.054529  , -0.03359394, ...,  0.26173216,\n",
            "          0.13964662,  2.        ],\n",
            "        [ 0.1199313 , -0.02709318, -0.02298842, ...,  0.35538226,\n",
            "          0.02612228,  2.        ],\n",
            "        ...,\n",
            "        [-0.13108963,  0.0942489 ,  0.2297157 , ...,  0.08399789,\n",
            "          0.00548005,  2.        ],\n",
            "        [-0.25405797,  0.08298113,  0.29714313, ...,  0.06414315,\n",
            "         -0.03265071,  2.        ],\n",
            "        [-0.3023427 ,  0.08113781,  0.28609776, ...,  0.04216471,\n",
            "         -0.01902958,  2.        ]], dtype=float32)\n",
            " array([[-1.9021211e-02, -1.2923376e-01, -2.7758436e-02, ...,\n",
            "          3.7908509e-02,  2.0823276e-01,  2.0000000e+00],\n",
            "        [ 1.3137007e-01, -2.6107261e-02, -3.2612131e-04, ...,\n",
            "          2.4896051e-01,  1.1185056e-01,  2.0000000e+00],\n",
            "        [ 1.3286164e-01,  3.9283082e-02,  2.0127535e-02, ...,\n",
            "          3.2355437e-01, -2.1107072e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-2.6037592e-02,  1.2898578e-01,  1.8876943e-01, ...,\n",
            "          6.1093256e-02,  2.5849866e-02,  2.0000000e+00],\n",
            "        [-2.2116481e-01,  1.2435863e-01,  3.3564767e-01, ...,\n",
            "          6.0196634e-02, -1.1307572e-02,  2.0000000e+00],\n",
            "        [-2.8065720e-01,  9.7209774e-02,  3.0026135e-01, ...,\n",
            "          5.0230898e-02, -7.4003427e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01709747, -0.12321088, -0.03531668, ...,  0.05020972,\n",
            "          0.2166379 ,  2.        ],\n",
            "        [ 0.14157511, -0.03226892, -0.01321817, ...,  0.24065152,\n",
            "          0.127208  ,  2.        ],\n",
            "        [ 0.13503394,  0.03365349,  0.01062424, ...,  0.3174746 ,\n",
            "         -0.02553911,  2.        ],\n",
            "        ...,\n",
            "        [-0.02960104,  0.14540261,  0.18799663, ...,  0.04518314,\n",
            "          0.02973875,  2.        ],\n",
            "        [-0.21977462,  0.14279357,  0.32258222, ...,  0.06029118,\n",
            "         -0.00621358,  2.        ],\n",
            "        [-0.27169028,  0.110273  ,  0.29398516, ...,  0.06938094,\n",
            "          0.00703427,  2.        ]], dtype=float32)\n",
            " array([[ 0.02896943, -0.12500235, -0.08587939, ...,  0.0250567 ,\n",
            "          0.20242688,  2.        ],\n",
            "        [ 0.21744224, -0.01447252, -0.07496443, ...,  0.2076353 ,\n",
            "          0.05325966,  2.        ],\n",
            "        [ 0.20755492,  0.02168025, -0.07093003, ...,  0.2858959 ,\n",
            "         -0.08817372,  2.        ],\n",
            "        ...,\n",
            "        [ 0.15810056,  0.01058365, -0.0391488 , ...,  0.04508584,\n",
            "          0.06877274,  2.        ],\n",
            "        [-0.07502406,  0.09102655,  0.23551469, ...,  0.09650861,\n",
            "         -0.01643426,  2.        ],\n",
            "        [-0.2501294 ,  0.07398054,  0.2822261 , ...,  0.08212439,\n",
            "         -0.00659996,  2.        ]], dtype=float32)\n",
            " array([[-0.01893533, -0.12321585, -0.03163066, ...,  0.03864685,\n",
            "          0.20698449,  2.        ],\n",
            "        [ 0.13077922, -0.02381088, -0.0054551 , ...,  0.24256335,\n",
            "          0.11008137,  2.        ],\n",
            "        [ 0.12834637,  0.04028173,  0.01314178, ...,  0.31824934,\n",
            "         -0.03053631,  2.        ],\n",
            "        ...,\n",
            "        [-0.02259835,  0.12990756,  0.18336596, ...,  0.05379957,\n",
            "          0.01936286,  2.        ],\n",
            "        [-0.2243165 ,  0.12508507,  0.3377074 , ...,  0.05689589,\n",
            "         -0.0147417 ,  2.        ],\n",
            "        [-0.28356284,  0.09453934,  0.30172464, ...,  0.04601872,\n",
            "         -0.00507573,  2.        ]], dtype=float32)\n",
            " array([[ 0.01316554, -0.12497742, -0.06388889, ...,  0.05864139,\n",
            "          0.2123518 ,  2.        ],\n",
            "        [ 0.19927303, -0.05211253, -0.07444704, ...,  0.23638028,\n",
            "          0.06475019,  2.        ],\n",
            "        [ 0.16620086, -0.01765813, -0.06638783, ...,  0.33006808,\n",
            "         -0.0789287 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.15727632,  0.03523066,  0.07013406, ...,  0.05462203,\n",
            "          0.01068464,  2.        ],\n",
            "        [-0.07504775,  0.07662337,  0.26285452, ...,  0.09818465,\n",
            "         -0.04310559,  2.        ],\n",
            "        [-0.22653584,  0.07441754,  0.2791244 , ...,  0.08516076,\n",
            "         -0.00552511,  2.        ]], dtype=float32)\n",
            " array([[-1.13181779e-02, -1.18677855e-01, -4.02372926e-02, ...,\n",
            "          5.34548685e-02,  2.19679877e-01,  2.00000000e+00],\n",
            "        [ 1.31097808e-01, -3.07193771e-02, -1.40107116e-02, ...,\n",
            "          2.11089954e-01,  1.35365739e-01,  2.00000000e+00],\n",
            "        [ 1.18369944e-01,  3.02461740e-02,  3.56259709e-03, ...,\n",
            "          2.96847761e-01, -2.88651288e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-2.87482347e-02,  1.61326736e-01,  1.85302719e-01, ...,\n",
            "          2.96225194e-02,  3.33471373e-02,  2.00000000e+00],\n",
            "        [-2.17122212e-01,  1.54885143e-01,  3.26846272e-01, ...,\n",
            "          5.16045950e-02,  1.27559516e-03,  2.00000000e+00],\n",
            "        [-2.66416728e-01,  1.07714310e-01,  2.96875477e-01, ...,\n",
            "          7.02023134e-02,  4.89980541e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01271082, -0.12156627, -0.0310789 , ...,  0.04379483,\n",
            "          0.20889315,  2.        ],\n",
            "        [ 0.15441768, -0.02103423, -0.009148  , ...,  0.2594796 ,\n",
            "          0.11218333,  2.        ],\n",
            "        [ 0.15891449,  0.04656251,  0.00464775, ...,  0.3298042 ,\n",
            "         -0.03256104,  2.        ],\n",
            "        ...,\n",
            "        [ 0.00729821,  0.12420505,  0.16605292, ...,  0.0684146 ,\n",
            "          0.03360057,  2.        ],\n",
            "        [-0.20208971,  0.12771018,  0.3278173 , ...,  0.07769917,\n",
            "         -0.00380297,  2.        ],\n",
            "        [-0.2620186 ,  0.10963   ,  0.29451087, ...,  0.05639404,\n",
            "          0.00656078,  2.        ]], dtype=float32)\n",
            " array([[-0.03322762, -0.13662688, -0.03760391, ...,  0.05783623,\n",
            "          0.21104024,  2.        ],\n",
            "        [ 0.14550538, -0.06808735, -0.05585315, ...,  0.2839864 ,\n",
            "          0.14449778,  2.        ],\n",
            "        [ 0.1158264 , -0.0514258 , -0.05867286, ...,  0.37618715,\n",
            "          0.0388146 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.12475187,  0.05448135,  0.20639586, ...,  0.10376165,\n",
            "          0.015029  ,  2.        ],\n",
            "        [-0.24123886,  0.05361287,  0.26819834, ...,  0.07924215,\n",
            "         -0.02966674,  2.        ],\n",
            "        [-0.29359153,  0.05848968,  0.27114657, ...,  0.04450746,\n",
            "         -0.01799116,  2.        ]], dtype=float32)\n",
            " array([[-0.02995788, -0.1512596 , -0.03716065, ...,  0.06100526,\n",
            "          0.21277727,  2.        ],\n",
            "        [ 0.17793585, -0.08073269, -0.04902349, ...,  0.28668946,\n",
            "          0.15203112,  2.        ],\n",
            "        [ 0.13628407, -0.06301911, -0.04315894, ...,  0.37961015,\n",
            "          0.0520674 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.11425708,  0.05277742,  0.20062523, ...,  0.09602853,\n",
            "          0.01049791,  2.        ],\n",
            "        [-0.23288526,  0.05345034,  0.25197083, ...,  0.07943644,\n",
            "         -0.03516779,  2.        ],\n",
            "        [-0.27584946,  0.05680097,  0.2587431 , ...,  0.04725881,\n",
            "         -0.01593215,  2.        ]], dtype=float32)\n",
            " array([[-1.9413531e-02, -1.4072677e-01, -3.5082396e-02, ...,\n",
            "          5.9848044e-02,  2.1916296e-01,  2.0000000e+00],\n",
            "        [ 1.5785328e-01, -4.3787200e-02, -1.6448192e-02, ...,\n",
            "          2.6331231e-01,  1.4113355e-01,  2.0000000e+00],\n",
            "        [ 1.5154551e-01,  1.1738909e-03,  6.7312238e-03, ...,\n",
            "          3.4524211e-01,  6.0516135e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-5.0785292e-02,  1.3751391e-01,  1.8168916e-01, ...,\n",
            "          4.9754400e-02,  1.8640816e-02,  2.0000000e+00],\n",
            "        [-2.1172805e-01,  1.2432895e-01,  2.8826836e-01, ...,\n",
            "          5.7693731e-02, -1.6036324e-02,  2.0000000e+00],\n",
            "        [-2.6769114e-01,  1.0080070e-01,  2.7464548e-01, ...,\n",
            "          7.1708247e-02,  1.0295863e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02060344, -0.13269417, -0.02865467, ...,  0.04396624,\n",
            "          0.2095229 ,  2.        ],\n",
            "        [ 0.1411847 , -0.0410035 , -0.00639481, ...,  0.2558081 ,\n",
            "          0.12755622,  2.        ],\n",
            "        [ 0.13540816,  0.00972812,  0.01339244, ...,  0.33674714,\n",
            "         -0.00285519,  2.        ],\n",
            "        ...,\n",
            "        [-0.07806261,  0.12977038,  0.22334108, ...,  0.08348747,\n",
            "          0.00352092,  2.        ],\n",
            "        [-0.24118596,  0.12237612,  0.33461556, ...,  0.06968496,\n",
            "         -0.02519758,  2.        ],\n",
            "        [-0.28950784,  0.09381961,  0.2960283 , ...,  0.05430537,\n",
            "         -0.01012367,  2.        ]], dtype=float32)\n",
            " array([[-3.4145094e-03, -1.2167451e-01, -4.7680233e-02, ...,\n",
            "          6.0639251e-02,  2.1816355e-01,  2.0000000e+00],\n",
            "        [ 1.5121377e-01, -2.3072910e-02, -2.3101661e-02, ...,\n",
            "          2.3383975e-01,  1.2365659e-01,  2.0000000e+00],\n",
            "        [ 1.4249232e-01,  3.9091751e-02, -7.7622682e-03, ...,\n",
            "          3.1642833e-01, -3.7366200e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 3.3381330e-03,  1.5159859e-01,  1.5183248e-01, ...,\n",
            "          4.5813721e-02,  3.2057762e-02,  2.0000000e+00],\n",
            "        [-1.9351174e-01,  1.4528498e-01,  3.0570859e-01, ...,\n",
            "          6.9020562e-02, -7.8032208e-03,  2.0000000e+00],\n",
            "        [-2.5202301e-01,  1.0122797e-01,  2.8371859e-01, ...,\n",
            "          7.6615117e-02,  1.3153922e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01689079, -0.13055812, -0.02648594, ...,  0.04628431,\n",
            "          0.21164498,  1.        ],\n",
            "        [ 0.14870636, -0.03934436, -0.00264476, ...,  0.26376608,\n",
            "          0.12621132,  1.        ],\n",
            "        [ 0.147545  ,  0.01518007,  0.01099353, ...,  0.34310046,\n",
            "         -0.0021672 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.06603411,  0.12515259,  0.22747234, ...,  0.08866294,\n",
            "          0.01038133,  1.        ],\n",
            "        [-0.23352712,  0.1250636 ,  0.33718243, ...,  0.08122372,\n",
            "         -0.0204341 ,  1.        ],\n",
            "        [-0.27883548,  0.10305358,  0.2974715 , ...,  0.05843033,\n",
            "          0.00146889,  1.        ]], dtype=float32)\n",
            " array([[-5.21307345e-03, -1.10098734e-01, -4.56507616e-02, ...,\n",
            "          4.03970741e-02,  2.04835892e-01,  0.00000000e+00],\n",
            "        [ 1.64797828e-01, -5.83928637e-03, -3.32686678e-02, ...,\n",
            "          2.53112048e-01,  7.06502944e-02,  0.00000000e+00],\n",
            "        [ 1.76939145e-01,  5.87203950e-02, -2.81351246e-02, ...,\n",
            "          3.12870622e-01, -7.06075281e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 8.20564851e-02,  8.81267264e-02,  5.35647012e-02, ...,\n",
            "          5.02421819e-02,  6.45162687e-02,  0.00000000e+00],\n",
            "        [-1.52295992e-01,  1.24163456e-01,  3.06767970e-01, ...,\n",
            "          1.03379861e-01, -1.09056782e-04,  0.00000000e+00],\n",
            "        [-2.50943005e-01,  1.04804918e-01,  2.92224020e-01, ...,\n",
            "          6.69917017e-02,  7.42367050e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.0165593 , -0.12993333, -0.02748554, ...,  0.04689191,\n",
            "          0.2114909 ,  2.        ],\n",
            "        [ 0.15160744, -0.03532492, -0.00497742, ...,  0.27008113,\n",
            "          0.12422502,  2.        ],\n",
            "        [ 0.15239275,  0.02252328,  0.00890682, ...,  0.34805092,\n",
            "         -0.00538094,  2.        ],\n",
            "        ...,\n",
            "        [-0.04556847,  0.11979751,  0.20983373, ...,  0.0913634 ,\n",
            "          0.01795984,  2.        ],\n",
            "        [-0.22480734,  0.12363733,  0.33103034, ...,  0.08389971,\n",
            "         -0.01491796,  2.        ],\n",
            "        [-0.2750353 ,  0.10239039,  0.29548004, ...,  0.06084546,\n",
            "          0.00305242,  2.        ]], dtype=float32)\n",
            " array([[-0.02785093, -0.13047689, -0.03140447, ...,  0.06253967,\n",
            "          0.21095368,  1.        ],\n",
            "        [ 0.16767001, -0.05115669, -0.02559949, ...,  0.28101107,\n",
            "          0.14118844,  1.        ],\n",
            "        [ 0.14788005, -0.01268458, -0.00435756, ...,  0.37595758,\n",
            "          0.01613838,  1.        ],\n",
            "        ...,\n",
            "        [-0.11834661,  0.11235137,  0.23219799, ...,  0.08921637,\n",
            "         -0.01007378,  1.        ],\n",
            "        [-0.24534364,  0.10157084,  0.2894478 , ...,  0.0798998 ,\n",
            "         -0.03517734,  1.        ],\n",
            "        [-0.28517613,  0.09082858,  0.27841   , ...,  0.06058622,\n",
            "         -0.00928741,  1.        ]], dtype=float32)\n",
            " array([[-0.03369351, -0.12997185, -0.03193486, ...,  0.06614373,\n",
            "          0.21209721,  1.        ],\n",
            "        [ 0.16423677, -0.05057324, -0.03024264, ...,  0.27483174,\n",
            "          0.14303657,  1.        ],\n",
            "        [ 0.13742463, -0.01939011, -0.0096274 , ...,  0.36681104,\n",
            "          0.032707  ,  1.        ],\n",
            "        ...,\n",
            "        [-0.14253527,  0.10846308,  0.24675296, ...,  0.07867935,\n",
            "         -0.01596371,  1.        ],\n",
            "        [-0.25802657,  0.09334178,  0.2913377 , ...,  0.07306611,\n",
            "         -0.04012088,  1.        ],\n",
            "        [-0.286614  ,  0.08862281,  0.27768475, ...,  0.05144254,\n",
            "         -0.01044509,  1.        ]], dtype=float32)\n",
            " array([[-0.03425734, -0.1550526 , -0.05182698, ...,  0.06683262,\n",
            "          0.2111723 ,  1.        ],\n",
            "        [ 0.16351433, -0.10831609, -0.06094582, ...,  0.30584767,\n",
            "          0.16566141,  1.        ],\n",
            "        [ 0.10888485, -0.10118258, -0.06026407, ...,  0.41152522,\n",
            "          0.07650483,  1.        ],\n",
            "        ...,\n",
            "        [-0.1695212 ,  0.03253163,  0.20910366, ...,  0.10721986,\n",
            "         -0.01974117,  1.        ],\n",
            "        [-0.25126046,  0.05331756,  0.2123532 , ...,  0.0891807 ,\n",
            "         -0.05014442,  1.        ],\n",
            "        [-0.2629712 ,  0.03390362,  0.23757066, ...,  0.03634107,\n",
            "         -0.02489718,  1.        ]], dtype=float32)\n",
            " array([[-0.02919985, -0.15321347, -0.05857433, ...,  0.05332206,\n",
            "          0.188496  ,  1.        ],\n",
            "        [ 0.09906989, -0.12728615, -0.06258538, ...,  0.2390439 ,\n",
            "          0.14539786,  1.        ],\n",
            "        [ 0.03125427, -0.12708643, -0.0772137 , ...,  0.33586988,\n",
            "          0.08444639,  1.        ],\n",
            "        ...,\n",
            "        [-0.23863687,  0.0591001 ,  0.21851812, ..., -0.00566128,\n",
            "         -0.08775006,  1.        ],\n",
            "        [-0.26985607,  0.07518084,  0.22466342, ...,  0.00176017,\n",
            "         -0.08128721,  1.        ],\n",
            "        [-0.2310284 ,  0.0389572 ,  0.24504519, ..., -0.01892592,\n",
            "         -0.05549843,  1.        ]], dtype=float32)\n",
            " array([[-0.03311662, -0.15671016, -0.05303816, ...,  0.06779441,\n",
            "          0.21191941,  1.        ],\n",
            "        [ 0.17174272, -0.10658637, -0.06286813, ...,  0.3148384 ,\n",
            "          0.16502215,  1.        ],\n",
            "        [ 0.11591683, -0.10169826, -0.06181872, ...,  0.42241487,\n",
            "          0.07927448,  1.        ],\n",
            "        ...,\n",
            "        [-0.15702184,  0.01674745,  0.20008567, ...,  0.10623779,\n",
            "         -0.02432294,  1.        ],\n",
            "        [-0.23228037,  0.03978052,  0.20111103, ...,  0.08787309,\n",
            "         -0.04766469,  1.        ],\n",
            "        [-0.25338995,  0.02436798,  0.23063289, ...,  0.03592379,\n",
            "         -0.02175262,  1.        ]], dtype=float32)\n",
            " array([[-0.02742982, -0.12977888, -0.0244744 , ...,  0.04163108,\n",
            "          0.20780471,  1.        ],\n",
            "        [ 0.12351288, -0.05055071, -0.00315868, ...,  0.23773757,\n",
            "          0.13278636,  1.        ],\n",
            "        [ 0.1069781 , -0.00969852,  0.0175971 , ...,  0.32142165,\n",
            "          0.01204104,  1.        ],\n",
            "        ...,\n",
            "        [-0.14126813,  0.13638589,  0.26333442, ...,  0.06639637,\n",
            "         -0.00381441,  1.        ],\n",
            "        [-0.26456526,  0.12559687,  0.3408127 , ...,  0.05306748,\n",
            "         -0.03718717,  1.        ],\n",
            "        [-0.3062458 ,  0.09234308,  0.30448806, ...,  0.03947905,\n",
            "         -0.01970178,  1.        ]], dtype=float32)\n",
            " array([[-0.02985744, -0.1538935 , -0.04480312, ...,  0.05190295,\n",
            "          0.21122557,  1.        ],\n",
            "        [ 0.14621778, -0.09360787, -0.06656948, ...,  0.27801776,\n",
            "          0.14917453,  1.        ],\n",
            "        [ 0.1049056 , -0.08455042, -0.07468644, ...,  0.36891428,\n",
            "          0.05268739,  1.        ],\n",
            "        ...,\n",
            "        [-0.12115301,  0.02112741,  0.18954204, ...,  0.10178988,\n",
            "          0.0291271 ,  1.        ],\n",
            "        [-0.22233778,  0.01956934,  0.24529985, ...,  0.07509661,\n",
            "         -0.0181682 ,  1.        ],\n",
            "        [-0.27716166,  0.02495602,  0.2560341 , ...,  0.03523659,\n",
            "         -0.01919959,  1.        ]], dtype=float32)\n",
            " array([[-0.03356726, -0.14359558, -0.03829879, ...,  0.05268684,\n",
            "          0.213615  ,  1.        ],\n",
            "        [ 0.14435694, -0.08055844, -0.05514506, ...,  0.27113858,\n",
            "          0.15781954,  1.        ],\n",
            "        [ 0.10188622, -0.0693067 , -0.05730677, ...,  0.36592323,\n",
            "          0.0634212 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.14731349,  0.05432905,  0.22179101, ...,  0.09881724,\n",
            "          0.02273854,  1.        ],\n",
            "        [-0.25481376,  0.04870837,  0.27650297, ...,  0.07563756,\n",
            "         -0.02956372,  1.        ],\n",
            "        [-0.30164728,  0.04804948,  0.27744576, ...,  0.03220261,\n",
            "         -0.02013901,  1.        ]], dtype=float32)\n",
            " array([[-0.02307515, -0.12807971, -0.0283715 , ...,  0.0538373 ,\n",
            "          0.21671395,  1.        ],\n",
            "        [ 0.14557791, -0.03862249, -0.0062051 , ...,  0.25744757,\n",
            "          0.13316375,  1.        ],\n",
            "        [ 0.14228643,  0.01945553,  0.01414398, ...,  0.335906  ,\n",
            "         -0.00715526,  1.        ],\n",
            "        ...,\n",
            "        [-0.0870638 ,  0.14182016,  0.23894213, ...,  0.06548604,\n",
            "          0.00213928,  1.        ],\n",
            "        [-0.24396263,  0.13633564,  0.33480215, ...,  0.06265268,\n",
            "         -0.02561638,  1.        ],\n",
            "        [-0.28476977,  0.10351855,  0.2991355 , ...,  0.06343844,\n",
            "          0.00282451,  1.        ]], dtype=float32)\n",
            " array([[-0.01944209, -0.11911654, -0.03249545, ...,  0.04748818,\n",
            "          0.2147467 ,  1.        ],\n",
            "        [ 0.12862176, -0.02906787, -0.00810636, ...,  0.23290479,\n",
            "          0.12244047,  1.        ],\n",
            "        [ 0.13086896,  0.03608425,  0.01409116, ...,  0.30596095,\n",
            "         -0.02737612,  1.        ],\n",
            "        ...,\n",
            "        [-0.05426065,  0.13854226,  0.21372505, ...,  0.04396769,\n",
            "          0.01462879,  1.        ],\n",
            "        [-0.2345111 ,  0.13718335,  0.34628963, ...,  0.05221232,\n",
            "         -0.00880241,  1.        ],\n",
            "        [-0.28080666,  0.10467912,  0.30783105, ...,  0.05626001,\n",
            "          0.01004902,  1.        ]], dtype=float32)\n",
            " array([[-2.66961046e-02, -1.65405691e-01, -5.11311293e-02, ...,\n",
            "          5.76186478e-02,  2.11493552e-01,  1.00000000e+00],\n",
            "        [ 1.43816605e-01, -1.13640763e-01, -7.62761086e-02, ...,\n",
            "          2.90333390e-01,  1.52532637e-01,  1.00000000e+00],\n",
            "        [ 9.77578014e-02, -1.10110804e-01, -8.57281312e-02, ...,\n",
            "          3.80917996e-01,  6.63004592e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.13879450e-01,  2.29654764e-03,  1.82448551e-01, ...,\n",
            "          1.07552633e-01,  1.75555795e-02,  1.00000000e+00],\n",
            "        [-2.04398617e-01,  4.81802598e-03,  2.15980396e-01, ...,\n",
            "          7.99287260e-02, -2.18128543e-02,  1.00000000e+00],\n",
            "        [-2.56302208e-01, -3.13288154e-04,  2.37274155e-01, ...,\n",
            "          3.94131914e-02, -2.38836147e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.01905062, -0.13826454, -0.0306271 , ...,  0.05413401,\n",
            "          0.2136279 ,  1.        ],\n",
            "        [ 0.15917967, -0.05160293, -0.02036033, ...,  0.28668895,\n",
            "          0.13608642,  1.        ],\n",
            "        [ 0.146336  , -0.01627452, -0.01490327, ...,  0.3738004 ,\n",
            "          0.0250689 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.09062319,  0.10034191,  0.21263523, ...,  0.10297871,\n",
            "          0.00572071,  1.        ],\n",
            "        [-0.22744338,  0.09450189,  0.29365632, ...,  0.0870024 ,\n",
            "         -0.02379191,  1.        ],\n",
            "        [-0.27771726,  0.08880963,  0.2813746 , ...,  0.06199351,\n",
            "         -0.00327096,  1.        ]], dtype=float32)\n",
            " array([[-1.65232625e-02, -1.32216305e-01, -2.73948107e-02, ...,\n",
            "          4.79815900e-02,  2.11172223e-01,  1.00000000e+00],\n",
            "        [ 1.53474867e-01, -3.99287529e-02, -4.41118563e-03, ...,\n",
            "          2.71434069e-01,  1.27386615e-01,  1.00000000e+00],\n",
            "        [ 1.51784852e-01,  1.17389141e-02,  8.49295128e-03, ...,\n",
            "          3.50862652e-01,  2.53528869e-03,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-6.76500201e-02,  1.23567402e-01,  2.23214284e-01, ...,\n",
            "          9.49734598e-02,  8.30406789e-03,  1.00000000e+00],\n",
            "        [-2.29891270e-01,  1.22572571e-01,  3.29089195e-01, ...,\n",
            "          8.31373110e-02, -2.26782560e-02,  1.00000000e+00],\n",
            "        [-2.76870728e-01,  1.01969056e-01,  2.94929504e-01, ...,\n",
            "          5.93762733e-02, -8.48595009e-05,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.0349558 , -0.13994732, -0.03701025, ...,  0.056892  ,\n",
            "          0.21296811,  1.        ],\n",
            "        [ 0.15240969, -0.06549003, -0.04085524, ...,  0.26745206,\n",
            "          0.14803913,  1.        ],\n",
            "        [ 0.1202508 , -0.04404005, -0.03248837, ...,  0.3541755 ,\n",
            "          0.04017897,  1.        ],\n",
            "        ...,\n",
            "        [-0.13977066,  0.07594635,  0.22811751, ...,  0.08043326,\n",
            "          0.00750606,  1.        ],\n",
            "        [-0.25786415,  0.06441204,  0.2804307 , ...,  0.06611612,\n",
            "         -0.03683887,  1.        ],\n",
            "        [-0.29200298,  0.07144496,  0.2743815 , ...,  0.04269158,\n",
            "         -0.01370497,  1.        ]], dtype=float32)\n",
            " array([[-3.3328377e-02, -1.5625581e-01, -5.9977535e-02, ...,\n",
            "          5.7159089e-02,  1.9439226e-01,  1.0000000e+00],\n",
            "        [ 1.0895038e-01, -1.2956758e-01, -6.8534620e-02, ...,\n",
            "          2.5934067e-01,  1.4804503e-01,  1.0000000e+00],\n",
            "        [ 4.3155748e-02, -1.2529996e-01, -7.9347402e-02, ...,\n",
            "          3.5849354e-01,  7.8262836e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-2.2391993e-01,  4.4601303e-02,  1.9500031e-01, ...,\n",
            "          3.5660520e-02, -7.9434812e-02,  1.0000000e+00],\n",
            "        [-2.6788437e-01,  6.4106911e-02,  2.0859616e-01, ...,\n",
            "          4.1395575e-02, -7.9674847e-02,  1.0000000e+00],\n",
            "        [-2.4928942e-01,  2.5005130e-02,  2.3824285e-01, ...,\n",
            "          9.5190881e-05, -5.0960965e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.00950694, -0.12748598, -0.0427044 , ...,  0.05597021,\n",
            "          0.21690679,  1.        ],\n",
            "        [ 0.152788  , -0.02275597, -0.01981901, ...,  0.24877718,\n",
            "          0.1197883 ,  1.        ],\n",
            "        [ 0.1564152 ,  0.04385666, -0.00735243, ...,  0.32623222,\n",
            "         -0.0351724 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.01054921,  0.1456196 ,  0.16743936, ...,  0.05145525,\n",
            "          0.01987988,  1.        ],\n",
            "        [-0.19856839,  0.14938611,  0.30889714, ...,  0.06384915,\n",
            "         -0.01215676,  1.        ],\n",
            "        [-0.26005787,  0.10809923,  0.2896407 , ...,  0.07289027,\n",
            "          0.00488184,  1.        ]], dtype=float32)\n",
            " array([[-0.03461648, -0.15468098, -0.05850868, ...,  0.061679  ,\n",
            "          0.20431195,  1.        ],\n",
            "        [ 0.12478136, -0.12000906, -0.07034819, ...,  0.278869  ,\n",
            "          0.1564056 ,  1.        ],\n",
            "        [ 0.06122292, -0.11649093, -0.0757074 , ...,  0.38417935,\n",
            "          0.08149802,  1.        ],\n",
            "        ...,\n",
            "        [-0.20912036,  0.03833066,  0.19805667, ...,  0.08979018,\n",
            "         -0.06073476,  1.        ],\n",
            "        [-0.26513463,  0.05177025,  0.19934645, ...,  0.07620249,\n",
            "         -0.07828113,  1.        ],\n",
            "        [-0.2651734 ,  0.02040601,  0.23486745, ...,  0.02140173,\n",
            "         -0.04558249,  1.        ]], dtype=float32)\n",
            " array([[-0.03135217, -0.15538514, -0.04787717, ...,  0.06286512,\n",
            "          0.21421197,  1.        ],\n",
            "        [ 0.17138708, -0.09281985, -0.06037733, ...,  0.2918374 ,\n",
            "          0.16021536,  1.        ],\n",
            "        [ 0.12310872, -0.09025231, -0.05826582, ...,  0.39270452,\n",
            "          0.0658422 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.14222066,  0.01745741,  0.20957784, ...,  0.09026897,\n",
            "         -0.00947594,  1.        ],\n",
            "        [-0.23508148,  0.03487102,  0.22233568, ...,  0.07778122,\n",
            "         -0.04125847,  1.        ],\n",
            "        [-0.2623621 ,  0.03361533,  0.24334785, ...,  0.03958853,\n",
            "         -0.01768341,  1.        ]], dtype=float32)\n",
            " array([[-0.01461086, -0.12219807, -0.04546318, ...,  0.05200389,\n",
            "          0.21176495,  1.        ],\n",
            "        [ 0.15175961, -0.00200064, -0.02232659, ...,  0.25010663,\n",
            "          0.10411764,  1.        ],\n",
            "        [ 0.16088912,  0.05809002, -0.00909252, ...,  0.3219822 ,\n",
            "         -0.04854963,  1.        ],\n",
            "        ...,\n",
            "        [ 0.01361189,  0.13290101,  0.13702403, ...,  0.05117431,\n",
            "          0.01059952,  1.        ],\n",
            "        [-0.19386445,  0.13947088,  0.30587804, ...,  0.06807405,\n",
            "         -0.01747612,  1.        ],\n",
            "        [-0.2591867 ,  0.10696064,  0.28773028, ...,  0.07110409,\n",
            "          0.00962614,  1.        ]], dtype=float32)\n",
            " array([[-2.1026121e-02, -1.3103032e-01, -2.8166601e-02, ...,\n",
            "          5.0616976e-02,  2.1747720e-01,  1.0000000e+00],\n",
            "        [ 1.4528707e-01, -4.0043242e-02, -9.2391996e-03, ...,\n",
            "          2.5472960e-01,  1.3721049e-01,  1.0000000e+00],\n",
            "        [ 1.3975371e-01,  1.2278179e-02,  1.6939554e-02, ...,\n",
            "          3.3400062e-01, -2.6381145e-05,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-7.6459855e-02,  1.3615617e-01,  2.2697221e-01, ...,\n",
            "          6.3196704e-02,  3.0260698e-03,  1.0000000e+00],\n",
            "        [-2.3608245e-01,  1.3349456e-01,  3.2722998e-01, ...,\n",
            "          6.2307507e-02, -2.5806053e-02,  1.0000000e+00],\n",
            "        [-2.8561041e-01,  9.8338380e-02,  2.9817167e-01, ...,\n",
            "          6.0455471e-02, -3.0897681e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.03590215, -0.15209131, -0.04616095, ...,  0.05551583,\n",
            "          0.21343012,  1.        ],\n",
            "        [ 0.14442067, -0.09469505, -0.06962399, ...,  0.29052433,\n",
            "          0.15638843,  1.        ],\n",
            "        [ 0.10103837, -0.09826997, -0.07563081, ...,  0.3786867 ,\n",
            "          0.08274521,  1.        ],\n",
            "        ...,\n",
            "        [-0.15384841,  0.02278051,  0.21277197, ...,  0.10364793,\n",
            "          0.0071427 ,  1.        ],\n",
            "        [-0.24387975,  0.02073051,  0.24173568, ...,  0.08095131,\n",
            "         -0.03246641,  1.        ],\n",
            "        [-0.28597152,  0.02196159,  0.25743264, ...,  0.03394723,\n",
            "         -0.02410006,  1.        ]], dtype=float32)\n",
            " array([[-3.33852135e-03, -1.15778483e-01, -4.74837609e-02, ...,\n",
            "          4.45071608e-02,  2.14429632e-01,  1.00000000e+00],\n",
            "        [ 1.44624740e-01, -1.42310765e-02, -2.58588158e-02, ...,\n",
            "          2.20551863e-01,  1.17450334e-01,  1.00000000e+00],\n",
            "        [ 1.50341377e-01,  4.70620207e-02, -8.88065249e-03, ...,\n",
            "          3.01016718e-01, -4.47448865e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.09520571e-02,  1.26374215e-01,  1.19132727e-01, ...,\n",
            "          3.69905978e-02,  4.14547436e-02,  1.00000000e+00],\n",
            "        [-1.84044898e-01,  1.43377990e-01,  3.01854312e-01, ...,\n",
            "          6.26306161e-02,  7.54818728e-04,  1.00000000e+00],\n",
            "        [-2.58963346e-01,  9.98300016e-02,  2.90714443e-01, ...,\n",
            "          6.62344322e-02,  2.72021163e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.02419298, -0.13035142, -0.02585465, ...,  0.04476782,\n",
            "          0.20999461,  1.        ],\n",
            "        [ 0.13286705, -0.04271316, -0.00513376, ...,  0.2548666 ,\n",
            "          0.1314402 ,  1.        ],\n",
            "        [ 0.12181895,  0.00652129,  0.01732065, ...,  0.33756092,\n",
            "          0.00562041,  1.        ],\n",
            "        ...,\n",
            "        [-0.10658393,  0.13298899,  0.24261715, ...,  0.07869069,\n",
            "         -0.00139316,  1.        ],\n",
            "        [-0.2518026 ,  0.12462718,  0.337341  , ...,  0.06418112,\n",
            "         -0.02969423,  1.        ],\n",
            "        [-0.3009743 ,  0.09218032,  0.30070874, ...,  0.05079202,\n",
            "         -0.01282852,  1.        ]], dtype=float32)\n",
            " array([[-0.03238541, -0.12967198, -0.03202756, ...,  0.06022902,\n",
            "          0.21270457,  1.        ],\n",
            "        [ 0.1504074 , -0.05382968, -0.02854712, ...,  0.25335756,\n",
            "          0.15380271,  1.        ],\n",
            "        [ 0.12193592, -0.02748324, -0.00926746, ...,  0.34636548,\n",
            "          0.04355088,  1.        ],\n",
            "        ...,\n",
            "        [-0.14492576,  0.11174309,  0.2424358 , ...,  0.06404389,\n",
            "         -0.00452153,  1.        ],\n",
            "        [-0.26396927,  0.08959006,  0.29985487, ...,  0.05773275,\n",
            "         -0.03827542,  1.        ],\n",
            "        [-0.2941182 ,  0.08096813,  0.27998146, ...,  0.04711724,\n",
            "         -0.01331865,  1.        ]], dtype=float32)\n",
            " array([[-1.50706768e-02, -1.22816958e-01, -4.01682295e-02, ...,\n",
            "          5.27929589e-02,  2.12520763e-01,  1.00000000e+00],\n",
            "        [ 1.54995874e-01, -7.51417596e-03, -1.46032618e-02, ...,\n",
            "          2.53675014e-01,  1.07213534e-01,  1.00000000e+00],\n",
            "        [ 1.62144318e-01,  6.00107238e-02, -3.10240983e-04, ...,\n",
            "          3.22599232e-01, -4.62166965e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-9.36184544e-03,  1.36988655e-01,  1.66254133e-01, ...,\n",
            "          5.11060879e-02,  1.31606357e-02,  1.00000000e+00],\n",
            "        [-2.05085635e-01,  1.40083686e-01,  3.13279957e-01, ...,\n",
            "          6.52530491e-02, -1.73724331e-02,  1.00000000e+00],\n",
            "        [-2.64551997e-01,  1.10289201e-01,  2.87976027e-01, ...,\n",
            "          7.25780204e-02,  1.06733516e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.03647119, -0.15691712, -0.05882998, ...,  0.06501878,\n",
            "          0.20149983,  1.        ],\n",
            "        [ 0.11903236, -0.12458274, -0.07019067, ...,  0.292892  ,\n",
            "          0.14885715,  1.        ],\n",
            "        [ 0.05362314, -0.1198422 , -0.07853846, ...,  0.3925827 ,\n",
            "          0.07929996,  1.        ],\n",
            "        ...,\n",
            "        [-0.21109787,  0.03992487,  0.1958616 , ...,  0.08657615,\n",
            "         -0.07547925,  1.        ],\n",
            "        [-0.2577429 ,  0.0522963 ,  0.19299836, ...,  0.07408333,\n",
            "         -0.08198024,  1.        ],\n",
            "        [-0.25591996,  0.02385133,  0.22902034, ...,  0.01996258,\n",
            "         -0.04479473,  1.        ]], dtype=float32)\n",
            " array([[-1.6255951e-02, -1.2160563e-01, -3.7983719e-02, ...,\n",
            "          3.8553838e-02,  2.0469695e-01,  1.0000000e+00],\n",
            "        [ 1.3729034e-01, -1.2841692e-02, -1.4170356e-02, ...,\n",
            "          2.4339692e-01,  9.4996192e-02,  1.0000000e+00],\n",
            "        [ 1.3982239e-01,  4.9073111e-02, -3.8791410e-04, ...,\n",
            "          3.1733158e-01, -4.5886494e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [ 7.3175519e-03,  1.2900834e-01,  1.4277178e-01, ...,\n",
            "          4.8720263e-02,  2.6580568e-02,  1.0000000e+00],\n",
            "        [-2.0645496e-01,  1.2010124e-01,  3.2378989e-01, ...,\n",
            "          6.4576782e-02, -1.5528712e-02,  1.0000000e+00],\n",
            "        [-2.7199820e-01,  9.5134474e-02,  2.9534593e-01, ...,\n",
            "          4.9894940e-02, -6.5186508e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.03515649, -0.15644094, -0.05465568, ...,  0.05846566,\n",
            "          0.21255217,  1.        ],\n",
            "        [ 0.13795327, -0.11073717, -0.0788487 , ...,  0.2972974 ,\n",
            "          0.15552251,  1.        ],\n",
            "        [ 0.08708223, -0.11305615, -0.0859467 , ...,  0.39449123,\n",
            "          0.07863779,  1.        ],\n",
            "        ...,\n",
            "        [-0.1422642 ,  0.0100184 ,  0.19686419, ...,  0.11287689,\n",
            "         -0.00395526,  1.        ],\n",
            "        [-0.22813411,  0.01861142,  0.21102928, ...,  0.09049167,\n",
            "         -0.04222427,  1.        ],\n",
            "        [-0.27104488,  0.00249507,  0.2397967 , ...,  0.03507655,\n",
            "         -0.03128054,  1.        ]], dtype=float32)\n",
            " array([[-0.02080481, -0.133375  , -0.02685499, ...,  0.0443515 ,\n",
            "          0.20907648,  1.        ],\n",
            "        [ 0.14128524, -0.04206533, -0.00612873, ...,  0.25828546,\n",
            "          0.1286722 ,  1.        ],\n",
            "        [ 0.12973303,  0.00778695,  0.01423045, ...,  0.34102675,\n",
            "          0.00454876,  1.        ],\n",
            "        ...,\n",
            "        [-0.09462931,  0.12715912,  0.22368777, ...,  0.07913209,\n",
            "          0.0035164 ,  1.        ],\n",
            "        [-0.24342352,  0.1157564 ,  0.32463682, ...,  0.06471501,\n",
            "         -0.02766356,  1.        ],\n",
            "        [-0.29328114,  0.091351  ,  0.29747292, ...,  0.05123254,\n",
            "         -0.01309738,  1.        ]], dtype=float32)\n",
            " array([[-1.01330923e-02, -1.19206548e-01, -3.34387273e-02, ...,\n",
            "          4.39279601e-02,  2.08608523e-01,  2.00000000e+00],\n",
            "        [ 1.52766511e-01, -1.42204082e-02, -1.27124032e-02, ...,\n",
            "          2.55864739e-01,  1.02696598e-01,  2.00000000e+00],\n",
            "        [ 1.62491232e-01,  5.53175919e-02, -2.40521552e-03, ...,\n",
            "          3.25239033e-01, -4.13950644e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.93332227e-02,  1.18870899e-01,  1.38798296e-01, ...,\n",
            "          5.40671535e-02,  4.14683372e-02,  2.00000000e+00],\n",
            "        [-1.90896630e-01,  1.24268554e-01,  3.24277252e-01, ...,\n",
            "          8.13734233e-02, -1.61194021e-03,  2.00000000e+00],\n",
            "        [-2.55787462e-01,  1.09874293e-01,  2.92672396e-01, ...,\n",
            "          5.63935079e-02,  7.30156945e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.01819520e-02, -1.19057618e-01, -3.08743697e-02, ...,\n",
            "          3.64007503e-02,  2.05101848e-01,  2.00000000e+00],\n",
            "        [ 1.24876410e-01, -2.07620077e-02,  3.05392430e-04, ...,\n",
            "          2.32191056e-01,  1.01715624e-01,  2.00000000e+00],\n",
            "        [ 1.25437841e-01,  4.68202382e-02,  2.03331746e-02, ...,\n",
            "          3.04798305e-01, -4.11274545e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.19535699e-02,  1.31546080e-01,  1.76029503e-01, ...,\n",
            "          3.55233103e-02,  3.21403742e-02,  2.00000000e+00],\n",
            "        [-2.20445231e-01,  1.30582884e-01,  3.42367411e-01, ...,\n",
            "          4.71301712e-02, -9.67218354e-03,  2.00000000e+00],\n",
            "        [-2.86299497e-01,  9.96802747e-02,  3.06852162e-01, ...,\n",
            "          4.24952768e-02, -1.73473323e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.03306458, -0.15574174, -0.05816447, ...,  0.05888721,\n",
            "          0.19233826,  2.        ],\n",
            "        [ 0.11204366, -0.1288932 , -0.0648201 , ...,  0.26006535,\n",
            "          0.14772734,  2.        ],\n",
            "        [ 0.04492518, -0.12457335, -0.07602876, ...,  0.35770586,\n",
            "          0.08329084,  2.        ],\n",
            "        ...,\n",
            "        [-0.24087891,  0.05319867,  0.20402943, ...,  0.03507139,\n",
            "         -0.08647879,  2.        ],\n",
            "        [-0.2758414 ,  0.06819569,  0.21127053, ...,  0.03437596,\n",
            "         -0.08204602,  2.        ],\n",
            "        [-0.24642605,  0.03388897,  0.23867439, ..., -0.00571033,\n",
            "         -0.05050536,  2.        ]], dtype=float32)\n",
            " array([[-0.02043065, -0.12152696, -0.02747405, ...,  0.03647267,\n",
            "          0.20608093,  2.        ],\n",
            "        [ 0.12706777, -0.02204737,  0.00618507, ...,  0.23299779,\n",
            "          0.10781125,  2.        ],\n",
            "        [ 0.12773433,  0.04257592,  0.02777779, ...,  0.30607083,\n",
            "         -0.03123893,  2.        ],\n",
            "        ...,\n",
            "        [-0.03284603,  0.13296194,  0.19456033, ...,  0.03974679,\n",
            "          0.02188246,  2.        ],\n",
            "        [-0.22662376,  0.12847139,  0.34624818, ...,  0.0421505 ,\n",
            "         -0.0140104 ,  2.        ],\n",
            "        [-0.28867123,  0.10222249,  0.30757234, ...,  0.03818193,\n",
            "         -0.00246797,  2.        ]], dtype=float32)\n",
            " array([[-0.03143179, -0.15689702, -0.05943136, ...,  0.05680875,\n",
            "          0.19155842,  2.        ],\n",
            "        [ 0.11371826, -0.13091886, -0.06445052, ...,  0.25783315,\n",
            "          0.14873494,  2.        ],\n",
            "        [ 0.04563731, -0.12559842, -0.07446805, ...,  0.35748336,\n",
            "          0.08327466,  2.        ],\n",
            "        ...,\n",
            "        [-0.22200164,  0.04716107,  0.1923016 , ...,  0.02577645,\n",
            "         -0.08338036,  2.        ],\n",
            "        [-0.2672748 ,  0.07083949,  0.20982502, ...,  0.03105986,\n",
            "         -0.07913751,  2.        ],\n",
            "        [-0.2435223 ,  0.03166194,  0.23598203, ..., -0.00653042,\n",
            "         -0.05150508,  2.        ]], dtype=float32)\n",
            " array([[-0.03538483, -0.13534008, -0.03330295, ...,  0.06224126,\n",
            "          0.21278442,  2.        ],\n",
            "        [ 0.16231096, -0.06030845, -0.0298604 , ...,  0.27530345,\n",
            "          0.15372066,  2.        ],\n",
            "        [ 0.12539838, -0.03321083, -0.01824571, ...,  0.367265  ,\n",
            "          0.04427567,  2.        ],\n",
            "        ...,\n",
            "        [-0.16472508,  0.09929305,  0.2530941 , ...,  0.08633608,\n",
            "         -0.01849134,  2.        ],\n",
            "        [-0.26727706,  0.08418173,  0.28580242, ...,  0.07618856,\n",
            "         -0.04185491,  2.        ],\n",
            "        [-0.2931111 ,  0.07842994,  0.27621984, ...,  0.04850299,\n",
            "         -0.01229779,  2.        ]], dtype=float32)\n",
            " array([[ 0.02112283, -0.12886925, -0.07947879, ...,  0.03271211,\n",
            "          0.18958512,  2.        ],\n",
            "        [ 0.21573502,  0.00912457, -0.0632293 , ...,  0.23252647,\n",
            "          0.04552215,  2.        ],\n",
            "        [ 0.19872226,  0.04221422, -0.05912919, ...,  0.3092748 ,\n",
            "         -0.09148222,  2.        ],\n",
            "        ...,\n",
            "        [ 0.16308843,  0.01089377, -0.00268424, ...,  0.0726378 ,\n",
            "          0.03570727,  2.        ],\n",
            "        [-0.07311214,  0.08130191,  0.25947005, ...,  0.11909104,\n",
            "         -0.02485208,  2.        ],\n",
            "        [-0.24809751,  0.07642537,  0.2872306 , ...,  0.08306855,\n",
            "         -0.02248034,  2.        ]], dtype=float32)\n",
            " array([[-0.0323956 , -0.13460648, -0.03229933, ...,  0.06862719,\n",
            "          0.21154958,  2.        ],\n",
            "        [ 0.17432453, -0.05256716, -0.03038313, ...,  0.2800701 ,\n",
            "          0.14392273,  2.        ],\n",
            "        [ 0.1466516 , -0.02130787, -0.01123064, ...,  0.37229076,\n",
            "          0.03042771,  2.        ],\n",
            "        ...,\n",
            "        [-0.1321702 ,  0.11852911,  0.23547941, ...,  0.08686   ,\n",
            "         -0.01527452,  2.        ],\n",
            "        [-0.2601657 ,  0.0962219 ,  0.28902936, ...,  0.07646408,\n",
            "         -0.0381878 ,  2.        ],\n",
            "        [-0.2837705 ,  0.09335311,  0.273643  , ...,  0.06364533,\n",
            "         -0.00782438,  2.        ]], dtype=float32)\n",
            " array([[-0.02759452, -0.14860521, -0.0604827 , ...,  0.05858247,\n",
            "          0.19738258,  2.        ],\n",
            "        [ 0.131629  , -0.12092443, -0.06156378, ...,  0.25214943,\n",
            "          0.16483687,  2.        ],\n",
            "        [ 0.06357726, -0.10880154, -0.06622373, ...,  0.363137  ,\n",
            "          0.08239521,  2.        ],\n",
            "        ...,\n",
            "        [-0.2266034 ,  0.05279104,  0.18761437, ...,  0.03269643,\n",
            "         -0.07481442,  2.        ],\n",
            "        [-0.27595314,  0.07189136,  0.21206303, ...,  0.04412488,\n",
            "         -0.07623972,  2.        ],\n",
            "        [-0.24853079,  0.03872584,  0.23651126, ...,  0.00595416,\n",
            "         -0.05201726,  2.        ]], dtype=float32)\n",
            " array([[-0.01725925, -0.11798313, -0.03836179, ...,  0.04614706,\n",
            "          0.21174358,  2.        ],\n",
            "        [ 0.1405575 , -0.0104807 , -0.01168748, ...,  0.24574542,\n",
            "          0.10579658,  2.        ],\n",
            "        [ 0.15171286,  0.05850211,  0.00774089, ...,  0.31455302,\n",
            "         -0.04919594,  2.        ],\n",
            "        ...,\n",
            "        [-0.00567039,  0.13452305,  0.16209444, ...,  0.0389418 ,\n",
            "          0.02513897,  2.        ],\n",
            "        [-0.20453379,  0.14244114,  0.3281292 , ...,  0.06042393,\n",
            "         -0.01086017,  2.        ],\n",
            "        [-0.2697053 ,  0.10616504,  0.29952174, ...,  0.06293584,\n",
            "          0.00443129,  2.        ]], dtype=float32)\n",
            " array([[-9.5237019e-03, -1.2093341e-01, -3.2613985e-02, ...,\n",
            "          4.7069725e-02,  2.1186240e-01,  2.0000000e+00],\n",
            "        [ 1.5747687e-01, -1.8730251e-02, -1.4562910e-02, ...,\n",
            "          2.6255575e-01,  1.1625521e-01,  2.0000000e+00],\n",
            "        [ 1.6440329e-01,  5.0777331e-02, -1.1762223e-03, ...,\n",
            "          3.3539075e-01, -2.6076233e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.5188373e-02,  1.1900038e-01,  1.5542893e-01, ...,\n",
            "          7.3396020e-02,  4.0777076e-02,  2.0000000e+00],\n",
            "        [-1.9608445e-01,  1.2173134e-01,  3.2399002e-01, ...,\n",
            "          8.8040181e-02,  8.6426700e-04,  2.0000000e+00],\n",
            "        [-2.5671008e-01,  1.0759356e-01,  2.9277408e-01, ...,\n",
            "          6.3280188e-02,  8.8380231e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.3606368e-02, -1.2205434e-01, -3.0466704e-02, ...,\n",
            "          4.6560496e-02,  2.1191640e-01,  2.0000000e+00],\n",
            "        [ 1.5123074e-01, -2.2259444e-02, -9.8322118e-03, ...,\n",
            "          2.6270688e-01,  1.1838171e-01,  2.0000000e+00],\n",
            "        [ 1.5652245e-01,  4.4931728e-02,  4.2714784e-03, ...,\n",
            "          3.3490252e-01, -2.3295276e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.7383802e-03,  1.2185714e-01,  1.7576434e-01, ...,\n",
            "          7.3139094e-02,  3.2754134e-02,  2.0000000e+00],\n",
            "        [-2.0784517e-01,  1.2519079e-01,  3.3086607e-01, ...,\n",
            "          8.0411434e-02, -2.4656039e-03,  2.0000000e+00],\n",
            "        [-2.6273936e-01,  1.0843594e-01,  2.9495674e-01, ...,\n",
            "          5.9402935e-02,  9.9569783e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.03205339, -0.13022694, -0.02962795, ...,  0.05299262,\n",
            "          0.2055159 ,  2.        ],\n",
            "        [ 0.14450994, -0.05621052, -0.02570199, ...,  0.2550283 ,\n",
            "          0.13879842,  2.        ],\n",
            "        [ 0.1225049 , -0.02709138, -0.0116666 , ...,  0.34503016,\n",
            "          0.02819583,  2.        ],\n",
            "        ...,\n",
            "        [-0.11999017,  0.09968148,  0.22005932, ...,  0.07228039,\n",
            "          0.01195458,  2.        ],\n",
            "        [-0.25138992,  0.09281776,  0.29483297, ...,  0.05866607,\n",
            "         -0.03091889,  2.        ],\n",
            "        [-0.2974618 ,  0.08762788,  0.2844663 , ...,  0.03941306,\n",
            "         -0.01768752,  2.        ]], dtype=float32)\n",
            " array([[-0.02784317, -0.1421136 , -0.03714063, ...,  0.06753361,\n",
            "          0.21632181,  2.        ],\n",
            "        [ 0.1843655 , -0.07037898, -0.04409961, ...,  0.28237346,\n",
            "          0.16306107,  2.        ],\n",
            "        [ 0.1428142 , -0.04721626, -0.03597663, ...,  0.38115382,\n",
            "          0.05573868,  2.        ],\n",
            "        ...,\n",
            "        [-0.09803611,  0.0833248 ,  0.20385195, ...,  0.1138429 ,\n",
            "          0.00789814,  2.        ],\n",
            "        [-0.2389242 ,  0.08062635,  0.27359658, ...,  0.09405863,\n",
            "         -0.02551282,  2.        ],\n",
            "        [-0.2832437 ,  0.07766346,  0.26292244, ...,  0.06995108,\n",
            "         -0.00886972,  2.        ]], dtype=float32)\n",
            " array([[-0.02938236, -0.14746566, -0.04263393, ...,  0.06232549,\n",
            "          0.21249469,  2.        ],\n",
            "        [ 0.15694349, -0.07694878, -0.06475262, ...,  0.29855412,\n",
            "          0.1436501 ,  2.        ],\n",
            "        [ 0.12555559, -0.06527878, -0.07103374, ...,  0.3890455 ,\n",
            "          0.04288363,  2.        ],\n",
            "        ...,\n",
            "        [-0.1092216 ,  0.03005066,  0.18553028, ...,  0.09978931,\n",
            "          0.0231484 ,  2.        ],\n",
            "        [-0.21550037,  0.03113534,  0.24186832, ...,  0.08299693,\n",
            "         -0.01901484,  2.        ],\n",
            "        [-0.2740315 ,  0.03948638,  0.2534646 , ...,  0.05346477,\n",
            "         -0.01717308,  2.        ]], dtype=float32)\n",
            " array([[-0.01875746, -0.11888348, -0.03308633, ...,  0.03600862,\n",
            "          0.2037521 ,  2.        ],\n",
            "        [ 0.12710924, -0.01135107, -0.00305333, ...,  0.23202817,\n",
            "          0.09040141,  2.        ],\n",
            "        [ 0.13461144,  0.05659389,  0.0124614 , ...,  0.303043  ,\n",
            "         -0.0532678 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.00269384,  0.12594478,  0.14870429, ...,  0.02730866,\n",
            "          0.03359742,  2.        ],\n",
            "        [-0.2095438 ,  0.12275729,  0.33692762, ...,  0.04881941,\n",
            "         -0.01340185,  2.        ],\n",
            "        [-0.27776378,  0.09643058,  0.3046144 , ...,  0.042345  ,\n",
            "         -0.00355528,  2.        ]], dtype=float32)\n",
            " array([[-0.01829606, -0.12294189, -0.03840005, ...,  0.04975357,\n",
            "          0.2139627 ,  2.        ],\n",
            "        [ 0.13864745, -0.02397471, -0.01094704, ...,  0.23167172,\n",
            "          0.1220087 ,  2.        ],\n",
            "        [ 0.13568035,  0.04336124,  0.00826598, ...,  0.31003258,\n",
            "         -0.0291345 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.03547104,  0.14975043,  0.18856427, ...,  0.04456607,\n",
            "          0.01961631,  2.        ],\n",
            "        [-0.22756219,  0.14125916,  0.3251553 , ...,  0.05857896,\n",
            "         -0.01090041,  2.        ],\n",
            "        [-0.27139008,  0.10689285,  0.29253516, ...,  0.06999806,\n",
            "          0.00884096,  2.        ]], dtype=float32)\n",
            " array([[-1.77658023e-03, -1.08281605e-01, -5.73967099e-02, ...,\n",
            "          4.38827090e-02,  2.11501524e-01,  2.00000000e+00],\n",
            "        [ 1.43937513e-01, -1.56032713e-03, -2.97743622e-02, ...,\n",
            "          2.22037897e-01,  9.85356197e-02,  2.00000000e+00],\n",
            "        [ 1.53497711e-01,  5.48077263e-02, -1.94172151e-02, ...,\n",
            "          2.97368139e-01, -6.34220988e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 3.67968455e-02,  1.27068833e-01,  1.15752049e-01, ...,\n",
            "          2.26422250e-02,  4.04400006e-02,  2.00000000e+00],\n",
            "        [-1.75093174e-01,  1.44731253e-01,  3.11121881e-01, ...,\n",
            "          6.16752729e-02, -9.96939931e-03,  2.00000000e+00],\n",
            "        [-2.59225219e-01,  9.94335189e-02,  2.94385821e-01, ...,\n",
            "          6.54006302e-02, -2.72723148e-04,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.04798114e-02, -1.32061899e-01, -3.38501222e-02, ...,\n",
            "          5.34272566e-02,  2.14915857e-01,  2.00000000e+00],\n",
            "        [ 1.40947118e-01, -3.41035724e-02, -1.26362415e-02, ...,\n",
            "          2.52002031e-01,  1.27354547e-01,  2.00000000e+00],\n",
            "        [ 1.40762404e-01,  3.01574580e-02,  7.11721554e-03, ...,\n",
            "          3.34439486e-01, -2.05930043e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-6.09584413e-02,  1.40408128e-01,  2.08083853e-01, ...,\n",
            "          6.74283355e-02,  8.93498491e-03,  2.00000000e+00],\n",
            "        [-2.32380345e-01,  1.41555473e-01,  3.24798077e-01, ...,\n",
            "          6.87708035e-02, -2.07784325e-02,  2.00000000e+00],\n",
            "        [-2.81881720e-01,  1.01704463e-01,  2.96430081e-01, ...,\n",
            "          6.83730245e-02,  1.32869207e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01890459, -0.14940593, -0.03438168, ...,  0.06279458,\n",
            "          0.22117157,  2.        ],\n",
            "        [ 0.17792715, -0.04960196, -0.03073816, ...,  0.2823832 ,\n",
            "          0.14309905,  2.        ],\n",
            "        [ 0.15979366, -0.012491  , -0.00861482, ...,  0.3689299 ,\n",
            "          0.02160777,  2.        ],\n",
            "        ...,\n",
            "        [-0.06602719,  0.09610913,  0.18379283, ...,  0.07480772,\n",
            "          0.00840722,  2.        ],\n",
            "        [-0.20667426,  0.08869311,  0.2663854 , ...,  0.07448124,\n",
            "         -0.02597818,  2.        ],\n",
            "        [-0.26700178,  0.08078192,  0.2661218 , ...,  0.07319619,\n",
            "         -0.00536735,  2.        ]], dtype=float32)\n",
            " array([[-1.76412761e-02, -1.16894886e-01, -3.03948540e-02, ...,\n",
            "          3.31853405e-02,  2.04246089e-01,  2.00000000e+00],\n",
            "        [ 1.26755342e-01, -1.51692694e-02, -8.88812472e-04, ...,\n",
            "          2.24320978e-01,  9.79019105e-02,  2.00000000e+00],\n",
            "        [ 1.30221561e-01,  5.18648401e-02,  1.91304684e-02, ...,\n",
            "          2.96005905e-01, -5.00808023e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.10413078e-02,  1.32174596e-01,  1.72393262e-01, ...,\n",
            "          1.97804980e-02,  3.29072550e-02,  2.00000000e+00],\n",
            "        [-2.16494262e-01,  1.36108801e-01,  3.42048645e-01, ...,\n",
            "          3.85403372e-02, -1.02454927e-02,  2.00000000e+00],\n",
            "        [-2.83346266e-01,  9.96036455e-02,  3.09140056e-01, ...,\n",
            "          4.19743024e-02, -6.28487207e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-9.8419785e-03, -1.0930533e-01, -4.7014207e-02, ...,\n",
            "          2.9070016e-02,  1.9949770e-01,  2.0000000e+00],\n",
            "        [ 1.3873512e-01, -5.3799949e-03, -1.6613152e-02, ...,\n",
            "          2.2244668e-01,  6.8133749e-02,  2.0000000e+00],\n",
            "        [ 1.5082011e-01,  5.6004290e-02, -7.8898259e-03, ...,\n",
            "          2.9095888e-01, -7.7944398e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 3.7560791e-02,  9.2703938e-02,  8.6145923e-02, ...,\n",
            "          1.1380427e-02,  6.2928103e-02,  2.0000000e+00],\n",
            "        [-1.7833893e-01,  1.3125795e-01,  3.2465440e-01, ...,\n",
            "          5.3703051e-02, -1.1416533e-03,  2.0000000e+00],\n",
            "        [-2.7345228e-01,  9.6320875e-02,  3.0470246e-01, ...,\n",
            "          4.7670972e-02, -4.4984184e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02331862, -0.13224742, -0.02901731, ...,  0.04744578,\n",
            "          0.21660478,  2.        ],\n",
            "        [ 0.1419894 , -0.03875061, -0.0056514 , ...,  0.2509805 ,\n",
            "          0.13149595,  2.        ],\n",
            "        [ 0.14223988,  0.02165684,  0.01937579, ...,  0.32417697,\n",
            "         -0.00564374,  2.        ],\n",
            "        ...,\n",
            "        [-0.08917492,  0.14835735,  0.2343129 , ...,  0.05347985,\n",
            "         -0.00994713,  2.        ],\n",
            "        [-0.2390165 ,  0.13748316,  0.33299148, ...,  0.05314212,\n",
            "         -0.03101346,  2.        ],\n",
            "        [-0.28520277,  0.09991997,  0.30140862, ...,  0.05741284,\n",
            "         -0.00618191,  2.        ]], dtype=float32)\n",
            " array([[-1.38793895e-02, -1.21513918e-01, -3.77990864e-02, ...,\n",
            "          4.96140532e-02,  2.19510719e-01,  0.00000000e+00],\n",
            "        [ 1.31722435e-01, -3.85234617e-02, -1.36117209e-02, ...,\n",
            "          2.28422344e-01,  1.41044676e-01,  0.00000000e+00],\n",
            "        [ 1.31995425e-01,  2.50065867e-02,  5.81687642e-03, ...,\n",
            "          3.09628755e-01, -1.63144488e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-5.88845313e-02,  1.48511708e-01,  2.08844364e-01, ...,\n",
            "          5.79196252e-02,  1.17694233e-02,  0.00000000e+00],\n",
            "        [-2.33649731e-01,  1.39857098e-01,  3.35885465e-01, ...,\n",
            "          6.13626577e-02, -1.64351854e-02,  0.00000000e+00],\n",
            "        [-2.80826509e-01,  1.00708663e-01,  3.02845329e-01, ...,\n",
            "          6.00713938e-02, -1.56176451e-04,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.02753714, -0.14807007, -0.05883229, ...,  0.06176234,\n",
            "          0.2019842 ,  0.        ],\n",
            "        [ 0.13694298, -0.11744019, -0.06242619, ...,  0.26240313,\n",
            "          0.16601506,  0.        ],\n",
            "        [ 0.07051834, -0.10753734, -0.06486657, ...,  0.37494898,\n",
            "          0.08837821,  0.        ],\n",
            "        ...,\n",
            "        [-0.21165685,  0.04964204,  0.19043419, ...,  0.05128235,\n",
            "         -0.06490473,  0.        ],\n",
            "        [-0.27189225,  0.05965149,  0.21044649, ...,  0.06247024,\n",
            "         -0.06953947,  0.        ],\n",
            "        [-0.25684586,  0.04226247,  0.24037005, ...,  0.01314814,\n",
            "         -0.04300357,  0.        ]], dtype=float32)\n",
            " array([[-0.01724049, -0.12853572, -0.03168064, ...,  0.03948403,\n",
            "          0.20589356,  0.        ],\n",
            "        [ 0.13360448, -0.03288339, -0.00711851, ...,  0.24856317,\n",
            "          0.11197498,  0.        ],\n",
            "        [ 0.13016775,  0.02774235,  0.01295034, ...,  0.32848775,\n",
            "         -0.02804065,  0.        ],\n",
            "        ...,\n",
            "        [-0.02941119,  0.12890759,  0.18507832, ...,  0.07269811,\n",
            "          0.01796409,  0.        ],\n",
            "        [-0.22225349,  0.12733963,  0.33029357, ...,  0.06259649,\n",
            "         -0.01405546,  0.        ],\n",
            "        [-0.2788665 ,  0.09645831,  0.2944133 , ...,  0.04626785,\n",
            "         -0.00767879,  0.        ]], dtype=float32)\n",
            " array([[-0.03620535, -0.15451264, -0.05660684, ...,  0.06076425,\n",
            "          0.20814033,  0.        ],\n",
            "        [ 0.13747689, -0.11800624, -0.07851393, ...,  0.28877366,\n",
            "          0.16109993,  0.        ],\n",
            "        [ 0.07578454, -0.11531438, -0.08314251, ...,  0.3956179 ,\n",
            "          0.0825597 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.1858128 ,  0.02232457,  0.19728398, ...,  0.10949606,\n",
            "         -0.03851924,  0.        ],\n",
            "        [-0.25982058,  0.0437252 ,  0.19870989, ...,  0.08716325,\n",
            "         -0.06905561,  0.        ],\n",
            "        [-0.27213433,  0.01951444,  0.23636726, ...,  0.023494  ,\n",
            "         -0.03796861,  0.        ]], dtype=float32)\n",
            " array([[-0.01936723, -0.13621877, -0.02886553, ...,  0.04947962,\n",
            "          0.21628413,  0.        ],\n",
            "        [ 0.15061088, -0.0484153 , -0.01072501, ...,  0.24879768,\n",
            "          0.13736038,  0.        ],\n",
            "        [ 0.13826375,  0.00455488,  0.01239951, ...,  0.33104423,\n",
            "         -0.00512545,  0.        ],\n",
            "        ...,\n",
            "        [-0.08952311,  0.15199856,  0.21589315, ...,  0.04876805,\n",
            "          0.00227822,  0.        ],\n",
            "        [-0.23536302,  0.13274285,  0.3085586 , ...,  0.05369464,\n",
            "         -0.02743929,  0.        ],\n",
            "        [-0.275805  ,  0.09793203,  0.2857594 , ...,  0.06478274,\n",
            "         -0.00546833,  0.        ]], dtype=float32)\n",
            " array([[-3.08834016e-04, -1.17166631e-01, -4.61579673e-02, ...,\n",
            "          5.75839058e-02,  2.18646437e-01,  0.00000000e+00],\n",
            "        [ 1.46776378e-01, -2.82294601e-02, -2.88003590e-02, ...,\n",
            "          2.25436553e-01,  1.26475528e-01,  0.00000000e+00],\n",
            "        [ 1.35769233e-01,  3.27276289e-02, -1.18631171e-02, ...,\n",
            "          3.12466919e-01, -3.84422392e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.25340242e-02,  1.47653639e-01,  1.30620211e-01, ...,\n",
            "          4.53451164e-02,  4.01573814e-02,  0.00000000e+00],\n",
            "        [-1.89869821e-01,  1.48540527e-01,  2.96514422e-01, ...,\n",
            "          7.14563802e-02,  2.89592217e-03,  0.00000000e+00],\n",
            "        [-2.48146340e-01,  1.07115224e-01,  2.81370580e-01, ...,\n",
            "          7.58918971e-02,  5.32218441e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.03199393, -0.13619512, -0.03906126, ...,  0.05468629,\n",
            "          0.20971248,  0.        ],\n",
            "        [ 0.1442832 , -0.072451  , -0.05300092, ...,  0.27039868,\n",
            "          0.13950686,  0.        ],\n",
            "        [ 0.1180485 , -0.05344436, -0.05538661, ...,  0.3643999 ,\n",
            "          0.02786182,  0.        ],\n",
            "        ...,\n",
            "        [-0.1233651 ,  0.0584075 ,  0.2015379 , ...,  0.09951323,\n",
            "          0.01716466,  0.        ],\n",
            "        [-0.24157815,  0.0536807 ,  0.27103594, ...,  0.07194363,\n",
            "         -0.02742266,  0.        ],\n",
            "        [-0.29100594,  0.0593278 ,  0.2698555 , ...,  0.03811486,\n",
            "         -0.01961621,  0.        ]], dtype=float32)\n",
            " array([[-0.03378477, -0.16060136, -0.05179932, ...,  0.05769264,\n",
            "          0.21215838,  0.        ],\n",
            "        [ 0.14189208, -0.10973261, -0.073591  , ...,  0.2910828 ,\n",
            "          0.15276358,  0.        ],\n",
            "        [ 0.09324002, -0.11339973, -0.08011403, ...,  0.380345  ,\n",
            "          0.0774243 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.13928464,  0.00563961,  0.19706044, ...,  0.10831141,\n",
            "          0.00554749,  0.        ],\n",
            "        [-0.23295684,  0.02087802,  0.21350475, ...,  0.08694743,\n",
            "         -0.04180528,  0.        ],\n",
            "        [-0.27079028,  0.0079864 ,  0.24093243, ...,  0.03428492,\n",
            "         -0.02811515,  0.        ]], dtype=float32)\n",
            " array([[-0.02823017, -0.12393438, -0.03161198, ...,  0.05164116,\n",
            "          0.2072014 ,  0.        ],\n",
            "        [ 0.13706507, -0.06182395, -0.03427041, ...,  0.26242906,\n",
            "          0.1374925 ,  0.        ],\n",
            "        [ 0.1196413 , -0.0295089 , -0.02375328, ...,  0.36198628,\n",
            "          0.01473058,  0.        ],\n",
            "        ...,\n",
            "        [-0.12826742,  0.1029757 ,  0.23544867, ...,  0.0937777 ,\n",
            "         -0.00282949,  0.        ],\n",
            "        [-0.25271556,  0.09442167,  0.30679208, ...,  0.0704852 ,\n",
            "         -0.03159675,  0.        ],\n",
            "        [-0.29966408,  0.08277538,  0.28857747, ...,  0.04494632,\n",
            "         -0.01845813,  0.        ]], dtype=float32)\n",
            " array([[ 0.01388634, -0.11026864, -0.06144489, ...,  0.05376919,\n",
            "          0.20722954,  0.        ],\n",
            "        [ 0.16737956, -0.01433512, -0.05442454, ...,  0.21749276,\n",
            "          0.09983942,  0.        ],\n",
            "        [ 0.15648678,  0.0394453 , -0.04368256, ...,  0.2999679 ,\n",
            "         -0.0629897 ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.07180007,  0.11392347,  0.07449375, ...,  0.04585604,\n",
            "          0.04871606,  0.        ],\n",
            "        [-0.15032218,  0.13257723,  0.2698867 , ...,  0.086236  ,\n",
            "         -0.00226844,  0.        ],\n",
            "        [-0.2419447 ,  0.09655008,  0.27145582, ...,  0.06956609,\n",
            "          0.00059861,  0.        ]], dtype=float32)\n",
            " array([[-0.03421102, -0.147076  , -0.0381652 , ...,  0.06113831,\n",
            "          0.21546327,  0.        ],\n",
            "        [ 0.16527455, -0.0831129 , -0.04908946, ...,  0.28767812,\n",
            "          0.16092122,  0.        ],\n",
            "        [ 0.11699872, -0.07924662, -0.04485791, ...,  0.3840177 ,\n",
            "          0.07121903,  0.        ],\n",
            "        ...,\n",
            "        [-0.15118505,  0.05494932,  0.22420785, ...,  0.10005048,\n",
            "          0.00263071,  0.        ],\n",
            "        [-0.263578  ,  0.05328072,  0.2578207 , ...,  0.0804942 ,\n",
            "         -0.04397631,  0.        ],\n",
            "        [-0.28969663,  0.05423373,  0.26423803, ...,  0.03838131,\n",
            "         -0.02131736,  0.        ]], dtype=float32)\n",
            " array([[-0.0333078 , -0.13998927, -0.03657612, ...,  0.05492349,\n",
            "          0.21127862,  0.        ],\n",
            "        [ 0.14827724, -0.07130702, -0.0499519 , ...,  0.2788612 ,\n",
            "          0.14751434,  0.        ],\n",
            "        [ 0.11443538, -0.05653666, -0.05216073, ...,  0.3697386 ,\n",
            "          0.04685856,  0.        ],\n",
            "        ...,\n",
            "        [-0.14160772,  0.05711604,  0.2241804 , ...,  0.08676621,\n",
            "          0.00995239,  0.        ],\n",
            "        [-0.24518189,  0.05584786,  0.2705739 , ...,  0.06983051,\n",
            "         -0.025954  ,  0.        ],\n",
            "        [-0.29352474,  0.05611045,  0.2750723 , ...,  0.03939183,\n",
            "         -0.01806896,  0.        ]], dtype=float32)\n",
            " array([[-0.0083478 , -0.11450306, -0.03470621, ...,  0.04325089,\n",
            "          0.20786326,  0.        ],\n",
            "        [ 0.16059946, -0.01098205, -0.01630138, ...,  0.2575245 ,\n",
            "          0.09645046,  0.        ],\n",
            "        [ 0.17225477,  0.0599304 , -0.00569723, ...,  0.32120705,\n",
            "         -0.05091513,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05224777,  0.11334234,  0.10838744, ...,  0.05301099,\n",
            "          0.05494562,  0.        ],\n",
            "        [-0.17324854,  0.12493108,  0.31366706, ...,  0.09096227,\n",
            "          0.00301993,  0.        ],\n",
            "        [-0.2529582 ,  0.11190556,  0.29264876, ...,  0.06016074,\n",
            "          0.00946447,  0.        ]], dtype=float32)\n",
            " array([[-0.03262887, -0.14375871, -0.03532254, ...,  0.06289613,\n",
            "          0.21466282,  0.        ],\n",
            "        [ 0.16686454, -0.0709767 , -0.03834858, ...,  0.2782775 ,\n",
            "          0.1526577 ,  0.        ],\n",
            "        [ 0.12338641, -0.05163218, -0.0291585 , ...,  0.370734  ,\n",
            "          0.0508346 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.14078757,  0.07539637,  0.23360467, ...,  0.09464204,\n",
            "         -0.00086047,  0.        ],\n",
            "        [-0.25556123,  0.062233  ,  0.27680856, ...,  0.07669771,\n",
            "         -0.04175996,  0.        ],\n",
            "        [-0.28229368,  0.07084479,  0.2690969 , ...,  0.04849378,\n",
            "         -0.01696519,  0.        ]], dtype=float32)\n",
            " array([[-0.03391745, -0.13540003, -0.0362187 , ...,  0.05257385,\n",
            "          0.2099488 ,  0.        ],\n",
            "        [ 0.13711722, -0.06742352, -0.04212019, ...,  0.26845405,\n",
            "          0.1467051 ,  0.        ],\n",
            "        [ 0.10808577, -0.047665  , -0.04103614, ...,  0.35934964,\n",
            "          0.04111985,  0.        ],\n",
            "        ...,\n",
            "        [-0.16042937,  0.06994257,  0.24740745, ...,  0.08888259,\n",
            "          0.00227256,  0.        ],\n",
            "        [-0.26049545,  0.06598742,  0.28810665, ...,  0.07017851,\n",
            "         -0.03323639,  0.        ],\n",
            "        [-0.3012768 ,  0.06601983,  0.28305233, ...,  0.03458909,\n",
            "         -0.01939631,  0.        ]], dtype=float32)\n",
            " array([[ 0.06250786, -0.22717749, -0.14560533, ..., -0.033278  ,\n",
            "          0.1874667 ,  0.        ],\n",
            "        [ 0.29687044,  0.00710882, -0.09368446, ..., -0.03633432,\n",
            "          0.03443502,  0.        ],\n",
            "        [ 0.3229723 ,  0.02231958, -0.07661767, ...,  0.01256877,\n",
            "         -0.00260136,  0.        ],\n",
            "        ...,\n",
            "        [ 0.18502247, -0.01933676, -0.14807758, ...,  0.02530233,\n",
            "          0.09274411,  0.        ],\n",
            "        [ 0.0838681 ,  0.03303347,  0.04377017, ...,  0.09600921,\n",
            "          0.01836698,  0.        ],\n",
            "        [-0.09867921, -0.0139999 ,  0.25860894, ...,  0.02004092,\n",
            "          0.03813343,  0.        ]], dtype=float32)\n",
            " array([[-0.00770989, -0.10988152, -0.05122291, ...,  0.02998647,\n",
            "          0.19736803,  0.        ],\n",
            "        [ 0.14725764, -0.00448409, -0.02493238, ...,  0.22941284,\n",
            "          0.05296984,  0.        ],\n",
            "        [ 0.15918882,  0.05549708, -0.02052126, ...,  0.2981895 ,\n",
            "         -0.09116606,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05126381,  0.0867865 ,  0.07023534, ...,  0.01703203,\n",
            "          0.0557189 ,  0.        ],\n",
            "        [-0.16808295,  0.12389506,  0.32086888, ...,  0.06387942,\n",
            "         -0.00872416,  0.        ],\n",
            "        [-0.26756698,  0.09312035,  0.29983068, ...,  0.05029715,\n",
            "         -0.00399821,  0.        ]], dtype=float32)\n",
            " array([[-0.01888611, -0.12349731, -0.03221035, ...,  0.04733855,\n",
            "          0.21726169,  0.        ],\n",
            "        [ 0.12879165, -0.03465383, -0.00711485, ...,  0.23842798,\n",
            "          0.13415001,  0.        ],\n",
            "        [ 0.12651469,  0.02624798,  0.01472754, ...,  0.31357193,\n",
            "         -0.01596351,  0.        ],\n",
            "        ...,\n",
            "        [-0.03477661,  0.14004524,  0.19496208, ...,  0.04704157,\n",
            "          0.02825261,  0.        ],\n",
            "        [-0.2229103 ,  0.14479682,  0.33094102, ...,  0.05614726,\n",
            "         -0.00611516,  0.        ],\n",
            "        [-0.28442264,  0.10038105,  0.3011533 , ...,  0.05664498,\n",
            "          0.00033527,  0.        ]], dtype=float32)\n",
            " array([[-2.42431350e-02, -1.31684482e-01, -2.58897021e-02, ...,\n",
            "          4.31920551e-02,  2.08820552e-01,  0.00000000e+00],\n",
            "        [ 1.30327970e-01, -4.57127169e-02, -2.29754500e-04, ...,\n",
            "          2.46086985e-01,  1.31864950e-01,  0.00000000e+00],\n",
            "        [ 1.19842134e-01,  1.71420979e-04,  1.98684279e-02, ...,\n",
            "          3.28587979e-01,  5.50611457e-03,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-1.09177597e-01,  1.33483022e-01,  2.53756046e-01, ...,\n",
            "          8.08317438e-02, -4.09068447e-03,  0.00000000e+00],\n",
            "        [-2.54411280e-01,  1.24907516e-01,  3.47878993e-01, ...,\n",
            "          6.21813498e-02, -3.25649157e-02,  0.00000000e+00],\n",
            "        [-3.02278638e-01,  9.15069431e-02,  3.03375125e-01, ...,\n",
            "          4.74313870e-02, -1.57350525e-02,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.00863604, -0.11535039, -0.03578259, ...,  0.04336778,\n",
            "          0.20925888,  1.        ],\n",
            "        [ 0.15857641, -0.01044429, -0.0188087 , ...,  0.2569353 ,\n",
            "          0.09658028,  1.        ],\n",
            "        [ 0.17053974,  0.06082953, -0.00754978, ...,  0.32055932,\n",
            "         -0.05129989,  1.        ],\n",
            "        ...,\n",
            "        [ 0.0549601 ,  0.11197611,  0.10715854, ...,  0.05189146,\n",
            "          0.05308717,  1.        ],\n",
            "        [-0.17326036,  0.12459357,  0.3170766 , ...,  0.09096101,\n",
            "          0.00200807,  1.        ],\n",
            "        [-0.25248352,  0.10922682,  0.29346633, ...,  0.06242468,\n",
            "          0.00921797,  1.        ]], dtype=float32)\n",
            " array([[-0.03049671, -0.1552062 , -0.06070391, ...,  0.05802335,\n",
            "          0.19119604,  1.        ],\n",
            "        [ 0.10908446, -0.12939218, -0.06851939, ...,  0.26162568,\n",
            "          0.145399  ,  1.        ],\n",
            "        [ 0.0406464 , -0.12769417, -0.08276057, ...,  0.36024415,\n",
            "          0.08183516,  1.        ],\n",
            "        ...,\n",
            "        [-0.23216084,  0.05243248,  0.19814876, ...,  0.03351101,\n",
            "         -0.08549556,  1.        ],\n",
            "        [-0.2680985 ,  0.06130483,  0.20405506, ...,  0.03364165,\n",
            "         -0.08210108,  1.        ],\n",
            "        [-0.24246411,  0.03061224,  0.23652533, ..., -0.00612585,\n",
            "         -0.05065754,  1.        ]], dtype=float32)\n",
            " array([[-0.03142974, -0.13249287, -0.0360553 , ...,  0.05477992,\n",
            "          0.21585546,  1.        ],\n",
            "        [ 0.14433765, -0.06661236, -0.04182461, ...,  0.26187983,\n",
            "          0.1601327 ,  1.        ],\n",
            "        [ 0.10830755, -0.04562644, -0.03342244, ...,  0.3583326 ,\n",
            "          0.04856908,  1.        ],\n",
            "        ...,\n",
            "        [-0.17232442,  0.08219409,  0.25384936, ...,  0.08205292,\n",
            "         -0.01211485,  1.        ],\n",
            "        [-0.27326512,  0.07090143,  0.29083884, ...,  0.06977752,\n",
            "         -0.04466575,  1.        ],\n",
            "        [-0.30155346,  0.07237522,  0.28159538, ...,  0.04011964,\n",
            "         -0.01756639,  1.        ]], dtype=float32)\n",
            " array([[-0.01935295, -0.13994281, -0.04357653, ...,  0.07454462,\n",
            "          0.21111614,  1.        ],\n",
            "        [ 0.19134106, -0.08260582, -0.07238938, ...,  0.3103904 ,\n",
            "          0.1602467 ,  1.        ],\n",
            "        [ 0.16063951, -0.07005225, -0.07946588, ...,  0.4164876 ,\n",
            "          0.06203399,  1.        ],\n",
            "        ...,\n",
            "        [-0.06102317,  0.03103221,  0.14919998, ...,  0.17004651,\n",
            "          0.02933378,  1.        ],\n",
            "        [-0.20968524,  0.05061518,  0.25743532, ...,  0.13931003,\n",
            "         -0.00529729,  1.        ],\n",
            "        [-0.28298542,  0.05690791,  0.25000924, ...,  0.07302113,\n",
            "         -0.00858889,  1.        ]], dtype=float32)\n",
            " array([[-0.0328275 , -0.13501327, -0.03099092, ...,  0.06456453,\n",
            "          0.21395871,  1.        ],\n",
            "        [ 0.16868521, -0.06022608, -0.02778458, ...,  0.26842085,\n",
            "          0.15014115,  1.        ],\n",
            "        [ 0.13720666, -0.03089164, -0.01538443, ...,  0.3634766 ,\n",
            "          0.04174133,  1.        ],\n",
            "        ...,\n",
            "        [-0.12600517,  0.11200277,  0.22904441, ...,  0.0818699 ,\n",
            "         -0.00189119,  1.        ],\n",
            "        [-0.25455585,  0.09200066,  0.28614825, ...,  0.06838141,\n",
            "         -0.03440831,  1.        ],\n",
            "        [-0.2847185 ,  0.08746713,  0.2727526 , ...,  0.0533959 ,\n",
            "         -0.01080056,  1.        ]], dtype=float32)\n",
            " array([[-0.03145939, -0.16085407, -0.04965286, ...,  0.05651963,\n",
            "          0.21146949,  1.        ],\n",
            "        [ 0.14584738, -0.10757039, -0.07179609, ...,  0.2929549 ,\n",
            "          0.15524235,  1.        ],\n",
            "        [ 0.10971302, -0.11246884, -0.07653057, ...,  0.37170273,\n",
            "          0.09428091,  1.        ],\n",
            "        ...,\n",
            "        [-0.13885824,  0.00570882,  0.19878095, ...,  0.10876229,\n",
            "          0.00536679,  1.        ],\n",
            "        [-0.22412212,  0.00822943,  0.22267668, ...,  0.08534726,\n",
            "         -0.03029137,  1.        ],\n",
            "        [-0.27117574,  0.00805163,  0.24480547, ...,  0.03691016,\n",
            "         -0.0218458 ,  1.        ]], dtype=float32)\n",
            " array([[-0.02268122, -0.1368224 , -0.03042446, ...,  0.05790232,\n",
            "          0.21727245,  1.        ],\n",
            "        [ 0.15270302, -0.0452668 , -0.01433461, ...,  0.26152533,\n",
            "          0.13648741,  1.        ],\n",
            "        [ 0.14112751,  0.00697511,  0.0037528 , ...,  0.3461324 ,\n",
            "         -0.00641594,  1.        ],\n",
            "        ...,\n",
            "        [-0.09666932,  0.1532691 ,  0.22608325, ...,  0.07187917,\n",
            "         -0.00450987,  1.        ],\n",
            "        [-0.2437151 ,  0.13414581,  0.31545866, ...,  0.06723938,\n",
            "         -0.03145377,  1.        ],\n",
            "        [-0.2791093 ,  0.10258302,  0.28865886, ...,  0.07243279,\n",
            "         -0.00132172,  1.        ]], dtype=float32)\n",
            " array([[-0.00239548, -0.18217301, -0.08319092, ...,  0.08676971,\n",
            "          0.2113053 ,  1.        ],\n",
            "        [ 0.21838231, -0.14993334, -0.13970387, ...,  0.3404688 ,\n",
            "          0.15779813,  1.        ],\n",
            "        [ 0.18831268, -0.14814065, -0.15628007, ...,  0.44547814,\n",
            "          0.08639205,  1.        ],\n",
            "        ...,\n",
            "        [ 0.00281352, -0.06926995,  0.05366249, ...,  0.20120528,\n",
            "          0.02196268,  1.        ],\n",
            "        [-0.1267778 , -0.03523651,  0.13905291, ...,  0.16715957,\n",
            "         -0.01119935,  1.        ],\n",
            "        [-0.2258127 , -0.03573944,  0.18056743, ...,  0.0807282 ,\n",
            "         -0.01994375,  1.        ]], dtype=float32)\n",
            " array([[-0.02225601, -0.13914259, -0.02998795, ...,  0.0485435 ,\n",
            "          0.21014105,  1.        ],\n",
            "        [ 0.14720309, -0.0494111 , -0.02058093, ...,  0.27506235,\n",
            "          0.13050264,  1.        ],\n",
            "        [ 0.13044369, -0.00943302, -0.00602507, ...,  0.36299247,\n",
            "          0.01199605,  1.        ],\n",
            "        ...,\n",
            "        [-0.08658994,  0.09570027,  0.20336004, ...,  0.08981007,\n",
            "          0.00714623,  1.        ],\n",
            "        [-0.22608894,  0.08842222,  0.29856336, ...,  0.0714362 ,\n",
            "         -0.02691715,  1.        ],\n",
            "        [-0.28804725,  0.08114675,  0.2898293 , ...,  0.05617496,\n",
            "         -0.0146734 ,  1.        ]], dtype=float32)\n",
            " array([[-0.02296563, -0.12910253, -0.02950166, ...,  0.04921945,\n",
            "          0.21635582,  1.        ],\n",
            "        [ 0.12699868, -0.04749877, -0.0078197 , ...,  0.23056066,\n",
            "          0.13819571,  1.        ],\n",
            "        [ 0.12289878,  0.00833472,  0.01510055, ...,  0.3107667 ,\n",
            "         -0.0090776 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.11998826,  0.1551555 ,  0.25838605, ...,  0.0523615 ,\n",
            "         -0.00624647,  1.        ],\n",
            "        [-0.25305003,  0.13882597,  0.34678417, ...,  0.05293529,\n",
            "         -0.03089179,  1.        ],\n",
            "        [-0.29208377,  0.10073031,  0.3055996 , ...,  0.05504682,\n",
            "         -0.00315082,  1.        ]], dtype=float32)\n",
            " array([[-0.01778642, -0.12645619, -0.02664015, ...,  0.04445148,\n",
            "          0.21146654,  1.        ],\n",
            "        [ 0.14549221, -0.0351176 , -0.00194769, ...,  0.2597273 ,\n",
            "          0.12223681,  1.        ],\n",
            "        [ 0.14805844,  0.02588911,  0.01300113, ...,  0.3341831 ,\n",
            "         -0.0134396 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.04084318,  0.12257966,  0.21101542, ...,  0.07796495,\n",
            "          0.01543138,  1.        ],\n",
            "        [-0.22689348,  0.12816413,  0.3409348 , ...,  0.07696061,\n",
            "         -0.01322433,  1.        ],\n",
            "        [-0.27581313,  0.10759062,  0.29965135, ...,  0.05597256,\n",
            "          0.00550278,  1.        ]], dtype=float32)\n",
            " array([[-0.02438894, -0.15482524, -0.06067955, ...,  0.04907952,\n",
            "          0.18095066,  1.        ],\n",
            "        [ 0.10042287, -0.13305989, -0.05455398, ...,  0.23494384,\n",
            "          0.14475147,  1.        ],\n",
            "        [ 0.03110962, -0.13487145, -0.07663831, ...,  0.32909495,\n",
            "          0.08843786,  1.        ],\n",
            "        ...,\n",
            "        [-0.21635379,  0.05466101,  0.22331384, ..., -0.03537429,\n",
            "         -0.09125253,  1.        ],\n",
            "        [-0.24815965,  0.07437647,  0.22853085, ..., -0.02755118,\n",
            "         -0.08771004,  1.        ],\n",
            "        [-0.20980735,  0.05580416,  0.24600387, ..., -0.04061862,\n",
            "         -0.0598426 ,  1.        ]], dtype=float32)\n",
            " array([[-0.03285024, -0.15013637, -0.05291598, ...,  0.06152605,\n",
            "          0.20646782,  1.        ],\n",
            "        [ 0.1365485 , -0.11106397, -0.06173865, ...,  0.27902853,\n",
            "          0.16371755,  1.        ],\n",
            "        [ 0.07510109, -0.10815027, -0.05901173, ...,  0.38389227,\n",
            "          0.08780156,  1.        ],\n",
            "        ...,\n",
            "        [-0.19432588,  0.03029116,  0.20490864, ...,  0.09385598,\n",
            "         -0.03927898,  1.        ],\n",
            "        [-0.27089503,  0.05171657,  0.21162668, ...,  0.08040889,\n",
            "         -0.06611237,  1.        ],\n",
            "        [-0.27158344,  0.04329588,  0.2422961 , ...,  0.0249258 ,\n",
            "         -0.03466797,  1.        ]], dtype=float32)\n",
            " array([[-0.0089506 , -0.10888892, -0.04913377, ...,  0.0295855 ,\n",
            "          0.1975909 ,  1.        ],\n",
            "        [ 0.1476206 , -0.00133797, -0.02420055, ...,  0.23115084,\n",
            "          0.05481748,  1.        ],\n",
            "        [ 0.16072719,  0.05844066, -0.02054308, ...,  0.29546162,\n",
            "         -0.08687877,  1.        ],\n",
            "        ...,\n",
            "        [ 0.04845535,  0.09332981,  0.07169899, ...,  0.01997325,\n",
            "          0.04491793,  1.        ],\n",
            "        [-0.1706241 ,  0.12845434,  0.32414383, ...,  0.06332026,\n",
            "         -0.01672988,  1.        ],\n",
            "        [-0.2690262 ,  0.09226496,  0.3049321 , ...,  0.05097986,\n",
            "         -0.00696227,  1.        ]], dtype=float32)\n",
            " array([[-0.03666857, -0.15830943, -0.06183608, ...,  0.06359263,\n",
            "          0.20666258,  1.        ],\n",
            "        [ 0.12612437, -0.12878586, -0.08050807, ...,  0.29770055,\n",
            "          0.15139322,  1.        ],\n",
            "        [ 0.06639121, -0.12627152, -0.08986894, ...,  0.39858833,\n",
            "          0.07715318,  1.        ],\n",
            "        ...,\n",
            "        [-0.18231104,  0.01812561,  0.1852739 , ...,  0.1065155 ,\n",
            "         -0.04862437,  1.        ],\n",
            "        [-0.23705582,  0.03226755,  0.18561907, ...,  0.0898207 ,\n",
            "         -0.07044501,  1.        ],\n",
            "        [-0.2600498 ,  0.00480263,  0.22524232, ...,  0.02741477,\n",
            "         -0.0372179 ,  1.        ]], dtype=float32)\n",
            " array([[-0.00446843, -0.11814194, -0.05279792, ...,  0.04874803,\n",
            "          0.2133169 ,  1.        ],\n",
            "        [ 0.14818391, -0.00782208, -0.03349764, ...,  0.22573239,\n",
            "          0.10948468,  1.        ],\n",
            "        [ 0.15226261,  0.04797788, -0.01923409, ...,  0.308622  ,\n",
            "         -0.05312546,  1.        ],\n",
            "        ...,\n",
            "        [ 0.04817954,  0.12207913,  0.09517533, ...,  0.0287824 ,\n",
            "          0.0464813 ,  1.        ],\n",
            "        [-0.17459199,  0.1429648 ,  0.2962546 , ...,  0.066497  ,\n",
            "         -0.00374374,  1.        ],\n",
            "        [-0.2580334 ,  0.10454911,  0.2845838 , ...,  0.06690774,\n",
            "          0.00253146,  1.        ]], dtype=float32)\n",
            " array([[-3.2556355e-02, -1.2572412e-01, -2.8697072e-02, ...,\n",
            "          6.1144259e-02,  2.1114340e-01,  1.0000000e+00],\n",
            "        [ 1.4668386e-01, -5.2171364e-02, -2.2656430e-02, ...,\n",
            "          2.5333345e-01,  1.4532247e-01,  1.0000000e+00],\n",
            "        [ 1.2512656e-01, -2.1004315e-02, -1.7908681e-04, ...,\n",
            "          3.4523636e-01,  3.1611606e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.5077704e-01,  1.2665276e-01,  2.5810343e-01, ...,\n",
            "          6.8862975e-02, -1.7656459e-02,  1.0000000e+00],\n",
            "        [-2.6116559e-01,  1.0680261e-01,  3.1329787e-01, ...,\n",
            "          6.5198183e-02, -4.1195169e-02,  1.0000000e+00],\n",
            "        [-2.9525530e-01,  9.1231830e-02,  2.8734869e-01, ...,\n",
            "          4.3075752e-02, -1.3016892e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.0333879 , -0.14646636, -0.04114733, ...,  0.05500285,\n",
            "          0.2144808 ,  1.        ],\n",
            "        [ 0.14852841, -0.08307905, -0.06550734, ...,  0.2836156 ,\n",
            "          0.15631229,  1.        ],\n",
            "        [ 0.10645127, -0.07504368, -0.07081989, ...,  0.3785138 ,\n",
            "          0.05924631,  1.        ],\n",
            "        ...,\n",
            "        [-0.13422295,  0.03699474,  0.20576482, ...,  0.10691633,\n",
            "          0.024183  ,  1.        ],\n",
            "        [-0.24470983,  0.03562671,  0.26049727, ...,  0.08040851,\n",
            "         -0.02755664,  1.        ],\n",
            "        [-0.29448876,  0.04008947,  0.26690212, ...,  0.03724464,\n",
            "         -0.01971132,  1.        ]], dtype=float32)\n",
            " array([[-0.03717034, -0.15487479, -0.05429149, ...,  0.05998304,\n",
            "          0.2100968 ,  1.        ],\n",
            "        [ 0.14085196, -0.11585267, -0.07477669, ...,  0.2889399 ,\n",
            "          0.1629395 ,  1.        ],\n",
            "        [ 0.0826325 , -0.11465187, -0.07865882, ...,  0.39125404,\n",
            "          0.08738364,  1.        ],\n",
            "        ...,\n",
            "        [-0.17734234,  0.01842542,  0.2040422 , ...,  0.11326569,\n",
            "         -0.02530393,  1.        ],\n",
            "        [-0.25842777,  0.04154824,  0.20859168, ...,  0.08893543,\n",
            "         -0.06387255,  1.        ],\n",
            "        [-0.2762257 ,  0.01978214,  0.24222554, ...,  0.02581203,\n",
            "         -0.0344581 ,  1.        ]], dtype=float32)\n",
            " array([[-0.0336393 , -0.12539811, -0.03146144, ...,  0.05483415,\n",
            "          0.20751233,  1.        ],\n",
            "        [ 0.1356755 , -0.0614607 , -0.03728278, ...,  0.27076572,\n",
            "          0.14000796,  1.        ],\n",
            "        [ 0.10867351, -0.03773299, -0.03293828, ...,  0.36652443,\n",
            "          0.03326073,  1.        ],\n",
            "        ...,\n",
            "        [-0.14535618,  0.08727865,  0.23987915, ...,  0.09648173,\n",
            "         -0.00218932,  1.        ],\n",
            "        [-0.26086792,  0.07715517,  0.29857573, ...,  0.07471856,\n",
            "         -0.03596871,  1.        ],\n",
            "        [-0.3053042 ,  0.07950476,  0.28499228, ...,  0.03663596,\n",
            "         -0.01729793,  1.        ]], dtype=float32)\n",
            " array([[-0.03101509, -0.1498019 , -0.05729734, ...,  0.05671167,\n",
            "          0.19794136,  1.        ],\n",
            "        [ 0.11975449, -0.11994053, -0.06375244, ...,  0.24640249,\n",
            "          0.15868361,  1.        ],\n",
            "        [ 0.05387842, -0.11025222, -0.06727825, ...,  0.35581395,\n",
            "          0.08158293,  1.        ],\n",
            "        ...,\n",
            "        [-0.22605786,  0.0460932 ,  0.19379157, ...,  0.03789191,\n",
            "         -0.07259159,  1.        ],\n",
            "        [-0.2788449 ,  0.06465357,  0.21287726, ...,  0.04722018,\n",
            "         -0.07383545,  1.        ],\n",
            "        [-0.25693664,  0.04430884,  0.24236798, ...,  0.00389493,\n",
            "         -0.04734744,  1.        ]], dtype=float32)\n",
            " array([[-0.02084407, -0.13299084, -0.02814703, ...,  0.0509769 ,\n",
            "          0.21343417,  1.        ],\n",
            "        [ 0.13985944, -0.04385815, -0.00739694, ...,  0.24602982,\n",
            "          0.13042426,  1.        ],\n",
            "        [ 0.13809504,  0.01750345,  0.01255802, ...,  0.32490534,\n",
            "         -0.01531106,  1.        ],\n",
            "        ...,\n",
            "        [-0.07681226,  0.14845322,  0.22027017, ...,  0.05717247,\n",
            "          0.01091978,  1.        ],\n",
            "        [-0.24104057,  0.13808449,  0.3310934 , ...,  0.05992776,\n",
            "         -0.01638676,  1.        ],\n",
            "        [-0.28152603,  0.1035581 ,  0.2963377 , ...,  0.06333285,\n",
            "          0.00397496,  1.        ]], dtype=float32)\n",
            " array([[-2.1871775e-02, -1.3559297e-01, -2.8791467e-02, ...,\n",
            "          5.0658505e-02,  2.1625368e-01,  1.0000000e+00],\n",
            "        [ 1.3819921e-01, -3.6318917e-02, -3.9881266e-05, ...,\n",
            "          2.3540293e-01,  1.2788874e-01,  1.0000000e+00],\n",
            "        [ 1.3593541e-01,  2.2482596e-02,  2.3177011e-02, ...,\n",
            "          3.0770975e-01, -9.7789727e-03,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-6.3690953e-02,  1.5104571e-01,  2.1280241e-01, ...,\n",
            "          4.6791829e-02,  8.4836483e-03,  1.0000000e+00],\n",
            "        [-2.3571357e-01,  1.4274159e-01,  3.2910940e-01, ...,\n",
            "          5.1271260e-02, -2.3928257e-02,  1.0000000e+00],\n",
            "        [-2.7759281e-01,  1.0503897e-01,  2.9767990e-01, ...,\n",
            "          5.9458897e-02, -6.6378753e-04,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02750656, -0.13902315, -0.02766697, ...,  0.05354372,\n",
            "          0.21586345,  1.        ],\n",
            "        [ 0.1460187 , -0.04903478, -0.01141072, ...,  0.24945396,\n",
            "          0.14326991,  1.        ],\n",
            "        [ 0.13350022, -0.00462159,  0.01365329, ...,  0.33017448,\n",
            "          0.01351366,  1.        ],\n",
            "        ...,\n",
            "        [-0.12638694,  0.14504416,  0.24056558, ...,  0.05152893,\n",
            "         -0.00676483,  1.        ],\n",
            "        [-0.2507546 ,  0.12212608,  0.3149006 , ...,  0.05308526,\n",
            "         -0.03305648,  1.        ],\n",
            "        [-0.28851384,  0.0950767 ,  0.29059955, ...,  0.05567019,\n",
            "         -0.00739002,  1.        ]], dtype=float32)\n",
            " array([[-0.03818538, -0.14898574, -0.04481905, ...,  0.0611383 ,\n",
            "          0.21631691,  1.        ],\n",
            "        [ 0.15086734, -0.09781709, -0.05822209, ...,  0.28166297,\n",
            "          0.16930492,  1.        ],\n",
            "        [ 0.09784087, -0.08789875, -0.05717806, ...,  0.3811175 ,\n",
            "          0.08004008,  1.        ],\n",
            "        ...,\n",
            "        [-0.16812094,  0.02844981,  0.22647983, ...,  0.09386489,\n",
            "         -0.00291579,  1.        ],\n",
            "        [-0.26855242,  0.04154604,  0.24121183, ...,  0.07390713,\n",
            "         -0.04533592,  1.        ],\n",
            "        [-0.28653762,  0.04335836,  0.25795653, ...,  0.02904651,\n",
            "         -0.02236015,  1.        ]], dtype=float32)\n",
            " array([[-2.76312493e-02, -1.63131177e-01, -5.43858334e-02, ...,\n",
            "          5.91125078e-02,  2.11066097e-01,  1.00000000e+00],\n",
            "        [ 1.48447990e-01, -1.13568835e-01, -7.97445029e-02, ...,\n",
            "          2.95876235e-01,  1.53014332e-01,  1.00000000e+00],\n",
            "        [ 1.04347616e-01, -1.17433265e-01, -8.55437890e-02, ...,\n",
            "          3.87663782e-01,  7.90476874e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.17408693e-01, -2.55971472e-03,  1.85246795e-01, ...,\n",
            "          1.20077118e-01,  1.05352728e-02,  1.00000000e+00],\n",
            "        [-2.12437063e-01,  6.51258416e-03,  2.07204208e-01, ...,\n",
            "          9.17508379e-02, -3.24712768e-02,  1.00000000e+00],\n",
            "        [-2.59960473e-01,  8.85982357e-04,  2.34579027e-01, ...,\n",
            "          3.95771898e-02, -2.57599652e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.03412068, -0.13850042, -0.03505816, ...,  0.05116812,\n",
            "          0.2097725 ,  1.        ],\n",
            "        [ 0.14255813, -0.07409268, -0.05209228, ...,  0.27028537,\n",
            "          0.14892045,  1.        ],\n",
            "        [ 0.10400998, -0.06067442, -0.05461182, ...,  0.3603555 ,\n",
            "          0.05399377,  1.        ],\n",
            "        ...,\n",
            "        [-0.14482504,  0.06029013,  0.22464886, ...,  0.09311247,\n",
            "          0.01762944,  1.        ],\n",
            "        [-0.2528159 ,  0.04777799,  0.27840412, ...,  0.06805088,\n",
            "         -0.02741494,  1.        ],\n",
            "        [-0.3012873 ,  0.05683375,  0.2779629 , ...,  0.03494003,\n",
            "         -0.01946898,  1.        ]], dtype=float32)\n",
            " array([[-0.02886548, -0.12449797, -0.03036177, ...,  0.05629142,\n",
            "          0.20674373,  1.        ],\n",
            "        [ 0.14118113, -0.06020146, -0.03244468, ...,  0.2699048 ,\n",
            "          0.13714361,  1.        ],\n",
            "        [ 0.12132673, -0.03020318, -0.02170702, ...,  0.36947125,\n",
            "          0.01912845,  1.        ],\n",
            "        ...,\n",
            "        [-0.11765094,  0.09910337,  0.22180077, ...,  0.09992595,\n",
            "          0.00520168,  1.        ],\n",
            "        [-0.25070718,  0.09379808,  0.30131352, ...,  0.07742674,\n",
            "         -0.03064987,  1.        ],\n",
            "        [-0.30030936,  0.08563938,  0.28550544, ...,  0.04727111,\n",
            "         -0.01662379,  1.        ]], dtype=float32)\n",
            " array([[-0.02221464, -0.14394395, -0.02767006, ...,  0.05423588,\n",
            "          0.21872294,  1.        ],\n",
            "        [ 0.15990902, -0.05164197, -0.01347519, ...,  0.2564385 ,\n",
            "          0.14355691,  1.        ],\n",
            "        [ 0.13958666, -0.00898025,  0.01122297, ...,  0.33993158,\n",
            "          0.01652662,  1.        ],\n",
            "        ...,\n",
            "        [-0.09064334,  0.131477  ,  0.21016957, ...,  0.05373463,\n",
            "          0.00778559,  1.        ],\n",
            "        [-0.23041108,  0.11469637,  0.29503095, ...,  0.05496695,\n",
            "         -0.02792651,  1.        ],\n",
            "        [-0.27722627,  0.09217588,  0.2805818 , ...,  0.06469619,\n",
            "         -0.00709259,  1.        ]], dtype=float32)\n",
            " array([[-1.62547100e-02, -1.31162897e-01, -2.76014414e-02, ...,\n",
            "          4.93635163e-02,  2.12308109e-01,  1.00000000e+00],\n",
            "        [ 1.54924601e-01, -3.99009734e-02, -8.47013481e-03, ...,\n",
            "          2.73337394e-01,  1.29686207e-01,  1.00000000e+00],\n",
            "        [ 1.53393403e-01,  1.47189535e-02,  4.68068197e-03, ...,\n",
            "          3.56161654e-01,  4.87617217e-04,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-6.11137077e-02,  1.20918371e-01,  2.17081830e-01, ...,\n",
            "          9.60127562e-02,  1.51938153e-02,  1.00000000e+00],\n",
            "        [-2.26123169e-01,  1.19559214e-01,  3.25694621e-01, ...,\n",
            "          8.70376602e-02, -1.81722827e-02,  1.00000000e+00],\n",
            "        [-2.75623590e-01,  1.00747071e-01,  2.92828739e-01, ...,\n",
            "          6.30187541e-02,  2.09458033e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.00203614, -0.14430082, -0.07249292, ...,  0.03645103,\n",
            "          0.1673165 ,  1.        ],\n",
            "        [ 0.09609808, -0.12222248, -0.07003035, ...,  0.195878  ,\n",
            "          0.13859472,  1.        ],\n",
            "        [ 0.035801  , -0.1201084 , -0.09612063, ...,  0.27369064,\n",
            "          0.09515563,  1.        ],\n",
            "        ...,\n",
            "        [-0.12933055,  0.02802032,  0.28814837, ..., -0.0490549 ,\n",
            "         -0.10840733,  1.        ],\n",
            "        [-0.22313534,  0.09176616,  0.25234067, ..., -0.04568714,\n",
            "         -0.09880371,  1.        ],\n",
            "        [-0.17063633,  0.11416283,  0.25786182, ..., -0.07237053,\n",
            "         -0.07836438,  1.        ]], dtype=float32)\n",
            " array([[-0.01702367, -0.14696154, -0.06850561, ...,  0.04637748,\n",
            "          0.18078078,  1.        ],\n",
            "        [ 0.10440655, -0.12604195, -0.06266817, ...,  0.2151966 ,\n",
            "          0.14980498,  1.        ],\n",
            "        [ 0.03595306, -0.12478966, -0.07724659, ...,  0.32291615,\n",
            "          0.0882856 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.20562996,  0.04679383,  0.2362845 , ..., -0.04836201,\n",
            "         -0.09270799,  1.        ],\n",
            "        [-0.24787742,  0.07429554,  0.24161267, ..., -0.03931066,\n",
            "         -0.08914664,  1.        ],\n",
            "        [-0.19759843,  0.07815223,  0.25264156, ..., -0.04039843,\n",
            "         -0.06498374,  1.        ]], dtype=float32)\n",
            " array([[-0.03254446, -0.14841296, -0.03520915, ...,  0.06004139,\n",
            "          0.21676832,  1.        ],\n",
            "        [ 0.16530757, -0.0729377 , -0.04100109, ...,  0.2721064 ,\n",
            "          0.1663907 ,  1.        ],\n",
            "        [ 0.11943004, -0.05315332, -0.03067736, ...,  0.36183134,\n",
            "          0.06746417,  1.        ],\n",
            "        ...,\n",
            "        [-0.13186213,  0.07827557,  0.22226751, ...,  0.08227494,\n",
            "          0.01399958,  1.        ],\n",
            "        [-0.25733176,  0.06486786,  0.2715733 , ...,  0.06557511,\n",
            "         -0.03822632,  1.        ],\n",
            "        [-0.2906703 ,  0.05751087,  0.26931667, ...,  0.04269058,\n",
            "         -0.0213002 ,  1.        ]], dtype=float32)\n",
            " array([[-0.02358875, -0.1295714 , -0.02442043, ...,  0.04340508,\n",
            "          0.20874974,  1.        ],\n",
            "        [ 0.13293986, -0.04106189, -0.00289147, ...,  0.252484  ,\n",
            "          0.1281447 ,  1.        ],\n",
            "        [ 0.12223987,  0.00937365,  0.02038899, ...,  0.3344926 ,\n",
            "          0.00343188,  1.        ],\n",
            "        ...,\n",
            "        [-0.10729261,  0.13057432,  0.2460707 , ...,  0.0740962 ,\n",
            "         -0.00504111,  1.        ],\n",
            "        [-0.25425154,  0.12029061,  0.3426299 , ...,  0.06126398,\n",
            "         -0.03238735,  1.        ],\n",
            "        [-0.3014602 ,  0.09284016,  0.30512366, ...,  0.04801406,\n",
            "         -0.01356607,  1.        ]], dtype=float32)\n",
            " array([[-0.01477761, -0.12275053, -0.03565429, ...,  0.04553136,\n",
            "          0.21547523,  1.        ],\n",
            "        [ 0.1362724 , -0.02108545, -0.01439015, ...,  0.23300436,\n",
            "          0.12471341,  1.        ],\n",
            "        [ 0.14109854,  0.04058022,  0.00807565, ...,  0.31284797,\n",
            "         -0.03001533,  1.        ],\n",
            "        ...,\n",
            "        [-0.01371499,  0.1321714 ,  0.16546471, ...,  0.04285989,\n",
            "          0.02328623,  1.        ],\n",
            "        [-0.20797646,  0.13772494,  0.3219982 , ...,  0.05258898,\n",
            "         -0.0105988 ,  1.        ],\n",
            "        [-0.26914018,  0.09968583,  0.29527497, ...,  0.0606435 ,\n",
            "         -0.00373883,  1.        ]], dtype=float32)\n",
            " array([[-0.01880161, -0.14755398, -0.03450478, ...,  0.05681061,\n",
            "          0.22038174,  1.        ],\n",
            "        [ 0.16727418, -0.0487203 , -0.02929938, ...,  0.27228254,\n",
            "          0.14221407,  1.        ],\n",
            "        [ 0.14685504, -0.01380308, -0.00916707, ...,  0.3558128 ,\n",
            "          0.01704977,  1.        ],\n",
            "        ...,\n",
            "        [-0.05135368,  0.10115176,  0.15885057, ...,  0.06109716,\n",
            "          0.02274592,  1.        ],\n",
            "        [-0.20687954,  0.09703857,  0.26557007, ...,  0.05985159,\n",
            "         -0.02921306,  1.        ],\n",
            "        [-0.2666497 ,  0.07472734,  0.26889417, ...,  0.06719336,\n",
            "         -0.01412373,  1.        ]], dtype=float32)\n",
            " array([[-3.2078370e-02, -1.5021740e-01, -4.0992688e-02, ...,\n",
            "          6.1970983e-02,  2.1797320e-01,  1.0000000e+00],\n",
            "        [ 1.6833924e-01, -7.9374626e-02, -5.4502975e-02, ...,\n",
            "          2.8696930e-01,  1.6513966e-01,  1.0000000e+00],\n",
            "        [ 1.2339974e-01, -6.6018119e-02, -4.8858214e-02, ...,\n",
            "          3.8119048e-01,  6.7405172e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.4040321e-01,  4.8622198e-02,  2.1850057e-01, ...,\n",
            "          8.2022242e-02,  2.5784236e-04,  1.0000000e+00],\n",
            "        [-2.4322325e-01,  5.2371264e-02,  2.5002986e-01, ...,\n",
            "          7.3669344e-02, -3.8192261e-02,  1.0000000e+00],\n",
            "        [-2.8261223e-01,  4.0713195e-02,  2.5855127e-01, ...,\n",
            "          3.8047910e-02, -2.0551918e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-1.17255533e-02, -1.22827418e-01, -3.09224948e-02, ...,\n",
            "          4.55951132e-02,  2.11059213e-01,  2.00000000e+00],\n",
            "        [ 1.55884922e-01, -2.33472697e-02, -1.15256859e-02, ...,\n",
            "          2.62945831e-01,  1.17339373e-01,  2.00000000e+00],\n",
            "        [ 1.61541626e-01,  4.30358164e-02,  2.15177028e-03, ...,\n",
            "          3.36109191e-01, -2.40114368e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.75578683e-03,  1.20297931e-01,  1.71115667e-01, ...,\n",
            "          7.55768195e-02,  3.32774445e-02,  2.00000000e+00],\n",
            "        [-2.04998478e-01,  1.24247685e-01,  3.28625530e-01, ...,\n",
            "          8.29735845e-02, -2.31205323e-03,  2.00000000e+00],\n",
            "        [-2.62021065e-01,  1.07166938e-01,  2.93840945e-01, ...,\n",
            "          6.09917194e-02,  7.03007542e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02452481, -0.1580924 , -0.06325781, ...,  0.05348477,\n",
            "          0.18438265,  2.        ],\n",
            "        [ 0.11129352, -0.13333535, -0.06279344, ...,  0.24354734,\n",
            "          0.14951049,  2.        ],\n",
            "        [ 0.0435982 , -0.13366832, -0.07917896, ...,  0.3410806 ,\n",
            "          0.08978602,  2.        ],\n",
            "        ...,\n",
            "        [-0.22415729,  0.04971977,  0.20273036, ..., -0.00737837,\n",
            "         -0.08866555,  2.        ],\n",
            "        [-0.26265922,  0.06759165,  0.20953698, ...,  0.00410016,\n",
            "         -0.08328262,  2.        ],\n",
            "        [-0.22577104,  0.03741316,  0.2346817 , ..., -0.02523686,\n",
            "         -0.0555364 ,  2.        ]], dtype=float32)\n",
            " array([[-0.03627414, -0.15161663, -0.04899341, ...,  0.06530434,\n",
            "          0.21155344,  2.        ],\n",
            "        [ 0.15872571, -0.10268603, -0.05855017, ...,  0.29826385,\n",
            "          0.16594444,  2.        ],\n",
            "        [ 0.10501091, -0.09552787, -0.05671069, ...,  0.4015281 ,\n",
            "          0.0778999 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.16473278,  0.03435559,  0.21576667, ...,  0.10745205,\n",
            "         -0.01116336,  2.        ],\n",
            "        [-0.26095748,  0.05643121,  0.22251926, ...,  0.0864609 ,\n",
            "         -0.05223651,  2.        ],\n",
            "        [-0.27087423,  0.04032133,  0.24408753, ...,  0.03381633,\n",
            "         -0.02545036,  2.        ]], dtype=float32)\n",
            " array([[-2.4939422e-02, -1.3292848e-01, -2.4406973e-02, ...,\n",
            "          4.4255268e-02,  2.0841897e-01,  2.0000000e+00],\n",
            "        [ 1.3504113e-01, -4.5279048e-02, -2.4268590e-03, ...,\n",
            "          2.4951661e-01,  1.3070716e-01,  2.0000000e+00],\n",
            "        [ 1.2007419e-01, -8.3314267e-04,  2.0617727e-02, ...,\n",
            "          3.3244476e-01,  9.1180373e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1247543e-01,  1.2968808e-01,  2.4567109e-01, ...,\n",
            "          7.3087044e-02, -2.1623403e-03,  2.0000000e+00],\n",
            "        [-2.5571692e-01,  1.2216800e-01,  3.3720601e-01, ...,\n",
            "          5.9609678e-02, -3.2654107e-02,  2.0000000e+00],\n",
            "        [-3.0304223e-01,  9.3342759e-02,  3.0124202e-01, ...,\n",
            "          4.5531545e-02, -1.4059771e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.57124212e-02, -1.37678728e-01, -2.75823697e-02, ...,\n",
            "          5.28977364e-02,  2.15140745e-01,  2.00000000e+00],\n",
            "        [ 1.51528448e-01, -4.70893681e-02, -8.12419783e-03, ...,\n",
            "          2.58076727e-01,  1.35931417e-01,  2.00000000e+00],\n",
            "        [ 1.35759234e-01,  5.87299350e-04,  1.70746502e-02, ...,\n",
            "          3.39030534e-01,  9.95391607e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.24688581e-01,  1.42474458e-01,  2.46376306e-01, ...,\n",
            "          6.17584214e-02, -1.15233101e-02,  2.00000000e+00],\n",
            "        [-2.50203907e-01,  1.25489488e-01,  3.20384085e-01, ...,\n",
            "          5.99763878e-02, -3.71855311e-02,  2.00000000e+00],\n",
            "        [-2.90288389e-01,  9.37921926e-02,  2.95369714e-01, ...,\n",
            "          5.79355918e-02, -1.10051995e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02076443, -0.12445816, -0.02650813, ...,  0.03748032,\n",
            "          0.2076035 ,  2.        ],\n",
            "        [ 0.12356376, -0.02424166,  0.00640942, ...,  0.22847977,\n",
            "          0.11285189,  2.        ],\n",
            "        [ 0.1225436 ,  0.0363031 ,  0.02718842, ...,  0.30279246,\n",
            "         -0.02254261,  2.        ],\n",
            "        ...,\n",
            "        [-0.04383318,  0.13592292,  0.20867425, ...,  0.0391182 ,\n",
            "          0.02335222,  2.        ],\n",
            "        [-0.23185806,  0.12688823,  0.35179836, ...,  0.04387961,\n",
            "         -0.01291472,  2.        ],\n",
            "        [-0.29118806,  0.09903164,  0.30936676, ...,  0.04061497,\n",
            "         -0.00389168,  2.        ]], dtype=float32)\n",
            " array([[-0.01652215, -0.11608578, -0.03778841, ...,  0.04734511,\n",
            "          0.21286939,  2.        ],\n",
            "        [ 0.13548103, -0.02044505, -0.01561737, ...,  0.2428149 ,\n",
            "          0.11232271,  2.        ],\n",
            "        [ 0.14351231,  0.04840067,  0.00518003, ...,  0.31243047,\n",
            "         -0.04535107,  2.        ],\n",
            "        ...,\n",
            "        [-0.02169414,  0.13638294,  0.18179055, ...,  0.04813622,\n",
            "          0.0100375 ,  2.        ],\n",
            "        [-0.21895885,  0.13756584,  0.33572578, ...,  0.06580136,\n",
            "         -0.01500245,  2.        ],\n",
            "        [-0.2717496 ,  0.10782441,  0.30496997, ...,  0.06798729,\n",
            "          0.0067237 ,  2.        ]], dtype=float32)\n",
            " array([[-0.03395514, -0.14447132, -0.03324958, ...,  0.05882109,\n",
            "          0.2117377 ,  2.        ],\n",
            "        [ 0.16430365, -0.06914343, -0.03584979, ...,  0.26845998,\n",
            "          0.15222892,  2.        ],\n",
            "        [ 0.12239945, -0.04812844, -0.0233942 , ...,  0.35400167,\n",
            "          0.0518944 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.14779297,  0.08557077,  0.23910731, ...,  0.07323747,\n",
            "         -0.00362661,  2.        ],\n",
            "        [-0.26188895,  0.06800286,  0.27909443, ...,  0.06386506,\n",
            "         -0.04171513,  2.        ],\n",
            "        [-0.2876687 ,  0.07144515,  0.27100027, ...,  0.04565222,\n",
            "         -0.01911933,  2.        ]], dtype=float32)\n",
            " array([[ 0.00657338, -0.10934892, -0.05444293, ...,  0.03964962,\n",
            "          0.20510148,  2.        ],\n",
            "        [ 0.18573178, -0.00241047, -0.04625988, ...,  0.2551872 ,\n",
            "          0.05645086,  2.        ],\n",
            "        [ 0.198127  ,  0.0562714 , -0.0450359 , ...,  0.31480742,\n",
            "         -0.07841921,  2.        ],\n",
            "        ...,\n",
            "        [ 0.11308608,  0.0679331 ,  0.01568196, ...,  0.06408984,\n",
            "          0.07244489,  2.        ],\n",
            "        [-0.1240731 ,  0.12109364,  0.28819096, ...,  0.11278326,\n",
            "         -0.00497006,  2.        ],\n",
            "        [-0.23702429,  0.10291395,  0.28212672, ...,  0.06844807,\n",
            "          0.00495235,  2.        ]], dtype=float32)\n",
            " array([[-1.19837904e-02, -1.21344559e-01, -3.20382304e-02, ...,\n",
            "          4.63971682e-02,  2.09740534e-01,  2.00000000e+00],\n",
            "        [ 1.49851426e-01, -2.23231744e-02, -1.33220702e-02, ...,\n",
            "          2.59419918e-01,  1.12829894e-01,  2.00000000e+00],\n",
            "        [ 1.57352686e-01,  4.61911596e-02, -8.27614567e-04, ...,\n",
            "          3.32041740e-01, -3.09966225e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 5.14029618e-03,  1.22721620e-01,  1.66899607e-01, ...,\n",
            "          6.94432855e-02,  3.33689228e-02,  2.00000000e+00],\n",
            "        [-2.06252992e-01,  1.25126079e-01,  3.29328179e-01, ...,\n",
            "          8.26353133e-02, -1.04629924e-03,  2.00000000e+00],\n",
            "        [-2.61112362e-01,  1.07754119e-01,  2.93283284e-01, ...,\n",
            "          6.00712337e-02,  8.65787268e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-3.4596302e-02, -1.3074453e-01, -2.8557148e-02, ...,\n",
            "          5.7996705e-02,  2.1014571e-01,  2.0000000e+00],\n",
            "        [ 1.5636081e-01, -5.4877631e-02, -2.4235526e-02, ...,\n",
            "          2.5508374e-01,  1.4573231e-01,  2.0000000e+00],\n",
            "        [ 1.2734124e-01, -2.3957791e-02, -9.5521042e-04, ...,\n",
            "          3.4167239e-01,  3.8847979e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.6026354e-01,  1.2411282e-01,  2.5882834e-01, ...,\n",
            "          6.5361321e-02, -9.2375418e-03,  2.0000000e+00],\n",
            "        [-2.6895553e-01,  1.0609480e-01,  3.0502355e-01, ...,\n",
            "          6.3293800e-02, -3.9318427e-02,  2.0000000e+00],\n",
            "        [-2.9956961e-01,  8.8912658e-02,  2.8473508e-01, ...,\n",
            "          4.2923652e-02, -1.6786836e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-3.08292620e-02, -1.23229355e-01, -2.86257956e-02, ...,\n",
            "          5.47434427e-02,  2.06777111e-01,  2.00000000e+00],\n",
            "        [ 1.38850167e-01, -5.52961417e-02, -2.82574743e-02, ...,\n",
            "          2.55264819e-01,  1.42011464e-01,  2.00000000e+00],\n",
            "        [ 1.18607797e-01, -2.55587902e-02, -1.32345352e-02, ...,\n",
            "          3.50603729e-01,  2.43637599e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.31162927e-01,  1.10822208e-01,  2.37128466e-01, ...,\n",
            "          8.36235806e-02,  1.74818200e-03,  2.00000000e+00],\n",
            "        [-2.60227501e-01,  1.00169308e-01,  3.10377151e-01, ...,\n",
            "          6.70051351e-02, -3.26590128e-02,  2.00000000e+00],\n",
            "        [-3.04867774e-01,  8.87634456e-02,  2.88562566e-01, ...,\n",
            "          4.41723689e-02, -1.76462345e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-5.0604274e-03, -1.1046249e-01, -5.2190464e-02, ...,\n",
            "          4.6180844e-02,  2.1384330e-01,  2.0000000e+00],\n",
            "        [ 1.5505765e-01, -2.1548562e-03, -3.6107231e-02, ...,\n",
            "          2.3563389e-01,  1.0780812e-01,  2.0000000e+00],\n",
            "        [ 1.6189930e-01,  5.4963782e-02, -1.7825378e-02, ...,\n",
            "          3.1287622e-01, -5.5065520e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.7091344e-02,  1.1605086e-01,  9.1365717e-02, ...,\n",
            "          3.2839194e-02,  4.4907540e-02,  2.0000000e+00],\n",
            "        [-1.6713937e-01,  1.4378312e-01,  2.9216138e-01, ...,\n",
            "          6.8425372e-02, -1.2239830e-03,  2.0000000e+00],\n",
            "        [-2.5569117e-01,  1.0733314e-01,  2.8324395e-01, ...,\n",
            "          7.0208959e-02,  8.0638826e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01881506, -0.12348311, -0.03160955, ...,  0.03867479,\n",
            "          0.20526557,  2.        ],\n",
            "        [ 0.13348669, -0.01774411, -0.0032661 , ...,  0.24006407,\n",
            "          0.10347437,  2.        ],\n",
            "        [ 0.13389052,  0.04470397,  0.01371646, ...,  0.31258443,\n",
            "         -0.03750933,  2.        ],\n",
            "        ...,\n",
            "        [-0.01084498,  0.13068606,  0.16865276, ...,  0.04604613,\n",
            "          0.02677535,  2.        ],\n",
            "        [-0.21725225,  0.12429554,  0.33336052, ...,  0.05380963,\n",
            "         -0.01344587,  2.        ],\n",
            "        [-0.2806811 ,  0.0978268 ,  0.30186728, ...,  0.04348883,\n",
            "         -0.0040317 ,  2.        ]], dtype=float32)\n",
            " array([[-2.32305713e-02, -1.29817262e-01, -2.48768814e-02, ...,\n",
            "          4.25917916e-02,  2.08857432e-01,  2.00000000e+00],\n",
            "        [ 1.33111328e-01, -3.90970893e-02,  6.74937735e-04, ...,\n",
            "          2.45802626e-01,  1.27214581e-01,  2.00000000e+00],\n",
            "        [ 1.25480637e-01,  1.40291825e-02,  2.40235478e-02, ...,\n",
            "          3.24861079e-01, -1.46323943e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-8.80111307e-02,  1.34226039e-01,  2.34887213e-01, ...,\n",
            "          6.74576908e-02,  3.47331259e-03,  2.00000000e+00],\n",
            "        [-2.49679655e-01,  1.26613915e-01,  3.44497651e-01, ...,\n",
            "          5.53678125e-02, -2.52898261e-02,  2.00000000e+00],\n",
            "        [-2.98288703e-01,  9.57650095e-02,  3.02645594e-01, ...,\n",
            "          4.57200892e-02, -9.85622872e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02516603, -0.14478306, -0.04454501, ...,  0.06732181,\n",
            "          0.21172825,  2.        ],\n",
            "        [ 0.15980521, -0.07893296, -0.06871942, ...,  0.3029888 ,\n",
            "          0.13846412,  2.        ],\n",
            "        [ 0.13565306, -0.06546146, -0.07597163, ...,  0.39569122,\n",
            "          0.03393065,  2.        ],\n",
            "        ...,\n",
            "        [-0.08977001,  0.02059223,  0.1698114 , ...,  0.10849401,\n",
            "          0.03128558,  2.        ],\n",
            "        [-0.20085818,  0.02670127,  0.23920345, ...,  0.09089978,\n",
            "         -0.01465718,  2.        ],\n",
            "        [-0.2648852 ,  0.0369721 ,  0.24905232, ...,  0.0599275 ,\n",
            "         -0.01579564,  2.        ]], dtype=float32)\n",
            " array([[-2.49218550e-02, -1.30810365e-01, -2.63516475e-02, ...,\n",
            "          4.62548174e-02,  2.15833157e-01,  2.00000000e+00],\n",
            "        [ 1.30697429e-01, -3.86050045e-02,  1.33059116e-03, ...,\n",
            "          2.24481195e-01,  1.35631129e-01,  2.00000000e+00],\n",
            "        [ 1.24524578e-01,  1.49323428e-02,  2.50468962e-02, ...,\n",
            "          3.01162183e-01, -3.67852999e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-7.21338168e-02,  1.49186492e-01,  2.20023677e-01, ...,\n",
            "          2.79017817e-02,  1.63179636e-02,  2.00000000e+00],\n",
            "        [-2.42132902e-01,  1.41294152e-01,  3.35723758e-01, ...,\n",
            "          3.97580788e-02, -1.51498523e-02,  2.00000000e+00],\n",
            "        [-2.92989492e-01,  1.00346588e-01,  2.99632818e-01, ...,\n",
            "          5.08317463e-02,  1.05099054e-04,  2.00000000e+00]], dtype=float32)\n",
            " array([[-3.2962184e-02, -1.2390009e-01, -3.0649470e-02, ...,\n",
            "          5.5099986e-02,  2.0647901e-01,  2.0000000e+00],\n",
            "        [ 1.3820404e-01, -5.5824146e-02, -2.8857283e-02, ...,\n",
            "          2.6068461e-01,  1.3869713e-01,  2.0000000e+00],\n",
            "        [ 1.1663206e-01, -2.5452558e-02, -1.4354622e-02, ...,\n",
            "          3.5408944e-01,  2.5178244e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.3712700e-01,  1.0336951e-01,  2.3864737e-01, ...,\n",
            "          8.7545373e-02, -1.2754719e-03,  2.0000000e+00],\n",
            "        [-2.5956970e-01,  9.2517287e-02,  3.0815434e-01, ...,\n",
            "          6.7634188e-02, -3.6932334e-02,  2.0000000e+00],\n",
            "        [-3.0457088e-01,  8.7667853e-02,  2.8941387e-01, ...,\n",
            "          3.7360560e-02, -1.6184710e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.7306155e-02, -1.2979585e-01, -3.8082547e-02, ...,\n",
            "          5.0144423e-02,  2.1947455e-01,  2.0000000e+00],\n",
            "        [ 1.4094961e-01, -3.1096123e-02, -1.2578886e-02, ...,\n",
            "          2.4793471e-01,  1.3041405e-01,  2.0000000e+00],\n",
            "        [ 1.4302719e-01,  3.1507056e-02,  7.9716723e-03, ...,\n",
            "          3.2390609e-01, -1.7212566e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-3.3925667e-02,  1.4426959e-01,  1.7870738e-01, ...,\n",
            "          5.6713074e-02,  2.7998723e-02,  2.0000000e+00],\n",
            "        [-2.1521388e-01,  1.4332306e-01,  3.1769359e-01, ...,\n",
            "          6.6155434e-02, -1.3733521e-02,  2.0000000e+00],\n",
            "        [-2.7182284e-01,  1.0166121e-01,  2.9328132e-01, ...,\n",
            "          7.1439102e-02, -8.7511784e-05,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.3148237e-02, -1.2475367e-01, -3.1022767e-02, ...,\n",
            "          4.4497781e-02,  2.0977940e-01,  2.0000000e+00],\n",
            "        [ 1.5401822e-01, -2.2238828e-02, -9.3844878e-03, ...,\n",
            "          2.6601252e-01,  1.1310957e-01,  2.0000000e+00],\n",
            "        [ 1.5963955e-01,  4.1096888e-02,  3.5403848e-03, ...,\n",
            "          3.3764350e-01, -2.4568589e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-8.5521629e-04,  1.2108675e-01,  1.6884623e-01, ...,\n",
            "          7.9212956e-02,  3.0083746e-02,  2.0000000e+00],\n",
            "        [-2.0465374e-01,  1.2580752e-01,  3.2465303e-01, ...,\n",
            "          8.1333153e-02, -5.2719563e-03,  2.0000000e+00],\n",
            "        [-2.6283294e-01,  1.0672572e-01,  2.9270330e-01, ...,\n",
            "          5.8747970e-02,  5.9541198e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02224377, -0.12836474, -0.02550164, ...,  0.0410096 ,\n",
            "          0.20730962,  2.        ],\n",
            "        [ 0.13599949, -0.03467594,  0.00283985, ...,  0.24863409,\n",
            "          0.1203284 ,  2.        ],\n",
            "        [ 0.12937605,  0.01963042,  0.02408848, ...,  0.32728136,\n",
            "         -0.00863014,  2.        ],\n",
            "        ...,\n",
            "        [-0.07457536,  0.13075694,  0.22406784, ...,  0.06820614,\n",
            "          0.00601674,  2.        ],\n",
            "        [-0.24408574,  0.12820028,  0.34105483, ...,  0.05649285,\n",
            "         -0.02467367,  2.        ],\n",
            "        [-0.29559502,  0.0998183 ,  0.30220404, ...,  0.0444949 ,\n",
            "         -0.00783281,  2.        ]], dtype=float32)\n",
            " array([[-2.23385431e-02, -1.31097749e-01, -2.53374651e-02, ...,\n",
            "          4.16971631e-02,  2.07570076e-01,  2.00000000e+00],\n",
            "        [ 1.32328972e-01, -4.44836393e-02,  2.10602582e-03, ...,\n",
            "          2.46231362e-01,  1.25475019e-01,  2.00000000e+00],\n",
            "        [ 1.18243925e-01,  2.64030386e-04,  2.24442221e-02, ...,\n",
            "          3.27915907e-01,  3.68924323e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.09913751e-01,  1.29907593e-01,  2.40356311e-01, ...,\n",
            "          6.79700077e-02, -3.80022754e-03,  2.00000000e+00],\n",
            "        [-2.52574772e-01,  1.27242252e-01,  3.36759984e-01, ...,\n",
            "          5.54371066e-02, -3.39922272e-02,  2.00000000e+00],\n",
            "        [-2.98510998e-01,  9.66253579e-02,  3.03379208e-01, ...,\n",
            "          4.31055464e-02, -1.21820820e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-1.34129375e-02, -1.24897219e-01, -4.07704338e-02, ...,\n",
            "          4.99238037e-02,  2.14064270e-01,  2.00000000e+00],\n",
            "        [ 1.48059398e-01, -2.76196506e-02, -1.91138703e-02, ...,\n",
            "          2.46981233e-01,  1.18498333e-01,  2.00000000e+00],\n",
            "        [ 1.50024459e-01,  4.12560664e-02,  6.61621278e-04, ...,\n",
            "          3.27255338e-01, -3.96292210e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.61985382e-02,  1.32643551e-01,  1.65899113e-01, ...,\n",
            "          5.75355738e-02,  2.64424775e-02,  2.00000000e+00],\n",
            "        [-2.08695754e-01,  1.34737134e-01,  3.09558600e-01, ...,\n",
            "          7.08854347e-02, -6.99107116e-03,  2.00000000e+00],\n",
            "        [-2.67086506e-01,  1.06613830e-01,  2.87256151e-01, ...,\n",
            "          7.57454783e-02,  9.09514073e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.07222197e-02, -1.37465760e-01, -3.17428224e-02, ...,\n",
            "          5.76602630e-02,  2.17638463e-01,  2.00000000e+00],\n",
            "        [ 1.48352802e-01, -4.68592346e-02, -9.98358708e-03, ...,\n",
            "          2.45579422e-01,  1.41183659e-01,  2.00000000e+00],\n",
            "        [ 1.38662994e-01,  4.41700220e-04,  1.01931663e-02, ...,\n",
            "          3.28848451e-01,  3.83896893e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.13264322e-01,  1.55425295e-01,  2.39181116e-01, ...,\n",
            "          6.76155537e-02, -5.32507244e-03,  2.00000000e+00],\n",
            "        [-2.48194292e-01,  1.32772475e-01,  3.23454320e-01, ...,\n",
            "          6.39059842e-02, -3.24430838e-02,  2.00000000e+00],\n",
            "        [-2.77297676e-01,  1.04316734e-01,  2.87861735e-01, ...,\n",
            "          6.91366345e-02, -2.53769592e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02031211, -0.12915096, -0.02845856, ...,  0.04276435,\n",
            "          0.20801662,  2.        ],\n",
            "        [ 0.13764757, -0.03560758, -0.00645812, ...,  0.2514546 ,\n",
            "          0.12265014,  2.        ],\n",
            "        [ 0.13185413,  0.02082645,  0.01455482, ...,  0.33419973,\n",
            "         -0.01484672,  2.        ],\n",
            "        ...,\n",
            "        [-0.05257419,  0.1271087 ,  0.20342343, ...,  0.07521813,\n",
            "          0.01449399,  2.        ],\n",
            "        [-0.23323841,  0.1246163 ,  0.33372548, ...,  0.06589407,\n",
            "         -0.01749287,  2.        ],\n",
            "        [-0.28863367,  0.09449816,  0.29768506, ...,  0.05164852,\n",
            "         -0.00850087,  2.        ]], dtype=float32)\n",
            " array([[-2.0037655e-02, -1.1978098e-01, -3.0170292e-02, ...,\n",
            "          3.5418410e-02,  2.0429365e-01,  2.0000000e+00],\n",
            "        [ 1.2173709e-01, -2.5461858e-02,  2.1716987e-03, ...,\n",
            "          2.2961934e-01,  1.0186598e-01,  2.0000000e+00],\n",
            "        [ 1.2629871e-01,  4.3784294e-02,  2.3068804e-02, ...,\n",
            "          3.0228165e-01, -4.4055905e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-2.9574756e-02,  1.3173069e-01,  1.9335042e-01, ...,\n",
            "          3.7330076e-02,  2.3410317e-02,  2.0000000e+00],\n",
            "        [-2.2569555e-01,  1.3060229e-01,  3.4722281e-01, ...,\n",
            "          4.5026131e-02, -1.2065740e-02,  2.0000000e+00],\n",
            "        [-2.8837860e-01,  9.9008590e-02,  3.0708870e-01, ...,\n",
            "          3.9304323e-02, -1.5556209e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.5139801e-02, -1.2950367e-01, -2.3249447e-02, ...,\n",
            "          4.0600158e-02,  2.0807411e-01,  2.0000000e+00],\n",
            "        [ 1.2812372e-01, -4.5036256e-02, -1.5361825e-04, ...,\n",
            "          2.3949033e-01,  1.3001101e-01,  2.0000000e+00],\n",
            "        [ 1.1218317e-01, -1.1441960e-03,  2.2887692e-02, ...,\n",
            "          3.2011425e-01,  9.2830937e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2808272e-01,  1.3240941e-01,  2.5896722e-01, ...,\n",
            "          6.0271211e-02, -7.9105226e-03,  2.0000000e+00],\n",
            "        [-2.6024410e-01,  1.2853186e-01,  3.4524852e-01, ...,\n",
            "          5.0656628e-02, -3.7894186e-02,  2.0000000e+00],\n",
            "        [-3.0402216e-01,  9.4690926e-02,  3.0927253e-01, ...,\n",
            "          4.1006982e-02, -1.6147817e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-3.1330071e-02, -1.3249075e-01, -3.6486987e-02, ...,\n",
            "          6.9723345e-02,  2.1431573e-01,  2.0000000e+00],\n",
            "        [ 1.7166644e-01, -5.2386861e-02, -3.9597120e-02, ...,\n",
            "          2.9092634e-01,  1.4307548e-01,  2.0000000e+00],\n",
            "        [ 1.4459223e-01, -2.7026486e-02, -2.7210077e-02, ...,\n",
            "          3.8596356e-01,  3.4624096e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1478408e-01,  9.5964342e-02,  2.2171518e-01, ...,\n",
            "          9.5824867e-02, -1.1567790e-03,  2.0000000e+00],\n",
            "        [-2.5147003e-01,  8.2127117e-02,  2.8214130e-01, ...,\n",
            "          7.9910159e-02, -3.8356688e-02,  2.0000000e+00],\n",
            "        [-2.8392622e-01,  8.6257935e-02,  2.7468219e-01, ...,\n",
            "          5.6677688e-02, -1.4903331e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.37155557e-02, -1.36514366e-01, -2.73607653e-02, ...,\n",
            "          4.77112569e-02,  2.09797099e-01,  2.00000000e+00],\n",
            "        [ 1.41396374e-01, -4.79958877e-02, -1.25873294e-02, ...,\n",
            "          2.64617145e-01,  1.35055840e-01,  2.00000000e+00],\n",
            "        [ 1.24493368e-01, -8.82514101e-03,  4.88124462e-03, ...,\n",
            "          3.51857483e-01,  1.39213791e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.09077603e-01,  1.18689284e-01,  2.31373638e-01, ...,\n",
            "          8.65580663e-02, -1.84657122e-03,  2.00000000e+00],\n",
            "        [-2.45546311e-01,  1.07601732e-01,  3.17167580e-01, ...,\n",
            "          6.81548044e-02, -3.15974206e-02,  2.00000000e+00],\n",
            "        [-2.97040403e-01,  8.56229290e-02,  2.92292833e-01, ...,\n",
            "          5.14542162e-02, -1.61537994e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01675459, -0.13241827, -0.032689  , ...,  0.05262958,\n",
            "          0.21887803,  2.        ],\n",
            "        [ 0.14886928, -0.04207616, -0.00785744, ...,  0.22803621,\n",
            "          0.13622868,  2.        ],\n",
            "        [ 0.13419579,  0.0153581 ,  0.01425529, ...,  0.30776426,\n",
            "         -0.01679922,  2.        ],\n",
            "        ...,\n",
            "        [-0.03175871,  0.1653944 ,  0.18082586, ...,  0.03037728,\n",
            "          0.02639674,  2.        ],\n",
            "        [-0.2139191 ,  0.14355816,  0.30802855, ...,  0.04322098,\n",
            "         -0.0078003 ,  2.        ],\n",
            "        [-0.26284212,  0.10780862,  0.28411594, ...,  0.06946221,\n",
            "          0.00325738,  2.        ]], dtype=float32)\n",
            " array([[-0.02315804, -0.13105212, -0.02957999, ...,  0.05058012,\n",
            "          0.21779229,  2.        ],\n",
            "        [ 0.13500243, -0.04281001, -0.00599558, ...,  0.24147137,\n",
            "          0.13343133,  2.        ],\n",
            "        [ 0.1327176 ,  0.01514635,  0.0151702 , ...,  0.32055983,\n",
            "         -0.00913312,  2.        ],\n",
            "        ...,\n",
            "        [-0.08486824,  0.14371964,  0.22855704, ...,  0.05478474,\n",
            "          0.0047828 ,  2.        ],\n",
            "        [-0.24718095,  0.13743573,  0.34020722, ...,  0.05599689,\n",
            "         -0.02291211,  2.        ],\n",
            "        [-0.287544  ,  0.10259891,  0.30054224, ...,  0.0632908 ,\n",
            "          0.00343905,  2.        ]], dtype=float32)\n",
            " array([[-7.7940100e-03, -1.1643796e-01, -4.3582514e-02, ...,\n",
            "          5.3988211e-02,  2.1529178e-01,  2.0000000e+00],\n",
            "        [ 1.4509822e-01, -2.8723530e-02, -2.1687731e-02, ...,\n",
            "          2.2319825e-01,  1.2777384e-01,  2.0000000e+00],\n",
            "        [ 1.3413145e-01,  3.0275291e-02, -3.5851449e-03, ...,\n",
            "          3.0367231e-01, -3.3799212e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.8159100e-03,  1.5032670e-01,  1.5748312e-01, ...,\n",
            "          4.3063663e-02,  3.6915720e-02,  2.0000000e+00],\n",
            "        [-1.9865984e-01,  1.4176518e-01,  3.1283826e-01, ...,\n",
            "          7.0267342e-02,  2.0794226e-03,  2.0000000e+00],\n",
            "        [-2.6058626e-01,  1.0730313e-01,  2.8934407e-01, ...,\n",
            "          7.2475672e-02,  6.2499903e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.03322813, -0.15457344, -0.05493136, ...,  0.06758822,\n",
            "          0.21175443,  2.        ],\n",
            "        [ 0.15497558, -0.10882518, -0.0715786 , ...,  0.30076215,\n",
            "          0.1533947 ,  2.        ],\n",
            "        [ 0.09975222, -0.10446794, -0.07174235, ...,  0.4085411 ,\n",
            "          0.06590702,  2.        ],\n",
            "        ...,\n",
            "        [-0.15233186,  0.02202589,  0.2003221 , ...,  0.11222131,\n",
            "         -0.01189366,  2.        ],\n",
            "        [-0.24517098,  0.04727799,  0.209348  , ...,  0.09459784,\n",
            "         -0.05323811,  2.        ],\n",
            "        [-0.26455003,  0.02958842,  0.23689415, ...,  0.03572473,\n",
            "         -0.02923426,  2.        ]], dtype=float32)\n",
            " array([[-1.0961010e-02, -1.1829240e-01, -3.2807030e-02, ...,\n",
            "          4.4310626e-02,  2.0977457e-01,  2.0000000e+00],\n",
            "        [ 1.4979300e-01, -1.9967010e-02, -1.3981996e-02, ...,\n",
            "          2.5452507e-01,  1.0565123e-01,  2.0000000e+00],\n",
            "        [ 1.6012771e-01,  5.0605919e-02, -1.6475912e-03, ...,\n",
            "          3.2395917e-01, -4.1054353e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.7676342e-02,  1.2082475e-01,  1.5174958e-01, ...,\n",
            "          6.2006809e-02,  3.9839938e-02,  2.0000000e+00],\n",
            "        [-1.9551668e-01,  1.2543394e-01,  3.2776549e-01, ...,\n",
            "          8.4084079e-02,  9.3515473e-04,  2.0000000e+00],\n",
            "        [-2.5973991e-01,  1.0983435e-01,  2.9542759e-01, ...,\n",
            "          5.8481328e-02,  8.4540630e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.03322137, -0.12316255, -0.03054539, ...,  0.05296833,\n",
            "          0.20517229,  2.        ],\n",
            "        [ 0.13133703, -0.05924057, -0.0300845 , ...,  0.25436956,\n",
            "          0.13921441,  2.        ],\n",
            "        [ 0.1099442 , -0.03054403, -0.01865598, ...,  0.34721407,\n",
            "          0.02516576,  2.        ],\n",
            "        ...,\n",
            "        [-0.15380192,  0.1073621 ,  0.2494774 , ...,  0.09623293,\n",
            "         -0.00823448,  2.        ],\n",
            "        [-0.2704158 ,  0.10084862,  0.31273112, ...,  0.07327332,\n",
            "         -0.04007948,  2.        ],\n",
            "        [-0.3086493 ,  0.08841884,  0.29066724, ...,  0.03428244,\n",
            "         -0.01951296,  2.        ]], dtype=float32)\n",
            " array([[-0.02187085, -0.14144163, -0.03497723, ...,  0.05989187,\n",
            "          0.21809019,  2.        ],\n",
            "        [ 0.16172406, -0.04766096, -0.02459321, ...,  0.28047094,\n",
            "          0.13849066,  2.        ],\n",
            "        [ 0.1474279 , -0.00588987, -0.00424209, ...,  0.37283528,\n",
            "          0.00856693,  2.        ],\n",
            "        ...,\n",
            "        [-0.08760419,  0.11801953,  0.20351505, ...,  0.08374158,\n",
            "          0.00379005,  2.        ],\n",
            "        [-0.22711855,  0.10989151,  0.2866756 , ...,  0.07852519,\n",
            "         -0.02958065,  2.        ],\n",
            "        [-0.27831247,  0.09368971,  0.27814898, ...,  0.07179451,\n",
            "         -0.00573455,  2.        ]], dtype=float32)\n",
            " array([[-1.7028078e-02, -1.1830984e-01, -3.5714906e-02, ...,\n",
            "          3.4029666e-02,  2.0591214e-01,  2.0000000e+00],\n",
            "        [ 1.2871473e-01, -1.4642207e-02, -6.8185786e-03, ...,\n",
            "          2.3100697e-01,  9.6916802e-02,  2.0000000e+00],\n",
            "        [ 1.3246781e-01,  5.2233037e-02,  8.5223122e-03, ...,\n",
            "          3.0199942e-01, -4.9010858e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.4098979e-03,  1.2597333e-01,  1.5043999e-01, ...,\n",
            "          3.3085946e-02,  3.1826518e-02,  2.0000000e+00],\n",
            "        [-2.1058205e-01,  1.2718761e-01,  3.3521158e-01, ...,\n",
            "          4.9593158e-02, -9.6607991e-03,  2.0000000e+00],\n",
            "        [-2.7848619e-01,  9.3981452e-02,  3.0178079e-01, ...,\n",
            "          4.5627788e-02, -5.0128014e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.10309289e-02, -1.33248433e-01, -2.77417079e-02, ...,\n",
            "          4.57186773e-02,  2.09592909e-01,  2.00000000e+00],\n",
            "        [ 1.41219020e-01, -3.85709070e-02, -5.74472174e-03, ...,\n",
            "          2.62154192e-01,  1.27441317e-01,  2.00000000e+00],\n",
            "        [ 1.36417374e-01,  1.20665822e-02,  1.43704601e-02, ...,\n",
            "          3.41081232e-01,  2.00933602e-04,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-8.81486386e-02,  1.28228068e-01,  2.34270036e-01, ...,\n",
            "          9.06424522e-02,  9.29939852e-04,  2.00000000e+00],\n",
            "        [-2.43011370e-01,  1.16230965e-01,  3.37999314e-01, ...,\n",
            "          7.59178475e-02, -2.78798249e-02,  2.00000000e+00],\n",
            "        [-2.90560275e-01,  9.23018679e-02,  2.98359692e-01, ...,\n",
            "          5.47569916e-02, -1.00065693e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 4.54281345e-02, -1.69927537e-01, -9.36583728e-02, ...,\n",
            "         -7.86879857e-04,  1.80927902e-01,  2.00000000e+00],\n",
            "        [ 2.74101526e-01, -2.72780610e-03, -8.57678577e-02, ...,\n",
            "          1.36205748e-01,  1.34541672e-02,  2.00000000e+00],\n",
            "        [ 2.72595286e-01,  4.08695005e-02, -6.96934387e-02, ...,\n",
            "          1.82836562e-01, -1.01418190e-01,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.38040870e-01,  5.91460662e-03, -1.13706104e-01, ...,\n",
            "          5.23598902e-02,  7.07255304e-02,  2.00000000e+00],\n",
            "        [-3.34937423e-02,  8.67825001e-02,  1.83643699e-01, ...,\n",
            "          1.11021444e-01, -3.56771760e-02,  2.00000000e+00],\n",
            "        [-2.29201183e-01,  4.27726842e-02,  2.97078788e-01, ...,\n",
            "          6.88884407e-02, -1.89769808e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 0.00778995, -0.10986402, -0.05826611, ...,  0.03027965,\n",
            "          0.1914196 ,  2.        ],\n",
            "        [ 0.18471704, -0.00221542, -0.04390402, ...,  0.23196772,\n",
            "          0.03447714,  2.        ],\n",
            "        [ 0.18669721,  0.04523101, -0.04206067, ...,  0.29448643,\n",
            "         -0.10024928,  2.        ],\n",
            "        ...,\n",
            "        [ 0.0857142 ,  0.06429377,  0.0410293 , ...,  0.03332373,\n",
            "          0.05891776,  2.        ],\n",
            "        [-0.13443463,  0.11889943,  0.3021004 , ...,  0.08877781,\n",
            "         -0.01664882,  2.        ],\n",
            "        [-0.2507574 ,  0.08836926,  0.29147747, ...,  0.05764017,\n",
            "         -0.01137916,  2.        ]], dtype=float32)\n",
            " array([[-1.1571941e-02, -1.2246791e-01, -4.0037483e-02, ...,\n",
            "          4.9951650e-02,  2.1377541e-01,  2.0000000e+00],\n",
            "        [ 1.3534370e-01, -2.5062960e-02, -1.7212780e-02, ...,\n",
            "          2.3468375e-01,  1.2515250e-01,  2.0000000e+00],\n",
            "        [ 1.3788909e-01,  3.6888421e-02,  1.7329277e-03, ...,\n",
            "          3.1210712e-01, -3.0578062e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1463593e-02,  1.4188309e-01,  1.5880249e-01, ...,\n",
            "          4.3698460e-02,  3.8517226e-02,  2.0000000e+00],\n",
            "        [-2.0998618e-01,  1.4381169e-01,  3.1988710e-01, ...,\n",
            "          6.1799441e-02, -4.4497740e-03,  2.0000000e+00],\n",
            "        [-2.6768240e-01,  1.0274305e-01,  2.9668134e-01, ...,\n",
            "          6.4013831e-02, -1.6516473e-04,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01730401, -0.13005471, -0.03781258, ...,  0.05362581,\n",
            "          0.21648854,  2.        ],\n",
            "        [ 0.15264978, -0.02362985, -0.0165387 , ...,  0.25787812,\n",
            "          0.12450594,  2.        ],\n",
            "        [ 0.15624557,  0.0424277 ,  0.0041446 , ...,  0.33687413,\n",
            "         -0.02532775,  2.        ],\n",
            "        ...,\n",
            "        [-0.04285945,  0.14702666,  0.18310761, ...,  0.05360767,\n",
            "          0.01333815,  2.        ],\n",
            "        [-0.21102132,  0.1375921 ,  0.29972097, ...,  0.05811973,\n",
            "         -0.01633329,  2.        ],\n",
            "        [-0.26426622,  0.10409798,  0.28345305, ...,  0.07078888,\n",
            "          0.0053425 ,  2.        ]], dtype=float32)\n",
            " array([[ 2.54899939e-03, -1.09652646e-01, -5.52405827e-02, ...,\n",
            "          5.19923493e-02,  2.13443249e-01,  2.00000000e+00],\n",
            "        [ 1.56913444e-01, -1.59126073e-02, -4.49434593e-02, ...,\n",
            "          2.14703619e-01,  1.09831959e-01,  2.00000000e+00],\n",
            "        [ 1.41939953e-01,  3.49166244e-02, -2.89712511e-02, ...,\n",
            "          3.05965334e-01, -5.51293269e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 4.60273735e-02,  1.28641501e-01,  1.00772642e-01, ...,\n",
            "          3.58888321e-02,  4.51405682e-02,  2.00000000e+00],\n",
            "        [-1.70294970e-01,  1.39450252e-01,  2.84638137e-01, ...,\n",
            "          8.39329138e-02,  1.46042876e-04,  2.00000000e+00],\n",
            "        [-2.51752973e-01,  1.04650967e-01,  2.80155003e-01, ...,\n",
            "          6.98230267e-02,  1.04122679e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.4289597e-02, -1.2287104e-01, -2.3046458e-02, ...,\n",
            "          3.6888953e-02,  2.0694841e-01,  2.0000000e+00],\n",
            "        [ 1.2149683e-01, -3.4252357e-02,  7.6022265e-03, ...,\n",
            "          2.2979742e-01,  1.1759377e-01,  2.0000000e+00],\n",
            "        [ 1.1702818e-01,  2.6898934e-02,  3.1513724e-02, ...,\n",
            "          3.0478093e-01, -1.7810201e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-8.0578797e-02,  1.3729580e-01,  2.4166983e-01, ...,\n",
            "          4.5756102e-02,  7.9500017e-04,  2.0000000e+00],\n",
            "        [-2.4895805e-01,  1.3532746e-01,  3.6338383e-01, ...,\n",
            "          3.8713634e-02, -2.7156508e-02,  2.0000000e+00],\n",
            "        [-3.0220044e-01,  1.0099348e-01,  3.1705186e-01, ...,\n",
            "          4.0997811e-02, -7.5017959e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.38104018e-02, -1.18889563e-01, -3.90977710e-02, ...,\n",
            "          4.85478416e-02,  2.11448908e-01,  2.00000000e+00],\n",
            "        [ 1.45567164e-01, -1.88126285e-02, -1.35144209e-02, ...,\n",
            "          2.27781698e-01,  1.14368275e-01,  2.00000000e+00],\n",
            "        [ 1.41742632e-01,  4.41622175e-02,  5.55221457e-04, ...,\n",
            "          2.98537612e-01, -3.79935615e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.24427835e-02,  1.52308822e-01,  1.48139536e-01, ...,\n",
            "          3.33900452e-02,  2.98915543e-02,  2.00000000e+00],\n",
            "        [-2.06924126e-01,  1.56615630e-01,  3.16626787e-01, ...,\n",
            "          6.29990920e-02, -7.51671009e-03,  2.00000000e+00],\n",
            "        [-2.69426793e-01,  1.11672908e-01,  2.95078129e-01, ...,\n",
            "          7.21920803e-02,  4.04846715e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.00874824, -0.11686739, -0.04247124, ...,  0.05585648,\n",
            "          0.21796142,  2.        ],\n",
            "        [ 0.1378477 , -0.03377773, -0.02328989, ...,  0.2228045 ,\n",
            "          0.13293597,  2.        ],\n",
            "        [ 0.12129262,  0.02652098, -0.00429241, ...,  0.307154  ,\n",
            "         -0.03152786,  2.        ],\n",
            "        ...,\n",
            "        [-0.00681017,  0.1492847 ,  0.16481239, ...,  0.03714512,\n",
            "          0.03584674,  2.        ],\n",
            "        [-0.19741645,  0.14639784,  0.31211153, ...,  0.06345107,\n",
            "          0.00439985,  2.        ],\n",
            "        [-0.26048085,  0.10581239,  0.2906339 , ...,  0.07824882,\n",
            "          0.00903645,  2.        ]], dtype=float32)\n",
            " array([[-0.01847531, -0.13760833, -0.03600984, ...,  0.06046814,\n",
            "          0.22175336,  2.        ],\n",
            "        [ 0.14943054, -0.04785894, -0.01397943, ...,  0.24162976,\n",
            "          0.14036451,  2.        ],\n",
            "        [ 0.13017157,  0.00389523,  0.00395607, ...,  0.32475457,\n",
            "         -0.01269249,  2.        ],\n",
            "        ...,\n",
            "        [-0.02620394,  0.16663954,  0.17273666, ...,  0.0355254 ,\n",
            "          0.03228004,  2.        ],\n",
            "        [-0.20231193,  0.1422798 ,  0.296119  , ...,  0.04623486,\n",
            "         -0.00593846,  2.        ],\n",
            "        [-0.2556912 ,  0.1038922 ,  0.27272946, ...,  0.0766525 ,\n",
            "          0.00387247,  2.        ]], dtype=float32)\n",
            " array([[-0.00348694, -0.10800996, -0.05251719, ...,  0.02500424,\n",
            "          0.19346553,  2.        ],\n",
            "        [ 0.1601824 , -0.00367526, -0.02754253, ...,  0.22202879,\n",
            "          0.04555078,  2.        ],\n",
            "        [ 0.1665884 ,  0.05190904, -0.02441525, ...,  0.28747687,\n",
            "         -0.0950271 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.05255336,  0.08369501,  0.07511098, ...,  0.01426861,\n",
            "          0.05709151,  2.        ],\n",
            "        [-0.16157742,  0.12525648,  0.32246315, ...,  0.05968031,\n",
            "         -0.00868774,  2.        ],\n",
            "        [-0.2651575 ,  0.09062364,  0.30362296, ...,  0.04719282,\n",
            "         -0.00750563,  2.        ]], dtype=float32)\n",
            " array([[-0.01634261, -0.11955868, -0.03727517, ...,  0.04681911,\n",
            "          0.2147831 ,  2.        ],\n",
            "        [ 0.13559309, -0.01918885, -0.01162453, ...,  0.23462908,\n",
            "          0.11535981,  2.        ],\n",
            "        [ 0.14165857,  0.04768632,  0.00653068, ...,  0.30691177,\n",
            "         -0.03879829,  2.        ],\n",
            "        ...,\n",
            "        [-0.03745681,  0.1368402 ,  0.1810616 , ...,  0.04836932,\n",
            "          0.01668401,  2.        ],\n",
            "        [-0.2236871 ,  0.14473777,  0.32766917, ...,  0.05859102,\n",
            "         -0.01314702,  2.        ],\n",
            "        [-0.27566   ,  0.10657671,  0.30089292, ...,  0.0625396 ,\n",
            "          0.00795852,  2.        ]], dtype=float32)\n",
            " array([[-1.7690100e-02, -1.2180847e-01, -3.2545198e-02, ...,\n",
            "          3.5468157e-02,  2.0617051e-01,  2.0000000e+00],\n",
            "        [ 1.2636510e-01, -1.9488886e-02,  1.0286877e-03, ...,\n",
            "          2.2450434e-01,  9.9125825e-02,  2.0000000e+00],\n",
            "        [ 1.3061443e-01,  4.5676790e-02,  1.9238913e-02, ...,\n",
            "          2.9434010e-01, -4.7298342e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-9.9646328e-03,  1.3372651e-01,  1.7010547e-01, ...,\n",
            "          2.6887832e-02,  3.7022341e-02,  2.0000000e+00],\n",
            "        [-2.1453594e-01,  1.3412985e-01,  3.3879870e-01, ...,\n",
            "          4.1747585e-02, -4.6949438e-03,  2.0000000e+00],\n",
            "        [-2.8084701e-01,  9.9306352e-02,  3.0356506e-01, ...,\n",
            "          3.9220870e-02,  7.7686983e-04,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.1204803e-02, -1.3971631e-01, -3.0337710e-02, ...,\n",
            "          5.3431801e-02,  2.1526954e-01,  2.0000000e+00],\n",
            "        [ 1.5428367e-01, -5.0313029e-02, -1.3503700e-02, ...,\n",
            "          2.6826695e-01,  1.3206601e-01,  2.0000000e+00],\n",
            "        [ 1.4423381e-01,  2.8956567e-03,  7.1141310e-03, ...,\n",
            "          3.5667488e-01, -9.1216038e-04,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-9.0625122e-02,  1.3788237e-01,  2.1999010e-01, ...,\n",
            "          7.2306804e-02, -3.6512255e-03,  2.0000000e+00],\n",
            "        [-2.3622832e-01,  1.2527516e-01,  3.0820855e-01, ...,\n",
            "          7.1653903e-02, -3.0163646e-02,  2.0000000e+00],\n",
            "        [-2.7840474e-01,  9.8382033e-02,  2.8577289e-01, ...,\n",
            "          7.0395082e-02, -3.6510269e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.84639692e-02, -1.25140473e-01, -2.91215107e-02, ...,\n",
            "          3.74332592e-02,  2.07849845e-01,  2.00000000e+00],\n",
            "        [ 1.27854645e-01, -2.40012724e-02,  1.98119460e-03, ...,\n",
            "          2.27851897e-01,  1.09795436e-01,  2.00000000e+00],\n",
            "        [ 1.29877493e-01,  3.87488231e-02,  2.20958851e-02, ...,\n",
            "          2.99826980e-01, -3.16541009e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-3.16135101e-02,  1.32885024e-01,  1.95684776e-01, ...,\n",
            "          4.10079733e-02,  2.82325763e-02,  2.00000000e+00],\n",
            "        [-2.25354180e-01,  1.28867626e-01,  3.46644163e-01, ...,\n",
            "          4.67829816e-02, -7.70824496e-03,  2.00000000e+00],\n",
            "        [-2.84466892e-01,  9.80417356e-02,  3.04317623e-01, ...,\n",
            "          4.20534499e-02, -9.70606692e-04,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01793253, -0.1229065 , -0.03727143, ...,  0.05596315,\n",
            "          0.21973467,  2.        ],\n",
            "        [ 0.13944715, -0.03717544, -0.01628651, ...,  0.21901004,\n",
            "          0.13698715,  2.        ],\n",
            "        [ 0.12145903,  0.0181559 ,  0.00449823, ...,  0.3052825 ,\n",
            "         -0.02122079,  2.        ],\n",
            "        ...,\n",
            "        [-0.01775227,  0.15623365,  0.16427599, ...,  0.0364672 ,\n",
            "          0.04042167,  2.        ],\n",
            "        [-0.20960748,  0.14838998,  0.3086936 , ...,  0.05687371,\n",
            "          0.00269213,  2.        ],\n",
            "        [-0.26589093,  0.10886653,  0.28428224, ...,  0.07618819,\n",
            "          0.00787243,  2.        ]], dtype=float32)\n",
            " array([[-0.03368976, -0.13488644, -0.03296263, ...,  0.05180957,\n",
            "          0.20882824,  2.        ],\n",
            "        [ 0.14175557, -0.06733368, -0.04062228, ...,  0.26704296,\n",
            "          0.14526561,  2.        ],\n",
            "        [ 0.10706498, -0.04713593, -0.03750598, ...,  0.35563588,\n",
            "          0.04434026,  2.        ],\n",
            "        ...,\n",
            "        [-0.13890788,  0.07237085,  0.22936827, ...,  0.09364565,\n",
            "          0.01338142,  2.        ],\n",
            "        [-0.2558885 ,  0.06289073,  0.2891215 , ...,  0.07042227,\n",
            "         -0.03442606,  2.        ],\n",
            "        [-0.3032323 ,  0.07043716,  0.2856523 , ...,  0.03486334,\n",
            "         -0.01716067,  2.        ]], dtype=float32)\n",
            " array([[-6.7492533e-03, -1.1480323e-01, -4.2911049e-02, ...,\n",
            "          3.9043721e-02,  2.0292631e-01,  2.0000000e+00],\n",
            "        [ 1.5184614e-01, -9.5941350e-03, -2.3677917e-02, ...,\n",
            "          2.2729959e-01,  8.0149792e-02,  2.0000000e+00],\n",
            "        [ 1.5488456e-01,  5.1055674e-02, -1.3970991e-02, ...,\n",
            "          3.0234262e-01, -6.7801744e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 4.3428268e-02,  1.0974554e-01,  1.0018587e-01, ...,\n",
            "          2.2118768e-02,  5.9476409e-02,  2.0000000e+00],\n",
            "        [-1.8133059e-01,  1.2128055e-01,  3.1275323e-01, ...,\n",
            "          6.3962817e-02,  2.2174695e-03,  2.0000000e+00],\n",
            "        [-2.6029220e-01,  9.4993882e-02,  2.8863531e-01, ...,\n",
            "          4.9347192e-02, -1.5888257e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.21049341e-02, -1.18831724e-01, -3.98111679e-02, ...,\n",
            "          5.50591499e-02,  2.17863902e-01,  2.00000000e+00],\n",
            "        [ 1.37769163e-01, -3.32535915e-02, -1.84411854e-02, ...,\n",
            "          2.10375085e-01,  1.31940395e-01,  2.00000000e+00],\n",
            "        [ 1.17745981e-01,  2.35484298e-02, -1.90765760e-03, ...,\n",
            "          2.98111618e-01, -2.87139416e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-3.69124510e-03,  1.54321462e-01,  1.59199640e-01, ...,\n",
            "          2.71449611e-02,  4.24759686e-02,  2.00000000e+00],\n",
            "        [-1.96716174e-01,  1.52448937e-01,  3.14545155e-01, ...,\n",
            "          5.59401773e-02,  5.41450176e-03,  2.00000000e+00],\n",
            "        [-2.59360760e-01,  1.09148055e-01,  2.89440870e-01, ...,\n",
            "          7.32594058e-02,  5.21720154e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01747171, -0.11298119, -0.03627186, ...,  0.02883613,\n",
            "          0.20004757,  2.        ],\n",
            "        [ 0.12908563, -0.0073276 , -0.00449342, ...,  0.22276494,\n",
            "          0.07688253,  2.        ],\n",
            "        [ 0.14315479,  0.06076347,  0.01012726, ...,  0.28814504,\n",
            "         -0.0720024 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.00502208,  0.11799572,  0.14198212, ...,  0.01259906,\n",
            "          0.03604037,  2.        ],\n",
            "        [-0.20186229,  0.13192618,  0.34706154, ...,  0.04025278,\n",
            "         -0.01123837,  2.        ],\n",
            "        [-0.27858195,  0.09573471,  0.31521913, ...,  0.03848377,\n",
            "         -0.00457751,  2.        ]], dtype=float32)\n",
            " array([[-0.02430294, -0.12333473, -0.02408767, ...,  0.03768035,\n",
            "          0.2075672 ,  2.        ],\n",
            "        [ 0.12043267, -0.0353735 ,  0.00401036, ...,  0.22996634,\n",
            "          0.11784622,  2.        ],\n",
            "        [ 0.11657033,  0.02418208,  0.02728388, ...,  0.30954465,\n",
            "         -0.02008249,  2.        ],\n",
            "        ...,\n",
            "        [-0.07469839,  0.13302572,  0.23537374, ...,  0.0470724 ,\n",
            "          0.00504803,  2.        ],\n",
            "        [-0.24745455,  0.13451049,  0.36158562, ...,  0.04128824,\n",
            "         -0.02310033,  2.        ],\n",
            "        [-0.30060872,  0.10042753,  0.314721  , ...,  0.03986115,\n",
            "         -0.00439297,  2.        ]], dtype=float32)\n",
            " array([[-0.02383904, -0.12965418, -0.02458566, ...,  0.04001015,\n",
            "          0.20825982,  2.        ],\n",
            "        [ 0.12761806, -0.03696444,  0.00670167, ...,  0.23356327,\n",
            "          0.12374615,  2.        ],\n",
            "        [ 0.12371228,  0.01799067,  0.02961966, ...,  0.3094534 ,\n",
            "         -0.0110709 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.08717255,  0.14012793,  0.24550197, ...,  0.0560042 ,\n",
            "          0.00348415,  2.        ],\n",
            "        [-0.24920069,  0.13037583,  0.35751116, ...,  0.04817497,\n",
            "         -0.02466202,  2.        ],\n",
            "        [-0.29687876,  0.09742802,  0.30747113, ...,  0.04143293,\n",
            "         -0.00718639,  2.        ]], dtype=float32)\n",
            " array([[ 0.00867058, -0.11601037, -0.0580594 , ...,  0.04590271,\n",
            "          0.21018623,  2.        ],\n",
            "        [ 0.18575552, -0.01800278, -0.04775624, ...,  0.22812831,\n",
            "          0.07886266,  2.        ],\n",
            "        [ 0.1705447 ,  0.03319638, -0.03990139, ...,  0.30899668,\n",
            "         -0.06725545,  2.        ],\n",
            "        ...,\n",
            "        [ 0.09364977,  0.08289639,  0.08053694, ...,  0.02892976,\n",
            "          0.04295725,  2.        ],\n",
            "        [-0.13463995,  0.11979156,  0.29074815, ...,  0.083671  ,\n",
            "         -0.01308422,  2.        ],\n",
            "        [-0.24189198,  0.10526612,  0.28128463, ...,  0.05998348,\n",
            "         -0.0038451 ,  2.        ]], dtype=float32)\n",
            " array([[-0.01649973, -0.12951855, -0.02718094, ...,  0.04717202,\n",
            "          0.21139564,  2.        ],\n",
            "        [ 0.15327452, -0.03555502, -0.00556271, ...,  0.2680717 ,\n",
            "          0.12642746,  2.        ],\n",
            "        [ 0.15252395,  0.02147505,  0.00877771, ...,  0.34726208,\n",
            "         -0.00233532,  2.        ],\n",
            "        ...,\n",
            "        [-0.0480383 ,  0.12249365,  0.21005568, ...,  0.08723339,\n",
            "          0.02010909,  2.        ],\n",
            "        [-0.2258082 ,  0.12289451,  0.33098954, ...,  0.08163191,\n",
            "         -0.01431391,  2.        ],\n",
            "        [-0.27508825,  0.10211354,  0.29534855, ...,  0.06035616,\n",
            "          0.00331995,  2.        ]], dtype=float32)\n",
            " array([[-0.03076708, -0.15191388, -0.05843464, ...,  0.05692876,\n",
            "          0.19354418,  2.        ],\n",
            "        [ 0.12033758, -0.12027757, -0.06107125, ...,  0.26006308,\n",
            "          0.15414916,  2.        ],\n",
            "        [ 0.0536495 , -0.11695078, -0.0693789 , ...,  0.36231515,\n",
            "          0.08788099,  2.        ],\n",
            "        ...,\n",
            "        [-0.23228878,  0.04865343,  0.19882174, ...,  0.0367942 ,\n",
            "         -0.07747597,  2.        ],\n",
            "        [-0.27519006,  0.06498305,  0.21128051, ...,  0.0377805 ,\n",
            "         -0.07697756,  2.        ],\n",
            "        [-0.24600554,  0.04131319,  0.23887305, ..., -0.00541983,\n",
            "         -0.04715889,  2.        ]], dtype=float32)\n",
            " array([[-2.92799473e-02, -1.51216060e-01, -5.93715422e-02, ...,\n",
            "          6.20769784e-02,  1.94987550e-01,  2.00000000e+00],\n",
            "        [ 1.29254833e-01, -1.22453570e-01, -6.36853799e-02, ...,\n",
            "          2.71552056e-01,  1.57429859e-01,  2.00000000e+00],\n",
            "        [ 5.97847104e-02, -1.16260745e-01, -6.77718446e-02, ...,\n",
            "          3.78405273e-01,  8.83190632e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-2.14331403e-01,  5.33599220e-02,  1.82250962e-01, ...,\n",
            "          3.03290989e-02, -7.53905922e-02,  2.00000000e+00],\n",
            "        [-2.65263230e-01,  6.87379315e-02,  2.04513550e-01, ...,\n",
            "          4.06261943e-02, -6.94511086e-02,  2.00000000e+00],\n",
            "        [-2.42122442e-01,  4.54094410e-02,  2.33200669e-01, ...,\n",
            "         -2.54302227e-04, -4.28718477e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 0.02592978, -0.1326232 , -0.07961189, ...,  0.05596863,\n",
            "          0.20637383,  2.        ],\n",
            "        [ 0.21014342, -0.0068955 , -0.07053353, ...,  0.24094509,\n",
            "          0.06082471,  2.        ],\n",
            "        [ 0.1806632 ,  0.0251996 , -0.06644922, ...,  0.33482185,\n",
            "         -0.09376422,  2.        ],\n",
            "        ...,\n",
            "        [ 0.16433279,  0.04667316,  0.04105252, ...,  0.0580323 ,\n",
            "          0.04245109,  2.        ],\n",
            "        [-0.08040489,  0.11569528,  0.25044635, ...,  0.09958172,\n",
            "         -0.0085832 ,  2.        ],\n",
            "        [-0.21052949,  0.07483868,  0.26468652, ...,  0.07874145,\n",
            "         -0.01025286,  2.        ]], dtype=float32)\n",
            " array([[-1.5702039e-03, -1.0780942e-01, -5.6409631e-02, ...,\n",
            "          2.4482258e-02,  1.9899438e-01,  2.0000000e+00],\n",
            "        [ 1.5230379e-01, -6.6180816e-03, -2.8903238e-02, ...,\n",
            "          2.1732223e-01,  6.0890283e-02,  2.0000000e+00],\n",
            "        [ 1.6241680e-01,  5.0100490e-02, -2.5908558e-02, ...,\n",
            "          2.8654638e-01, -8.7927923e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.6396686e-02,  8.5167661e-02,  6.7811556e-02, ...,\n",
            "          1.5955605e-02,  6.6210538e-02,  2.0000000e+00],\n",
            "        [-1.6055493e-01,  1.2701751e-01,  3.0842143e-01, ...,\n",
            "          6.2837563e-02, -2.1741153e-03,  2.0000000e+00],\n",
            "        [-2.6350069e-01,  8.7668598e-02,  3.0035982e-01, ...,\n",
            "          5.3289771e-02, -4.6337876e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.03058418, -0.16082561, -0.0559805 , ...,  0.06539982,\n",
            "          0.2161643 ,  2.        ],\n",
            "        [ 0.15551051, -0.10602922, -0.07627898, ...,  0.30454612,\n",
            "          0.15745208,  2.        ],\n",
            "        [ 0.10616075, -0.10531559, -0.08296652, ...,  0.4059495 ,\n",
            "          0.06904098,  2.        ],\n",
            "        ...,\n",
            "        [-0.12423263,  0.00211582,  0.19173262, ...,  0.0993957 ,\n",
            "         -0.00847089,  2.        ],\n",
            "        [-0.2160071 ,  0.0239162 ,  0.20072073, ...,  0.08656564,\n",
            "         -0.04093348,  2.        ],\n",
            "        [-0.25570178,  0.01003918,  0.22974817, ...,  0.04128231,\n",
            "         -0.02225566,  2.        ]], dtype=float32)\n",
            " array([[ 5.17729074e-02, -2.19369695e-01, -1.17399156e-01, ...,\n",
            "         -1.66878253e-02,  1.98648214e-01,  2.00000000e+00],\n",
            "        [ 3.10936123e-01,  2.58923527e-02, -9.55180079e-02, ...,\n",
            "          2.84913331e-02,  1.00180451e-02,  2.00000000e+00],\n",
            "        [ 3.21848661e-01,  5.93319274e-02, -7.92049021e-02, ...,\n",
            "          8.75126645e-02, -6.49503618e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.70968980e-01, -7.25491066e-03, -1.35978609e-01, ...,\n",
            "          5.09137549e-02,  5.96464910e-02,  2.00000000e+00],\n",
            "        [ 3.30771655e-02,  5.89126535e-02,  1.01152264e-01, ...,\n",
            "          1.10715002e-01, -9.12269950e-03,  2.00000000e+00],\n",
            "        [-1.43789366e-01,  1.62790120e-02,  2.84120321e-01, ...,\n",
            "          4.67642285e-02,  1.61156373e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 0.01186576, -0.11134393, -0.0601698 , ...,  0.05406455,\n",
            "          0.20991398,  2.        ],\n",
            "        [ 0.16796778, -0.01614368, -0.05501695, ...,  0.2268102 ,\n",
            "          0.09440993,  2.        ],\n",
            "        [ 0.15976608,  0.03328632, -0.04268743, ...,  0.30741888,\n",
            "         -0.06619439,  2.        ],\n",
            "        ...,\n",
            "        [ 0.0911177 ,  0.10390371,  0.05591189, ...,  0.03205312,\n",
            "          0.05758102,  2.        ],\n",
            "        [-0.1420398 ,  0.1343779 ,  0.2699548 , ...,  0.08813463,\n",
            "         -0.00442374,  2.        ],\n",
            "        [-0.24249068,  0.0958266 ,  0.27927187, ...,  0.06823157,\n",
            "         -0.00403144,  2.        ]], dtype=float32)\n",
            " array([[-1.74365137e-02, -1.19775884e-01, -3.36936787e-02, ...,\n",
            "          3.72975357e-02,  2.06463039e-01,  2.00000000e+00],\n",
            "        [ 1.33016020e-01, -1.71044879e-02, -2.10805191e-03, ...,\n",
            "          2.28055120e-01,  1.02163725e-01,  2.00000000e+00],\n",
            "        [ 1.31059080e-01,  4.66331914e-02,  1.56238070e-02, ...,\n",
            "          3.01663280e-01, -4.16454822e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.36975013e-02,  1.32258475e-01,  1.71642721e-01, ...,\n",
            "          3.59254293e-02,  3.48837934e-02,  2.00000000e+00],\n",
            "        [-2.19783932e-01,  1.26912221e-01,  3.37808877e-01, ...,\n",
            "          4.95257080e-02, -5.33087645e-03,  2.00000000e+00],\n",
            "        [-2.79244214e-01,  9.80862379e-02,  2.98085600e-01, ...,\n",
            "          4.19885367e-02,  1.74474169e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02983232, -0.14659917, -0.03566116, ...,  0.06035346,\n",
            "          0.2158043 ,  2.        ],\n",
            "        [ 0.16453004, -0.07600013, -0.04240802, ...,  0.27383992,\n",
            "          0.15834017,  2.        ],\n",
            "        [ 0.12074443, -0.05880851, -0.03517045, ...,  0.36845112,\n",
            "          0.05626207,  2.        ],\n",
            "        ...,\n",
            "        [-0.11721491,  0.05350009,  0.21673356, ...,  0.08536812,\n",
            "          0.00872264,  2.        ],\n",
            "        [-0.23567922,  0.04986363,  0.2645867 , ...,  0.0695653 ,\n",
            "         -0.0346719 ,  2.        ],\n",
            "        [-0.27727816,  0.06095142,  0.26310274, ...,  0.04411001,\n",
            "         -0.01205712,  2.        ]], dtype=float32)\n",
            " array([[ 0.03611891, -0.12666522, -0.08665457, ...,  0.02848442,\n",
            "          0.19340439,  2.        ],\n",
            "        [ 0.21188071, -0.03314567, -0.07926604, ...,  0.20883228,\n",
            "          0.06193379,  2.        ],\n",
            "        [ 0.19990154,  0.00714263, -0.0645055 , ...,  0.29083028,\n",
            "         -0.08719877,  2.        ],\n",
            "        ...,\n",
            "        [ 0.1620112 ,  0.02510812,  0.00312538, ...,  0.06354415,\n",
            "          0.06524449,  2.        ],\n",
            "        [-0.06319188,  0.07950925,  0.23452695, ...,  0.11591317,\n",
            "         -0.01788844,  2.        ],\n",
            "        [-0.22901967,  0.06243887,  0.2816109 , ...,  0.08743662,\n",
            "         -0.01504868,  2.        ]], dtype=float32)\n",
            " array([[ 0.01754181, -0.11630016, -0.06281462, ...,  0.02273544,\n",
            "          0.18931058,  2.        ],\n",
            "        [ 0.19560894, -0.01384257, -0.04615188, ...,  0.22156006,\n",
            "          0.02796651,  2.        ],\n",
            "        [ 0.1913634 ,  0.0314828 , -0.04373498, ...,  0.28016046,\n",
            "         -0.10216887,  2.        ],\n",
            "        ...,\n",
            "        [ 0.09434528,  0.03785443,  0.03574145, ...,  0.04151082,\n",
            "          0.07260939,  2.        ],\n",
            "        [-0.12191379,  0.10615824,  0.30424228, ...,  0.09194328,\n",
            "         -0.01042496,  2.        ],\n",
            "        [-0.25033888,  0.07719075,  0.301972  , ...,  0.057828  ,\n",
            "         -0.01297911,  2.        ]], dtype=float32)\n",
            " array([[-0.03295666, -0.13019381, -0.03267292, ...,  0.05572275,\n",
            "          0.21046405,  2.        ],\n",
            "        [ 0.14573221, -0.05493668, -0.02974645, ...,  0.25579748,\n",
            "          0.14877038,  2.        ],\n",
            "        [ 0.11409359, -0.03256965, -0.0117433 , ...,  0.34428534,\n",
            "          0.04563309,  2.        ],\n",
            "        ...,\n",
            "        [-0.15857704,  0.09135657,  0.26127622, ...,  0.07831275,\n",
            "         -0.01162989,  2.        ],\n",
            "        [-0.26879606,  0.07700376,  0.30448675, ...,  0.06753937,\n",
            "         -0.0477221 ,  2.        ],\n",
            "        [-0.30008456,  0.08502801,  0.28444794, ...,  0.03785806,\n",
            "         -0.0185583 ,  2.        ]], dtype=float32)\n",
            " array([[-0.01637167, -0.1288519 , -0.02728851, ...,  0.0465681 ,\n",
            "          0.21114227,  3.        ],\n",
            "        [ 0.14970583, -0.03769656, -0.00590002, ...,  0.26253805,\n",
            "          0.12575346,  3.        ],\n",
            "        [ 0.14947744,  0.02082173,  0.0102956 , ...,  0.3421139 ,\n",
            "         -0.01125154,  3.        ],\n",
            "        ...,\n",
            "        [-0.04038913,  0.12055006,  0.20441075, ...,  0.08161098,\n",
            "          0.01975922,  3.        ],\n",
            "        [-0.2248375 ,  0.12595537,  0.33333123, ...,  0.07731747,\n",
            "         -0.01435323,  3.        ],\n",
            "        [-0.27460414,  0.10538875,  0.29561898, ...,  0.05601711,\n",
            "          0.00347381,  3.        ]], dtype=float32)\n",
            " array([[-0.02237599, -0.13794209, -0.02849396, ...,  0.0545837 ,\n",
            "          0.21695396,  0.        ],\n",
            "        [ 0.1472648 , -0.04886949, -0.01070032, ...,  0.25292358,\n",
            "          0.13949284,  0.        ],\n",
            "        [ 0.13595644,  0.0012    ,  0.01098617, ...,  0.33817923,\n",
            "          0.00708071,  0.        ],\n",
            "        ...,\n",
            "        [-0.09056563,  0.14234915,  0.2211558 , ...,  0.06590389,\n",
            "          0.00173809,  0.        ],\n",
            "        [-0.2468245 ,  0.13254449,  0.3203731 , ...,  0.06539837,\n",
            "         -0.028892  ,  0.        ],\n",
            "        [-0.2872361 ,  0.09743987,  0.292311  , ...,  0.06523556,\n",
            "         -0.00294644,  0.        ]], dtype=float32)\n",
            " array([[-2.42558420e-02, -1.33070305e-01, -2.52358932e-02, ...,\n",
            "          4.68528122e-02,  2.09280178e-01,  0.00000000e+00],\n",
            "        [ 1.35332480e-01, -4.81409691e-02, -1.06527805e-02, ...,\n",
            "          2.57648170e-01,  1.31897673e-01,  0.00000000e+00],\n",
            "        [ 1.21124707e-01, -2.68997089e-03,  8.18575919e-03, ...,\n",
            "          3.44128191e-01,  9.89921112e-03,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-1.16736397e-01,  1.26858488e-01,  2.42055893e-01, ...,\n",
            "          8.18403289e-02, -3.14121833e-04,  0.00000000e+00],\n",
            "        [-2.54189491e-01,  1.13990277e-01,  3.29869926e-01, ...,\n",
            "          6.78133368e-02, -2.99450103e-02,  0.00000000e+00],\n",
            "        [-2.99777687e-01,  9.09529924e-02,  2.98318952e-01, ...,\n",
            "          4.84187864e-02, -1.16631445e-02,  0.00000000e+00]], dtype=float32)\n",
            " array([[-1.86443180e-02, -1.14403613e-01, -3.66871282e-02, ...,\n",
            "          3.44535522e-02,  2.02536866e-01,  0.00000000e+00],\n",
            "        [ 1.28941491e-01, -1.34679005e-02, -7.26275425e-03, ...,\n",
            "          2.32615247e-01,  7.87707418e-02,  0.00000000e+00],\n",
            "        [ 1.38211876e-01,  5.72253950e-02,  7.17473403e-03, ...,\n",
            "          3.01659256e-01, -6.71571270e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.46273915e-02,  1.18760914e-01,  1.27757072e-01, ...,\n",
            "          2.63439063e-02,  5.17172180e-02,  0.00000000e+00],\n",
            "        [-2.02498034e-01,  1.28486186e-01,  3.33142579e-01, ...,\n",
            "          5.42437509e-02, -4.66221943e-03,  0.00000000e+00],\n",
            "        [-2.80517250e-01,  9.72236097e-02,  3.03642035e-01, ...,\n",
            "          4.70051803e-02,  2.85063521e-04,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.03520603, -0.15269056, -0.05638042, ...,  0.05950005,\n",
            "          0.2096184 ,  0.        ],\n",
            "        [ 0.13771114, -0.11372418, -0.07597794, ...,  0.2843338 ,\n",
            "          0.16246186,  0.        ],\n",
            "        [ 0.07982775, -0.11375597, -0.08034786, ...,  0.3898306 ,\n",
            "          0.08527289,  0.        ],\n",
            "        ...,\n",
            "        [-0.18515281,  0.02249629,  0.2020171 , ...,  0.10690989,\n",
            "         -0.03759996,  0.        ],\n",
            "        [-0.26020315,  0.03722868,  0.20510858, ...,  0.08578946,\n",
            "         -0.06747767,  0.        ],\n",
            "        [-0.2766243 ,  0.01963335,  0.24109223, ...,  0.02242417,\n",
            "         -0.03625875,  0.        ]], dtype=float32)\n",
            " array([[-0.02202629, -0.13436879, -0.02889259, ...,  0.05068167,\n",
            "          0.21745206,  0.        ],\n",
            "        [ 0.14232685, -0.04635741, -0.00772201, ...,  0.24418433,\n",
            "          0.1361179 ,  0.        ],\n",
            "        [ 0.13293922,  0.00962984,  0.0164728 , ...,  0.32424733,\n",
            "         -0.00218674,  0.        ],\n",
            "        ...,\n",
            "        [-0.07771487,  0.14870672,  0.21504687, ...,  0.05266661,\n",
            "          0.01104627,  0.        ],\n",
            "        [-0.2379851 ,  0.14174719,  0.31742185, ...,  0.05898244,\n",
            "         -0.0223893 ,  0.        ],\n",
            "        [-0.28365573,  0.10113052,  0.2916664 , ...,  0.06497268,\n",
            "         -0.00194701,  0.        ]], dtype=float32)\n",
            " array([[-0.02498045, -0.12927376, -0.02357622, ...,  0.04350647,\n",
            "          0.2070475 ,  0.        ],\n",
            "        [ 0.12868738, -0.04182516,  0.0007332 , ...,  0.24692357,\n",
            "          0.12649925,  0.        ],\n",
            "        [ 0.11650721,  0.0049977 ,  0.02166218, ...,  0.3276018 ,\n",
            "          0.00350045,  0.        ],\n",
            "        ...,\n",
            "        [-0.11177039,  0.13366191,  0.25230017, ...,  0.07015545,\n",
            "         -0.00320341,  0.        ],\n",
            "        [-0.2561651 ,  0.12229806,  0.34907886, ...,  0.05825484,\n",
            "         -0.03223031,  0.        ],\n",
            "        [-0.3023876 ,  0.09488626,  0.30717382, ...,  0.04276699,\n",
            "         -0.01185198,  0.        ]], dtype=float32)\n",
            " array([[-0.02912681, -0.12344509, -0.0261516 , ...,  0.0490243 ,\n",
            "          0.20478661,  0.        ],\n",
            "        [ 0.1327806 , -0.05389144, -0.01614528, ...,  0.24706823,\n",
            "          0.13660993,  0.        ],\n",
            "        [ 0.11406272, -0.01961334,  0.00319512, ...,  0.3403934 ,\n",
            "          0.0138936 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.14641969,  0.12369169,  0.255305  , ...,  0.08261113,\n",
            "         -0.00920618,  0.        ],\n",
            "        [-0.26673347,  0.11029909,  0.3267629 , ...,  0.06538752,\n",
            "         -0.03944035,  0.        ],\n",
            "        [-0.30820256,  0.0937884 ,  0.29711363, ...,  0.03974879,\n",
            "         -0.01746876,  0.        ]], dtype=float32)\n",
            " array([[-0.02331657, -0.12999949, -0.02980142, ...,  0.04924263,\n",
            "          0.21334775,  0.        ],\n",
            "        [ 0.13829991, -0.04144775, -0.00632616, ...,  0.24773748,\n",
            "          0.1277436 ,  0.        ],\n",
            "        [ 0.1348685 ,  0.01702049,  0.01772079, ...,  0.32621062,\n",
            "         -0.01438168,  0.        ],\n",
            "        ...,\n",
            "        [-0.09448799,  0.14652334,  0.23677878, ...,  0.06393766,\n",
            "         -0.00155833,  0.        ],\n",
            "        [-0.2505008 ,  0.13837217,  0.33957246, ...,  0.05818041,\n",
            "         -0.03186399,  0.        ],\n",
            "        [-0.28937504,  0.10306723,  0.30107793, ...,  0.0587499 ,\n",
            "         -0.00393274,  0.        ]], dtype=float32)\n",
            " array([[ 0.00314237, -0.10345753, -0.06425022, ...,  0.03365968,\n",
            "          0.20227502,  0.        ],\n",
            "        [ 0.16405986,  0.00820009, -0.03701883, ...,  0.22435915,\n",
            "          0.07566608,  0.        ],\n",
            "        [ 0.16860142,  0.06254929, -0.02757354, ...,  0.3052232 ,\n",
            "         -0.0809003 ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.07833051,  0.0856446 ,  0.04953894, ...,  0.04335492,\n",
            "          0.05621871,  0.        ],\n",
            "        [-0.1463221 ,  0.13708052,  0.3006408 , ...,  0.08128867,\n",
            "         -0.00704555,  0.        ],\n",
            "        [-0.25395906,  0.098526  ,  0.29274333, ...,  0.06304353,\n",
            "         -0.0026616 ,  0.        ]], dtype=float32)\n",
            " array([[-0.03413427, -0.12462689, -0.03117526, ...,  0.05197352,\n",
            "          0.20739534,  0.        ],\n",
            "        [ 0.13395461, -0.05592593, -0.03250667, ...,  0.25526106,\n",
            "          0.14703372,  0.        ],\n",
            "        [ 0.10559446, -0.0313003 , -0.02168581, ...,  0.34648967,\n",
            "          0.03913869,  0.        ],\n",
            "        ...,\n",
            "        [-0.15795322,  0.09697188,  0.25007498, ...,  0.08759096,\n",
            "          0.00051561,  0.        ],\n",
            "        [-0.27152717,  0.08249653,  0.3074991 , ...,  0.06613325,\n",
            "         -0.03793184,  0.        ],\n",
            "        [-0.31129405,  0.08297896,  0.29005346, ...,  0.03109119,\n",
            "         -0.01930606,  0.        ]], dtype=float32)\n",
            " array([[-0.02324015, -0.12834632, -0.02483963, ...,  0.04037478,\n",
            "          0.20833743,  0.        ],\n",
            "        [ 0.12641087, -0.03826324,  0.00336283, ...,  0.2399566 ,\n",
            "          0.12272856,  0.        ],\n",
            "        [ 0.12148178,  0.01825456,  0.02613478, ...,  0.31698805,\n",
            "         -0.0108926 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.08127248,  0.13668323,  0.2388177 , ...,  0.06151449,\n",
            "          0.00779734,  0.        ],\n",
            "        [-0.24687795,  0.13052373,  0.35308495, ...,  0.05310778,\n",
            "         -0.02461996,  0.        ],\n",
            "        [-0.29901123,  0.09712976,  0.30767545, ...,  0.04448463,\n",
            "         -0.0086096 ,  0.        ]], dtype=float32)\n",
            " array([[-0.02191956, -0.16947204, -0.04666083, ...,  0.06804747,\n",
            "          0.21122286,  0.        ],\n",
            "        [ 0.19010037, -0.09707025, -0.05902236, ...,  0.31030995,\n",
            "          0.14689533,  0.        ],\n",
            "        [ 0.14861673, -0.09184304, -0.06049786, ...,  0.39847288,\n",
            "          0.06156828,  0.        ],\n",
            "        ...,\n",
            "        [-0.08050936,  0.00666223,  0.16119303, ...,  0.09916874,\n",
            "          0.01489405,  0.        ],\n",
            "        [-0.19062643,  0.02274868,  0.19891344, ...,  0.08591622,\n",
            "         -0.02045695,  0.        ],\n",
            "        [-0.240873  ,  0.02195768,  0.22737187, ...,  0.05699196,\n",
            "         -0.01445276,  0.        ]], dtype=float32)\n",
            " array([[-1.4399991e-02, -1.1611620e-01, -3.4175631e-02, ...,\n",
            "          4.3111969e-02,  2.0754968e-01,  0.0000000e+00],\n",
            "        [ 1.3994357e-01, -2.0907745e-02, -1.4895519e-02, ...,\n",
            "          2.4935885e-01,  9.8450713e-02,  0.0000000e+00],\n",
            "        [ 1.5063439e-01,  4.8895083e-02, -2.9921078e-03, ...,\n",
            "          3.1882977e-01, -4.9629584e-02,  0.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.2369733e-02,  1.2092329e-01,  1.5318510e-01, ...,\n",
            "          5.5114411e-02,  3.8252894e-02,  0.0000000e+00],\n",
            "        [-1.9987206e-01,  1.2628531e-01,  3.3233190e-01, ...,\n",
            "          8.0706403e-02,  2.2220312e-04,  0.0000000e+00],\n",
            "        [-2.6456979e-01,  1.0794211e-01,  2.9637685e-01, ...,\n",
            "          5.5213694e-02,  9.5783425e-03,  0.0000000e+00]], dtype=float32)\n",
            " array([[ 2.41555063e-05, -1.09340362e-01, -5.06579280e-02, ...,\n",
            "          4.11569811e-02,  2.03350440e-01,  0.00000000e+00],\n",
            "        [ 1.80355743e-01, -3.93523648e-03, -4.20061797e-02, ...,\n",
            "          2.55870432e-01,  5.73865511e-02,  0.00000000e+00],\n",
            "        [ 1.90443814e-01,  5.69635369e-02, -3.95333320e-02, ...,\n",
            "          3.13446760e-01, -7.72397742e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 9.62907746e-02,  7.98243806e-02,  3.81246209e-02, ...,\n",
            "          5.77899925e-02,  6.13779463e-02,  0.00000000e+00],\n",
            "        [-1.37794763e-01,  1.23467304e-01,  3.00123334e-01, ...,\n",
            "          1.13006644e-01, -6.55732071e-03,  0.00000000e+00],\n",
            "        [-2.44163126e-01,  1.03626445e-01,  2.89366066e-01, ...,\n",
            "          6.78095594e-02,  5.92817366e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.02348512, -0.13035853, -0.02980401, ...,  0.04711983,\n",
            "          0.21473412,  0.        ],\n",
            "        [ 0.1260452 , -0.03821783, -0.00837306, ...,  0.24236621,\n",
            "          0.12395158,  0.        ],\n",
            "        [ 0.13071689,  0.02528022,  0.01496376, ...,  0.3206218 ,\n",
            "         -0.020647  ,  0.        ],\n",
            "        ...,\n",
            "        [-0.06717963,  0.1401748 ,  0.21846785, ...,  0.051353  ,\n",
            "          0.00383256,  0.        ],\n",
            "        [-0.24169195,  0.14132321,  0.34078777, ...,  0.05338374,\n",
            "         -0.02264558,  0.        ],\n",
            "        [-0.28718206,  0.10064969,  0.30389717, ...,  0.05898089,\n",
            "          0.00114197,  0.        ]], dtype=float32)\n",
            " array([[-0.02133249, -0.1220579 , -0.02948798, ...,  0.03886698,\n",
            "          0.20653169,  0.        ],\n",
            "        [ 0.12251801, -0.02438235, -0.00221275, ...,  0.23411056,\n",
            "          0.10763633,  0.        ],\n",
            "        [ 0.12253804,  0.0401642 ,  0.0158961 , ...,  0.30832183,\n",
            "         -0.03271574,  0.        ],\n",
            "        ...,\n",
            "        [-0.02833656,  0.1319901 ,  0.19092004, ...,  0.03881343,\n",
            "          0.02801788,  0.        ],\n",
            "        [-0.2297713 ,  0.12981924,  0.3466661 , ...,  0.04682697,\n",
            "         -0.00937745,  0.        ],\n",
            "        [-0.28895962,  0.10025246,  0.30626532, ...,  0.04376646,\n",
            "         -0.00085595,  0.        ]], dtype=float32)\n",
            " array([[ 0.05354775, -0.20470047, -0.10656381, ..., -0.01139846,\n",
            "          0.18814053,  0.        ],\n",
            "        [ 0.31474578,  0.01916454, -0.09842851, ...,  0.07402953,\n",
            "          0.00989604,  0.        ],\n",
            "        [ 0.31240755,  0.05506718, -0.07978693, ...,  0.12204283,\n",
            "         -0.09469166,  0.        ],\n",
            "        ...,\n",
            "        [ 0.16424008, -0.01194559, -0.1623185 , ...,  0.03517276,\n",
            "          0.07698955,  0.        ],\n",
            "        [ 0.01811628,  0.05308146,  0.12953319, ...,  0.10955985,\n",
            "         -0.02127033,  0.        ],\n",
            "        [-0.17442049,  0.02574887,  0.2821743 , ...,  0.05390009,\n",
            "         -0.01381258,  0.        ]], dtype=float32)\n",
            " array([[-0.00746522, -0.11792487, -0.04569609, ...,  0.04964843,\n",
            "          0.21355842,  0.        ],\n",
            "        [ 0.14567359, -0.01528369, -0.02625343, ...,  0.23894136,\n",
            "          0.11684205,  0.        ],\n",
            "        [ 0.15040809,  0.0503085 , -0.00976779, ...,  0.3195206 ,\n",
            "         -0.04657724,  0.        ],\n",
            "        ...,\n",
            "        [-0.00151524,  0.14000621,  0.14292163, ...,  0.04892357,\n",
            "          0.02311725,  0.        ],\n",
            "        [-0.199215  ,  0.1496082 ,  0.306432  , ...,  0.06817286,\n",
            "         -0.00961818,  0.        ],\n",
            "        [-0.2611384 ,  0.1046599 ,  0.289491  , ...,  0.07094705,\n",
            "          0.00325524,  0.        ]], dtype=float32)\n",
            " array([[-0.01667459, -0.11866918, -0.03530796, ...,  0.04408614,\n",
            "          0.21548028,  0.        ],\n",
            "        [ 0.12708516, -0.02275225, -0.00814675, ...,  0.22758338,\n",
            "          0.12531208,  0.        ],\n",
            "        [ 0.13159803,  0.03999691,  0.01641461, ...,  0.29961327,\n",
            "         -0.02670292,  0.        ],\n",
            "        ...,\n",
            "        [-0.03681563,  0.14253345,  0.19735669, ...,  0.04619598,\n",
            "          0.01926314,  0.        ],\n",
            "        [-0.22229438,  0.13939932,  0.34009072, ...,  0.05607871,\n",
            "         -0.0108941 ,  0.        ],\n",
            "        [-0.2814787 ,  0.09870503,  0.3086569 , ...,  0.05591563,\n",
            "         -0.00127252,  0.        ]], dtype=float32)\n",
            " array([[-0.00116715, -0.12458944, -0.04707282, ...,  0.05515541,\n",
            "          0.2145739 ,  0.        ],\n",
            "        [ 0.16360264, -0.011059  , -0.02611814, ...,  0.23877774,\n",
            "          0.11756982,  0.        ],\n",
            "        [ 0.16470131,  0.05197058, -0.00741936, ...,  0.3214787 ,\n",
            "         -0.04036128,  0.        ],\n",
            "        ...,\n",
            "        [ 0.04171571,  0.12739924,  0.11194377, ...,  0.03662002,\n",
            "          0.03801142,  0.        ],\n",
            "        [-0.16612257,  0.13724576,  0.27920854, ...,  0.05670184,\n",
            "         -0.00652385,  0.        ],\n",
            "        [-0.24541552,  0.10863123,  0.27377024, ...,  0.07093716,\n",
            "          0.00240788,  0.        ]], dtype=float32)\n",
            " array([[-0.02138951, -0.12121896, -0.02804859, ...,  0.03832725,\n",
            "          0.2061501 ,  0.        ],\n",
            "        [ 0.12227751, -0.02901548,  0.00065084, ...,  0.233636  ,\n",
            "          0.11118168,  0.        ],\n",
            "        [ 0.12202297,  0.03580398,  0.02136949, ...,  0.30945757,\n",
            "         -0.03127633,  0.        ],\n",
            "        ...,\n",
            "        [-0.03622976,  0.12984183,  0.20354973, ...,  0.04511   ,\n",
            "          0.0156477 ,  0.        ],\n",
            "        [-0.2274242 ,  0.12834181,  0.34840184, ...,  0.05191514,\n",
            "         -0.01845326,  0.        ],\n",
            "        [-0.29116413,  0.1006157 ,  0.31360507, ...,  0.04501297,\n",
            "         -0.00209571,  0.        ]], dtype=float32)\n",
            " array([[ 0.0292323 , -0.13026458, -0.07392593, ...,  0.01161531,\n",
            "          0.18071058,  0.        ],\n",
            "        [ 0.22255997, -0.01906616, -0.0643228 , ...,  0.1909676 ,\n",
            "          0.01456259,  0.        ],\n",
            "        [ 0.22585048,  0.02201726, -0.05601162, ...,  0.24293919,\n",
            "         -0.10981473,  0.        ],\n",
            "        ...,\n",
            "        [ 0.13094366, -0.00153994, -0.05486963, ...,  0.03950429,\n",
            "          0.07099599,  0.        ],\n",
            "        [-0.07871556,  0.0952933 ,  0.26070413, ...,  0.10442971,\n",
            "         -0.03195761,  0.        ],\n",
            "        [-0.26027396,  0.06465278,  0.30386263, ...,  0.07199034,\n",
            "         -0.01824013,  0.        ]], dtype=float32)\n",
            " array([[-0.01502221, -0.12648578, -0.03635695, ...,  0.04745623,\n",
            "          0.21722467,  0.        ],\n",
            "        [ 0.13515028, -0.02770747, -0.01555942, ...,  0.23563454,\n",
            "          0.1274689 ,  0.        ],\n",
            "        [ 0.13488182,  0.0368774 ,  0.00563874, ...,  0.3131228 ,\n",
            "         -0.02639894,  0.        ],\n",
            "        ...,\n",
            "        [-0.01975349,  0.13996498,  0.15909879, ...,  0.04661169,\n",
            "          0.03765636,  0.        ],\n",
            "        [-0.21459916,  0.14373335,  0.31355396, ...,  0.05757703,\n",
            "         -0.00509691,  0.        ],\n",
            "        [-0.27182132,  0.10447467,  0.29051587, ...,  0.06269245,\n",
            "          0.00432717,  0.        ]], dtype=float32)\n",
            " array([[-0.00510096, -0.11692548, -0.04833753, ...,  0.05297056,\n",
            "          0.21689172,  0.        ],\n",
            "        [ 0.14650212, -0.01346086, -0.03239004, ...,  0.23529619,\n",
            "          0.11900122,  0.        ],\n",
            "        [ 0.15362792,  0.04674752, -0.01565224, ...,  0.31561533,\n",
            "         -0.04062163,  0.        ],\n",
            "        ...,\n",
            "        [ 0.04089506,  0.12033158,  0.09682029, ...,  0.04598722,\n",
            "          0.04601602,  0.        ],\n",
            "        [-0.17375886,  0.13551196,  0.28672343, ...,  0.0761872 ,\n",
            "          0.00053146,  0.        ],\n",
            "        [-0.25489768,  0.10845909,  0.2848868 , ...,  0.07535421,\n",
            "          0.01047088,  0.        ]], dtype=float32)\n",
            " array([[-0.03316279, -0.12820487, -0.0324354 , ...,  0.05492957,\n",
            "          0.20910455,  0.        ],\n",
            "        [ 0.13864556, -0.05967386, -0.03882203, ...,  0.27029085,\n",
            "          0.14702472,  0.        ],\n",
            "        [ 0.10975651, -0.03678428, -0.03077625, ...,  0.36207497,\n",
            "          0.04188975,  0.        ],\n",
            "        ...,\n",
            "        [-0.14341213,  0.08856437,  0.23882711, ...,  0.09355155,\n",
            "         -0.0021646 ,  0.        ],\n",
            "        [-0.26176953,  0.0742125 ,  0.2981877 , ...,  0.07100499,\n",
            "         -0.0370827 ,  0.        ],\n",
            "        [-0.30743945,  0.07988156,  0.28690654, ...,  0.03674104,\n",
            "         -0.01758117,  0.        ]], dtype=float32)\n",
            " array([[ 0.01544338, -0.11191582, -0.06711379, ...,  0.0387624 ,\n",
            "          0.20880277,  0.        ],\n",
            "        [ 0.17980108, -0.00509691, -0.05532445, ...,  0.21865751,\n",
            "          0.07654244,  0.        ],\n",
            "        [ 0.18213606,  0.04107853, -0.04459095, ...,  0.29895964,\n",
            "         -0.07809997,  0.        ],\n",
            "        ...,\n",
            "        [ 0.10755177,  0.06874344,  0.02253051, ...,  0.03950789,\n",
            "          0.07318252,  0.        ],\n",
            "        [-0.12796514,  0.12764364,  0.27037644, ...,  0.08316243,\n",
            "          0.00076525,  0.        ],\n",
            "        [-0.24121305,  0.09661821,  0.2792873 , ...,  0.06378949,\n",
            "         -0.00031788,  0.        ]], dtype=float32)\n",
            " array([[-0.01774156, -0.12600154, -0.02946129, ...,  0.03835232,\n",
            "          0.207582  ,  0.        ],\n",
            "        [ 0.1330399 , -0.02379643, -0.00247252, ...,  0.24293779,\n",
            "          0.1106225 ,  0.        ],\n",
            "        [ 0.13175584,  0.04026794,  0.01832011, ...,  0.32153043,\n",
            "         -0.02509818,  0.        ],\n",
            "        ...,\n",
            "        [-0.01852494,  0.1263586 ,  0.17921685, ...,  0.05430831,\n",
            "          0.03001333,  0.        ],\n",
            "        [-0.2192231 ,  0.12507224,  0.33495733, ...,  0.05876937,\n",
            "         -0.00729459,  0.        ],\n",
            "        [-0.28083536,  0.09817064,  0.29941887, ...,  0.05023274,\n",
            "         -0.00504927,  0.        ]], dtype=float32)\n",
            " array([[-0.01614952, -0.13188967, -0.03547577, ...,  0.05436365,\n",
            "          0.21994983,  0.        ],\n",
            "        [ 0.14762847, -0.04598985, -0.02924673, ...,  0.2617495 ,\n",
            "          0.14277379,  0.        ],\n",
            "        [ 0.1401661 ,  0.00927051, -0.00971096, ...,  0.35632282,\n",
            "         -0.0063797 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.04744829,  0.12966968,  0.17316075, ...,  0.06525526,\n",
            "          0.01877537,  0.        ],\n",
            "        [-0.21268572,  0.1275731 ,  0.2877683 , ...,  0.06961942,\n",
            "         -0.01281438,  0.        ],\n",
            "        [-0.26992685,  0.09392954,  0.27699193, ...,  0.07412635,\n",
            "         -0.00167656,  0.        ]], dtype=float32)\n",
            " array([[-5.41121373e-03, -1.09437518e-01, -4.54782508e-02, ...,\n",
            "          4.09112200e-02,  2.03524277e-01,  0.00000000e+00],\n",
            "        [ 1.62683561e-01, -4.28041676e-03, -2.84687728e-02, ...,\n",
            "          2.50744581e-01,  7.08327517e-02,  0.00000000e+00],\n",
            "        [ 1.75611347e-01,  6.24141246e-02, -2.28141472e-02, ...,\n",
            "          3.11904609e-01, -7.23971352e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 7.81936795e-02,  9.00893584e-02,  5.81045784e-02, ...,\n",
            "          4.02088463e-02,  6.17703199e-02,  0.00000000e+00],\n",
            "        [-1.55216396e-01,  1.26081705e-01,  3.08573246e-01, ...,\n",
            "          9.50367972e-02,  2.96896265e-04,  0.00000000e+00],\n",
            "        [-2.52029330e-01,  1.10479504e-01,  2.90031314e-01, ...,\n",
            "          5.83111756e-02,  6.41053682e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.01483055, -0.12404978, -0.02907629, ...,  0.04485377,\n",
            "          0.21203521,  3.        ],\n",
            "        [ 0.15147495, -0.02539426, -0.0060473 , ...,  0.26071265,\n",
            "          0.12166853,  3.        ],\n",
            "        [ 0.15451987,  0.03823886,  0.00864688, ...,  0.33150798,\n",
            "         -0.0161427 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.01267376,  0.1239945 ,  0.18634842, ...,  0.07411047,\n",
            "          0.02721305,  3.        ],\n",
            "        [-0.21270739,  0.12594137,  0.33383954, ...,  0.07659243,\n",
            "         -0.00646719,  3.        ],\n",
            "        [-0.26683548,  0.10633241,  0.29681826, ...,  0.05612719,\n",
            "          0.00706185,  3.        ]], dtype=float32)\n",
            " array([[-1.9664383e-02, -1.3145210e-01, -3.2571442e-02, ...,\n",
            "          5.1460601e-02,  2.1638456e-01,  1.0000000e+00],\n",
            "        [ 1.4736992e-01, -3.7810158e-02, -1.9345757e-02, ...,\n",
            "          2.5275642e-01,  1.3344666e-01,  1.0000000e+00],\n",
            "        [ 1.4332171e-01,  2.0878928e-02,  2.5516134e-03, ...,\n",
            "          3.3810568e-01, -1.4501036e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-6.5361470e-02,  1.4596152e-01,  1.9768460e-01, ...,\n",
            "          5.5706482e-02,  7.6979063e-03,  1.0000000e+00],\n",
            "        [-2.3335655e-01,  1.3565049e-01,  3.1646645e-01, ...,\n",
            "          5.9482262e-02, -2.3942312e-02,  1.0000000e+00],\n",
            "        [-2.7526352e-01,  9.9643722e-02,  2.8983465e-01, ...,\n",
            "          6.7294002e-02,  5.3236645e-04,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.03336255, -0.15952244, -0.05200159, ...,  0.06538031,\n",
            "          0.2106759 ,  1.        ],\n",
            "        [ 0.17317288, -0.11706089, -0.06572358, ...,  0.31778705,\n",
            "          0.16960695,  1.        ],\n",
            "        [ 0.12067405, -0.10989899, -0.06555831, ...,  0.42198217,\n",
            "          0.0854109 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.1525042 ,  0.02250678,  0.1975867 , ...,  0.11639389,\n",
            "         -0.01327245,  1.        ],\n",
            "        [-0.23907055,  0.03874758,  0.20440514, ...,  0.0912487 ,\n",
            "         -0.04091028,  1.        ],\n",
            "        [-0.2611722 ,  0.02617697,  0.23406261, ...,  0.03640728,\n",
            "         -0.02054228,  1.        ]], dtype=float32)\n",
            " array([[-0.02264646, -0.13338909, -0.03001359, ...,  0.0552885 ,\n",
            "          0.2168349 ,  1.        ],\n",
            "        [ 0.15312776, -0.04587824, -0.01392792, ...,  0.26523095,\n",
            "          0.1403255 ,  1.        ],\n",
            "        [ 0.14211722,  0.00386729,  0.00902171, ...,  0.354598  ,\n",
            "          0.0016262 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.12188178,  0.13225666,  0.25074634, ...,  0.08226662,\n",
            "         -0.02064609,  1.        ],\n",
            "        [-0.24840531,  0.12173783,  0.32328105, ...,  0.0740667 ,\n",
            "         -0.03851113,  1.        ],\n",
            "        [-0.2853853 ,  0.09538835,  0.29468468, ...,  0.06437643,\n",
            "         -0.00526218,  1.        ]], dtype=float32)\n",
            " array([[-0.02370227, -0.13224758, -0.02523117, ...,  0.04588544,\n",
            "          0.20899968,  1.        ],\n",
            "        [ 0.13366564, -0.04899461, -0.00533331, ...,  0.25737756,\n",
            "          0.13377944,  1.        ],\n",
            "        [ 0.11718984, -0.00796367,  0.01465603, ...,  0.3397888 ,\n",
            "          0.01754362,  1.        ],\n",
            "        ...,\n",
            "        [-0.12655433,  0.12947105,  0.25505027, ...,  0.07818237,\n",
            "         -0.00592632,  1.        ],\n",
            "        [-0.25624263,  0.11456487,  0.33708367, ...,  0.06528661,\n",
            "         -0.03251409,  1.        ],\n",
            "        [-0.30377385,  0.08944135,  0.30215925, ...,  0.04715906,\n",
            "         -0.0141461 ,  1.        ]], dtype=float32)\n",
            " array([[-2.78904457e-02, -1.24062918e-01, -3.12797539e-02, ...,\n",
            "          5.37903905e-02,  2.05610096e-01,  1.00000000e+00],\n",
            "        [ 1.40148610e-01, -5.53118065e-02, -2.57421639e-02, ...,\n",
            "          2.61023760e-01,  1.37999669e-01,  1.00000000e+00],\n",
            "        [ 1.22189313e-01, -2.45672222e-02, -1.36317154e-02, ...,\n",
            "          3.57155263e-01,  1.91219002e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.24628715e-01,  1.03917763e-01,  2.24111959e-01, ...,\n",
            "          9.72265601e-02, -2.35226005e-04,  1.00000000e+00],\n",
            "        [-2.52894431e-01,  1.00607783e-01,  3.05962592e-01, ...,\n",
            "          7.20267892e-02, -3.50594446e-02,  1.00000000e+00],\n",
            "        [-3.01327318e-01,  8.79905820e-02,  2.87715733e-01, ...,\n",
            "          4.43134196e-02, -1.85735729e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.01749524, -0.1239253 , -0.03427749, ...,  0.05090967,\n",
            "          0.21397223,  1.        ],\n",
            "        [ 0.14834076, -0.02194314, -0.01346144, ...,  0.25423834,\n",
            "          0.11690494,  1.        ],\n",
            "        [ 0.15216361,  0.04426229,  0.00616973, ...,  0.3268365 ,\n",
            "         -0.03475524,  1.        ],\n",
            "        ...,\n",
            "        [-0.0388938 ,  0.13798706,  0.19590525, ...,  0.05785534,\n",
            "          0.00222138,  1.        ],\n",
            "        [-0.22352073,  0.13879754,  0.32362768, ...,  0.06404681,\n",
            "         -0.02015423,  1.        ],\n",
            "        [-0.26974154,  0.10936551,  0.29587188, ...,  0.07062072,\n",
            "          0.00876498,  1.        ]], dtype=float32)\n",
            " array([[-2.45665163e-02, -1.34312496e-01, -2.75526866e-02, ...,\n",
            "          4.68450971e-02,  2.08608836e-01,  1.00000000e+00],\n",
            "        [ 1.36866882e-01, -4.74484563e-02, -1.19380457e-02, ...,\n",
            "          2.66723394e-01,  1.31052971e-01,  1.00000000e+00],\n",
            "        [ 1.17855869e-01, -8.14324245e-03,  4.64201998e-03, ...,\n",
            "          3.51357371e-01,  1.77231897e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.17316395e-01,  1.19747661e-01,  2.35990450e-01, ...,\n",
            "          8.45808163e-02, -7.60230701e-04,  1.00000000e+00],\n",
            "        [-2.49458432e-01,  1.05175570e-01,  3.21674079e-01, ...,\n",
            "          6.84904605e-02, -3.17641906e-02,  1.00000000e+00],\n",
            "        [-2.99105525e-01,  8.65547359e-02,  2.96258956e-01, ...,\n",
            "          4.89501730e-02, -1.50077827e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.03380454, -0.15741938, -0.0584895 , ...,  0.06213852,\n",
            "          0.21094014,  1.        ],\n",
            "        [ 0.13910751, -0.11913418, -0.08158167, ...,  0.30501398,\n",
            "          0.15522668,  1.        ],\n",
            "        [ 0.08516707, -0.11939061, -0.08924095, ...,  0.407235  ,\n",
            "          0.08010318,  1.        ],\n",
            "        ...,\n",
            "        [-0.1575073 ,  0.00935247,  0.19161813, ...,  0.11336827,\n",
            "         -0.02766697,  1.        ],\n",
            "        [-0.2279045 ,  0.02249978,  0.1927189 , ...,  0.09231174,\n",
            "         -0.05436935,  1.        ],\n",
            "        [-0.26373145,  0.00415025,  0.22885454, ...,  0.03192943,\n",
            "         -0.03265665,  1.        ]], dtype=float32)\n",
            " array([[-0.02049593, -0.13257314, -0.03407004, ...,  0.05660817,\n",
            "          0.21761474,  1.        ],\n",
            "        [ 0.159542  , -0.03424236, -0.0144226 , ...,  0.26799417,\n",
            "          0.12887345,  1.        ],\n",
            "        [ 0.15168414,  0.02457297,  0.00474343, ...,  0.34788233,\n",
            "         -0.01307442,  1.        ],\n",
            "        ...,\n",
            "        [-0.04854366,  0.14668669,  0.2051006 , ...,  0.07333324,\n",
            "          0.0094137 ,  1.        ],\n",
            "        [-0.22564429,  0.13667904,  0.31348994, ...,  0.07235198,\n",
            "         -0.01796333,  1.        ],\n",
            "        [-0.27078265,  0.1042214 ,  0.28862777, ...,  0.07422666,\n",
            "          0.00404603,  1.        ]], dtype=float32)\n",
            " array([[-0.0244292 , -0.13176064, -0.02626042, ...,  0.04327898,\n",
            "          0.21004514,  1.        ],\n",
            "        [ 0.13073008, -0.04800883, -0.0039393 , ...,  0.24726053,\n",
            "          0.13292055,  1.        ],\n",
            "        [ 0.11567546, -0.00404234,  0.01797117, ...,  0.33176   ,\n",
            "          0.00821906,  1.        ],\n",
            "        ...,\n",
            "        [-0.12115783,  0.13153686,  0.24734282, ...,  0.07088745,\n",
            "         -0.00350703,  1.        ],\n",
            "        [-0.2560426 ,  0.12156787,  0.33586764, ...,  0.05657971,\n",
            "         -0.03423894,  1.        ],\n",
            "        [-0.30243674,  0.09213585,  0.3010503 , ...,  0.04409275,\n",
            "         -0.01590163,  1.        ]], dtype=float32)\n",
            " array([[-1.64711885e-02, -1.29008234e-01, -3.04759517e-02, ...,\n",
            "          4.95640524e-02,  2.10281745e-01,  1.00000000e+00],\n",
            "        [ 1.51258275e-01, -3.82613763e-02, -1.32064596e-02, ...,\n",
            "          2.75980294e-01,  1.24914058e-01,  1.00000000e+00],\n",
            "        [ 1.50279000e-01,  1.46878641e-02, -8.83131521e-04, ...,\n",
            "          3.59793633e-01, -7.45686749e-03,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-4.78518158e-02,  1.18684724e-01,  1.97856754e-01, ...,\n",
            "          1.00346074e-01,  1.61595959e-02,  1.00000000e+00],\n",
            "        [-2.23673001e-01,  1.19339734e-01,  3.21650565e-01, ...,\n",
            "          8.73823464e-02, -1.77335478e-02,  1.00000000e+00],\n",
            "        [-2.72497922e-01,  1.02216475e-01,  2.89108157e-01, ...,\n",
            "          5.90588488e-02,  1.98428007e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-9.2304451e-03, -1.1846925e-01, -3.3539265e-02, ...,\n",
            "          4.3783642e-02,  2.0902130e-01,  1.0000000e+00],\n",
            "        [ 1.5776487e-01, -1.7369822e-02, -1.4773730e-02, ...,\n",
            "          2.5961486e-01,  1.0695558e-01,  1.0000000e+00],\n",
            "        [ 1.6547239e-01,  5.2686650e-02, -2.1851732e-04, ...,\n",
            "          3.2864183e-01, -3.9926890e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [ 3.1178327e-02,  1.2141363e-01,  1.4081101e-01, ...,\n",
            "          6.3977428e-02,  4.2776048e-02,  1.0000000e+00],\n",
            "        [-1.8793458e-01,  1.2622254e-01,  3.1939080e-01, ...,\n",
            "          8.4126286e-02, -8.8948582e-08,  1.0000000e+00],\n",
            "        [-2.5644174e-01,  1.1000537e-01,  2.9263857e-01, ...,\n",
            "          5.9298042e-02,  7.1333032e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.0322363 , -0.15823288, -0.04381682, ...,  0.06023479,\n",
            "          0.21169837,  1.        ],\n",
            "        [ 0.16591048, -0.09612425, -0.05398342, ...,  0.3026771 ,\n",
            "          0.15704627,  1.        ],\n",
            "        [ 0.11900704, -0.09456845, -0.05397129, ...,  0.38775668,\n",
            "          0.08525305,  1.        ],\n",
            "        ...,\n",
            "        [-0.1319621 ,  0.01970115,  0.20867203, ...,  0.1140107 ,\n",
            "          0.0100354 ,  1.        ],\n",
            "        [-0.23455724,  0.03319609,  0.23352216, ...,  0.0939602 ,\n",
            "         -0.03806137,  1.        ],\n",
            "        [-0.27426037,  0.03326831,  0.2526274 , ...,  0.03904299,\n",
            "         -0.01821063,  1.        ]], dtype=float32)\n",
            " array([[-0.0378045 , -0.15285866, -0.05741339, ...,  0.06115913,\n",
            "          0.20402932,  1.        ],\n",
            "        [ 0.11943454, -0.12139756, -0.07385018, ...,  0.28325528,\n",
            "          0.15133336,  1.        ],\n",
            "        [ 0.05414636, -0.11784264, -0.08132719, ...,  0.3870265 ,\n",
            "          0.07832758,  1.        ],\n",
            "        ...,\n",
            "        [-0.20849553,  0.03451633,  0.1996971 , ...,  0.09235831,\n",
            "         -0.05796757,  1.        ],\n",
            "        [-0.26309443,  0.05088788,  0.19875664, ...,  0.07833716,\n",
            "         -0.07878377,  1.        ],\n",
            "        [-0.26773664,  0.0227823 ,  0.23444891, ...,  0.02102865,\n",
            "         -0.04289364,  1.        ]], dtype=float32)\n",
            " array([[-2.3037661e-02, -1.3275211e-01, -2.4409924e-02, ...,\n",
            "          4.5870740e-02,  2.0882769e-01,  1.0000000e+00],\n",
            "        [ 1.3580495e-01, -4.5902200e-02, -3.2553058e-03, ...,\n",
            "          2.5412515e-01,  1.3301715e-01,  1.0000000e+00],\n",
            "        [ 1.2123727e-01, -2.9262288e-03,  1.6433522e-02, ...,\n",
            "          3.3625072e-01,  1.6170820e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1660930e-01,  1.3043401e-01,  2.5291446e-01, ...,\n",
            "          7.8278445e-02, -7.7681069e-04,  1.0000000e+00],\n",
            "        [-2.5581652e-01,  1.1684508e-01,  3.3968160e-01, ...,\n",
            "          6.5750510e-02, -2.9008454e-02,  1.0000000e+00],\n",
            "        [-3.0165249e-01,  9.1062844e-02,  3.0189541e-01, ...,\n",
            "          4.8656274e-02, -1.2670942e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02460298, -0.13020667, -0.02479949, ...,  0.04437539,\n",
            "          0.20773336,  1.        ],\n",
            "        [ 0.12706341, -0.05075973, -0.00337186, ...,  0.24664956,\n",
            "          0.13281755,  1.        ],\n",
            "        [ 0.11080398, -0.00871872,  0.01633468, ...,  0.33341128,\n",
            "          0.00796976,  1.        ],\n",
            "        ...,\n",
            "        [-0.1276158 ,  0.1340761 ,  0.2629553 , ...,  0.07944738,\n",
            "         -0.00705965,  1.        ],\n",
            "        [-0.26330543,  0.12430702,  0.34776893, ...,  0.06218985,\n",
            "         -0.03556756,  1.        ],\n",
            "        [-0.30796283,  0.09288449,  0.30591455, ...,  0.04505692,\n",
            "         -0.01777129,  1.        ]], dtype=float32)\n",
            " array([[-0.01620841, -0.11773072, -0.03516945, ...,  0.04362996,\n",
            "          0.2141623 ,  1.        ],\n",
            "        [ 0.14078018, -0.02220813, -0.01490067, ...,  0.2424094 ,\n",
            "          0.1210461 ,  1.        ],\n",
            "        [ 0.14557967,  0.04830053,  0.01100862, ...,  0.31725368,\n",
            "         -0.03361328,  1.        ],\n",
            "        ...,\n",
            "        [-0.01741089,  0.12930603,  0.17857507, ...,  0.0489898 ,\n",
            "          0.02075768,  1.        ],\n",
            "        [-0.20842344,  0.13970393,  0.32807228, ...,  0.06285021,\n",
            "         -0.00764915,  1.        ],\n",
            "        [-0.26904917,  0.10445111,  0.3028323 , ...,  0.06321496,\n",
            "          0.0072558 ,  1.        ]], dtype=float32)\n",
            " array([[-0.01418314, -0.12019573, -0.03814282, ...,  0.04645696,\n",
            "          0.21531636,  1.        ],\n",
            "        [ 0.13174894, -0.019515  , -0.01128546, ...,  0.22620018,\n",
            "          0.12257495,  1.        ],\n",
            "        [ 0.13476354,  0.04570853,  0.00437545, ...,  0.30188993,\n",
            "         -0.03457795,  1.        ],\n",
            "        ...,\n",
            "        [-0.02320079,  0.14353374,  0.1623102 , ...,  0.03084776,\n",
            "          0.03192446,  1.        ],\n",
            "        [-0.21669225,  0.14942133,  0.32556406, ...,  0.04771538,\n",
            "         -0.00456815,  1.        ],\n",
            "        [-0.2713474 ,  0.10159727,  0.29738098, ...,  0.06286889,\n",
            "          0.00328986,  1.        ]], dtype=float32)\n",
            " array([[-0.01255337, -0.11673891, -0.04070864, ...,  0.03707341,\n",
            "          0.20039546,  1.        ],\n",
            "        [ 0.1472193 , -0.00927668, -0.01923006, ...,  0.23944497,\n",
            "          0.07263502,  1.        ],\n",
            "        [ 0.15036267,  0.05548036, -0.00938066, ...,  0.31006548,\n",
            "         -0.06876746,  1.        ],\n",
            "        ...,\n",
            "        [ 0.03779997,  0.11574401,  0.10532504, ...,  0.03302018,\n",
            "          0.04011523,  1.        ],\n",
            "        [-0.19146043,  0.11958548,  0.31669173, ...,  0.06617972,\n",
            "         -0.01339722,  1.        ],\n",
            "        [-0.26819155,  0.09167331,  0.29600394, ...,  0.04660028,\n",
            "         -0.0060981 ,  1.        ]], dtype=float32)\n",
            " array([[-3.4119174e-02, -1.2609503e-01, -3.2121886e-02, ...,\n",
            "          5.3747442e-02,  2.0741294e-01,  1.0000000e+00],\n",
            "        [ 1.3606580e-01, -5.7571292e-02, -3.5891037e-02, ...,\n",
            "          2.5656876e-01,  1.4182188e-01,  1.0000000e+00],\n",
            "        [ 1.1186314e-01, -3.0388186e-02, -2.5419068e-02, ...,\n",
            "          3.5008436e-01,  3.0079493e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.4986108e-01,  9.2533864e-02,  2.4263185e-01, ...,\n",
            "          9.1341436e-02,  9.5851917e-04,  1.0000000e+00],\n",
            "        [-2.6687372e-01,  8.6918660e-02,  3.0241480e-01, ...,\n",
            "          7.0061743e-02, -3.9379880e-02,  1.0000000e+00],\n",
            "        [-3.0663216e-01,  8.3335027e-02,  2.8768888e-01, ...,\n",
            "          3.4783069e-02, -1.9950319e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-2.2607822e-02, -1.3059178e-01, -2.5754562e-02, ...,\n",
            "          4.3271460e-02,  2.0920937e-01,  1.0000000e+00],\n",
            "        [ 1.3324611e-01, -4.5269825e-02, -4.3163975e-03, ...,\n",
            "          2.5232968e-01,  1.2839189e-01,  1.0000000e+00],\n",
            "        [ 1.2332881e-01,  6.4068460e-03,  1.5882131e-02, ...,\n",
            "          3.3774880e-01, -9.0039166e-04,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-9.7444423e-02,  1.3515939e-01,  2.3557778e-01, ...,\n",
            "          7.8423887e-02,  6.2723234e-03,  1.0000000e+00],\n",
            "        [-2.4838863e-01,  1.2595436e-01,  3.3848542e-01, ...,\n",
            "          6.5060414e-02, -2.6763149e-02,  1.0000000e+00],\n",
            "        [-2.9805568e-01,  9.4081685e-02,  3.0058500e-01, ...,\n",
            "          4.9112435e-02, -1.1457022e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02939509, -0.15052249, -0.0435121 , ...,  0.05776186,\n",
            "          0.21362925,  1.        ],\n",
            "        [ 0.15401527, -0.08289156, -0.06814846, ...,  0.29493776,\n",
            "          0.14829867,  1.        ],\n",
            "        [ 0.119144  , -0.0732405 , -0.07406658, ...,  0.38771212,\n",
            "          0.04877469,  1.        ],\n",
            "        ...,\n",
            "        [-0.11935864,  0.0269765 ,  0.19199298, ...,  0.0999032 ,\n",
            "          0.02337913,  1.        ],\n",
            "        [-0.2193294 ,  0.02635626,  0.24202067, ...,  0.07933273,\n",
            "         -0.01793019,  1.        ],\n",
            "        [-0.27621874,  0.03396474,  0.2537206 , ...,  0.04598169,\n",
            "         -0.01728746,  1.        ]], dtype=float32)\n",
            " array([[-0.0155017 , -0.1164477 , -0.03738982, ...,  0.0441276 ,\n",
            "          0.21700682,  1.        ],\n",
            "        [ 0.13892342, -0.02250945, -0.01677296, ...,  0.24084191,\n",
            "          0.12254092,  1.        ],\n",
            "        [ 0.1453566 ,  0.04588739,  0.00709062, ...,  0.31505302,\n",
            "         -0.03336922,  1.        ],\n",
            "        ...,\n",
            "        [-0.01768866,  0.13042194,  0.16877909, ...,  0.04970678,\n",
            "          0.02881481,  1.        ],\n",
            "        [-0.20745632,  0.1445704 ,  0.31804076, ...,  0.06116961,\n",
            "         -0.00462589,  1.        ],\n",
            "        [-0.27287656,  0.10671308,  0.29804462, ...,  0.06321174,\n",
            "          0.00859632,  1.        ]], dtype=float32)\n",
            " array([[-0.03674658, -0.15518832, -0.0555952 , ...,  0.06155408,\n",
            "          0.21135478,  1.        ],\n",
            "        [ 0.13988611, -0.11181495, -0.07855086, ...,  0.3021231 ,\n",
            "          0.15748572,  1.        ],\n",
            "        [ 0.086004  , -0.11208406, -0.08586544, ...,  0.4009268 ,\n",
            "          0.08149134,  1.        ],\n",
            "        ...,\n",
            "        [-0.1688612 ,  0.01622963,  0.20079197, ...,  0.10555796,\n",
            "         -0.03149424,  1.        ],\n",
            "        [-0.2366675 ,  0.02304958,  0.20445564, ...,  0.08749329,\n",
            "         -0.05338522,  1.        ],\n",
            "        [-0.2712694 ,  0.00962042,  0.23740368, ...,  0.02975094,\n",
            "         -0.03293324,  1.        ]], dtype=float32)\n",
            " array([[-1.6869638e-02, -1.2340236e-01, -3.6242716e-02, ...,\n",
            "          4.5904037e-02,  2.1689023e-01,  1.0000000e+00],\n",
            "        [ 1.3710696e-01, -2.3871765e-02, -1.5155001e-02, ...,\n",
            "          2.4205661e-01,  1.2592006e-01,  1.0000000e+00],\n",
            "        [ 1.3922358e-01,  3.9824352e-02,  5.6118807e-03, ...,\n",
            "          3.1895638e-01, -2.1927902e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-3.0807488e-02,  1.3592713e-01,  1.7691751e-01, ...,\n",
            "          5.0100658e-02,  2.4297427e-02,  1.0000000e+00],\n",
            "        [-2.1536100e-01,  1.3658194e-01,  3.1884757e-01, ...,\n",
            "          5.6070875e-02, -9.8005310e-03,  1.0000000e+00],\n",
            "        [-2.7424774e-01,  9.7144842e-02,  2.9467931e-01, ...,\n",
            "          5.9895374e-02, -5.4129562e-04,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02217198, -0.14914873, -0.04404445, ...,  0.07346633,\n",
            "          0.21567486,  1.        ],\n",
            "        [ 0.19506057, -0.06830287, -0.05820715, ...,  0.3007375 ,\n",
            "          0.1508604 ,  1.        ],\n",
            "        [ 0.16017114, -0.05618699, -0.05092775, ...,  0.39667732,\n",
            "          0.04858255,  1.        ],\n",
            "        ...,\n",
            "        [-0.08093791,  0.03568661,  0.1769267 , ...,  0.08544556,\n",
            "          0.01099601,  1.        ],\n",
            "        [-0.19349319,  0.04985096,  0.22445948, ...,  0.08350211,\n",
            "         -0.02406853,  1.        ],\n",
            "        [-0.2466875 ,  0.05235057,  0.23948814, ...,  0.06380884,\n",
            "         -0.01042477,  1.        ]], dtype=float32)\n",
            " array([[-0.01327848, -0.12250534, -0.03055838, ...,  0.04405614,\n",
            "          0.21024957,  1.        ],\n",
            "        [ 0.14698268, -0.0244194 , -0.0106489 , ...,  0.2613021 ,\n",
            "          0.11209685,  1.        ],\n",
            "        [ 0.15544634,  0.04334809,  0.00350242, ...,  0.3329562 ,\n",
            "         -0.03080771,  1.        ],\n",
            "        ...,\n",
            "        [-0.00274834,  0.12260263,  0.17440921, ...,  0.07372025,\n",
            "          0.02769721,  1.        ],\n",
            "        [-0.20785686,  0.12690032,  0.33362854, ...,  0.0811473 ,\n",
            "         -0.00488417,  1.        ],\n",
            "        [-0.26560944,  0.10709003,  0.29780298, ...,  0.05935733,\n",
            "          0.00626357,  1.        ]], dtype=float32)\n",
            " array([[-0.01523639, -0.12740256, -0.02798125, ...,  0.04626468,\n",
            "          0.21076052,  1.        ],\n",
            "        [ 0.14983755, -0.03176328, -0.00376947, ...,  0.26311105,\n",
            "          0.12118605,  1.        ],\n",
            "        [ 0.15208764,  0.0273828 ,  0.00937176, ...,  0.3385799 ,\n",
            "         -0.01344517,  1.        ],\n",
            "        ...,\n",
            "        [-0.03301089,  0.12414891,  0.20183736, ...,  0.08243634,\n",
            "          0.02152513,  1.        ],\n",
            "        [-0.22145227,  0.1276973 ,  0.33587486, ...,  0.08124578,\n",
            "         -0.01176192,  1.        ],\n",
            "        [-0.27115738,  0.10742261,  0.29754934, ...,  0.05799746,\n",
            "          0.00524192,  1.        ]], dtype=float32)\n",
            " array([[-0.00394507, -0.11304309, -0.0417644 , ...,  0.04137134,\n",
            "          0.2050478 ,  0.        ],\n",
            "        [ 0.16195841, -0.0053108 , -0.02572901, ...,  0.24394487,\n",
            "          0.08493565,  0.        ],\n",
            "        [ 0.17260201,  0.06082173, -0.01823127, ...,  0.311647  ,\n",
            "         -0.06232702,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05867664,  0.10721779,  0.09002659, ...,  0.03945896,\n",
            "          0.05802524,  0.        ],\n",
            "        [-0.17345306,  0.12355632,  0.31002244, ...,  0.08415824,\n",
            "         -0.0016944 ,  0.        ],\n",
            "        [-0.25124767,  0.10869855,  0.28654882, ...,  0.05380462,\n",
            "          0.00145502,  0.        ]], dtype=float32)\n",
            " array([[-1.42191704e-02, -1.21749952e-01, -2.91807577e-02, ...,\n",
            "          4.33440320e-02,  2.10779414e-01,  3.00000000e+00],\n",
            "        [ 1.48342550e-01, -2.54682600e-02, -5.51636005e-03, ...,\n",
            "          2.54553467e-01,  1.15070276e-01,  3.00000000e+00],\n",
            "        [ 1.54797614e-01,  4.32595834e-02,  9.99491941e-03, ...,\n",
            "          3.25119019e-01, -2.96794437e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.03454595e-03,  1.22992247e-01,  1.75663963e-01, ...,\n",
            "          6.10467233e-02,  3.43217105e-02,  3.00000000e+00],\n",
            "        [-2.08152011e-01,  1.28415808e-01,  3.34005892e-01, ...,\n",
            "          7.37982541e-02, -2.10620672e-03,  3.00000000e+00],\n",
            "        [-2.66187251e-01,  1.09809183e-01,  2.97495931e-01, ...,\n",
            "          5.49639203e-02,  8.85419920e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.01626579, -0.12921573, -0.02740039, ...,  0.0470802 ,\n",
            "          0.21232162,  3.        ],\n",
            "        [ 0.15282391, -0.03487961, -0.00492918, ...,  0.26723668,\n",
            "          0.12605324,  3.        ],\n",
            "        [ 0.15346721,  0.02429049,  0.00970464, ...,  0.3445449 ,\n",
            "         -0.00602763,  3.        ],\n",
            "        ...,\n",
            "        [-0.03980157,  0.12074697,  0.20521459, ...,  0.0878748 ,\n",
            "          0.01954398,  3.        ],\n",
            "        [-0.22294079,  0.12399863,  0.33191493, ...,  0.08203062,\n",
            "         -0.01370182,  3.        ],\n",
            "        [-0.27270314,  0.10441282,  0.2952879 , ...,  0.05917932,\n",
            "          0.00383013,  3.        ]], dtype=float32)\n",
            " array([[-1.12440940e-02, -1.23878345e-01, -3.15896794e-02, ...,\n",
            "          4.64421995e-02,  2.11777151e-01,  2.00000000e+00],\n",
            "        [ 1.60041332e-01, -2.51826290e-02, -1.32871447e-02, ...,\n",
            "          2.68625289e-01,  1.20678082e-01,  2.00000000e+00],\n",
            "        [ 1.63767934e-01,  3.98649424e-02,  1.07669213e-03, ...,\n",
            "          3.43894124e-01, -2.07280833e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-3.88204353e-05,  1.17788635e-01,  1.64725706e-01, ...,\n",
            "          8.44372585e-02,  3.46698873e-02,  2.00000000e+00],\n",
            "        [-2.02794522e-01,  1.22463018e-01,  3.18190455e-01, ...,\n",
            "          8.50330517e-02, -2.84069055e-03,  2.00000000e+00],\n",
            "        [-2.61612058e-01,  1.06876746e-01,  2.89862782e-01, ...,\n",
            "          6.20902888e-02,  7.83887412e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-3.69484606e-03, -1.11819416e-01, -4.37767915e-02, ...,\n",
            "          4.20171618e-02,  2.06159711e-01,  2.00000000e+00],\n",
            "        [ 1.66917562e-01, -5.27932728e-03, -3.20441686e-02, ...,\n",
            "          2.51613498e-01,  7.54520819e-02,  2.00000000e+00],\n",
            "        [ 1.80990547e-01,  6.13278672e-02, -2.72135735e-02, ...,\n",
            "          3.15719873e-01, -6.69883266e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 7.47874603e-02,  9.80172753e-02,  7.07319304e-02, ...,\n",
            "          5.31582609e-02,  6.04294948e-02,  2.00000000e+00],\n",
            "        [-1.59396470e-01,  1.24466285e-01,  3.05934668e-01, ...,\n",
            "          1.01617910e-01, -5.59009553e-04,  2.00000000e+00],\n",
            "        [-2.47582763e-01,  1.06982410e-01,  2.89038271e-01, ...,\n",
            "          6.42084181e-02,  6.41275337e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01573599, -0.12534836, -0.02889393, ...,  0.04590463,\n",
            "          0.21126783,  1.        ],\n",
            "        [ 0.14969361, -0.02950898, -0.00651639, ...,  0.26259917,\n",
            "          0.12134559,  1.        ],\n",
            "        [ 0.15243982,  0.03221598,  0.00824964, ...,  0.33773816,\n",
            "         -0.0173633 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.02921724,  0.12307289,  0.19809087, ...,  0.08278764,\n",
            "          0.0203053 ,  1.        ],\n",
            "        [-0.22277676,  0.12676406,  0.3370428 , ...,  0.07989442,\n",
            "         -0.01157213,  1.        ],\n",
            "        [-0.27130273,  0.10735155,  0.29748166, ...,  0.05721361,\n",
            "          0.00533486,  1.        ]], dtype=float32)\n",
            " array([[ 2.23713629e-02, -1.19910218e-01, -7.37381130e-02, ...,\n",
            "          5.94319291e-02,  2.13191062e-01,  3.00000000e+00],\n",
            "        [ 1.89956129e-01, -6.04336616e-03, -6.35773391e-02, ...,\n",
            "          2.37670138e-01,  8.01294446e-02,  3.00000000e+00],\n",
            "        [ 1.86401069e-01,  4.56673503e-02, -5.46421595e-02, ...,\n",
            "          3.25590640e-01, -8.12445879e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.26823172e-01,  8.67818594e-02,  3.11833061e-02, ...,\n",
            "          4.75516282e-02,  5.81776462e-02,  3.00000000e+00],\n",
            "        [-1.11257076e-01,  1.32269204e-01,  2.41128251e-01, ...,\n",
            "          8.69496688e-02, -1.92473026e-03,  3.00000000e+00],\n",
            "        [-2.19657928e-01,  9.29528475e-02,  2.60228097e-01, ...,\n",
            "          7.70629123e-02,  2.01061065e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.0358177 , -0.14835478, -0.04467376, ...,  0.06341485,\n",
            "          0.21239613,  3.        ],\n",
            "        [ 0.15116788, -0.10162023, -0.05306782, ...,  0.28254128,\n",
            "          0.17458743,  3.        ],\n",
            "        [ 0.09624863, -0.08861382, -0.05203802, ...,  0.3856488 ,\n",
            "          0.08304416,  3.        ],\n",
            "        ...,\n",
            "        [-0.17999978,  0.04180461,  0.22773854, ...,  0.08818824,\n",
            "         -0.01610329,  3.        ],\n",
            "        [-0.27723104,  0.06801715,  0.23517072, ...,  0.07118528,\n",
            "         -0.05517603,  3.        ],\n",
            "        [-0.27975857,  0.04872304,  0.2534869 , ...,  0.02755263,\n",
            "         -0.03044967,  3.        ]], dtype=float32)\n",
            " array([[-0.03042706, -0.14562948, -0.0419724 , ...,  0.05365938,\n",
            "          0.21184492,  3.        ],\n",
            "        [ 0.14998205, -0.07932954, -0.06259006, ...,  0.28113928,\n",
            "          0.14587365,  3.        ],\n",
            "        [ 0.11548831, -0.06747676, -0.06792514, ...,  0.37436888,\n",
            "          0.04325574,  3.        ],\n",
            "        ...,\n",
            "        [-0.117492  ,  0.04141832,  0.1887943 , ...,  0.1012419 ,\n",
            "          0.02411709,  3.        ],\n",
            "        [-0.23048982,  0.03815247,  0.25317514, ...,  0.07432229,\n",
            "         -0.02379187,  3.        ],\n",
            "        [-0.28535503,  0.04345846,  0.26123822, ...,  0.03975853,\n",
            "         -0.02064956,  3.        ]], dtype=float32)\n",
            " array([[-2.16265190e-02, -1.31717265e-01, -2.62883212e-02, ...,\n",
            "          4.39692214e-02,  2.08980948e-01,  3.00000000e+00],\n",
            "        [ 1.33002639e-01, -4.39932346e-02, -2.94610392e-03, ...,\n",
            "          2.51598835e-01,  1.29833117e-01,  3.00000000e+00],\n",
            "        [ 1.23257264e-01,  5.03899762e-03,  1.67597122e-02, ...,\n",
            "          3.33162874e-01,  1.37576682e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-9.13782343e-02,  1.30802646e-01,  2.33851045e-01, ...,\n",
            "          7.97718465e-02,  3.17742303e-03,  3.00000000e+00],\n",
            "        [-2.47688591e-01,  1.24367625e-01,  3.39769602e-01, ...,\n",
            "          6.60577789e-02, -2.80379690e-02,  3.00000000e+00],\n",
            "        [-2.95321435e-01,  9.29125473e-02,  2.99951613e-01, ...,\n",
            "          4.93020266e-02, -1.11773666e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.79939996e-02, -1.18247651e-01, -3.34849544e-02, ...,\n",
            "          3.60572152e-02,  2.02909335e-01,  3.00000000e+00],\n",
            "        [ 1.27415165e-01, -1.48700681e-02, -5.19880792e-03, ...,\n",
            "          2.35814676e-01,  9.31387022e-02,  3.00000000e+00],\n",
            "        [ 1.28970966e-01,  5.20354882e-02,  1.02084605e-02, ...,\n",
            "          3.10117364e-01, -4.77794297e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 8.49581193e-05,  1.28213897e-01,  1.57036185e-01, ...,\n",
            "          3.42650414e-02,  3.04493662e-02,  3.00000000e+00],\n",
            "        [-2.13364020e-01,  1.23168506e-01,  3.36904377e-01, ...,\n",
            "          5.19778877e-02, -1.24132540e-02,  3.00000000e+00],\n",
            "        [-2.79509723e-01,  9.54631120e-02,  3.04808795e-01, ...,\n",
            "          4.24712263e-02, -4.21518786e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.5128378e-02, -1.3240051e-01, -2.5378371e-02, ...,\n",
            "          4.5785658e-02,  2.0890997e-01,  3.0000000e+00],\n",
            "        [ 1.3483886e-01, -4.4366959e-02, -8.5356506e-03, ...,\n",
            "          2.5420508e-01,  1.3238016e-01,  3.0000000e+00],\n",
            "        [ 1.1862171e-01, -1.7317873e-03,  1.1974119e-02, ...,\n",
            "          3.3871147e-01,  1.1562647e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2463879e-01,  1.2764530e-01,  2.4528228e-01, ...,\n",
            "          7.6956660e-02, -7.5910510e-03,  3.0000000e+00],\n",
            "        [-2.5710782e-01,  1.1278194e-01,  3.3198202e-01, ...,\n",
            "          6.0572512e-02, -3.5984527e-02,  3.0000000e+00],\n",
            "        [-3.0271828e-01,  8.9220285e-02,  3.0084261e-01, ...,\n",
            "          4.4762596e-02, -1.6629679e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.0323167e-02, -1.3773121e-01, -2.9960746e-02, ...,\n",
            "          5.5055961e-02,  2.1913098e-01,  3.0000000e+00],\n",
            "        [ 1.4841369e-01, -4.4756491e-02, -8.8663911e-03, ...,\n",
            "          2.4056654e-01,  1.4160377e-01,  3.0000000e+00],\n",
            "        [ 1.3592938e-01,  4.1494183e-03,  1.2184331e-02, ...,\n",
            "          3.2485297e-01, -8.5826876e-05,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-5.9594940e-02,  1.5464541e-01,  2.0000573e-01, ...,\n",
            "          4.6890032e-02,  2.1217873e-02,  3.0000000e+00],\n",
            "        [-2.2963336e-01,  1.4430822e-01,  3.0870330e-01, ...,\n",
            "          5.3201530e-02, -1.4656176e-02,  3.0000000e+00],\n",
            "        [-2.7719381e-01,  1.0698682e-01,  2.8686601e-01, ...,\n",
            "          7.1912944e-02,  2.0158959e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-9.6662687e-03, -1.1324165e-01, -3.4763549e-02, ...,\n",
            "          4.2410508e-02,  2.0851006e-01,  3.0000000e+00],\n",
            "        [ 1.5298787e-01, -1.0524190e-02, -1.3202905e-02, ...,\n",
            "          2.4593966e-01,  1.0085740e-01,  3.0000000e+00],\n",
            "        [ 1.6281842e-01,  6.0497988e-02, -2.8194461e-04, ...,\n",
            "          3.1144196e-01, -4.9244706e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 3.5227805e-02,  1.1680430e-01,  1.2289393e-01, ...,\n",
            "          3.8100347e-02,  5.0202329e-02,  3.0000000e+00],\n",
            "        [-1.8547036e-01,  1.2705946e-01,  3.2412925e-01, ...,\n",
            "          7.6058261e-02,  3.4856386e-03,  3.0000000e+00],\n",
            "        [-2.5679818e-01,  1.1157189e-01,  2.9449177e-01, ...,\n",
            "          5.4932412e-02,  7.3289955e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-1.3215460e-02, -1.2042994e-01, -3.1706471e-02, ...,\n",
            "          4.4977039e-02,  2.1061082e-01,  3.0000000e+00],\n",
            "        [ 1.4992426e-01, -2.2156978e-02, -1.2832073e-02, ...,\n",
            "          2.5777319e-01,  1.1213206e-01,  3.0000000e+00],\n",
            "        [ 1.5633565e-01,  4.6152204e-02,  1.4669942e-03, ...,\n",
            "          3.2887948e-01, -3.2741331e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 7.4714688e-03,  1.2218603e-01,  1.6499254e-01, ...,\n",
            "          6.6342026e-02,  3.5533331e-02,  3.0000000e+00],\n",
            "        [-2.0300514e-01,  1.2663913e-01,  3.2963443e-01, ...,\n",
            "          8.0325708e-02, -9.3540951e-04,  3.0000000e+00],\n",
            "        [-2.6308626e-01,  1.0915706e-01,  2.9554468e-01, ...,\n",
            "          5.8799312e-02,  9.0279942e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03765602, -0.12617788, -0.03910878, ...,  0.06750498,\n",
            "          0.20677991,  3.        ],\n",
            "        [ 0.17430408,  0.01794174, -0.03148841, ...,  0.29172885,\n",
            "          0.12337881,  3.        ],\n",
            "        [ 0.18683533,  0.05670454, -0.00857538, ...,  0.35948253,\n",
            "          0.0546322 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.08459453,  0.10265721,  0.22753972, ...,  0.14022683,\n",
            "         -0.01418083,  3.        ],\n",
            "        [-0.21401122,  0.09748346,  0.30905804, ...,  0.11196777,\n",
            "         -0.03845031,  3.        ],\n",
            "        [-0.27860758,  0.08571183,  0.2802591 , ...,  0.05778735,\n",
            "         -0.01883662,  3.        ]], dtype=float32)\n",
            " array([[-0.0372475 , -0.14063826, -0.03138664, ...,  0.06150356,\n",
            "          0.2143564 ,  3.        ],\n",
            "        [ 0.15818822, -0.06158632, -0.03617916, ...,  0.26221904,\n",
            "          0.1513943 ,  3.        ],\n",
            "        [ 0.12110928, -0.04055912, -0.02064632, ...,  0.35295242,\n",
            "          0.05043113,  3.        ],\n",
            "        ...,\n",
            "        [-0.12884557,  0.10105988,  0.2289939 , ...,  0.06661305,\n",
            "          0.00958864,  3.        ],\n",
            "        [-0.26086116,  0.08855465,  0.28659058, ...,  0.0581761 ,\n",
            "         -0.03500282,  3.        ],\n",
            "        [-0.2951575 ,  0.08005369,  0.2768496 , ...,  0.04646793,\n",
            "         -0.01485887,  3.        ]], dtype=float32)\n",
            " array([[ 0.05606213, -0.2066301 , -0.11454425, ..., -0.01319182,\n",
            "          0.18909787,  3.        ],\n",
            "        [ 0.32013124,  0.02215601, -0.10699871, ...,  0.06091345,\n",
            "          0.01811507,  3.        ],\n",
            "        [ 0.31666487,  0.05735199, -0.08835828, ...,  0.11527643,\n",
            "         -0.08300672,  3.        ],\n",
            "        ...,\n",
            "        [ 0.1674411 , -0.02129094, -0.17718858, ...,  0.03601348,\n",
            "          0.07962772,  3.        ],\n",
            "        [ 0.0269583 ,  0.04357944,  0.10191137, ...,  0.11779964,\n",
            "         -0.01524291,  3.        ],\n",
            "        [-0.16847266,  0.02251454,  0.27832806, ...,  0.0567752 ,\n",
            "         -0.00957952,  3.        ]], dtype=float32)\n",
            " array([[-1.97207872e-02, -1.31224960e-01, -3.35579179e-02, ...,\n",
            "          5.54759465e-02,  2.18666062e-01,  3.00000000e+00],\n",
            "        [ 1.36658177e-01, -4.33818176e-02, -9.66118742e-03, ...,\n",
            "          2.42903739e-01,  1.41674638e-01,  3.00000000e+00],\n",
            "        [ 1.32605359e-01,  1.47242015e-02,  1.46062402e-02, ...,\n",
            "          3.22383851e-01, -7.50580011e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-6.06290475e-02,  1.41855642e-01,  2.20847681e-01, ...,\n",
            "          6.62560835e-02,  8.54363851e-03,  3.00000000e+00],\n",
            "        [-2.37234965e-01,  1.33621141e-01,  3.35862011e-01, ...,\n",
            "          6.71323314e-02, -2.19983608e-02,  3.00000000e+00],\n",
            "        [-2.79400349e-01,  1.00536093e-01,  2.96551406e-01, ...,\n",
            "          6.72592148e-02,  1.24931568e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.9286282e-02, -1.3474585e-01, -3.3612341e-02, ...,\n",
            "          5.3176139e-02,  2.2093399e-01,  3.0000000e+00],\n",
            "        [ 1.4775285e-01, -4.0117234e-02, -1.2729223e-02, ...,\n",
            "          2.6014048e-01,  1.4269218e-01,  3.0000000e+00],\n",
            "        [ 1.4002122e-01,  1.5890583e-02,  1.1442351e-02, ...,\n",
            "          3.4369814e-01,  2.5740927e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-7.5330570e-02,  1.4800769e-01,  2.1301597e-01, ...,\n",
            "          7.5468756e-02,  5.4081273e-03,  3.0000000e+00],\n",
            "        [-2.3136339e-01,  1.3398343e-01,  3.1464535e-01, ...,\n",
            "          6.7554601e-02, -3.0756546e-02,  3.0000000e+00],\n",
            "        [-2.8190383e-01,  9.0156779e-02,  2.8919771e-01, ...,\n",
            "          6.8510413e-02, -1.3499530e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.01752434, -0.13033342, -0.03221682, ...,  0.04303879,\n",
            "          0.20961732,  3.        ],\n",
            "        [ 0.1455017 , -0.03082827, -0.00843588, ...,  0.25994995,\n",
            "          0.12214079,  3.        ],\n",
            "        [ 0.14210454,  0.02506923,  0.01080197, ...,  0.33971724,\n",
            "         -0.01348237,  3.        ],\n",
            "        ...,\n",
            "        [-0.03605311,  0.12654822,  0.18635604, ...,  0.0830823 ,\n",
            "          0.0169796 ,  3.        ],\n",
            "        [-0.2188805 ,  0.1228598 ,  0.32031855, ...,  0.07258447,\n",
            "         -0.01705747,  3.        ],\n",
            "        [-0.27983227,  0.09242395,  0.29089972, ...,  0.05569983,\n",
            "         -0.00981381,  3.        ]], dtype=float32)\n",
            " array([[ 6.0791124e-02, -1.7408335e-01, -1.0676468e-01, ...,\n",
            "          5.6695029e-02,  2.0969565e-01,  3.0000000e+00],\n",
            "        [ 2.8853449e-01, -3.8610487e-03, -1.1435641e-01, ...,\n",
            "          1.9057924e-01,  3.1892478e-02,  3.0000000e+00],\n",
            "        [ 2.6732963e-01,  2.0960540e-02, -8.5680827e-02, ...,\n",
            "          2.6974198e-01, -9.2269965e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 2.1513206e-01, -8.2695568e-03, -1.1078948e-02, ...,\n",
            "          9.3773194e-02, -5.0769942e-03,  3.0000000e+00],\n",
            "        [-1.0342986e-03,  3.2726694e-02,  1.6716059e-01, ...,\n",
            "          1.4074947e-01, -5.0802480e-02,  3.0000000e+00],\n",
            "        [-1.4433403e-01,  2.0009121e-02,  2.6709393e-01, ...,\n",
            "          8.1125587e-02, -1.4697881e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.01637246, -0.1192834 , -0.03568114, ...,  0.03678631,\n",
            "          0.20330194,  3.        ],\n",
            "        [ 0.13471487, -0.0095031 , -0.00880662, ...,  0.239124  ,\n",
            "          0.08793258,  3.        ],\n",
            "        [ 0.14044872,  0.05856425,  0.00576246, ...,  0.31063712,\n",
            "         -0.05553756,  3.        ],\n",
            "        ...,\n",
            "        [ 0.01227452,  0.12616435,  0.13766345, ...,  0.0374716 ,\n",
            "          0.02943558,  3.        ],\n",
            "        [-0.20262788,  0.12285651,  0.32680538, ...,  0.05746879,\n",
            "         -0.01408126,  3.        ],\n",
            "        [-0.27247477,  0.09606472,  0.2998382 , ...,  0.04558321,\n",
            "         -0.00489119,  3.        ]], dtype=float32)\n",
            " array([[-6.47630217e-03, -1.22187816e-01, -4.63827178e-02, ...,\n",
            "          5.14049269e-02,  2.18824714e-01,  3.00000000e+00],\n",
            "        [ 1.41300842e-01, -2.03478783e-02, -1.94900557e-02, ...,\n",
            "          2.31170073e-01,  1.24083340e-01,  3.00000000e+00],\n",
            "        [ 1.40626267e-01,  4.32002172e-02, -2.12780287e-04, ...,\n",
            "          3.13007385e-01, -3.96227241e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.37931388e-02,  1.60088956e-01,  1.63580641e-01, ...,\n",
            "          2.97281314e-02,  2.73445323e-02,  3.00000000e+00],\n",
            "        [-1.96040332e-01,  1.51725665e-01,  3.09362411e-01, ...,\n",
            "          4.51735780e-02, -1.19824754e-02,  3.00000000e+00],\n",
            "        [-2.51595140e-01,  9.51828286e-02,  2.86458910e-01, ...,\n",
            "          6.82941526e-02, -6.44596294e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.01584053, -0.11881967, -0.03534972, ...,  0.04614159,\n",
            "          0.21513692,  3.        ],\n",
            "        [ 0.13429062, -0.01717867, -0.01113086, ...,  0.23357493,\n",
            "          0.11697115,  3.        ],\n",
            "        [ 0.13942863,  0.05225468,  0.00873816, ...,  0.30355152,\n",
            "         -0.03639289,  3.        ],\n",
            "        ...,\n",
            "        [-0.01626606,  0.14287467,  0.16668075, ...,  0.034352  ,\n",
            "          0.02655517,  3.        ],\n",
            "        [-0.21605939,  0.149902  ,  0.32870185, ...,  0.05624273,\n",
            "         -0.00469725,  3.        ],\n",
            "        [-0.2721867 ,  0.10796288,  0.30161443, ...,  0.06632163,\n",
            "          0.00787315,  3.        ]], dtype=float32)\n",
            " array([[-2.39981525e-02, -1.33640990e-01, -2.68301871e-02, ...,\n",
            "          5.18729724e-02,  2.17038080e-01,  3.00000000e+00],\n",
            "        [ 1.35872915e-01, -4.64823171e-02, -2.34293914e-03, ...,\n",
            "          2.40369946e-01,  1.38853922e-01,  3.00000000e+00],\n",
            "        [ 1.28326535e-01,  7.71824503e-03,  2.00396348e-02, ...,\n",
            "          3.18458349e-01, -2.17019464e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.06495000e-01,  1.52710438e-01,  2.45878637e-01, ...,\n",
            "          4.96370830e-02, -1.05128356e-03,  3.00000000e+00],\n",
            "        [-2.50360250e-01,  1.36900470e-01,  3.34929764e-01, ...,\n",
            "          5.54188713e-02, -2.72719841e-02,  3.00000000e+00],\n",
            "        [-2.85584956e-01,  1.04775175e-01,  2.97305763e-01, ...,\n",
            "          6.27260953e-02,  1.07763486e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.4363661e-02, -1.3286442e-01, -2.4839189e-02, ...,\n",
            "          4.4475194e-02,  2.0863806e-01,  3.0000000e+00],\n",
            "        [ 1.3264096e-01, -4.5923423e-02, -3.7946654e-03, ...,\n",
            "          2.5444689e-01,  1.3248068e-01,  3.0000000e+00],\n",
            "        [ 1.1780422e-01, -2.3133727e-03,  1.4644377e-02, ...,\n",
            "          3.3671606e-01,  1.3868334e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2228352e-01,  1.3262552e-01,  2.4991995e-01, ...,\n",
            "          7.8226000e-02, -3.8004518e-03,  3.0000000e+00],\n",
            "        [-2.5722477e-01,  1.1711497e-01,  3.3677322e-01, ...,\n",
            "          6.5319687e-02, -3.1646546e-02,  3.0000000e+00],\n",
            "        [-3.0187878e-01,  9.1062471e-02,  3.0185601e-01, ...,\n",
            "          4.8232481e-02, -1.5336704e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03263953, -0.14863898, -0.03627412, ...,  0.06198514,\n",
            "          0.21629529,  3.        ],\n",
            "        [ 0.16618754, -0.07904869, -0.04904103, ...,  0.2793797 ,\n",
            "          0.15937422,  3.        ],\n",
            "        [ 0.12109112, -0.06362029, -0.0434444 , ...,  0.37363195,\n",
            "          0.05964724,  3.        ],\n",
            "        ...,\n",
            "        [-0.13523263,  0.05945902,  0.22300592, ...,  0.08463722,\n",
            "          0.00305769,  3.        ],\n",
            "        [-0.251825  ,  0.05536093,  0.2622882 , ...,  0.07021257,\n",
            "         -0.0392278 ,  3.        ],\n",
            "        [-0.2842519 ,  0.05627694,  0.2661922 , ...,  0.04131477,\n",
            "         -0.01805978,  3.        ]], dtype=float32)\n",
            " array([[-0.02400226, -0.13181703, -0.02703542, ...,  0.04513605,\n",
            "          0.21024877,  3.        ],\n",
            "        [ 0.13415238, -0.0482038 , -0.01015194, ...,  0.25224125,\n",
            "          0.13568728,  3.        ],\n",
            "        [ 0.11816382, -0.00576683,  0.01067869, ...,  0.3388855 ,\n",
            "          0.01073074,  3.        ],\n",
            "        ...,\n",
            "        [-0.12304031,  0.12940061,  0.24561839, ...,  0.08253802,\n",
            "         -0.0033749 ,  3.        ],\n",
            "        [-0.25495616,  0.11923149,  0.3301165 , ...,  0.06448383,\n",
            "         -0.03441548,  3.        ],\n",
            "        [-0.30387133,  0.08735828,  0.2981568 , ...,  0.04737866,\n",
            "         -0.01771155,  3.        ]], dtype=float32)\n",
            " array([[-0.0345355 , -0.13242282, -0.03353845, ...,  0.05477359,\n",
            "          0.20842277,  3.        ],\n",
            "        [ 0.14286278, -0.06333118, -0.04377036, ...,  0.27167124,\n",
            "          0.14342777,  3.        ],\n",
            "        [ 0.11233077, -0.04194912, -0.03959278, ...,  0.36169723,\n",
            "          0.04092338,  3.        ],\n",
            "        ...,\n",
            "        [-0.1424092 ,  0.0715952 ,  0.22846279, ...,  0.08794331,\n",
            "          0.00892484,  3.        ],\n",
            "        [-0.25387034,  0.06099225,  0.28469336, ...,  0.06713088,\n",
            "         -0.03177129,  3.        ],\n",
            "        [-0.30198324,  0.07172336,  0.2811014 , ...,  0.03652894,\n",
            "         -0.01785707,  3.        ]], dtype=float32)\n",
            " array([[-0.01556515, -0.12577657, -0.02891915, ...,  0.04459435,\n",
            "          0.21094489,  3.        ],\n",
            "        [ 0.15069829, -0.0321804 , -0.0064649 , ...,  0.2600786 ,\n",
            "          0.12171058,  3.        ],\n",
            "        [ 0.15247218,  0.02842396,  0.0093351 , ...,  0.3363011 ,\n",
            "         -0.01783034,  3.        ],\n",
            "        ...,\n",
            "        [-0.02630301,  0.12279201,  0.19120553, ...,  0.07880225,\n",
            "          0.0225908 ,  3.        ],\n",
            "        [-0.22075589,  0.12732486,  0.33080226, ...,  0.07592165,\n",
            "         -0.01061056,  3.        ],\n",
            "        [-0.27155587,  0.10804608,  0.29461443, ...,  0.05538446,\n",
            "          0.0053229 ,  3.        ]], dtype=float32)\n",
            " array([[-2.43096203e-02, -1.30091995e-01, -2.49868706e-02, ...,\n",
            "          4.19969484e-02,  2.08714709e-01,  3.00000000e+00],\n",
            "        [ 1.28278583e-01, -4.59036380e-02, -2.29380559e-03, ...,\n",
            "          2.39335731e-01,  1.32851288e-01,  3.00000000e+00],\n",
            "        [ 1.15803026e-01,  1.74887793e-03,  1.97842550e-02, ...,\n",
            "          3.22644532e-01,  5.17778890e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.14107735e-01,  1.38830975e-01,  2.53774583e-01, ...,\n",
            "          7.02653676e-02,  1.71802030e-03,  3.00000000e+00],\n",
            "        [-2.58953631e-01,  1.26213253e-01,  3.46906513e-01, ...,\n",
            "          5.72355539e-02, -2.94132922e-02,  3.00000000e+00],\n",
            "        [-3.05363119e-01,  9.11866948e-02,  3.03506047e-01, ...,\n",
            "          4.60299514e-02, -1.53266527e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03296309, -0.15572417, -0.03811675, ...,  0.06031336,\n",
            "          0.21503596,  3.        ],\n",
            "        [ 0.17021869, -0.08491901, -0.04989444, ...,  0.27664587,\n",
            "          0.15288655,  3.        ],\n",
            "        [ 0.12534523, -0.0671917 , -0.04571522, ...,  0.36379573,\n",
            "          0.05204917,  3.        ],\n",
            "        ...,\n",
            "        [-0.10622683,  0.06165973,  0.20072164, ...,  0.076522  ,\n",
            "          0.01702583,  3.        ],\n",
            "        [-0.23071168,  0.06216092,  0.24858776, ...,  0.0621007 ,\n",
            "         -0.03273885,  3.        ],\n",
            "        [-0.27345735,  0.05261154,  0.2576379 , ...,  0.04544994,\n",
            "         -0.01907424,  3.        ]], dtype=float32)\n",
            " array([[-3.21111716e-02, -1.58664048e-01, -5.62724173e-02, ...,\n",
            "          6.03674203e-02,  2.11042598e-01,  3.00000000e+00],\n",
            "        [ 1.40671313e-01, -1.14476293e-01, -7.73136914e-02, ...,\n",
            "          3.04532409e-01,  1.52742818e-01,  3.00000000e+00],\n",
            "        [ 8.94295052e-02, -1.15756065e-01, -8.45709518e-02, ...,\n",
            "          4.01393801e-01,  7.70059079e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.44463226e-01,  8.38079397e-03,  1.95589453e-01, ...,\n",
            "          1.14668243e-01, -1.46225924e-02,  3.00000000e+00],\n",
            "        [-2.21103892e-01,  1.74254049e-02,  2.00981781e-01, ...,\n",
            "          9.32140350e-02, -4.50591743e-02,  3.00000000e+00],\n",
            "        [-2.61939704e-01,  1.70496886e-03,  2.32190460e-01, ...,\n",
            "          3.76735814e-02, -2.99146250e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.67018659e-02, -1.19139031e-01, -3.41832750e-02, ...,\n",
            "          3.49256322e-02,  2.04136267e-01,  3.00000000e+00],\n",
            "        [ 1.31395862e-01, -1.40451863e-02, -3.98022030e-03, ...,\n",
            "          2.32611030e-01,  9.49714035e-02,  3.00000000e+00],\n",
            "        [ 1.32704124e-01,  5.09883016e-02,  1.19130295e-02, ...,\n",
            "          3.03918958e-01, -4.81621772e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.90670106e-03,  1.28730834e-01,  1.51354104e-01, ...,\n",
            "          3.37664634e-02,  3.41944247e-02,  3.00000000e+00],\n",
            "        [-2.11557940e-01,  1.25267580e-01,  3.32407057e-01, ...,\n",
            "          5.02936542e-02, -1.19981458e-02,  3.00000000e+00],\n",
            "        [-2.80819714e-01,  9.61744413e-02,  3.04516792e-01, ...,\n",
            "          4.26150337e-02, -3.94507172e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.1396449e-02, -1.2505965e-01, -2.6744625e-02, ...,\n",
            "          3.9018389e-02,  2.0784691e-01,  3.0000000e+00],\n",
            "        [ 1.2666708e-01, -3.1450592e-02,  2.7751553e-04, ...,\n",
            "          2.3244916e-01,  1.1868861e-01,  3.0000000e+00],\n",
            "        [ 1.2329386e-01,  2.8911291e-02,  2.0696620e-02, ...,\n",
            "          3.0932200e-01, -1.9827403e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-5.3940028e-02,  1.3435721e-01,  2.1559083e-01, ...,\n",
            "          4.9712915e-02,  2.0289559e-02,  3.0000000e+00],\n",
            "        [-2.3744433e-01,  1.3071197e-01,  3.5054398e-01, ...,\n",
            "          4.8843712e-02, -1.3904695e-02,  3.0000000e+00],\n",
            "        [-2.9442617e-01,  9.7564340e-02,  3.0893916e-01, ...,\n",
            "          4.2614061e-02, -5.5648605e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02651091, -0.1357903 , -0.02618888, ...,  0.05126897,\n",
            "          0.2144228 ,  3.        ],\n",
            "        [ 0.14367259, -0.04612779, -0.00650336, ...,  0.24591309,\n",
            "          0.13611515,  3.        ],\n",
            "        [ 0.13202685,  0.00597478,  0.01926431, ...,  0.32379487,\n",
            "          0.00445902,  3.        ],\n",
            "        ...,\n",
            "        [-0.12747712,  0.15072124,  0.25107872, ...,  0.05862782,\n",
            "         -0.01189997,  3.        ],\n",
            "        [-0.26037502,  0.13085516,  0.33139378, ...,  0.0549744 ,\n",
            "         -0.03576061,  3.        ],\n",
            "        [-0.29170302,  0.09488784,  0.2984373 , ...,  0.05895108,\n",
            "         -0.00750041,  3.        ]], dtype=float32)\n",
            " array([[ 5.0999080e-03, -1.1186360e-01, -5.7125192e-02, ...,\n",
            "          5.0795421e-02,  2.1115413e-01,  3.0000000e+00],\n",
            "        [ 1.5806502e-01, -1.8330384e-02, -4.7397215e-02, ...,\n",
            "          2.1432264e-01,  1.1152190e-01,  3.0000000e+00],\n",
            "        [ 1.4635892e-01,  2.9185625e-02, -3.2058857e-02, ...,\n",
            "          3.0116245e-01, -5.1060021e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 7.1943104e-02,  1.1100489e-01,  7.6416716e-02, ...,\n",
            "          3.1494312e-02,  5.4771237e-02,  3.0000000e+00],\n",
            "        [-1.5249646e-01,  1.4285235e-01,  2.7436268e-01, ...,\n",
            "          7.6557972e-02,  1.3760616e-03,  3.0000000e+00],\n",
            "        [-2.5299785e-01,  9.4361611e-02,  2.7620354e-01, ...,\n",
            "          6.9653504e-02, -1.1767545e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.0311460e-02, -1.2580556e-01, -2.8641954e-02, ...,\n",
            "          3.5458375e-02,  2.0701469e-01,  3.0000000e+00],\n",
            "        [ 1.2230800e-01, -2.7708629e-02,  1.0737504e-03, ...,\n",
            "          2.3894158e-01,  1.0830219e-01,  3.0000000e+00],\n",
            "        [ 1.2803556e-01,  4.1664034e-02,  2.3460614e-02, ...,\n",
            "          3.1473359e-01, -3.3459395e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-2.6616964e-02,  1.2958303e-01,  1.8789612e-01, ...,\n",
            "          4.7080170e-02,  3.1141071e-02,  3.0000000e+00],\n",
            "        [-2.2262232e-01,  1.2875399e-01,  3.4143582e-01, ...,\n",
            "          5.2258935e-02, -7.8531783e-03,  3.0000000e+00],\n",
            "        [-2.8458926e-01,  9.7860813e-02,  3.0253124e-01, ...,\n",
            "          4.4317946e-02, -4.7737053e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03289258, -0.14168464, -0.03860606, ...,  0.05420645,\n",
            "          0.21258114,  3.        ],\n",
            "        [ 0.14811176, -0.07365936, -0.05910559, ...,  0.27998674,\n",
            "          0.15197289,  3.        ],\n",
            "        [ 0.11179678, -0.06148484, -0.06153405, ...,  0.37278974,\n",
            "          0.05040985,  3.        ],\n",
            "        ...,\n",
            "        [-0.13167018,  0.04985314,  0.21178317, ...,  0.09715582,\n",
            "          0.01984994,  3.        ],\n",
            "        [-0.24178858,  0.0441364 ,  0.26683563, ...,  0.07257617,\n",
            "         -0.02525011,  3.        ],\n",
            "        [-0.29347506,  0.05000946,  0.2695207 , ...,  0.03850571,\n",
            "         -0.0185525 ,  3.        ]], dtype=float32)\n",
            " array([[ 6.6920620e-06, -1.0930280e-01, -5.8084287e-02, ...,\n",
            "          4.3424275e-02,  2.1006559e-01,  3.0000000e+00],\n",
            "        [ 1.5178758e-01, -6.2385821e-03, -4.0219482e-02, ...,\n",
            "          2.1845889e-01,  9.1796026e-02,  3.0000000e+00],\n",
            "        [ 1.5763807e-01,  4.8820294e-02, -2.9057076e-02, ...,\n",
            "          2.9690987e-01, -6.8260193e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.1278409e-02,  1.0717771e-01,  8.1310242e-02, ...,\n",
            "          2.2209929e-02,  3.9377566e-02,  3.0000000e+00],\n",
            "        [-1.7111905e-01,  1.3738073e-01,  3.0060548e-01, ...,\n",
            "          7.0908539e-02, -1.1220399e-02,  3.0000000e+00],\n",
            "        [-2.6196405e-01,  1.0320545e-01,  2.9060796e-01, ...,\n",
            "          6.1536621e-02,  3.0910508e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03168089, -0.14038396, -0.038695  , ...,  0.05866873,\n",
            "          0.21004176,  1.        ],\n",
            "        [ 0.14897779, -0.07412195, -0.05799118, ...,  0.2869787 ,\n",
            "          0.13991459,  1.        ],\n",
            "        [ 0.12076312, -0.05719289, -0.06241304, ...,  0.37596157,\n",
            "          0.03702178,  1.        ],\n",
            "        ...,\n",
            "        [-0.11540929,  0.04188072,  0.19513296, ...,  0.09635434,\n",
            "          0.02185475,  1.        ],\n",
            "        [-0.22903784,  0.03910687,  0.25912073, ...,  0.07480802,\n",
            "         -0.02330177,  1.        ],\n",
            "        [-0.28392968,  0.05210161,  0.26507595, ...,  0.04309972,\n",
            "         -0.01682643,  1.        ]], dtype=float32)\n",
            " array([[-2.96707395e-02, -1.65648028e-01, -5.48810735e-02, ...,\n",
            "          5.86438477e-02,  2.09325925e-01,  1.00000000e+00],\n",
            "        [ 1.40921488e-01, -1.23487823e-01, -7.38619938e-02, ...,\n",
            "          2.99359262e-01,  1.50912911e-01,  1.00000000e+00],\n",
            "        [ 9.67810377e-02, -1.24971069e-01, -8.15463960e-02, ...,\n",
            "          3.82254779e-01,  8.78648162e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.27783045e-01,  4.81474563e-04,  1.89470813e-01, ...,\n",
            "          1.14938885e-01,  1.30390539e-03,  1.00000000e+00],\n",
            "        [-2.11345136e-01,  9.71012097e-03,  2.02797487e-01, ...,\n",
            "          9.21567678e-02, -3.77808660e-02,  1.00000000e+00],\n",
            "        [-2.58400589e-01, -2.54332297e-03,  2.32440576e-01, ...,\n",
            "          3.59126441e-02, -2.85749603e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.03519288, -0.15686208, -0.05863317, ...,  0.0621115 ,\n",
            "          0.21081221,  1.        ],\n",
            "        [ 0.13592328, -0.11752284, -0.08158483, ...,  0.30345735,\n",
            "          0.15556388,  1.        ],\n",
            "        [ 0.08198822, -0.11734275, -0.09058322, ...,  0.40318504,\n",
            "          0.07934005,  1.        ],\n",
            "        ...,\n",
            "        [-0.16125062,  0.00928036,  0.19137019, ...,  0.10850102,\n",
            "         -0.03216268,  1.        ],\n",
            "        [-0.2277285 ,  0.01879492,  0.19465002, ...,  0.08818953,\n",
            "         -0.05439419,  1.        ],\n",
            "        [-0.2632017 ,  0.0040849 ,  0.23122641, ...,  0.03058452,\n",
            "         -0.03182989,  1.        ]], dtype=float32)\n",
            " array([[-0.02733649, -0.1356771 , -0.03802711, ...,  0.0613826 ,\n",
            "          0.20886776,  1.        ],\n",
            "        [ 0.15374412, -0.07219581, -0.05574708, ...,  0.28646028,\n",
            "          0.13459897,  1.        ],\n",
            "        [ 0.13510609, -0.05064093, -0.05929709, ...,  0.37892243,\n",
            "          0.02334876,  1.        ],\n",
            "        ...,\n",
            "        [-0.09617367,  0.05538465,  0.18705669, ...,  0.10524058,\n",
            "          0.01880117,  1.        ],\n",
            "        [-0.22247684,  0.0560141 ,  0.26337025, ...,  0.08269707,\n",
            "         -0.02379485,  1.        ],\n",
            "        [-0.28035784,  0.06277973,  0.26634797, ...,  0.04957056,\n",
            "         -0.01923563,  1.        ]], dtype=float32)\n",
            " array([[-2.2219066e-02, -1.3671038e-01, -3.0924490e-02, ...,\n",
            "          5.4141968e-02,  2.1606162e-01,  1.0000000e+00],\n",
            "        [ 1.4186770e-01, -4.8140299e-02, -9.7058490e-03, ...,\n",
            "          2.4890678e-01,  1.3667791e-01,  1.0000000e+00],\n",
            "        [ 1.3318254e-01, -8.3086407e-04,  1.3963878e-02, ...,\n",
            "          3.2744265e-01, -1.0226273e-03,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1401240e-01,  1.5166995e-01,  2.3716657e-01, ...,\n",
            "          5.4467943e-02, -1.0226709e-02,  1.0000000e+00],\n",
            "        [-2.4386832e-01,  1.2755008e-01,  3.1923887e-01, ...,\n",
            "          5.5935387e-02, -3.5379257e-02,  1.0000000e+00],\n",
            "        [-2.7901042e-01,  1.0095960e-01,  2.8922051e-01, ...,\n",
            "          6.0974315e-02, -6.1557177e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02325043, -0.13458689, -0.02797038, ...,  0.05155512,\n",
            "          0.2147662 ,  1.        ],\n",
            "        [ 0.14193875, -0.04717052, -0.00978197, ...,  0.25267318,\n",
            "          0.13708444,  1.        ],\n",
            "        [ 0.1293087 , -0.00267749,  0.01620586, ...,  0.33663607,\n",
            "          0.00528957,  1.        ],\n",
            "        ...,\n",
            "        [-0.12765579,  0.14568979,  0.24615401, ...,  0.06085765,\n",
            "         -0.01248307,  1.        ],\n",
            "        [-0.24975447,  0.12439726,  0.32383928, ...,  0.05797473,\n",
            "         -0.03813874,  1.        ],\n",
            "        [-0.288683  ,  0.09618583,  0.2952273 , ...,  0.05618988,\n",
            "         -0.01157447,  1.        ]], dtype=float32)\n",
            " array([[-0.03246275, -0.1261555 , -0.03141084, ...,  0.063269  ,\n",
            "          0.21246096,  1.        ],\n",
            "        [ 0.15153588, -0.05667331, -0.0319286 , ...,  0.25800517,\n",
            "          0.15007317,  1.        ],\n",
            "        [ 0.12232822, -0.03088791, -0.01335771, ...,  0.35318926,\n",
            "          0.03791112,  1.        ],\n",
            "        ...,\n",
            "        [-0.16975547,  0.11080982,  0.26645255, ...,  0.07976668,\n",
            "         -0.02187725,  1.        ],\n",
            "        [-0.27658886,  0.09548786,  0.30940518, ...,  0.07337851,\n",
            "         -0.04702028,  1.        ],\n",
            "        [-0.29637924,  0.09047251,  0.28230718, ...,  0.04879227,\n",
            "         -0.01306589,  1.        ]], dtype=float32)\n",
            " array([[-0.03606439, -0.15529408, -0.05528739, ...,  0.05820163,\n",
            "          0.21285236,  1.        ],\n",
            "        [ 0.14065063, -0.11330698, -0.07992934, ...,  0.293716  ,\n",
            "          0.15907326,  1.        ],\n",
            "        [ 0.08799924, -0.11544355, -0.08570997, ...,  0.39237785,\n",
            "          0.08269546,  1.        ],\n",
            "        ...,\n",
            "        [-0.1559799 ,  0.00533115,  0.19889131, ...,  0.11380617,\n",
            "         -0.00954693,  1.        ],\n",
            "        [-0.23754652,  0.01776534,  0.2100676 , ...,  0.09054802,\n",
            "         -0.04792377,  1.        ],\n",
            "        [-0.2765568 ,  0.00694067,  0.24162604, ...,  0.02908639,\n",
            "         -0.02961555,  1.        ]], dtype=float32)\n",
            " array([[-0.03293056, -0.13167034, -0.03561874, ...,  0.05822736,\n",
            "          0.21018097,  1.        ],\n",
            "        [ 0.1423172 , -0.06497009, -0.05059374, ...,  0.28015557,\n",
            "          0.14400236,  1.        ],\n",
            "        [ 0.1137423 , -0.04564629, -0.05068811, ...,  0.37416744,\n",
            "          0.03428324,  1.        ],\n",
            "        ...,\n",
            "        [-0.1344817 ,  0.06983668,  0.22199014, ...,  0.10085937,\n",
            "          0.00650398,  1.        ],\n",
            "        [-0.25070593,  0.06178803,  0.28090128, ...,  0.07590018,\n",
            "         -0.03301832,  1.        ],\n",
            "        [-0.29968715,  0.06863825,  0.27799487, ...,  0.04194754,\n",
            "         -0.0204166 ,  1.        ]], dtype=float32)\n",
            " array([[-0.03103615, -0.13386056, -0.02803065, ...,  0.06095063,\n",
            "          0.21038175,  1.        ],\n",
            "        [ 0.15669197, -0.05686193, -0.01733323, ...,  0.26389432,\n",
            "          0.1412625 ,  1.        ],\n",
            "        [ 0.13108796, -0.02526842, -0.00214104, ...,  0.3545716 ,\n",
            "          0.03840961,  1.        ],\n",
            "        ...,\n",
            "        [-0.13071024,  0.12387058,  0.24110505, ...,  0.07262   ,\n",
            "         -0.00254485,  1.        ],\n",
            "        [-0.2589397 ,  0.10101078,  0.30496216, ...,  0.06750104,\n",
            "         -0.03310678,  1.        ],\n",
            "        [-0.29050726,  0.0926737 ,  0.28228965, ...,  0.05643981,\n",
            "         -0.00893   ,  1.        ]], dtype=float32)\n",
            " array([[-0.01466923, -0.1279824 , -0.02943756, ...,  0.04615651,\n",
            "          0.2115993 ,  1.        ],\n",
            "        [ 0.15444236, -0.03175626, -0.0075085 , ...,  0.26987407,\n",
            "          0.12365108,  1.        ],\n",
            "        [ 0.15565315,  0.02640635,  0.00564198, ...,  0.346535  ,\n",
            "         -0.00972374,  1.        ],\n",
            "        ...,\n",
            "        [-0.03225168,  0.12241184,  0.19253202, ...,  0.08787651,\n",
            "          0.02059651,  1.        ],\n",
            "        [-0.2160203 ,  0.12571074,  0.32459962, ...,  0.08139801,\n",
            "         -0.01319796,  1.        ],\n",
            "        [-0.2686987 ,  0.10547164,  0.2925389 , ...,  0.05989752,\n",
            "          0.0034886 ,  1.        ]], dtype=float32)\n",
            " array([[-0.03572368, -0.14632939, -0.04153671, ...,  0.06174657,\n",
            "          0.2174028 ,  1.        ],\n",
            "        [ 0.1575279 , -0.08527543, -0.05384105, ...,  0.28657454,\n",
            "          0.16709729,  1.        ],\n",
            "        [ 0.10685301, -0.07833523, -0.05342168, ...,  0.38612458,\n",
            "          0.07600249,  1.        ],\n",
            "        ...,\n",
            "        [-0.15068658,  0.03938822,  0.22951107, ...,  0.09142182,\n",
            "         -0.00221296,  1.        ],\n",
            "        [-0.26438868,  0.04893238,  0.2496616 , ...,  0.07367581,\n",
            "         -0.04308289,  1.        ],\n",
            "        [-0.2876414 ,  0.04864335,  0.26200435, ...,  0.03574016,\n",
            "         -0.01763892,  1.        ]], dtype=float32)\n",
            " array([[-0.02858817, -0.15941623, -0.05016449, ...,  0.05607425,\n",
            "          0.21226895,  3.        ],\n",
            "        [ 0.15010156, -0.10508431, -0.0691442 , ...,  0.29579237,\n",
            "          0.15230457,  3.        ],\n",
            "        [ 0.11018132, -0.10941626, -0.07366552, ...,  0.38340196,\n",
            "          0.08235608,  3.        ],\n",
            "        ...,\n",
            "        [-0.11840279,  0.00590978,  0.1997659 , ...,  0.12103761,\n",
            "          0.01064881,  3.        ],\n",
            "        [-0.2164094 ,  0.01238574,  0.22832711, ...,  0.09473285,\n",
            "         -0.03106504,  3.        ],\n",
            "        [-0.26588827,  0.01673085,  0.24507654, ...,  0.03839815,\n",
            "         -0.02044113,  3.        ]], dtype=float32)\n",
            " array([[-2.19829045e-02, -1.53203741e-01, -6.40568286e-02, ...,\n",
            "          5.15695103e-02,  1.85668454e-01,  3.00000000e+00],\n",
            "        [ 1.11658975e-01, -1.28500357e-01, -6.21656962e-02, ...,\n",
            "          2.44003728e-01,  1.52021214e-01,  3.00000000e+00],\n",
            "        [ 4.37728837e-02, -1.28265843e-01, -7.95088410e-02, ...,\n",
            "          3.40990335e-01,  8.88343081e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-2.13937864e-01,  4.44745347e-02,  1.92387402e-01, ...,\n",
            "         -5.92636236e-04, -8.11131522e-02,  3.00000000e+00],\n",
            "        [-2.56900400e-01,  6.72820732e-02,  2.09799796e-01, ...,\n",
            "          1.17795393e-02, -7.76547939e-02,  3.00000000e+00],\n",
            "        [-2.26241708e-01,  3.50087732e-02,  2.34168202e-01, ...,\n",
            "         -1.58295482e-02, -4.90011200e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.01258063e-02, -1.25680998e-01, -3.22612934e-02, ...,\n",
            "          3.98916900e-02,  2.09829822e-01,  3.00000000e+00],\n",
            "        [ 1.18094385e-01, -4.55681197e-02, -1.00164185e-03, ...,\n",
            "          2.35972360e-01,  1.17282532e-01,  3.00000000e+00],\n",
            "        [ 1.19458303e-01,  1.47894258e-02,  1.71865914e-02, ...,\n",
            "          3.12425941e-01, -2.54659653e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-5.56970909e-02,  1.36512339e-01,  2.19645798e-01, ...,\n",
            "          6.24526702e-02,  1.27732614e-02,  3.00000000e+00],\n",
            "        [-2.31775895e-01,  1.39040843e-01,  3.42401356e-01, ...,\n",
            "          6.52938634e-02, -1.10571878e-02,  3.00000000e+00],\n",
            "        [-2.83455700e-01,  1.02543212e-01,  2.97596395e-01, ...,\n",
            "          4.83824164e-02,  3.10529256e-04,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03146018, -0.12771362, -0.03372172, ...,  0.0569599 ,\n",
            "          0.20694195,  3.        ],\n",
            "        [ 0.13438287, -0.06563529, -0.03848175, ...,  0.26707986,\n",
            "          0.13323227,  3.        ],\n",
            "        [ 0.11419789, -0.03955742, -0.03406073, ...,  0.36777204,\n",
            "          0.0149207 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.12994073,  0.09264549,  0.23331188, ...,  0.10663002,\n",
            "         -0.00689792,  3.        ],\n",
            "        [-0.25634852,  0.08520914,  0.30227053, ...,  0.08326019,\n",
            "         -0.03656641,  3.        ],\n",
            "        [-0.2968624 ,  0.08741881,  0.28299472, ...,  0.04453406,\n",
            "         -0.01304263,  3.        ]], dtype=float32)\n",
            " array([[-2.93502919e-02, -1.29058719e-01, -3.16166617e-02, ...,\n",
            "          5.79049774e-02,  2.08787724e-01,  3.00000000e+00],\n",
            "        [ 1.42076686e-01, -6.07199818e-02, -3.43901366e-02, ...,\n",
            "          2.66965508e-01,  1.36815667e-01,  3.00000000e+00],\n",
            "        [ 1.23637766e-01, -3.38418260e-02, -2.38940008e-02, ...,\n",
            "          3.67403597e-01,  1.45335766e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.20739520e-01,  9.23433974e-02,  2.27220073e-01, ...,\n",
            "          9.17018428e-02, -2.05991976e-03,  3.00000000e+00],\n",
            "        [-2.44098634e-01,  8.56272578e-02,  2.93996722e-01, ...,\n",
            "          7.69628063e-02, -3.11946087e-02,  3.00000000e+00],\n",
            "        [-2.92804301e-01,  8.73133466e-02,  2.80020416e-01, ...,\n",
            "          5.11817038e-02, -1.10692130e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.0320242 , -0.14517078, -0.03975233, ...,  0.05667661,\n",
            "          0.21241398,  3.        ],\n",
            "        [ 0.14857742, -0.07827871, -0.06002158, ...,  0.29108056,\n",
            "          0.14531663,  3.        ],\n",
            "        [ 0.1131751 , -0.06717858, -0.06594674, ...,  0.38526058,\n",
            "          0.04672673,  3.        ],\n",
            "        ...,\n",
            "        [-0.1274412 ,  0.04298184,  0.21096613, ...,  0.10833887,\n",
            "          0.01056082,  3.        ],\n",
            "        [-0.23902735,  0.04213675,  0.26288274, ...,  0.08731084,\n",
            "         -0.02897166,  3.        ],\n",
            "        [-0.2863169 ,  0.05638986,  0.26525137, ...,  0.04368903,\n",
            "         -0.01211508,  3.        ]], dtype=float32)\n",
            " array([[-1.53056253e-02, -1.19718485e-01, -3.87944765e-02, ...,\n",
            "          3.87765765e-02,  2.09613174e-01,  3.00000000e+00],\n",
            "        [ 1.16522133e-01, -3.74050587e-02, -1.07200770e-02, ...,\n",
            "          2.32392609e-01,  1.13031499e-01,  3.00000000e+00],\n",
            "        [ 1.19311690e-01,  3.03255562e-02,  6.30686665e-03, ...,\n",
            "          3.07010591e-01, -3.66528146e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-3.42489816e-02,  1.33849606e-01,  1.96899191e-01, ...,\n",
            "          5.76876514e-02,  2.56588999e-02,  3.00000000e+00],\n",
            "        [-2.24835515e-01,  1.33448958e-01,  3.42786580e-01, ...,\n",
            "          6.54915050e-02, -4.03535832e-03,  3.00000000e+00],\n",
            "        [-2.86382765e-01,  9.48862061e-02,  3.03132594e-01, ...,\n",
            "          5.37684374e-02,  1.36542681e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[ 0.02330904, -0.1220863 , -0.07146731, ...,  0.0117717 ,\n",
            "          0.18302168,  3.        ],\n",
            "        [ 0.20423548, -0.03113045, -0.05897428, ...,  0.19906917,\n",
            "          0.02792544,  3.        ],\n",
            "        [ 0.20789741,  0.0131831 , -0.05611333, ...,  0.25726002,\n",
            "         -0.10500649,  3.        ],\n",
            "        ...,\n",
            "        [ 0.12139069,  0.00753898, -0.03714581, ...,  0.05094496,\n",
            "          0.06145121,  3.        ],\n",
            "        [-0.09324409,  0.08716383,  0.27048942, ...,  0.11526657,\n",
            "         -0.02710199,  3.        ],\n",
            "        [-0.25955108,  0.06783333,  0.30768687, ...,  0.07671025,\n",
            "         -0.01063502,  3.        ]], dtype=float32)\n",
            " array([[-0.03282588, -0.13871206, -0.03535999, ...,  0.05401817,\n",
            "          0.21127154,  3.        ],\n",
            "        [ 0.14120407, -0.07542464, -0.04335294, ...,  0.27261287,\n",
            "          0.15172878,  3.        ],\n",
            "        [ 0.10554992, -0.06017422, -0.04190573, ...,  0.36553705,\n",
            "          0.04954536,  3.        ],\n",
            "        ...,\n",
            "        [-0.14286087,  0.06828921,  0.23050684, ...,  0.09935479,\n",
            "          0.00817981,  3.        ],\n",
            "        [-0.25252196,  0.06401131,  0.28478044, ...,  0.08127538,\n",
            "         -0.0349338 ,  3.        ],\n",
            "        [-0.30093926,  0.06571184,  0.28198233, ...,  0.0343153 ,\n",
            "         -0.01335387,  3.        ]], dtype=float32)\n",
            " array([[ 0.01658736, -0.11033   , -0.07012013, ...,  0.02931445,\n",
            "          0.19282976,  3.        ],\n",
            "        [ 0.1791922 , -0.02852413, -0.05170103, ...,  0.22595467,\n",
            "          0.05219283,  3.        ],\n",
            "        [ 0.18634827,  0.02340818, -0.05352934, ...,  0.29708663,\n",
            "         -0.09420501,  3.        ],\n",
            "        ...,\n",
            "        [ 0.10580648,  0.05959006,  0.01465615, ...,  0.05250478,\n",
            "          0.07453158,  3.        ],\n",
            "        [-0.11499153,  0.11159504,  0.27635685, ...,  0.10738701,\n",
            "         -0.01007123,  3.        ],\n",
            "        [-0.24576859,  0.07973887,  0.29736388, ...,  0.07294604,\n",
            "         -0.00524197,  3.        ]], dtype=float32)\n",
            " array([[-2.02205405e-02, -1.14494592e-01, -3.28165665e-02, ...,\n",
            "          3.70793790e-02,  2.05418363e-01,  3.00000000e+00],\n",
            "        [ 1.17274046e-01, -2.94663794e-02, -8.76450911e-03, ...,\n",
            "          2.32295811e-01,  9.87747833e-02,  3.00000000e+00],\n",
            "        [ 1.28508091e-01,  3.98055017e-02,  9.93626937e-03, ...,\n",
            "          3.03030759e-01, -5.29142246e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-3.15901302e-02,  1.34921044e-01,  1.93355873e-01, ...,\n",
            "          3.95786650e-02,  1.68113429e-02,  3.00000000e+00],\n",
            "        [-2.23234832e-01,  1.36545807e-01,  3.49538386e-01, ...,\n",
            "          5.76692261e-02, -9.92312562e-03,  3.00000000e+00],\n",
            "        [-2.83182710e-01,  1.03528418e-01,  3.10906678e-01, ...,\n",
            "          4.49880771e-02,  2.67293816e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.6839802e-02, -1.6232708e-01, -5.8440860e-02, ...,\n",
            "          6.0786162e-02,  2.1045119e-01,  3.0000000e+00],\n",
            "        [ 1.4046587e-01, -1.2277539e-01, -8.2796700e-02, ...,\n",
            "          3.0439341e-01,  1.4951308e-01,  3.0000000e+00],\n",
            "        [ 9.0917818e-02, -1.2562297e-01, -9.0733550e-02, ...,\n",
            "          4.0088034e-01,  7.0582122e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2811738e-01, -3.8633292e-04,  1.8598019e-01, ...,\n",
            "          1.3122141e-01, -2.6631092e-03,  3.0000000e+00],\n",
            "        [-2.0358533e-01,  4.3280390e-03,  2.0242982e-01, ...,\n",
            "          1.0168999e-01, -3.4687106e-02,  3.0000000e+00],\n",
            "        [-2.5219694e-01, -1.7231617e-02,  2.3340520e-01, ...,\n",
            "          4.2291146e-02, -3.2393835e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.2799198e-02, -1.3219519e-01, -2.5184711e-02, ...,\n",
            "          4.3624289e-02,  2.0894235e-01,  3.0000000e+00],\n",
            "        [ 1.2621792e-01, -4.7798667e-02, -5.2864925e-04, ...,\n",
            "          2.4541393e-01,  1.2359359e-01,  3.0000000e+00],\n",
            "        [ 1.2234411e-01,  4.3304195e-03,  2.0621389e-02, ...,\n",
            "          3.2695177e-01, -1.1984013e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0094092e-01,  1.3414794e-01,  2.5064307e-01, ...,\n",
            "          6.9510095e-02, -6.8099666e-03,  3.0000000e+00],\n",
            "        [-2.5025123e-01,  1.2975575e-01,  3.5158128e-01, ...,\n",
            "          6.1500724e-02, -3.0151799e-02,  3.0000000e+00],\n",
            "        [-2.9404122e-01,  9.7847611e-02,  3.0344054e-01, ...,\n",
            "          4.6448037e-02, -7.5813388e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-1.61988251e-02, -1.22580484e-01, -3.30364704e-02, ...,\n",
            "          3.81643400e-02,  2.06297398e-01,  3.00000000e+00],\n",
            "        [ 1.23181626e-01, -3.48659046e-02, -8.33009277e-03, ...,\n",
            "          2.41720319e-01,  1.05855651e-01,  3.00000000e+00],\n",
            "        [ 1.26496986e-01,  3.33548523e-02,  1.28315082e-02, ...,\n",
            "          3.20353836e-01, -4.10443880e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-3.50726061e-02,  1.30624980e-01,  1.90506831e-01, ...,\n",
            "          6.24487847e-02,  1.50590809e-02,  3.00000000e+00],\n",
            "        [-2.23644555e-01,  1.33565456e-01,  3.36296916e-01, ...,\n",
            "          6.68661073e-02, -8.01622961e-03,  3.00000000e+00],\n",
            "        [-2.78449774e-01,  1.00367293e-01,  2.97365814e-01, ...,\n",
            "          4.99390811e-02, -2.62114685e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.02402237, -0.13073899, -0.02667447, ...,  0.044377  ,\n",
            "          0.20830949,  3.        ],\n",
            "        [ 0.12533106, -0.05234846, -0.01015041, ...,  0.24369214,\n",
            "          0.12836067,  3.        ],\n",
            "        [ 0.1139009 , -0.00503985,  0.01190991, ...,  0.33275294,\n",
            "         -0.00922056,  3.        ],\n",
            "        ...,\n",
            "        [-0.11475337,  0.13021165,  0.2392005 , ...,  0.07657706,\n",
            "         -0.00451631,  3.        ],\n",
            "        [-0.257891  ,  0.12728333,  0.34003016, ...,  0.05934478,\n",
            "         -0.03611124,  3.        ],\n",
            "        [-0.3017055 ,  0.08949185,  0.29837042, ...,  0.04789464,\n",
            "         -0.01343972,  3.        ]], dtype=float32)\n",
            " array([[-0.0299778 , -0.11958277, -0.02936352, ...,  0.05654799,\n",
            "          0.20481572,  3.        ],\n",
            "        [ 0.13000391, -0.06339668, -0.02917516, ...,  0.25926167,\n",
            "          0.14003618,  3.        ],\n",
            "        [ 0.11730373, -0.02869693, -0.0166303 , ...,  0.35846293,\n",
            "          0.01291678,  3.        ],\n",
            "        ...,\n",
            "        [-0.17421634,  0.1252246 ,  0.26938382, ...,  0.10792283,\n",
            "         -0.0215946 ,  3.        ],\n",
            "        [-0.27712864,  0.10127471,  0.32924607, ...,  0.08003184,\n",
            "         -0.0444396 ,  3.        ],\n",
            "        [-0.30186284,  0.08774574,  0.29489714, ...,  0.04635534,\n",
            "         -0.01600234,  3.        ]], dtype=float32)\n",
            " array([[-3.20340768e-02, -1.54850900e-01, -5.54366484e-02, ...,\n",
            "          5.74387088e-02,  2.13140830e-01,  3.00000000e+00],\n",
            "        [ 1.39925733e-01, -1.10193342e-01, -8.05953667e-02, ...,\n",
            "          2.98840612e-01,  1.53121114e-01,  3.00000000e+00],\n",
            "        [ 8.96732211e-02, -1.12741269e-01, -8.89076218e-02, ...,\n",
            "          3.98629278e-01,  6.79630041e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.39556512e-01,  1.89623708e-04,  1.95789367e-01, ...,\n",
            "          1.28725395e-01,  4.09573731e-05,  3.00000000e+00],\n",
            "        [-2.22559601e-01,  5.97104849e-03,  2.20387384e-01, ...,\n",
            "          1.00169584e-01, -3.74128036e-02,  3.00000000e+00],\n",
            "        [-2.70199031e-01,  2.01756507e-03,  2.44661987e-01, ...,\n",
            "          3.71354148e-02, -2.88168434e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.010466  , -0.11264233, -0.04060423, ...,  0.03678708,\n",
            "          0.20019436,  3.        ],\n",
            "        [ 0.14248024, -0.01801163, -0.02369531, ...,  0.23150125,\n",
            "          0.07150439,  3.        ],\n",
            "        [ 0.15751904,  0.04459667, -0.0155848 , ...,  0.29672486,\n",
            "         -0.07831386,  3.        ],\n",
            "        ...,\n",
            "        [ 0.01563984,  0.1152036 ,  0.13065536, ...,  0.03280066,\n",
            "          0.02510782,  3.        ],\n",
            "        [-0.1924023 ,  0.13212512,  0.32991046, ...,  0.07044253,\n",
            "         -0.0139457 ,  3.        ],\n",
            "        [-0.2679038 ,  0.10295431,  0.30688533, ...,  0.05158453,\n",
            "         -0.0033497 ,  3.        ]], dtype=float32)\n",
            " array([[-2.16161087e-02, -1.21824712e-01, -2.68713664e-02, ...,\n",
            "          3.57342251e-02,  2.01695904e-01,  3.00000000e+00],\n",
            "        [ 1.23677276e-01, -2.60951575e-02,  2.93283886e-03, ...,\n",
            "          2.36231402e-01,  9.56884697e-02,  3.00000000e+00],\n",
            "        [ 1.28473625e-01,  3.96582112e-02,  2.44967397e-02, ...,\n",
            "          3.07941049e-01, -4.95606996e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-2.26687808e-02,  1.37679905e-01,  1.93810552e-01, ...,\n",
            "          4.16776463e-02,  1.52366171e-02,  3.00000000e+00],\n",
            "        [-2.17518464e-01,  1.34284809e-01,  3.47619116e-01, ...,\n",
            "          4.77603748e-02, -1.13398032e-02,  3.00000000e+00],\n",
            "        [-2.83778369e-01,  1.05579793e-01,  3.08464676e-01, ...,\n",
            "          3.86615284e-02, -5.27937477e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.0214787 , -0.12898158, -0.02419063, ...,  0.03977524,\n",
            "          0.20710316,  3.        ],\n",
            "        [ 0.12138289, -0.04925561,  0.00315097, ...,  0.24271438,\n",
            "          0.12320927,  3.        ],\n",
            "        [ 0.12268315,  0.00863328,  0.02093124, ...,  0.32580826,\n",
            "         -0.00913699,  3.        ],\n",
            "        ...,\n",
            "        [-0.11539488,  0.13999787,  0.27024645, ...,  0.07898334,\n",
            "         -0.01527476,  3.        ],\n",
            "        [-0.2535563 ,  0.12901998,  0.3621891 , ...,  0.06334206,\n",
            "         -0.03273052,  3.        ],\n",
            "        [-0.2977635 ,  0.0956047 ,  0.31277505, ...,  0.05010311,\n",
            "         -0.01539685,  3.        ]], dtype=float32)\n",
            " array([[-0.02208608, -0.13260946, -0.02809433, ...,  0.04878151,\n",
            "          0.21422581,  3.        ],\n",
            "        [ 0.14454058, -0.0524269 , -0.00943107, ...,  0.23052204,\n",
            "          0.14261077,  3.        ],\n",
            "        [ 0.1289133 , -0.00601971,  0.01362418, ...,  0.31499907,\n",
            "          0.00654138,  3.        ],\n",
            "        ...,\n",
            "        [-0.14668095,  0.15362161,  0.26214054, ...,  0.05573525,\n",
            "         -0.01086606,  3.        ],\n",
            "        [-0.2559371 ,  0.12918784,  0.3254413 , ...,  0.05362561,\n",
            "         -0.03333055,  3.        ],\n",
            "        [-0.28561437,  0.0980811 ,  0.2923513 , ...,  0.05461711,\n",
            "         -0.01112447,  3.        ]], dtype=float32)\n",
            " array([[-5.77106420e-03, -1.13426134e-01, -4.95507009e-02, ...,\n",
            "          3.87220979e-02,  1.99417368e-01,  3.00000000e+00],\n",
            "        [ 1.40844882e-01, -2.45503541e-02, -3.27397585e-02, ...,\n",
            "          2.40959704e-01,  7.04283193e-02,  3.00000000e+00],\n",
            "        [ 1.55676425e-01,  3.91020812e-02, -2.76868492e-02, ...,\n",
            "          3.10778826e-01, -7.58247226e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 5.46317883e-02,  9.96517688e-02,  8.93243253e-02, ...,\n",
            "          5.12790270e-02,  4.55149263e-02,  3.00000000e+00],\n",
            "        [-1.72933027e-01,  1.22564167e-01,  3.09900254e-01, ...,\n",
            "          9.14925113e-02, -8.18562973e-03,  3.00000000e+00],\n",
            "        [-2.57625133e-01,  9.92245600e-02,  2.95799375e-01, ...,\n",
            "          6.16704710e-02,  9.99053009e-04,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.8463928e-02, -1.3101842e-01, -2.9413754e-02, ...,\n",
            "          4.4410583e-02,  2.0643087e-01,  3.0000000e+00],\n",
            "        [ 1.3482703e-01, -5.2449342e-02, -7.8931805e-03, ...,\n",
            "          2.6432991e-01,  1.2401653e-01,  3.0000000e+00],\n",
            "        [ 1.3068527e-01,  1.6595884e-03,  3.7709360e-03, ...,\n",
            "          3.5876825e-01, -1.6478365e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-8.4125452e-02,  1.1630329e-01,  2.1774642e-01, ...,\n",
            "          9.5705509e-02, -9.4049564e-03,  3.0000000e+00],\n",
            "        [-2.3604189e-01,  1.1482376e-01,  3.2621577e-01, ...,\n",
            "          7.8835391e-02, -3.0938733e-02,  3.0000000e+00],\n",
            "        [-2.8532118e-01,  9.5921390e-02,  2.9382080e-01, ...,\n",
            "          5.1319897e-02, -1.0711456e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.2797778e-02, -1.3299553e-01, -2.6981207e-02, ...,\n",
            "          4.5511026e-02,  2.0941976e-01,  3.0000000e+00],\n",
            "        [ 1.3212739e-01, -4.8767492e-02, -9.1922972e-03, ...,\n",
            "          2.5633785e-01,  1.2677203e-01,  3.0000000e+00],\n",
            "        [ 1.2300858e-01, -2.2897411e-03,  9.1021657e-03, ...,\n",
            "          3.4397995e-01, -5.2766204e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0903234e-01,  1.2480000e-01,  2.4428119e-01, ...,\n",
            "          8.3601296e-02, -1.5052218e-02,  3.0000000e+00],\n",
            "        [-2.4604349e-01,  1.1928393e-01,  3.3419627e-01, ...,\n",
            "          7.0251778e-02, -3.4177374e-02,  3.0000000e+00],\n",
            "        [-2.9287830e-01,  9.3225941e-02,  2.9622841e-01, ...,\n",
            "          5.0548233e-02, -9.5643429e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.9151846e-02, -1.5608521e-01, -5.1161975e-02, ...,\n",
            "          5.8132082e-02,  2.1457800e-01,  3.0000000e+00],\n",
            "        [ 1.5146132e-01, -9.9043928e-02, -7.3872782e-02, ...,\n",
            "          2.9973480e-01,  1.5275005e-01,  3.0000000e+00],\n",
            "        [ 1.0573684e-01, -1.0206230e-01, -7.9417385e-02, ...,\n",
            "          3.9565197e-01,  6.9989599e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2805466e-01,  6.2076310e-03,  2.0760724e-01, ...,\n",
            "          1.1792136e-01,  8.5470214e-04,  3.0000000e+00],\n",
            "        [-2.1818206e-01,  1.1454998e-02,  2.2952677e-01, ...,\n",
            "          9.3560115e-02, -3.3849120e-02,  3.0000000e+00],\n",
            "        [-2.6607624e-01,  2.0241085e-02,  2.4725850e-01, ...,\n",
            "          4.0469375e-02, -1.5791936e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02981128, -0.12799439, -0.03697564, ...,  0.05528156,\n",
            "          0.20957074,  3.        ],\n",
            "        [ 0.13692582, -0.06740607, -0.036604  , ...,  0.2692712 ,\n",
            "          0.14339449,  3.        ],\n",
            "        [ 0.11586213, -0.04738403, -0.03767421, ...,  0.37048733,\n",
            "          0.02520141,  3.        ],\n",
            "        ...,\n",
            "        [-0.13154744,  0.07846002,  0.2345194 , ...,  0.10070831,\n",
            "         -0.0039511 ,  3.        ],\n",
            "        [-0.24851008,  0.06808609,  0.29323354, ...,  0.08274508,\n",
            "         -0.03545779,  3.        ],\n",
            "        [-0.2940951 ,  0.07923756,  0.27783978, ...,  0.04376419,\n",
            "         -0.01463933,  3.        ]], dtype=float32)\n",
            " array([[-0.03375871, -0.15084751, -0.05739906, ...,  0.06405276,\n",
            "          0.20402808,  3.        ],\n",
            "        [ 0.13181227, -0.112735  , -0.06807923, ...,  0.30076018,\n",
            "          0.15197286,  3.        ],\n",
            "        [ 0.06883921, -0.11184493, -0.07510886, ...,  0.4039792 ,\n",
            "          0.08097871,  3.        ],\n",
            "        ...,\n",
            "        [-0.1998136 ,  0.03891187,  0.19650215, ...,  0.10353853,\n",
            "         -0.062539  ,  3.        ],\n",
            "        [-0.25567892,  0.04686004,  0.19707516, ...,  0.08541898,\n",
            "         -0.07620696,  3.        ],\n",
            "        [-0.26048717,  0.03052348,  0.23477742, ...,  0.02598767,\n",
            "         -0.04086171,  3.        ]], dtype=float32)\n",
            " array([[-2.0164521e-02, -1.3351543e-01, -2.8111184e-02, ...,\n",
            "          5.0774839e-02,  2.1123905e-01,  3.0000000e+00],\n",
            "        [ 1.3638401e-01, -5.4910313e-02, -1.3881037e-02, ...,\n",
            "          2.6582089e-01,  1.3393405e-01,  3.0000000e+00],\n",
            "        [ 1.2519763e-01, -1.5987696e-02,  8.5446698e-04, ...,\n",
            "          3.5817444e-01,  4.2078923e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1982509e-01,  1.1457288e-01,  2.4578756e-01, ...,\n",
            "          9.6247286e-02, -2.3223678e-02,  3.0000000e+00],\n",
            "        [-2.4745138e-01,  1.0688700e-01,  3.2514697e-01, ...,\n",
            "          8.1849292e-02, -3.9642442e-02,  3.0000000e+00],\n",
            "        [-2.9283285e-01,  8.9748137e-02,  2.9204017e-01, ...,\n",
            "          5.3138014e-02, -1.0990714e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[ 0.00972853, -0.11258149, -0.0607333 , ...,  0.0252244 ,\n",
            "          0.18964837,  3.        ],\n",
            "        [ 0.17713231, -0.02523613, -0.04735305, ...,  0.23078735,\n",
            "          0.03913756,  3.        ],\n",
            "        [ 0.17899987,  0.02264711, -0.04591607, ...,  0.29158577,\n",
            "         -0.09979261,  3.        ],\n",
            "        ...,\n",
            "        [ 0.08960249,  0.05439582,  0.0351621 , ...,  0.04546451,\n",
            "          0.04925188,  3.        ],\n",
            "        [-0.12950854,  0.11367967,  0.3008402 , ...,  0.09934425,\n",
            "         -0.02014535,  3.        ],\n",
            "        [-0.25534445,  0.0848437 ,  0.30273703, ...,  0.06517108,\n",
            "         -0.01013045,  3.        ]], dtype=float32)\n",
            " array([[-1.92765035e-02, -1.25831082e-01, -3.23298015e-02, ...,\n",
            "          4.02164385e-02,  2.08019927e-01,  3.00000000e+00],\n",
            "        [ 1.18973210e-01, -3.58874053e-02, -2.98517826e-03, ...,\n",
            "          2.34409824e-01,  1.08754426e-01,  3.00000000e+00],\n",
            "        [ 1.30011544e-01,  2.53483672e-02,  1.26287248e-02, ...,\n",
            "          3.02913219e-01, -4.03884649e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-7.13506415e-02,  1.43446714e-01,  2.24064916e-01, ...,\n",
            "          5.97694367e-02, -9.13861953e-03,  3.00000000e+00],\n",
            "        [-2.36871764e-01,  1.37470394e-01,  3.51461351e-01, ...,\n",
            "          5.52627742e-02, -2.58191023e-02,  3.00000000e+00],\n",
            "        [-2.83701420e-01,  1.02943547e-01,  3.07204932e-01, ...,\n",
            "          4.43784110e-02, -2.45830673e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.02625283, -0.12600219, -0.02427731, ...,  0.03639002,\n",
            "          0.20370209,  3.        ],\n",
            "        [ 0.11471019, -0.03972964,  0.01301718, ...,  0.22564164,\n",
            "          0.10943853,  3.        ],\n",
            "        [ 0.11482544,  0.01698927,  0.03447786, ...,  0.29889125,\n",
            "         -0.02941887,  3.        ],\n",
            "        ...,\n",
            "        [-0.10109858,  0.14469355,  0.26333088, ...,  0.05049668,\n",
            "         -0.01112023,  3.        ],\n",
            "        [-0.25069737,  0.13281108,  0.36867142, ...,  0.04256957,\n",
            "         -0.02766019,  3.        ],\n",
            "        [-0.29863095,  0.10066603,  0.31623027, ...,  0.0338348 ,\n",
            "         -0.00741013,  3.        ]], dtype=float32)\n",
            " array([[-0.0338434 , -0.13494438, -0.03129611, ...,  0.05993336,\n",
            "          0.21160446,  3.        ],\n",
            "        [ 0.16555543, -0.05941794, -0.027263  , ...,  0.25443473,\n",
            "          0.14624889,  3.        ],\n",
            "        [ 0.12872453, -0.03227044, -0.00989717, ...,  0.34182107,\n",
            "          0.03836967,  3.        ],\n",
            "        ...,\n",
            "        [-0.14449596,  0.10683166,  0.2501367 , ...,  0.06680865,\n",
            "         -0.00753474,  3.        ],\n",
            "        [-0.25005198,  0.08759545,  0.28931752, ...,  0.06075793,\n",
            "         -0.04071204,  3.        ],\n",
            "        [-0.28062335,  0.08077925,  0.27648568, ...,  0.04801811,\n",
            "         -0.01816561,  3.        ]], dtype=float32)\n",
            " array([[-0.03191906, -0.12083417, -0.02869014, ...,  0.05302762,\n",
            "          0.205589  ,  3.        ],\n",
            "        [ 0.12816608, -0.05901944, -0.02041288, ...,  0.24287698,\n",
            "          0.13737439,  3.        ],\n",
            "        [ 0.11157236, -0.02717467, -0.00524223, ...,  0.33512053,\n",
            "          0.01842322,  3.        ],\n",
            "        ...,\n",
            "        [-0.1720293 ,  0.11956781,  0.27027795, ...,  0.08275028,\n",
            "         -0.02439269,  3.        ],\n",
            "        [-0.28180656,  0.09950574,  0.32684934, ...,  0.06841448,\n",
            "         -0.04629679,  3.        ],\n",
            "        [-0.3014756 ,  0.09662105,  0.2920446 , ...,  0.03419911,\n",
            "         -0.01480124,  3.        ]], dtype=float32)\n",
            " array([[-0.03673476, -0.14976062, -0.04340422, ...,  0.0548093 ,\n",
            "          0.21338977,  3.        ],\n",
            "        [ 0.14082836, -0.09285263, -0.05733325, ...,  0.2858256 ,\n",
            "          0.15814394,  3.        ],\n",
            "        [ 0.09762313, -0.09201831, -0.065043  , ...,  0.37848637,\n",
            "          0.07959742,  3.        ],\n",
            "        ...,\n",
            "        [-0.14984117,  0.03336218,  0.22252251, ...,  0.11066452,\n",
            "          0.01024729,  3.        ],\n",
            "        [-0.25405756,  0.03823949,  0.25746295, ...,  0.0863971 ,\n",
            "         -0.03897691,  3.        ],\n",
            "        [-0.2904364 ,  0.03768509,  0.26585123, ...,  0.03045403,\n",
            "         -0.0170591 ,  3.        ]], dtype=float32)\n",
            " array([[-0.03236147, -0.12230533, -0.03096994, ...,  0.05215107,\n",
            "          0.2044309 ,  3.        ],\n",
            "        [ 0.12546146, -0.06443471, -0.02679869, ...,  0.24915107,\n",
            "          0.13444972,  3.        ],\n",
            "        [ 0.10923046, -0.03420969, -0.01646982, ...,  0.3431503 ,\n",
            "          0.01575023,  3.        ],\n",
            "        ...,\n",
            "        [-0.16127022,  0.11514755,  0.26061043, ...,  0.09094582,\n",
            "         -0.01903635,  3.        ],\n",
            "        [-0.27408934,  0.10127728,  0.3199021 , ...,  0.07296458,\n",
            "         -0.0442314 ,  3.        ],\n",
            "        [-0.30261245,  0.09189623,  0.29130757, ...,  0.03267606,\n",
            "         -0.01776919,  3.        ]], dtype=float32)\n",
            " array([[-0.03365082, -0.14048488, -0.03606168, ...,  0.05165389,\n",
            "          0.20889755,  3.        ],\n",
            "        [ 0.13745677, -0.07421686, -0.0425311 , ...,  0.2676182 ,\n",
            "          0.1425297 ,  3.        ],\n",
            "        [ 0.10615065, -0.05674819, -0.04331815, ...,  0.35729775,\n",
            "          0.04022665,  3.        ],\n",
            "        ...,\n",
            "        [-0.14263278,  0.06532165,  0.22835083, ...,  0.08829635,\n",
            "          0.0088421 ,  3.        ],\n",
            "        [-0.2501933 ,  0.06243254,  0.281973  , ...,  0.07287394,\n",
            "         -0.03375153,  3.        ],\n",
            "        [-0.29373652,  0.06567511,  0.2806247 , ...,  0.03413124,\n",
            "         -0.01455717,  3.        ]], dtype=float32)\n",
            " array([[-2.59207319e-02, -1.28751248e-01, -2.55053956e-02, ...,\n",
            "          4.26448435e-02,  2.07067490e-01,  3.00000000e+00],\n",
            "        [ 1.17058463e-01, -5.03225103e-02, -1.51414261e-03, ...,\n",
            "          2.43736073e-01,  1.24665402e-01,  3.00000000e+00],\n",
            "        [ 1.11648135e-01,  6.15156081e-04,  1.67416856e-02, ...,\n",
            "          3.27491134e-01, -9.92884673e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.27014071e-01,  1.38501242e-01,  2.70195156e-01, ...,\n",
            "          6.70526028e-02, -1.84238851e-02,  3.00000000e+00],\n",
            "        [-2.56912738e-01,  1.30712897e-01,  3.56409550e-01, ...,\n",
            "          5.93164898e-02, -3.51295210e-02,  3.00000000e+00],\n",
            "        [-3.00736368e-01,  9.63714793e-02,  3.09608668e-01, ...,\n",
            "          4.13543135e-02, -9.58637521e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03580412, -0.15276387, -0.05172395, ...,  0.05912283,\n",
            "          0.21131386,  3.        ],\n",
            "        [ 0.13726476, -0.11237761, -0.07127362, ...,  0.29361638,\n",
            "          0.15893003,  3.        ],\n",
            "        [ 0.07886523, -0.1126871 , -0.07589324, ...,  0.39410466,\n",
            "          0.08187127,  3.        ],\n",
            "        ...,\n",
            "        [-0.16166687,  0.01918147,  0.20432158, ...,  0.11706856,\n",
            "         -0.01593274,  3.        ],\n",
            "        [-0.24764611,  0.03272326,  0.21482436, ...,  0.09347611,\n",
            "         -0.05310037,  3.        ],\n",
            "        [-0.2752807 ,  0.01528462,  0.24391556, ...,  0.03184511,\n",
            "         -0.03667171,  3.        ]], dtype=float32)\n",
            " array([[-0.03761688, -0.14654465, -0.0465009 , ...,  0.05631119,\n",
            "          0.21404764,  3.        ],\n",
            "        [ 0.13510363, -0.09967351, -0.06939232, ...,  0.2887285 ,\n",
            "          0.15967456,  3.        ],\n",
            "        [ 0.08544319, -0.10163988, -0.07366276, ...,  0.38535532,\n",
            "          0.08302774,  3.        ],\n",
            "        ...,\n",
            "        [-0.15374216,  0.01706693,  0.21482928, ...,  0.12340943,\n",
            "          0.00623269,  3.        ],\n",
            "        [-0.25485873,  0.02554582,  0.24311529, ...,  0.09477589,\n",
            "         -0.04067153,  3.        ],\n",
            "        [-0.2900401 ,  0.02480322,  0.2596219 , ...,  0.03111133,\n",
            "         -0.02834465,  3.        ]], dtype=float32)\n",
            " array([[-0.03325312, -0.14616685, -0.03796598, ...,  0.052062  ,\n",
            "          0.21223436,  3.        ],\n",
            "        [ 0.1395985 , -0.08561779, -0.0498491 , ...,  0.27164334,\n",
            "          0.15206051,  3.        ],\n",
            "        [ 0.09990145, -0.07354215, -0.05159269, ...,  0.36303017,\n",
            "          0.05601695,  3.        ],\n",
            "        ...,\n",
            "        [-0.15012912,  0.03804706,  0.22563487, ...,  0.1039352 ,\n",
            "          0.0164042 ,  3.        ],\n",
            "        [-0.25060833,  0.04188088,  0.2743813 , ...,  0.08123438,\n",
            "         -0.03479806,  3.        ],\n",
            "        [-0.29285634,  0.04998936,  0.27548108, ...,  0.0311817 ,\n",
            "         -0.02246122,  3.        ]], dtype=float32)\n",
            " array([[-0.03365557, -0.12206956, -0.03201787, ...,  0.05227484,\n",
            "          0.20710322,  3.        ],\n",
            "        [ 0.12362584, -0.05936981, -0.02818713, ...,  0.24987262,\n",
            "          0.13937092,  3.        ],\n",
            "        [ 0.10501129, -0.03088814, -0.0161353 , ...,  0.34288785,\n",
            "          0.01943498,  3.        ],\n",
            "        ...,\n",
            "        [-0.16597888,  0.11242104,  0.2696183 , ...,  0.09485579,\n",
            "         -0.01817882,  3.        ],\n",
            "        [-0.27783188,  0.09756421,  0.3246673 , ...,  0.07219635,\n",
            "         -0.04621748,  3.        ],\n",
            "        [-0.3062022 ,  0.08875249,  0.29330948, ...,  0.0321569 ,\n",
            "         -0.0204796 ,  3.        ]], dtype=float32)\n",
            " array([[-0.02942681, -0.11908815, -0.02980764, ...,  0.05386681,\n",
            "          0.20493607,  3.        ],\n",
            "        [ 0.12996429, -0.06129855, -0.03228764, ...,  0.25797364,\n",
            "          0.13845743,  3.        ],\n",
            "        [ 0.11517731, -0.02995219, -0.02127288, ...,  0.3556877 ,\n",
            "          0.01306213,  3.        ],\n",
            "        ...,\n",
            "        [-0.16122451,  0.12117858,  0.2607554 , ...,  0.11451551,\n",
            "         -0.01781373,  3.        ],\n",
            "        [-0.27314043,  0.10972882,  0.32400966, ...,  0.08360948,\n",
            "         -0.04033365,  3.        ],\n",
            "        [-0.3067899 ,  0.0841978 ,  0.2928168 , ...,  0.04446338,\n",
            "         -0.02684383,  3.        ]], dtype=float32)\n",
            " array([[-2.1121070e-02, -1.2455164e-01, -2.7308749e-02, ...,\n",
            "          3.7394688e-02,  2.0569079e-01,  3.0000000e+00],\n",
            "        [ 1.2404425e-01, -3.4314845e-02, -1.9138881e-03, ...,\n",
            "          2.3863979e-01,  1.0913859e-01,  3.0000000e+00],\n",
            "        [ 1.2187372e-01,  2.9034141e-02,  1.6030021e-02, ...,\n",
            "          3.1912291e-01, -3.1404566e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-5.0821301e-02,  1.3145880e-01,  2.1602498e-01, ...,\n",
            "          6.2318042e-02,  4.4347653e-03,  3.0000000e+00],\n",
            "        [-2.3504524e-01,  1.3006583e-01,  3.5182631e-01, ...,\n",
            "          5.7463981e-02, -1.7808715e-02,  3.0000000e+00],\n",
            "        [-2.9217929e-01,  9.4727986e-02,  3.0781114e-01, ...,\n",
            "          4.5448732e-02, -1.1193435e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03148295, -0.15598084, -0.04375713, ...,  0.05151289,\n",
            "          0.21126807,  3.        ],\n",
            "        [ 0.1440089 , -0.09297489, -0.05833964, ...,  0.2726085 ,\n",
            "          0.14786375,  3.        ],\n",
            "        [ 0.1042456 , -0.08474875, -0.06325711, ...,  0.36503062,\n",
            "          0.05020859,  3.        ],\n",
            "        ...,\n",
            "        [-0.12492227,  0.02365418,  0.20128316, ...,  0.09876578,\n",
            "          0.02081433,  3.        ],\n",
            "        [-0.23062754,  0.0282854 ,  0.2517253 , ...,  0.07520614,\n",
            "         -0.03213391,  3.        ],\n",
            "        [-0.27530527,  0.03555173,  0.2599531 , ...,  0.02938017,\n",
            "         -0.01758882,  3.        ]], dtype=float32)\n",
            " array([[-3.21018212e-02, -1.57993063e-01, -5.52570224e-02, ...,\n",
            "          5.76307513e-02,  2.12238938e-01,  3.00000000e+00],\n",
            "        [ 1.38236091e-01, -1.16716042e-01, -8.06559548e-02, ...,\n",
            "          2.96715796e-01,  1.54578999e-01,  3.00000000e+00],\n",
            "        [ 8.78467038e-02, -1.18949063e-01, -8.66742730e-02, ...,\n",
            "          3.93953472e-01,  7.44101480e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.39817432e-01,  1.01435208e-03,  1.92270011e-01, ...,\n",
            "          1.26516551e-01,  2.88162287e-03,  3.00000000e+00],\n",
            "        [-2.22566441e-01,  1.07526705e-02,  2.13017821e-01, ...,\n",
            "          9.88367945e-02, -3.69641259e-02,  3.00000000e+00],\n",
            "        [-2.65458226e-01, -8.49125069e-03,  2.41121739e-01, ...,\n",
            "          3.88302878e-02, -3.43822949e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.01806537, -0.12258662, -0.03378353, ...,  0.03756016,\n",
            "          0.20515436,  3.        ],\n",
            "        [ 0.12085601, -0.02873428, -0.00955439, ...,  0.23779824,\n",
            "          0.09386514,  3.        ],\n",
            "        [ 0.1322161 ,  0.03864106,  0.00807866, ...,  0.3100427 ,\n",
            "         -0.05695739,  3.        ],\n",
            "        ...,\n",
            "        [-0.02720019,  0.12899226,  0.18240651, ...,  0.04652276,\n",
            "          0.01071126,  3.        ],\n",
            "        [-0.21895869,  0.12798503,  0.3388067 , ...,  0.05848043,\n",
            "         -0.01485574,  3.        ],\n",
            "        [-0.27861133,  0.09764937,  0.30196127, ...,  0.04833419,\n",
            "         -0.00302328,  3.        ]], dtype=float32)\n",
            " array([[-3.65830697e-02, -1.50540978e-01, -5.08662648e-02, ...,\n",
            "          5.63831776e-02,  2.14153185e-01,  3.00000000e+00],\n",
            "        [ 1.39262125e-01, -1.05890684e-01, -7.30569288e-02, ...,\n",
            "          2.94469953e-01,  1.57992721e-01,  3.00000000e+00],\n",
            "        [ 8.79179314e-02, -1.07808650e-01, -7.82882720e-02, ...,\n",
            "          3.92579973e-01,  7.93115050e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.49372131e-01,  5.99496299e-03,  2.06019193e-01, ...,\n",
            "          1.18697748e-01, -9.01551277e-04,  3.00000000e+00],\n",
            "        [-2.38963887e-01,  1.36718238e-02,  2.31105641e-01, ...,\n",
            "          9.34750885e-02, -4.06462476e-02,  3.00000000e+00],\n",
            "        [-2.81303555e-01,  1.42417559e-02,  2.51549393e-01, ...,\n",
            "          3.23445909e-02, -2.71834917e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.27094330e-02, -1.34448290e-01, -2.55786981e-02, ...,\n",
            "          4.44022417e-02,  2.06052393e-01,  3.00000000e+00],\n",
            "        [ 1.31656170e-01, -5.31101376e-02, -4.83749574e-03, ...,\n",
            "          2.58621842e-01,  1.20766915e-01,  3.00000000e+00],\n",
            "        [ 1.18016019e-01, -9.77392960e-03,  7.35618360e-03, ...,\n",
            "          3.48370373e-01, -2.11128057e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-9.57594365e-02,  1.21110238e-01,  2.36637190e-01, ...,\n",
            "          9.03910995e-02, -9.62341763e-03,  3.00000000e+00],\n",
            "        [-2.45922044e-01,  1.19162172e-01,  3.36767316e-01, ...,\n",
            "          7.65866265e-02, -3.06761824e-02,  3.00000000e+00],\n",
            "        [-2.93004811e-01,  9.63500142e-02,  2.97441214e-01, ...,\n",
            "          5.15191220e-02, -9.11098812e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.9235896e-02, -1.2392162e-01, -3.3755381e-02, ...,\n",
            "          3.9687637e-02,  2.0136389e-01,  3.0000000e+00],\n",
            "        [ 1.2627508e-01, -3.1445391e-02, -8.8880742e-03, ...,\n",
            "          2.4626103e-01,  9.7789928e-02,  3.0000000e+00],\n",
            "        [ 1.2731938e-01,  3.4205705e-02,  7.4353698e-03, ...,\n",
            "          3.2631361e-01, -4.6426382e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-2.1675130e-02,  1.2682138e-01,  1.7759624e-01, ...,\n",
            "          6.4751364e-02,  1.5075660e-02,  3.0000000e+00],\n",
            "        [-2.1969716e-01,  1.2698527e-01,  3.3115947e-01, ...,\n",
            "          6.7629248e-02, -1.0641644e-02,  3.0000000e+00],\n",
            "        [-2.7544600e-01,  1.0200601e-01,  2.9188564e-01, ...,\n",
            "          4.6140078e-02, -9.4223238e-04,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.00990508, -0.11480179, -0.04322895, ...,  0.03050138,\n",
            "          0.19440733,  3.        ],\n",
            "        [ 0.15063162, -0.01252074, -0.02272008, ...,  0.23879442,\n",
            "          0.05874696,  3.        ],\n",
            "        [ 0.15291426,  0.0518219 , -0.01498252, ...,  0.30728224,\n",
            "         -0.08056296,  3.        ],\n",
            "        ...,\n",
            "        [ 0.03360715,  0.11913187,  0.11546605, ...,  0.0337767 ,\n",
            "          0.02145026,  3.        ],\n",
            "        [-0.18449146,  0.12857223,  0.32173756, ...,  0.06621842,\n",
            "         -0.02162696,  3.        ],\n",
            "        [-0.26827446,  0.08710448,  0.3035016 , ...,  0.0489798 ,\n",
            "         -0.01817292,  3.        ]], dtype=float32)\n",
            " array([[ 1.26429899e-02, -1.14339679e-01, -6.71406388e-02, ...,\n",
            "          2.14698464e-02,  1.92434698e-01,  3.00000000e+00],\n",
            "        [ 1.80716857e-01, -3.34284306e-02, -6.02313504e-02, ...,\n",
            "          2.17103273e-01,  3.17547247e-02,  3.00000000e+00],\n",
            "        [ 1.86721981e-01,  1.09776827e-02, -6.07245751e-02, ...,\n",
            "          2.73017973e-01, -1.05094165e-01,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.03181735e-01,  2.99183521e-02, -1.65169197e-03, ...,\n",
            "          2.80347690e-02,  5.65515086e-02,  3.00000000e+00],\n",
            "        [-1.11395337e-01,  1.16593614e-01,  2.94944465e-01, ...,\n",
            "          8.48650709e-02, -1.65515840e-02,  3.00000000e+00],\n",
            "        [-2.63473511e-01,  8.58742967e-02,  3.12658131e-01, ...,\n",
            "          6.11772053e-02, -4.03221278e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[ 4.76593114e-02, -1.71373501e-01, -9.44769904e-02, ...,\n",
            "          1.04773976e-03,  1.85875729e-01,  3.00000000e+00],\n",
            "        [ 2.74883807e-01, -1.94049664e-02, -9.19802785e-02, ...,\n",
            "          1.43170819e-01,  2.01121289e-02,  3.00000000e+00],\n",
            "        [ 2.75589824e-01,  2.97632087e-02, -7.62770399e-02, ...,\n",
            "          1.86485007e-01, -9.77631286e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.42296329e-01,  3.59265669e-03, -1.04541957e-01, ...,\n",
            "          8.81987289e-02,  5.12241796e-02,  3.00000000e+00],\n",
            "        [-1.33836232e-02,  7.65140131e-02,  1.58428803e-01, ...,\n",
            "          1.24680944e-01, -2.83324290e-02,  3.00000000e+00],\n",
            "        [-2.31045961e-01,  5.49465120e-02,  2.93466926e-01, ...,\n",
            "          8.14660490e-02, -7.78377708e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.10155249e-02, -1.17097765e-01, -2.86554359e-02, ...,\n",
            "          4.41239700e-02,  2.16455877e-01,  3.00000000e+00],\n",
            "        [ 1.30313411e-01, -3.21802311e-02,  1.05484331e-03, ...,\n",
            "          2.09888682e-01,  1.27107531e-01,  3.00000000e+00],\n",
            "        [ 1.20534129e-01,  3.10975928e-02,  2.49372106e-02, ...,\n",
            "          2.88456082e-01, -2.33742688e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-8.82543251e-02,  1.65208504e-01,  2.48685136e-01, ...,\n",
            "          2.90381759e-02,  2.75248103e-03,  3.00000000e+00],\n",
            "        [-2.43653178e-01,  1.47751570e-01,  3.52561861e-01, ...,\n",
            "          4.09392081e-02, -1.39522636e-02,  3.00000000e+00],\n",
            "        [-2.80051470e-01,  1.11692682e-01,  3.08009535e-01, ...,\n",
            "          5.93151823e-02,  2.58138333e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.02015561, -0.11555224, -0.03191376, ...,  0.03958203,\n",
            "          0.20372607,  3.        ],\n",
            "        [ 0.12412049, -0.01989096, -0.00387011, ...,  0.23422346,\n",
            "          0.08647777,  3.        ],\n",
            "        [ 0.13769598,  0.04944921,  0.00998566, ...,  0.29878265,\n",
            "         -0.06328046,  3.        ],\n",
            "        ...,\n",
            "        [-0.01193836,  0.1358685 ,  0.16917203, ...,  0.0324842 ,\n",
            "          0.0234336 ,  3.        ],\n",
            "        [-0.21094644,  0.1325309 ,  0.3432699 , ...,  0.05739373,\n",
            "         -0.0071136 ,  3.        ],\n",
            "        [-0.27315   ,  0.10723392,  0.3041126 , ...,  0.0440096 ,\n",
            "          0.00638522,  3.        ]], dtype=float32)\n",
            " array([[-2.3815418e-02, -1.2975281e-01, -2.6826063e-02, ...,\n",
            "          4.1690808e-02,  2.0696785e-01,  3.0000000e+00],\n",
            "        [ 1.1959338e-01, -4.9163949e-02, -1.2335076e-03, ...,\n",
            "          2.4442230e-01,  1.1915302e-01,  3.0000000e+00],\n",
            "        [ 1.1695317e-01,  5.0675371e-03,  1.6199347e-02, ...,\n",
            "          3.2601067e-01, -1.8499827e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-9.8675109e-02,  1.3778965e-01,  2.5280246e-01, ...,\n",
            "          6.8795897e-02, -6.7539993e-03,  3.0000000e+00],\n",
            "        [-2.4860552e-01,  1.3222018e-01,  3.5509765e-01, ...,\n",
            "          6.1990846e-02, -2.8450193e-02,  3.0000000e+00],\n",
            "        [-2.9340118e-01,  1.0042074e-01,  3.0641991e-01, ...,\n",
            "          4.3607157e-02, -5.9007332e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02487378, -0.13590741, -0.02785897, ...,  0.04422173,\n",
            "          0.20663449,  3.        ],\n",
            "        [ 0.12782963, -0.05375709, -0.01024718, ...,  0.2582845 ,\n",
            "          0.12291991,  3.        ],\n",
            "        [ 0.11838717, -0.00745074,  0.00561116, ...,  0.34373298,\n",
            "         -0.00464397,  3.        ],\n",
            "        ...,\n",
            "        [-0.11863738,  0.13193925,  0.24188527, ...,  0.0773939 ,\n",
            "         -0.01162342,  3.        ],\n",
            "        [-0.24299312,  0.12311039,  0.32650015, ...,  0.0656953 ,\n",
            "         -0.03441283,  3.        ],\n",
            "        [-0.28836218,  0.09480885,  0.30051336, ...,  0.04804932,\n",
            "         -0.01283369,  3.        ]], dtype=float32)\n",
            " array([[-2.24402733e-02, -1.30457371e-01, -2.72116512e-02, ...,\n",
            "          4.17025313e-02,  2.07492962e-01,  3.00000000e+00],\n",
            "        [ 1.23944715e-01, -4.93629910e-02, -3.29079106e-03, ...,\n",
            "          2.49890149e-01,  1.19389951e-01,  3.00000000e+00],\n",
            "        [ 1.20078243e-01,  4.47278563e-03,  1.28055839e-02, ...,\n",
            "          3.34606647e-01, -1.69580877e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-8.70686322e-02,  1.30784482e-01,  2.27753446e-01, ...,\n",
            "          7.25792274e-02, -1.04759343e-03,  3.00000000e+00],\n",
            "        [-2.44264916e-01,  1.29932702e-01,  3.40112686e-01, ...,\n",
            "          6.57258630e-02, -2.56055873e-02,  3.00000000e+00],\n",
            "        [-2.88764596e-01,  9.77883041e-02,  2.98629373e-01, ...,\n",
            "          4.67983596e-02, -5.64509537e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03262919, -0.1600632 , -0.05377334, ...,  0.05434416,\n",
            "          0.2098516 ,  3.        ],\n",
            "        [ 0.13638641, -0.11643462, -0.06919105, ...,  0.286815  ,\n",
            "          0.15044558,  3.        ],\n",
            "        [ 0.08970752, -0.11910625, -0.07559768, ...,  0.3767598 ,\n",
            "          0.07775247,  3.        ],\n",
            "        ...,\n",
            "        [-0.14931732, -0.00357088,  0.2049597 , ...,  0.10465018,\n",
            "         -0.00953945,  3.        ],\n",
            "        [-0.22739252,  0.0217317 ,  0.21488795, ...,  0.08643512,\n",
            "         -0.04433105,  3.        ],\n",
            "        [-0.26103112,  0.01011654,  0.24134658, ...,  0.03055524,\n",
            "         -0.02280935,  3.        ]], dtype=float32)\n",
            " array([[-0.02124436, -0.12425826, -0.03003837, ...,  0.03787656,\n",
            "          0.20455642,  3.        ],\n",
            "        [ 0.121962  , -0.03823803, -0.0045077 , ...,  0.24123414,\n",
            "          0.10787863,  3.        ],\n",
            "        [ 0.12413916,  0.02493836,  0.01384824, ...,  0.319565  ,\n",
            "         -0.03660805,  3.        ],\n",
            "        ...,\n",
            "        [-0.05087145,  0.13706334,  0.20942976, ...,  0.06449993,\n",
            "          0.00524628,  3.        ],\n",
            "        [-0.23120688,  0.13871723,  0.34330162, ...,  0.06154133,\n",
            "         -0.01968662,  3.        ],\n",
            "        [-0.28366518,  0.10594545,  0.30408835, ...,  0.04427962,\n",
            "         -0.00394951,  3.        ]], dtype=float32)\n",
            " array([[-2.55173277e-02, -1.34997934e-01, -2.77976990e-02, ...,\n",
            "          4.44970094e-02,  2.07637921e-01,  3.00000000e+00],\n",
            "        [ 1.28475145e-01, -5.55717461e-02, -1.04094120e-02, ...,\n",
            "          2.63736904e-01,  1.23502977e-01,  3.00000000e+00],\n",
            "        [ 1.16656244e-01, -1.04600489e-02,  4.75005247e-03, ...,\n",
            "          3.50952625e-01, -7.31651380e-04,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.25790253e-01,  1.24058694e-01,  2.47142062e-01, ...,\n",
            "          7.10380673e-02, -1.37282033e-02,  3.00000000e+00],\n",
            "        [-2.40570948e-01,  1.19286723e-01,  3.20331186e-01, ...,\n",
            "          6.55032769e-02, -3.47874574e-02,  3.00000000e+00],\n",
            "        [-2.91573972e-01,  9.19590294e-02,  3.00894856e-01, ...,\n",
            "          4.65658940e-02, -1.25976130e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03465031, -0.14080895, -0.0348593 , ...,  0.05213465,\n",
            "          0.21292292,  3.        ],\n",
            "        [ 0.13713521, -0.07768145, -0.04953633, ...,  0.2719838 ,\n",
            "          0.15585539,  3.        ],\n",
            "        [ 0.09901278, -0.06302436, -0.04980599, ...,  0.36399087,\n",
            "          0.0567484 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.15393102,  0.05532818,  0.23825032, ...,  0.10412672,\n",
            "          0.01276827,  3.        ],\n",
            "        [-0.2604077 ,  0.05121448,  0.28599623, ...,  0.08013762,\n",
            "         -0.03338965,  3.        ],\n",
            "        [-0.30161616,  0.05558887,  0.2815296 , ...,  0.0346545 ,\n",
            "         -0.021799  ,  3.        ]], dtype=float32)\n",
            " array([[-2.6349511e-02, -1.3375646e-01, -2.6219228e-02, ...,\n",
            "          4.6570927e-02,  2.1001363e-01,  3.0000000e+00],\n",
            "        [ 1.2334053e-01, -5.4781973e-02, -4.0490809e-03, ...,\n",
            "          2.4474868e-01,  1.3148409e-01,  3.0000000e+00],\n",
            "        [ 1.1155966e-01, -1.3820088e-02,  1.6282385e-02, ...,\n",
            "          3.2848936e-01,  2.1197770e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.3818866e-01,  1.2847738e-01,  2.6602623e-01, ...,\n",
            "          7.0458680e-02, -2.2131572e-02,  3.0000000e+00],\n",
            "        [-2.5951979e-01,  1.2026987e-01,  3.4310761e-01, ...,\n",
            "          6.1262444e-02, -4.3857165e-02,  3.0000000e+00],\n",
            "        [-3.0221200e-01,  9.0371691e-02,  3.0385557e-01, ...,\n",
            "          4.3074381e-02, -1.4059938e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03448787, -0.14519444, -0.04308529, ...,  0.05514093,\n",
            "          0.21468143,  3.        ],\n",
            "        [ 0.13627005, -0.09076608, -0.06226354, ...,  0.2933525 ,\n",
            "          0.15583307,  3.        ],\n",
            "        [ 0.09603819, -0.09329373, -0.06987162, ...,  0.38325888,\n",
            "          0.0825698 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.15168218,  0.02450921,  0.22272176, ...,  0.12198984,\n",
            "          0.01047841,  3.        ],\n",
            "        [-0.2519111 ,  0.02286096,  0.26211074, ...,  0.09205897,\n",
            "         -0.03035798,  3.        ],\n",
            "        [-0.29150853,  0.03134479,  0.26577088, ...,  0.03926785,\n",
            "         -0.02428021,  3.        ]], dtype=float32)\n",
            " array([[-0.03642388, -0.14413589, -0.04058006, ...,  0.05495886,\n",
            "          0.21410128,  3.        ],\n",
            "        [ 0.13750681, -0.0871869 , -0.0570397 , ...,  0.28681642,\n",
            "          0.1580359 ,  3.        ],\n",
            "        [ 0.09552722, -0.0872163 , -0.06226628, ...,  0.37714326,\n",
            "          0.08226501,  3.        ],\n",
            "        ...,\n",
            "        [-0.15822795,  0.03479892,  0.22855455, ...,  0.11173863,\n",
            "          0.01004804,  3.        ],\n",
            "        [-0.2625398 ,  0.03795423,  0.26521182, ...,  0.08762997,\n",
            "         -0.03774343,  3.        ],\n",
            "        [-0.29806593,  0.04129237,  0.27016056, ...,  0.03200577,\n",
            "         -0.02238477,  3.        ]], dtype=float32)\n",
            " array([[-0.03481351, -0.13915446, -0.0329786 , ...,  0.05118736,\n",
            "          0.21104838,  3.        ],\n",
            "        [ 0.13329674, -0.07393695, -0.04596176, ...,  0.27227923,\n",
            "          0.14899838,  3.        ],\n",
            "        [ 0.09925044, -0.05819338, -0.04629309, ...,  0.3615002 ,\n",
            "          0.04951667,  3.        ],\n",
            "        ...,\n",
            "        [-0.14688455,  0.06661443,  0.23236138, ...,  0.10446371,\n",
            "          0.01515322,  3.        ],\n",
            "        [-0.25844595,  0.05485107,  0.28913236, ...,  0.07478023,\n",
            "         -0.0288624 ,  3.        ],\n",
            "        [-0.30167657,  0.06077835,  0.28411925, ...,  0.03475708,\n",
            "         -0.02076996,  3.        ]], dtype=float32)\n",
            " array([[-0.02259022, -0.11599946, -0.03095138, ...,  0.03989968,\n",
            "          0.20527428,  3.        ],\n",
            "        [ 0.11424531, -0.03061811, -0.00712416, ...,  0.23406354,\n",
            "          0.10032489,  3.        ],\n",
            "        [ 0.12392182,  0.03796866,  0.01292418, ...,  0.30388686,\n",
            "         -0.04932818,  3.        ],\n",
            "        ...,\n",
            "        [-0.04421627,  0.13516445,  0.20481108, ...,  0.04260269,\n",
            "          0.0154914 ,  3.        ],\n",
            "        [-0.22641797,  0.14062522,  0.35000297, ...,  0.05776798,\n",
            "         -0.0088329 ,  3.        ],\n",
            "        [-0.2852972 ,  0.10478852,  0.31055188, ...,  0.04466429,\n",
            "          0.00599775,  3.        ]], dtype=float32)\n",
            " array([[-0.03639153, -0.15272082, -0.05307846, ...,  0.0579443 ,\n",
            "          0.21139824,  3.        ],\n",
            "        [ 0.13371556, -0.11597493, -0.0749682 , ...,  0.2931161 ,\n",
            "          0.1585181 ,  3.        ],\n",
            "        [ 0.07637687, -0.11637484, -0.07982028, ...,  0.39428878,\n",
            "          0.07976915,  3.        ],\n",
            "        ...,\n",
            "        [-0.15898009,  0.00927988,  0.20066553, ...,  0.11456289,\n",
            "         -0.01586635,  3.        ],\n",
            "        [-0.24241175,  0.02377777,  0.21171853, ...,  0.09040972,\n",
            "         -0.05335457,  3.        ],\n",
            "        [-0.27369913,  0.01018722,  0.2429895 , ...,  0.02949326,\n",
            "         -0.03354912,  3.        ]], dtype=float32)\n",
            " array([[-0.01097947, -0.11259118, -0.04400494, ...,  0.0393071 ,\n",
            "          0.20218033,  3.        ],\n",
            "        [ 0.13378918, -0.0223803 , -0.02602837, ...,  0.23645805,\n",
            "          0.07892171,  3.        ],\n",
            "        [ 0.14414658,  0.04132855, -0.01539028, ...,  0.30390453,\n",
            "         -0.07075398,  3.        ],\n",
            "        ...,\n",
            "        [ 0.0328493 ,  0.10507789,  0.10128965, ...,  0.03855507,\n",
            "          0.05502559,  3.        ],\n",
            "        [-0.18407656,  0.13140903,  0.31496915, ...,  0.08439607,\n",
            "          0.00303013,  3.        ],\n",
            "        [-0.26841518,  0.09804365,  0.2981491 , ...,  0.05645971,\n",
            "          0.00364547,  3.        ]], dtype=float32)\n",
            " array([[-2.66243424e-02, -1.31710902e-01, -2.31973361e-02, ...,\n",
            "          4.29835320e-02,  2.06783906e-01,  3.00000000e+00],\n",
            "        [ 1.20358229e-01, -5.48921116e-02,  2.92089135e-05, ...,\n",
            "          2.47180611e-01,  1.25835001e-01,  3.00000000e+00],\n",
            "        [ 1.08376950e-01, -9.04917996e-03,  1.68202613e-02, ...,\n",
            "          3.31856787e-01,  1.57833332e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.35827810e-01,  1.30864888e-01,  2.67744064e-01, ...,\n",
            "          8.26664567e-02, -1.72458664e-02,  3.00000000e+00],\n",
            "        [-2.61050612e-01,  1.22118324e-01,  3.50397885e-01, ...,\n",
            "          6.36911541e-02, -4.03764099e-02,  3.00000000e+00],\n",
            "        [-3.03932011e-01,  9.09181312e-02,  3.09482098e-01, ...,\n",
            "          4.55953367e-02, -2.10881662e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03236727, -0.13797839, -0.037877  , ...,  0.05321454,\n",
            "          0.209754  ,  3.        ],\n",
            "        [ 0.1397525 , -0.0760988 , -0.05515943, ...,  0.27469888,\n",
            "          0.14008425,  3.        ],\n",
            "        [ 0.11282735, -0.05726798, -0.05950167, ...,  0.36736274,\n",
            "          0.02928082,  3.        ],\n",
            "        ...,\n",
            "        [-0.13561752,  0.05325273,  0.21238619, ...,  0.10815952,\n",
            "          0.01600758,  3.        ],\n",
            "        [-0.24353468,  0.05183651,  0.27311155, ...,  0.07723302,\n",
            "         -0.02576751,  3.        ],\n",
            "        [-0.29142615,  0.05280491,  0.27437744, ...,  0.04125229,\n",
            "         -0.0228084 ,  3.        ]], dtype=float32)\n",
            " array([[-2.40672119e-02, -1.27811104e-01, -2.21071858e-02, ...,\n",
            "          4.11701612e-02,  2.04936281e-01,  3.00000000e+00],\n",
            "        [ 1.26049474e-01, -4.32838500e-02,  3.96694813e-04, ...,\n",
            "          2.47597277e-01,  1.13792934e-01,  3.00000000e+00],\n",
            "        [ 1.27163187e-01,  2.18883771e-02,  1.95215885e-02, ...,\n",
            "          3.31054926e-01, -2.37325579e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-9.04916972e-02,  1.40032738e-01,  2.49782056e-01, ...,\n",
            "          6.79871812e-02, -4.29555075e-03,  3.00000000e+00],\n",
            "        [-2.44306564e-01,  1.35133728e-01,  3.59500498e-01, ...,\n",
            "          5.77291623e-02, -2.09243596e-02,  3.00000000e+00],\n",
            "        [-2.96047539e-01,  1.01326056e-01,  3.12248319e-01, ...,\n",
            "          4.76289093e-02, -1.14632947e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03311254, -0.13633277, -0.03653162, ...,  0.05326869,\n",
            "          0.20955457,  3.        ],\n",
            "        [ 0.13949718, -0.07377529, -0.05286901, ...,  0.27422085,\n",
            "          0.1395403 ,  3.        ],\n",
            "        [ 0.11137679, -0.0562657 , -0.05677032, ...,  0.36401123,\n",
            "          0.03153837,  3.        ],\n",
            "        ...,\n",
            "        [-0.14002979,  0.06241048,  0.21944763, ...,  0.11129872,\n",
            "          0.01166681,  3.        ],\n",
            "        [-0.24826196,  0.05700942,  0.27749947, ...,  0.08141149,\n",
            "         -0.02857951,  3.        ],\n",
            "        [-0.29332307,  0.05903146,  0.27747267, ...,  0.04162332,\n",
            "         -0.02347614,  3.        ]], dtype=float32)\n",
            " array([[-0.02348108, -0.12915388, -0.02414301, ...,  0.0422509 ,\n",
            "          0.20721002,  3.        ],\n",
            "        [ 0.1236995 , -0.04728536, -0.00328673, ...,  0.25321206,\n",
            "          0.12003246,  3.        ],\n",
            "        [ 0.1189454 ,  0.00813668,  0.01414955, ...,  0.33571368,\n",
            "         -0.01039817,  3.        ],\n",
            "        ...,\n",
            "        [-0.09963024,  0.13289654,  0.25066653, ...,  0.08375174,\n",
            "         -0.01018665,  3.        ],\n",
            "        [-0.24796362,  0.127745  ,  0.3533759 , ...,  0.06610792,\n",
            "         -0.02821089,  3.        ],\n",
            "        [-0.30001944,  0.08864493,  0.3073822 , ...,  0.04931507,\n",
            "         -0.01549272,  3.        ]], dtype=float32)\n",
            " array([[-0.02441304, -0.13171647, -0.02475142, ...,  0.04143228,\n",
            "          0.2079206 ,  3.        ],\n",
            "        [ 0.12281395, -0.05186946, -0.00449393, ...,  0.24426861,\n",
            "          0.1281165 ,  3.        ],\n",
            "        [ 0.1105217 , -0.00751109,  0.01484145, ...,  0.32871014,\n",
            "          0.00429957,  3.        ],\n",
            "        ...,\n",
            "        [-0.1335369 ,  0.13662253,  0.26400065, ...,  0.08465368,\n",
            "         -0.01476511,  3.        ],\n",
            "        [-0.25939074,  0.12673485,  0.3472405 , ...,  0.06251606,\n",
            "         -0.03681611,  3.        ],\n",
            "        [-0.30217734,  0.08708441,  0.30595738, ...,  0.04697151,\n",
            "         -0.02409364,  3.        ]], dtype=float32)\n",
            " array([[-2.59401407e-02, -1.29668653e-01, -2.65336800e-02, ...,\n",
            "          4.13844064e-02,  2.07225695e-01,  3.00000000e+00],\n",
            "        [ 1.17237754e-01, -5.06578796e-02, -1.12701557e-03, ...,\n",
            "          2.42574573e-01,  1.20721526e-01,  3.00000000e+00],\n",
            "        [ 1.16457254e-01,  4.47516609e-03,  1.63844060e-02, ...,\n",
            "          3.24167669e-01, -1.61813982e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.24435440e-01,  1.41583607e-01,  2.71520853e-01, ...,\n",
            "          6.29079342e-02, -1.74563844e-02,  3.00000000e+00],\n",
            "        [-2.54311860e-01,  1.33908182e-01,  3.57779741e-01, ...,\n",
            "          5.77554777e-02, -3.51780802e-02,  3.00000000e+00],\n",
            "        [-2.96029031e-01,  9.95386839e-02,  3.09574783e-01, ...,\n",
            "          4.13736925e-02, -8.83769430e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03340805, -0.15632665, -0.05753306, ...,  0.06148266,\n",
            "          0.21201766,  3.        ],\n",
            "        [ 0.142164  , -0.11430765, -0.07920568, ...,  0.30600727,\n",
            "          0.15485264,  3.        ],\n",
            "        [ 0.08732186, -0.11605141, -0.08564394, ...,  0.40917838,\n",
            "          0.07817008,  3.        ],\n",
            "        ...,\n",
            "        [-0.15474693,  0.01503777,  0.19932465, ...,  0.12114955,\n",
            "         -0.0280026 ,  3.        ],\n",
            "        [-0.22561795,  0.02506073,  0.20231226, ...,  0.09657434,\n",
            "         -0.05256019,  3.        ],\n",
            "        [-0.26424244,  0.00978628,  0.23434216, ...,  0.03604103,\n",
            "         -0.02921795,  3.        ]], dtype=float32)\n",
            " array([[-0.01734843, -0.12475757, -0.0334565 , ...,  0.0394348 ,\n",
            "          0.20509115,  3.        ],\n",
            "        [ 0.12590902, -0.03030984, -0.00952857, ...,  0.2414522 ,\n",
            "          0.10244409,  3.        ],\n",
            "        [ 0.13087459,  0.03553138,  0.00905666, ...,  0.31812355,\n",
            "         -0.04476139,  3.        ],\n",
            "        ...,\n",
            "        [-0.03052458,  0.13186209,  0.18517974, ...,  0.0573793 ,\n",
            "          0.0100527 ,  3.        ],\n",
            "        [-0.2180565 ,  0.12970497,  0.33403137, ...,  0.06578693,\n",
            "         -0.01436453,  3.        ],\n",
            "        [-0.27506268,  0.09879845,  0.29878268, ...,  0.04993171,\n",
            "         -0.00578471,  3.        ]], dtype=float32)\n",
            " array([[-0.00702859, -0.11945689, -0.04473344, ...,  0.04446989,\n",
            "          0.21075118,  3.        ],\n",
            "        [ 0.12409035, -0.03741765, -0.02561476, ...,  0.2374674 ,\n",
            "          0.1095217 ,  3.        ],\n",
            "        [ 0.13182573,  0.03074285, -0.0162643 , ...,  0.31322336,\n",
            "         -0.04662397,  3.        ],\n",
            "        ...,\n",
            "        [-0.04259444,  0.1357939 ,  0.17046405, ...,  0.07059837,\n",
            "          0.01992296,  3.        ],\n",
            "        [-0.22436494,  0.12839653,  0.3252086 , ...,  0.08262432,\n",
            "         -0.00770323,  3.        ],\n",
            "        [-0.26537323,  0.09233804,  0.29772156, ...,  0.0689886 ,\n",
            "          0.00923829,  3.        ]], dtype=float32)\n",
            " array([[-1.88996065e-02, -1.15934059e-01, -3.37220654e-02, ...,\n",
            "          3.86738628e-02,  2.03978702e-01,  3.00000000e+00],\n",
            "        [ 1.21010266e-01, -2.59728990e-02, -8.79450422e-03, ...,\n",
            "          2.33881459e-01,  9.97565165e-02,  3.00000000e+00],\n",
            "        [ 1.28433093e-01,  4.25124206e-02,  1.32510550e-02, ...,\n",
            "          3.08068961e-01, -4.94654365e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-2.94472110e-02,  1.32265061e-01,  1.82749093e-01, ...,\n",
            "          4.47946191e-02,  2.91415695e-02,  3.00000000e+00],\n",
            "        [-2.15751037e-01,  1.32029116e-01,  3.41575056e-01, ...,\n",
            "          5.95004559e-02, -1.13455497e-03,  3.00000000e+00],\n",
            "        [-2.76433766e-01,  1.05465680e-01,  3.00982118e-01, ...,\n",
            "          4.46466394e-02,  4.21565073e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-3.07101961e-02, -1.31473467e-01, -3.42142731e-02, ...,\n",
            "          5.14900684e-02,  2.08553299e-01,  3.00000000e+00],\n",
            "        [ 1.39397606e-01, -6.21558614e-02, -4.01446968e-02, ...,\n",
            "          2.70380497e-01,  1.40791893e-01,  3.00000000e+00],\n",
            "        [ 1.17876463e-01, -3.92119102e-02, -3.75402048e-02, ...,\n",
            "          3.59852284e-01,  3.16236280e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.44738719e-01,  9.21373814e-02,  2.38927111e-01, ...,\n",
            "          1.06637314e-01,  3.37628953e-05,  3.00000000e+00],\n",
            "        [-2.54779905e-01,  7.49822631e-02,  2.97772676e-01, ...,\n",
            "          7.92269260e-02, -3.13698389e-02,  3.00000000e+00],\n",
            "        [-2.96977282e-01,  6.93628863e-02,  2.86067158e-01, ...,\n",
            "          4.34518978e-02, -2.61017568e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03047934, -0.13663167, -0.0371367 , ...,  0.05460845,\n",
            "          0.20852318,  3.        ],\n",
            "        [ 0.14621778, -0.07558379, -0.05202864, ...,  0.28330368,\n",
            "          0.13782708,  3.        ],\n",
            "        [ 0.12077525, -0.05689837, -0.05620532, ...,  0.3735507 ,\n",
            "          0.03381396,  3.        ],\n",
            "        ...,\n",
            "        [-0.12683146,  0.06108353,  0.21632512, ...,  0.1138027 ,\n",
            "          0.00755133,  3.        ],\n",
            "        [-0.23839004,  0.05563614,  0.2774904 , ...,  0.08419067,\n",
            "         -0.02841096,  3.        ],\n",
            "        [-0.2899493 ,  0.06238139,  0.27439833, ...,  0.04499366,\n",
            "         -0.02112967,  3.        ]], dtype=float32)\n",
            " array([[-0.01925903, -0.12744778, -0.03088802, ...,  0.03990886,\n",
            "          0.20328124,  3.        ],\n",
            "        [ 0.127582  , -0.03903618, -0.00825775, ...,  0.24940947,\n",
            "          0.10749737,  3.        ],\n",
            "        [ 0.12563173,  0.02184103,  0.00885351, ...,  0.33305135,\n",
            "         -0.03371508,  3.        ],\n",
            "        ...,\n",
            "        [-0.04388094,  0.12168926,  0.20080636, ...,  0.0716681 ,\n",
            "          0.00661241,  3.        ],\n",
            "        [-0.23099287,  0.12551656,  0.3403888 , ...,  0.06673685,\n",
            "         -0.01551225,  3.        ],\n",
            "        [-0.2838517 ,  0.09933632,  0.29749104, ...,  0.04691488,\n",
            "         -0.00567938,  3.        ]], dtype=float32)\n",
            " array([[-0.02519823, -0.12045938, -0.0253285 , ...,  0.03895503,\n",
            "          0.20556624,  3.        ],\n",
            "        [ 0.11626763, -0.02800715,  0.00671152, ...,  0.23042262,\n",
            "          0.10562423,  3.        ],\n",
            "        [ 0.12331982,  0.0389228 ,  0.02603182, ...,  0.2983689 ,\n",
            "         -0.03751331,  3.        ],\n",
            "        ...,\n",
            "        [-0.05109806,  0.14006048,  0.22120431, ...,  0.03409246,\n",
            "          0.01034515,  3.        ],\n",
            "        [-0.23283607,  0.13255158,  0.3623117 , ...,  0.04450805,\n",
            "         -0.01396735,  3.        ],\n",
            "        [-0.28528622,  0.10878763,  0.31198227, ...,  0.0376408 ,\n",
            "          0.00440981,  3.        ]], dtype=float32)\n",
            " array([[-2.0449586e-02, -1.2689969e-01, -2.8222021e-02, ...,\n",
            "          4.4398163e-02,  2.1522272e-01,  3.0000000e+00],\n",
            "        [ 1.3947648e-01, -3.7686177e-02,  2.2645164e-03, ...,\n",
            "          2.1393241e-01,  1.3094868e-01,  3.0000000e+00],\n",
            "        [ 1.2443437e-01,  1.9758968e-02,  2.3166625e-02, ...,\n",
            "          2.9274905e-01, -1.2103058e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0557750e-01,  1.7179322e-01,  2.5142941e-01, ...,\n",
            "          3.8061589e-02,  2.1945087e-03,  3.0000000e+00],\n",
            "        [-2.4670027e-01,  1.4977075e-01,  3.3918509e-01, ...,\n",
            "          4.1720100e-02, -2.0381307e-02,  3.0000000e+00],\n",
            "        [-2.7822948e-01,  1.1068169e-01,  2.9885671e-01, ...,\n",
            "          5.8028780e-02, -3.9690128e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02555769, -0.13263996, -0.02736862, ...,  0.04731269,\n",
            "          0.20729354,  3.        ],\n",
            "        [ 0.12528414, -0.06065865, -0.01244512, ...,  0.26471704,\n",
            "          0.12874267,  3.        ],\n",
            "        [ 0.10879354, -0.02655595, -0.00373648, ...,  0.35536242,\n",
            "          0.01025801,  3.        ],\n",
            "        ...,\n",
            "        [-0.12168068,  0.12114187,  0.24588329, ...,  0.09150527,\n",
            "         -0.01160036,  3.        ],\n",
            "        [-0.25153992,  0.11458337,  0.32982242, ...,  0.07373212,\n",
            "         -0.03720096,  3.        ],\n",
            "        [-0.29813656,  0.09127757,  0.29679662, ...,  0.04470073,\n",
            "         -0.01390291,  3.        ]], dtype=float32)\n",
            " array([[-0.03362947, -0.15376644, -0.05640186, ...,  0.05913611,\n",
            "          0.2045425 ,  3.        ],\n",
            "        [ 0.12828933, -0.11726185, -0.06647032, ...,  0.27790388,\n",
            "          0.1592412 ,  3.        ],\n",
            "        [ 0.06573184, -0.11539228, -0.06871335, ...,  0.37942174,\n",
            "          0.08529825,  3.        ],\n",
            "        ...,\n",
            "        [-0.1939595 ,  0.02755469,  0.19977269, ...,  0.08950487,\n",
            "         -0.04503879,  3.        ],\n",
            "        [-0.2639887 ,  0.04841029,  0.20484604, ...,  0.07776015,\n",
            "         -0.07302109,  3.        ],\n",
            "        [-0.26600567,  0.03027704,  0.23795924, ...,  0.01936577,\n",
            "         -0.03815295,  3.        ]], dtype=float32)\n",
            " array([[-2.4392754e-02, -1.2508173e-01, -2.5923617e-02, ...,\n",
            "          3.9791074e-02,  2.0784183e-01,  3.0000000e+00],\n",
            "        [ 1.1387167e-01, -4.1585874e-02,  3.0874293e-03, ...,\n",
            "          2.3292781e-01,  1.1651346e-01,  3.0000000e+00],\n",
            "        [ 1.1703575e-01,  1.8335726e-02,  2.3664627e-02, ...,\n",
            "          3.0824995e-01, -2.8994910e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-7.7524185e-02,  1.4125732e-01,  2.4060529e-01, ...,\n",
            "          5.2111257e-02, -1.9819529e-03,  3.0000000e+00],\n",
            "        [-2.4402855e-01,  1.3789466e-01,  3.5878879e-01, ...,\n",
            "          5.2705698e-02, -2.2693720e-02,  3.0000000e+00],\n",
            "        [-2.9393789e-01,  1.0249141e-01,  3.1130084e-01, ...,\n",
            "          4.0661961e-02, -2.3230405e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.028498  , -0.15419829, -0.05879167, ...,  0.05837439,\n",
            "          0.19922374,  3.        ],\n",
            "        [ 0.1290421 , -0.12349773, -0.06695905, ...,  0.26962268,\n",
            "          0.16066967,  3.        ],\n",
            "        [ 0.06662861, -0.12070934, -0.07141157, ...,  0.3698383 ,\n",
            "          0.09282012,  3.        ],\n",
            "        ...,\n",
            "        [-0.20333561,  0.03060527,  0.18648244, ...,  0.07424344,\n",
            "         -0.06290764,  3.        ],\n",
            "        [-0.261393  ,  0.0444745 ,  0.19942284, ...,  0.06783518,\n",
            "         -0.07597727,  3.        ],\n",
            "        [-0.2542556 ,  0.02625888,  0.23295243, ...,  0.01013871,\n",
            "         -0.04559561,  3.        ]], dtype=float32)\n",
            " array([[-3.03216875e-02, -1.30306289e-01, -3.54777090e-02, ...,\n",
            "          5.33149540e-02,  2.09034920e-01,  3.00000000e+00],\n",
            "        [ 1.38371065e-01, -6.64667562e-02, -4.55721468e-02, ...,\n",
            "          2.70170927e-01,  1.40725434e-01,  3.00000000e+00],\n",
            "        [ 1.17907077e-01, -4.30361219e-02, -4.47542779e-02, ...,\n",
            "          3.64672542e-01,  2.45250985e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.40653118e-01,  7.75505230e-02,  2.24704549e-01, ...,\n",
            "          1.13575324e-01,  2.67466158e-03,  3.00000000e+00],\n",
            "        [-2.52688289e-01,  7.08203986e-02,  2.87976652e-01, ...,\n",
            "          8.17388445e-02, -3.26835513e-02,  3.00000000e+00],\n",
            "        [-2.96363592e-01,  6.42918572e-02,  2.80743450e-01, ...,\n",
            "          4.48924489e-02, -2.58725528e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03301723, -0.14124285, -0.03769327, ...,  0.05421724,\n",
            "          0.21317172,  3.        ],\n",
            "        [ 0.14172933, -0.08223649, -0.05872727, ...,  0.2857487 ,\n",
            "          0.15076856,  3.        ],\n",
            "        [ 0.10479569, -0.06984753, -0.06396817, ...,  0.380451  ,\n",
            "          0.05102573,  3.        ],\n",
            "        ...,\n",
            "        [-0.13455117,  0.04088826,  0.21744034, ...,  0.11444053,\n",
            "          0.01921972,  3.        ],\n",
            "        [-0.2444732 ,  0.03897492,  0.27434814, ...,  0.08630218,\n",
            "         -0.02692552,  3.        ],\n",
            "        [-0.29422766,  0.04984508,  0.27318624, ...,  0.03996495,\n",
            "         -0.01911757,  3.        ]], dtype=float32)\n",
            " array([[-1.8680794e-02, -1.1690225e-01, -3.3126298e-02, ...,\n",
            "          3.9417803e-02,  2.0390545e-01,  3.0000000e+00],\n",
            "        [ 1.2300075e-01, -2.8095298e-02, -7.9889745e-03, ...,\n",
            "          2.3766041e-01,  9.3032949e-02,  3.0000000e+00],\n",
            "        [ 1.3051842e-01,  3.8599860e-02,  9.8239407e-03, ...,\n",
            "          3.0652505e-01, -5.4359220e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-6.7725866e-03,  1.3253108e-01,  1.6696091e-01, ...,\n",
            "          4.6570390e-02,  2.9175403e-02,  3.0000000e+00],\n",
            "        [-2.1172790e-01,  1.3423991e-01,  3.3067772e-01, ...,\n",
            "          6.7435890e-02, -3.9693331e-03,  3.0000000e+00],\n",
            "        [-2.7348682e-01,  1.0398811e-01,  2.9796073e-01, ...,\n",
            "          4.3195453e-02,  2.4692379e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02247781, -0.1272444 , -0.02728319, ...,  0.03861277,\n",
            "          0.20622061,  3.        ],\n",
            "        [ 0.1186611 , -0.04083417, -0.00322415, ...,  0.24394691,\n",
            "          0.11346979,  3.        ],\n",
            "        [ 0.11862006,  0.02110849,  0.01342061, ...,  0.3233315 ,\n",
            "         -0.02425218,  3.        ],\n",
            "        ...,\n",
            "        [-0.07145763,  0.13366704,  0.22864467, ...,  0.07571004,\n",
            "         -0.00534579,  3.        ],\n",
            "        [-0.24130529,  0.13212104,  0.35787204, ...,  0.06018023,\n",
            "         -0.02618129,  3.        ],\n",
            "        [-0.29635423,  0.09324899,  0.31031212, ...,  0.04560291,\n",
            "         -0.01651254,  3.        ]], dtype=float32)\n",
            " array([[-0.03433557, -0.14525774, -0.04176388, ...,  0.05301389,\n",
            "          0.21122329,  3.        ],\n",
            "        [ 0.13844323, -0.08787591, -0.05191284, ...,  0.28092274,\n",
            "          0.15487924,  3.        ],\n",
            "        [ 0.10077835, -0.08889294, -0.05818406, ...,  0.36878455,\n",
            "          0.08285046,  3.        ],\n",
            "        ...,\n",
            "        [-0.15722579,  0.03922691,  0.23007238, ...,  0.10769355,\n",
            "          0.00726832,  3.        ],\n",
            "        [-0.2592087 ,  0.03865242,  0.26881438, ...,  0.08420585,\n",
            "         -0.03823658,  3.        ],\n",
            "        [-0.2943581 ,  0.04575617,  0.2726816 , ...,  0.02878365,\n",
            "         -0.01742147,  3.        ]], dtype=float32)\n",
            " array([[-0.03289485, -0.14047565, -0.03550848, ...,  0.04881483,\n",
            "          0.21098834,  3.        ],\n",
            "        [ 0.13077506, -0.07804935, -0.04944213, ...,  0.2667449 ,\n",
            "          0.15325445,  3.        ],\n",
            "        [ 0.09546348, -0.06572847, -0.0546941 , ...,  0.35809442,\n",
            "          0.05536297,  3.        ],\n",
            "        ...,\n",
            "        [-0.14752364,  0.05894036,  0.22682154, ...,  0.11869982,\n",
            "          0.01961927,  3.        ],\n",
            "        [-0.26047137,  0.05191864,  0.2880768 , ...,  0.08561406,\n",
            "         -0.02954367,  3.        ],\n",
            "        [-0.29982534,  0.05164141,  0.28290144, ...,  0.03901129,\n",
            "         -0.02663822,  3.        ]], dtype=float32)\n",
            " array([[-2.97363065e-02, -1.26362845e-01, -2.83826906e-02, ...,\n",
            "          4.97488044e-02,  2.05043748e-01,  3.00000000e+00],\n",
            "        [ 1.27277598e-01, -5.80538400e-02, -1.85732748e-02, ...,\n",
            "          2.49365494e-01,  1.34030864e-01,  3.00000000e+00],\n",
            "        [ 1.13927856e-01, -2.27955077e-02, -2.41766777e-03, ...,\n",
            "          3.41882050e-01,  9.10661463e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.54845580e-01,  1.30735174e-01,  2.66058505e-01, ...,\n",
            "          8.11136961e-02, -1.80446208e-02,  3.00000000e+00],\n",
            "        [-2.66025782e-01,  1.19429164e-01,  3.28107417e-01, ...,\n",
            "          7.11689964e-02, -4.00965102e-02,  3.00000000e+00],\n",
            "        [-3.03884864e-01,  9.39076468e-02,  2.98704237e-01, ...,\n",
            "          4.35755365e-02, -1.60592403e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.21533943e-02, -1.36213526e-01, -3.00319102e-02, ...,\n",
            "          5.09565212e-02,  2.11979270e-01,  3.00000000e+00],\n",
            "        [ 1.37591720e-01, -5.06297983e-02, -1.24618588e-02, ...,\n",
            "          2.62795746e-01,  1.32620618e-01,  3.00000000e+00],\n",
            "        [ 1.25265062e-01, -1.15601914e-02,  7.58244051e-03, ...,\n",
            "          3.49040449e-01,  2.89605674e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.14632756e-01,  1.19941026e-01,  2.35777274e-01, ...,\n",
            "          8.41756687e-02, -1.51085947e-02,  3.00000000e+00],\n",
            "        [-2.41587207e-01,  1.10244095e-01,  3.15542072e-01, ...,\n",
            "          7.05058053e-02, -3.49102020e-02,  3.00000000e+00],\n",
            "        [-2.89474279e-01,  9.13708583e-02,  2.87259400e-01, ...,\n",
            "          5.21364547e-02, -1.16924932e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.67581418e-02, -1.21440202e-01, -2.49756575e-02, ...,\n",
            "          3.93147394e-02,  2.04748601e-01,  3.00000000e+00],\n",
            "        [ 1.15014747e-01, -3.06657366e-02,  6.74786558e-03, ...,\n",
            "          2.31879294e-01,  1.05347365e-01,  3.00000000e+00],\n",
            "        [ 1.24105804e-01,  3.51750478e-02,  2.53514741e-02, ...,\n",
            "          2.99193501e-01, -3.89328115e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-7.14134648e-02,  1.43170312e-01,  2.35238120e-01, ...,\n",
            "          4.07922529e-02, -9.67199728e-03,  3.00000000e+00],\n",
            "        [-2.40943119e-01,  1.37035459e-01,  3.63358200e-01, ...,\n",
            "          4.20625359e-02, -2.50094775e-02,  3.00000000e+00],\n",
            "        [-2.89182425e-01,  1.11364856e-01,  3.14483434e-01, ...,\n",
            "          3.81374396e-02,  2.55997921e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.35543288e-02, -1.31975278e-01, -2.46849153e-02, ...,\n",
            "          4.77378480e-02,  2.15225175e-01,  3.00000000e+00],\n",
            "        [ 1.41693354e-01, -4.81317043e-02,  6.31323375e-04, ...,\n",
            "          2.25864768e-01,  1.39583558e-01,  3.00000000e+00],\n",
            "        [ 1.26063243e-01,  2.74516083e-03,  2.67648511e-02, ...,\n",
            "          3.04507166e-01,  3.26262927e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.38684332e-01,  1.56768918e-01,  2.75530934e-01, ...,\n",
            "          4.38753776e-02, -7.56388763e-03,  3.00000000e+00],\n",
            "        [-2.53164232e-01,  1.36028081e-01,  3.40771854e-01, ...,\n",
            "          4.85246964e-02, -2.94402447e-02,  3.00000000e+00],\n",
            "        [-2.86562532e-01,  1.00234166e-01,  3.01202536e-01, ...,\n",
            "          5.53612895e-02, -7.39185419e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03426046, -0.14182542, -0.0373667 , ...,  0.05306241,\n",
            "          0.21306357,  3.        ],\n",
            "        [ 0.13675353, -0.08135054, -0.06079144, ...,  0.2795295 ,\n",
            "          0.15415582,  3.        ],\n",
            "        [ 0.09841625, -0.06949996, -0.06701523, ...,  0.37279993,\n",
            "          0.0554956 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.15639968,  0.05393057,  0.23090371, ...,  0.1064449 ,\n",
            "          0.01371162,  3.        ],\n",
            "        [-0.25472888,  0.04474672,  0.2792923 , ...,  0.08073712,\n",
            "         -0.02719326,  3.        ],\n",
            "        [-0.29606238,  0.04251522,  0.27848172, ...,  0.04183786,\n",
            "         -0.024819  ,  3.        ]], dtype=float32)\n",
            " array([[-0.03318226, -0.12428118, -0.03289997, ...,  0.05473684,\n",
            "          0.2059398 ,  3.        ],\n",
            "        [ 0.12545288, -0.06610136, -0.03172934, ...,  0.25735855,\n",
            "          0.13586645,  3.        ],\n",
            "        [ 0.10748557, -0.03764403, -0.02670796, ...,  0.35353002,\n",
            "          0.01861953,  3.        ],\n",
            "        ...,\n",
            "        [-0.15260203,  0.10905447,  0.25415537, ...,  0.09767395,\n",
            "         -0.01631712,  3.        ],\n",
            "        [-0.26908383,  0.09679084,  0.31357616, ...,  0.07756452,\n",
            "         -0.04195781,  3.        ],\n",
            "        [-0.30375645,  0.08925492,  0.28886855, ...,  0.03499823,\n",
            "         -0.01862727,  3.        ]], dtype=float32)              ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define the maximum length you want\n",
        "max_length = 117\n",
        "\n",
        "# Truncate sequences longer than max_length and pad sequences shorter than max_length\n",
        "padded_sequences = pad_sequences(combined_data, maxlen=max_length, truncating='post', padding='post', dtype='float32')\n",
        "\n",
        "# Stack the padded sequences into a single numpy array\n",
        "X = np.stack(padded_sequences)"
      ],
      "metadata": {
        "id": "0w8KItoqIOc4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = X[:, :, -1]  # Assuming -1 is the index of the last column\n",
        "\n",
        "# Remove the last column from X to get the features\n",
        "X = X[:, :, :-1]"
      ],
      "metadata": {
        "id": "7bebh7liJG3_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.amax(y, axis=1)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "8S1g4dbSbOWG",
        "outputId": "604db5d9-bafa-49ea-f915-79bf8d95a0e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(546,)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the class distribution\n",
        "class_distribution = np.bincount(y.astype(int))\n",
        "\n",
        "# Print the class distribution\n",
        "print(\"Class Distribution:\")\n",
        "for class_label, count in enumerate(class_distribution):\n",
        "    print(f\"Class {class_label}: {count} samples\")\n"
      ],
      "metadata": {
        "id": "va7W7B0jJfIS",
        "outputId": "4898e524-6b4c-478c-87bb-109605892114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "Class 0: 79 samples\n",
            "Class 1: 152 samples\n",
            "Class 2: 151 samples\n",
            "Class 3: 164 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the class distribution\n",
        "plt.bar(range(len(class_distribution)), class_distribution)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Class Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uIfkpUZwzyoD",
        "outputId": "7789ce79-7068-4f55-fc81-fd5dc4c15f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "fI7BAGV5IRs7",
        "outputId": "781edb85-d62e-43f5-8fee-bfa3b2171f95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [3., 3., 3., ..., 0., 0., 0.],\n",
              "       [3., 3., 3., ..., 0., 0., 0.],\n",
              "       [3., 3., 3., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming you have already loaded and preprocessed your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Define LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=64))  # LSTM layer\n",
        "model.add(Dense(units=4, activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, batch_size=128, epochs=150)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Extract the class with the highest probability for each sample\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "class_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3']  # Define class names based on your problem\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SQa_RFYJ0VvP",
        "outputId": "5213692e-f5f7-45e8-a6a0-e35610e4f70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (436, 117, 768)\n",
            "X_test shape: (110, 117, 768)\n",
            "y_train shape: (436,)\n",
            "y_test shape: (110,)\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 8s 465ms/step - loss: 1.4010 - accuracy: 0.2615\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 1s 338ms/step - loss: 1.3826 - accuracy: 0.3050\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 1s 336ms/step - loss: 1.3594 - accuracy: 0.3257\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 1s 320ms/step - loss: 1.3463 - accuracy: 0.3624\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 1s 332ms/step - loss: 1.3440 - accuracy: 0.3555\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 2s 380ms/step - loss: 1.3374 - accuracy: 0.3601\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 1.3282 - accuracy: 0.3624\n",
            "Epoch 8/150\n",
            "2/4 [==============>...............] - ETA: 0s - loss: 1.3185 - accuracy: 0.3711"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-b75d3edaddeb>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EmotionClassifier(feature_dim, hidden_dim, num_classes).to(device)"
      ],
      "metadata": {
        "id": "6qXp_DZp0mbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay_epoch epochs\"\"\"\n",
        "    lr = initial_lr * (0.1**(epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def train_model(num_epochs, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch)\n",
        "        for features, labels in loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Optional: Print average gradients per epoch to check for vanishing/exploding gradients\n",
        "        avg_gradients = {name: torch.mean(param.grad.abs()).item() for name, param in model.named_parameters() if param.grad is not None}\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(loader)}, Avg Gradients: {avg_gradients}\")\n",
        "\n",
        "        # Check for NaN loss\n",
        "        if torch.isnan(loss).any():\n",
        "            print(\"NaN loss detected\")\n",
        "            break\n",
        "\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "I1nsJZ3a0oqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(50)\n",
        "evaluate_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqi6fr7x0s80",
        "outputId": "23427e20-2fe2-4ea7-988d-0c425ea6717c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7050982117652893, Avg Gradients: {'lstm.weight_ih_l0': 0.00015319950762204826, 'lstm.weight_hh_l0': 0.0001138313818955794, 'lstm.bias_ih_l0': 0.00045707906247116625, 'lstm.bias_hh_l0': 0.00045707906247116625, 'classifier.weight': 0.010660267435014248, 'classifier.bias': 0.004405215382575989}\n",
            "Epoch 2, Loss: 0.6446354389190674, Avg Gradients: {'lstm.weight_ih_l0': 0.00011407291458453983, 'lstm.weight_hh_l0': 9.138100722339004e-05, 'lstm.bias_ih_l0': 0.0005290161934681237, 'lstm.bias_hh_l0': 0.0005290161934681237, 'classifier.weight': 0.010138976387679577, 'classifier.bias': 0.028205230832099915}\n",
            "Epoch 3, Loss: 0.6003038883209229, Avg Gradients: {'lstm.weight_ih_l0': 8.434417395619676e-05, 'lstm.weight_hh_l0': 8.907501614885405e-05, 'lstm.bias_ih_l0': 0.0007479123887605965, 'lstm.bias_hh_l0': 0.0007479123887605965, 'classifier.weight': 0.010165289044380188, 'classifier.bias': 0.055923957377672195}\n",
            "Epoch 4, Loss: 0.5680534839630127, Avg Gradients: {'lstm.weight_ih_l0': 5.7642406318336725e-05, 'lstm.weight_hh_l0': 8.380445069633424e-05, 'lstm.bias_ih_l0': 0.0009154333965852857, 'lstm.bias_hh_l0': 0.0009154333965852857, 'classifier.weight': 0.009360942989587784, 'classifier.bias': 0.07788243889808655}\n",
            "Epoch 5, Loss: 0.5654211640357971, Avg Gradients: {'lstm.weight_ih_l0': 5.526038512471132e-05, 'lstm.weight_hh_l0': 8.30204226076603e-05, 'lstm.bias_ih_l0': 0.0009281523525714874, 'lstm.bias_hh_l0': 0.0009281523525714874, 'classifier.weight': 0.009229740127921104, 'classifier.bias': 0.0796666294336319}\n",
            "Epoch 6, Loss: 0.5628683567047119, Avg Gradients: {'lstm.weight_ih_l0': 5.2991508709965274e-05, 'lstm.weight_hh_l0': 8.228303340729326e-05, 'lstm.bias_ih_l0': 0.0009401073330081999, 'lstm.bias_hh_l0': 0.0009401073330081999, 'classifier.weight': 0.009092732332646847, 'classifier.bias': 0.08135106414556503}\n",
            "Epoch 7, Loss: 0.5603942275047302, Avg Gradients: {'lstm.weight_ih_l0': 5.0801823817892e-05, 'lstm.weight_hh_l0': 8.154720126185566e-05, 'lstm.bias_ih_l0': 0.0009514251141808927, 'lstm.bias_hh_l0': 0.0009514251141808927, 'classifier.weight': 0.008949346840381622, 'classifier.bias': 0.08294837176799774}\n",
            "Epoch 8, Loss: 0.5601511597633362, Avg Gradients: {'lstm.weight_ih_l0': 5.058874376118183e-05, 'lstm.weight_hh_l0': 8.14757077023387e-05, 'lstm.bias_ih_l0': 0.0009525122586637735, 'lstm.bias_hh_l0': 0.0009525122586637735, 'classifier.weight': 0.008934767916798592, 'classifier.bias': 0.08310237526893616}\n",
            "Epoch 9, Loss: 0.5599085688591003, Avg Gradients: {'lstm.weight_ih_l0': 5.037964365328662e-05, 'lstm.weight_hh_l0': 8.140889985952526e-05, 'lstm.bias_ih_l0': 0.000953582813963294, 'lstm.bias_hh_l0': 0.000953582813963294, 'classifier.weight': 0.008920280262827873, 'classifier.bias': 0.0832539051771164}\n",
            "Epoch 10, Loss: 0.559666633605957, Avg Gradients: {'lstm.weight_ih_l0': 5.017354851588607e-05, 'lstm.weight_hh_l0': 8.134573727147654e-05, 'lstm.bias_ih_l0': 0.0009546603541821241, 'lstm.bias_hh_l0': 0.0009546603541821241, 'classifier.weight': 0.008905836381018162, 'classifier.bias': 0.08340348303318024}\n",
            "Epoch 11, Loss: 0.5596424341201782, Avg Gradients: {'lstm.weight_ih_l0': 5.0153186748502776e-05, 'lstm.weight_hh_l0': 8.133973460644484e-05, 'lstm.bias_ih_l0': 0.0009547670488245785, 'lstm.bias_hh_l0': 0.0009547670488245785, 'classifier.weight': 0.008904400281608105, 'classifier.bias': 0.08341828733682632}\n",
            "Epoch 12, Loss: 0.5596181750297546, Avg Gradients: {'lstm.weight_ih_l0': 5.01329886901658e-05, 'lstm.weight_hh_l0': 8.133399387588724e-05, 'lstm.bias_ih_l0': 0.0009548733360134065, 'lstm.bias_hh_l0': 0.0009548733360134065, 'classifier.weight': 0.008902967907488346, 'classifier.bias': 0.08343301713466644}\n",
            "Epoch 13, Loss: 0.5595939755439758, Avg Gradients: {'lstm.weight_ih_l0': 5.011292523704469e-05, 'lstm.weight_hh_l0': 8.132847142405808e-05, 'lstm.bias_ih_l0': 0.0009549791575409472, 'lstm.bias_hh_l0': 0.0009549791575409472, 'classifier.weight': 0.00890154018998146, 'classifier.bias': 0.08344767242670059}\n",
            "Epoch 14, Loss: 0.55959153175354, Avg Gradients: {'lstm.weight_ih_l0': 5.0110946176573634e-05, 'lstm.weight_hh_l0': 8.132794755510986e-05, 'lstm.bias_ih_l0': 0.0009549895767122507, 'lstm.bias_hh_l0': 0.0009549895767122507, 'classifier.weight': 0.008901399560272694, 'classifier.bias': 0.08344912528991699}\n",
            "Epoch 15, Loss: 0.5595890879631042, Avg Gradients: {'lstm.weight_ih_l0': 5.0108945288229734e-05, 'lstm.weight_hh_l0': 8.132740913424641e-05, 'lstm.bias_ih_l0': 0.0009550002869218588, 'lstm.bias_hh_l0': 0.0009550002869218588, 'classifier.weight': 0.008901255205273628, 'classifier.bias': 0.08345059305429459}\n",
            "Epoch 16, Loss: 0.5595866441726685, Avg Gradients: {'lstm.weight_ih_l0': 5.010697350371629e-05, 'lstm.weight_hh_l0': 8.132692892104387e-05, 'lstm.bias_ih_l0': 0.0009550107643008232, 'lstm.bias_hh_l0': 0.0009550107643008232, 'classifier.weight': 0.008901115506887436, 'classifier.bias': 0.08345203846693039}\n",
            "Epoch 17, Loss: 0.5595864057540894, Avg Gradients: {'lstm.weight_ih_l0': 5.010676977690309e-05, 'lstm.weight_hh_l0': 8.132685616146773e-05, 'lstm.bias_ih_l0': 0.0009550119284540415, 'lstm.bias_hh_l0': 0.0009550119284540415, 'classifier.weight': 0.008901100605726242, 'classifier.bias': 0.08345219492912292}\n",
            "Epoch 18, Loss: 0.559586226940155, Avg Gradients: {'lstm.weight_ih_l0': 5.010657332604751e-05, 'lstm.weight_hh_l0': 8.132679795380682e-05, 'lstm.bias_ih_l0': 0.0009550127433612943, 'lstm.bias_hh_l0': 0.0009550127433612943, 'classifier.weight': 0.008901085704565048, 'classifier.bias': 0.08345231413841248}\n",
            "Epoch 19, Loss: 0.5595859885215759, Avg Gradients: {'lstm.weight_ih_l0': 5.010638778912835e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550138493068516, 'lstm.bias_hh_l0': 0.0009550138493068516, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345246315002441}\n",
            "Epoch 20, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132675429806113e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 21, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 22, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 23, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132677612593397e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.0834524855017662}\n",
            "Epoch 24, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 25, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 26, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 27, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132677612593397e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 28, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 29, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 30, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 31, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 32, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 33, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 34, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 35, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 36, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 37, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 38, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 39, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 40, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 41, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 42, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 43, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 44, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 45, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 46, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 47, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 48, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 49, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 50, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GO0bvm6a02Fu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}