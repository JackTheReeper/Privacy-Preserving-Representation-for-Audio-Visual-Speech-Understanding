{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "IRcv11EWEled"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Dependancies"
      ],
      "metadata": {
        "id": "qBmn_DkCFAFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "JxlYZMCuNefB",
        "outputId": "18cadc3a-bab6-4106-8f2d-c2cfdfee16ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9c418b4df3904799b96f7571317bbc9d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GABUf90oBGy3",
        "outputId": "fd5fab9b-476e-4b40-a4ee-c9ecb20a735b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding'...\n",
            "remote: Enumerating objects: 104881, done.\u001b[K\n",
            "remote: Counting objects: 100% (1176/1176), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1094/1094), done.\u001b[K\n",
            "remote: Total 104881 (delta 99), reused 1136 (delta 82), pack-reused 103705\u001b[K\n",
            "Receiving objects: 100% (104881/104881), 3.13 GiB | 33.39 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n",
            "Updating files: 100% (104377/104377), done.\n",
            "/content\n",
            "Cloning into 'av_hubert'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 149 (delta 18), reused 22 (delta 14), pack-reused 111\u001b[K\n",
            "Receiving objects: 100% (149/149), 4.65 MiB | 10.25 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content/av_hubert\n",
            "Submodule 'fairseq' (https://github.com/pytorch/fairseq) registered for path 'fairseq'\n",
            "Cloning into '/content/av_hubert/fairseq'...\n",
            "Submodule path 'fairseq': checked out 'afc77bdf4bb51453ce76f1572ef2ee6ddcda8eeb'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=be623c8ada326f2bdb0b10011b1d301ae628c3cf42226ea52f4be2c59b77aa74\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n",
            "Collecting scikit-video\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.11.4)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n",
            "/content/av_hubert/fairseq\n",
            "Processing /content/av_hubert/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (3.0.10)\n",
            "Collecting hydra-core<1.1 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.23.5)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (4.11.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (4.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==1.0.0a0+afc77bd) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq==1.0.0a0+afc77bd) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq==1.0.0a0+afc77bd) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+afc77bd-cp310-cp310-linux_x86_64.whl size=2472384 sha256=38ae6fae499c2fa33d9102a2f296697b67c3ba74223eeb3bdd3bc4d6a211fbd0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-35xg19v6/wheels/9d/d5/16/2858bd41b3c8f8a9994060d9742bf0c2277ddbd72d53c55737\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=dadc3525ef88c9f8d5d9e165332f8876bf26708d9002817c22664773e8aab0e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 colorama-0.4.6 fairseq-1.0.0a0+afc77bd hydra-core-1.0.7 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShreyAgarwal11/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding.git\n",
        "%cd /content/\n",
        "!git clone https://github.com/facebookresearch/av_hubert.git\n",
        "\n",
        "%cd av_hubert\n",
        "!git submodule init\n",
        "!git submodule update\n",
        "!pip install scipy\n",
        "!pip install sentencepiece\n",
        "!pip install python_speech_features\n",
        "!pip install scikit-video\n",
        "\n",
        "%cd fairseq\n",
        "!pip install ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data/misc/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -O /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!wget --content-disposition https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy -O /content/data/misc/20words_mean_face.npy"
      ],
      "metadata": {
        "id": "Z8VUJ4WLkHoK",
        "outputId": "a5e1c43e-41ac-4bb7-d6bb-20615acfa365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-03 22:50:27--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]  61.07M   138MB/s    in 0.4s    \n",
            "\n",
            "2024-05-03 22:50:28 (138 MB/s) - ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "--2024-05-03 22:50:37--  https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy [following]\n",
            "--2024-05-03 22:50:37--  https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1168 (1.1K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/misc/20words_mean_face.npy’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]   1.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-03 22:50:37 (63.5 MB/s) - ‘/content/data/misc/20words_mean_face.npy’ saved [1168/1168]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import a pre-trained model**"
      ],
      "metadata": {
        "id": "B1Mx4qTIG1AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuned model -> Noise-Augmented AV-HuBERT Base"
      ],
      "metadata": {
        "id": "k9u9TinFIF3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%mkdir -p /content/data/\n",
        "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/avsr/base_noise_pt_noise_ft_433h.pt -O /content/data/finetune-model.pt"
      ],
      "metadata": {
        "id": "1e8mNAjvFS9U",
        "outputId": "e81d00e0-d4f6-406b-9ecf-d64994629a7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/fairseq\n",
            "--2024-05-03 22:50:38--  https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/avsr/base_noise_pt_noise_ft_433h.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.78, 13.226.210.25, 13.226.210.15, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1928060481 (1.8G) [binary/octet-stream]\n",
            "Saving to: ‘/content/data/finetune-model.pt’\n",
            "\n",
            "/content/data/finet 100%[===================>]   1.79G   107MB/s    in 15s     \n",
            "\n",
            "2024-05-03 22:50:53 (121 MB/s) - ‘/content/data/finetune-model.pt’ saved [1928060481/1928060481]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shrey's Video frame creation"
      ],
      "metadata": {
        "id": "IRcv11EWEled"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "frame_folder = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mwbt0/video/sa1'\n",
        "\n",
        "output_video_path = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/output_video.mp4'\n",
        "\n",
        "frame_rate = 25\n",
        "\n",
        "frame_files = [f for f in os.listdir(frame_folder) if os.path.isfile(os.path.join(frame_folder, f))]\n",
        "\n",
        "frame_files.sort()\n",
        "\n",
        "video_resolution = (512, 384)\n",
        "\n",
        "if video_resolution is None:\n",
        "    first_frame_path = os.path.join(frame_folder, frame_files[0])\n",
        "    first_frame = cv2.imread(first_frame_path)\n",
        "    video_resolution = (first_frame.shape[1], first_frame.shape[0])\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, video_resolution)\n",
        "\n",
        "for frame_file in frame_files:\n",
        "    frame_path = os.path.join(frame_folder, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "    if (frame.shape[1], frame.shape[0]) != video_resolution:\n",
        "        frame = cv2.resize(frame, video_resolution)\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "91haYEVIZtYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Frame creation and Deepfake video segregation"
      ],
      "metadata": {
        "id": "vYrFJ2tuZloT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video from VidTIMIT that coincide with deepfake in folder comman_data"
      ],
      "metadata": {
        "id": "6pa-2ocfE0b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "%mkdir -p /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/\n",
        "%mkdir -p /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/"
      ],
      "metadata": {
        "id": "x-h8uaJNix4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_output_video(frame_folder, frame_rate=25, video_resolution=(512, 384)):\n",
        "    frame_files = [f for f in os.listdir(frame_folder) if os.path.isfile(os.path.join(frame_folder, f))]\n",
        "    frame_files.sort()\n",
        "\n",
        "    if video_resolution is None:\n",
        "        first_frame_path = os.path.join(frame_folder, frame_files[0])\n",
        "        first_frame = cv2.imread(first_frame_path)\n",
        "        video_resolution = (first_frame.shape[1], first_frame.shape[0])\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "\n",
        "    # Split the input path and extract the necessary components\n",
        "    parts = frame_folder.split('/')\n",
        "    speaker = parts[-3]  # Get the speaker ID (e.g., fadg0)\n",
        "    video_name = parts[-1]  # Get the video name (e.g., sa1)\n",
        "\n",
        "    # Define the output path\n",
        "    output_video_path = os.path.join('/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/', f\"{video_name}-video-{speaker}.mp4\")\n",
        "\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, video_resolution)\n",
        "\n",
        "    for frame_file in frame_files:\n",
        "        frame_path = os.path.join(frame_folder, frame_file)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        if (frame.shape[1], frame.shape[0]) != video_resolution:\n",
        "            frame = cv2.resize(frame, video_resolution)\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "omNF8lSLWhP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder1 = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/DeepfakeTIMIT/higher_quality/'\n",
        "folder2 = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/'\n",
        "output_vdtimit = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/'\n",
        "\n",
        "\n",
        "# Get list of files in each folder\n",
        "files1 = os.listdir(folder1)\n",
        "files2 = os.listdir(folder2)\n",
        "\n",
        "# Extract filenames without extensions\n",
        "file_names1 = [os.path.splitext(file)[0] for file in files1]\n",
        "file_names2 = [os.path.splitext(file)[0] for file in files2]\n",
        "\n",
        "# Find common filenames\n",
        "common_file_names = set(file_names1).intersection(file_names2)\n",
        "\n",
        "# Process files with common names\n",
        "for common_name in common_file_names:\n",
        "\n",
        "    check_folder = os.path.join(folder2, common_name)\n",
        "\n",
        "    file_path2_audio = os.path.join(check_folder + '/audio')\n",
        "    try:\n",
        "        files2_in_audio = os.listdir(file_path2_audio)\n",
        "        # print(files2_in_audio)\n",
        "    except FileNotFoundError:\n",
        "        # If directory does not exist, delete it and continue to the next directory\n",
        "        shutil.rmtree(check_folder)\n",
        "        print(\"Removed dir :\",  check_folder)\n",
        "        continue\n",
        "\n",
        "    file_path1 = os.path.join(folder1, common_name)\n",
        "    file_path2 = os.path.join(folder2, common_name + '/video')\n",
        "    files1_in = os.listdir(file_path1)\n",
        "    files2_in = os.listdir(file_path2)\n",
        "\n",
        "    # Extract filenames without extensions\n",
        "    file_names1_in = [file.split('-')[0] for file in files1_in if 'video' in file]\n",
        "    # print(file_names1_in)\n",
        "    file_names2_in = [file.split('-')[0] for file in files2_in]\n",
        "    # print(file_names2_in)\n",
        "    files2_audio_in = [file.split('.')[0] for file in files2_in_audio]\n",
        "    # print(files2_audio_in)\n",
        "\n",
        "    # # Find common filenames\n",
        "    common_file_names_in = set(file_names1_in).intersection(file_names2_in)\n",
        "    # print(common_file_names_in)\n",
        "    common_audio_file = set(common_file_names_in).intersection(files2_audio_in)\n",
        "    # print(\"Printed Audio -\",common_audio_file)\n",
        "\n",
        "    for filename in common_audio_file:\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename_audio = filename + '-audio-' + common_name + '.wav'\n",
        "        # print(new_filename_audio)\n",
        "        file_path = os.path.join(output_vdtimit, new_filename_audio)\n",
        "        # print(\"New file path -\",file_path)\n",
        "        shift_path = os.path.join(check_folder + '/audio/' + filename + '.wav')\n",
        "        if os.path.exists(shift_path):\n",
        "                # print(\"Shift_path -\",shift_path)\n",
        "                shutil.copy(shift_path, file_path)\n",
        "                # print(f\"File copied successfully! '{file_path}'\")\n",
        "        else:\n",
        "          print(\"Does not exits\")\n",
        "\n",
        "    for common_name_in in common_file_names_in:\n",
        "\n",
        "      file_path1_in1 = os.path.join(file_path1, common_name_in)\n",
        "      file_path2_in2 = os.path.join(file_path2, common_name_in)\n",
        "\n",
        "      # Check if both files exist before proceeding\n",
        "\n",
        "      if os.path.exists(file_path2_in2):\n",
        "          create_output_video(file_path2_in2)\n",
        "          # Do something with the files, such as processing or using them in your code\n",
        "          # print(f\"Files with name '{common_name_in}' exist in both folders:\")\n",
        "          # print(f\"File path in folder1: {file_path1_in1}\")\n",
        "          # print(f\"File path in folder2: {file_path2_in2}\")\n",
        "          # Your code to process or use the files goes here\n",
        "      else:\n",
        "          print(f\"Files with name '{common_name_in}' do not exist in both folders.\")\n",
        "          print(f\"File path in folder1: {file_path1_in1}\")\n",
        "          print(f\"File path in folder2: {file_path2_in2}\")"
      ],
      "metadata": {
        "id": "oyOJtvRJFO4Q",
        "outputId": "02478b1a-7f35-44d7-a1e2-d092364f5d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/fcmh0\n",
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mdld0\n",
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mrgg0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video from DeepfakeTIMIT that coincide with VidTIMIT in folder comman_data_deep"
      ],
      "metadata": {
        "id": "2SrP046UFBLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_folder = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/DeepfakeTIMIT/higher_quality/'\n",
        "output_video_path = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/'\n",
        "\n",
        "# Get list of directories in the frame_folder\n",
        "directories = [os.path.join(frame_folder, name) for name in os.listdir(frame_folder) if os.path.isdir(os.path.join(frame_folder, name))]\n",
        "\n",
        "# Process files in each directory\n",
        "for directory in directories:\n",
        "    # Get list of files in each directory\n",
        "    files_in_directory = os.listdir(directory)\n",
        "    # print(\"directory -\", directory)\n",
        "    intial = directory.split('/')\n",
        "    speaker = intial[-1]\n",
        "    # print(intial[-1])\n",
        "\n",
        "    # Process each file\n",
        "    for filename in files_in_directory:\n",
        "\n",
        "      if filename.startswith('.'):\n",
        "          continue\n",
        "\n",
        "      if 'video' not in filename:\n",
        "        # print(filename)\n",
        "        file_path_audio = os.path.join(directory, filename)\n",
        "        # print(file_path)\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        # print(name)\n",
        "\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename_audio = name + '-audio-' + speaker + ext\n",
        "        # print(new_filename_audio)\n",
        "\n",
        "        # Construct the new path\n",
        "        new_path_audio = os.path.join(output_video_path, new_filename_audio)\n",
        "        # print(new_path_audio)\n",
        "\n",
        "        # Copy the file to the new path\n",
        "        shutil.copy(file_path_audio, new_path_audio)\n",
        "\n",
        "        # print(f\"File copied successfully! '{new_path_audio}'\")\n",
        "\n",
        "      if 'video' in filename:\n",
        "        # print(filename)\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        # print(file_path)\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        # print(name)\n",
        "\n",
        "        # Split the name into parts separated by '-'\n",
        "        parts = name.split('-')\n",
        "        # print(\"Parts -\",parts)\n",
        "\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename = parts[0] + '-video-' + speaker + ext\n",
        "        # print(new_filename)\n",
        "\n",
        "        # Construct the new path\n",
        "        new_path = os.path.join(output_video_path, new_filename)\n",
        "        print(new_path)\n",
        "\n",
        "        # Copy the file to the new path\n",
        "        shutil.copy(file_path, new_path)\n",
        "\n",
        "        # print(f\"File copied successfully! '{new_path}'\")"
      ],
      "metadata": {
        "id": "EQzAaXQh_u6q",
        "outputId": "3e3556d0-dba8-4421-d511-b5f0ecd5484d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si913-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx193-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1543-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx103-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2173-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx373-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx283-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx13-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx410-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1490-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si860-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si569-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1199-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx209-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx119-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1829-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx29-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx299-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx389-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si824-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1454-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2084-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx389-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1469-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx119-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si839-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx209-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx299-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2099-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx29-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx95-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx1625-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx275-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si995-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2255-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx5-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx12-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx282-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1542-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2172-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si912-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx372-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx192-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1010-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2270-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx290-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx380-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1640-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx20-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx409-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx319-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx229-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx49-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1039-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1669-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2299-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx139-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1894-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si634-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx274-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx4-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx364-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx94-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1264-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx95-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx275-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si635-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx5-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx99-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx279-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx369-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1539-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si909-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx101-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx191-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx371-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si911-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx11-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1541-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2171-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx188-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx278-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si548-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx98-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx8-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx368-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx293-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx383-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx113-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2183-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si923-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx203-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1398-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx228-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si768-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx48-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx408-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx138-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2028-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx318-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx403-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si943-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx313-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx43-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1573-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2203-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx133-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si734-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1624-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx304-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx34-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2222-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx214-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1024-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx124-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx394-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx19-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1909-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx379-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx199-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si649-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1279-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx372-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx282-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1425-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx12-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1555-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx192-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2028-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si469-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx199-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx379-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx19-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1729-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx205-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx385-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx295-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx25-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1825-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx1195-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si565-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx115-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx188-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx98-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx368-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx8-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1988-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2247-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx278-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si728-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx410-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2030-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1400-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si770-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx190-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si522-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx370-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si730-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx100-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx10-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1899-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si639-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx369-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx279-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx99-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si869-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx34-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx214-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx394-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2104-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx304-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx124-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1746-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx126-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx36-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1587-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx396-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1566-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2149-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx36-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si756-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx126-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx396-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2016-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1386-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1714-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx274-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx4-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx364-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1653-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx94-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1084-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fedw0.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AVHubert functions"
      ],
      "metadata": {
        "id": "7ZrRghxYFfWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/av_hubert/avhubert\n",
        "import cv2\n",
        "import tempfile\n",
        "import torch\n",
        "import utils as avhubert_utils\n",
        "from argparse import Namespace\n",
        "import fairseq\n",
        "from fairseq import checkpoint_utils, options, tasks, utils\n",
        "from IPython.display import HTML\n",
        "from python_speech_features import logfbank\n",
        "from scipy.io import wavfile"
      ],
      "metadata": {
        "id": "LjBk19NqG-X0",
        "outputId": "cd9bb4f1-a6b5-4ab7-c62e-b87bab76851a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/avhubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction using AV-HUBERT**"
      ],
      "metadata": {
        "id": "LZm64rT1hyRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stacker(feats, stack_order):\n",
        "            \"\"\"\n",
        "            Concatenating consecutive audio frames\n",
        "            Args:\n",
        "            feats - numpy.ndarray of shape [T, F]\n",
        "            stack_order - int (number of neighboring frames to concatenate\n",
        "            Returns:\n",
        "            feats - numpy.ndarray of shape [T', F']\n",
        "            \"\"\"\n",
        "            feat_dim = feats.shape[1]\n",
        "            if len(feats) % stack_order != 0:\n",
        "                res = stack_order - len(feats) % stack_order\n",
        "                res = np.zeros([res, feat_dim]).astype(feats.dtype)\n",
        "                feats = np.concatenate([feats, res], axis=0)\n",
        "            feats = feats.reshape((-1, stack_order, feat_dim)).reshape(-1, stack_order*feat_dim)\n",
        "            return feats"
      ],
      "metadata": {
        "id": "KVK2SUGkWZED"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_visual_feature(video_path, audio_path, ckpt_path, user_dir, is_finetune_ckpt=False):\n",
        "  utils.import_user_module(Namespace(user_dir=user_dir))\n",
        "  models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
        "  transform = avhubert_utils.Compose([\n",
        "      avhubert_utils.Normalize(0.0, 255.0),\n",
        "      avhubert_utils.CenterCrop((task.cfg.image_crop_size, task.cfg.image_crop_size)),\n",
        "      avhubert_utils.Normalize(task.cfg.image_mean, task.cfg.image_std)])\n",
        "  frames = avhubert_utils.load_video(video_path)\n",
        "  print(f\"Load video {video_path}: shape {frames.shape}\")\n",
        "  sample_rate, wav_data = wavfile.read(audio_path)\n",
        "  audio_features = logfbank(wav_data, sample_rate).astype(np.float32)\n",
        "  audio_features = stacker(audio_features, 4)\n",
        "  print(f\"Load audio {audio_path}: shape {audio_features.shape}\")\n",
        "  audio_features = torch.FloatTensor(audio_features).unsqueeze(dim=0).permute(0, 2, 1).cuda()\n",
        "  frames = torch.FloatTensor(frames).unsqueeze(dim=0).unsqueeze(dim=0).cuda()\n",
        "  if audio_features.shape[2] < frames.shape[2]:\n",
        "    # Pad features_audio\n",
        "    padding_size = frames.shape[2] - audio_features.shape[2]\n",
        "    padding = torch.zeros((audio_features.shape[0], audio_features.shape[1], padding_size)).cuda()\n",
        "    audio_features = torch.cat([audio_features, padding], dim=2)\n",
        "  print(f\"Load video {video_path}: shape {frames.shape}\")\n",
        "  print(f\"Load audio {audio_path}: shape {audio_features.shape}\")\n",
        "  model = models[0]\n",
        "  if hasattr(models[0], 'decoder'):\n",
        "    print(f\"Checkpoint: fine-tuned\")\n",
        "    model = models[0].encoder.w2v_model\n",
        "  else:\n",
        "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")\n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # Specify output_layer if you want to extract feature of an intermediate layer\n",
        "    layer_features = []\n",
        "    for i in range(12):\n",
        "      feature, _ = model.extract_finetune(source={'video': frames, 'audio': audio_features}, padding_mask=None, output_layer=(i+1))\n",
        "      layer_features.append(feature)\n",
        "    feature, _ = model.extract_finetune(source={'video': frames, 'audio': audio_features}, padding_mask=None, output_layer=None)\n",
        "    feature = feature.squeeze(dim=0)\n",
        "  print(f\"AvHuBert Feature shape: {feature.shape}\")\n",
        "  return layer_features, feature\n"
      ],
      "metadata": {
        "id": "C6RNFXKwIfqN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_real = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/'\n",
        "folder_path_deep = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/'\n",
        "\n",
        "# Initialize an empty list to store pairs of file paths\n",
        "real_file_pairs = []\n",
        "deep_file_pairs = []\n",
        "\n",
        "# Get the list of files in the real folder\n",
        "files_real = os.listdir(folder_path_real)\n",
        "\n",
        "# Get the list of files in the deep folder\n",
        "files_deep = os.listdir(folder_path_deep)\n",
        "\n",
        "# Iterate over each file in the real folder\n",
        "for file_real in files_real:\n",
        "    # Split the filename and extension\n",
        "    name, ext_real = os.path.splitext(file_real)\n",
        "    # print(file_real)\n",
        "\n",
        "    # Check if the file is an audio file\n",
        "    if ext_real == '.wav':\n",
        "        # Construct the expected video filename\n",
        "        audio_filename_real = name\n",
        "        video_filename_real = name.replace('-audio-', '-video-')\n",
        "        # print(video_filename)\n",
        "\n",
        "        # Check if the video file exists in the deep folder\n",
        "        for file_deep in files_deep:\n",
        "            name_deep, ext_deep = os.path.splitext(file_deep)\n",
        "            # print(name_deep)\n",
        "                # Check if the file is an audio file\n",
        "            if ext_deep == '.wav':\n",
        "                # Construct the expected video filename\n",
        "                audio_filename_deep = name_deep\n",
        "                video_filename_deep = name_deep.replace('-audio-', '-video-')\n",
        "                if video_filename_deep == video_filename_real:\n",
        "                    # Construct the paths for the audio and video files in both folders\n",
        "                    audio_path_real = os.path.join(folder_path_real, audio_filename_real + ext_deep)\n",
        "                    # print(audio_path_real)\n",
        "                    video_path_real = os.path.join(folder_path_real, video_filename_real + '.mp4')\n",
        "                    audio_path_deep = os.path.join(folder_path_deep, audio_filename_deep + ext_deep)\n",
        "                    # print(audio_path_deep)\n",
        "                    video_path_deep = os.path.join(folder_path_deep, video_filename_real + '.avi')\n",
        "\n",
        "                    # Check if both audio and video files exist in both folders\n",
        "                    if os.path.exists(audio_path_real) and os.path.exists(video_path_real) and \\\n",
        "                      os.path.exists(audio_path_deep) and os.path.exists(video_path_deep):\n",
        "                        # Add the pair of paths to the list\n",
        "                        real_file_pairs.append((audio_path_real, video_path_real))\n",
        "                        deep_file_pairs.append((audio_path_deep, video_path_deep))\n",
        "\n",
        "# Print the number of file pairs found\n",
        "print(len(os.listdir(folder_path_real)))\n",
        "print(len(os.listdir(folder_path_deep)))\n",
        "print(len(real_file_pairs))\n",
        "print(len(deep_file_pairs))\n"
      ],
      "metadata": {
        "id": "QkWDR7zwuVOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8129e1-5f2d-4759-8511-113499ab2e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "580\n",
            "640\n",
            "290\n",
            "290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = \"/content/data/finetune-model.pt\"\n",
        "user_dir = \"/content/av_hubert/avhubert\"\n",
        "\n",
        "feature_real = {}\n",
        "feature_deep = {}\n",
        "\n",
        "# Counter variables to keep track of iterations\n",
        "count_real = 0\n",
        "count_deep = 0\n",
        "\n",
        "# Loop over real_file_pairs\n",
        "for pair in real_file_pairs:\n",
        "    # Increment the counter\n",
        "    count_real += 1\n",
        "\n",
        "    audio_path = pair[0]\n",
        "    mouth_roi_path = pair[1]\n",
        "    name_r, ext_r = os.path.splitext(pair[0])\n",
        "    index_data_r = name_r.split('/')[-1].replace('-audio-', '')\n",
        "\n",
        "    # Check if the index is not already in feature_real\n",
        "    if index_data_r not in feature_real:\n",
        "        layer_features, feature_real[index_data_r] = extract_visual_feature(mouth_roi_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "    # # Break after every 5 iterations\n",
        "    if count_real == 50:\n",
        "        break\n",
        "\n",
        "# Loop over deep_file_pairs\n",
        "for pair in deep_file_pairs:\n",
        "    # Increment the counter\n",
        "    count_deep += 1\n",
        "\n",
        "    audio_path = pair[0]\n",
        "    mouth_roi_path = pair[1]\n",
        "    name_d, ext_d = os.path.splitext(pair[0])\n",
        "    index_data_d = name_d.split('/')[-1].replace('-audio-', '')\n",
        "\n",
        "    # Check if the index is not already in feature_deep\n",
        "    if index_data_d not in feature_deep:\n",
        "        layer_features, feature_deep[index_data_d] = extract_visual_feature(mouth_roi_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "    # Break after every 5 iterations\n",
        "    if count_deep == 50:\n",
        "        break"
      ],
      "metadata": {
        "id": "6j5un1rYER11",
        "outputId": "90070275-5dc3-4a15-a7f1-ca22dcd0a98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-video-mrjo0.mp4: shape (138, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-audio-mrjo0.wav: shape (138, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-video-mrjo0.mp4: shape torch.Size([1, 1, 138, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-audio-mrjo0.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-video-fdac1.mp4: shape (137, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-audio-fdac1.wav: shape (137, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-video-fdac1.mp4: shape torch.Size([1, 1, 137, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-audio-fdac1.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-video-fram1.mp4: shape (114, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-audio-fram1.wav: shape (114, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-video-fram1.mp4: shape torch.Size([1, 1, 114, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-audio-fram1.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-video-fkms0.mp4: shape (102, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-audio-fkms0.wav: shape (102, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-video-fkms0.mp4: shape torch.Size([1, 1, 102, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-audio-fkms0.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-video-msjs1.mp4: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-audio-msjs1.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-video-msjs1.mp4: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-audio-msjs1.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-video-fjre0.mp4: shape (82, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-audio-fjre0.wav: shape (82, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-video-fjre0.mp4: shape torch.Size([1, 1, 82, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-audio-fjre0.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mwbt0.mp4: shape (104, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mwbt0.wav: shape (104, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mwbt0.mp4: shape torch.Size([1, 1, 104, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mwbt0.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjas0.mp4: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjas0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjas0.mp4: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjas0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-video-fjwb0.mp4: shape (123, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-audio-fjwb0.wav: shape (123, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-video-fjwb0.mp4: shape torch.Size([1, 1, 123, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-audio-fjwb0.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-video-mpgl0.mp4: shape (98, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-audio-mpgl0.wav: shape (98, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-video-mpgl0.mp4: shape torch.Size([1, 1, 98, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-audio-mpgl0.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-video-mpgl0.mp4: shape (72, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-audio-mpgl0.wav: shape (72, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-video-mpgl0.mp4: shape torch.Size([1, 1, 72, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-audio-mpgl0.wav: shape torch.Size([1, 104, 72])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([72, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fedw0.mp4: shape (92, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fedw0.wav: shape (92, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fedw0.mp4: shape torch.Size([1, 1, 92, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fedw0.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-video-felc0.mp4: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-audio-felc0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-video-felc0.mp4: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-audio-felc0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-video-faks0.mp4: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-video-faks0.mp4: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjwb0.mp4: shape (99, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjwb0.wav: shape (99, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjwb0.mp4: shape torch.Size([1, 1, 99, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjwb0.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-video-mjsw0.mp4: shape (90, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-audio-mjsw0.wav: shape (90, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-video-mjsw0.mp4: shape torch.Size([1, 1, 90, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-audio-mjsw0.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-video-mwbt0.mp4: shape (101, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-audio-mwbt0.wav: shape (101, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-video-mwbt0.mp4: shape torch.Size([1, 1, 101, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-audio-mwbt0.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-mstk0.mp4: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-mstk0.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-mstk0.mp4: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-mstk0.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-video-fjre0.mp4: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-audio-fjre0.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-video-fjre0.mp4: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-audio-fjre0.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-video-mgwt0.mp4: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-audio-mgwt0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-video-mgwt0.mp4: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-audio-mgwt0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-video-mrjo0.mp4: shape (86, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-audio-mrjo0.wav: shape (86, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-video-mrjo0.mp4: shape torch.Size([1, 1, 86, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-audio-mrjo0.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-video-mgwt0.mp4: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-audio-mgwt0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-video-mgwt0.mp4: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-audio-mgwt0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-video-mwbt0.mp4: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-audio-mwbt0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-video-mwbt0.mp4: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-audio-mwbt0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-msjs1.mp4: shape (121, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-msjs1.wav: shape (121, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-msjs1.mp4: shape torch.Size([1, 1, 121, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-msjs1.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-video-fkms0.mp4: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-audio-fkms0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-video-fkms0.mp4: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-audio-fkms0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-video-fdac1.mp4: shape (88, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-audio-fdac1.wav: shape (88, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-video-fdac1.mp4: shape torch.Size([1, 1, 88, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-audio-fdac1.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mgwt0.mp4: shape (125, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mgwt0.wav: shape (125, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mgwt0.mp4: shape torch.Size([1, 1, 125, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mgwt0.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-video-fkms0.mp4: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-video-fkms0.mp4: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-video-mpgl0.mp4: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-audio-mpgl0.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-video-mpgl0.mp4: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-audio-mpgl0.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fram1.mp4: shape (117, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fram1.wav: shape (117, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fram1.mp4: shape torch.Size([1, 1, 117, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fram1.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-video-fdrd1.mp4: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-audio-fdrd1.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-video-fdrd1.mp4: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-audio-fdrd1.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-video-mrcz0.mp4: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-audio-mrcz0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-video-mrcz0.mp4: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-audio-mrcz0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-video-mmdm2.mp4: shape (116, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-audio-mmdm2.wav: shape (116, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-video-mmdm2.mp4: shape torch.Size([1, 1, 116, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-audio-mmdm2.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-video-mmdb1.mp4: shape (97, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-audio-mmdb1.wav: shape (97, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-video-mmdb1.mp4: shape torch.Size([1, 1, 97, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-audio-mmdb1.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-video-fjem0.mp4: shape (155, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-audio-fjem0.wav: shape (155, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-video-fjem0.mp4: shape torch.Size([1, 1, 155, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-audio-fjem0.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-video-mmdb1.mp4: shape (128, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-audio-mmdb1.wav: shape (128, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-video-mmdb1.mp4: shape torch.Size([1, 1, 128, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-audio-mmdb1.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fdac1.mp4: shape (95, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fdac1.wav: shape (95, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fdac1.mp4: shape torch.Size([1, 1, 95, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fdac1.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mjar0.mp4: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mjar0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mjar0.mp4: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mjar0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-faks0.mp4: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-faks0.mp4: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-video-mjsw0.mp4: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-audio-mjsw0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-video-mjsw0.mp4: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-audio-mjsw0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-faks0.mp4: shape (81, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-faks0.wav: shape (81, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-faks0.mp4: shape torch.Size([1, 1, 81, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-faks0.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-video-fjwb0.mp4: shape (182, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-audio-fjwb0.wav: shape (182, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-video-fjwb0.mp4: shape torch.Size([1, 1, 182, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-audio-fjwb0.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-video-fram1.mp4: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-audio-fram1.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-video-fram1.mp4: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-audio-fram1.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-video-fkms0.mp4: shape (106, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-audio-fkms0.wav: shape (106, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-video-fkms0.mp4: shape torch.Size([1, 1, 106, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-audio-fkms0.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-video-fcft0.mp4: shape (112, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-audio-fcft0.wav: shape (112, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-video-fcft0.mp4: shape torch.Size([1, 1, 112, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-audio-fcft0.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-video-fcft0.mp4: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-audio-fcft0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-video-fcft0.mp4: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-audio-fcft0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mdab0.mp4: shape (149, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mdab0.wav: shape (149, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mdab0.mp4: shape torch.Size([1, 1, 149, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mdab0.wav: shape torch.Size([1, 104, 149])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([149, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mstk0.mp4: shape (93, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mstk0.wav: shape (93, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mstk0.mp4: shape torch.Size([1, 1, 93, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mstk0.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-video-mstk0.mp4: shape (69, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-audio-mstk0.wav: shape (69, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-video-mstk0.mp4: shape torch.Size([1, 1, 69, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-audio-mstk0.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-video-fkms0.mp4: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-video-fkms0.mp4: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi: shape (138, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-audio-mrjo0.wav: shape (138, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi: shape torch.Size([1, 1, 138, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-audio-mrjo0.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi: shape (137, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-audio-fdac1.wav: shape (137, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi: shape torch.Size([1, 1, 137, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-audio-fdac1.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-audio-fram1.wav: shape (114, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-audio-fram1.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi: shape (102, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-audio-fkms0.wav: shape (102, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi: shape torch.Size([1, 1, 102, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-audio-fkms0.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-audio-msjs1.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-audio-msjs1.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi: shape (82, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-audio-fjre0.wav: shape (82, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi: shape torch.Size([1, 1, 82, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-audio-fjre0.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi: shape (104, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mwbt0.wav: shape (104, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi: shape torch.Size([1, 1, 104, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mwbt0.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjas0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjas0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi: shape (123, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-audio-fjwb0.wav: shape (123, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi: shape torch.Size([1, 1, 123, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-audio-fjwb0.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi: shape (98, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-audio-mpgl0.wav: shape (98, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi: shape torch.Size([1, 1, 98, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-audio-mpgl0.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi: shape (72, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-audio-mpgl0.wav: shape (72, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi: shape torch.Size([1, 1, 72, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-audio-mpgl0.wav: shape torch.Size([1, 104, 72])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([72, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi: shape (92, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fedw0.wav: shape (92, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi: shape torch.Size([1, 1, 92, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fedw0.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-audio-felc0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-audio-felc0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi: shape (99, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjwb0.wav: shape (99, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi: shape torch.Size([1, 1, 99, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjwb0.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi: shape (90, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-audio-mjsw0.wav: shape (90, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi: shape torch.Size([1, 1, 90, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-audio-mjsw0.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi: shape (101, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-audio-mwbt0.wav: shape (101, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi: shape torch.Size([1, 1, 101, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-audio-mwbt0.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-mstk0.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-mstk0.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-audio-fjre0.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-audio-fjre0.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-audio-mgwt0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-audio-mgwt0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi: shape (86, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-audio-mrjo0.wav: shape (86, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi: shape torch.Size([1, 1, 86, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-audio-mrjo0.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-audio-mgwt0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-audio-mgwt0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-audio-mwbt0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-audio-mwbt0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi: shape (121, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-msjs1.wav: shape (121, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi: shape torch.Size([1, 1, 121, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-msjs1.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-audio-fkms0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-audio-fkms0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi: shape (88, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-audio-fdac1.wav: shape (88, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi: shape torch.Size([1, 1, 88, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-audio-fdac1.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi: shape (125, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mgwt0.wav: shape (125, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi: shape torch.Size([1, 1, 125, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mgwt0.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-audio-mpgl0.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-audio-mpgl0.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi: shape (117, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fram1.wav: shape (117, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi: shape torch.Size([1, 1, 117, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fram1.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-audio-fdrd1.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-audio-fdrd1.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-audio-mrcz0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-audio-mrcz0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi: shape (116, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-audio-mmdm2.wav: shape (116, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi: shape torch.Size([1, 1, 116, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-audio-mmdm2.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi: shape (97, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-audio-mmdb1.wav: shape (97, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi: shape torch.Size([1, 1, 97, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-audio-mmdb1.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi: shape (155, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-audio-fjem0.wav: shape (155, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi: shape torch.Size([1, 1, 155, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-audio-fjem0.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi: shape (128, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-audio-mmdb1.wav: shape (128, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi: shape torch.Size([1, 1, 128, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-audio-mmdb1.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi: shape (95, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fdac1.wav: shape (95, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi: shape torch.Size([1, 1, 95, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fdac1.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mjar0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mjar0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-audio-mjsw0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-audio-mjsw0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi: shape (81, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-faks0.wav: shape (81, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi: shape torch.Size([1, 1, 81, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-faks0.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi: shape (182, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-audio-fjwb0.wav: shape (182, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi: shape torch.Size([1, 1, 182, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-audio-fjwb0.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-audio-fram1.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-audio-fram1.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi: shape (106, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-audio-fkms0.wav: shape (106, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi: shape torch.Size([1, 1, 106, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-audio-fkms0.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi: shape (113, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-audio-fcft0.wav: shape (112, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi: shape torch.Size([1, 1, 113, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-audio-fcft0.wav: shape torch.Size([1, 104, 113])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([113, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-audio-fcft0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-audio-fcft0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi: shape (149, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mdab0.wav: shape (149, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi: shape torch.Size([1, 1, 149, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mdab0.wav: shape torch.Size([1, 104, 149])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([149, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi: shape (93, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mstk0.wav: shape (93, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi: shape torch.Size([1, 1, 93, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mstk0.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi: shape (69, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-audio-mstk0.wav: shape (69, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi: shape torch.Size([1, 1, 69, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-audio-mstk0.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_real"
      ],
      "metadata": {
        "id": "AkbrG_-FsY5B",
        "outputId": "4e9570bf-879f-4ecc-8e2f-14c8501dc351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'si1364mrjo0': tensor([[ 0.0337, -0.1497, -0.0243,  ...,  0.2315,  0.0290,  0.1629],\n",
              "         [ 0.1824, -0.0650, -0.0055,  ..., -0.1429,  0.1406,  0.1006],\n",
              "         [ 0.1506, -0.0165,  0.0294,  ..., -0.2116,  0.1907, -0.0434],\n",
              "         ...,\n",
              "         [-0.0669,  0.0628,  0.3312,  ..., -0.1542, -0.0586, -0.0743],\n",
              "         [-0.1628,  0.0195,  0.3841,  ..., -0.0440,  0.0142, -0.0896],\n",
              "         [-0.1855,  0.0034,  0.3307,  ...,  0.1063,  0.0212, -0.1072]],\n",
              "        device='cuda:0'),\n",
              " 'si844fdac1': tensor([[ 0.0372, -0.1600, -0.0227,  ...,  0.2216,  0.0322,  0.1591],\n",
              "         [ 0.1889, -0.0792, -0.0043,  ..., -0.1479,  0.1435,  0.0944],\n",
              "         [ 0.1673, -0.0344,  0.0250,  ..., -0.2216,  0.1901, -0.0467],\n",
              "         ...,\n",
              "         [-0.0475,  0.0446,  0.3250,  ..., -0.1681, -0.0527, -0.0792],\n",
              "         [-0.1483,  0.0048,  0.3779,  ..., -0.0552,  0.0187, -0.0937],\n",
              "         [-0.1741, -0.0109,  0.3278,  ...,  0.0910,  0.0260, -0.1122]],\n",
              "        device='cuda:0'),\n",
              " 'si1360fram1': tensor([[ 0.0072, -0.1443, -0.0176,  ...,  0.2343,  0.0249,  0.1746],\n",
              "         [ 0.1128, -0.0520,  0.0250,  ..., -0.1086,  0.1449,  0.0915],\n",
              "         [ 0.0819, -0.0033,  0.0516,  ..., -0.1755,  0.2143, -0.0359],\n",
              "         ...,\n",
              "         [-0.1347,  0.0525,  0.3527,  ..., -0.1316, -0.0646, -0.0771],\n",
              "         [-0.2172,  0.0200,  0.4000,  ..., -0.0223,  0.0024, -0.0948],\n",
              "         [-0.2141,  0.0228,  0.3412,  ...,  0.1099,  0.0125, -0.1113]],\n",
              "        device='cuda:0'),\n",
              " 'sx320fkms0': tensor([[ 0.0043, -0.1467, -0.0145,  ...,  0.2350,  0.0253,  0.1789],\n",
              "         [ 0.1053, -0.0555,  0.0263,  ..., -0.1069,  0.1434,  0.0925],\n",
              "         [ 0.0755, -0.0106,  0.0526,  ..., -0.1696,  0.2176, -0.0276],\n",
              "         ...,\n",
              "         [-0.1449,  0.0434,  0.3575,  ..., -0.1262, -0.0627, -0.0716],\n",
              "         [-0.2193,  0.0163,  0.4002,  ..., -0.0195, -0.0012, -0.0921],\n",
              "         [-0.2154,  0.0206,  0.3437,  ...,  0.1059,  0.0113, -0.1087]],\n",
              "        device='cuda:0'),\n",
              " 'sx189msjs1': tensor([[ 0.0073, -0.1462, -0.0172,  ...,  0.2339,  0.0259,  0.1749],\n",
              "         [ 0.1164, -0.0526,  0.0255,  ..., -0.1054,  0.1460,  0.0934],\n",
              "         [ 0.0841, -0.0058,  0.0518,  ..., -0.1719,  0.2144, -0.0297],\n",
              "         ...,\n",
              "         [-0.1339,  0.0520,  0.3575,  ..., -0.1268, -0.0617, -0.0753],\n",
              "         [-0.2142,  0.0194,  0.4013,  ..., -0.0187,  0.0036, -0.0943],\n",
              "         [-0.2130,  0.0214,  0.3415,  ...,  0.1103,  0.0151, -0.1123]],\n",
              "        device='cuda:0'),\n",
              " 'sx216fjre0': tensor([[-0.0231, -0.1300, -0.0133,  ...,  0.2515,  0.0321,  0.1874],\n",
              "         [ 0.0805, -0.0770,  0.0007,  ..., -0.1145,  0.1688,  0.1001],\n",
              "         [ 0.0564, -0.0450,  0.0237,  ..., -0.1578,  0.2528, -0.0095],\n",
              "         ...,\n",
              "         [-0.1780,  0.0075,  0.3169,  ..., -0.1198, -0.0118, -0.0391],\n",
              "         [-0.2610, -0.0017,  0.3806,  ..., -0.0011,  0.0166, -0.0714],\n",
              "         [-0.2458,  0.0212,  0.3312,  ...,  0.1370,  0.0110, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mwbt0': tensor([[ 0.0039, -0.1435, -0.0142,  ...,  0.2401,  0.0269,  0.1794],\n",
              "         [ 0.1137, -0.0542,  0.0234,  ..., -0.1071,  0.1480,  0.0953],\n",
              "         [ 0.0819, -0.0101,  0.0506,  ..., -0.1676,  0.2249, -0.0256],\n",
              "         ...,\n",
              "         [-0.1467,  0.0447,  0.3564,  ..., -0.1232, -0.0552, -0.0701],\n",
              "         [-0.2228,  0.0163,  0.3984,  ..., -0.0144,  0.0051, -0.0914],\n",
              "         [-0.2210,  0.0221,  0.3417,  ...,  0.1137,  0.0125, -0.1075]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjas0': tensor([[-0.0228, -0.1282, -0.0134,  ...,  0.2526,  0.0328,  0.1881],\n",
              "         [ 0.0863, -0.0750,  0.0033,  ..., -0.1139,  0.1672,  0.1024],\n",
              "         [ 0.0622, -0.0422,  0.0269,  ..., -0.1575,  0.2518, -0.0062],\n",
              "         ...,\n",
              "         [-0.1783,  0.0096,  0.3180,  ..., -0.1156, -0.0099, -0.0376],\n",
              "         [-0.2621,  0.0028,  0.3819,  ...,  0.0036,  0.0165, -0.0723],\n",
              "         [-0.2488,  0.0257,  0.3320,  ...,  0.1455,  0.0125, -0.0875]],\n",
              "        device='cuda:0'),\n",
              " 'si1265fjwb0': tensor([[ 0.0141, -0.1428, -0.0217,  ...,  0.2342,  0.0244,  0.1698],\n",
              "         [ 0.1297, -0.0460,  0.0175,  ..., -0.1117,  0.1411,  0.0958],\n",
              "         [ 0.0944,  0.0059,  0.0498,  ..., -0.1780,  0.2037, -0.0392],\n",
              "         ...,\n",
              "         [-0.1180,  0.0671,  0.3516,  ..., -0.1309, -0.0684, -0.0763],\n",
              "         [-0.2057,  0.0284,  0.4017,  ..., -0.0255,  0.0017, -0.0923],\n",
              "         [-0.2078,  0.0242,  0.3402,  ...,  0.1092,  0.0144, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx289mpgl0': tensor([[ 0.0091, -0.1472, -0.0139,  ...,  0.2412,  0.0297,  0.1820],\n",
              "         [ 0.1253, -0.0425,  0.0244,  ..., -0.0961,  0.1475,  0.1031],\n",
              "         [ 0.0838,  0.0024,  0.0587,  ..., -0.1476,  0.2263, -0.0181],\n",
              "         ...,\n",
              "         [-0.1254,  0.0581,  0.3635,  ..., -0.1057, -0.0637, -0.0620],\n",
              "         [-0.2037,  0.0297,  0.4090,  ..., -0.0036,  0.0025, -0.0869],\n",
              "         [-0.2093,  0.0301,  0.3528,  ...,  0.1138,  0.0200, -0.1104]],\n",
              "        device='cuda:0'),\n",
              " 'si1099mpgl0': tensor([[-0.0186, -0.1369, -0.0121,  ...,  0.2543,  0.0388,  0.1961],\n",
              "         [ 0.0951, -0.0746, -0.0009,  ..., -0.1204,  0.1830,  0.1259],\n",
              "         [ 0.0627, -0.0512,  0.0245,  ..., -0.1554,  0.2666,  0.0121],\n",
              "         ...,\n",
              "         [-0.1634,  0.0064,  0.3123,  ..., -0.1153, -0.0189, -0.0218],\n",
              "         [-0.2512,  0.0022,  0.3781,  ..., -0.0008,  0.0212, -0.0631],\n",
              "         [-0.2526,  0.0166,  0.3380,  ...,  0.1396,  0.0252, -0.0845]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fedw0': tensor([[-0.0159, -0.1243, -0.0121,  ...,  0.2576,  0.0311,  0.1828],\n",
              "         [ 0.0940, -0.0663,  0.0100,  ..., -0.1000,  0.1616,  0.0936],\n",
              "         [ 0.0694, -0.0253,  0.0391,  ..., -0.1477,  0.2515, -0.0189],\n",
              "         ...,\n",
              "         [-0.1754,  0.0226,  0.3289,  ..., -0.1140, -0.0240, -0.0498],\n",
              "         [-0.2544,  0.0087,  0.3896,  ...,  0.0032,  0.0102, -0.0778],\n",
              "         [-0.2409,  0.0304,  0.3369,  ...,  0.1420,  0.0090, -0.0946]],\n",
              "        device='cuda:0'),\n",
              " 'sx306felc0': tensor([[-0.0230, -0.1318, -0.0134,  ...,  0.2511,  0.0324,  0.1886],\n",
              "         [ 0.0821, -0.0792,  0.0004,  ..., -0.1165,  0.1715,  0.1039],\n",
              "         [ 0.0571, -0.0495,  0.0221,  ..., -0.1593,  0.2543, -0.0052],\n",
              "         ...,\n",
              "         [-0.1783,  0.0068,  0.3163,  ..., -0.1184, -0.0096, -0.0371],\n",
              "         [-0.2611, -0.0022,  0.3793,  ..., -0.0020,  0.0187, -0.0710],\n",
              "         [-0.2485,  0.0195,  0.3311,  ...,  0.1379,  0.0142, -0.0877]],\n",
              "        device='cuda:0'),\n",
              " 'sx223faks0': tensor([[-0.0198, -0.1216, -0.0138,  ...,  0.2569,  0.0346,  0.1875],\n",
              "         [ 0.0946, -0.0660,  0.0030,  ..., -0.1066,  0.1677,  0.0958],\n",
              "         [ 0.0709, -0.0275,  0.0338,  ..., -0.1508,  0.2570, -0.0169],\n",
              "         ...,\n",
              "         [-0.1764,  0.0195,  0.3217,  ..., -0.1083, -0.0122, -0.0469],\n",
              "         [-0.2584,  0.0097,  0.3857,  ...,  0.0078,  0.0144, -0.0763],\n",
              "         [-0.2453,  0.0337,  0.3332,  ...,  0.1524,  0.0100, -0.0880]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjwb0': tensor([[ 0.0014, -0.1457, -0.0121,  ...,  0.2378,  0.0261,  0.1801],\n",
              "         [ 0.1052, -0.0560,  0.0262,  ..., -0.1053,  0.1472,  0.0952],\n",
              "         [ 0.0755, -0.0118,  0.0525,  ..., -0.1633,  0.2234, -0.0224],\n",
              "         ...,\n",
              "         [-0.1497,  0.0418,  0.3587,  ..., -0.1237, -0.0549, -0.0682],\n",
              "         [-0.2238,  0.0164,  0.4016,  ..., -0.0134,  0.0036, -0.0915],\n",
              "         [-0.2197,  0.0221,  0.3468,  ...,  0.1102,  0.0137, -0.1092]],\n",
              "        device='cuda:0'),\n",
              " 'sx200mjsw0': tensor([[-2.0566e-02, -1.2432e-01, -1.3577e-02,  ...,  2.5526e-01,\n",
              "           2.9607e-02,  1.8338e-01],\n",
              "         [ 8.5371e-02, -7.2390e-02,  8.2970e-03,  ..., -1.0220e-01,\n",
              "           1.6294e-01,  9.3353e-02],\n",
              "         [ 6.5961e-02, -3.3431e-02,  3.3400e-02,  ..., -1.5043e-01,\n",
              "           2.4809e-01, -1.6579e-02],\n",
              "         ...,\n",
              "         [-1.7590e-01,  1.7300e-02,  3.2030e-01,  ..., -1.2037e-01,\n",
              "          -1.7848e-02, -4.6448e-02],\n",
              "         [-2.5933e-01,  5.5850e-03,  3.8638e-01,  ...,  1.4496e-04,\n",
              "           1.0303e-02, -7.5431e-02],\n",
              "         [-2.4106e-01,  3.0342e-02,  3.3469e-01,  ...,  1.4170e-01,\n",
              "           7.1860e-03, -9.2562e-02]], device='cuda:0'),\n",
              " 'sx23mwbt0': tensor([[ 0.0025, -0.1439, -0.0123,  ...,  0.2402,  0.0273,  0.1814],\n",
              "         [ 0.1076, -0.0529,  0.0255,  ..., -0.1038,  0.1501,  0.0953],\n",
              "         [ 0.0778, -0.0080,  0.0524,  ..., -0.1622,  0.2277, -0.0226],\n",
              "         ...,\n",
              "         [-0.1494,  0.0452,  0.3583,  ..., -0.1193, -0.0559, -0.0675],\n",
              "         [-0.2243,  0.0191,  0.4006,  ..., -0.0101,  0.0037, -0.0907],\n",
              "         [-0.2220,  0.0256,  0.3449,  ...,  0.1151,  0.0124, -0.1069]],\n",
              "        device='cuda:0'),\n",
              " 'sa2mstk0': tensor([[-0.0211, -0.1248, -0.0130,  ...,  0.2558,  0.0336,  0.1869],\n",
              "         [ 0.0907, -0.0702,  0.0030,  ..., -0.1069,  0.1693,  0.0951],\n",
              "         [ 0.0679, -0.0337,  0.0314,  ..., -0.1502,  0.2568, -0.0152],\n",
              "         ...,\n",
              "         [-0.1768,  0.0129,  0.3190,  ..., -0.1128, -0.0107, -0.0433],\n",
              "         [-0.2592,  0.0036,  0.3837,  ...,  0.0052,  0.0164, -0.0740],\n",
              "         [-0.2457,  0.0303,  0.3320,  ...,  0.1474,  0.0099, -0.0883]],\n",
              "        device='cuda:0'),\n",
              " 'si1116fjre0': tensor([[-2.2373e-02, -1.2633e-01, -1.4098e-02,  ...,  2.5344e-01,\n",
              "           3.2464e-02,  1.8662e-01],\n",
              "         [ 8.4849e-02, -7.4590e-02,  1.6153e-03,  ..., -1.1096e-01,\n",
              "           1.6800e-01,  9.7663e-02],\n",
              "         [ 6.1451e-02, -4.0138e-02,  2.6897e-02,  ..., -1.5533e-01,\n",
              "           2.5327e-01, -1.1467e-02],\n",
              "         ...,\n",
              "         [-1.7874e-01,  1.2468e-02,  3.1842e-01,  ..., -1.1770e-01,\n",
              "          -9.5204e-03, -4.1744e-02],\n",
              "         [-2.6057e-01,  2.8049e-03,  3.8228e-01,  ..., -1.7838e-04,\n",
              "           1.6679e-02, -7.1759e-02],\n",
              "         [-2.4418e-01,  2.4986e-02,  3.3159e-01,  ...,  1.4010e-01,\n",
              "           1.0695e-02, -8.9632e-02]], device='cuda:0'),\n",
              " 'sx9mgwt0': tensor([[-0.0214, -0.1309, -0.0114,  ...,  0.2514,  0.0360,  0.1900],\n",
              "         [ 0.0898, -0.0733,  0.0032,  ..., -0.1140,  0.1782,  0.1056],\n",
              "         [ 0.0645, -0.0435,  0.0266,  ..., -0.1557,  0.2635, -0.0037],\n",
              "         ...,\n",
              "         [-0.1762,  0.0087,  0.3198,  ..., -0.1089, -0.0044, -0.0383],\n",
              "         [-0.2592,  0.0020,  0.3801,  ...,  0.0061,  0.0232, -0.0721],\n",
              "         [-0.2493,  0.0244,  0.3318,  ...,  0.1488,  0.0175, -0.0859]],\n",
              "        device='cuda:0'),\n",
              " 'sx104mrjo0': tensor([[-0.0209, -0.1245, -0.0134,  ...,  0.2543,  0.0339,  0.1876],\n",
              "         [ 0.0898, -0.0705,  0.0030,  ..., -0.1103,  0.1670,  0.0977],\n",
              "         [ 0.0675, -0.0334,  0.0315,  ..., -0.1537,  0.2549, -0.0150],\n",
              "         ...,\n",
              "         [-0.1774,  0.0134,  0.3200,  ..., -0.1134, -0.0119, -0.0443],\n",
              "         [-0.2589,  0.0043,  0.3837,  ...,  0.0036,  0.0148, -0.0749],\n",
              "         [-0.2459,  0.0297,  0.3325,  ...,  0.1470,  0.0103, -0.0886]],\n",
              "        device='cuda:0'),\n",
              " 'si2169mgwt0': tensor([[ 0.0336, -0.1531, -0.0254,  ...,  0.2263,  0.0281,  0.1603],\n",
              "         [ 0.1838, -0.0674, -0.0029,  ..., -0.1395,  0.1383,  0.0999],\n",
              "         [ 0.1569, -0.0172,  0.0318,  ..., -0.2119,  0.1815, -0.0405],\n",
              "         ...,\n",
              "         [-0.0598,  0.0635,  0.3335,  ..., -0.1544, -0.0612, -0.0745],\n",
              "         [-0.1578,  0.0195,  0.3855,  ..., -0.0457,  0.0113, -0.0903],\n",
              "         [-0.1800,  0.0007,  0.3317,  ...,  0.0994,  0.0243, -0.1105]],\n",
              "        device='cuda:0'),\n",
              " 'si1553mwbt0': tensor([[ 6.1505e-02, -1.8270e-01, -2.2577e-02,  ...,  2.0218e-01,\n",
              "           4.1628e-02,  1.4101e-01],\n",
              "         [ 2.3370e-01, -1.0931e-01, -2.6595e-02,  ..., -1.7940e-01,\n",
              "           1.5029e-01,  8.2723e-02],\n",
              "         [ 2.1353e-01, -7.0665e-02,  6.1105e-03,  ..., -2.4896e-01,\n",
              "           1.8864e-01, -6.0677e-02],\n",
              "         ...,\n",
              "         [ 6.7605e-03,  2.2074e-04,  2.9472e-01,  ..., -1.9426e-01,\n",
              "          -1.9625e-02, -9.0448e-02],\n",
              "         [-1.0311e-01, -2.8520e-02,  3.5607e-01,  ..., -8.0391e-02,\n",
              "           3.5491e-02, -1.0273e-01],\n",
              "         [-1.3965e-01, -5.1976e-02,  3.1431e-01,  ...,  6.6258e-02,\n",
              "           4.4224e-02, -1.2452e-01]], device='cuda:0'),\n",
              " 'sa2msjs1': tensor([[ 1.4235e-02, -1.4513e-01, -2.1532e-02,  ...,  2.3095e-01,\n",
              "           2.5181e-02,  1.6905e-01],\n",
              "         [ 1.2928e-01, -4.6622e-02,  1.9454e-02,  ..., -1.0818e-01,\n",
              "           1.4347e-01,  9.6025e-02],\n",
              "         [ 9.5176e-02,  6.3880e-03,  5.1152e-02,  ..., -1.7624e-01,\n",
              "           2.0259e-01, -3.6020e-02],\n",
              "         ...,\n",
              "         [-1.1317e-01,  7.3411e-02,  3.5462e-01,  ..., -1.2877e-01,\n",
              "          -7.1437e-02, -7.5461e-02],\n",
              "         [-2.0168e-01,  3.3741e-02,  4.0441e-01,  ..., -2.5533e-02,\n",
              "           3.2468e-04, -9.1011e-02],\n",
              "         [-2.0372e-01,  2.4952e-02,  3.4008e-01,  ...,  1.0835e-01,\n",
              "           1.7668e-02, -1.1255e-01]], device='cuda:0'),\n",
              " 'sx230fkms0': tensor([[ 0.0099, -0.1432, -0.0189,  ...,  0.2350,  0.0241,  0.1734],\n",
              "         [ 0.1157, -0.0471,  0.0227,  ..., -0.1075,  0.1401,  0.0927],\n",
              "         [ 0.0787,  0.0032,  0.0529,  ..., -0.1737,  0.2096, -0.0391],\n",
              "         ...,\n",
              "         [-0.1323,  0.0580,  0.3581,  ..., -0.1272, -0.0680, -0.0772],\n",
              "         [-0.2130,  0.0245,  0.4033,  ..., -0.0235, -0.0026, -0.0933],\n",
              "         [-0.2112,  0.0247,  0.3416,  ...,  0.1081,  0.0125, -0.1114]],\n",
              "        device='cuda:0'),\n",
              " 'si1474fdac1': tensor([[-0.0223, -0.1241, -0.0143,  ...,  0.2549,  0.0315,  0.1851],\n",
              "         [ 0.0852, -0.0735,  0.0039,  ..., -0.1076,  0.1661,  0.0936],\n",
              "         [ 0.0636, -0.0357,  0.0295,  ..., -0.1536,  0.2516, -0.0161],\n",
              "         ...,\n",
              "         [-0.1792,  0.0141,  0.3181,  ..., -0.1202, -0.0127, -0.0437],\n",
              "         [-0.2618,  0.0035,  0.3835,  ...,  0.0013,  0.0143, -0.0738],\n",
              "         [-0.2431,  0.0288,  0.3322,  ...,  0.1423,  0.0074, -0.0901]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mgwt0': tensor([[ 0.0157, -0.1426, -0.0225,  ...,  0.2340,  0.0251,  0.1705],\n",
              "         [ 0.1358, -0.0458,  0.0164,  ..., -0.1124,  0.1431,  0.0963],\n",
              "         [ 0.1002,  0.0073,  0.0487,  ..., -0.1790,  0.2041, -0.0384],\n",
              "         ...,\n",
              "         [-0.1153,  0.0727,  0.3511,  ..., -0.1286, -0.0679, -0.0758],\n",
              "         [-0.2035,  0.0304,  0.3997,  ..., -0.0248,  0.0038, -0.0912],\n",
              "         [-0.2067,  0.0258,  0.3377,  ...,  0.1121,  0.0160, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx140fkms0': tensor([[ 0.0077, -0.1453, -0.0176,  ...,  0.2353,  0.0241,  0.1758],\n",
              "         [ 0.1138, -0.0524,  0.0235,  ..., -0.1104,  0.1378,  0.0935],\n",
              "         [ 0.0793, -0.0042,  0.0529,  ..., -0.1748,  0.2106, -0.0350],\n",
              "         ...,\n",
              "         [-0.1374,  0.0492,  0.3580,  ..., -0.1281, -0.0658, -0.0750],\n",
              "         [-0.2139,  0.0186,  0.4009,  ..., -0.0234, -0.0023, -0.0930],\n",
              "         [-0.2123,  0.0201,  0.3418,  ...,  0.1057,  0.0116, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx109mpgl0': tensor([[ 0.0125, -0.1453, -0.0172,  ...,  0.2368,  0.0287,  0.1775],\n",
              "         [ 0.1243, -0.0357,  0.0251,  ..., -0.0919,  0.1434,  0.1002],\n",
              "         [ 0.0819,  0.0137,  0.0616,  ..., -0.1489,  0.2137, -0.0226],\n",
              "         ...,\n",
              "         [-0.1216,  0.0779,  0.3657,  ..., -0.1059, -0.0737, -0.0661],\n",
              "         [-0.2051,  0.0424,  0.4145,  ..., -0.0041, -0.0017, -0.0865],\n",
              "         [-0.2074,  0.0359,  0.3505,  ...,  0.1167,  0.0193, -0.1128]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fram1': tensor([[ 0.0096, -0.1445, -0.0188,  ...,  0.2341,  0.0255,  0.1731],\n",
              "         [ 0.1209, -0.0516,  0.0236,  ..., -0.1100,  0.1445,  0.0923],\n",
              "         [ 0.0881, -0.0040,  0.0508,  ..., -0.1765,  0.2108, -0.0340],\n",
              "         ...,\n",
              "         [-0.1282,  0.0568,  0.3528,  ..., -0.1327, -0.0645, -0.0769],\n",
              "         [-0.2121,  0.0227,  0.4002,  ..., -0.0256,  0.0025, -0.0935],\n",
              "         [-0.2117,  0.0225,  0.3407,  ...,  0.1086,  0.0131, -0.1112]],\n",
              "        device='cuda:0'),\n",
              " 'si1544fdrd1': tensor([[-0.0228, -0.1244, -0.0136,  ...,  0.2544,  0.0333,  0.1861],\n",
              "         [ 0.0877, -0.0725,  0.0032,  ..., -0.1052,  0.1718,  0.0950],\n",
              "         [ 0.0657, -0.0362,  0.0284,  ..., -0.1505,  0.2579, -0.0136],\n",
              "         ...,\n",
              "         [-0.1788,  0.0141,  0.3192,  ..., -0.1124, -0.0072, -0.0425],\n",
              "         [-0.2622,  0.0046,  0.3836,  ...,  0.0074,  0.0181, -0.0730],\n",
              "         [-0.2453,  0.0315,  0.3318,  ...,  0.1485,  0.0100, -0.0877]],\n",
              "        device='cuda:0'),\n",
              " 'sx281mrcz0': tensor([[ 0.0108, -0.1414, -0.0185,  ...,  0.2367,  0.0239,  0.1747],\n",
              "         [ 0.1197, -0.0464,  0.0243,  ..., -0.1049,  0.1416,  0.0954],\n",
              "         [ 0.0828,  0.0042,  0.0540,  ..., -0.1708,  0.2113, -0.0317],\n",
              "         ...,\n",
              "         [-0.1299,  0.0612,  0.3583,  ..., -0.1256, -0.0695, -0.0740],\n",
              "         [-0.2127,  0.0282,  0.4048,  ..., -0.0185, -0.0025, -0.0921],\n",
              "         [-0.2130,  0.0293,  0.3430,  ...,  0.1139,  0.0109, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx102mmdm2': tensor([[ 0.0099, -0.1444, -0.0191,  ...,  0.2345,  0.0243,  0.1732],\n",
              "         [ 0.1206, -0.0480,  0.0227,  ..., -0.1083,  0.1412,  0.0937],\n",
              "         [ 0.0851,  0.0026,  0.0520,  ..., -0.1747,  0.2084, -0.0363],\n",
              "         ...,\n",
              "         [-0.1286,  0.0593,  0.3556,  ..., -0.1282, -0.0657, -0.0769],\n",
              "         [-0.2117,  0.0249,  0.4013,  ..., -0.0229,  0.0014, -0.0929],\n",
              "         [-0.2112,  0.0226,  0.3404,  ...,  0.1090,  0.0144, -0.1116]],\n",
              "        device='cuda:0'),\n",
              " 'sx185mmdb1': tensor([[-0.0008, -0.1455, -0.0117,  ...,  0.2385,  0.0272,  0.1809],\n",
              "         [ 0.1028, -0.0586,  0.0260,  ..., -0.1037,  0.1539,  0.0951],\n",
              "         [ 0.0756, -0.0155,  0.0496,  ..., -0.1623,  0.2313, -0.0202],\n",
              "         ...,\n",
              "         [-0.1540,  0.0379,  0.3549,  ..., -0.1217, -0.0499, -0.0673],\n",
              "         [-0.2266,  0.0131,  0.3980,  ..., -0.0109,  0.0073, -0.0911],\n",
              "         [-0.2216,  0.0204,  0.3448,  ...,  0.1126,  0.0151, -0.1079]],\n",
              "        device='cuda:0'),\n",
              " 'sx184fjem0': tensor([[ 0.0627, -0.1800, -0.0228,  ...,  0.2009,  0.0405,  0.1383],\n",
              "         [ 0.2294, -0.1084, -0.0298,  ..., -0.1753,  0.1510,  0.0822],\n",
              "         [ 0.2121, -0.0680,  0.0026,  ..., -0.2462,  0.1867, -0.0631],\n",
              "         ...,\n",
              "         [ 0.0105, -0.0010,  0.2849,  ..., -0.1989, -0.0188, -0.0953],\n",
              "         [-0.1019, -0.0282,  0.3538,  ..., -0.0850,  0.0350, -0.1082],\n",
              "         [-0.1363, -0.0527,  0.3155,  ...,  0.0635,  0.0465, -0.1290]],\n",
              "        device='cuda:0'),\n",
              " 'sx365mmdb1': tensor([[ 0.0189, -0.1429, -0.0273,  ...,  0.2287,  0.0198,  0.1659],\n",
              "         [ 0.1387, -0.0433,  0.0144,  ..., -0.1126,  0.1343,  0.0973],\n",
              "         [ 0.1041,  0.0092,  0.0482,  ..., -0.1829,  0.1884, -0.0393],\n",
              "         ...,\n",
              "         [-0.1017,  0.0791,  0.3475,  ..., -0.1311, -0.0814, -0.0719],\n",
              "         [-0.1917,  0.0361,  0.4035,  ..., -0.0290, -0.0074, -0.0912],\n",
              "         [-0.1993,  0.0261,  0.3404,  ...,  0.1044,  0.0148, -0.1118]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fdac1': tensor([[-0.0096, -0.1351, -0.0107,  ...,  0.2502,  0.0263,  0.1819],\n",
              "         [ 0.0917, -0.0663,  0.0195,  ..., -0.1041,  0.1569,  0.0924],\n",
              "         [ 0.0691, -0.0242,  0.0439,  ..., -0.1581,  0.2405, -0.0214],\n",
              "         ...,\n",
              "         [-0.1706,  0.0274,  0.3375,  ..., -0.1245, -0.0385, -0.0582],\n",
              "         [-0.2457,  0.0081,  0.3919,  ..., -0.0069,  0.0091, -0.0836],\n",
              "         [-0.2371,  0.0232,  0.3402,  ...,  0.1232,  0.0100, -0.1003]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mjar0': tensor([[ 0.0532, -0.1684, -0.0249,  ...,  0.2132,  0.0353,  0.1472],\n",
              "         [ 0.2159, -0.0904, -0.0206,  ..., -0.1643,  0.1445,  0.0897],\n",
              "         [ 0.1917, -0.0461,  0.0133,  ..., -0.2360,  0.1837, -0.0566],\n",
              "         ...,\n",
              "         [-0.0119,  0.0267,  0.3048,  ..., -0.1833, -0.0404, -0.0861],\n",
              "         [-0.1189, -0.0074,  0.3655,  ..., -0.0693,  0.0234, -0.0999],\n",
              "         [-0.1514, -0.0314,  0.3202,  ...,  0.0800,  0.0357, -0.1196]],\n",
              "        device='cuda:0'),\n",
              " 'sa1faks0': tensor([[-0.0211, -0.1240, -0.0142,  ...,  0.2552,  0.0333,  0.1860],\n",
              "         [ 0.0910, -0.0726,  0.0039,  ..., -0.1054,  0.1680,  0.0934],\n",
              "         [ 0.0694, -0.0339,  0.0302,  ..., -0.1517,  0.2542, -0.0162],\n",
              "         ...,\n",
              "         [-0.1796,  0.0163,  0.3204,  ..., -0.1158, -0.0099, -0.0448],\n",
              "         [-0.2614,  0.0051,  0.3837,  ...,  0.0039,  0.0168, -0.0745],\n",
              "         [-0.2445,  0.0309,  0.3306,  ...,  0.1469,  0.0087, -0.0886]],\n",
              "        device='cuda:0'),\n",
              " 'sx110mjsw0': tensor([[-0.0230, -0.1272, -0.0126,  ...,  0.2527,  0.0312,  0.1872],\n",
              "         [ 0.0824, -0.0747,  0.0043,  ..., -0.1114,  0.1686,  0.1000],\n",
              "         [ 0.0599, -0.0402,  0.0278,  ..., -0.1552,  0.2525, -0.0095],\n",
              "         ...,\n",
              "         [-0.1771,  0.0112,  0.3174,  ..., -0.1171, -0.0092, -0.0384],\n",
              "         [-0.2614,  0.0028,  0.3823,  ...,  0.0014,  0.0166, -0.0713],\n",
              "         [-0.2464,  0.0251,  0.3335,  ...,  0.1426,  0.0131, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa2faks0': tensor([[-2.2797e-02, -1.3038e-01, -1.4583e-02,  ...,  2.5046e-01,\n",
              "           3.3861e-02,  1.9000e-01],\n",
              "         [ 8.7162e-02, -7.9114e-02, -2.3932e-03,  ..., -1.1778e-01,\n",
              "           1.7294e-01,  1.0336e-01],\n",
              "         [ 6.2019e-02, -4.9000e-02,  1.9768e-02,  ..., -1.5948e-01,\n",
              "           2.5668e-01, -5.8069e-03],\n",
              "         ...,\n",
              "         [-1.8025e-01,  6.4512e-03,  3.1554e-01,  ..., -1.1420e-01,\n",
              "          -1.4576e-03, -3.9848e-02],\n",
              "         [-2.6216e-01, -2.3430e-03,  3.7725e-01,  ...,  3.1153e-04,\n",
              "           2.3854e-02, -7.2195e-02],\n",
              "         [-2.5041e-01,  2.1052e-02,  3.2726e-01,  ...,  1.4220e-01,\n",
              "           1.5340e-02, -8.4601e-02]], device='cuda:0'),\n",
              " 'si992fjwb0': tensor([[ 0.1106, -0.2704, -0.0029,  ...,  0.1403,  0.0545,  0.0792],\n",
              "         [ 0.2836, -0.2338, -0.0565,  ..., -0.2338,  0.1671,  0.0300],\n",
              "         [ 0.2622, -0.2131, -0.0345,  ..., -0.2746,  0.2050, -0.1089],\n",
              "         ...,\n",
              "         [ 0.0525, -0.1699,  0.1857,  ..., -0.2776,  0.0535, -0.1642],\n",
              "         [-0.0541, -0.1844,  0.2951,  ..., -0.1654,  0.0956, -0.1783],\n",
              "         [-0.0763, -0.1990,  0.3075,  ...,  0.0047,  0.0933, -0.1868]],\n",
              "        device='cuda:0'),\n",
              " 'sx280fram1': tensor([[-0.0245, -0.1269, -0.0143,  ...,  0.2529,  0.0314,  0.1862],\n",
              "         [ 0.0812, -0.0773,  0.0037,  ..., -0.1113,  0.1689,  0.0971],\n",
              "         [ 0.0591, -0.0439,  0.0255,  ..., -0.1558,  0.2508, -0.0092],\n",
              "         ...,\n",
              "         [-0.1792,  0.0124,  0.3177,  ..., -0.1220, -0.0104, -0.0404],\n",
              "         [-0.2623,  0.0022,  0.3823,  ..., -0.0024,  0.0153, -0.0712],\n",
              "         [-0.2448,  0.0259,  0.3310,  ...,  0.1388,  0.0093, -0.0890]],\n",
              "        device='cuda:0'),\n",
              " 'si2120fkms0': tensor([[ 0.0054, -0.1454, -0.0156,  ...,  0.2354,  0.0253,  0.1782],\n",
              "         [ 0.1074, -0.0538,  0.0252,  ..., -0.1072,  0.1432,  0.0924],\n",
              "         [ 0.0770, -0.0072,  0.0515,  ..., -0.1712,  0.2175, -0.0318],\n",
              "         ...,\n",
              "         [-0.1448,  0.0452,  0.3572,  ..., -0.1270, -0.0615, -0.0736],\n",
              "         [-0.2198,  0.0166,  0.4000,  ..., -0.0196,  0.0007, -0.0936],\n",
              "         [-0.2160,  0.0224,  0.3418,  ...,  0.1089,  0.0110, -0.1090]],\n",
              "        device='cuda:0'),\n",
              " 'si1808fcft0': tensor([[ 0.0073, -0.1452, -0.0176,  ...,  0.2340,  0.0252,  0.1749],\n",
              "         [ 0.1147, -0.0546,  0.0241,  ..., -0.1093,  0.1452,  0.0916],\n",
              "         [ 0.0851, -0.0077,  0.0499,  ..., -0.1764,  0.2149, -0.0355],\n",
              "         ...,\n",
              "         [-0.1363,  0.0507,  0.3540,  ..., -0.1306, -0.0620, -0.0764],\n",
              "         [-0.2164,  0.0180,  0.3983,  ..., -0.0218,  0.0038, -0.0939],\n",
              "         [-0.2141,  0.0207,  0.3396,  ...,  0.1078,  0.0122, -0.1108]],\n",
              "        device='cuda:0'),\n",
              " 'si1178fcft0': tensor([[ 3.6749e-02, -1.5935e-01, -2.1553e-02,  ...,  2.2148e-01,\n",
              "           3.0667e-02,  1.6090e-01],\n",
              "         [ 1.8511e-01, -8.0462e-02,  7.8195e-05,  ..., -1.4571e-01,\n",
              "           1.4074e-01,  9.4329e-02],\n",
              "         [ 1.6743e-01, -3.5364e-02,  2.7424e-02,  ..., -2.2293e-01,\n",
              "           1.8783e-01, -4.5636e-02],\n",
              "         ...,\n",
              "         [-5.2479e-02,  4.4527e-02,  3.2721e-01,  ..., -1.6802e-01,\n",
              "          -5.3071e-02, -7.9380e-02],\n",
              "         [-1.5103e-01,  4.8072e-03,  3.7890e-01,  ..., -5.5657e-02,\n",
              "           1.8111e-02, -9.3312e-02],\n",
              "         [-1.7642e-01, -9.1262e-03,  3.2792e-01,  ...,  9.2908e-02,\n",
              "           2.3915e-02, -1.1017e-01]], device='cuda:0'),\n",
              " 'sa1mdab0': tensor([[ 0.0612, -0.1850, -0.0193,  ...,  0.2024,  0.0413,  0.1423],\n",
              "         [ 0.2303, -0.1170, -0.0235,  ..., -0.1787,  0.1497,  0.0797],\n",
              "         [ 0.2144, -0.0805,  0.0057,  ..., -0.2491,  0.1912, -0.0640],\n",
              "         ...,\n",
              "         [ 0.0039, -0.0100,  0.2945,  ..., -0.1990, -0.0182, -0.0910],\n",
              "         [-0.1054, -0.0354,  0.3551,  ..., -0.0832,  0.0373, -0.1030],\n",
              "         [-0.1422, -0.0545,  0.3141,  ...,  0.0671,  0.0413, -0.1223]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mstk0': tensor([[-0.0148, -0.1270, -0.0115,  ...,  0.2550,  0.0294,  0.1838],\n",
              "         [ 0.0945, -0.0673,  0.0117,  ..., -0.1015,  0.1606,  0.0923],\n",
              "         [ 0.0725, -0.0254,  0.0402,  ..., -0.1516,  0.2492, -0.0209],\n",
              "         ...,\n",
              "         [-0.1737,  0.0220,  0.3287,  ..., -0.1149, -0.0252, -0.0524],\n",
              "         [-0.2525,  0.0080,  0.3890,  ...,  0.0017,  0.0114, -0.0795],\n",
              "         [-0.2423,  0.0296,  0.3361,  ...,  0.1401,  0.0086, -0.0935]],\n",
              "        device='cuda:0'),\n",
              " 'si2284mstk0': tensor([[-0.0221, -0.1369, -0.0167,  ...,  0.2465,  0.0372,  0.1958],\n",
              "         [ 0.0826, -0.0840, -0.0174,  ..., -0.1343,  0.1787,  0.1211],\n",
              "         [ 0.0510, -0.0636,  0.0007,  ..., -0.1726,  0.2626,  0.0089],\n",
              "         ...,\n",
              "         [-0.1771, -0.0130,  0.3044,  ..., -0.1168,  0.0019, -0.0271],\n",
              "         [-0.2629, -0.0142,  0.3658,  ..., -0.0056,  0.0308, -0.0659],\n",
              "         [-0.2576,  0.0076,  0.3243,  ...,  0.1383,  0.0224, -0.0805]],\n",
              "        device='cuda:0'),\n",
              " 'sx50fkms0': tensor([[ 0.0080, -0.1466, -0.0177,  ...,  0.2326,  0.0248,  0.1749],\n",
              "         [ 0.1131, -0.0524,  0.0254,  ..., -0.1085,  0.1394,  0.0936],\n",
              "         [ 0.0793, -0.0036,  0.0533,  ..., -0.1747,  0.2085, -0.0322],\n",
              "         ...,\n",
              "         [-0.1352,  0.0526,  0.3588,  ..., -0.1280, -0.0657, -0.0756],\n",
              "         [-0.2123,  0.0204,  0.4024,  ..., -0.0239, -0.0013, -0.0933],\n",
              "         [-0.2105,  0.0205,  0.3413,  ...,  0.1054,  0.0132, -0.1110]],\n",
              "        device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_deep"
      ],
      "metadata": {
        "id": "X6xDeKtVscGP",
        "outputId": "8bc846d7-5fd9-43af-d6ef-756bb3406569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'si1364mrjo0': tensor([[ 0.0321, -0.1495, -0.0234,  ...,  0.2316,  0.0286,  0.1641],\n",
              "         [ 0.1767, -0.0651, -0.0033,  ..., -0.1411,  0.1404,  0.0989],\n",
              "         [ 0.1460, -0.0175,  0.0306,  ..., -0.2103,  0.1939, -0.0450],\n",
              "         ...,\n",
              "         [-0.0735,  0.0599,  0.3316,  ..., -0.1554, -0.0606, -0.0764],\n",
              "         [-0.1686,  0.0165,  0.3847,  ..., -0.0434,  0.0144, -0.0920],\n",
              "         [-0.1892,  0.0049,  0.3314,  ...,  0.1092,  0.0190, -0.1077]],\n",
              "        device='cuda:0'),\n",
              " 'si844fdac1': tensor([[ 0.0344, -0.1576, -0.0225,  ...,  0.2241,  0.0302,  0.1604],\n",
              "         [ 0.1824, -0.0761, -0.0015,  ..., -0.1453,  0.1417,  0.0947],\n",
              "         [ 0.1597, -0.0310,  0.0280,  ..., -0.2187,  0.1911, -0.0478],\n",
              "         ...,\n",
              "         [-0.0572,  0.0468,  0.3266,  ..., -0.1675, -0.0557, -0.0794],\n",
              "         [-0.1559,  0.0062,  0.3804,  ..., -0.0533,  0.0173, -0.0945],\n",
              "         [-0.1803, -0.0074,  0.3302,  ...,  0.0945,  0.0230, -0.1122]],\n",
              "        device='cuda:0'),\n",
              " 'si1360fram1': tensor([[-0.0308, -0.1419, -0.0235,  ...,  0.2269,  0.0422,  0.1903],\n",
              "         [ 0.0971, -0.0689,  0.0105,  ..., -0.1291,  0.1926,  0.0746],\n",
              "         [ 0.1010, -0.0227,  0.0086,  ..., -0.2004,  0.2591, -0.0281],\n",
              "         ...,\n",
              "         [-0.1573,  0.0333,  0.3409,  ..., -0.0660, -0.0106, -0.0604],\n",
              "         [-0.2623,  0.0215,  0.3735,  ...,  0.0580,  0.0306, -0.0942],\n",
              "         [-0.2394,  0.0821,  0.3034,  ...,  0.2322,  0.0225, -0.0251]],\n",
              "        device='cuda:0'),\n",
              " 'sx320fkms0': tensor([[ 0.0033, -0.1466, -0.0141,  ...,  0.2357,  0.0249,  0.1795],\n",
              "         [ 0.1015, -0.0565,  0.0264,  ..., -0.1074,  0.1423,  0.0924],\n",
              "         [ 0.0730, -0.0114,  0.0520,  ..., -0.1699,  0.2185, -0.0294],\n",
              "         ...,\n",
              "         [-0.1478,  0.0408,  0.3555,  ..., -0.1286, -0.0634, -0.0718],\n",
              "         [-0.2213,  0.0149,  0.4005,  ..., -0.0199, -0.0023, -0.0930],\n",
              "         [-0.2178,  0.0209,  0.3446,  ...,  0.1070,  0.0110, -0.1091]],\n",
              "        device='cuda:0'),\n",
              " 'sx189msjs1': tensor([[ 0.0042, -0.1437, -0.0151,  ...,  0.2371,  0.0259,  0.1774],\n",
              "         [ 0.1066, -0.0525,  0.0262,  ..., -0.1054,  0.1465,  0.0919],\n",
              "         [ 0.0773, -0.0061,  0.0519,  ..., -0.1691,  0.2214, -0.0330],\n",
              "         ...,\n",
              "         [-0.1467,  0.0469,  0.3552,  ..., -0.1283, -0.0615, -0.0755],\n",
              "         [-0.2243,  0.0172,  0.4010,  ..., -0.0161,  0.0024, -0.0957],\n",
              "         [-0.2213,  0.0255,  0.3425,  ...,  0.1165,  0.0116, -0.1106]],\n",
              "        device='cuda:0'),\n",
              " 'sx216fjre0': tensor([[-0.0236, -0.1295, -0.0137,  ...,  0.2521,  0.0314,  0.1868],\n",
              "         [ 0.0791, -0.0777,  0.0005,  ..., -0.1153,  0.1660,  0.1001],\n",
              "         [ 0.0555, -0.0443,  0.0233,  ..., -0.1594,  0.2500, -0.0101],\n",
              "         ...,\n",
              "         [-0.1790,  0.0073,  0.3151,  ..., -0.1219, -0.0127, -0.0392],\n",
              "         [-0.2623, -0.0021,  0.3807,  ..., -0.0025,  0.0152, -0.0719],\n",
              "         [-0.2463,  0.0214,  0.3320,  ...,  0.1376,  0.0098, -0.0898]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mwbt0': tensor([[ 0.0031, -0.1445, -0.0142,  ...,  0.2392,  0.0263,  0.1791],\n",
              "         [ 0.1084, -0.0542,  0.0242,  ..., -0.1078,  0.1457,  0.0941],\n",
              "         [ 0.0775, -0.0099,  0.0515,  ..., -0.1679,  0.2235, -0.0284],\n",
              "         ...,\n",
              "         [-0.1477,  0.0425,  0.3550,  ..., -0.1259, -0.0583, -0.0712],\n",
              "         [-0.2236,  0.0154,  0.3998,  ..., -0.0153,  0.0029, -0.0936],\n",
              "         [-0.2208,  0.0217,  0.3439,  ...,  0.1126,  0.0125, -0.1097]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjas0': tensor([[-0.0230, -0.1290, -0.0131,  ...,  0.2524,  0.0320,  0.1879],\n",
              "         [ 0.0839, -0.0755,  0.0037,  ..., -0.1131,  0.1666,  0.1012],\n",
              "         [ 0.0607, -0.0419,  0.0271,  ..., -0.1571,  0.2509, -0.0081],\n",
              "         ...,\n",
              "         [-0.1770,  0.0097,  0.3169,  ..., -0.1166, -0.0121, -0.0385],\n",
              "         [-0.2614,  0.0028,  0.3825,  ...,  0.0018,  0.0150, -0.0729],\n",
              "         [-0.2487,  0.0262,  0.3330,  ...,  0.1455,  0.0117, -0.0884]],\n",
              "        device='cuda:0'),\n",
              " 'si1265fjwb0': tensor([[ 0.0138, -0.1436, -0.0218,  ...,  0.2345,  0.0243,  0.1699],\n",
              "         [ 0.1300, -0.0487,  0.0172,  ..., -0.1144,  0.1404,  0.0950],\n",
              "         [ 0.0960,  0.0017,  0.0485,  ..., -0.1810,  0.2043, -0.0406],\n",
              "         ...,\n",
              "         [-0.1192,  0.0622,  0.3496,  ..., -0.1352, -0.0676, -0.0770],\n",
              "         [-0.2061,  0.0241,  0.3997,  ..., -0.0279,  0.0023, -0.0928],\n",
              "         [-0.2087,  0.0219,  0.3392,  ...,  0.1090,  0.0135, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx289mpgl0': tensor([[ 0.0067, -0.1468, -0.0138,  ...,  0.2424,  0.0296,  0.1823],\n",
              "         [ 0.1197, -0.0448,  0.0236,  ..., -0.0981,  0.1496,  0.1020],\n",
              "         [ 0.0805, -0.0008,  0.0562,  ..., -0.1495,  0.2295, -0.0192],\n",
              "         ...,\n",
              "         [-0.1326,  0.0536,  0.3615,  ..., -0.1093, -0.0615, -0.0624],\n",
              "         [-0.2088,  0.0253,  0.4066,  ..., -0.0050,  0.0031, -0.0876],\n",
              "         [-0.2124,  0.0284,  0.3515,  ...,  0.1142,  0.0193, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'si1099mpgl0': tensor([[-0.0200, -0.1367, -0.0128,  ...,  0.2536,  0.0387,  0.1959],\n",
              "         [ 0.0926, -0.0763, -0.0027,  ..., -0.1226,  0.1849,  0.1244],\n",
              "         [ 0.0613, -0.0527,  0.0213,  ..., -0.1576,  0.2684,  0.0109],\n",
              "         ...,\n",
              "         [-0.1648,  0.0023,  0.3086,  ..., -0.1171, -0.0151, -0.0211],\n",
              "         [-0.2534, -0.0016,  0.3757,  ..., -0.0013,  0.0238, -0.0634],\n",
              "         [-0.2530,  0.0152,  0.3364,  ...,  0.1407,  0.0246, -0.0845]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fedw0': tensor([[-0.0169, -0.1245, -0.0130,  ...,  0.2566,  0.0309,  0.1835],\n",
              "         [ 0.0929, -0.0679,  0.0081,  ..., -0.1033,  0.1603,  0.0930],\n",
              "         [ 0.0704, -0.0266,  0.0370,  ..., -0.1508,  0.2497, -0.0202],\n",
              "         ...,\n",
              "         [-0.1761,  0.0210,  0.3257,  ..., -0.1154, -0.0213, -0.0500],\n",
              "         [-0.2561,  0.0078,  0.3880,  ...,  0.0029,  0.0115, -0.0780],\n",
              "         [-0.2421,  0.0300,  0.3354,  ...,  0.1433,  0.0085, -0.0936]],\n",
              "        device='cuda:0'),\n",
              " 'sx306felc0': tensor([[-0.0240, -0.1317, -0.0146,  ...,  0.2502,  0.0328,  0.1892],\n",
              "         [ 0.0806, -0.0807, -0.0024,  ..., -0.1192,  0.1713,  0.1043],\n",
              "         [ 0.0566, -0.0505,  0.0187,  ..., -0.1625,  0.2546, -0.0061],\n",
              "         ...,\n",
              "         [-0.1796,  0.0053,  0.3140,  ..., -0.1190, -0.0064, -0.0374],\n",
              "         [-0.2628, -0.0031,  0.3776,  ..., -0.0025,  0.0204, -0.0715],\n",
              "         [-0.2495,  0.0187,  0.3296,  ...,  0.1377,  0.0141, -0.0870]],\n",
              "        device='cuda:0'),\n",
              " 'sx223faks0': tensor([[-0.0200, -0.1223, -0.0142,  ...,  0.2563,  0.0337,  0.1870],\n",
              "         [ 0.0926, -0.0685,  0.0018,  ..., -0.1081,  0.1645,  0.0956],\n",
              "         [ 0.0700, -0.0290,  0.0319,  ..., -0.1528,  0.2535, -0.0179],\n",
              "         ...,\n",
              "         [-0.1771,  0.0176,  0.3188,  ..., -0.1118, -0.0135, -0.0468],\n",
              "         [-0.2602,  0.0082,  0.3849,  ...,  0.0060,  0.0134, -0.0764],\n",
              "         [-0.2459,  0.0322,  0.3324,  ...,  0.1510,  0.0090, -0.0888]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjwb0': tensor([[-0.0008, -0.1453, -0.0118,  ...,  0.2387,  0.0262,  0.1808],\n",
              "         [ 0.1013, -0.0575,  0.0264,  ..., -0.1065,  0.1495,  0.0939],\n",
              "         [ 0.0748, -0.0143,  0.0510,  ..., -0.1645,  0.2261, -0.0232],\n",
              "         ...,\n",
              "         [-0.1543,  0.0391,  0.3539,  ..., -0.1272, -0.0537, -0.0672],\n",
              "         [-0.2283,  0.0144,  0.3993,  ..., -0.0139,  0.0052, -0.0914],\n",
              "         [-0.2232,  0.0218,  0.3454,  ...,  0.1118,  0.0130, -0.1083]],\n",
              "        device='cuda:0'),\n",
              " 'sx200mjsw0': tensor([[-2.1014e-02, -1.2408e-01, -1.2605e-02,  ...,  2.5589e-01,\n",
              "           2.9466e-02,  1.8257e-01],\n",
              "         [ 8.3613e-02, -7.0768e-02,  9.0826e-03,  ..., -1.0080e-01,\n",
              "           1.6260e-01,  9.1813e-02],\n",
              "         [ 6.3595e-02, -3.2072e-02,  3.4370e-02,  ..., -1.4866e-01,\n",
              "           2.4855e-01, -1.7632e-02],\n",
              "         ...,\n",
              "         [-1.7604e-01,  1.6261e-02,  3.1865e-01,  ..., -1.2207e-01,\n",
              "          -2.0170e-02, -4.4449e-02],\n",
              "         [-2.5951e-01,  5.0842e-03,  3.8657e-01,  ...,  1.8064e-04,\n",
              "           1.0752e-02, -7.4890e-02],\n",
              "         [-2.4036e-01,  3.0519e-02,  3.3597e-01,  ...,  1.4265e-01,\n",
              "           6.8874e-03, -9.3277e-02]], device='cuda:0'),\n",
              " 'sx23mwbt0': tensor([[ 0.0023, -0.1446, -0.0126,  ...,  0.2393,  0.0263,  0.1808],\n",
              "         [ 0.1036, -0.0541,  0.0260,  ..., -0.1059,  0.1456,  0.0945],\n",
              "         [ 0.0744, -0.0090,  0.0531,  ..., -0.1643,  0.2244, -0.0265],\n",
              "         ...,\n",
              "         [-0.1494,  0.0430,  0.3565,  ..., -0.1250, -0.0616, -0.0681],\n",
              "         [-0.2245,  0.0178,  0.4014,  ..., -0.0138, -0.0004, -0.0917],\n",
              "         [-0.2217,  0.0242,  0.3459,  ...,  0.1130,  0.0114, -0.1082]],\n",
              "        device='cuda:0'),\n",
              " 'sa2mstk0': tensor([[-0.0224, -0.1248, -0.0142,  ...,  0.2551,  0.0338,  0.1873],\n",
              "         [ 0.0883, -0.0715,  0.0008,  ..., -0.1095,  0.1678,  0.0949],\n",
              "         [ 0.0667, -0.0342,  0.0286,  ..., -0.1532,  0.2556, -0.0168],\n",
              "         ...,\n",
              "         [-0.1775,  0.0119,  0.3157,  ..., -0.1155, -0.0102, -0.0430],\n",
              "         [-0.2611,  0.0033,  0.3822,  ...,  0.0043,  0.0163, -0.0743],\n",
              "         [-0.2459,  0.0300,  0.3312,  ...,  0.1479,  0.0091, -0.0880]],\n",
              "        device='cuda:0'),\n",
              " 'si1116fjre0': tensor([[-2.2920e-02, -1.2627e-01, -1.4684e-02,  ...,  2.5352e-01,\n",
              "           3.2366e-02,  1.8685e-01],\n",
              "         [ 8.2940e-02, -7.5871e-02,  3.0879e-04,  ..., -1.1319e-01,\n",
              "           1.6595e-01,  9.8150e-02],\n",
              "         [ 6.0528e-02, -4.0918e-02,  2.4898e-02,  ..., -1.5813e-01,\n",
              "           2.5163e-01, -1.2298e-02],\n",
              "         ...,\n",
              "         [-1.7897e-01,  1.1056e-02,  3.1452e-01,  ..., -1.1976e-01,\n",
              "          -8.6734e-03, -4.2062e-02],\n",
              "         [-2.6200e-01,  1.7057e-03,  3.8109e-01,  ..., -9.4267e-04,\n",
              "           1.6593e-02, -7.2813e-02],\n",
              "         [-2.4542e-01,  2.4561e-02,  3.3150e-01,  ...,  1.4080e-01,\n",
              "           1.0509e-02, -9.0239e-02]], device='cuda:0'),\n",
              " 'sx9mgwt0': tensor([[-2.1855e-02, -1.3138e-01, -1.2213e-02,  ...,  2.5026e-01,\n",
              "           3.4956e-02,  1.9002e-01],\n",
              "         [ 8.7677e-02, -7.5929e-02,  8.6759e-04,  ..., -1.1736e-01,\n",
              "           1.7456e-01,  1.0564e-01],\n",
              "         [ 6.3008e-02, -4.5173e-02,  2.4336e-02,  ..., -1.5946e-01,\n",
              "           2.5998e-01, -5.2715e-03],\n",
              "         ...,\n",
              "         [-1.7735e-01,  6.5645e-03,  3.1645e-01,  ..., -1.1292e-01,\n",
              "          -4.5673e-03, -3.8324e-02],\n",
              "         [-2.6069e-01, -3.7497e-05,  3.7912e-01,  ...,  2.8420e-03,\n",
              "           2.2369e-02, -7.2859e-02],\n",
              "         [-2.5039e-01,  2.2066e-02,  3.3089e-01,  ...,  1.4717e-01,\n",
              "           1.6807e-02, -8.6532e-02]], device='cuda:0'),\n",
              " 'sx104mrjo0': tensor([[-0.0218, -0.1248, -0.0138,  ...,  0.2536,  0.0333,  0.1875],\n",
              "         [ 0.0873, -0.0721,  0.0017,  ..., -0.1114,  0.1656,  0.0971],\n",
              "         [ 0.0658, -0.0347,  0.0286,  ..., -0.1557,  0.2529, -0.0154],\n",
              "         ...,\n",
              "         [-0.1783,  0.0116,  0.3175,  ..., -0.1152, -0.0116, -0.0433],\n",
              "         [-0.2609,  0.0029,  0.3827,  ...,  0.0030,  0.0148, -0.0751],\n",
              "         [-0.2467,  0.0292,  0.3319,  ...,  0.1480,  0.0105, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'si2169mgwt0': tensor([[ 0.0350, -0.1551, -0.0236,  ...,  0.2265,  0.0283,  0.1604],\n",
              "         [ 0.1857, -0.0725, -0.0037,  ..., -0.1450,  0.1373,  0.0978],\n",
              "         [ 0.1597, -0.0266,  0.0296,  ..., -0.2173,  0.1852, -0.0444],\n",
              "         ...,\n",
              "         [-0.0585,  0.0537,  0.3309,  ..., -0.1620, -0.0606, -0.0771],\n",
              "         [-0.1557,  0.0115,  0.3823,  ..., -0.0512,  0.0127, -0.0923],\n",
              "         [-0.1799, -0.0040,  0.3299,  ...,  0.0977,  0.0215, -0.1101]],\n",
              "        device='cuda:0'),\n",
              " 'si1553mwbt0': tensor([[ 0.0572, -0.1743, -0.0238,  ...,  0.2073,  0.0371,  0.1427],\n",
              "         [ 0.2236, -0.0999, -0.0236,  ..., -0.1736,  0.1439,  0.0865],\n",
              "         [ 0.2013, -0.0586,  0.0131,  ..., -0.2442,  0.1833, -0.0615],\n",
              "         ...,\n",
              "         [-0.0022,  0.0115,  0.2976,  ..., -0.1929, -0.0334, -0.0900],\n",
              "         [-0.1106, -0.0212,  0.3616,  ..., -0.0766,  0.0272, -0.1042],\n",
              "         [-0.1449, -0.0429,  0.3194,  ...,  0.0708,  0.0391, -0.1244]],\n",
              "        device='cuda:0'),\n",
              " 'sa2msjs1': tensor([[ 0.0108, -0.1425, -0.0198,  ...,  0.2347,  0.0247,  0.1717],\n",
              "         [ 0.1176, -0.0448,  0.0222,  ..., -0.1042,  0.1445,  0.0928],\n",
              "         [ 0.0830,  0.0066,  0.0522,  ..., -0.1719,  0.2097, -0.0403],\n",
              "         ...,\n",
              "         [-0.1263,  0.0652,  0.3532,  ..., -0.1279, -0.0687, -0.0792],\n",
              "         [-0.2126,  0.0293,  0.4033,  ..., -0.0212,  0.0006, -0.0945],\n",
              "         [-0.2114,  0.0278,  0.3420,  ...,  0.1131,  0.0149, -0.1128]],\n",
              "        device='cuda:0'),\n",
              " 'sx230fkms0': tensor([[ 0.0086, -0.1434, -0.0184,  ...,  0.2356,  0.0240,  0.1743],\n",
              "         [ 0.1120, -0.0486,  0.0241,  ..., -0.1069,  0.1399,  0.0918],\n",
              "         [ 0.0774,  0.0008,  0.0526,  ..., -0.1743,  0.2107, -0.0384],\n",
              "         ...,\n",
              "         [-0.1355,  0.0544,  0.3562,  ..., -0.1297, -0.0689, -0.0775],\n",
              "         [-0.2158,  0.0226,  0.4023,  ..., -0.0230, -0.0030, -0.0943],\n",
              "         [-0.2134,  0.0244,  0.3422,  ...,  0.1090,  0.0110, -0.1113]],\n",
              "        device='cuda:0'),\n",
              " 'si1474fdac1': tensor([[-0.0227, -0.1247, -0.0144,  ...,  0.2537,  0.0315,  0.1852],\n",
              "         [ 0.0839, -0.0748,  0.0032,  ..., -0.1093,  0.1643,  0.0931],\n",
              "         [ 0.0637, -0.0366,  0.0282,  ..., -0.1554,  0.2498, -0.0173],\n",
              "         ...,\n",
              "         [-0.1795,  0.0118,  0.3152,  ..., -0.1223, -0.0122, -0.0448],\n",
              "         [-0.2628,  0.0021,  0.3826,  ..., -0.0009,  0.0140, -0.0751],\n",
              "         [-0.2443,  0.0287,  0.3313,  ...,  0.1434,  0.0067, -0.0902]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mgwt0': tensor([[ 0.0153, -0.1433, -0.0225,  ...,  0.2338,  0.0236,  0.1698],\n",
              "         [ 0.1347, -0.0479,  0.0157,  ..., -0.1159,  0.1395,  0.0948],\n",
              "         [ 0.0999,  0.0033,  0.0481,  ..., -0.1821,  0.2021, -0.0416],\n",
              "         ...,\n",
              "         [-0.1151,  0.0666,  0.3484,  ..., -0.1347, -0.0705, -0.0771],\n",
              "         [-0.2029,  0.0261,  0.3989,  ..., -0.0283,  0.0016, -0.0929],\n",
              "         [-0.2072,  0.0224,  0.3379,  ...,  0.1100,  0.0139, -0.1114]],\n",
              "        device='cuda:0'),\n",
              " 'sx140fkms0': tensor([[ 0.0061, -0.1455, -0.0172,  ...,  0.2358,  0.0242,  0.1764],\n",
              "         [ 0.1085, -0.0534,  0.0243,  ..., -0.1096,  0.1385,  0.0927],\n",
              "         [ 0.0762, -0.0060,  0.0523,  ..., -0.1744,  0.2127, -0.0355],\n",
              "         ...,\n",
              "         [-0.1414,  0.0466,  0.3558,  ..., -0.1308, -0.0664, -0.0748],\n",
              "         [-0.2174,  0.0168,  0.4002,  ..., -0.0231, -0.0024, -0.0940],\n",
              "         [-0.2153,  0.0202,  0.3422,  ...,  0.1059,  0.0110, -0.1109]],\n",
              "        device='cuda:0'),\n",
              " 'sx109mpgl0': tensor([[ 0.0114, -0.1466, -0.0176,  ...,  0.2362,  0.0281,  0.1766],\n",
              "         [ 0.1222, -0.0390,  0.0244,  ..., -0.0945,  0.1438,  0.0984],\n",
              "         [ 0.0805,  0.0086,  0.0589,  ..., -0.1530,  0.2140, -0.0247],\n",
              "         ...,\n",
              "         [-0.1220,  0.0708,  0.3627,  ..., -0.1106, -0.0730, -0.0687],\n",
              "         [-0.2051,  0.0362,  0.4128,  ..., -0.0075, -0.0015, -0.0882],\n",
              "         [-0.2071,  0.0317,  0.3494,  ...,  0.1145,  0.0196, -0.1144]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fram1': tensor([[ 0.0081, -0.1443, -0.0187,  ...,  0.2346,  0.0255,  0.1741],\n",
              "         [ 0.1182, -0.0538,  0.0234,  ..., -0.1128,  0.1448,  0.0912],\n",
              "         [ 0.0883, -0.0077,  0.0489,  ..., -0.1791,  0.2137, -0.0363],\n",
              "         ...,\n",
              "         [-0.1334,  0.0511,  0.3499,  ..., -0.1357, -0.0630, -0.0783],\n",
              "         [-0.2152,  0.0177,  0.3970,  ..., -0.0267,  0.0034, -0.0946],\n",
              "         [-0.2151,  0.0212,  0.3387,  ...,  0.1097,  0.0109, -0.1107]],\n",
              "        device='cuda:0'),\n",
              " 'si1544fdrd1': tensor([[-0.0227, -0.1250, -0.0146,  ...,  0.2530,  0.0332,  0.1866],\n",
              "         [ 0.0862, -0.0745,  0.0009,  ..., -0.1086,  0.1695,  0.0951],\n",
              "         [ 0.0650, -0.0384,  0.0258,  ..., -0.1536,  0.2554, -0.0144],\n",
              "         ...,\n",
              "         [-0.1793,  0.0125,  0.3164,  ..., -0.1160, -0.0070, -0.0434],\n",
              "         [-0.2626,  0.0034,  0.3821,  ...,  0.0038,  0.0182, -0.0737],\n",
              "         [-0.2455,  0.0297,  0.3305,  ...,  0.1463,  0.0092, -0.0883]],\n",
              "        device='cuda:0'),\n",
              " 'sx281mrcz0': tensor([[ 0.0085, -0.1414, -0.0176,  ...,  0.2371,  0.0243,  0.1760],\n",
              "         [ 0.1144, -0.0475,  0.0251,  ..., -0.1053,  0.1441,  0.0931],\n",
              "         [ 0.0795,  0.0019,  0.0527,  ..., -0.1708,  0.2167, -0.0338],\n",
              "         ...,\n",
              "         [-0.1353,  0.0564,  0.3562,  ..., -0.1286, -0.0687, -0.0753],\n",
              "         [-0.2168,  0.0244,  0.4036,  ..., -0.0197, -0.0022, -0.0934],\n",
              "         [-0.2166,  0.0292,  0.3428,  ...,  0.1147,  0.0092, -0.1098]],\n",
              "        device='cuda:0'),\n",
              " 'sx102mmdm2': tensor([[ 0.0084, -0.1437, -0.0185,  ...,  0.2353,  0.0234,  0.1736],\n",
              "         [ 0.1143, -0.0485,  0.0247,  ..., -0.1072,  0.1396,  0.0921],\n",
              "         [ 0.0804,  0.0019,  0.0534,  ..., -0.1743,  0.2091, -0.0383],\n",
              "         ...,\n",
              "         [-0.1328,  0.0543,  0.3544,  ..., -0.1321, -0.0682, -0.0776],\n",
              "         [-0.2147,  0.0221,  0.4022,  ..., -0.0239, -0.0015, -0.0945],\n",
              "         [-0.2133,  0.0230,  0.3420,  ...,  0.1100,  0.0127, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx185mmdb1': tensor([[-0.0021, -0.1455, -0.0116,  ...,  0.2389,  0.0267,  0.1814],\n",
              "         [ 0.0977, -0.0606,  0.0252,  ..., -0.1058,  0.1529,  0.0938],\n",
              "         [ 0.0726, -0.0186,  0.0479,  ..., -0.1639,  0.2310, -0.0224],\n",
              "         ...,\n",
              "         [-0.1574,  0.0351,  0.3499,  ..., -0.1251, -0.0500, -0.0672],\n",
              "         [-0.2304,  0.0114,  0.3963,  ..., -0.0117,  0.0079, -0.0918],\n",
              "         [-0.2242,  0.0192,  0.3441,  ...,  0.1136,  0.0145, -0.1077]],\n",
              "        device='cuda:0'),\n",
              " 'sx184fjem0': tensor([[ 0.0633, -0.1824, -0.0211,  ...,  0.1995,  0.0395,  0.1378],\n",
              "         [ 0.2279, -0.1120, -0.0271,  ..., -0.1770,  0.1490,  0.0798],\n",
              "         [ 0.2119, -0.0731,  0.0047,  ..., -0.2480,  0.1865, -0.0662],\n",
              "         ...,\n",
              "         [ 0.0114, -0.0050,  0.2846,  ..., -0.2016, -0.0198, -0.0965],\n",
              "         [-0.1011, -0.0315,  0.3541,  ..., -0.0860,  0.0358, -0.1090],\n",
              "         [-0.1367, -0.0555,  0.3162,  ...,  0.0630,  0.0445, -0.1290]],\n",
              "        device='cuda:0'),\n",
              " 'sx365mmdb1': tensor([[ 0.0181, -0.1434, -0.0263,  ...,  0.2299,  0.0203,  0.1660],\n",
              "         [ 0.1355, -0.0453,  0.0148,  ..., -0.1132,  0.1355,  0.0958],\n",
              "         [ 0.1015,  0.0073,  0.0476,  ..., -0.1843,  0.1912, -0.0429],\n",
              "         ...,\n",
              "         [-0.1045,  0.0739,  0.3463,  ..., -0.1351, -0.0812, -0.0743],\n",
              "         [-0.1947,  0.0320,  0.4025,  ..., -0.0310, -0.0065, -0.0929],\n",
              "         [-0.2009,  0.0247,  0.3401,  ...,  0.1052,  0.0140, -0.1127]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fdac1': tensor([[-0.0107, -0.1352, -0.0108,  ...,  0.2502,  0.0262,  0.1821],\n",
              "         [ 0.0896, -0.0669,  0.0191,  ..., -0.1052,  0.1552,  0.0917],\n",
              "         [ 0.0690, -0.0235,  0.0434,  ..., -0.1590,  0.2401, -0.0239],\n",
              "         ...,\n",
              "         [-0.1712,  0.0256,  0.3354,  ..., -0.1258, -0.0379, -0.0580],\n",
              "         [-0.2467,  0.0069,  0.3918,  ..., -0.0075,  0.0084, -0.0837],\n",
              "         [-0.2386,  0.0234,  0.3400,  ...,  0.1253,  0.0099, -0.1002]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mjar0': tensor([[ 0.0525, -0.1695, -0.0234,  ...,  0.2136,  0.0354,  0.1481],\n",
              "         [ 0.2144, -0.0923, -0.0188,  ..., -0.1645,  0.1453,  0.0875],\n",
              "         [ 0.1918, -0.0501,  0.0134,  ..., -0.2360,  0.1870, -0.0584],\n",
              "         ...,\n",
              "         [-0.0159,  0.0239,  0.3049,  ..., -0.1848, -0.0404, -0.0863],\n",
              "         [-0.1215, -0.0099,  0.3654,  ..., -0.0690,  0.0244, -0.1007],\n",
              "         [-0.1540, -0.0315,  0.3213,  ...,  0.0815,  0.0347, -0.1194]],\n",
              "        device='cuda:0'),\n",
              " 'sa1faks0': tensor([[-2.1034e-02, -1.2466e-01, -1.4833e-02,  ...,  2.5455e-01,\n",
              "           3.2707e-02,  1.8555e-01],\n",
              "         [ 8.7882e-02, -7.4265e-02,  1.9939e-03,  ..., -1.0809e-01,\n",
              "           1.6368e-01,  9.3794e-02],\n",
              "         [ 6.6562e-02, -3.5678e-02,  2.8359e-02,  ..., -1.5450e-01,\n",
              "           2.5045e-01, -1.7240e-02],\n",
              "         ...,\n",
              "         [-1.8020e-01,  1.4047e-02,  3.1849e-01,  ..., -1.1973e-01,\n",
              "          -1.1978e-02, -4.6564e-02],\n",
              "         [-2.6155e-01,  2.8232e-03,  3.8337e-01,  ...,  2.7419e-04,\n",
              "           1.4559e-02, -7.4942e-02],\n",
              "         [-2.4422e-01,  2.8756e-02,  3.3078e-01,  ...,  1.4380e-01,\n",
              "           7.5664e-03, -8.9859e-02]], device='cuda:0'),\n",
              " 'sx110mjsw0': tensor([[-0.0236, -0.1280, -0.0131,  ...,  0.2519,  0.0311,  0.1872],\n",
              "         [ 0.0809, -0.0769,  0.0034,  ..., -0.1129,  0.1690,  0.1001],\n",
              "         [ 0.0591, -0.0429,  0.0255,  ..., -0.1577,  0.2519, -0.0087],\n",
              "         ...,\n",
              "         [-0.1774,  0.0101,  0.3152,  ..., -0.1200, -0.0087, -0.0386],\n",
              "         [-0.2618,  0.0016,  0.3809,  ..., -0.0006,  0.0172, -0.0718],\n",
              "         [-0.2469,  0.0238,  0.3323,  ...,  0.1415,  0.0128, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa2faks0': tensor([[-0.0231, -0.1307, -0.0150,  ...,  0.2503,  0.0333,  0.1897],\n",
              "         [ 0.0836, -0.0809, -0.0037,  ..., -0.1190,  0.1701,  0.1030],\n",
              "         [ 0.0591, -0.0507,  0.0177,  ..., -0.1614,  0.2541, -0.0066],\n",
              "         ...,\n",
              "         [-0.1813,  0.0051,  0.3138,  ..., -0.1168, -0.0029, -0.0402],\n",
              "         [-0.2630, -0.0033,  0.3771,  ..., -0.0016,  0.0231, -0.0722],\n",
              "         [-0.2509,  0.0195,  0.3275,  ...,  0.1407,  0.0144, -0.0860]],\n",
              "        device='cuda:0'),\n",
              " 'si992fjwb0': tensor([[ 0.1117, -0.2771, -0.0015,  ...,  0.1391,  0.0547,  0.0795],\n",
              "         [ 0.2824, -0.2419, -0.0550,  ..., -0.2368,  0.1682,  0.0279],\n",
              "         [ 0.2602, -0.2234, -0.0363,  ..., -0.2759,  0.2083, -0.1080],\n",
              "         ...,\n",
              "         [ 0.0500, -0.1794,  0.1812,  ..., -0.2817,  0.0572, -0.1670],\n",
              "         [-0.0552, -0.1936,  0.2924,  ..., -0.1668,  0.0985, -0.1790],\n",
              "         [-0.0781, -0.2067,  0.3075,  ...,  0.0047,  0.0945, -0.1872]],\n",
              "        device='cuda:0'),\n",
              " 'sx280fram1': tensor([[-0.0246, -0.1274, -0.0152,  ...,  0.2514,  0.0314,  0.1868],\n",
              "         [ 0.0809, -0.0794,  0.0010,  ..., -0.1141,  0.1673,  0.0975],\n",
              "         [ 0.0595, -0.0461,  0.0225,  ..., -0.1589,  0.2494, -0.0103],\n",
              "         ...,\n",
              "         [-0.1799,  0.0099,  0.3139,  ..., -0.1234, -0.0076, -0.0416],\n",
              "         [-0.2637,  0.0006,  0.3798,  ..., -0.0031,  0.0168, -0.0726],\n",
              "         [-0.2459,  0.0242,  0.3294,  ...,  0.1389,  0.0091, -0.0887]],\n",
              "        device='cuda:0'),\n",
              " 'si2120fkms0': tensor([[ 0.0044, -0.1465, -0.0156,  ...,  0.2341,  0.0243,  0.1785],\n",
              "         [ 0.1041, -0.0561,  0.0258,  ..., -0.1097,  0.1404,  0.0918],\n",
              "         [ 0.0751, -0.0095,  0.0510,  ..., -0.1747,  0.2153, -0.0330],\n",
              "         ...,\n",
              "         [-0.1461,  0.0431,  0.3555,  ..., -0.1298, -0.0636, -0.0746],\n",
              "         [-0.2205,  0.0150,  0.3992,  ..., -0.0206, -0.0007, -0.0946],\n",
              "         [-0.2171,  0.0196,  0.3420,  ...,  0.1071,  0.0107, -0.1093]],\n",
              "        device='cuda:0'),\n",
              " 'si1808fcft0': tensor([[-0.0314, -0.1414, -0.0240,  ...,  0.2280,  0.0426,  0.1899],\n",
              "         [ 0.0972, -0.0725,  0.0071,  ..., -0.1292,  0.1952,  0.0769],\n",
              "         [ 0.0996, -0.0297,  0.0055,  ..., -0.1996,  0.2614, -0.0247],\n",
              "         ...,\n",
              "         [-0.1567,  0.0294,  0.3382,  ..., -0.0691, -0.0068, -0.0591],\n",
              "         [-0.2610,  0.0176,  0.3739,  ...,  0.0556,  0.0328, -0.0945],\n",
              "         [-0.2405,  0.0823,  0.3048,  ...,  0.2330,  0.0239, -0.0271]],\n",
              "        device='cuda:0'),\n",
              " 'si1178fcft0': tensor([[ 0.0355, -0.1606, -0.0216,  ...,  0.2211,  0.0296,  0.1600],\n",
              "         [ 0.1830, -0.0821,  0.0005,  ..., -0.1461,  0.1389,  0.0934],\n",
              "         [ 0.1671, -0.0382,  0.0274,  ..., -0.2233,  0.1869, -0.0475],\n",
              "         ...,\n",
              "         [-0.0514,  0.0407,  0.3246,  ..., -0.1730, -0.0544, -0.0803],\n",
              "         [-0.1506,  0.0015,  0.3783,  ..., -0.0584,  0.0180, -0.0954],\n",
              "         [-0.1776, -0.0121,  0.3288,  ...,  0.0913,  0.0237, -0.1126]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mdab0': tensor([[ 0.0622, -0.1898, -0.0188,  ...,  0.1982,  0.0397,  0.1384],\n",
              "         [ 0.2319, -0.1232, -0.0240,  ..., -0.1824,  0.1457,  0.0763],\n",
              "         [ 0.2178, -0.0888,  0.0049,  ..., -0.2538,  0.1866, -0.0677],\n",
              "         ...,\n",
              "         [ 0.0098, -0.0191,  0.2881,  ..., -0.2070, -0.0183, -0.0939],\n",
              "         [-0.1001, -0.0432,  0.3532,  ..., -0.0900,  0.0370, -0.1070],\n",
              "         [-0.1391, -0.0639,  0.3143,  ...,  0.0611,  0.0426, -0.1273]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mstk0': tensor([[-0.0151, -0.1271, -0.0124,  ...,  0.2544,  0.0294,  0.1840],\n",
              "         [ 0.0925, -0.0688,  0.0097,  ..., -0.1047,  0.1585,  0.0929],\n",
              "         [ 0.0709, -0.0278,  0.0380,  ..., -0.1544,  0.2476, -0.0215],\n",
              "         ...,\n",
              "         [-0.1736,  0.0210,  0.3258,  ..., -0.1188, -0.0260, -0.0525],\n",
              "         [-0.2534,  0.0073,  0.3878,  ..., -0.0006,  0.0102, -0.0798],\n",
              "         [-0.2429,  0.0284,  0.3352,  ...,  0.1384,  0.0081, -0.0937]],\n",
              "        device='cuda:0'),\n",
              " 'si2284mstk0': tensor([[-0.0229, -0.1371, -0.0174,  ...,  0.2457,  0.0369,  0.1957],\n",
              "         [ 0.0808, -0.0853, -0.0189,  ..., -0.1357,  0.1782,  0.1211],\n",
              "         [ 0.0503, -0.0644, -0.0014,  ..., -0.1744,  0.2625,  0.0075],\n",
              "         ...,\n",
              "         [-0.1762, -0.0138,  0.3007,  ..., -0.1199,  0.0004, -0.0256],\n",
              "         [-0.2638, -0.0148,  0.3648,  ..., -0.0070,  0.0303, -0.0662],\n",
              "         [-0.2582,  0.0072,  0.3242,  ...,  0.1376,  0.0223, -0.0810]],\n",
              "        device='cuda:0'),\n",
              " 'sx50fkms0': tensor([[ 0.0064, -0.1465, -0.0172,  ...,  0.2337,  0.0247,  0.1757],\n",
              "         [ 0.1099, -0.0532,  0.0255,  ..., -0.1096,  0.1394,  0.0929],\n",
              "         [ 0.0780, -0.0061,  0.0526,  ..., -0.1756,  0.2107, -0.0327],\n",
              "         ...,\n",
              "         [-0.1385,  0.0483,  0.3564,  ..., -0.1321, -0.0655, -0.0750],\n",
              "         [-0.2159,  0.0176,  0.4009,  ..., -0.0243, -0.0011, -0.0941],\n",
              "         [-0.2136,  0.0195,  0.3419,  ...,  0.1055,  0.0126, -0.1114]],\n",
              "        device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Diffrential Privacy filter"
      ],
      "metadata": {
        "id": "vsuSDhRQEYF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "8O3flG4_EhHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "input_size = 768  # Size of input features\n",
        "hidden_size = 384  # Size of hidden layer\n",
        "output_size = 768  # Size of output features (deepfake-like features)\n",
        "batch_size = 24\n",
        "num_layers = 2\n",
        "noise_multiplier = 0.1\n",
        "max_grad_norm = 1.0\n",
        "num_epochs = 1000\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "0yStXMpSFxez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom dataset\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, real_features, deepfake_features):\n",
        "        self.real_features = real_features\n",
        "        self.deepfake_features = deepfake_features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.real_features[idx], self.deepfake_features[idx]"
      ],
      "metadata": {
        "id": "fl_CPzqaF4Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Uss5bl6OuqmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dict_to_tensor(feature_real, feature_deep, desired_size, device):\n",
        "  \"\"\"\n",
        "  Processes dictionaries of real and deepfake feature sequences into tensors.\n",
        "\n",
        "  Args:\n",
        "      feature_real: A dictionary of real feature sequences (tensors).\n",
        "      feature_deep: A dictionary of deepfake feature sequences (tensors).\n",
        "      desired_size: The desired size for the output tensors.\n",
        "      device: The device to move the tensors to (e.g., 'cuda:0' for GPU).\n",
        "\n",
        "  Returns:\n",
        "      A tuple of tensors representing the processed real and deepfake features.\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine keys from both dictionaries\n",
        "  all_keys = set(feature_real.keys()) | set(feature_deep.keys())\n",
        "\n",
        "  # Find minimum sequence length across all features (using chain)\n",
        "  min_length = min(len(seq) for seq in chain(feature_real.values(), feature_deep.values()))\n",
        "\n",
        "  # Process each feature sequence, considering minimum length\n",
        "  tensor_list_real = {key: None for key in all_keys}  # Initialize empty dict\n",
        "  tensor_list_deep = {key: None for key in all_keys}  # Initialize empty dict\n",
        "  for key in all_keys:\n",
        "    real_seq = feature_real.get(key)\n",
        "    deep_seq = feature_deep.get(key)\n",
        "    if real_seq is not None:\n",
        "      tensor_list_real[key] = F.interpolate(\n",
        "          real_seq[:min_length].unsqueeze(0), size=(desired_size,), mode='nearest').squeeze(0)\n",
        "    if deep_seq is not None:\n",
        "      tensor_list_deep[key] = F.interpolate(\n",
        "          deep_seq[:min_length].unsqueeze(0), size=(desired_size,), mode='nearest').squeeze(0)\n",
        "\n",
        "  # Stack and move to desired device\n",
        "  real_features_tensor = torch.stack([tensor_list_real[key] for key in feature_real.keys()]).to(device)\n",
        "  deepfake_features_tensor = torch.stack([tensor_list_deep[key] for key in feature_deep.keys()]).to(device)\n",
        "  return real_features_tensor, deepfake_features_tensor"
      ],
      "metadata": {
        "id": "FbaYoCPuLzOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic dataset\n",
        "# Convert dictionary to tensor and resize features\n",
        "real_features, deepfake_features = dict_to_tensor(feature_real, feature_deep, input_size, device)"
      ],
      "metadata": {
        "id": "hSdQOER2L2Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_features"
      ],
      "metadata": {
        "id": "rcWkNwCOxeaA",
        "outputId": "81528df5-88d3-4b1d-e376-00d80fd612b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0337, -0.1497, -0.0243,  ...,  0.2315,  0.0290,  0.1629],\n",
              "         [ 0.1824, -0.0650, -0.0055,  ..., -0.1429,  0.1406,  0.1006],\n",
              "         [ 0.1506, -0.0165,  0.0294,  ..., -0.2116,  0.1907, -0.0434],\n",
              "         ...,\n",
              "         [ 0.2791,  0.0735,  0.0227,  ..., -0.1190, -0.4003,  0.0074],\n",
              "         [ 0.2787,  0.0734,  0.0228,  ..., -0.1215, -0.4004,  0.0088],\n",
              "         [ 0.2786,  0.0735,  0.0229,  ..., -0.1232, -0.4015,  0.0099]],\n",
              "\n",
              "        [[ 0.0372, -0.1600, -0.0227,  ...,  0.2216,  0.0322,  0.1591],\n",
              "         [ 0.1889, -0.0792, -0.0043,  ..., -0.1479,  0.1435,  0.0944],\n",
              "         [ 0.1673, -0.0344,  0.0250,  ..., -0.2216,  0.1901, -0.0467],\n",
              "         ...,\n",
              "         [ 0.2975,  0.0570,  0.0192,  ..., -0.1471, -0.3939, -0.0063],\n",
              "         [ 0.2970,  0.0565,  0.0197,  ..., -0.1460, -0.3938, -0.0063],\n",
              "         [ 0.2970,  0.0560,  0.0199,  ..., -0.1455, -0.3936, -0.0058]],\n",
              "\n",
              "        [[ 0.0072, -0.1443, -0.0176,  ...,  0.2343,  0.0249,  0.1746],\n",
              "         [ 0.1128, -0.0520,  0.0250,  ..., -0.1086,  0.1449,  0.0915],\n",
              "         [ 0.0819, -0.0033,  0.0516,  ..., -0.1755,  0.2143, -0.0359],\n",
              "         ...,\n",
              "         [ 0.2232,  0.1251,  0.0354,  ..., -0.0600, -0.3834, -0.0033],\n",
              "         [ 0.2233,  0.1243,  0.0348,  ..., -0.0594, -0.3838, -0.0035],\n",
              "         [ 0.2240,  0.1234,  0.0345,  ..., -0.0599, -0.3843, -0.0041]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.0148, -0.1270, -0.0115,  ...,  0.2550,  0.0294,  0.1838],\n",
              "         [ 0.0945, -0.0673,  0.0117,  ..., -0.1015,  0.1606,  0.0923],\n",
              "         [ 0.0725, -0.0254,  0.0402,  ..., -0.1516,  0.2492, -0.0209],\n",
              "         ...,\n",
              "         [ 0.1946,  0.1038,  0.0346,  ..., -0.0725, -0.4455,  0.0026],\n",
              "         [ 0.1923,  0.1032,  0.0350,  ..., -0.0735, -0.4495,  0.0035],\n",
              "         [ 0.1899,  0.1025,  0.0358,  ..., -0.0756, -0.4555,  0.0049]],\n",
              "\n",
              "        [[-0.0221, -0.1369, -0.0167,  ...,  0.2465,  0.0372,  0.1958],\n",
              "         [ 0.0826, -0.0840, -0.0174,  ..., -0.1343,  0.1787,  0.1211],\n",
              "         [ 0.0510, -0.0636,  0.0007,  ..., -0.1726,  0.2626,  0.0089],\n",
              "         ...,\n",
              "         [-0.1771, -0.0130,  0.3044,  ..., -0.1168,  0.0019, -0.0271],\n",
              "         [-0.2629, -0.0142,  0.3658,  ..., -0.0056,  0.0308, -0.0659],\n",
              "         [-0.2576,  0.0076,  0.3243,  ...,  0.1383,  0.0224, -0.0805]],\n",
              "\n",
              "        [[ 0.0080, -0.1466, -0.0177,  ...,  0.2326,  0.0248,  0.1749],\n",
              "         [ 0.1131, -0.0524,  0.0254,  ..., -0.1085,  0.1394,  0.0936],\n",
              "         [ 0.0793, -0.0036,  0.0533,  ..., -0.1747,  0.2085, -0.0322],\n",
              "         ...,\n",
              "         [ 0.2216,  0.1213,  0.0409,  ..., -0.0617, -0.3851, -0.0047],\n",
              "         [ 0.2227,  0.1206,  0.0416,  ..., -0.0644, -0.3863, -0.0039],\n",
              "         [ 0.2225,  0.1200,  0.0427,  ..., -0.0659, -0.3888, -0.0037]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deepfake_features"
      ],
      "metadata": {
        "id": "0XsTUh5gVEOn",
        "outputId": "439e0c14-27b5-4a3c-b476-5744f91b81e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 3.2117e-02, -1.4953e-01, -2.3393e-02,  ...,  2.3164e-01,\n",
              "           2.8560e-02,  1.6406e-01],\n",
              "         [ 1.7674e-01, -6.5082e-02, -3.2546e-03,  ..., -1.4112e-01,\n",
              "           1.4044e-01,  9.8912e-02],\n",
              "         [ 1.4602e-01, -1.7526e-02,  3.0644e-02,  ..., -2.1033e-01,\n",
              "           1.9388e-01, -4.4958e-02],\n",
              "         ...,\n",
              "         [ 2.7445e-01,  7.3909e-02,  1.9542e-02,  ..., -1.1725e-01,\n",
              "          -4.0546e-01,  6.8320e-03],\n",
              "         [ 2.7438e-01,  7.4162e-02,  1.9759e-02,  ..., -1.1950e-01,\n",
              "          -4.0531e-01,  7.9358e-03],\n",
              "         [ 2.7426e-01,  7.4530e-02,  2.0117e-02,  ..., -1.2073e-01,\n",
              "          -4.0587e-01,  9.0176e-03]],\n",
              "\n",
              "        [[ 3.4436e-02, -1.5756e-01, -2.2521e-02,  ...,  2.2409e-01,\n",
              "           3.0163e-02,  1.6043e-01],\n",
              "         [ 1.8238e-01, -7.6064e-02, -1.5109e-03,  ..., -1.4532e-01,\n",
              "           1.4173e-01,  9.4654e-02],\n",
              "         [ 1.5974e-01, -3.0997e-02,  2.7993e-02,  ..., -2.1875e-01,\n",
              "           1.9105e-01, -4.7759e-02],\n",
              "         ...,\n",
              "         [ 2.8726e-01,  6.2903e-02,  1.9651e-02,  ..., -1.3937e-01,\n",
              "          -4.0017e-01, -3.9510e-03],\n",
              "         [ 2.8700e-01,  6.1975e-02,  1.9243e-02,  ..., -1.3787e-01,\n",
              "          -4.0011e-01, -4.0791e-03],\n",
              "         [ 2.8739e-01,  6.1736e-02,  1.9519e-02,  ..., -1.3767e-01,\n",
              "          -3.9945e-01, -4.3995e-03]],\n",
              "\n",
              "        [[-3.0757e-02, -1.4190e-01, -2.3544e-02,  ...,  2.2695e-01,\n",
              "           4.2190e-02,  1.9027e-01],\n",
              "         [ 9.7086e-02, -6.8938e-02,  1.0541e-02,  ..., -1.2914e-01,\n",
              "           1.9258e-01,  7.4643e-02],\n",
              "         [ 1.0102e-01, -2.2707e-02,  8.6362e-03,  ..., -2.0044e-01,\n",
              "           2.5908e-01, -2.8121e-02],\n",
              "         ...,\n",
              "         [ 2.2486e-01,  9.8309e-02, -2.1018e-02,  ..., -1.2990e-01,\n",
              "          -3.3694e-01,  1.9893e-02],\n",
              "         [ 2.2561e-01,  9.8580e-02, -2.1355e-02,  ..., -1.2795e-01,\n",
              "          -3.3861e-01,  1.9287e-02],\n",
              "         [ 2.2661e-01,  9.8659e-02, -2.1357e-02,  ..., -1.2761e-01,\n",
              "          -3.3955e-01,  1.9011e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.5143e-02, -1.2709e-01, -1.2373e-02,  ...,  2.5443e-01,\n",
              "           2.9362e-02,  1.8401e-01],\n",
              "         [ 9.2547e-02, -6.8764e-02,  9.6828e-03,  ..., -1.0467e-01,\n",
              "           1.5845e-01,  9.2928e-02],\n",
              "         [ 7.0905e-02, -2.7753e-02,  3.8029e-02,  ..., -1.5436e-01,\n",
              "           2.4760e-01, -2.1508e-02],\n",
              "         ...,\n",
              "         [ 1.9314e-01,  1.0059e-01,  3.1117e-02,  ..., -7.6773e-02,\n",
              "          -4.4561e-01, -5.1245e-04],\n",
              "         [ 1.9095e-01,  1.0028e-01,  3.2421e-02,  ..., -7.8042e-02,\n",
              "          -4.4945e-01,  6.0385e-04],\n",
              "         [ 1.8873e-01,  9.9352e-02,  3.3595e-02,  ..., -7.9798e-02,\n",
              "          -4.5578e-01,  1.7091e-03]],\n",
              "\n",
              "        [[-2.2943e-02, -1.3709e-01, -1.7439e-02,  ...,  2.4568e-01,\n",
              "           3.6937e-02,  1.9565e-01],\n",
              "         [ 8.0793e-02, -8.5318e-02, -1.8878e-02,  ..., -1.3566e-01,\n",
              "           1.7817e-01,  1.2112e-01],\n",
              "         [ 5.0304e-02, -6.4362e-02, -1.3710e-03,  ..., -1.7443e-01,\n",
              "           2.6246e-01,  7.4737e-03],\n",
              "         ...,\n",
              "         [-1.7623e-01, -1.3758e-02,  3.0073e-01,  ..., -1.1994e-01,\n",
              "           3.9272e-04, -2.5592e-02],\n",
              "         [-2.6376e-01, -1.4785e-02,  3.6478e-01,  ..., -6.9887e-03,\n",
              "           3.0288e-02, -6.6200e-02],\n",
              "         [-2.5825e-01,  7.2269e-03,  3.2424e-01,  ...,  1.3763e-01,\n",
              "           2.2313e-02, -8.0961e-02]],\n",
              "\n",
              "        [[ 6.4495e-03, -1.4651e-01, -1.7213e-02,  ...,  2.3372e-01,\n",
              "           2.4673e-02,  1.7573e-01],\n",
              "         [ 1.0992e-01, -5.3213e-02,  2.5519e-02,  ..., -1.0958e-01,\n",
              "           1.3935e-01,  9.2881e-02],\n",
              "         [ 7.7984e-02, -6.0822e-03,  5.2618e-02,  ..., -1.7556e-01,\n",
              "           2.1070e-01, -3.2668e-02],\n",
              "         ...,\n",
              "         [ 2.2052e-01,  1.1893e-01,  3.8744e-02,  ..., -6.4763e-02,\n",
              "          -3.8759e-01, -6.3891e-03],\n",
              "         [ 2.2097e-01,  1.1824e-01,  3.9431e-02,  ..., -6.6059e-02,\n",
              "          -3.8941e-01, -5.9452e-03],\n",
              "         [ 2.2158e-01,  1.1787e-01,  4.0339e-02,  ..., -6.8050e-02,\n",
              "          -3.9135e-01, -6.2366e-03]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(real_features))\n",
        "val_size = len(real_features) - train_size\n",
        "train_real, val_real = random_split(real_features, [train_size, val_size])\n",
        "train_deepfake, val_deepfake = random_split(deepfake_features, [train_size, val_size])\n"
      ],
      "metadata": {
        "id": "mhkvrReAF-1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for training and validation sets\n",
        "train_dataset = MyDataset(train_real, train_deepfake)\n",
        "val_dataset = MyDataset(val_real, val_deepfake)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "bYcpZR0xGBVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation metrics function\n",
        "def evaluate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay_epoch epochs\"\"\"\n",
        "    lr = initial_lr * (0.1**(epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Define a function to calculate moving averages\n",
        "def moving_average(data, window_size):\n",
        "    \"\"\"Calculate the moving average of data using a window size.\"\"\"\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')"
      ],
      "metadata": {
        "id": "C-Z8UlyQMvn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 1"
      ],
      "metadata": {
        "id": "lRtud1lE5luq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "    super(Generator, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Define the layers\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "    self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers[:-1]:\n",
        "      x = F.relu(layer(x))\n",
        "    x = self.layers[-1](x)\n",
        "    return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator(Generator):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm):\n",
        "        super(DPGenerator, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.noise_multiplier = noise_multiplier\n",
        "\n",
        "  def forward(self, x):\n",
        "      return super(DPGenerator, self).forward(x)\n",
        "\n",
        "  def backward(self, loss):\n",
        "      loss.backward()\n",
        "      for param in self.parameters():\n",
        "          if param.grad is not None:\n",
        "              param.grad += torch.randn_like(param.grad) * self.noise_multiplier\n",
        "              param.grad = torch.clamp(param.grad, -self.max_grad_norm, self.max_grad_norm)"
      ],
      "metadata": {
        "id": "8zObOanL5erP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = DPGenerator(input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "nteMvITmGC8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "ZCi7BmmdGJeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model(real_features)\n",
        "        loss = criterion(output, deepfake_features)\n",
        "        model.backward(loss)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SdmPbTeYYZw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 2"
      ],
      "metadata": {
        "id": "heneizAW8hUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator2, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator2(Generator2):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, max_grad_norm):\n",
        "          super(DPGenerator2, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.noise_log_std = nn.Parameter(torch.zeros(1))  # Trainable log std for noise\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super(DPGenerator2, self).forward(x)\n",
        "\n",
        "    def backward(self, loss):\n",
        "      loss.backward()\n",
        "      for param in self.parameters():\n",
        "        if param.grad is not None:\n",
        "          noise = torch.randn_like(param.grad) * torch.exp(self.noise_log_std)\n",
        "          param.grad += noise\n",
        "          param.grad = torch.clamp(param.grad, -self.max_grad_norm, self.max_grad_norm)"
      ],
      "metadata": {
        "id": "-d1UL-x58g_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model2 = DPGenerator2(input_size, hidden_size, output_size, num_layers, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer2 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion2 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "kL6oUuJm8g7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "MH8-MXJe8g0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer2.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model2(real_features)\n",
        "        loss = criterion2(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model2.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model2(real_features)\n",
        "            loss = criterion2(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fpVeqHQyBvMi",
        "outputId": "ca3f6219-4f95-4918-97ca-aa018c15f404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [1/1000], Validation Loss: 0.0297\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [2/1000], Validation Loss: 0.0297\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [3/1000], Validation Loss: 0.0297\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [4/1000], Validation Loss: 0.0297\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [5/1000], Validation Loss: 0.0297\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [6/1000], Validation Loss: 0.0297\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [7/1000], Validation Loss: 0.0297\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [8/1000], Validation Loss: 0.0297\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [9/1000], Validation Loss: 0.0297\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [10/1000], Validation Loss: 0.0297\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [11/1000], Validation Loss: 0.0297\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [12/1000], Validation Loss: 0.0297\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [13/1000], Validation Loss: 0.0297\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [14/1000], Validation Loss: 0.0297\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [15/1000], Validation Loss: 0.0297\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [16/1000], Validation Loss: 0.0297\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [17/1000], Validation Loss: 0.0297\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [18/1000], Validation Loss: 0.0297\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [19/1000], Validation Loss: 0.0297\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [20/1000], Validation Loss: 0.0297\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [21/1000], Validation Loss: 0.0297\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [22/1000], Validation Loss: 0.0297\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [23/1000], Validation Loss: 0.0297\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [24/1000], Validation Loss: 0.0297\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [25/1000], Validation Loss: 0.0297\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [26/1000], Validation Loss: 0.0297\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [27/1000], Validation Loss: 0.0297\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [28/1000], Validation Loss: 0.0297\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [29/1000], Validation Loss: 0.0297\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [30/1000], Validation Loss: 0.0297\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [31/1000], Validation Loss: 0.0297\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [32/1000], Validation Loss: 0.0297\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [33/1000], Validation Loss: 0.0297\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [34/1000], Validation Loss: 0.0297\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [35/1000], Validation Loss: 0.0297\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [36/1000], Validation Loss: 0.0297\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [37/1000], Validation Loss: 0.0297\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [38/1000], Validation Loss: 0.0297\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [39/1000], Validation Loss: 0.0297\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [40/1000], Validation Loss: 0.0297\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [41/1000], Validation Loss: 0.0297\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [42/1000], Validation Loss: 0.0297\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [43/1000], Validation Loss: 0.0297\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [44/1000], Validation Loss: 0.0297\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [45/1000], Validation Loss: 0.0297\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [46/1000], Validation Loss: 0.0297\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [47/1000], Validation Loss: 0.0297\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [48/1000], Validation Loss: 0.0297\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [49/1000], Validation Loss: 0.0297\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [50/1000], Validation Loss: 0.0297\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [51/1000], Validation Loss: 0.0297\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [52/1000], Validation Loss: 0.0297\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [53/1000], Validation Loss: 0.0297\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [54/1000], Validation Loss: 0.0297\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [55/1000], Validation Loss: 0.0297\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [56/1000], Validation Loss: 0.0297\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [57/1000], Validation Loss: 0.0297\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [58/1000], Validation Loss: 0.0297\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [59/1000], Validation Loss: 0.0297\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [60/1000], Validation Loss: 0.0297\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [61/1000], Validation Loss: 0.0297\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [62/1000], Validation Loss: 0.0297\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [63/1000], Validation Loss: 0.0297\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [64/1000], Validation Loss: 0.0297\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [65/1000], Validation Loss: 0.0297\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [66/1000], Validation Loss: 0.0297\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [67/1000], Validation Loss: 0.0297\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [68/1000], Validation Loss: 0.0297\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [69/1000], Validation Loss: 0.0297\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [70/1000], Validation Loss: 0.0297\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [71/1000], Validation Loss: 0.0297\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [72/1000], Validation Loss: 0.0297\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [73/1000], Validation Loss: 0.0297\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [74/1000], Validation Loss: 0.0297\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [75/1000], Validation Loss: 0.0297\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [76/1000], Validation Loss: 0.0297\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [77/1000], Validation Loss: 0.0297\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [78/1000], Validation Loss: 0.0297\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [79/1000], Validation Loss: 0.0297\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [80/1000], Validation Loss: 0.0297\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [81/1000], Validation Loss: 0.0297\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [82/1000], Validation Loss: 0.0297\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [83/1000], Validation Loss: 0.0297\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [84/1000], Validation Loss: 0.0297\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [85/1000], Validation Loss: 0.0297\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [86/1000], Validation Loss: 0.0297\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [87/1000], Validation Loss: 0.0297\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [88/1000], Validation Loss: 0.0297\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [89/1000], Validation Loss: 0.0297\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [90/1000], Validation Loss: 0.0297\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [91/1000], Validation Loss: 0.0297\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [92/1000], Validation Loss: 0.0297\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [93/1000], Validation Loss: 0.0297\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [94/1000], Validation Loss: 0.0297\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [95/1000], Validation Loss: 0.0297\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [96/1000], Validation Loss: 0.0297\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [97/1000], Validation Loss: 0.0297\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [98/1000], Validation Loss: 0.0297\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [99/1000], Validation Loss: 0.0297\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [100/1000], Validation Loss: 0.0297\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [101/1000], Validation Loss: 0.0297\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [102/1000], Validation Loss: 0.0297\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [103/1000], Validation Loss: 0.0297\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [104/1000], Validation Loss: 0.0297\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [105/1000], Validation Loss: 0.0297\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [106/1000], Validation Loss: 0.0297\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [107/1000], Validation Loss: 0.0297\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [108/1000], Validation Loss: 0.0297\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [109/1000], Validation Loss: 0.0297\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [110/1000], Validation Loss: 0.0297\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [111/1000], Validation Loss: 0.0297\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [112/1000], Validation Loss: 0.0297\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [113/1000], Validation Loss: 0.0297\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [114/1000], Validation Loss: 0.0297\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [115/1000], Validation Loss: 0.0297\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [116/1000], Validation Loss: 0.0297\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [117/1000], Validation Loss: 0.0297\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [118/1000], Validation Loss: 0.0297\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [119/1000], Validation Loss: 0.0297\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [120/1000], Validation Loss: 0.0297\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [121/1000], Validation Loss: 0.0297\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [122/1000], Validation Loss: 0.0297\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [123/1000], Validation Loss: 0.0297\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [124/1000], Validation Loss: 0.0297\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [125/1000], Validation Loss: 0.0297\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [126/1000], Validation Loss: 0.0297\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [127/1000], Validation Loss: 0.0297\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [128/1000], Validation Loss: 0.0297\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [129/1000], Validation Loss: 0.0297\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [130/1000], Validation Loss: 0.0297\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [131/1000], Validation Loss: 0.0297\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [132/1000], Validation Loss: 0.0297\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [133/1000], Validation Loss: 0.0297\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [134/1000], Validation Loss: 0.0297\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [135/1000], Validation Loss: 0.0297\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [136/1000], Validation Loss: 0.0297\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [137/1000], Validation Loss: 0.0297\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [138/1000], Validation Loss: 0.0297\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [139/1000], Validation Loss: 0.0297\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [140/1000], Validation Loss: 0.0297\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [141/1000], Validation Loss: 0.0297\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [142/1000], Validation Loss: 0.0297\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [143/1000], Validation Loss: 0.0297\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [144/1000], Validation Loss: 0.0297\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [145/1000], Validation Loss: 0.0297\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [146/1000], Validation Loss: 0.0297\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [147/1000], Validation Loss: 0.0297\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [148/1000], Validation Loss: 0.0297\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [149/1000], Validation Loss: 0.0297\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [150/1000], Validation Loss: 0.0297\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [151/1000], Validation Loss: 0.0297\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [152/1000], Validation Loss: 0.0297\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [153/1000], Validation Loss: 0.0297\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [154/1000], Validation Loss: 0.0297\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [155/1000], Validation Loss: 0.0297\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [156/1000], Validation Loss: 0.0297\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [157/1000], Validation Loss: 0.0297\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [158/1000], Validation Loss: 0.0297\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [159/1000], Validation Loss: 0.0297\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [160/1000], Validation Loss: 0.0297\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [161/1000], Validation Loss: 0.0297\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [162/1000], Validation Loss: 0.0297\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [163/1000], Validation Loss: 0.0297\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [164/1000], Validation Loss: 0.0297\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [165/1000], Validation Loss: 0.0297\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [166/1000], Validation Loss: 0.0297\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [167/1000], Validation Loss: 0.0297\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [168/1000], Validation Loss: 0.0297\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [169/1000], Validation Loss: 0.0297\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [170/1000], Validation Loss: 0.0297\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [171/1000], Validation Loss: 0.0297\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [172/1000], Validation Loss: 0.0297\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [173/1000], Validation Loss: 0.0297\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [174/1000], Validation Loss: 0.0297\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [175/1000], Validation Loss: 0.0297\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [176/1000], Validation Loss: 0.0297\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [177/1000], Validation Loss: 0.0297\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [178/1000], Validation Loss: 0.0297\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [179/1000], Validation Loss: 0.0297\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [180/1000], Validation Loss: 0.0297\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [181/1000], Validation Loss: 0.0297\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [182/1000], Validation Loss: 0.0297\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [183/1000], Validation Loss: 0.0297\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [184/1000], Validation Loss: 0.0297\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [185/1000], Validation Loss: 0.0297\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [186/1000], Validation Loss: 0.0297\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [187/1000], Validation Loss: 0.0297\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [188/1000], Validation Loss: 0.0297\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [189/1000], Validation Loss: 0.0297\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [190/1000], Validation Loss: 0.0297\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [191/1000], Validation Loss: 0.0297\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [192/1000], Validation Loss: 0.0297\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [193/1000], Validation Loss: 0.0297\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [194/1000], Validation Loss: 0.0297\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [195/1000], Validation Loss: 0.0297\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [196/1000], Validation Loss: 0.0297\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [197/1000], Validation Loss: 0.0297\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [198/1000], Validation Loss: 0.0297\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [199/1000], Validation Loss: 0.0297\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [200/1000], Validation Loss: 0.0297\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [201/1000], Validation Loss: 0.0297\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [202/1000], Validation Loss: 0.0297\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [203/1000], Validation Loss: 0.0297\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [204/1000], Validation Loss: 0.0297\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [205/1000], Validation Loss: 0.0297\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [206/1000], Validation Loss: 0.0297\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [207/1000], Validation Loss: 0.0297\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [208/1000], Validation Loss: 0.0297\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [209/1000], Validation Loss: 0.0297\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [210/1000], Validation Loss: 0.0297\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [211/1000], Validation Loss: 0.0297\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [212/1000], Validation Loss: 0.0297\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [213/1000], Validation Loss: 0.0297\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [214/1000], Validation Loss: 0.0297\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [215/1000], Validation Loss: 0.0297\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0285\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [216/1000], Validation Loss: 0.0297\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [217/1000], Validation Loss: 0.0297\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [218/1000], Validation Loss: 0.0297\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [219/1000], Validation Loss: 0.0297\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [220/1000], Validation Loss: 0.0297\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [221/1000], Validation Loss: 0.0297\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [222/1000], Validation Loss: 0.0297\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [223/1000], Validation Loss: 0.0297\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [224/1000], Validation Loss: 0.0297\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [225/1000], Validation Loss: 0.0297\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [226/1000], Validation Loss: 0.0297\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [227/1000], Validation Loss: 0.0297\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [228/1000], Validation Loss: 0.0297\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [229/1000], Validation Loss: 0.0297\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [230/1000], Validation Loss: 0.0297\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [231/1000], Validation Loss: 0.0297\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [232/1000], Validation Loss: 0.0297\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [233/1000], Validation Loss: 0.0297\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [234/1000], Validation Loss: 0.0297\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [235/1000], Validation Loss: 0.0297\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [236/1000], Validation Loss: 0.0297\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [237/1000], Validation Loss: 0.0297\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [238/1000], Validation Loss: 0.0297\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [239/1000], Validation Loss: 0.0297\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [240/1000], Validation Loss: 0.0297\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [241/1000], Validation Loss: 0.0297\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [242/1000], Validation Loss: 0.0297\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [243/1000], Validation Loss: 0.0297\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [244/1000], Validation Loss: 0.0297\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [245/1000], Validation Loss: 0.0297\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [246/1000], Validation Loss: 0.0297\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [247/1000], Validation Loss: 0.0297\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [248/1000], Validation Loss: 0.0297\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [249/1000], Validation Loss: 0.0297\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [250/1000], Validation Loss: 0.0297\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [251/1000], Validation Loss: 0.0297\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [252/1000], Validation Loss: 0.0297\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [253/1000], Validation Loss: 0.0297\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [254/1000], Validation Loss: 0.0297\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0284\n",
            "Epoch [255/1000], Validation Loss: 0.0297\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [256/1000], Validation Loss: 0.0297\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [257/1000], Validation Loss: 0.0297\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [258/1000], Validation Loss: 0.0297\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [259/1000], Validation Loss: 0.0297\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [260/1000], Validation Loss: 0.0297\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [261/1000], Validation Loss: 0.0297\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [262/1000], Validation Loss: 0.0297\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [263/1000], Validation Loss: 0.0297\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [264/1000], Validation Loss: 0.0297\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [265/1000], Validation Loss: 0.0297\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [266/1000], Validation Loss: 0.0297\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [267/1000], Validation Loss: 0.0297\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [268/1000], Validation Loss: 0.0297\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [269/1000], Validation Loss: 0.0297\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [270/1000], Validation Loss: 0.0297\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [271/1000], Validation Loss: 0.0297\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [272/1000], Validation Loss: 0.0297\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [273/1000], Validation Loss: 0.0297\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [274/1000], Validation Loss: 0.0297\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [275/1000], Validation Loss: 0.0297\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [276/1000], Validation Loss: 0.0297\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [277/1000], Validation Loss: 0.0297\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [278/1000], Validation Loss: 0.0297\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [279/1000], Validation Loss: 0.0297\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [280/1000], Validation Loss: 0.0297\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [281/1000], Validation Loss: 0.0297\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [282/1000], Validation Loss: 0.0297\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [283/1000], Validation Loss: 0.0297\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [284/1000], Validation Loss: 0.0297\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [285/1000], Validation Loss: 0.0297\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [286/1000], Validation Loss: 0.0297\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [287/1000], Validation Loss: 0.0297\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [288/1000], Validation Loss: 0.0297\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [289/1000], Validation Loss: 0.0297\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [290/1000], Validation Loss: 0.0297\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [291/1000], Validation Loss: 0.0297\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [292/1000], Validation Loss: 0.0297\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [293/1000], Validation Loss: 0.0297\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [294/1000], Validation Loss: 0.0297\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [295/1000], Validation Loss: 0.0297\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [296/1000], Validation Loss: 0.0297\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [297/1000], Validation Loss: 0.0297\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [298/1000], Validation Loss: 0.0297\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [299/1000], Validation Loss: 0.0297\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [300/1000], Validation Loss: 0.0297\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [301/1000], Validation Loss: 0.0297\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [302/1000], Validation Loss: 0.0297\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [303/1000], Validation Loss: 0.0297\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [304/1000], Validation Loss: 0.0297\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [305/1000], Validation Loss: 0.0297\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [306/1000], Validation Loss: 0.0297\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [307/1000], Validation Loss: 0.0297\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [308/1000], Validation Loss: 0.0297\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [309/1000], Validation Loss: 0.0297\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [310/1000], Validation Loss: 0.0297\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [311/1000], Validation Loss: 0.0297\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [312/1000], Validation Loss: 0.0297\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [313/1000], Validation Loss: 0.0297\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [314/1000], Validation Loss: 0.0297\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [315/1000], Validation Loss: 0.0297\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [316/1000], Validation Loss: 0.0297\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [317/1000], Validation Loss: 0.0297\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [318/1000], Validation Loss: 0.0297\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [319/1000], Validation Loss: 0.0297\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [320/1000], Validation Loss: 0.0297\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [321/1000], Validation Loss: 0.0297\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [322/1000], Validation Loss: 0.0297\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [323/1000], Validation Loss: 0.0297\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [324/1000], Validation Loss: 0.0297\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [325/1000], Validation Loss: 0.0297\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [326/1000], Validation Loss: 0.0297\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [327/1000], Validation Loss: 0.0297\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [328/1000], Validation Loss: 0.0297\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [329/1000], Validation Loss: 0.0297\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [330/1000], Validation Loss: 0.0297\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [331/1000], Validation Loss: 0.0297\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [332/1000], Validation Loss: 0.0297\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [333/1000], Validation Loss: 0.0297\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [334/1000], Validation Loss: 0.0297\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [335/1000], Validation Loss: 0.0297\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [336/1000], Validation Loss: 0.0297\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [337/1000], Validation Loss: 0.0297\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [338/1000], Validation Loss: 0.0297\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [339/1000], Validation Loss: 0.0297\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [340/1000], Validation Loss: 0.0297\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [341/1000], Validation Loss: 0.0297\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [342/1000], Validation Loss: 0.0297\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [343/1000], Validation Loss: 0.0297\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [344/1000], Validation Loss: 0.0297\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [345/1000], Validation Loss: 0.0297\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [346/1000], Validation Loss: 0.0297\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [347/1000], Validation Loss: 0.0297\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [348/1000], Validation Loss: 0.0297\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [349/1000], Validation Loss: 0.0297\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [350/1000], Validation Loss: 0.0297\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [351/1000], Validation Loss: 0.0297\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [352/1000], Validation Loss: 0.0297\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [353/1000], Validation Loss: 0.0297\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [354/1000], Validation Loss: 0.0297\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [355/1000], Validation Loss: 0.0297\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [356/1000], Validation Loss: 0.0297\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [357/1000], Validation Loss: 0.0297\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [358/1000], Validation Loss: 0.0297\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [359/1000], Validation Loss: 0.0297\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [360/1000], Validation Loss: 0.0297\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [361/1000], Validation Loss: 0.0297\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [362/1000], Validation Loss: 0.0297\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [363/1000], Validation Loss: 0.0297\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [364/1000], Validation Loss: 0.0297\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [365/1000], Validation Loss: 0.0297\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [366/1000], Validation Loss: 0.0297\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [367/1000], Validation Loss: 0.0297\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [368/1000], Validation Loss: 0.0297\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [369/1000], Validation Loss: 0.0297\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [370/1000], Validation Loss: 0.0297\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [371/1000], Validation Loss: 0.0297\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [372/1000], Validation Loss: 0.0297\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [373/1000], Validation Loss: 0.0297\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [374/1000], Validation Loss: 0.0297\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [375/1000], Validation Loss: 0.0297\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [376/1000], Validation Loss: 0.0297\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [377/1000], Validation Loss: 0.0297\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [378/1000], Validation Loss: 0.0297\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [379/1000], Validation Loss: 0.0297\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [380/1000], Validation Loss: 0.0297\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [381/1000], Validation Loss: 0.0297\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [382/1000], Validation Loss: 0.0297\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [383/1000], Validation Loss: 0.0297\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [384/1000], Validation Loss: 0.0297\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [385/1000], Validation Loss: 0.0297\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [386/1000], Validation Loss: 0.0297\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [387/1000], Validation Loss: 0.0297\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [388/1000], Validation Loss: 0.0297\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [389/1000], Validation Loss: 0.0297\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [390/1000], Validation Loss: 0.0297\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [391/1000], Validation Loss: 0.0297\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [392/1000], Validation Loss: 0.0297\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [393/1000], Validation Loss: 0.0297\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [394/1000], Validation Loss: 0.0297\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [395/1000], Validation Loss: 0.0297\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [396/1000], Validation Loss: 0.0297\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [397/1000], Validation Loss: 0.0297\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [398/1000], Validation Loss: 0.0297\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [399/1000], Validation Loss: 0.0297\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [400/1000], Validation Loss: 0.0297\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [401/1000], Validation Loss: 0.0297\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [402/1000], Validation Loss: 0.0297\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [403/1000], Validation Loss: 0.0297\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [404/1000], Validation Loss: 0.0297\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [405/1000], Validation Loss: 0.0297\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [406/1000], Validation Loss: 0.0297\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [407/1000], Validation Loss: 0.0297\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [408/1000], Validation Loss: 0.0297\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [409/1000], Validation Loss: 0.0297\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [410/1000], Validation Loss: 0.0297\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [411/1000], Validation Loss: 0.0297\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [412/1000], Validation Loss: 0.0297\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [413/1000], Validation Loss: 0.0297\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [414/1000], Validation Loss: 0.0297\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [415/1000], Validation Loss: 0.0297\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [416/1000], Validation Loss: 0.0297\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [417/1000], Validation Loss: 0.0297\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [418/1000], Validation Loss: 0.0297\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [419/1000], Validation Loss: 0.0297\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [420/1000], Validation Loss: 0.0297\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [421/1000], Validation Loss: 0.0297\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [422/1000], Validation Loss: 0.0297\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [423/1000], Validation Loss: 0.0297\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [424/1000], Validation Loss: 0.0297\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [425/1000], Validation Loss: 0.0297\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [426/1000], Validation Loss: 0.0297\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [427/1000], Validation Loss: 0.0297\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [428/1000], Validation Loss: 0.0297\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [429/1000], Validation Loss: 0.0297\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [430/1000], Validation Loss: 0.0297\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [431/1000], Validation Loss: 0.0297\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [432/1000], Validation Loss: 0.0297\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [433/1000], Validation Loss: 0.0297\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [434/1000], Validation Loss: 0.0297\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [435/1000], Validation Loss: 0.0297\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [436/1000], Validation Loss: 0.0297\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [437/1000], Validation Loss: 0.0297\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [438/1000], Validation Loss: 0.0297\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [439/1000], Validation Loss: 0.0297\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [440/1000], Validation Loss: 0.0297\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [441/1000], Validation Loss: 0.0297\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [442/1000], Validation Loss: 0.0297\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [443/1000], Validation Loss: 0.0297\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [444/1000], Validation Loss: 0.0297\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [445/1000], Validation Loss: 0.0297\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [446/1000], Validation Loss: 0.0297\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [447/1000], Validation Loss: 0.0297\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [448/1000], Validation Loss: 0.0297\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [449/1000], Validation Loss: 0.0297\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [450/1000], Validation Loss: 0.0297\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [451/1000], Validation Loss: 0.0297\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [452/1000], Validation Loss: 0.0297\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [453/1000], Validation Loss: 0.0297\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [454/1000], Validation Loss: 0.0297\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [455/1000], Validation Loss: 0.0297\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [456/1000], Validation Loss: 0.0297\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [457/1000], Validation Loss: 0.0297\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [458/1000], Validation Loss: 0.0297\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [459/1000], Validation Loss: 0.0297\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [460/1000], Validation Loss: 0.0297\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [461/1000], Validation Loss: 0.0297\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [462/1000], Validation Loss: 0.0297\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [463/1000], Validation Loss: 0.0297\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [464/1000], Validation Loss: 0.0297\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [465/1000], Validation Loss: 0.0297\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [466/1000], Validation Loss: 0.0297\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [467/1000], Validation Loss: 0.0297\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [468/1000], Validation Loss: 0.0297\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [469/1000], Validation Loss: 0.0297\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [470/1000], Validation Loss: 0.0297\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [471/1000], Validation Loss: 0.0297\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [472/1000], Validation Loss: 0.0297\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [473/1000], Validation Loss: 0.0297\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [474/1000], Validation Loss: 0.0297\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [475/1000], Validation Loss: 0.0297\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [476/1000], Validation Loss: 0.0297\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [477/1000], Validation Loss: 0.0297\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [478/1000], Validation Loss: 0.0297\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [479/1000], Validation Loss: 0.0297\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [480/1000], Validation Loss: 0.0297\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [481/1000], Validation Loss: 0.0297\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [482/1000], Validation Loss: 0.0297\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [483/1000], Validation Loss: 0.0297\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [484/1000], Validation Loss: 0.0297\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [485/1000], Validation Loss: 0.0297\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [486/1000], Validation Loss: 0.0297\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [487/1000], Validation Loss: 0.0297\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [488/1000], Validation Loss: 0.0297\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [489/1000], Validation Loss: 0.0297\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [490/1000], Validation Loss: 0.0297\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [491/1000], Validation Loss: 0.0297\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [492/1000], Validation Loss: 0.0297\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [493/1000], Validation Loss: 0.0297\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [494/1000], Validation Loss: 0.0297\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [495/1000], Validation Loss: 0.0297\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [496/1000], Validation Loss: 0.0297\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [497/1000], Validation Loss: 0.0297\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [498/1000], Validation Loss: 0.0297\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [499/1000], Validation Loss: 0.0297\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [500/1000], Validation Loss: 0.0297\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [501/1000], Validation Loss: 0.0297\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [502/1000], Validation Loss: 0.0297\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [503/1000], Validation Loss: 0.0297\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [504/1000], Validation Loss: 0.0297\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [505/1000], Validation Loss: 0.0297\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [506/1000], Validation Loss: 0.0297\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [507/1000], Validation Loss: 0.0297\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [508/1000], Validation Loss: 0.0297\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [509/1000], Validation Loss: 0.0297\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [510/1000], Validation Loss: 0.0297\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [511/1000], Validation Loss: 0.0297\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [512/1000], Validation Loss: 0.0297\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [513/1000], Validation Loss: 0.0297\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [514/1000], Validation Loss: 0.0297\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [515/1000], Validation Loss: 0.0297\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [516/1000], Validation Loss: 0.0297\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [517/1000], Validation Loss: 0.0297\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [518/1000], Validation Loss: 0.0297\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [519/1000], Validation Loss: 0.0297\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [520/1000], Validation Loss: 0.0297\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [521/1000], Validation Loss: 0.0297\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [522/1000], Validation Loss: 0.0297\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [523/1000], Validation Loss: 0.0297\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [524/1000], Validation Loss: 0.0297\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [525/1000], Validation Loss: 0.0297\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [526/1000], Validation Loss: 0.0297\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [527/1000], Validation Loss: 0.0297\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [528/1000], Validation Loss: 0.0297\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [529/1000], Validation Loss: 0.0297\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [530/1000], Validation Loss: 0.0297\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [531/1000], Validation Loss: 0.0297\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [532/1000], Validation Loss: 0.0297\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [533/1000], Validation Loss: 0.0297\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [534/1000], Validation Loss: 0.0297\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [535/1000], Validation Loss: 0.0297\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [536/1000], Validation Loss: 0.0297\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [537/1000], Validation Loss: 0.0297\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [538/1000], Validation Loss: 0.0297\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [539/1000], Validation Loss: 0.0297\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [540/1000], Validation Loss: 0.0297\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [541/1000], Validation Loss: 0.0297\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [542/1000], Validation Loss: 0.0297\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [543/1000], Validation Loss: 0.0297\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [544/1000], Validation Loss: 0.0297\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [545/1000], Validation Loss: 0.0297\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [546/1000], Validation Loss: 0.0297\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [547/1000], Validation Loss: 0.0297\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [548/1000], Validation Loss: 0.0297\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [549/1000], Validation Loss: 0.0297\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [550/1000], Validation Loss: 0.0297\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [551/1000], Validation Loss: 0.0297\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [552/1000], Validation Loss: 0.0297\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [553/1000], Validation Loss: 0.0297\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [554/1000], Validation Loss: 0.0297\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [555/1000], Validation Loss: 0.0297\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [556/1000], Validation Loss: 0.0297\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [557/1000], Validation Loss: 0.0297\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [558/1000], Validation Loss: 0.0297\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [559/1000], Validation Loss: 0.0297\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [560/1000], Validation Loss: 0.0297\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [561/1000], Validation Loss: 0.0297\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [562/1000], Validation Loss: 0.0297\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [563/1000], Validation Loss: 0.0297\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [564/1000], Validation Loss: 0.0297\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [565/1000], Validation Loss: 0.0297\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [566/1000], Validation Loss: 0.0297\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [567/1000], Validation Loss: 0.0297\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [568/1000], Validation Loss: 0.0297\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [569/1000], Validation Loss: 0.0297\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [570/1000], Validation Loss: 0.0297\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [571/1000], Validation Loss: 0.0297\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [572/1000], Validation Loss: 0.0297\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [573/1000], Validation Loss: 0.0297\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [574/1000], Validation Loss: 0.0297\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [575/1000], Validation Loss: 0.0297\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [576/1000], Validation Loss: 0.0297\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [577/1000], Validation Loss: 0.0297\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [578/1000], Validation Loss: 0.0297\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [579/1000], Validation Loss: 0.0297\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [580/1000], Validation Loss: 0.0297\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [581/1000], Validation Loss: 0.0297\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [582/1000], Validation Loss: 0.0297\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [583/1000], Validation Loss: 0.0297\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [584/1000], Validation Loss: 0.0297\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [585/1000], Validation Loss: 0.0297\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [586/1000], Validation Loss: 0.0297\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [587/1000], Validation Loss: 0.0297\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [588/1000], Validation Loss: 0.0297\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [589/1000], Validation Loss: 0.0297\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [590/1000], Validation Loss: 0.0297\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [591/1000], Validation Loss: 0.0297\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [592/1000], Validation Loss: 0.0297\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [593/1000], Validation Loss: 0.0297\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [594/1000], Validation Loss: 0.0297\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [595/1000], Validation Loss: 0.0297\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [596/1000], Validation Loss: 0.0297\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [597/1000], Validation Loss: 0.0297\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [598/1000], Validation Loss: 0.0297\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [599/1000], Validation Loss: 0.0297\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [600/1000], Validation Loss: 0.0297\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [601/1000], Validation Loss: 0.0297\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [602/1000], Validation Loss: 0.0297\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [603/1000], Validation Loss: 0.0297\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [604/1000], Validation Loss: 0.0297\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [605/1000], Validation Loss: 0.0297\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [606/1000], Validation Loss: 0.0297\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [607/1000], Validation Loss: 0.0297\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [608/1000], Validation Loss: 0.0297\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [609/1000], Validation Loss: 0.0297\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [610/1000], Validation Loss: 0.0297\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [611/1000], Validation Loss: 0.0297\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [612/1000], Validation Loss: 0.0297\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [613/1000], Validation Loss: 0.0297\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [614/1000], Validation Loss: 0.0297\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [615/1000], Validation Loss: 0.0297\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [616/1000], Validation Loss: 0.0297\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [617/1000], Validation Loss: 0.0297\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [618/1000], Validation Loss: 0.0297\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [619/1000], Validation Loss: 0.0297\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [620/1000], Validation Loss: 0.0297\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [621/1000], Validation Loss: 0.0297\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [622/1000], Validation Loss: 0.0297\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [623/1000], Validation Loss: 0.0297\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [624/1000], Validation Loss: 0.0297\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [625/1000], Validation Loss: 0.0297\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [626/1000], Validation Loss: 0.0297\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [627/1000], Validation Loss: 0.0297\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [628/1000], Validation Loss: 0.0297\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [629/1000], Validation Loss: 0.0297\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [630/1000], Validation Loss: 0.0297\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [631/1000], Validation Loss: 0.0297\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [632/1000], Validation Loss: 0.0297\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [633/1000], Validation Loss: 0.0297\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [634/1000], Validation Loss: 0.0297\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [635/1000], Validation Loss: 0.0297\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [636/1000], Validation Loss: 0.0297\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [637/1000], Validation Loss: 0.0297\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [638/1000], Validation Loss: 0.0297\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [639/1000], Validation Loss: 0.0297\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [640/1000], Validation Loss: 0.0297\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [641/1000], Validation Loss: 0.0297\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [642/1000], Validation Loss: 0.0297\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [643/1000], Validation Loss: 0.0297\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [644/1000], Validation Loss: 0.0297\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [645/1000], Validation Loss: 0.0297\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [646/1000], Validation Loss: 0.0297\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [647/1000], Validation Loss: 0.0297\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [648/1000], Validation Loss: 0.0297\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [649/1000], Validation Loss: 0.0297\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [650/1000], Validation Loss: 0.0297\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [651/1000], Validation Loss: 0.0297\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [652/1000], Validation Loss: 0.0297\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [653/1000], Validation Loss: 0.0297\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [654/1000], Validation Loss: 0.0297\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [655/1000], Validation Loss: 0.0297\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [656/1000], Validation Loss: 0.0297\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [657/1000], Validation Loss: 0.0297\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [658/1000], Validation Loss: 0.0297\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [659/1000], Validation Loss: 0.0297\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [660/1000], Validation Loss: 0.0297\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [661/1000], Validation Loss: 0.0297\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [662/1000], Validation Loss: 0.0297\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [663/1000], Validation Loss: 0.0297\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [664/1000], Validation Loss: 0.0297\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [665/1000], Validation Loss: 0.0297\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [666/1000], Validation Loss: 0.0297\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [667/1000], Validation Loss: 0.0297\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [668/1000], Validation Loss: 0.0297\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [669/1000], Validation Loss: 0.0297\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [670/1000], Validation Loss: 0.0297\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [671/1000], Validation Loss: 0.0297\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [672/1000], Validation Loss: 0.0297\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [673/1000], Validation Loss: 0.0297\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [674/1000], Validation Loss: 0.0297\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [675/1000], Validation Loss: 0.0297\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [676/1000], Validation Loss: 0.0297\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [677/1000], Validation Loss: 0.0297\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [678/1000], Validation Loss: 0.0297\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [679/1000], Validation Loss: 0.0297\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [680/1000], Validation Loss: 0.0297\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [681/1000], Validation Loss: 0.0297\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [682/1000], Validation Loss: 0.0297\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [683/1000], Validation Loss: 0.0297\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [684/1000], Validation Loss: 0.0297\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [685/1000], Validation Loss: 0.0297\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [686/1000], Validation Loss: 0.0297\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [687/1000], Validation Loss: 0.0297\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [688/1000], Validation Loss: 0.0297\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [689/1000], Validation Loss: 0.0297\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [690/1000], Validation Loss: 0.0297\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [691/1000], Validation Loss: 0.0297\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [692/1000], Validation Loss: 0.0297\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [693/1000], Validation Loss: 0.0297\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [694/1000], Validation Loss: 0.0297\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [695/1000], Validation Loss: 0.0297\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [696/1000], Validation Loss: 0.0297\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [697/1000], Validation Loss: 0.0297\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [698/1000], Validation Loss: 0.0297\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [699/1000], Validation Loss: 0.0297\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [700/1000], Validation Loss: 0.0297\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [701/1000], Validation Loss: 0.0297\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [702/1000], Validation Loss: 0.0297\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [703/1000], Validation Loss: 0.0297\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [704/1000], Validation Loss: 0.0297\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [705/1000], Validation Loss: 0.0297\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [706/1000], Validation Loss: 0.0297\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [707/1000], Validation Loss: 0.0297\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [708/1000], Validation Loss: 0.0297\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [709/1000], Validation Loss: 0.0297\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [710/1000], Validation Loss: 0.0297\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [711/1000], Validation Loss: 0.0297\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [712/1000], Validation Loss: 0.0297\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [713/1000], Validation Loss: 0.0297\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [714/1000], Validation Loss: 0.0297\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [715/1000], Validation Loss: 0.0297\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [716/1000], Validation Loss: 0.0297\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [717/1000], Validation Loss: 0.0297\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [718/1000], Validation Loss: 0.0297\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [719/1000], Validation Loss: 0.0297\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [720/1000], Validation Loss: 0.0297\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [721/1000], Validation Loss: 0.0297\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [722/1000], Validation Loss: 0.0297\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [723/1000], Validation Loss: 0.0297\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [724/1000], Validation Loss: 0.0297\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [725/1000], Validation Loss: 0.0297\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [726/1000], Validation Loss: 0.0297\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [727/1000], Validation Loss: 0.0297\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [728/1000], Validation Loss: 0.0297\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [729/1000], Validation Loss: 0.0297\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [730/1000], Validation Loss: 0.0297\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [731/1000], Validation Loss: 0.0297\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [732/1000], Validation Loss: 0.0297\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [733/1000], Validation Loss: 0.0297\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [734/1000], Validation Loss: 0.0297\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [735/1000], Validation Loss: 0.0297\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [736/1000], Validation Loss: 0.0297\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [737/1000], Validation Loss: 0.0297\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [738/1000], Validation Loss: 0.0297\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [739/1000], Validation Loss: 0.0297\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [740/1000], Validation Loss: 0.0297\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [741/1000], Validation Loss: 0.0297\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [742/1000], Validation Loss: 0.0297\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [743/1000], Validation Loss: 0.0297\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [744/1000], Validation Loss: 0.0297\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [745/1000], Validation Loss: 0.0297\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [746/1000], Validation Loss: 0.0297\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [747/1000], Validation Loss: 0.0297\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [748/1000], Validation Loss: 0.0297\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [749/1000], Validation Loss: 0.0297\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [750/1000], Validation Loss: 0.0297\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [751/1000], Validation Loss: 0.0297\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [752/1000], Validation Loss: 0.0297\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [753/1000], Validation Loss: 0.0297\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [754/1000], Validation Loss: 0.0297\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [755/1000], Validation Loss: 0.0297\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [756/1000], Validation Loss: 0.0297\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [757/1000], Validation Loss: 0.0297\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [758/1000], Validation Loss: 0.0297\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [759/1000], Validation Loss: 0.0297\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [760/1000], Validation Loss: 0.0297\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [761/1000], Validation Loss: 0.0297\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [762/1000], Validation Loss: 0.0297\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [763/1000], Validation Loss: 0.0297\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [764/1000], Validation Loss: 0.0297\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [765/1000], Validation Loss: 0.0297\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [766/1000], Validation Loss: 0.0297\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [767/1000], Validation Loss: 0.0297\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [768/1000], Validation Loss: 0.0297\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [769/1000], Validation Loss: 0.0297\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [770/1000], Validation Loss: 0.0297\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [771/1000], Validation Loss: 0.0297\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [772/1000], Validation Loss: 0.0297\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [773/1000], Validation Loss: 0.0297\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [774/1000], Validation Loss: 0.0297\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [775/1000], Validation Loss: 0.0297\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [776/1000], Validation Loss: 0.0297\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [777/1000], Validation Loss: 0.0297\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [778/1000], Validation Loss: 0.0297\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [779/1000], Validation Loss: 0.0297\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [780/1000], Validation Loss: 0.0297\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [781/1000], Validation Loss: 0.0297\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [782/1000], Validation Loss: 0.0297\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [783/1000], Validation Loss: 0.0297\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [784/1000], Validation Loss: 0.0297\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [785/1000], Validation Loss: 0.0297\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [786/1000], Validation Loss: 0.0297\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [787/1000], Validation Loss: 0.0297\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [788/1000], Validation Loss: 0.0297\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [789/1000], Validation Loss: 0.0297\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [790/1000], Validation Loss: 0.0297\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [791/1000], Validation Loss: 0.0297\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [792/1000], Validation Loss: 0.0297\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [793/1000], Validation Loss: 0.0297\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [794/1000], Validation Loss: 0.0297\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [795/1000], Validation Loss: 0.0297\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [796/1000], Validation Loss: 0.0297\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [797/1000], Validation Loss: 0.0297\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [798/1000], Validation Loss: 0.0297\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [799/1000], Validation Loss: 0.0297\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [800/1000], Validation Loss: 0.0297\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [801/1000], Validation Loss: 0.0297\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [802/1000], Validation Loss: 0.0297\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [803/1000], Validation Loss: 0.0297\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [804/1000], Validation Loss: 0.0297\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [805/1000], Validation Loss: 0.0297\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [806/1000], Validation Loss: 0.0297\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [807/1000], Validation Loss: 0.0297\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [808/1000], Validation Loss: 0.0297\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [809/1000], Validation Loss: 0.0297\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [810/1000], Validation Loss: 0.0297\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [811/1000], Validation Loss: 0.0297\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [812/1000], Validation Loss: 0.0297\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [813/1000], Validation Loss: 0.0297\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [814/1000], Validation Loss: 0.0297\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [815/1000], Validation Loss: 0.0297\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [816/1000], Validation Loss: 0.0297\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [817/1000], Validation Loss: 0.0297\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [818/1000], Validation Loss: 0.0297\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [819/1000], Validation Loss: 0.0297\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [820/1000], Validation Loss: 0.0297\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [821/1000], Validation Loss: 0.0297\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [822/1000], Validation Loss: 0.0297\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [823/1000], Validation Loss: 0.0297\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [824/1000], Validation Loss: 0.0297\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [825/1000], Validation Loss: 0.0297\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [826/1000], Validation Loss: 0.0297\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [827/1000], Validation Loss: 0.0297\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [828/1000], Validation Loss: 0.0297\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [829/1000], Validation Loss: 0.0297\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [830/1000], Validation Loss: 0.0297\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [831/1000], Validation Loss: 0.0297\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [832/1000], Validation Loss: 0.0297\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [833/1000], Validation Loss: 0.0297\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [834/1000], Validation Loss: 0.0297\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [835/1000], Validation Loss: 0.0297\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [836/1000], Validation Loss: 0.0297\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [837/1000], Validation Loss: 0.0297\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [838/1000], Validation Loss: 0.0297\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [839/1000], Validation Loss: 0.0297\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [840/1000], Validation Loss: 0.0297\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [841/1000], Validation Loss: 0.0297\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [842/1000], Validation Loss: 0.0297\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [843/1000], Validation Loss: 0.0297\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [844/1000], Validation Loss: 0.0297\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [845/1000], Validation Loss: 0.0297\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [846/1000], Validation Loss: 0.0297\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [847/1000], Validation Loss: 0.0297\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [848/1000], Validation Loss: 0.0297\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [849/1000], Validation Loss: 0.0297\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [850/1000], Validation Loss: 0.0297\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0285\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [851/1000], Validation Loss: 0.0297\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [852/1000], Validation Loss: 0.0297\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [853/1000], Validation Loss: 0.0297\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [854/1000], Validation Loss: 0.0297\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [855/1000], Validation Loss: 0.0297\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [856/1000], Validation Loss: 0.0297\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [857/1000], Validation Loss: 0.0297\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [858/1000], Validation Loss: 0.0297\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [859/1000], Validation Loss: 0.0297\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [860/1000], Validation Loss: 0.0297\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [861/1000], Validation Loss: 0.0297\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [862/1000], Validation Loss: 0.0297\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [863/1000], Validation Loss: 0.0297\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [864/1000], Validation Loss: 0.0297\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [865/1000], Validation Loss: 0.0297\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [866/1000], Validation Loss: 0.0297\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [867/1000], Validation Loss: 0.0297\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [868/1000], Validation Loss: 0.0297\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [869/1000], Validation Loss: 0.0297\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [870/1000], Validation Loss: 0.0297\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [871/1000], Validation Loss: 0.0297\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [872/1000], Validation Loss: 0.0297\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [873/1000], Validation Loss: 0.0297\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [874/1000], Validation Loss: 0.0297\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [875/1000], Validation Loss: 0.0297\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [876/1000], Validation Loss: 0.0297\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [877/1000], Validation Loss: 0.0297\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [878/1000], Validation Loss: 0.0297\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [879/1000], Validation Loss: 0.0297\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [880/1000], Validation Loss: 0.0297\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [881/1000], Validation Loss: 0.0297\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [882/1000], Validation Loss: 0.0297\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [883/1000], Validation Loss: 0.0297\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [884/1000], Validation Loss: 0.0297\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [885/1000], Validation Loss: 0.0297\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [886/1000], Validation Loss: 0.0297\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [887/1000], Validation Loss: 0.0297\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [888/1000], Validation Loss: 0.0297\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [889/1000], Validation Loss: 0.0297\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [890/1000], Validation Loss: 0.0297\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [891/1000], Validation Loss: 0.0297\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [892/1000], Validation Loss: 0.0297\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [893/1000], Validation Loss: 0.0297\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [894/1000], Validation Loss: 0.0297\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [895/1000], Validation Loss: 0.0297\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [896/1000], Validation Loss: 0.0297\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [897/1000], Validation Loss: 0.0297\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [898/1000], Validation Loss: 0.0297\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [899/1000], Validation Loss: 0.0297\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [900/1000], Validation Loss: 0.0297\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [901/1000], Validation Loss: 0.0297\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [902/1000], Validation Loss: 0.0297\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [903/1000], Validation Loss: 0.0297\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [904/1000], Validation Loss: 0.0297\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [905/1000], Validation Loss: 0.0297\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [906/1000], Validation Loss: 0.0297\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [907/1000], Validation Loss: 0.0297\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [908/1000], Validation Loss: 0.0297\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [909/1000], Validation Loss: 0.0297\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [910/1000], Validation Loss: 0.0297\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [911/1000], Validation Loss: 0.0297\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [912/1000], Validation Loss: 0.0297\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [913/1000], Validation Loss: 0.0297\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [914/1000], Validation Loss: 0.0297\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [915/1000], Validation Loss: 0.0297\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [916/1000], Validation Loss: 0.0297\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [917/1000], Validation Loss: 0.0297\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [918/1000], Validation Loss: 0.0297\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [919/1000], Validation Loss: 0.0297\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [920/1000], Validation Loss: 0.0297\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [921/1000], Validation Loss: 0.0297\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [922/1000], Validation Loss: 0.0297\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [923/1000], Validation Loss: 0.0297\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [924/1000], Validation Loss: 0.0297\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [925/1000], Validation Loss: 0.0297\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [926/1000], Validation Loss: 0.0297\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [927/1000], Validation Loss: 0.0297\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [928/1000], Validation Loss: 0.0297\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [929/1000], Validation Loss: 0.0297\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [930/1000], Validation Loss: 0.0297\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [931/1000], Validation Loss: 0.0297\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [932/1000], Validation Loss: 0.0297\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [933/1000], Validation Loss: 0.0297\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [934/1000], Validation Loss: 0.0297\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [935/1000], Validation Loss: 0.0297\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [936/1000], Validation Loss: 0.0297\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [937/1000], Validation Loss: 0.0297\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [938/1000], Validation Loss: 0.0297\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [939/1000], Validation Loss: 0.0297\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [940/1000], Validation Loss: 0.0297\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [941/1000], Validation Loss: 0.0297\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [942/1000], Validation Loss: 0.0297\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [943/1000], Validation Loss: 0.0297\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [944/1000], Validation Loss: 0.0297\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [945/1000], Validation Loss: 0.0297\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [946/1000], Validation Loss: 0.0297\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [947/1000], Validation Loss: 0.0297\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [948/1000], Validation Loss: 0.0297\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [949/1000], Validation Loss: 0.0297\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [950/1000], Validation Loss: 0.0297\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [951/1000], Validation Loss: 0.0297\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [952/1000], Validation Loss: 0.0297\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [953/1000], Validation Loss: 0.0297\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [954/1000], Validation Loss: 0.0297\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [955/1000], Validation Loss: 0.0297\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [956/1000], Validation Loss: 0.0297\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [957/1000], Validation Loss: 0.0297\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [958/1000], Validation Loss: 0.0297\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [959/1000], Validation Loss: 0.0297\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [960/1000], Validation Loss: 0.0297\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [961/1000], Validation Loss: 0.0297\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [962/1000], Validation Loss: 0.0297\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [963/1000], Validation Loss: 0.0297\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [964/1000], Validation Loss: 0.0297\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [965/1000], Validation Loss: 0.0297\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [966/1000], Validation Loss: 0.0297\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [967/1000], Validation Loss: 0.0297\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [968/1000], Validation Loss: 0.0297\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [969/1000], Validation Loss: 0.0297\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [970/1000], Validation Loss: 0.0297\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [971/1000], Validation Loss: 0.0297\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [972/1000], Validation Loss: 0.0297\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [973/1000], Validation Loss: 0.0297\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [974/1000], Validation Loss: 0.0297\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [975/1000], Validation Loss: 0.0297\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [976/1000], Validation Loss: 0.0297\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [977/1000], Validation Loss: 0.0297\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [978/1000], Validation Loss: 0.0297\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [979/1000], Validation Loss: 0.0297\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [980/1000], Validation Loss: 0.0297\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [981/1000], Validation Loss: 0.0297\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [982/1000], Validation Loss: 0.0297\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [983/1000], Validation Loss: 0.0297\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [984/1000], Validation Loss: 0.0297\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [985/1000], Validation Loss: 0.0297\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [986/1000], Validation Loss: 0.0297\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [987/1000], Validation Loss: 0.0297\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [988/1000], Validation Loss: 0.0297\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [989/1000], Validation Loss: 0.0297\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [990/1000], Validation Loss: 0.0297\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [991/1000], Validation Loss: 0.0297\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [992/1000], Validation Loss: 0.0297\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [993/1000], Validation Loss: 0.0297\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [994/1000], Validation Loss: 0.0297\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [995/1000], Validation Loss: 0.0297\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [996/1000], Validation Loss: 0.0297\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [997/1000], Validation Loss: 0.0297\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [998/1000], Validation Loss: 0.0297\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [999/1000], Validation Loss: 0.0297\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [1000/1000], Validation Loss: 0.0297\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 3"
      ],
      "metadata": {
        "id": "8v7yjLSS51TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator3(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator3, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator3(Generator3):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, max_grad_norm):\n",
        "          super(DPGenerator3, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "          self.noise_multiplier = nn.Parameter(torch.tensor(1.0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = F.relu(layer(x))\n",
        "            # Add noise proportional to the noise multiplier\n",
        "            noise = torch.randn_like(x) * self.noise_multiplier\n",
        "            x = x + noise  # Use x = x + noise instead of inplace operation x += noise\n",
        "        x = self.layers[-1](x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GhQGwJUW5s05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model3 = DPGenerator3(input_size, hidden_size, output_size, num_layers, max_grad_norm).to(device)\n",
        "model3.noise_multiplier.data.fill_(noise_multiplier)\n",
        "\n",
        "\n",
        "# Define the loss function\n",
        "optimizer3 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion3 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "V5TCXM3o50Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []"
      ],
      "metadata": {
        "id": "VaVk1xZK6Dgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model3.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer3.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model3(real_features)\n",
        "        loss = criterion3(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer3.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model3.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model3(real_features)\n",
        "            loss = criterion3(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bJjjJ0PrGMdm",
        "outputId": "7728e7f3-623e-4c65-e623-58acd21df6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [1/1000], Validation Loss: 0.0315\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [2/1000], Validation Loss: 0.0314\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [3/1000], Validation Loss: 0.0315\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [4/1000], Validation Loss: 0.0314\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [5/1000], Validation Loss: 0.0314\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [6/1000], Validation Loss: 0.0315\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [7/1000], Validation Loss: 0.0315\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [8/1000], Validation Loss: 0.0314\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [9/1000], Validation Loss: 0.0314\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [10/1000], Validation Loss: 0.0315\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [11/1000], Validation Loss: 0.0315\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [12/1000], Validation Loss: 0.0314\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [13/1000], Validation Loss: 0.0314\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [14/1000], Validation Loss: 0.0315\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [15/1000], Validation Loss: 0.0315\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [16/1000], Validation Loss: 0.0315\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [17/1000], Validation Loss: 0.0315\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [18/1000], Validation Loss: 0.0314\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [19/1000], Validation Loss: 0.0314\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [20/1000], Validation Loss: 0.0313\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [21/1000], Validation Loss: 0.0315\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [22/1000], Validation Loss: 0.0315\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [23/1000], Validation Loss: 0.0315\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [24/1000], Validation Loss: 0.0315\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [25/1000], Validation Loss: 0.0315\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [26/1000], Validation Loss: 0.0314\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [27/1000], Validation Loss: 0.0314\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [28/1000], Validation Loss: 0.0314\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [29/1000], Validation Loss: 0.0315\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [30/1000], Validation Loss: 0.0314\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [31/1000], Validation Loss: 0.0315\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [32/1000], Validation Loss: 0.0314\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [33/1000], Validation Loss: 0.0315\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [34/1000], Validation Loss: 0.0314\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [35/1000], Validation Loss: 0.0315\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [36/1000], Validation Loss: 0.0314\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [37/1000], Validation Loss: 0.0315\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [38/1000], Validation Loss: 0.0314\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [39/1000], Validation Loss: 0.0314\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [40/1000], Validation Loss: 0.0315\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [41/1000], Validation Loss: 0.0315\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [42/1000], Validation Loss: 0.0314\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [43/1000], Validation Loss: 0.0315\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [44/1000], Validation Loss: 0.0315\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [45/1000], Validation Loss: 0.0315\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [46/1000], Validation Loss: 0.0315\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [47/1000], Validation Loss: 0.0315\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [48/1000], Validation Loss: 0.0314\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [49/1000], Validation Loss: 0.0315\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [50/1000], Validation Loss: 0.0315\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [51/1000], Validation Loss: 0.0315\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [52/1000], Validation Loss: 0.0314\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [53/1000], Validation Loss: 0.0315\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [54/1000], Validation Loss: 0.0314\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [55/1000], Validation Loss: 0.0314\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [56/1000], Validation Loss: 0.0315\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [57/1000], Validation Loss: 0.0314\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [58/1000], Validation Loss: 0.0314\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [59/1000], Validation Loss: 0.0315\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [60/1000], Validation Loss: 0.0314\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [61/1000], Validation Loss: 0.0315\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [62/1000], Validation Loss: 0.0314\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [63/1000], Validation Loss: 0.0315\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [64/1000], Validation Loss: 0.0315\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [65/1000], Validation Loss: 0.0315\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [66/1000], Validation Loss: 0.0314\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [67/1000], Validation Loss: 0.0314\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [68/1000], Validation Loss: 0.0315\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [69/1000], Validation Loss: 0.0315\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [70/1000], Validation Loss: 0.0315\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [71/1000], Validation Loss: 0.0314\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [72/1000], Validation Loss: 0.0314\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [73/1000], Validation Loss: 0.0314\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [74/1000], Validation Loss: 0.0315\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [75/1000], Validation Loss: 0.0315\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [76/1000], Validation Loss: 0.0315\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [77/1000], Validation Loss: 0.0314\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [78/1000], Validation Loss: 0.0314\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [79/1000], Validation Loss: 0.0315\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [80/1000], Validation Loss: 0.0314\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [81/1000], Validation Loss: 0.0314\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [82/1000], Validation Loss: 0.0314\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [83/1000], Validation Loss: 0.0315\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [84/1000], Validation Loss: 0.0314\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [85/1000], Validation Loss: 0.0315\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [86/1000], Validation Loss: 0.0314\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [87/1000], Validation Loss: 0.0314\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [88/1000], Validation Loss: 0.0314\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [89/1000], Validation Loss: 0.0315\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [90/1000], Validation Loss: 0.0315\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [91/1000], Validation Loss: 0.0314\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [92/1000], Validation Loss: 0.0315\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [93/1000], Validation Loss: 0.0315\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [94/1000], Validation Loss: 0.0314\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [95/1000], Validation Loss: 0.0314\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [96/1000], Validation Loss: 0.0314\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [97/1000], Validation Loss: 0.0315\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [98/1000], Validation Loss: 0.0314\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [99/1000], Validation Loss: 0.0314\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [100/1000], Validation Loss: 0.0314\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [101/1000], Validation Loss: 0.0314\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [102/1000], Validation Loss: 0.0314\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [103/1000], Validation Loss: 0.0314\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [104/1000], Validation Loss: 0.0315\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [105/1000], Validation Loss: 0.0315\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [106/1000], Validation Loss: 0.0314\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [107/1000], Validation Loss: 0.0315\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [108/1000], Validation Loss: 0.0314\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [109/1000], Validation Loss: 0.0315\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [110/1000], Validation Loss: 0.0314\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [111/1000], Validation Loss: 0.0314\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [112/1000], Validation Loss: 0.0314\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [113/1000], Validation Loss: 0.0314\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [114/1000], Validation Loss: 0.0315\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [115/1000], Validation Loss: 0.0315\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [116/1000], Validation Loss: 0.0314\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [117/1000], Validation Loss: 0.0315\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [118/1000], Validation Loss: 0.0315\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [119/1000], Validation Loss: 0.0315\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [120/1000], Validation Loss: 0.0315\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [121/1000], Validation Loss: 0.0314\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [122/1000], Validation Loss: 0.0315\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [123/1000], Validation Loss: 0.0314\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [124/1000], Validation Loss: 0.0314\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [125/1000], Validation Loss: 0.0314\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [126/1000], Validation Loss: 0.0314\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [127/1000], Validation Loss: 0.0315\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [128/1000], Validation Loss: 0.0314\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [129/1000], Validation Loss: 0.0314\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [130/1000], Validation Loss: 0.0314\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [131/1000], Validation Loss: 0.0315\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [132/1000], Validation Loss: 0.0315\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [133/1000], Validation Loss: 0.0314\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [134/1000], Validation Loss: 0.0314\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [135/1000], Validation Loss: 0.0315\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [136/1000], Validation Loss: 0.0315\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [137/1000], Validation Loss: 0.0314\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [138/1000], Validation Loss: 0.0315\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [139/1000], Validation Loss: 0.0315\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [140/1000], Validation Loss: 0.0314\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [141/1000], Validation Loss: 0.0315\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [142/1000], Validation Loss: 0.0314\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [143/1000], Validation Loss: 0.0314\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [144/1000], Validation Loss: 0.0314\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [145/1000], Validation Loss: 0.0315\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [146/1000], Validation Loss: 0.0313\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [147/1000], Validation Loss: 0.0314\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [148/1000], Validation Loss: 0.0314\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [149/1000], Validation Loss: 0.0313\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [150/1000], Validation Loss: 0.0314\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [151/1000], Validation Loss: 0.0314\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [152/1000], Validation Loss: 0.0315\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [153/1000], Validation Loss: 0.0315\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [154/1000], Validation Loss: 0.0315\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [155/1000], Validation Loss: 0.0314\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [156/1000], Validation Loss: 0.0315\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [157/1000], Validation Loss: 0.0315\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [158/1000], Validation Loss: 0.0314\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [159/1000], Validation Loss: 0.0314\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [160/1000], Validation Loss: 0.0314\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [161/1000], Validation Loss: 0.0314\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [162/1000], Validation Loss: 0.0314\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [163/1000], Validation Loss: 0.0314\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [164/1000], Validation Loss: 0.0315\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [165/1000], Validation Loss: 0.0315\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [166/1000], Validation Loss: 0.0315\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [167/1000], Validation Loss: 0.0314\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [168/1000], Validation Loss: 0.0314\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [169/1000], Validation Loss: 0.0315\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [170/1000], Validation Loss: 0.0315\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [171/1000], Validation Loss: 0.0314\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [172/1000], Validation Loss: 0.0315\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [173/1000], Validation Loss: 0.0315\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [174/1000], Validation Loss: 0.0314\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [175/1000], Validation Loss: 0.0315\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [176/1000], Validation Loss: 0.0315\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [177/1000], Validation Loss: 0.0315\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [178/1000], Validation Loss: 0.0314\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [179/1000], Validation Loss: 0.0315\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [180/1000], Validation Loss: 0.0314\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [181/1000], Validation Loss: 0.0315\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [182/1000], Validation Loss: 0.0315\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [183/1000], Validation Loss: 0.0315\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [184/1000], Validation Loss: 0.0315\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [185/1000], Validation Loss: 0.0315\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [186/1000], Validation Loss: 0.0314\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [187/1000], Validation Loss: 0.0315\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [188/1000], Validation Loss: 0.0314\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [189/1000], Validation Loss: 0.0315\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [190/1000], Validation Loss: 0.0314\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [191/1000], Validation Loss: 0.0314\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [192/1000], Validation Loss: 0.0315\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [193/1000], Validation Loss: 0.0315\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [194/1000], Validation Loss: 0.0315\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [195/1000], Validation Loss: 0.0315\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [196/1000], Validation Loss: 0.0315\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [197/1000], Validation Loss: 0.0314\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [198/1000], Validation Loss: 0.0314\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [199/1000], Validation Loss: 0.0314\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [200/1000], Validation Loss: 0.0314\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [201/1000], Validation Loss: 0.0314\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [202/1000], Validation Loss: 0.0314\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [203/1000], Validation Loss: 0.0314\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [204/1000], Validation Loss: 0.0315\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [205/1000], Validation Loss: 0.0314\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [206/1000], Validation Loss: 0.0314\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [207/1000], Validation Loss: 0.0315\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [208/1000], Validation Loss: 0.0314\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [209/1000], Validation Loss: 0.0315\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [210/1000], Validation Loss: 0.0315\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [211/1000], Validation Loss: 0.0314\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [212/1000], Validation Loss: 0.0314\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [213/1000], Validation Loss: 0.0314\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [214/1000], Validation Loss: 0.0314\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [215/1000], Validation Loss: 0.0314\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [216/1000], Validation Loss: 0.0315\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [217/1000], Validation Loss: 0.0314\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [218/1000], Validation Loss: 0.0315\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [219/1000], Validation Loss: 0.0315\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [220/1000], Validation Loss: 0.0314\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [221/1000], Validation Loss: 0.0314\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [222/1000], Validation Loss: 0.0314\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [223/1000], Validation Loss: 0.0315\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [224/1000], Validation Loss: 0.0314\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [225/1000], Validation Loss: 0.0315\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [226/1000], Validation Loss: 0.0315\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [227/1000], Validation Loss: 0.0314\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [228/1000], Validation Loss: 0.0314\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [229/1000], Validation Loss: 0.0315\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [230/1000], Validation Loss: 0.0314\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [231/1000], Validation Loss: 0.0315\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [232/1000], Validation Loss: 0.0315\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [233/1000], Validation Loss: 0.0315\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [234/1000], Validation Loss: 0.0315\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [235/1000], Validation Loss: 0.0315\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [236/1000], Validation Loss: 0.0315\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [237/1000], Validation Loss: 0.0315\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [238/1000], Validation Loss: 0.0314\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [239/1000], Validation Loss: 0.0315\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [240/1000], Validation Loss: 0.0314\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [241/1000], Validation Loss: 0.0315\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [242/1000], Validation Loss: 0.0315\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [243/1000], Validation Loss: 0.0315\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [244/1000], Validation Loss: 0.0314\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [245/1000], Validation Loss: 0.0315\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [246/1000], Validation Loss: 0.0315\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [247/1000], Validation Loss: 0.0315\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [248/1000], Validation Loss: 0.0314\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [249/1000], Validation Loss: 0.0314\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [250/1000], Validation Loss: 0.0314\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [251/1000], Validation Loss: 0.0314\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [252/1000], Validation Loss: 0.0314\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [253/1000], Validation Loss: 0.0314\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [254/1000], Validation Loss: 0.0315\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [255/1000], Validation Loss: 0.0315\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [256/1000], Validation Loss: 0.0315\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [257/1000], Validation Loss: 0.0315\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [258/1000], Validation Loss: 0.0314\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [259/1000], Validation Loss: 0.0315\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [260/1000], Validation Loss: 0.0315\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [261/1000], Validation Loss: 0.0314\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [262/1000], Validation Loss: 0.0314\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [263/1000], Validation Loss: 0.0315\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [264/1000], Validation Loss: 0.0315\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [265/1000], Validation Loss: 0.0315\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [266/1000], Validation Loss: 0.0314\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [267/1000], Validation Loss: 0.0315\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [268/1000], Validation Loss: 0.0314\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [269/1000], Validation Loss: 0.0315\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [270/1000], Validation Loss: 0.0315\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [271/1000], Validation Loss: 0.0315\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [272/1000], Validation Loss: 0.0315\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [273/1000], Validation Loss: 0.0314\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [274/1000], Validation Loss: 0.0314\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [275/1000], Validation Loss: 0.0314\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [276/1000], Validation Loss: 0.0314\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [277/1000], Validation Loss: 0.0315\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [278/1000], Validation Loss: 0.0314\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [279/1000], Validation Loss: 0.0314\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [280/1000], Validation Loss: 0.0315\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [281/1000], Validation Loss: 0.0315\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [282/1000], Validation Loss: 0.0315\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [283/1000], Validation Loss: 0.0315\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [284/1000], Validation Loss: 0.0314\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [285/1000], Validation Loss: 0.0314\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [286/1000], Validation Loss: 0.0314\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [287/1000], Validation Loss: 0.0315\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [288/1000], Validation Loss: 0.0314\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [289/1000], Validation Loss: 0.0314\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [290/1000], Validation Loss: 0.0315\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [291/1000], Validation Loss: 0.0314\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [292/1000], Validation Loss: 0.0315\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [293/1000], Validation Loss: 0.0314\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [294/1000], Validation Loss: 0.0315\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [295/1000], Validation Loss: 0.0315\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [296/1000], Validation Loss: 0.0315\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [297/1000], Validation Loss: 0.0314\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [298/1000], Validation Loss: 0.0315\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [299/1000], Validation Loss: 0.0314\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [300/1000], Validation Loss: 0.0314\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [301/1000], Validation Loss: 0.0315\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [302/1000], Validation Loss: 0.0314\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [303/1000], Validation Loss: 0.0314\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [304/1000], Validation Loss: 0.0315\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [305/1000], Validation Loss: 0.0315\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [306/1000], Validation Loss: 0.0314\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [307/1000], Validation Loss: 0.0315\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [308/1000], Validation Loss: 0.0315\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [309/1000], Validation Loss: 0.0314\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [310/1000], Validation Loss: 0.0315\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [311/1000], Validation Loss: 0.0314\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [312/1000], Validation Loss: 0.0314\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [313/1000], Validation Loss: 0.0314\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [314/1000], Validation Loss: 0.0314\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [315/1000], Validation Loss: 0.0314\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [316/1000], Validation Loss: 0.0314\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [317/1000], Validation Loss: 0.0315\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [318/1000], Validation Loss: 0.0315\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [319/1000], Validation Loss: 0.0314\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [320/1000], Validation Loss: 0.0315\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [321/1000], Validation Loss: 0.0314\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [322/1000], Validation Loss: 0.0314\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [323/1000], Validation Loss: 0.0315\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [324/1000], Validation Loss: 0.0314\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [325/1000], Validation Loss: 0.0314\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [326/1000], Validation Loss: 0.0315\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [327/1000], Validation Loss: 0.0315\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [328/1000], Validation Loss: 0.0315\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [329/1000], Validation Loss: 0.0315\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [330/1000], Validation Loss: 0.0315\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [331/1000], Validation Loss: 0.0314\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [332/1000], Validation Loss: 0.0314\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [333/1000], Validation Loss: 0.0314\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [334/1000], Validation Loss: 0.0314\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [335/1000], Validation Loss: 0.0314\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [336/1000], Validation Loss: 0.0314\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [337/1000], Validation Loss: 0.0314\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [338/1000], Validation Loss: 0.0315\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [339/1000], Validation Loss: 0.0315\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [340/1000], Validation Loss: 0.0315\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [341/1000], Validation Loss: 0.0315\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [342/1000], Validation Loss: 0.0315\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [343/1000], Validation Loss: 0.0314\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [344/1000], Validation Loss: 0.0315\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [345/1000], Validation Loss: 0.0315\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [346/1000], Validation Loss: 0.0315\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [347/1000], Validation Loss: 0.0315\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [348/1000], Validation Loss: 0.0315\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [349/1000], Validation Loss: 0.0314\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [350/1000], Validation Loss: 0.0315\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [351/1000], Validation Loss: 0.0315\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [352/1000], Validation Loss: 0.0314\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [353/1000], Validation Loss: 0.0315\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [354/1000], Validation Loss: 0.0315\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [355/1000], Validation Loss: 0.0315\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [356/1000], Validation Loss: 0.0315\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [357/1000], Validation Loss: 0.0314\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [358/1000], Validation Loss: 0.0315\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [359/1000], Validation Loss: 0.0314\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [360/1000], Validation Loss: 0.0314\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [361/1000], Validation Loss: 0.0314\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [362/1000], Validation Loss: 0.0314\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [363/1000], Validation Loss: 0.0314\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [364/1000], Validation Loss: 0.0314\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [365/1000], Validation Loss: 0.0314\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [366/1000], Validation Loss: 0.0315\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [367/1000], Validation Loss: 0.0314\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [368/1000], Validation Loss: 0.0314\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [369/1000], Validation Loss: 0.0315\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [370/1000], Validation Loss: 0.0315\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [371/1000], Validation Loss: 0.0315\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [372/1000], Validation Loss: 0.0315\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [373/1000], Validation Loss: 0.0314\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [374/1000], Validation Loss: 0.0314\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [375/1000], Validation Loss: 0.0314\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [376/1000], Validation Loss: 0.0315\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [377/1000], Validation Loss: 0.0315\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [378/1000], Validation Loss: 0.0314\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [379/1000], Validation Loss: 0.0314\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [380/1000], Validation Loss: 0.0315\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [381/1000], Validation Loss: 0.0314\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [382/1000], Validation Loss: 0.0314\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [383/1000], Validation Loss: 0.0315\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [384/1000], Validation Loss: 0.0314\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [385/1000], Validation Loss: 0.0314\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [386/1000], Validation Loss: 0.0314\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [387/1000], Validation Loss: 0.0314\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [388/1000], Validation Loss: 0.0315\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [389/1000], Validation Loss: 0.0314\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [390/1000], Validation Loss: 0.0315\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [391/1000], Validation Loss: 0.0315\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [392/1000], Validation Loss: 0.0314\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [393/1000], Validation Loss: 0.0315\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [394/1000], Validation Loss: 0.0314\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [395/1000], Validation Loss: 0.0314\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [396/1000], Validation Loss: 0.0315\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [397/1000], Validation Loss: 0.0314\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [398/1000], Validation Loss: 0.0314\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [399/1000], Validation Loss: 0.0315\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [400/1000], Validation Loss: 0.0315\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [401/1000], Validation Loss: 0.0315\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [402/1000], Validation Loss: 0.0314\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [403/1000], Validation Loss: 0.0315\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [404/1000], Validation Loss: 0.0315\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [405/1000], Validation Loss: 0.0315\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [406/1000], Validation Loss: 0.0315\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [407/1000], Validation Loss: 0.0315\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [408/1000], Validation Loss: 0.0314\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [409/1000], Validation Loss: 0.0315\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [410/1000], Validation Loss: 0.0315\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [411/1000], Validation Loss: 0.0314\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [412/1000], Validation Loss: 0.0315\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [413/1000], Validation Loss: 0.0314\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [414/1000], Validation Loss: 0.0315\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [415/1000], Validation Loss: 0.0315\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [416/1000], Validation Loss: 0.0315\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [417/1000], Validation Loss: 0.0315\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [418/1000], Validation Loss: 0.0315\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [419/1000], Validation Loss: 0.0315\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [420/1000], Validation Loss: 0.0314\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [421/1000], Validation Loss: 0.0314\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [422/1000], Validation Loss: 0.0314\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [423/1000], Validation Loss: 0.0315\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [424/1000], Validation Loss: 0.0315\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [425/1000], Validation Loss: 0.0314\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [426/1000], Validation Loss: 0.0314\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [427/1000], Validation Loss: 0.0314\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [428/1000], Validation Loss: 0.0314\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [429/1000], Validation Loss: 0.0314\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [430/1000], Validation Loss: 0.0315\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [431/1000], Validation Loss: 0.0315\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [432/1000], Validation Loss: 0.0314\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [433/1000], Validation Loss: 0.0315\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [434/1000], Validation Loss: 0.0314\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [435/1000], Validation Loss: 0.0315\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [436/1000], Validation Loss: 0.0315\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [437/1000], Validation Loss: 0.0314\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [438/1000], Validation Loss: 0.0315\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [439/1000], Validation Loss: 0.0315\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [440/1000], Validation Loss: 0.0315\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [441/1000], Validation Loss: 0.0314\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [442/1000], Validation Loss: 0.0314\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [443/1000], Validation Loss: 0.0315\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [444/1000], Validation Loss: 0.0314\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [445/1000], Validation Loss: 0.0315\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [446/1000], Validation Loss: 0.0314\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [447/1000], Validation Loss: 0.0314\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [448/1000], Validation Loss: 0.0315\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [449/1000], Validation Loss: 0.0315\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [450/1000], Validation Loss: 0.0314\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [451/1000], Validation Loss: 0.0314\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [452/1000], Validation Loss: 0.0315\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [453/1000], Validation Loss: 0.0314\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [454/1000], Validation Loss: 0.0314\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [455/1000], Validation Loss: 0.0315\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [456/1000], Validation Loss: 0.0315\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [457/1000], Validation Loss: 0.0315\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [458/1000], Validation Loss: 0.0314\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [459/1000], Validation Loss: 0.0314\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [460/1000], Validation Loss: 0.0314\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [461/1000], Validation Loss: 0.0315\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [462/1000], Validation Loss: 0.0315\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [463/1000], Validation Loss: 0.0314\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [464/1000], Validation Loss: 0.0315\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [465/1000], Validation Loss: 0.0315\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [466/1000], Validation Loss: 0.0315\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [467/1000], Validation Loss: 0.0314\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [468/1000], Validation Loss: 0.0314\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [469/1000], Validation Loss: 0.0315\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [470/1000], Validation Loss: 0.0315\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [471/1000], Validation Loss: 0.0314\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [472/1000], Validation Loss: 0.0314\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [473/1000], Validation Loss: 0.0314\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [474/1000], Validation Loss: 0.0315\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [475/1000], Validation Loss: 0.0315\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [476/1000], Validation Loss: 0.0315\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [477/1000], Validation Loss: 0.0314\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [478/1000], Validation Loss: 0.0314\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [479/1000], Validation Loss: 0.0315\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [480/1000], Validation Loss: 0.0314\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [481/1000], Validation Loss: 0.0315\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [482/1000], Validation Loss: 0.0314\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [483/1000], Validation Loss: 0.0314\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [484/1000], Validation Loss: 0.0314\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [485/1000], Validation Loss: 0.0314\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [486/1000], Validation Loss: 0.0315\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [487/1000], Validation Loss: 0.0314\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [488/1000], Validation Loss: 0.0315\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [489/1000], Validation Loss: 0.0315\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [490/1000], Validation Loss: 0.0315\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [491/1000], Validation Loss: 0.0315\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [492/1000], Validation Loss: 0.0315\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [493/1000], Validation Loss: 0.0315\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [494/1000], Validation Loss: 0.0315\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [495/1000], Validation Loss: 0.0315\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [496/1000], Validation Loss: 0.0315\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [497/1000], Validation Loss: 0.0315\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [498/1000], Validation Loss: 0.0314\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [499/1000], Validation Loss: 0.0314\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [500/1000], Validation Loss: 0.0314\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [501/1000], Validation Loss: 0.0315\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [502/1000], Validation Loss: 0.0314\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [503/1000], Validation Loss: 0.0315\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [504/1000], Validation Loss: 0.0314\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [505/1000], Validation Loss: 0.0314\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [506/1000], Validation Loss: 0.0315\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [507/1000], Validation Loss: 0.0314\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [508/1000], Validation Loss: 0.0314\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [509/1000], Validation Loss: 0.0314\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [510/1000], Validation Loss: 0.0314\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [511/1000], Validation Loss: 0.0315\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [512/1000], Validation Loss: 0.0315\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [513/1000], Validation Loss: 0.0315\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [514/1000], Validation Loss: 0.0315\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [515/1000], Validation Loss: 0.0315\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [516/1000], Validation Loss: 0.0315\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [517/1000], Validation Loss: 0.0314\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [518/1000], Validation Loss: 0.0314\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [519/1000], Validation Loss: 0.0314\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [520/1000], Validation Loss: 0.0315\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [521/1000], Validation Loss: 0.0314\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [522/1000], Validation Loss: 0.0314\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [523/1000], Validation Loss: 0.0314\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [524/1000], Validation Loss: 0.0315\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [525/1000], Validation Loss: 0.0315\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [526/1000], Validation Loss: 0.0315\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [527/1000], Validation Loss: 0.0315\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [528/1000], Validation Loss: 0.0315\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [529/1000], Validation Loss: 0.0314\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [530/1000], Validation Loss: 0.0315\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [531/1000], Validation Loss: 0.0315\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [532/1000], Validation Loss: 0.0315\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [533/1000], Validation Loss: 0.0314\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [534/1000], Validation Loss: 0.0315\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [535/1000], Validation Loss: 0.0315\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [536/1000], Validation Loss: 0.0315\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [537/1000], Validation Loss: 0.0314\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [538/1000], Validation Loss: 0.0314\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [539/1000], Validation Loss: 0.0315\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [540/1000], Validation Loss: 0.0314\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [541/1000], Validation Loss: 0.0315\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [542/1000], Validation Loss: 0.0315\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [543/1000], Validation Loss: 0.0315\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [544/1000], Validation Loss: 0.0314\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [545/1000], Validation Loss: 0.0315\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [546/1000], Validation Loss: 0.0315\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [547/1000], Validation Loss: 0.0314\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [548/1000], Validation Loss: 0.0315\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [549/1000], Validation Loss: 0.0314\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [550/1000], Validation Loss: 0.0314\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [551/1000], Validation Loss: 0.0314\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [552/1000], Validation Loss: 0.0314\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [553/1000], Validation Loss: 0.0315\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [554/1000], Validation Loss: 0.0314\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [555/1000], Validation Loss: 0.0314\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [556/1000], Validation Loss: 0.0314\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [557/1000], Validation Loss: 0.0314\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [558/1000], Validation Loss: 0.0314\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [559/1000], Validation Loss: 0.0314\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [560/1000], Validation Loss: 0.0315\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [561/1000], Validation Loss: 0.0314\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [562/1000], Validation Loss: 0.0314\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [563/1000], Validation Loss: 0.0315\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [564/1000], Validation Loss: 0.0315\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [565/1000], Validation Loss: 0.0315\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [566/1000], Validation Loss: 0.0315\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [567/1000], Validation Loss: 0.0314\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [568/1000], Validation Loss: 0.0314\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [569/1000], Validation Loss: 0.0315\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [570/1000], Validation Loss: 0.0315\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [571/1000], Validation Loss: 0.0314\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [572/1000], Validation Loss: 0.0314\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [573/1000], Validation Loss: 0.0314\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [574/1000], Validation Loss: 0.0315\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [575/1000], Validation Loss: 0.0315\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [576/1000], Validation Loss: 0.0314\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [577/1000], Validation Loss: 0.0314\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [578/1000], Validation Loss: 0.0314\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [579/1000], Validation Loss: 0.0315\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [580/1000], Validation Loss: 0.0315\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [581/1000], Validation Loss: 0.0314\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [582/1000], Validation Loss: 0.0315\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [583/1000], Validation Loss: 0.0315\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [584/1000], Validation Loss: 0.0314\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [585/1000], Validation Loss: 0.0315\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [586/1000], Validation Loss: 0.0314\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [587/1000], Validation Loss: 0.0315\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [588/1000], Validation Loss: 0.0315\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [589/1000], Validation Loss: 0.0314\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [590/1000], Validation Loss: 0.0315\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [591/1000], Validation Loss: 0.0315\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [592/1000], Validation Loss: 0.0314\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [593/1000], Validation Loss: 0.0314\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [594/1000], Validation Loss: 0.0315\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [595/1000], Validation Loss: 0.0315\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [596/1000], Validation Loss: 0.0315\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [597/1000], Validation Loss: 0.0314\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [598/1000], Validation Loss: 0.0315\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [599/1000], Validation Loss: 0.0315\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [600/1000], Validation Loss: 0.0315\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [601/1000], Validation Loss: 0.0315\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [602/1000], Validation Loss: 0.0314\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [603/1000], Validation Loss: 0.0315\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [604/1000], Validation Loss: 0.0314\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [605/1000], Validation Loss: 0.0315\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [606/1000], Validation Loss: 0.0314\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [607/1000], Validation Loss: 0.0314\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [608/1000], Validation Loss: 0.0314\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [609/1000], Validation Loss: 0.0315\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [610/1000], Validation Loss: 0.0314\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [611/1000], Validation Loss: 0.0315\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [612/1000], Validation Loss: 0.0315\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [613/1000], Validation Loss: 0.0314\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [614/1000], Validation Loss: 0.0314\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [615/1000], Validation Loss: 0.0315\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [616/1000], Validation Loss: 0.0314\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [617/1000], Validation Loss: 0.0314\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [618/1000], Validation Loss: 0.0315\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [619/1000], Validation Loss: 0.0314\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [620/1000], Validation Loss: 0.0314\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [621/1000], Validation Loss: 0.0315\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [622/1000], Validation Loss: 0.0315\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [623/1000], Validation Loss: 0.0314\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [624/1000], Validation Loss: 0.0315\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [625/1000], Validation Loss: 0.0315\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [626/1000], Validation Loss: 0.0314\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [627/1000], Validation Loss: 0.0314\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [628/1000], Validation Loss: 0.0315\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [629/1000], Validation Loss: 0.0314\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [630/1000], Validation Loss: 0.0314\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [631/1000], Validation Loss: 0.0315\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [632/1000], Validation Loss: 0.0315\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [633/1000], Validation Loss: 0.0314\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [634/1000], Validation Loss: 0.0314\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [635/1000], Validation Loss: 0.0314\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [636/1000], Validation Loss: 0.0314\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [637/1000], Validation Loss: 0.0314\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [638/1000], Validation Loss: 0.0314\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [639/1000], Validation Loss: 0.0314\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [640/1000], Validation Loss: 0.0314\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [641/1000], Validation Loss: 0.0315\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [642/1000], Validation Loss: 0.0315\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [643/1000], Validation Loss: 0.0314\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [644/1000], Validation Loss: 0.0314\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [645/1000], Validation Loss: 0.0315\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [646/1000], Validation Loss: 0.0314\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [647/1000], Validation Loss: 0.0314\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [648/1000], Validation Loss: 0.0314\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [649/1000], Validation Loss: 0.0314\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [650/1000], Validation Loss: 0.0314\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [651/1000], Validation Loss: 0.0314\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [652/1000], Validation Loss: 0.0315\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [653/1000], Validation Loss: 0.0314\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [654/1000], Validation Loss: 0.0314\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [655/1000], Validation Loss: 0.0314\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [656/1000], Validation Loss: 0.0315\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [657/1000], Validation Loss: 0.0315\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [658/1000], Validation Loss: 0.0314\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [659/1000], Validation Loss: 0.0314\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [660/1000], Validation Loss: 0.0314\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [661/1000], Validation Loss: 0.0315\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [662/1000], Validation Loss: 0.0314\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [663/1000], Validation Loss: 0.0315\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [664/1000], Validation Loss: 0.0314\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [665/1000], Validation Loss: 0.0315\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [666/1000], Validation Loss: 0.0315\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [667/1000], Validation Loss: 0.0314\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [668/1000], Validation Loss: 0.0315\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [669/1000], Validation Loss: 0.0315\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [670/1000], Validation Loss: 0.0315\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [671/1000], Validation Loss: 0.0314\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [672/1000], Validation Loss: 0.0314\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [673/1000], Validation Loss: 0.0315\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [674/1000], Validation Loss: 0.0314\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [675/1000], Validation Loss: 0.0315\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [676/1000], Validation Loss: 0.0314\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [677/1000], Validation Loss: 0.0315\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [678/1000], Validation Loss: 0.0314\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [679/1000], Validation Loss: 0.0315\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [680/1000], Validation Loss: 0.0314\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [681/1000], Validation Loss: 0.0314\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [682/1000], Validation Loss: 0.0314\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [683/1000], Validation Loss: 0.0314\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [684/1000], Validation Loss: 0.0314\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [685/1000], Validation Loss: 0.0314\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [686/1000], Validation Loss: 0.0314\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [687/1000], Validation Loss: 0.0314\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [688/1000], Validation Loss: 0.0315\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [689/1000], Validation Loss: 0.0315\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [690/1000], Validation Loss: 0.0315\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [691/1000], Validation Loss: 0.0315\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [692/1000], Validation Loss: 0.0314\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [693/1000], Validation Loss: 0.0314\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [694/1000], Validation Loss: 0.0314\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [695/1000], Validation Loss: 0.0315\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [696/1000], Validation Loss: 0.0315\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [697/1000], Validation Loss: 0.0315\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [698/1000], Validation Loss: 0.0314\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [699/1000], Validation Loss: 0.0314\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [700/1000], Validation Loss: 0.0314\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [701/1000], Validation Loss: 0.0314\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [702/1000], Validation Loss: 0.0315\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [703/1000], Validation Loss: 0.0314\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [704/1000], Validation Loss: 0.0314\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [705/1000], Validation Loss: 0.0315\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [706/1000], Validation Loss: 0.0315\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [707/1000], Validation Loss: 0.0314\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [708/1000], Validation Loss: 0.0314\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [709/1000], Validation Loss: 0.0315\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [710/1000], Validation Loss: 0.0314\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [711/1000], Validation Loss: 0.0315\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [712/1000], Validation Loss: 0.0314\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [713/1000], Validation Loss: 0.0314\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [714/1000], Validation Loss: 0.0314\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [715/1000], Validation Loss: 0.0315\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [716/1000], Validation Loss: 0.0314\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [717/1000], Validation Loss: 0.0314\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [718/1000], Validation Loss: 0.0315\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [719/1000], Validation Loss: 0.0315\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [720/1000], Validation Loss: 0.0315\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [721/1000], Validation Loss: 0.0315\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [722/1000], Validation Loss: 0.0315\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [723/1000], Validation Loss: 0.0314\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [724/1000], Validation Loss: 0.0315\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [725/1000], Validation Loss: 0.0315\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [726/1000], Validation Loss: 0.0314\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [727/1000], Validation Loss: 0.0315\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [728/1000], Validation Loss: 0.0315\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [729/1000], Validation Loss: 0.0314\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [730/1000], Validation Loss: 0.0314\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [731/1000], Validation Loss: 0.0314\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [732/1000], Validation Loss: 0.0315\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [733/1000], Validation Loss: 0.0315\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [734/1000], Validation Loss: 0.0314\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [735/1000], Validation Loss: 0.0315\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [736/1000], Validation Loss: 0.0314\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [737/1000], Validation Loss: 0.0314\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [738/1000], Validation Loss: 0.0315\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [739/1000], Validation Loss: 0.0314\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [740/1000], Validation Loss: 0.0314\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [741/1000], Validation Loss: 0.0315\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [742/1000], Validation Loss: 0.0315\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [743/1000], Validation Loss: 0.0314\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [744/1000], Validation Loss: 0.0315\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [745/1000], Validation Loss: 0.0314\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [746/1000], Validation Loss: 0.0314\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [747/1000], Validation Loss: 0.0315\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [748/1000], Validation Loss: 0.0314\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [749/1000], Validation Loss: 0.0315\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [750/1000], Validation Loss: 0.0314\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [751/1000], Validation Loss: 0.0315\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [752/1000], Validation Loss: 0.0315\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [753/1000], Validation Loss: 0.0315\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [754/1000], Validation Loss: 0.0314\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [755/1000], Validation Loss: 0.0315\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [756/1000], Validation Loss: 0.0315\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [757/1000], Validation Loss: 0.0314\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [758/1000], Validation Loss: 0.0314\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [759/1000], Validation Loss: 0.0314\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [760/1000], Validation Loss: 0.0315\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [761/1000], Validation Loss: 0.0315\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [762/1000], Validation Loss: 0.0315\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [763/1000], Validation Loss: 0.0315\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [764/1000], Validation Loss: 0.0315\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [765/1000], Validation Loss: 0.0315\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [766/1000], Validation Loss: 0.0314\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [767/1000], Validation Loss: 0.0315\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [768/1000], Validation Loss: 0.0315\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [769/1000], Validation Loss: 0.0314\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [770/1000], Validation Loss: 0.0315\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [771/1000], Validation Loss: 0.0315\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [772/1000], Validation Loss: 0.0315\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [773/1000], Validation Loss: 0.0314\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [774/1000], Validation Loss: 0.0314\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [775/1000], Validation Loss: 0.0315\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [776/1000], Validation Loss: 0.0314\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [777/1000], Validation Loss: 0.0314\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [778/1000], Validation Loss: 0.0314\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [779/1000], Validation Loss: 0.0315\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [780/1000], Validation Loss: 0.0314\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [781/1000], Validation Loss: 0.0314\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [782/1000], Validation Loss: 0.0314\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [783/1000], Validation Loss: 0.0315\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [784/1000], Validation Loss: 0.0315\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [785/1000], Validation Loss: 0.0315\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [786/1000], Validation Loss: 0.0315\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [787/1000], Validation Loss: 0.0315\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [788/1000], Validation Loss: 0.0315\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [789/1000], Validation Loss: 0.0315\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [790/1000], Validation Loss: 0.0314\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [791/1000], Validation Loss: 0.0315\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [792/1000], Validation Loss: 0.0315\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [793/1000], Validation Loss: 0.0315\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [794/1000], Validation Loss: 0.0314\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [795/1000], Validation Loss: 0.0314\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [796/1000], Validation Loss: 0.0314\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [797/1000], Validation Loss: 0.0314\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [798/1000], Validation Loss: 0.0314\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [799/1000], Validation Loss: 0.0314\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [800/1000], Validation Loss: 0.0314\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [801/1000], Validation Loss: 0.0314\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [802/1000], Validation Loss: 0.0314\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [803/1000], Validation Loss: 0.0314\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [804/1000], Validation Loss: 0.0315\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [805/1000], Validation Loss: 0.0315\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [806/1000], Validation Loss: 0.0315\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [807/1000], Validation Loss: 0.0315\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [808/1000], Validation Loss: 0.0315\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [809/1000], Validation Loss: 0.0315\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [810/1000], Validation Loss: 0.0314\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [811/1000], Validation Loss: 0.0314\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [812/1000], Validation Loss: 0.0314\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [813/1000], Validation Loss: 0.0314\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [814/1000], Validation Loss: 0.0314\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [815/1000], Validation Loss: 0.0314\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [816/1000], Validation Loss: 0.0314\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [817/1000], Validation Loss: 0.0315\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [818/1000], Validation Loss: 0.0315\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [819/1000], Validation Loss: 0.0315\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [820/1000], Validation Loss: 0.0314\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [821/1000], Validation Loss: 0.0314\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [822/1000], Validation Loss: 0.0314\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [823/1000], Validation Loss: 0.0314\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [824/1000], Validation Loss: 0.0315\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [825/1000], Validation Loss: 0.0314\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [826/1000], Validation Loss: 0.0315\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [827/1000], Validation Loss: 0.0315\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [828/1000], Validation Loss: 0.0314\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [829/1000], Validation Loss: 0.0315\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [830/1000], Validation Loss: 0.0314\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [831/1000], Validation Loss: 0.0315\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [832/1000], Validation Loss: 0.0315\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [833/1000], Validation Loss: 0.0314\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [834/1000], Validation Loss: 0.0314\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [835/1000], Validation Loss: 0.0315\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [836/1000], Validation Loss: 0.0314\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [837/1000], Validation Loss: 0.0314\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [838/1000], Validation Loss: 0.0314\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [839/1000], Validation Loss: 0.0314\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [840/1000], Validation Loss: 0.0315\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [841/1000], Validation Loss: 0.0314\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [842/1000], Validation Loss: 0.0315\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [843/1000], Validation Loss: 0.0315\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [844/1000], Validation Loss: 0.0314\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [845/1000], Validation Loss: 0.0314\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [846/1000], Validation Loss: 0.0314\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [847/1000], Validation Loss: 0.0314\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [848/1000], Validation Loss: 0.0314\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [849/1000], Validation Loss: 0.0314\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [850/1000], Validation Loss: 0.0314\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [851/1000], Validation Loss: 0.0315\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [852/1000], Validation Loss: 0.0315\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [853/1000], Validation Loss: 0.0314\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [854/1000], Validation Loss: 0.0314\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [855/1000], Validation Loss: 0.0314\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [856/1000], Validation Loss: 0.0314\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [857/1000], Validation Loss: 0.0315\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [858/1000], Validation Loss: 0.0315\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [859/1000], Validation Loss: 0.0314\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [860/1000], Validation Loss: 0.0314\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [861/1000], Validation Loss: 0.0315\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [862/1000], Validation Loss: 0.0314\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [863/1000], Validation Loss: 0.0314\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [864/1000], Validation Loss: 0.0314\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [865/1000], Validation Loss: 0.0315\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [866/1000], Validation Loss: 0.0314\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [867/1000], Validation Loss: 0.0314\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [868/1000], Validation Loss: 0.0315\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [869/1000], Validation Loss: 0.0315\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [870/1000], Validation Loss: 0.0314\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [871/1000], Validation Loss: 0.0315\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [872/1000], Validation Loss: 0.0315\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [873/1000], Validation Loss: 0.0314\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [874/1000], Validation Loss: 0.0315\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [875/1000], Validation Loss: 0.0315\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0321\n",
            "Epoch [876/1000], Validation Loss: 0.0315\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [877/1000], Validation Loss: 0.0314\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [878/1000], Validation Loss: 0.0315\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [879/1000], Validation Loss: 0.0315\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [880/1000], Validation Loss: 0.0315\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [881/1000], Validation Loss: 0.0314\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [882/1000], Validation Loss: 0.0315\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [883/1000], Validation Loss: 0.0314\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [884/1000], Validation Loss: 0.0315\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [885/1000], Validation Loss: 0.0314\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [886/1000], Validation Loss: 0.0314\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [887/1000], Validation Loss: 0.0314\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [888/1000], Validation Loss: 0.0315\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [889/1000], Validation Loss: 0.0315\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [890/1000], Validation Loss: 0.0315\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [891/1000], Validation Loss: 0.0315\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [892/1000], Validation Loss: 0.0315\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [893/1000], Validation Loss: 0.0314\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [894/1000], Validation Loss: 0.0314\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [895/1000], Validation Loss: 0.0315\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [896/1000], Validation Loss: 0.0315\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [897/1000], Validation Loss: 0.0314\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [898/1000], Validation Loss: 0.0315\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [899/1000], Validation Loss: 0.0315\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [900/1000], Validation Loss: 0.0314\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [901/1000], Validation Loss: 0.0314\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [902/1000], Validation Loss: 0.0314\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [903/1000], Validation Loss: 0.0315\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [904/1000], Validation Loss: 0.0314\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [905/1000], Validation Loss: 0.0314\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [906/1000], Validation Loss: 0.0315\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [907/1000], Validation Loss: 0.0314\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [908/1000], Validation Loss: 0.0314\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [909/1000], Validation Loss: 0.0315\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [910/1000], Validation Loss: 0.0314\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [911/1000], Validation Loss: 0.0314\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [912/1000], Validation Loss: 0.0314\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [913/1000], Validation Loss: 0.0315\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [914/1000], Validation Loss: 0.0314\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [915/1000], Validation Loss: 0.0314\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [916/1000], Validation Loss: 0.0315\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [917/1000], Validation Loss: 0.0315\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [918/1000], Validation Loss: 0.0315\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [919/1000], Validation Loss: 0.0314\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [920/1000], Validation Loss: 0.0314\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [921/1000], Validation Loss: 0.0315\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [922/1000], Validation Loss: 0.0314\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [923/1000], Validation Loss: 0.0314\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [924/1000], Validation Loss: 0.0315\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [925/1000], Validation Loss: 0.0315\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [926/1000], Validation Loss: 0.0314\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [927/1000], Validation Loss: 0.0314\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [928/1000], Validation Loss: 0.0314\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [929/1000], Validation Loss: 0.0314\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [930/1000], Validation Loss: 0.0314\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [931/1000], Validation Loss: 0.0314\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [932/1000], Validation Loss: 0.0315\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [933/1000], Validation Loss: 0.0315\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [934/1000], Validation Loss: 0.0314\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [935/1000], Validation Loss: 0.0314\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [936/1000], Validation Loss: 0.0314\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [937/1000], Validation Loss: 0.0314\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [938/1000], Validation Loss: 0.0314\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [939/1000], Validation Loss: 0.0314\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [940/1000], Validation Loss: 0.0314\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [941/1000], Validation Loss: 0.0315\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [942/1000], Validation Loss: 0.0314\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [943/1000], Validation Loss: 0.0315\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [944/1000], Validation Loss: 0.0314\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [945/1000], Validation Loss: 0.0314\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [946/1000], Validation Loss: 0.0314\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [947/1000], Validation Loss: 0.0314\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [948/1000], Validation Loss: 0.0315\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [949/1000], Validation Loss: 0.0314\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [950/1000], Validation Loss: 0.0315\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [951/1000], Validation Loss: 0.0314\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [952/1000], Validation Loss: 0.0315\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [953/1000], Validation Loss: 0.0315\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [954/1000], Validation Loss: 0.0315\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [955/1000], Validation Loss: 0.0314\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [956/1000], Validation Loss: 0.0315\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [957/1000], Validation Loss: 0.0314\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [958/1000], Validation Loss: 0.0315\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [959/1000], Validation Loss: 0.0315\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [960/1000], Validation Loss: 0.0314\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [961/1000], Validation Loss: 0.0315\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [962/1000], Validation Loss: 0.0315\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [963/1000], Validation Loss: 0.0315\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [964/1000], Validation Loss: 0.0315\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [965/1000], Validation Loss: 0.0315\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [966/1000], Validation Loss: 0.0315\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [967/1000], Validation Loss: 0.0315\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [968/1000], Validation Loss: 0.0314\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [969/1000], Validation Loss: 0.0314\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [970/1000], Validation Loss: 0.0315\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [971/1000], Validation Loss: 0.0315\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [972/1000], Validation Loss: 0.0314\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [973/1000], Validation Loss: 0.0315\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [974/1000], Validation Loss: 0.0314\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [975/1000], Validation Loss: 0.0315\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [976/1000], Validation Loss: 0.0315\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [977/1000], Validation Loss: 0.0314\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [978/1000], Validation Loss: 0.0314\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [979/1000], Validation Loss: 0.0314\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [980/1000], Validation Loss: 0.0315\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [981/1000], Validation Loss: 0.0315\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [982/1000], Validation Loss: 0.0314\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [983/1000], Validation Loss: 0.0314\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [984/1000], Validation Loss: 0.0315\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [985/1000], Validation Loss: 0.0315\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [986/1000], Validation Loss: 0.0314\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [987/1000], Validation Loss: 0.0314\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [988/1000], Validation Loss: 0.0314\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [989/1000], Validation Loss: 0.0316\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [990/1000], Validation Loss: 0.0314\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [991/1000], Validation Loss: 0.0314\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [992/1000], Validation Loss: 0.0314\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [993/1000], Validation Loss: 0.0314\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [994/1000], Validation Loss: 0.0314\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [995/1000], Validation Loss: 0.0314\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [996/1000], Validation Loss: 0.0315\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [997/1000], Validation Loss: 0.0314\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [998/1000], Validation Loss: 0.0314\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [999/1000], Validation Loss: 0.0314\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [1000/1000], Validation Loss: 0.0315\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 4"
      ],
      "metadata": {
        "id": "NJExqqSw6IdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator4(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator4, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator4(Generator4):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm):\n",
        "          super(DPGenerator4, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.noise_multiplier = noise_multiplier\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "\n",
        "          # Ensure all parameters have requires_grad=True\n",
        "          for param in self.parameters():\n",
        "              param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add noise during forward pass for privacy\n",
        "        with torch.no_grad():\n",
        "            x = super().forward(x)\n",
        "            x += torch.randn_like(x) * self.noise_multiplier\n",
        "        return x"
      ],
      "metadata": {
        "id": "tS7S0E8a6KTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model4 = DPGenerator4(input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer4 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion4 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "CMz0aC9Q62Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "fCCdDGKS6Jsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model4.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer4.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device).float(), deepfake_features.to(device).float()\n",
        "        real_features.requires_grad = True  # Ensure gradients are tracked for inputs\n",
        "        deepfake_features.requires_grad = True\n",
        "        output = model4(real_features)\n",
        "        loss = criterion4(output, deepfake_features)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer4.step()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model4.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model4(real_features)\n",
        "            loss = criterion4(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iUHQ830T67Xp",
        "outputId": "7e5a6040-75ec-42d1-86e3-f28facea5d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [1/1000], Validation Loss: 0.0382\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [2/1000], Validation Loss: 0.0383\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [3/1000], Validation Loss: 0.0383\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [4/1000], Validation Loss: 0.0382\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [5/1000], Validation Loss: 0.0382\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [6/1000], Validation Loss: 0.0382\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [7/1000], Validation Loss: 0.0382\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [8/1000], Validation Loss: 0.0382\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [9/1000], Validation Loss: 0.0382\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [10/1000], Validation Loss: 0.0382\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [11/1000], Validation Loss: 0.0383\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [12/1000], Validation Loss: 0.0383\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [13/1000], Validation Loss: 0.0382\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [14/1000], Validation Loss: 0.0382\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [15/1000], Validation Loss: 0.0382\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [16/1000], Validation Loss: 0.0382\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [17/1000], Validation Loss: 0.0384\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [18/1000], Validation Loss: 0.0383\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [19/1000], Validation Loss: 0.0383\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [20/1000], Validation Loss: 0.0382\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [21/1000], Validation Loss: 0.0383\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [22/1000], Validation Loss: 0.0381\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [23/1000], Validation Loss: 0.0382\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [24/1000], Validation Loss: 0.0381\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [25/1000], Validation Loss: 0.0381\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [26/1000], Validation Loss: 0.0383\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [27/1000], Validation Loss: 0.0382\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [28/1000], Validation Loss: 0.0381\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [29/1000], Validation Loss: 0.0382\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [30/1000], Validation Loss: 0.0382\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [31/1000], Validation Loss: 0.0382\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [32/1000], Validation Loss: 0.0383\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [33/1000], Validation Loss: 0.0383\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [34/1000], Validation Loss: 0.0382\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [35/1000], Validation Loss: 0.0382\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [36/1000], Validation Loss: 0.0383\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [37/1000], Validation Loss: 0.0382\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [38/1000], Validation Loss: 0.0382\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [39/1000], Validation Loss: 0.0382\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [40/1000], Validation Loss: 0.0381\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [41/1000], Validation Loss: 0.0382\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [42/1000], Validation Loss: 0.0383\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [43/1000], Validation Loss: 0.0382\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [44/1000], Validation Loss: 0.0383\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [45/1000], Validation Loss: 0.0382\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [46/1000], Validation Loss: 0.0381\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [47/1000], Validation Loss: 0.0383\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0388\n",
            "Epoch [48/1000], Validation Loss: 0.0383\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [49/1000], Validation Loss: 0.0382\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [50/1000], Validation Loss: 0.0382\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [51/1000], Validation Loss: 0.0382\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [52/1000], Validation Loss: 0.0383\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [53/1000], Validation Loss: 0.0383\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [54/1000], Validation Loss: 0.0383\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [55/1000], Validation Loss: 0.0383\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [56/1000], Validation Loss: 0.0382\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [57/1000], Validation Loss: 0.0382\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [58/1000], Validation Loss: 0.0383\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [59/1000], Validation Loss: 0.0381\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [60/1000], Validation Loss: 0.0382\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [61/1000], Validation Loss: 0.0383\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [62/1000], Validation Loss: 0.0383\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [63/1000], Validation Loss: 0.0383\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [64/1000], Validation Loss: 0.0383\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [65/1000], Validation Loss: 0.0382\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [66/1000], Validation Loss: 0.0383\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [67/1000], Validation Loss: 0.0382\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [68/1000], Validation Loss: 0.0382\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [69/1000], Validation Loss: 0.0382\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [70/1000], Validation Loss: 0.0382\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [71/1000], Validation Loss: 0.0382\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [72/1000], Validation Loss: 0.0382\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [73/1000], Validation Loss: 0.0382\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [74/1000], Validation Loss: 0.0382\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [75/1000], Validation Loss: 0.0382\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [76/1000], Validation Loss: 0.0382\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [77/1000], Validation Loss: 0.0382\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [78/1000], Validation Loss: 0.0382\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [79/1000], Validation Loss: 0.0383\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [80/1000], Validation Loss: 0.0382\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [81/1000], Validation Loss: 0.0383\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [82/1000], Validation Loss: 0.0383\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [83/1000], Validation Loss: 0.0383\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [84/1000], Validation Loss: 0.0383\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [85/1000], Validation Loss: 0.0382\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [86/1000], Validation Loss: 0.0382\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [87/1000], Validation Loss: 0.0383\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [88/1000], Validation Loss: 0.0382\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [89/1000], Validation Loss: 0.0384\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [90/1000], Validation Loss: 0.0383\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [91/1000], Validation Loss: 0.0381\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [92/1000], Validation Loss: 0.0381\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [93/1000], Validation Loss: 0.0383\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [94/1000], Validation Loss: 0.0383\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [95/1000], Validation Loss: 0.0382\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [96/1000], Validation Loss: 0.0382\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [97/1000], Validation Loss: 0.0382\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [98/1000], Validation Loss: 0.0382\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [99/1000], Validation Loss: 0.0383\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [100/1000], Validation Loss: 0.0381\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [101/1000], Validation Loss: 0.0382\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [102/1000], Validation Loss: 0.0382\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [103/1000], Validation Loss: 0.0382\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [104/1000], Validation Loss: 0.0382\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [105/1000], Validation Loss: 0.0382\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [106/1000], Validation Loss: 0.0383\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [107/1000], Validation Loss: 0.0382\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [108/1000], Validation Loss: 0.0382\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [109/1000], Validation Loss: 0.0383\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [110/1000], Validation Loss: 0.0382\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [111/1000], Validation Loss: 0.0381\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [112/1000], Validation Loss: 0.0382\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [113/1000], Validation Loss: 0.0382\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [114/1000], Validation Loss: 0.0383\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [115/1000], Validation Loss: 0.0382\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [116/1000], Validation Loss: 0.0382\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [117/1000], Validation Loss: 0.0383\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [118/1000], Validation Loss: 0.0382\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [119/1000], Validation Loss: 0.0383\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [120/1000], Validation Loss: 0.0382\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [121/1000], Validation Loss: 0.0383\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [122/1000], Validation Loss: 0.0383\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [123/1000], Validation Loss: 0.0383\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [124/1000], Validation Loss: 0.0383\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [125/1000], Validation Loss: 0.0382\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [126/1000], Validation Loss: 0.0382\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [127/1000], Validation Loss: 0.0383\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [128/1000], Validation Loss: 0.0382\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [129/1000], Validation Loss: 0.0382\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [130/1000], Validation Loss: 0.0383\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [131/1000], Validation Loss: 0.0382\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [132/1000], Validation Loss: 0.0383\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [133/1000], Validation Loss: 0.0382\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [134/1000], Validation Loss: 0.0382\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [135/1000], Validation Loss: 0.0382\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [136/1000], Validation Loss: 0.0382\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [137/1000], Validation Loss: 0.0382\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [138/1000], Validation Loss: 0.0381\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [139/1000], Validation Loss: 0.0383\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [140/1000], Validation Loss: 0.0383\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [141/1000], Validation Loss: 0.0382\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [142/1000], Validation Loss: 0.0382\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [143/1000], Validation Loss: 0.0383\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [144/1000], Validation Loss: 0.0382\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [145/1000], Validation Loss: 0.0383\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [146/1000], Validation Loss: 0.0382\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [147/1000], Validation Loss: 0.0382\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [148/1000], Validation Loss: 0.0382\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [149/1000], Validation Loss: 0.0382\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [150/1000], Validation Loss: 0.0382\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [151/1000], Validation Loss: 0.0383\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [152/1000], Validation Loss: 0.0383\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [153/1000], Validation Loss: 0.0383\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [154/1000], Validation Loss: 0.0383\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [155/1000], Validation Loss: 0.0382\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [156/1000], Validation Loss: 0.0382\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [157/1000], Validation Loss: 0.0381\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [158/1000], Validation Loss: 0.0383\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [159/1000], Validation Loss: 0.0382\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [160/1000], Validation Loss: 0.0381\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [161/1000], Validation Loss: 0.0382\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [162/1000], Validation Loss: 0.0383\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [163/1000], Validation Loss: 0.0382\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [164/1000], Validation Loss: 0.0382\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [165/1000], Validation Loss: 0.0383\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [166/1000], Validation Loss: 0.0382\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [167/1000], Validation Loss: 0.0382\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [168/1000], Validation Loss: 0.0382\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [169/1000], Validation Loss: 0.0382\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [170/1000], Validation Loss: 0.0382\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [171/1000], Validation Loss: 0.0382\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [172/1000], Validation Loss: 0.0382\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [173/1000], Validation Loss: 0.0381\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [174/1000], Validation Loss: 0.0381\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [175/1000], Validation Loss: 0.0383\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [176/1000], Validation Loss: 0.0383\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [177/1000], Validation Loss: 0.0382\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [178/1000], Validation Loss: 0.0382\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [179/1000], Validation Loss: 0.0382\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [180/1000], Validation Loss: 0.0382\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [181/1000], Validation Loss: 0.0381\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [182/1000], Validation Loss: 0.0383\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [183/1000], Validation Loss: 0.0382\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [184/1000], Validation Loss: 0.0383\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [185/1000], Validation Loss: 0.0382\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [186/1000], Validation Loss: 0.0382\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [187/1000], Validation Loss: 0.0383\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0387\n",
            "Epoch [188/1000], Validation Loss: 0.0383\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [189/1000], Validation Loss: 0.0381\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [190/1000], Validation Loss: 0.0383\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [191/1000], Validation Loss: 0.0382\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [192/1000], Validation Loss: 0.0382\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [193/1000], Validation Loss: 0.0383\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [194/1000], Validation Loss: 0.0382\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [195/1000], Validation Loss: 0.0383\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [196/1000], Validation Loss: 0.0382\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [197/1000], Validation Loss: 0.0382\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [198/1000], Validation Loss: 0.0382\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [199/1000], Validation Loss: 0.0381\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [200/1000], Validation Loss: 0.0382\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [201/1000], Validation Loss: 0.0382\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [202/1000], Validation Loss: 0.0383\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [203/1000], Validation Loss: 0.0383\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [204/1000], Validation Loss: 0.0382\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [205/1000], Validation Loss: 0.0383\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [206/1000], Validation Loss: 0.0382\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [207/1000], Validation Loss: 0.0383\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [208/1000], Validation Loss: 0.0383\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [209/1000], Validation Loss: 0.0382\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [210/1000], Validation Loss: 0.0381\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [211/1000], Validation Loss: 0.0382\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [212/1000], Validation Loss: 0.0383\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [213/1000], Validation Loss: 0.0382\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [214/1000], Validation Loss: 0.0382\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [215/1000], Validation Loss: 0.0382\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [216/1000], Validation Loss: 0.0382\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [217/1000], Validation Loss: 0.0382\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [218/1000], Validation Loss: 0.0383\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [219/1000], Validation Loss: 0.0382\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [220/1000], Validation Loss: 0.0382\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [221/1000], Validation Loss: 0.0382\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [222/1000], Validation Loss: 0.0382\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [223/1000], Validation Loss: 0.0382\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [224/1000], Validation Loss: 0.0383\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [225/1000], Validation Loss: 0.0383\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [226/1000], Validation Loss: 0.0383\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [227/1000], Validation Loss: 0.0383\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [228/1000], Validation Loss: 0.0382\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [229/1000], Validation Loss: 0.0381\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [230/1000], Validation Loss: 0.0383\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [231/1000], Validation Loss: 0.0383\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [232/1000], Validation Loss: 0.0382\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [233/1000], Validation Loss: 0.0382\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [234/1000], Validation Loss: 0.0382\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [235/1000], Validation Loss: 0.0382\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [236/1000], Validation Loss: 0.0382\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [237/1000], Validation Loss: 0.0382\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [238/1000], Validation Loss: 0.0382\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [239/1000], Validation Loss: 0.0382\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [240/1000], Validation Loss: 0.0383\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [241/1000], Validation Loss: 0.0382\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [242/1000], Validation Loss: 0.0382\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [243/1000], Validation Loss: 0.0382\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [244/1000], Validation Loss: 0.0382\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [245/1000], Validation Loss: 0.0382\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [246/1000], Validation Loss: 0.0382\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [247/1000], Validation Loss: 0.0383\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [248/1000], Validation Loss: 0.0382\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [249/1000], Validation Loss: 0.0383\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [250/1000], Validation Loss: 0.0382\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [251/1000], Validation Loss: 0.0382\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [252/1000], Validation Loss: 0.0383\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [253/1000], Validation Loss: 0.0382\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [254/1000], Validation Loss: 0.0382\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [255/1000], Validation Loss: 0.0382\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [256/1000], Validation Loss: 0.0382\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [257/1000], Validation Loss: 0.0383\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [258/1000], Validation Loss: 0.0382\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [259/1000], Validation Loss: 0.0382\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [260/1000], Validation Loss: 0.0382\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [261/1000], Validation Loss: 0.0382\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [262/1000], Validation Loss: 0.0383\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [263/1000], Validation Loss: 0.0382\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [264/1000], Validation Loss: 0.0382\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [265/1000], Validation Loss: 0.0382\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [266/1000], Validation Loss: 0.0383\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [267/1000], Validation Loss: 0.0382\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [268/1000], Validation Loss: 0.0382\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [269/1000], Validation Loss: 0.0382\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [270/1000], Validation Loss: 0.0382\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [271/1000], Validation Loss: 0.0382\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [272/1000], Validation Loss: 0.0382\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [273/1000], Validation Loss: 0.0381\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [274/1000], Validation Loss: 0.0382\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [275/1000], Validation Loss: 0.0382\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [276/1000], Validation Loss: 0.0383\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [277/1000], Validation Loss: 0.0382\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [278/1000], Validation Loss: 0.0382\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [279/1000], Validation Loss: 0.0383\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [280/1000], Validation Loss: 0.0381\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [281/1000], Validation Loss: 0.0381\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [282/1000], Validation Loss: 0.0383\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [283/1000], Validation Loss: 0.0382\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [284/1000], Validation Loss: 0.0382\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [285/1000], Validation Loss: 0.0383\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [286/1000], Validation Loss: 0.0383\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [287/1000], Validation Loss: 0.0383\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [288/1000], Validation Loss: 0.0382\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [289/1000], Validation Loss: 0.0382\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [290/1000], Validation Loss: 0.0383\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [291/1000], Validation Loss: 0.0382\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [292/1000], Validation Loss: 0.0382\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [293/1000], Validation Loss: 0.0382\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [294/1000], Validation Loss: 0.0382\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [295/1000], Validation Loss: 0.0382\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [296/1000], Validation Loss: 0.0382\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [297/1000], Validation Loss: 0.0381\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [298/1000], Validation Loss: 0.0383\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [299/1000], Validation Loss: 0.0382\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [300/1000], Validation Loss: 0.0382\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [301/1000], Validation Loss: 0.0382\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [302/1000], Validation Loss: 0.0382\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [303/1000], Validation Loss: 0.0382\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [304/1000], Validation Loss: 0.0381\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [305/1000], Validation Loss: 0.0382\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [306/1000], Validation Loss: 0.0382\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [307/1000], Validation Loss: 0.0383\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [308/1000], Validation Loss: 0.0383\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [309/1000], Validation Loss: 0.0382\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [310/1000], Validation Loss: 0.0382\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [311/1000], Validation Loss: 0.0382\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [312/1000], Validation Loss: 0.0381\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [313/1000], Validation Loss: 0.0383\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [314/1000], Validation Loss: 0.0383\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [315/1000], Validation Loss: 0.0381\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [316/1000], Validation Loss: 0.0383\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [317/1000], Validation Loss: 0.0383\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [318/1000], Validation Loss: 0.0382\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [319/1000], Validation Loss: 0.0383\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [320/1000], Validation Loss: 0.0382\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [321/1000], Validation Loss: 0.0383\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [322/1000], Validation Loss: 0.0383\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [323/1000], Validation Loss: 0.0381\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [324/1000], Validation Loss: 0.0383\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [325/1000], Validation Loss: 0.0383\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [326/1000], Validation Loss: 0.0383\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [327/1000], Validation Loss: 0.0382\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [328/1000], Validation Loss: 0.0382\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [329/1000], Validation Loss: 0.0382\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [330/1000], Validation Loss: 0.0383\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [331/1000], Validation Loss: 0.0383\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [332/1000], Validation Loss: 0.0382\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [333/1000], Validation Loss: 0.0383\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [334/1000], Validation Loss: 0.0383\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [335/1000], Validation Loss: 0.0382\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [336/1000], Validation Loss: 0.0382\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [337/1000], Validation Loss: 0.0383\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [338/1000], Validation Loss: 0.0382\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [339/1000], Validation Loss: 0.0382\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [340/1000], Validation Loss: 0.0382\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [341/1000], Validation Loss: 0.0382\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [342/1000], Validation Loss: 0.0382\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [343/1000], Validation Loss: 0.0382\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [344/1000], Validation Loss: 0.0382\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [345/1000], Validation Loss: 0.0382\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [346/1000], Validation Loss: 0.0382\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [347/1000], Validation Loss: 0.0384\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [348/1000], Validation Loss: 0.0383\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [349/1000], Validation Loss: 0.0382\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [350/1000], Validation Loss: 0.0382\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [351/1000], Validation Loss: 0.0382\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [352/1000], Validation Loss: 0.0382\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [353/1000], Validation Loss: 0.0382\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [354/1000], Validation Loss: 0.0382\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [355/1000], Validation Loss: 0.0383\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [356/1000], Validation Loss: 0.0382\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [357/1000], Validation Loss: 0.0382\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [358/1000], Validation Loss: 0.0383\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [359/1000], Validation Loss: 0.0383\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [360/1000], Validation Loss: 0.0382\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [361/1000], Validation Loss: 0.0382\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [362/1000], Validation Loss: 0.0382\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [363/1000], Validation Loss: 0.0381\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [364/1000], Validation Loss: 0.0381\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [365/1000], Validation Loss: 0.0382\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [366/1000], Validation Loss: 0.0383\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [367/1000], Validation Loss: 0.0382\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [368/1000], Validation Loss: 0.0383\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [369/1000], Validation Loss: 0.0383\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [370/1000], Validation Loss: 0.0382\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [371/1000], Validation Loss: 0.0383\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [372/1000], Validation Loss: 0.0383\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [373/1000], Validation Loss: 0.0382\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [374/1000], Validation Loss: 0.0382\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [375/1000], Validation Loss: 0.0382\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [376/1000], Validation Loss: 0.0382\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [377/1000], Validation Loss: 0.0382\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [378/1000], Validation Loss: 0.0383\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [379/1000], Validation Loss: 0.0383\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [380/1000], Validation Loss: 0.0383\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [381/1000], Validation Loss: 0.0382\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [382/1000], Validation Loss: 0.0382\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [383/1000], Validation Loss: 0.0382\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [384/1000], Validation Loss: 0.0382\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [385/1000], Validation Loss: 0.0382\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [386/1000], Validation Loss: 0.0382\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [387/1000], Validation Loss: 0.0382\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [388/1000], Validation Loss: 0.0383\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [389/1000], Validation Loss: 0.0382\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [390/1000], Validation Loss: 0.0383\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [391/1000], Validation Loss: 0.0382\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [392/1000], Validation Loss: 0.0382\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [393/1000], Validation Loss: 0.0382\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [394/1000], Validation Loss: 0.0383\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [395/1000], Validation Loss: 0.0382\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [396/1000], Validation Loss: 0.0383\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [397/1000], Validation Loss: 0.0383\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [398/1000], Validation Loss: 0.0383\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [399/1000], Validation Loss: 0.0382\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [400/1000], Validation Loss: 0.0382\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [401/1000], Validation Loss: 0.0383\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [402/1000], Validation Loss: 0.0383\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [403/1000], Validation Loss: 0.0382\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [404/1000], Validation Loss: 0.0382\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [405/1000], Validation Loss: 0.0382\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [406/1000], Validation Loss: 0.0382\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [407/1000], Validation Loss: 0.0383\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [408/1000], Validation Loss: 0.0382\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [409/1000], Validation Loss: 0.0382\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [410/1000], Validation Loss: 0.0383\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [411/1000], Validation Loss: 0.0383\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [412/1000], Validation Loss: 0.0383\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [413/1000], Validation Loss: 0.0381\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [414/1000], Validation Loss: 0.0382\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [415/1000], Validation Loss: 0.0382\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [416/1000], Validation Loss: 0.0382\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [417/1000], Validation Loss: 0.0382\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [418/1000], Validation Loss: 0.0382\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [419/1000], Validation Loss: 0.0383\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [420/1000], Validation Loss: 0.0383\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [421/1000], Validation Loss: 0.0383\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [422/1000], Validation Loss: 0.0382\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [423/1000], Validation Loss: 0.0382\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [424/1000], Validation Loss: 0.0382\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [425/1000], Validation Loss: 0.0383\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [426/1000], Validation Loss: 0.0382\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [427/1000], Validation Loss: 0.0383\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [428/1000], Validation Loss: 0.0382\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [429/1000], Validation Loss: 0.0381\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [430/1000], Validation Loss: 0.0382\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [431/1000], Validation Loss: 0.0381\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [432/1000], Validation Loss: 0.0382\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [433/1000], Validation Loss: 0.0382\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [434/1000], Validation Loss: 0.0383\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [435/1000], Validation Loss: 0.0382\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [436/1000], Validation Loss: 0.0383\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [437/1000], Validation Loss: 0.0382\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [438/1000], Validation Loss: 0.0382\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [439/1000], Validation Loss: 0.0383\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [440/1000], Validation Loss: 0.0382\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [441/1000], Validation Loss: 0.0382\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [442/1000], Validation Loss: 0.0382\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [443/1000], Validation Loss: 0.0382\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [444/1000], Validation Loss: 0.0383\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [445/1000], Validation Loss: 0.0382\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [446/1000], Validation Loss: 0.0383\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [447/1000], Validation Loss: 0.0381\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [448/1000], Validation Loss: 0.0382\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [449/1000], Validation Loss: 0.0382\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [450/1000], Validation Loss: 0.0382\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [451/1000], Validation Loss: 0.0382\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [452/1000], Validation Loss: 0.0382\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [453/1000], Validation Loss: 0.0382\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [454/1000], Validation Loss: 0.0383\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [455/1000], Validation Loss: 0.0382\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [456/1000], Validation Loss: 0.0382\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [457/1000], Validation Loss: 0.0382\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [458/1000], Validation Loss: 0.0382\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [459/1000], Validation Loss: 0.0382\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [460/1000], Validation Loss: 0.0383\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [461/1000], Validation Loss: 0.0382\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [462/1000], Validation Loss: 0.0382\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [463/1000], Validation Loss: 0.0382\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [464/1000], Validation Loss: 0.0382\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [465/1000], Validation Loss: 0.0383\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [466/1000], Validation Loss: 0.0383\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [467/1000], Validation Loss: 0.0382\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [468/1000], Validation Loss: 0.0383\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [469/1000], Validation Loss: 0.0382\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [470/1000], Validation Loss: 0.0382\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [471/1000], Validation Loss: 0.0382\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [472/1000], Validation Loss: 0.0382\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [473/1000], Validation Loss: 0.0382\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [474/1000], Validation Loss: 0.0381\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [475/1000], Validation Loss: 0.0382\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [476/1000], Validation Loss: 0.0382\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [477/1000], Validation Loss: 0.0383\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [478/1000], Validation Loss: 0.0382\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [479/1000], Validation Loss: 0.0382\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [480/1000], Validation Loss: 0.0382\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [481/1000], Validation Loss: 0.0382\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [482/1000], Validation Loss: 0.0383\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [483/1000], Validation Loss: 0.0381\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [484/1000], Validation Loss: 0.0382\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [485/1000], Validation Loss: 0.0382\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [486/1000], Validation Loss: 0.0382\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [487/1000], Validation Loss: 0.0383\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [488/1000], Validation Loss: 0.0382\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [489/1000], Validation Loss: 0.0382\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [490/1000], Validation Loss: 0.0383\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [491/1000], Validation Loss: 0.0382\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [492/1000], Validation Loss: 0.0381\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [493/1000], Validation Loss: 0.0382\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [494/1000], Validation Loss: 0.0383\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [495/1000], Validation Loss: 0.0382\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [496/1000], Validation Loss: 0.0382\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [497/1000], Validation Loss: 0.0382\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [498/1000], Validation Loss: 0.0383\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [499/1000], Validation Loss: 0.0382\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [500/1000], Validation Loss: 0.0382\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [501/1000], Validation Loss: 0.0383\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [502/1000], Validation Loss: 0.0382\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [503/1000], Validation Loss: 0.0381\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [504/1000], Validation Loss: 0.0382\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [505/1000], Validation Loss: 0.0382\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [506/1000], Validation Loss: 0.0382\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [507/1000], Validation Loss: 0.0383\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [508/1000], Validation Loss: 0.0382\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [509/1000], Validation Loss: 0.0382\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [510/1000], Validation Loss: 0.0383\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [511/1000], Validation Loss: 0.0382\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [512/1000], Validation Loss: 0.0383\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [513/1000], Validation Loss: 0.0382\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [514/1000], Validation Loss: 0.0382\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [515/1000], Validation Loss: 0.0383\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [516/1000], Validation Loss: 0.0382\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [517/1000], Validation Loss: 0.0381\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [518/1000], Validation Loss: 0.0382\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [519/1000], Validation Loss: 0.0383\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [520/1000], Validation Loss: 0.0382\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [521/1000], Validation Loss: 0.0383\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [522/1000], Validation Loss: 0.0382\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [523/1000], Validation Loss: 0.0382\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [524/1000], Validation Loss: 0.0383\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [525/1000], Validation Loss: 0.0382\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [526/1000], Validation Loss: 0.0383\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [527/1000], Validation Loss: 0.0383\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [528/1000], Validation Loss: 0.0382\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [529/1000], Validation Loss: 0.0383\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [530/1000], Validation Loss: 0.0383\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [531/1000], Validation Loss: 0.0383\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0387\n",
            "Epoch [532/1000], Validation Loss: 0.0382\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [533/1000], Validation Loss: 0.0383\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [534/1000], Validation Loss: 0.0382\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [535/1000], Validation Loss: 0.0382\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [536/1000], Validation Loss: 0.0383\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [537/1000], Validation Loss: 0.0383\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [538/1000], Validation Loss: 0.0382\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [539/1000], Validation Loss: 0.0383\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [540/1000], Validation Loss: 0.0382\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [541/1000], Validation Loss: 0.0382\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [542/1000], Validation Loss: 0.0383\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [543/1000], Validation Loss: 0.0383\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [544/1000], Validation Loss: 0.0382\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [545/1000], Validation Loss: 0.0382\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [546/1000], Validation Loss: 0.0382\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [547/1000], Validation Loss: 0.0383\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [548/1000], Validation Loss: 0.0382\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [549/1000], Validation Loss: 0.0382\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [550/1000], Validation Loss: 0.0382\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [551/1000], Validation Loss: 0.0382\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [552/1000], Validation Loss: 0.0382\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [553/1000], Validation Loss: 0.0382\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [554/1000], Validation Loss: 0.0382\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [555/1000], Validation Loss: 0.0383\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [556/1000], Validation Loss: 0.0383\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0366\n",
            "Epoch [557/1000], Validation Loss: 0.0383\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [558/1000], Validation Loss: 0.0383\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [559/1000], Validation Loss: 0.0383\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [560/1000], Validation Loss: 0.0382\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [561/1000], Validation Loss: 0.0382\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [562/1000], Validation Loss: 0.0383\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [563/1000], Validation Loss: 0.0382\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [564/1000], Validation Loss: 0.0382\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [565/1000], Validation Loss: 0.0381\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [566/1000], Validation Loss: 0.0383\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [567/1000], Validation Loss: 0.0382\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [568/1000], Validation Loss: 0.0383\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [569/1000], Validation Loss: 0.0383\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [570/1000], Validation Loss: 0.0383\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [571/1000], Validation Loss: 0.0382\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [572/1000], Validation Loss: 0.0382\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [573/1000], Validation Loss: 0.0383\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [574/1000], Validation Loss: 0.0382\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [575/1000], Validation Loss: 0.0382\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [576/1000], Validation Loss: 0.0383\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [577/1000], Validation Loss: 0.0382\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [578/1000], Validation Loss: 0.0383\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [579/1000], Validation Loss: 0.0383\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [580/1000], Validation Loss: 0.0381\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [581/1000], Validation Loss: 0.0383\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [582/1000], Validation Loss: 0.0381\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [583/1000], Validation Loss: 0.0383\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [584/1000], Validation Loss: 0.0383\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [585/1000], Validation Loss: 0.0382\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [586/1000], Validation Loss: 0.0383\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [587/1000], Validation Loss: 0.0383\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [588/1000], Validation Loss: 0.0382\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [589/1000], Validation Loss: 0.0382\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [590/1000], Validation Loss: 0.0383\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [591/1000], Validation Loss: 0.0381\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [592/1000], Validation Loss: 0.0382\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [593/1000], Validation Loss: 0.0382\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [594/1000], Validation Loss: 0.0382\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [595/1000], Validation Loss: 0.0382\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [596/1000], Validation Loss: 0.0383\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [597/1000], Validation Loss: 0.0382\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [598/1000], Validation Loss: 0.0382\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [599/1000], Validation Loss: 0.0383\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [600/1000], Validation Loss: 0.0382\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [601/1000], Validation Loss: 0.0383\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [602/1000], Validation Loss: 0.0382\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [603/1000], Validation Loss: 0.0382\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [604/1000], Validation Loss: 0.0382\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [605/1000], Validation Loss: 0.0382\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [606/1000], Validation Loss: 0.0382\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [607/1000], Validation Loss: 0.0383\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [608/1000], Validation Loss: 0.0382\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [609/1000], Validation Loss: 0.0382\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [610/1000], Validation Loss: 0.0383\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [611/1000], Validation Loss: 0.0383\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [612/1000], Validation Loss: 0.0382\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [613/1000], Validation Loss: 0.0383\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [614/1000], Validation Loss: 0.0382\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [615/1000], Validation Loss: 0.0381\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [616/1000], Validation Loss: 0.0382\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [617/1000], Validation Loss: 0.0382\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [618/1000], Validation Loss: 0.0382\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [619/1000], Validation Loss: 0.0382\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [620/1000], Validation Loss: 0.0382\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [621/1000], Validation Loss: 0.0383\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [622/1000], Validation Loss: 0.0382\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [623/1000], Validation Loss: 0.0383\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [624/1000], Validation Loss: 0.0382\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [625/1000], Validation Loss: 0.0382\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [626/1000], Validation Loss: 0.0382\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [627/1000], Validation Loss: 0.0383\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [628/1000], Validation Loss: 0.0382\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [629/1000], Validation Loss: 0.0383\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [630/1000], Validation Loss: 0.0382\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [631/1000], Validation Loss: 0.0383\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [632/1000], Validation Loss: 0.0382\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [633/1000], Validation Loss: 0.0382\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [634/1000], Validation Loss: 0.0382\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [635/1000], Validation Loss: 0.0382\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [636/1000], Validation Loss: 0.0383\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [637/1000], Validation Loss: 0.0382\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [638/1000], Validation Loss: 0.0382\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [639/1000], Validation Loss: 0.0382\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [640/1000], Validation Loss: 0.0382\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [641/1000], Validation Loss: 0.0383\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [642/1000], Validation Loss: 0.0383\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [643/1000], Validation Loss: 0.0382\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [644/1000], Validation Loss: 0.0382\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [645/1000], Validation Loss: 0.0383\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [646/1000], Validation Loss: 0.0382\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [647/1000], Validation Loss: 0.0382\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [648/1000], Validation Loss: 0.0383\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [649/1000], Validation Loss: 0.0382\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [650/1000], Validation Loss: 0.0381\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [651/1000], Validation Loss: 0.0382\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [652/1000], Validation Loss: 0.0381\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [653/1000], Validation Loss: 0.0382\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [654/1000], Validation Loss: 0.0381\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [655/1000], Validation Loss: 0.0382\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [656/1000], Validation Loss: 0.0383\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [657/1000], Validation Loss: 0.0382\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [658/1000], Validation Loss: 0.0382\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [659/1000], Validation Loss: 0.0383\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [660/1000], Validation Loss: 0.0382\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [661/1000], Validation Loss: 0.0383\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0388\n",
            "Epoch [662/1000], Validation Loss: 0.0382\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [663/1000], Validation Loss: 0.0383\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [664/1000], Validation Loss: 0.0382\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [665/1000], Validation Loss: 0.0382\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [666/1000], Validation Loss: 0.0382\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [667/1000], Validation Loss: 0.0382\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [668/1000], Validation Loss: 0.0382\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [669/1000], Validation Loss: 0.0382\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [670/1000], Validation Loss: 0.0382\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [671/1000], Validation Loss: 0.0382\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [672/1000], Validation Loss: 0.0382\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [673/1000], Validation Loss: 0.0383\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [674/1000], Validation Loss: 0.0382\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [675/1000], Validation Loss: 0.0382\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [676/1000], Validation Loss: 0.0382\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [677/1000], Validation Loss: 0.0382\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [678/1000], Validation Loss: 0.0382\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [679/1000], Validation Loss: 0.0382\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [680/1000], Validation Loss: 0.0382\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [681/1000], Validation Loss: 0.0382\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [682/1000], Validation Loss: 0.0383\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [683/1000], Validation Loss: 0.0383\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [684/1000], Validation Loss: 0.0382\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [685/1000], Validation Loss: 0.0382\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [686/1000], Validation Loss: 0.0382\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [687/1000], Validation Loss: 0.0382\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [688/1000], Validation Loss: 0.0381\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [689/1000], Validation Loss: 0.0383\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [690/1000], Validation Loss: 0.0382\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [691/1000], Validation Loss: 0.0381\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [692/1000], Validation Loss: 0.0382\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [693/1000], Validation Loss: 0.0382\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [694/1000], Validation Loss: 0.0382\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [695/1000], Validation Loss: 0.0382\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [696/1000], Validation Loss: 0.0383\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [697/1000], Validation Loss: 0.0383\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [698/1000], Validation Loss: 0.0383\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [699/1000], Validation Loss: 0.0382\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [700/1000], Validation Loss: 0.0382\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [701/1000], Validation Loss: 0.0382\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [702/1000], Validation Loss: 0.0383\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [703/1000], Validation Loss: 0.0382\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [704/1000], Validation Loss: 0.0382\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [705/1000], Validation Loss: 0.0383\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [706/1000], Validation Loss: 0.0382\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [707/1000], Validation Loss: 0.0382\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [708/1000], Validation Loss: 0.0381\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [709/1000], Validation Loss: 0.0383\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [710/1000], Validation Loss: 0.0383\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [711/1000], Validation Loss: 0.0382\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [712/1000], Validation Loss: 0.0383\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [713/1000], Validation Loss: 0.0382\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [714/1000], Validation Loss: 0.0381\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [715/1000], Validation Loss: 0.0383\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [716/1000], Validation Loss: 0.0382\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [717/1000], Validation Loss: 0.0382\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [718/1000], Validation Loss: 0.0383\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [719/1000], Validation Loss: 0.0383\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [720/1000], Validation Loss: 0.0383\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [721/1000], Validation Loss: 0.0382\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [722/1000], Validation Loss: 0.0382\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [723/1000], Validation Loss: 0.0382\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [724/1000], Validation Loss: 0.0382\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [725/1000], Validation Loss: 0.0383\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [726/1000], Validation Loss: 0.0382\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [727/1000], Validation Loss: 0.0383\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [728/1000], Validation Loss: 0.0382\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [729/1000], Validation Loss: 0.0382\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [730/1000], Validation Loss: 0.0383\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [731/1000], Validation Loss: 0.0382\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [732/1000], Validation Loss: 0.0382\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [733/1000], Validation Loss: 0.0382\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [734/1000], Validation Loss: 0.0383\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [735/1000], Validation Loss: 0.0382\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [736/1000], Validation Loss: 0.0382\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [737/1000], Validation Loss: 0.0382\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [738/1000], Validation Loss: 0.0383\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [739/1000], Validation Loss: 0.0382\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [740/1000], Validation Loss: 0.0382\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [741/1000], Validation Loss: 0.0383\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [742/1000], Validation Loss: 0.0383\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [743/1000], Validation Loss: 0.0383\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [744/1000], Validation Loss: 0.0383\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [745/1000], Validation Loss: 0.0383\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [746/1000], Validation Loss: 0.0383\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [747/1000], Validation Loss: 0.0382\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [748/1000], Validation Loss: 0.0383\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [749/1000], Validation Loss: 0.0383\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [750/1000], Validation Loss: 0.0381\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [751/1000], Validation Loss: 0.0381\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [752/1000], Validation Loss: 0.0382\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [753/1000], Validation Loss: 0.0382\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [754/1000], Validation Loss: 0.0382\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [755/1000], Validation Loss: 0.0382\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [756/1000], Validation Loss: 0.0382\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [757/1000], Validation Loss: 0.0382\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [758/1000], Validation Loss: 0.0383\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [759/1000], Validation Loss: 0.0382\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [760/1000], Validation Loss: 0.0382\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [761/1000], Validation Loss: 0.0382\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [762/1000], Validation Loss: 0.0383\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [763/1000], Validation Loss: 0.0382\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [764/1000], Validation Loss: 0.0382\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [765/1000], Validation Loss: 0.0382\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [766/1000], Validation Loss: 0.0382\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [767/1000], Validation Loss: 0.0382\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [768/1000], Validation Loss: 0.0382\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [769/1000], Validation Loss: 0.0382\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [770/1000], Validation Loss: 0.0383\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [771/1000], Validation Loss: 0.0382\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [772/1000], Validation Loss: 0.0382\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [773/1000], Validation Loss: 0.0382\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [774/1000], Validation Loss: 0.0383\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [775/1000], Validation Loss: 0.0382\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [776/1000], Validation Loss: 0.0382\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [777/1000], Validation Loss: 0.0383\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [778/1000], Validation Loss: 0.0383\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [779/1000], Validation Loss: 0.0383\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [780/1000], Validation Loss: 0.0383\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [781/1000], Validation Loss: 0.0382\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [782/1000], Validation Loss: 0.0382\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [783/1000], Validation Loss: 0.0382\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [784/1000], Validation Loss: 0.0383\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [785/1000], Validation Loss: 0.0383\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [786/1000], Validation Loss: 0.0382\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [787/1000], Validation Loss: 0.0382\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [788/1000], Validation Loss: 0.0381\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [789/1000], Validation Loss: 0.0382\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [790/1000], Validation Loss: 0.0383\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [791/1000], Validation Loss: 0.0381\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [792/1000], Validation Loss: 0.0382\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [793/1000], Validation Loss: 0.0382\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [794/1000], Validation Loss: 0.0383\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [795/1000], Validation Loss: 0.0383\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [796/1000], Validation Loss: 0.0381\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [797/1000], Validation Loss: 0.0381\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [798/1000], Validation Loss: 0.0381\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [799/1000], Validation Loss: 0.0383\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [800/1000], Validation Loss: 0.0382\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [801/1000], Validation Loss: 0.0382\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [802/1000], Validation Loss: 0.0382\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [803/1000], Validation Loss: 0.0381\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [804/1000], Validation Loss: 0.0383\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [805/1000], Validation Loss: 0.0383\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [806/1000], Validation Loss: 0.0381\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [807/1000], Validation Loss: 0.0382\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [808/1000], Validation Loss: 0.0383\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [809/1000], Validation Loss: 0.0382\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [810/1000], Validation Loss: 0.0383\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [811/1000], Validation Loss: 0.0383\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [812/1000], Validation Loss: 0.0382\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [813/1000], Validation Loss: 0.0382\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [814/1000], Validation Loss: 0.0382\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [815/1000], Validation Loss: 0.0382\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [816/1000], Validation Loss: 0.0381\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [817/1000], Validation Loss: 0.0382\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [818/1000], Validation Loss: 0.0382\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [819/1000], Validation Loss: 0.0382\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [820/1000], Validation Loss: 0.0382\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [821/1000], Validation Loss: 0.0382\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [822/1000], Validation Loss: 0.0383\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [823/1000], Validation Loss: 0.0382\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [824/1000], Validation Loss: 0.0383\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [825/1000], Validation Loss: 0.0383\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [826/1000], Validation Loss: 0.0382\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [827/1000], Validation Loss: 0.0382\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [828/1000], Validation Loss: 0.0382\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [829/1000], Validation Loss: 0.0382\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [830/1000], Validation Loss: 0.0383\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [831/1000], Validation Loss: 0.0382\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [832/1000], Validation Loss: 0.0382\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [833/1000], Validation Loss: 0.0382\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [834/1000], Validation Loss: 0.0383\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [835/1000], Validation Loss: 0.0382\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [836/1000], Validation Loss: 0.0381\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [837/1000], Validation Loss: 0.0382\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [838/1000], Validation Loss: 0.0381\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [839/1000], Validation Loss: 0.0382\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [840/1000], Validation Loss: 0.0383\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [841/1000], Validation Loss: 0.0382\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [842/1000], Validation Loss: 0.0383\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [843/1000], Validation Loss: 0.0382\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [844/1000], Validation Loss: 0.0382\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [845/1000], Validation Loss: 0.0382\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [846/1000], Validation Loss: 0.0382\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [847/1000], Validation Loss: 0.0383\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [848/1000], Validation Loss: 0.0383\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [849/1000], Validation Loss: 0.0383\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [850/1000], Validation Loss: 0.0382\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [851/1000], Validation Loss: 0.0382\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [852/1000], Validation Loss: 0.0382\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [853/1000], Validation Loss: 0.0381\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [854/1000], Validation Loss: 0.0382\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [855/1000], Validation Loss: 0.0383\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [856/1000], Validation Loss: 0.0382\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [857/1000], Validation Loss: 0.0383\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [858/1000], Validation Loss: 0.0382\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [859/1000], Validation Loss: 0.0383\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [860/1000], Validation Loss: 0.0382\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [861/1000], Validation Loss: 0.0381\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [862/1000], Validation Loss: 0.0382\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [863/1000], Validation Loss: 0.0383\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [864/1000], Validation Loss: 0.0383\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [865/1000], Validation Loss: 0.0383\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [866/1000], Validation Loss: 0.0381\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [867/1000], Validation Loss: 0.0382\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [868/1000], Validation Loss: 0.0383\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [869/1000], Validation Loss: 0.0383\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [870/1000], Validation Loss: 0.0382\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [871/1000], Validation Loss: 0.0383\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [872/1000], Validation Loss: 0.0383\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [873/1000], Validation Loss: 0.0383\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [874/1000], Validation Loss: 0.0382\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [875/1000], Validation Loss: 0.0382\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [876/1000], Validation Loss: 0.0383\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [877/1000], Validation Loss: 0.0382\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [878/1000], Validation Loss: 0.0383\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [879/1000], Validation Loss: 0.0382\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [880/1000], Validation Loss: 0.0382\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [881/1000], Validation Loss: 0.0382\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [882/1000], Validation Loss: 0.0382\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [883/1000], Validation Loss: 0.0382\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [884/1000], Validation Loss: 0.0382\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [885/1000], Validation Loss: 0.0383\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [886/1000], Validation Loss: 0.0382\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [887/1000], Validation Loss: 0.0383\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [888/1000], Validation Loss: 0.0383\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [889/1000], Validation Loss: 0.0383\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [890/1000], Validation Loss: 0.0383\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [891/1000], Validation Loss: 0.0383\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [892/1000], Validation Loss: 0.0382\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [893/1000], Validation Loss: 0.0382\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [894/1000], Validation Loss: 0.0382\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [895/1000], Validation Loss: 0.0382\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [896/1000], Validation Loss: 0.0383\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [897/1000], Validation Loss: 0.0382\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [898/1000], Validation Loss: 0.0382\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [899/1000], Validation Loss: 0.0382\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [900/1000], Validation Loss: 0.0382\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [901/1000], Validation Loss: 0.0382\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [902/1000], Validation Loss: 0.0383\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [903/1000], Validation Loss: 0.0383\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [904/1000], Validation Loss: 0.0383\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [905/1000], Validation Loss: 0.0382\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [906/1000], Validation Loss: 0.0382\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [907/1000], Validation Loss: 0.0383\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [908/1000], Validation Loss: 0.0382\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [909/1000], Validation Loss: 0.0382\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [910/1000], Validation Loss: 0.0382\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [911/1000], Validation Loss: 0.0381\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [912/1000], Validation Loss: 0.0383\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [913/1000], Validation Loss: 0.0382\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [914/1000], Validation Loss: 0.0382\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [915/1000], Validation Loss: 0.0383\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [916/1000], Validation Loss: 0.0383\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [917/1000], Validation Loss: 0.0383\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [918/1000], Validation Loss: 0.0382\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [919/1000], Validation Loss: 0.0382\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [920/1000], Validation Loss: 0.0383\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [921/1000], Validation Loss: 0.0382\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [922/1000], Validation Loss: 0.0382\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [923/1000], Validation Loss: 0.0382\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [924/1000], Validation Loss: 0.0383\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [925/1000], Validation Loss: 0.0382\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [926/1000], Validation Loss: 0.0382\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [927/1000], Validation Loss: 0.0382\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [928/1000], Validation Loss: 0.0382\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [929/1000], Validation Loss: 0.0382\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [930/1000], Validation Loss: 0.0382\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [931/1000], Validation Loss: 0.0382\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [932/1000], Validation Loss: 0.0382\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [933/1000], Validation Loss: 0.0382\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [934/1000], Validation Loss: 0.0382\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [935/1000], Validation Loss: 0.0382\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [936/1000], Validation Loss: 0.0382\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [937/1000], Validation Loss: 0.0381\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [938/1000], Validation Loss: 0.0382\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [939/1000], Validation Loss: 0.0382\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [940/1000], Validation Loss: 0.0383\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [941/1000], Validation Loss: 0.0382\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [942/1000], Validation Loss: 0.0383\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [943/1000], Validation Loss: 0.0382\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [944/1000], Validation Loss: 0.0382\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [945/1000], Validation Loss: 0.0382\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [946/1000], Validation Loss: 0.0382\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [947/1000], Validation Loss: 0.0382\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [948/1000], Validation Loss: 0.0382\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [949/1000], Validation Loss: 0.0382\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [950/1000], Validation Loss: 0.0382\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [951/1000], Validation Loss: 0.0382\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [952/1000], Validation Loss: 0.0383\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [953/1000], Validation Loss: 0.0382\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [954/1000], Validation Loss: 0.0382\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [955/1000], Validation Loss: 0.0383\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [956/1000], Validation Loss: 0.0382\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [957/1000], Validation Loss: 0.0382\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [958/1000], Validation Loss: 0.0383\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [959/1000], Validation Loss: 0.0382\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [960/1000], Validation Loss: 0.0383\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [961/1000], Validation Loss: 0.0383\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [962/1000], Validation Loss: 0.0382\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [963/1000], Validation Loss: 0.0383\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [964/1000], Validation Loss: 0.0383\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [965/1000], Validation Loss: 0.0383\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [966/1000], Validation Loss: 0.0382\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [967/1000], Validation Loss: 0.0382\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [968/1000], Validation Loss: 0.0382\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [969/1000], Validation Loss: 0.0382\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [970/1000], Validation Loss: 0.0383\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [971/1000], Validation Loss: 0.0382\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [972/1000], Validation Loss: 0.0382\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [973/1000], Validation Loss: 0.0381\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [974/1000], Validation Loss: 0.0383\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [975/1000], Validation Loss: 0.0382\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [976/1000], Validation Loss: 0.0381\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [977/1000], Validation Loss: 0.0382\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [978/1000], Validation Loss: 0.0382\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [979/1000], Validation Loss: 0.0383\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [980/1000], Validation Loss: 0.0382\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [981/1000], Validation Loss: 0.0383\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [982/1000], Validation Loss: 0.0383\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [983/1000], Validation Loss: 0.0382\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [984/1000], Validation Loss: 0.0382\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [985/1000], Validation Loss: 0.0383\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [986/1000], Validation Loss: 0.0382\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [987/1000], Validation Loss: 0.0383\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [988/1000], Validation Loss: 0.0382\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [989/1000], Validation Loss: 0.0383\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [990/1000], Validation Loss: 0.0382\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [991/1000], Validation Loss: 0.0382\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [992/1000], Validation Loss: 0.0382\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [993/1000], Validation Loss: 0.0382\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [994/1000], Validation Loss: 0.0382\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [995/1000], Validation Loss: 0.0382\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [996/1000], Validation Loss: 0.0382\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [997/1000], Validation Loss: 0.0383\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [998/1000], Validation Loss: 0.0381\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [999/1000], Validation Loss: 0.0382\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [1000/1000], Validation Loss: 0.0382\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPFAW-kJL9dV",
        "outputId": "15967133-b68b-495c-c8c9-2cf6adb3e8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.037904392927885056,\n",
              " 0.037195563316345215,\n",
              " 0.03758431226015091,\n",
              " 0.03771628439426422,\n",
              " 0.03793232515454292,\n",
              " 0.03719206154346466,\n",
              " 0.037802327424287796,\n",
              " 0.03734620288014412,\n",
              " 0.03778769075870514,\n",
              " 0.037410397082567215,\n",
              " 0.03770967572927475,\n",
              " 0.03752969577908516,\n",
              " 0.03786255419254303,\n",
              " 0.03727363795042038,\n",
              " 0.03767665475606918,\n",
              " 0.0376417450606823,\n",
              " 0.03785935789346695,\n",
              " 0.03729652985930443,\n",
              " 0.03719864413142204,\n",
              " 0.0380912646651268,\n",
              " 0.03798770159482956,\n",
              " 0.03724668174982071,\n",
              " 0.03755659982562065,\n",
              " 0.03776998817920685,\n",
              " 0.0375327467918396,\n",
              " 0.037792056798934937,\n",
              " 0.03748596832156181,\n",
              " 0.03795449063181877,\n",
              " 0.03781898319721222,\n",
              " 0.0373639352619648,\n",
              " 0.03734074532985687,\n",
              " 0.03803573176264763,\n",
              " 0.037850067019462585,\n",
              " 0.037272557616233826,\n",
              " 0.03770868107676506,\n",
              " 0.0375395193696022,\n",
              " 0.037011295557022095,\n",
              " 0.03863564878702164,\n",
              " 0.03709288686513901,\n",
              " 0.03843695670366287,\n",
              " 0.037963394075632095,\n",
              " 0.03722498193383217,\n",
              " 0.03755880892276764,\n",
              " 0.03769954293966293,\n",
              " 0.03772813081741333,\n",
              " 0.03755708411335945,\n",
              " 0.03760956972837448,\n",
              " 0.03762303665280342,\n",
              " 0.03765060380101204,\n",
              " 0.03755282610654831,\n",
              " 0.03740273416042328,\n",
              " 0.038011584430933,\n",
              " 0.03766823932528496,\n",
              " 0.03742051497101784,\n",
              " 0.037915267050266266,\n",
              " 0.037161704152822495,\n",
              " 0.03764345869421959,\n",
              " 0.03753802180290222,\n",
              " 0.03753620386123657,\n",
              " 0.03777606785297394,\n",
              " 0.03771766647696495,\n",
              " 0.03731240704655647,\n",
              " 0.037656284868717194,\n",
              " 0.03758618235588074,\n",
              " 0.037402331829071045,\n",
              " 0.038016177713871,\n",
              " 0.03768832981586456,\n",
              " 0.037511225789785385,\n",
              " 0.03747820854187012,\n",
              " 0.03777703270316124,\n",
              " 0.03770747780799866,\n",
              " 0.037525177001953125,\n",
              " 0.03768777474761009,\n",
              " 0.03753969445824623,\n",
              " 0.038090433925390244,\n",
              " 0.03693054988980293,\n",
              " 0.03769424557685852,\n",
              " 0.03759271278977394,\n",
              " 0.03722045570611954,\n",
              " 0.0383058562874794,\n",
              " 0.03759842738509178,\n",
              " 0.03780968487262726,\n",
              " 0.03754114359617233,\n",
              " 0.037684280425310135,\n",
              " 0.037851374596357346,\n",
              " 0.03729468956589699,\n",
              " 0.038211286067962646,\n",
              " 0.036723095923662186,\n",
              " 0.03774191066622734,\n",
              " 0.03735692426562309,\n",
              " 0.03735368326306343,\n",
              " 0.0381055623292923,\n",
              " 0.03741328418254852,\n",
              " 0.037910763174295425,\n",
              " 0.036882348358631134,\n",
              " 0.03875010460615158,\n",
              " 0.03780025243759155,\n",
              " 0.03746131807565689,\n",
              " 0.037381429225206375,\n",
              " 0.037942446768283844,\n",
              " 0.037344302982091904,\n",
              " 0.038034189492464066,\n",
              " 0.037724532186985016,\n",
              " 0.037480223923921585,\n",
              " 0.037937361747026443,\n",
              " 0.03708522021770477,\n",
              " 0.03769679740071297,\n",
              " 0.03751630708575249,\n",
              " 0.03751230239868164,\n",
              " 0.037909820675849915,\n",
              " 0.03737097978591919,\n",
              " 0.03803499788045883,\n",
              " 0.037376902997493744,\n",
              " 0.038065649569034576,\n",
              " 0.03801684454083443,\n",
              " 0.037116751074790955,\n",
              " 0.037405770272016525,\n",
              " 0.038000959903001785,\n",
              " 0.037215668708086014,\n",
              " 0.03827577456831932,\n",
              " 0.03809899464249611,\n",
              " 0.03699593245983124,\n",
              " 0.03773021325469017,\n",
              " 0.03740520030260086,\n",
              " 0.03793872147798538,\n",
              " 0.03709324821829796,\n",
              " 0.03752371296286583,\n",
              " 0.037886135280132294,\n",
              " 0.03769815340638161,\n",
              " 0.0375201478600502,\n",
              " 0.03756813332438469,\n",
              " 0.03763763606548309,\n",
              " 0.03759470209479332,\n",
              " 0.037574950605630875,\n",
              " 0.03736724331974983,\n",
              " 0.0380733422935009,\n",
              " 0.03783133625984192,\n",
              " 0.03730729594826698,\n",
              " 0.03805193305015564,\n",
              " 0.03703521937131882,\n",
              " 0.03762310743331909,\n",
              " 0.03765656799077988,\n",
              " 0.03781744837760925,\n",
              " 0.037325575947761536,\n",
              " 0.03797318413853645,\n",
              " 0.03701115772128105,\n",
              " 0.03748495504260063,\n",
              " 0.03788638487458229,\n",
              " 0.03754574432969093,\n",
              " 0.037740930914878845,\n",
              " 0.03787226974964142,\n",
              " 0.0372408963739872,\n",
              " 0.037739742547273636,\n",
              " 0.037385351955890656,\n",
              " 0.03784732520580292,\n",
              " 0.037310972809791565,\n",
              " 0.03739144653081894,\n",
              " 0.037986576557159424,\n",
              " 0.03722769394516945,\n",
              " 0.03828496113419533,\n",
              " 0.03753090277314186,\n",
              " 0.03777339309453964,\n",
              " 0.037400223314762115,\n",
              " 0.03800049051642418,\n",
              " 0.038010336458683014,\n",
              " 0.03704051300883293,\n",
              " 0.03751254826784134,\n",
              " 0.03790725767612457,\n",
              " 0.03812795132398605,\n",
              " 0.0369560532271862,\n",
              " 0.03774178400635719,\n",
              " 0.03744189813733101,\n",
              " 0.037633225321769714,\n",
              " 0.03758976235985756,\n",
              " 0.03720178082585335,\n",
              " 0.03829988092184067,\n",
              " 0.037837572395801544,\n",
              " 0.03737550973892212,\n",
              " 0.03731232509016991,\n",
              " 0.03821192681789398,\n",
              " 0.037875112146139145,\n",
              " 0.037129029631614685,\n",
              " 0.03796787187457085,\n",
              " 0.037247899919748306,\n",
              " 0.03758363425731659,\n",
              " 0.03763749450445175,\n",
              " 0.0378846749663353,\n",
              " 0.03731613606214523,\n",
              " 0.03729037195444107,\n",
              " 0.03816170617938042,\n",
              " 0.03763184696435928,\n",
              " 0.03767160326242447,\n",
              " 0.03784298151731491,\n",
              " 0.03727483004331589,\n",
              " 0.037644512951374054,\n",
              " 0.037592556327581406,\n",
              " 0.03758244216442108,\n",
              " 0.037647996097803116,\n",
              " 0.03717551380395889,\n",
              " 0.038278140127658844,\n",
              " 0.03715813532471657,\n",
              " 0.03845914080739021,\n",
              " 0.037550076842308044,\n",
              " 0.03788469731807709,\n",
              " 0.037524621933698654,\n",
              " 0.03783510997891426,\n",
              " 0.037364277988672256,\n",
              " 0.03802766650915146,\n",
              " 0.037805814296007156,\n",
              " 0.03745291382074356,\n",
              " 0.037916965782642365,\n",
              " 0.03723287954926491,\n",
              " 0.03765163943171501,\n",
              " 0.03759611397981644,\n",
              " 0.03745773434638977,\n",
              " 0.03778970614075661,\n",
              " 0.037735339254140854,\n",
              " 0.03748799115419388,\n",
              " 0.03755062073469162,\n",
              " 0.03775455430150032,\n",
              " 0.0374419130384922,\n",
              " 0.037928659468889236,\n",
              " 0.03742784261703491,\n",
              " 0.03787560015916824,\n",
              " 0.037694044411182404,\n",
              " 0.037522949278354645,\n",
              " 0.03773244842886925,\n",
              " 0.03743862733244896,\n",
              " 0.03802989050745964,\n",
              " 0.03696113079786301,\n",
              " 0.037662338465452194,\n",
              " 0.03763822093605995,\n",
              " 0.03768393397331238,\n",
              " 0.03753599897027016,\n",
              " 0.03764231503009796,\n",
              " 0.03765714913606644,\n",
              " 0.03737948462367058,\n",
              " 0.03801703453063965,\n",
              " 0.037840958684682846,\n",
              " 0.03734859079122543,\n",
              " 0.037859559059143066,\n",
              " 0.03736790642142296,\n",
              " 0.03765874728560448,\n",
              " 0.03760072961449623,\n",
              " 0.03799058869481087,\n",
              " 0.0371461845934391,\n",
              " 0.037749797105789185,\n",
              " 0.03750895336270332,\n",
              " 0.037994544953107834,\n",
              " 0.03710244968533516,\n",
              " 0.0376264862716198,\n",
              " 0.0376175232231617,\n",
              " 0.037425681948661804,\n",
              " 0.03785640001296997,\n",
              " 0.03754037991166115,\n",
              " 0.037931889295578,\n",
              " 0.03712058439850807,\n",
              " 0.03831639140844345,\n",
              " 0.037583332508802414,\n",
              " 0.03773929178714752,\n",
              " 0.03761164844036102,\n",
              " 0.03768695518374443,\n",
              " 0.037667710334062576,\n",
              " 0.037617165595293045,\n",
              " 0.03750668093562126,\n",
              " 0.037797246128320694,\n",
              " 0.03788655996322632,\n",
              " 0.03722810372710228,\n",
              " 0.037569161504507065,\n",
              " 0.03773186355829239,\n",
              " 0.03767084702849388,\n",
              " 0.037672847509384155,\n",
              " 0.037809714674949646,\n",
              " 0.037284985184669495,\n",
              " 0.037782590836286545,\n",
              " 0.03748700022697449,\n",
              " 0.03799613192677498,\n",
              " 0.03712257742881775,\n",
              " 0.037957437336444855,\n",
              " 0.03706654533743858,\n",
              " 0.03807083144783974,\n",
              " 0.03702197223901749,\n",
              " 0.03745047003030777,\n",
              " 0.03785422816872597,\n",
              " 0.037509262561798096,\n",
              " 0.037742506712675095,\n",
              " 0.037653952836990356,\n",
              " 0.03756820783019066,\n",
              " 0.03750777617096901,\n",
              " 0.03786575794219971,\n",
              " 0.037673935294151306,\n",
              " 0.03766100853681564,\n",
              " 0.037634193897247314,\n",
              " 0.037517134100198746,\n",
              " 0.037729501724243164,\n",
              " 0.037577297538518906,\n",
              " 0.03749329596757889,\n",
              " 0.03780435025691986,\n",
              " 0.03749673813581467,\n",
              " 0.0379444882273674,\n",
              " 0.03793645277619362,\n",
              " 0.03712541237473488,\n",
              " 0.03724682331085205,\n",
              " 0.03819785267114639,\n",
              " 0.037730902433395386,\n",
              " 0.03754657134413719,\n",
              " 0.03791683539748192,\n",
              " 0.037158966064453125,\n",
              " 0.03770497813820839,\n",
              " 0.03757505491375923,\n",
              " 0.03792527690529823,\n",
              " 0.037254516035318375,\n",
              " 0.037473320960998535,\n",
              " 0.03781332075595856,\n",
              " 0.03735698014497757,\n",
              " 0.03808387368917465,\n",
              " 0.037753209471702576,\n",
              " 0.03744006156921387,\n",
              " 0.0377742275595665,\n",
              " 0.03743637353181839,\n",
              " 0.038061756640672684,\n",
              " 0.036971498280763626,\n",
              " 0.03761583939194679,\n",
              " 0.03774658590555191,\n",
              " 0.03760687634348869,\n",
              " 0.037728194147348404,\n",
              " 0.03730412945151329,\n",
              " 0.03808068484067917,\n",
              " 0.03754572197794914,\n",
              " 0.037700194865465164,\n",
              " 0.03769812360405922,\n",
              " 0.0374615378677845,\n",
              " 0.03810218721628189,\n",
              " 0.03701365366578102,\n",
              " 0.03776496648788452,\n",
              " 0.03740861266851425,\n",
              " 0.03801523521542549,\n",
              " 0.037044208496809006,\n",
              " 0.03751145303249359,\n",
              " 0.037868741899728775,\n",
              " 0.03760183975100517,\n",
              " 0.03779161721467972,\n",
              " 0.037353403866291046,\n",
              " 0.03815165162086487,\n",
              " 0.03748820722103119,\n",
              " 0.03788483515381813,\n",
              " 0.0374918095767498,\n",
              " 0.03775787726044655,\n",
              " 0.038057830184698105,\n",
              " 0.037011802196502686,\n",
              " 0.037418268620967865,\n",
              " 0.03799081966280937,\n",
              " 0.03769080713391304,\n",
              " 0.03758411109447479,\n",
              " 0.0376519151031971,\n",
              " 0.037636347115039825,\n",
              " 0.037685178220272064,\n",
              " 0.03763173520565033,\n",
              " 0.03801517188549042,\n",
              " 0.037216369062662125,\n",
              " 0.03740597143769264,\n",
              " 0.03787181153893471,\n",
              " 0.037465035915374756,\n",
              " 0.03788842633366585,\n",
              " 0.03787396103143692,\n",
              " 0.037187933921813965,\n",
              " 0.03775571659207344,\n",
              " 0.03749817982316017,\n",
              " 0.03788318112492561,\n",
              " 0.037315499037504196,\n",
              " 0.03773101791739464,\n",
              " 0.03745449334383011,\n",
              " 0.0374738834798336,\n",
              " 0.03788738325238228,\n",
              " 0.03696904331445694,\n",
              " 0.03865745663642883,\n",
              " 0.037688449025154114,\n",
              " 0.03755943849682808,\n",
              " 0.03745080530643463,\n",
              " 0.03789931908249855,\n",
              " 0.03771807625889778,\n",
              " 0.037474341690540314,\n",
              " 0.037847429513931274,\n",
              " 0.03735899180173874,\n",
              " 0.037545643746852875,\n",
              " 0.03779461979866028,\n",
              " 0.0377873033285141,\n",
              " 0.037395115941762924,\n",
              " 0.037257712334394455,\n",
              " 0.03812884911894798,\n",
              " 0.03785323351621628,\n",
              " 0.03742946311831474,\n",
              " 0.03788980096578598,\n",
              " 0.03716028481721878,\n",
              " 0.037109117954969406,\n",
              " 0.03850777819752693,\n",
              " 0.037203725427389145,\n",
              " 0.03826265409588814,\n",
              " 0.03761059418320656,\n",
              " 0.037657734006643295,\n",
              " 0.037976063787937164,\n",
              " 0.037254225462675095,\n",
              " 0.03751136362552643,\n",
              " 0.03777902573347092,\n",
              " 0.037719011306762695,\n",
              " 0.03755754977464676,\n",
              " 0.037797048687934875,\n",
              " 0.03734862059354782,\n",
              " 0.037541139870882034,\n",
              " 0.037776101380586624,\n",
              " 0.03782278671860695,\n",
              " 0.037235405296087265,\n",
              " 0.03755933791399002,\n",
              " 0.037727102637290955,\n",
              " 0.03790000453591347,\n",
              " 0.03722761943936348,\n",
              " 0.03775107488036156,\n",
              " 0.0375402458012104,\n",
              " 0.037590451538562775,\n",
              " 0.03773973882198334,\n",
              " 0.03784635663032532,\n",
              " 0.03732689470052719,\n",
              " 0.03740924596786499,\n",
              " 0.03803178668022156,\n",
              " 0.03772308677434921,\n",
              " 0.03743438795208931,\n",
              " 0.038252972066402435,\n",
              " 0.036785244941711426,\n",
              " 0.03805038705468178,\n",
              " 0.03702416270971298,\n",
              " 0.03757694736123085,\n",
              " 0.037753865122795105,\n",
              " 0.03769681975245476,\n",
              " 0.03754749521613121,\n",
              " 0.03782421350479126,\n",
              " 0.03736009821295738,\n",
              " 0.03758449852466583,\n",
              " 0.03763207048177719,\n",
              " 0.037624605000019073,\n",
              " 0.037680577486753464,\n",
              " 0.03733443096280098,\n",
              " 0.03805161267518997,\n",
              " 0.03758722171187401,\n",
              " 0.0376831516623497,\n",
              " 0.037810977548360825,\n",
              " 0.03742142766714096,\n",
              " 0.037638258188962936,\n",
              " 0.037651143968105316,\n",
              " 0.037859562784433365,\n",
              " 0.03719744086265564,\n",
              " 0.03787888586521149,\n",
              " 0.03722313046455383,\n",
              " 0.037956949323415756,\n",
              " 0.03714142367243767,\n",
              " 0.037360578775405884,\n",
              " 0.03812602534890175,\n",
              " 0.03742978721857071,\n",
              " 0.03793705627322197,\n",
              " 0.0377759113907814,\n",
              " 0.037325065582990646,\n",
              " 0.03745757415890694,\n",
              " 0.03790157288312912,\n",
              " 0.037756871432065964,\n",
              " 0.03758465498685837,\n",
              " 0.03798028454184532,\n",
              " 0.03715852275490761,\n",
              " 0.037762414664030075,\n",
              " 0.037454813718795776,\n",
              " 0.03776432201266289,\n",
              " 0.03735501319169998,\n",
              " 0.037428393959999084,\n",
              " 0.03787660971283913,\n",
              " 0.03718569874763489,\n",
              " 0.038441598415374756,\n",
              " 0.03793925791978836,\n",
              " 0.037123970687389374,\n",
              " 0.03753823786973953,\n",
              " 0.0376744419336319,\n",
              " 0.03781770169734955,\n",
              " 0.03732487931847572,\n",
              " 0.03771868720650673,\n",
              " 0.0375383086502552,\n",
              " 0.03826781362295151,\n",
              " 0.036687757819890976,\n",
              " 0.03734873607754707,\n",
              " 0.03795670345425606,\n",
              " 0.03747139498591423,\n",
              " 0.03788437694311142,\n",
              " 0.03803957253694534,\n",
              " 0.03695794194936752,\n",
              " 0.03803836181759834,\n",
              " 0.03704468905925751,\n",
              " 0.037488337606191635,\n",
              " 0.03785095736384392,\n",
              " 0.03807177022099495,\n",
              " 0.03707965090870857,\n",
              " 0.037809308618307114,\n",
              " 0.03732916712760925,\n",
              " 0.037454236298799515,\n",
              " 0.03794172406196594,\n",
              " 0.03751898184418678,\n",
              " 0.037751395255327225,\n",
              " 0.03721673786640167,\n",
              " 0.03824726119637489,\n",
              " 0.03763306140899658,\n",
              " 0.0376870259642601,\n",
              " 0.03772642835974693,\n",
              " 0.03756598010659218,\n",
              " 0.03781167045235634,\n",
              " 0.03733948618173599,\n",
              " 0.03783789649605751,\n",
              " 0.037497226148843765,\n",
              " 0.03790139779448509,\n",
              " 0.0371687225997448,\n",
              " 0.03717314079403877,\n",
              " 0.038352418690919876,\n",
              " 0.037477705627679825,\n",
              " 0.037816017866134644,\n",
              " 0.037397004663944244,\n",
              " 0.037958551198244095,\n",
              " 0.037757664918899536,\n",
              " 0.03735680878162384,\n",
              " 0.037683919072151184,\n",
              " 0.037462420761585236,\n",
              " 0.03745906427502632,\n",
              " 0.03790479525923729,\n",
              " 0.03806772455573082,\n",
              " 0.03711540624499321,\n",
              " 0.037845224142074585,\n",
              " 0.0372602753341198,\n",
              " 0.03778010979294777,\n",
              " 0.03734264150261879,\n",
              " 0.037451088428497314,\n",
              " 0.03796420991420746,\n",
              " 0.03762710094451904,\n",
              " 0.037717923521995544,\n",
              " 0.03791368007659912,\n",
              " 0.037227727472782135,\n",
              " 0.03769952058792114,\n",
              " 0.037566520273685455,\n",
              " 0.03760021552443504,\n",
              " 0.03773070499300957,\n",
              " 0.03695487603545189,\n",
              " 0.03862696886062622,\n",
              " 0.03816882148385048,\n",
              " 0.03676611930131912,\n",
              " 0.037751730531454086,\n",
              " 0.037458471953868866,\n",
              " 0.037245526909828186,\n",
              " 0.03810805082321167,\n",
              " 0.03737218305468559,\n",
              " 0.03795359656214714,\n",
              " 0.037542082369327545,\n",
              " 0.03776797279715538,\n",
              " 0.037270840257406235,\n",
              " 0.038137082010507584,\n",
              " 0.037272240966558456,\n",
              " 0.038209158927202225,\n",
              " 0.03711854666471481,\n",
              " 0.03841467946767807,\n",
              " 0.037449609488248825,\n",
              " 0.037920817732810974,\n",
              " 0.03753930702805519,\n",
              " 0.03772779181599617,\n",
              " 0.037440769374370575,\n",
              " 0.037877097725868225,\n",
              " 0.03761639446020126,\n",
              " 0.03763223811984062,\n",
              " 0.037310779094696045,\n",
              " 0.037977512925863266,\n",
              " 0.03780221939086914,\n",
              " 0.03728143498301506,\n",
              " 0.03751711919903755,\n",
              " 0.03784932568669319,\n",
              " 0.037939876317977905,\n",
              " 0.03719901666045189,\n",
              " 0.03785531222820282,\n",
              " 0.037213362753391266,\n",
              " 0.0375509113073349,\n",
              " 0.037779491394758224,\n",
              " 0.03784932196140289,\n",
              " 0.03726871684193611,\n",
              " 0.03740227594971657,\n",
              " 0.03794121369719505,\n",
              " 0.037696849554777145,\n",
              " 0.0375078022480011,\n",
              " 0.03705506771802902,\n",
              " 0.0384649857878685,\n",
              " 0.03754468634724617,\n",
              " 0.037688832730054855,\n",
              " 0.03794889897108078,\n",
              " 0.03707245737314224,\n",
              " 0.03744564577937126,\n",
              " 0.03787316754460335,\n",
              " 0.037898845970630646,\n",
              " 0.03730959817767143,\n",
              " 0.03801116719841957,\n",
              " 0.03717270493507385,\n",
              " 0.03743312507867813,\n",
              " 0.03788834065198898,\n",
              " 0.037558816373348236,\n",
              " 0.037759482860565186,\n",
              " 0.03744928166270256,\n",
              " 0.037843506783246994,\n",
              " 0.03709395229816437,\n",
              " 0.038458507508039474,\n",
              " 0.03758906200528145,\n",
              " 0.037568312138319016,\n",
              " 0.03779253363609314,\n",
              " 0.03738008067011833,\n",
              " 0.03784219175577164,\n",
              " 0.03741665557026863,\n",
              " 0.037583231925964355,\n",
              " 0.03767526149749756,\n",
              " 0.03758889064192772,\n",
              " 0.037712518125772476,\n",
              " 0.03725240379571915,\n",
              " 0.03813367709517479,\n",
              " 0.03777444735169411,\n",
              " 0.037386372685432434,\n",
              " 0.037908460944890976,\n",
              " 0.03710818663239479,\n",
              " 0.038055505603551865,\n",
              " 0.036986541002988815,\n",
              " 0.03775176778435707,\n",
              " 0.0374605692923069,\n",
              " 0.03712946176528931,\n",
              " 0.03836098313331604,\n",
              " 0.037452857941389084,\n",
              " 0.03790541738271713,\n",
              " 0.037963803857564926,\n",
              " 0.03715577721595764,\n",
              " 0.03731662780046463,\n",
              " 0.038048937916755676,\n",
              " 0.03798074647784233,\n",
              " 0.037069592624902725,\n",
              " 0.03814839571714401,\n",
              " 0.03684879094362259,\n",
              " 0.037748560309410095,\n",
              " 0.0374973826110363,\n",
              " 0.0374273844063282,\n",
              " 0.03792807459831238,\n",
              " 0.0377938449382782,\n",
              " 0.03736314922571182,\n",
              " 0.037922248244285583,\n",
              " 0.03727676719427109,\n",
              " 0.037340644747018814,\n",
              " 0.038094617426395416,\n",
              " 0.03754090145230293,\n",
              " 0.037689607590436935,\n",
              " 0.03805287554860115,\n",
              " 0.03704031929373741,\n",
              " 0.0373678058385849,\n",
              " 0.03809374198317528,\n",
              " 0.03732402250170708,\n",
              " 0.03813571110367775,\n",
              " 0.037483345717191696,\n",
              " 0.03786667436361313,\n",
              " 0.03754400834441185,\n",
              " 0.037611231207847595,\n",
              " 0.037831712514162064,\n",
              " 0.03725864365696907,\n",
              " 0.037514373660087585,\n",
              " 0.03774517774581909,\n",
              " 0.03722678869962692,\n",
              " 0.03821505233645439,\n",
              " 0.03709283843636513,\n",
              " 0.038435015827417374,\n",
              " 0.037701722234487534,\n",
              " 0.037587009370326996,\n",
              " 0.03724096715450287,\n",
              " 0.038148973137140274,\n",
              " 0.03787907958030701,\n",
              " 0.03720957785844803,\n",
              " 0.037673838436603546,\n",
              " 0.03758164867758751,\n",
              " 0.03758896887302399,\n",
              " 0.037690382450819016,\n",
              " 0.03772721812129021,\n",
              " 0.037580106407403946,\n",
              " 0.0376955009996891,\n",
              " 0.03754330053925514,\n",
              " 0.03737952560186386,\n",
              " 0.038010574877262115,\n",
              " 0.03766190633177757,\n",
              " 0.03763147071003914,\n",
              " 0.037625957280397415,\n",
              " 0.03766251355409622,\n",
              " 0.03730596601963043,\n",
              " 0.038086868822574615,\n",
              " 0.03782830014824867,\n",
              " 0.03728068619966507,\n",
              " 0.037817101925611496,\n",
              " 0.03730299323797226,\n",
              " 0.03766227886080742,\n",
              " 0.037620462477207184,\n",
              " 0.037877801805734634,\n",
              " 0.03724602237343788,\n",
              " 0.037983160465955734,\n",
              " 0.03715400770306587,\n",
              " 0.03762809559702873,\n",
              " 0.03766750171780586,\n",
              " 0.03721414506435394,\n",
              " 0.038197387009859085,\n",
              " 0.03751834109425545,\n",
              " 0.03779520094394684,\n",
              " 0.0374000184237957,\n",
              " 0.037986401468515396,\n",
              " 0.0374981164932251,\n",
              " 0.037800271064043045,\n",
              " 0.0374348945915699,\n",
              " 0.03794087842106819,\n",
              " 0.037757690995931625,\n",
              " 0.037370435893535614,\n",
              " 0.037710174918174744,\n",
              " 0.037591636180877686,\n",
              " 0.037212446331977844,\n",
              " 0.038316451013088226,\n",
              " 0.03710830211639404,\n",
              " 0.038406092673540115,\n",
              " 0.03754587098956108,\n",
              " 0.03780645877122879,\n",
              " 0.03789478540420532,\n",
              " 0.03726763278245926,\n",
              " 0.037729959934949875,\n",
              " 0.037422072142362595,\n",
              " 0.03766140714287758,\n",
              " 0.037660468369722366,\n",
              " 0.03811214119195938,\n",
              " 0.03690425679087639,\n",
              " 0.03764517232775688,\n",
              " 0.037578921765089035,\n",
              " 0.03780948370695114,\n",
              " 0.03738468885421753,\n",
              " 0.037895720452070236,\n",
              " 0.03722652420401573,\n",
              " 0.03757777810096741,\n",
              " 0.037718888372182846,\n",
              " 0.036998264491558075,\n",
              " 0.03847833350300789,\n",
              " 0.03766384720802307,\n",
              " 0.037612415850162506,\n",
              " 0.037522684782743454,\n",
              " 0.0378083698451519,\n",
              " 0.037515003234148026,\n",
              " 0.03778056055307388,\n",
              " 0.037407997995615005,\n",
              " 0.038015030324459076,\n",
              " 0.037540044635534286,\n",
              " 0.037820957601070404,\n",
              " 0.03768739849328995,\n",
              " 0.03765449672937393,\n",
              " 0.03813721239566803,\n",
              " 0.03684866800904274,\n",
              " 0.03775961324572563,\n",
              " 0.03740280494093895,\n",
              " 0.03784602880477905,\n",
              " 0.03738068416714668,\n",
              " 0.03783021867275238,\n",
              " 0.037349551916122437,\n",
              " 0.038044486194849014,\n",
              " 0.037113260477781296,\n",
              " 0.03803912177681923,\n",
              " 0.03703615069389343,\n",
              " 0.037476785480976105,\n",
              " 0.037884894758462906,\n",
              " 0.03741982579231262,\n",
              " 0.03796956688165665,\n",
              " 0.03748134896159172,\n",
              " 0.03779028356075287,\n",
              " 0.037981029599905014,\n",
              " 0.03713458776473999,\n",
              " 0.037915416061878204,\n",
              " 0.03725718334317207,\n",
              " 0.037353821098804474,\n",
              " 0.03812916949391365,\n",
              " 0.03765458986163139,\n",
              " 0.037605009973049164,\n",
              " 0.03749215230345726,\n",
              " 0.03789692372083664,\n",
              " 0.037509310990571976,\n",
              " 0.037759650498628616,\n",
              " 0.037474896758794785,\n",
              " 0.03784765303134918,\n",
              " 0.037574879825115204,\n",
              " 0.03770527243614197,\n",
              " 0.03759815916419029,\n",
              " 0.03770521655678749,\n",
              " 0.037711773067712784,\n",
              " 0.037578243762254715,\n",
              " 0.03762652724981308,\n",
              " 0.03759552165865898,\n",
              " 0.03766549006104469,\n",
              " 0.03761754184961319,\n",
              " 0.037403132766485214,\n",
              " 0.03798547759652138,\n",
              " 0.03784115985035896,\n",
              " 0.037226490676403046,\n",
              " 0.03784790262579918,\n",
              " 0.03730632737278938,\n",
              " 0.03769707679748535,\n",
              " 0.037603382021188736,\n",
              " 0.037701912224292755,\n",
              " 0.03747517243027687,\n",
              " 0.037751153111457825,\n",
              " 0.037420064210891724,\n",
              " 0.03781191632151604,\n",
              " 0.03740160912275314,\n",
              " 0.03773198276758194,\n",
              " 0.03730550780892372,\n",
              " 0.03757351636886597,\n",
              " 0.0377669632434845,\n",
              " 0.03726513311266899,\n",
              " 0.038272466510534286,\n",
              " 0.03793516382575035,\n",
              " 0.03732016310095787,\n",
              " 0.03736773878335953,\n",
              " 0.03804919123649597,\n",
              " 0.038128964602947235,\n",
              " 0.0368371307849884,\n",
              " 0.03780146315693855,\n",
              " 0.037529878318309784,\n",
              " 0.037861697375774384,\n",
              " 0.037223149091005325,\n",
              " 0.038052208721637726,\n",
              " 0.03714181110262871,\n",
              " 0.03752010315656662,\n",
              " 0.03772801533341408,\n",
              " 0.03768541291356087,\n",
              " 0.03750383108854294,\n",
              " 0.03791764751076698,\n",
              " 0.03723223879933357,\n",
              " 0.03799033537507057,\n",
              " 0.03707129880785942,\n",
              " 0.03790968656539917,\n",
              " 0.03733225166797638,\n",
              " 0.03760269284248352,\n",
              " 0.03774480149149895,\n",
              " 0.037670377641916275,\n",
              " 0.037546854466199875,\n",
              " 0.03765007480978966,\n",
              " 0.037570200860500336,\n",
              " 0.03750862926244736,\n",
              " 0.03781742975115776,\n",
              " 0.03764454647898674,\n",
              " 0.03765609860420227,\n",
              " 0.037621766328811646,\n",
              " 0.0377255342900753,\n",
              " 0.03751856088638306,\n",
              " 0.03775697946548462,\n",
              " 0.0378105603158474,\n",
              " 0.037413064390420914,\n",
              " 0.03765273466706276,\n",
              " 0.03771787881851196,\n",
              " 0.038131795823574066,\n",
              " 0.03690456598997116,\n",
              " 0.0380614697933197,\n",
              " 0.037101320922374725,\n",
              " 0.037703581154346466,\n",
              " 0.037527862936258316,\n",
              " 0.037745337933301926,\n",
              " 0.037471186369657516,\n",
              " 0.03780703991651535,\n",
              " 0.03736655041575432,\n",
              " 0.03791021183133125,\n",
              " 0.03717151656746864,\n",
              " 0.03787475451827049,\n",
              " 0.03724949061870575,\n",
              " 0.037797801196575165,\n",
              " 0.03731519356369972,\n",
              " 0.037628356367349625,\n",
              " 0.03761562332510948,\n",
              " 0.037689849734306335,\n",
              " 0.037592533975839615,\n",
              " 0.03767462074756622,\n",
              " 0.037577491253614426,\n",
              " 0.03747357800602913,\n",
              " 0.03793850168585777,\n",
              " 0.03777036815881729,\n",
              " 0.03743208572268486,\n",
              " 0.03772687539458275,\n",
              " 0.03743397071957588,\n",
              " 0.03739629313349724,\n",
              " 0.03787316754460335,\n",
              " 0.037944111973047256,\n",
              " 0.037152960896492004,\n",
              " 0.037909768521785736,\n",
              " 0.03723993897438049,\n",
              " 0.03774071857333183,\n",
              " 0.037434954196214676,\n",
              " 0.03755269944667816,\n",
              " 0.037806879729032516,\n",
              " 0.03788537532091141,\n",
              " 0.037251487374305725,\n",
              " 0.03753053396940231,\n",
              " 0.037717945873737335,\n",
              " 0.037630967795848846,\n",
              " 0.0376020148396492,\n",
              " 0.037315238267183304,\n",
              " 0.038011450320482254,\n",
              " 0.03786161541938782,\n",
              " 0.0372931994497776,\n",
              " 0.03741760179400444,\n",
              " 0.03787918761372566,\n",
              " 0.03738988935947418,\n",
              " 0.03794483840465546,\n",
              " 0.03729219734668732,\n",
              " 0.03808792680501938,\n",
              " 0.03747854009270668,\n",
              " 0.037811294198036194,\n",
              " 0.037305980920791626,\n",
              " 0.038060735911130905,\n",
              " 0.0373457632958889,\n",
              " 0.03797163814306259,\n",
              " 0.03697850927710533,\n",
              " 0.03845110535621643,\n",
              " 0.03743531182408333,\n",
              " 0.03804284706711769,\n",
              " 0.03783722594380379,\n",
              " 0.03736007213592529,\n",
              " 0.0371951200067997,\n",
              " 0.038210466504096985,\n",
              " 0.03738521412014961,\n",
              " 0.03788354992866516,\n",
              " 0.03759103640913963,\n",
              " 0.037774037569761276,\n",
              " 0.037408750504255295,\n",
              " 0.03801474720239639,\n",
              " 0.03778219223022461,\n",
              " 0.037476930767297745,\n",
              " 0.037340033799409866,\n",
              " 0.0380224883556366,\n",
              " 0.03731851279735565,\n",
              " 0.038028817623853683,\n",
              " 0.037586286664009094,\n",
              " 0.037650056183338165,\n",
              " 0.03728253021836281,\n",
              " 0.03814937174320221,\n",
              " 0.03794505447149277,\n",
              " 0.037173978984355927,\n",
              " 0.03783472627401352,\n",
              " 0.03738349303603172,\n",
              " 0.038061100989580154,\n",
              " 0.037003349512815475,\n",
              " 0.037156447768211365,\n",
              " 0.038409534841775894,\n",
              " 0.0378095880150795,\n",
              " 0.0374535396695137,\n",
              " 0.037871986627578735,\n",
              " 0.03722439706325531,\n",
              " 0.03756186366081238,\n",
              " 0.03774131089448929,\n",
              " 0.03812677040696144,\n",
              " 0.036866601556539536,\n",
              " 0.03750462830066681,\n",
              " 0.0378461591899395,\n",
              " 0.03756510093808174,\n",
              " 0.03767108917236328,\n",
              " 0.03745702654123306,\n",
              " 0.037911541759967804,\n",
              " 0.03765679895877838,\n",
              " 0.037542469799518585,\n",
              " 0.037574488669633865,\n",
              " 0.03789626806974411,\n",
              " 0.03766950964927673,\n",
              " 0.03760390728712082,\n",
              " 0.037876859307289124,\n",
              " 0.03727057948708534,\n",
              " 0.03729305788874626,\n",
              " 0.038133908063173294,\n",
              " 0.0376061275601387,\n",
              " 0.03769614174962044,\n",
              " 0.037799250334501266,\n",
              " 0.03751256689429283,\n",
              " 0.037823766469955444,\n",
              " 0.037351660430431366,\n",
              " 0.037500444799661636,\n",
              " 0.03784826770424843,\n",
              " 0.037187978625297546,\n",
              " 0.03838752210140228,\n",
              " 0.03769898787140846,\n",
              " 0.03744786977767944,\n",
              " 0.03761877119541168,\n",
              " 0.03766242787241936,\n",
              " 0.03765276074409485,\n",
              " 0.037535205483436584,\n",
              " 0.03740246221423149,\n",
              " 0.03789272904396057,\n",
              " 0.037935271859169006,\n",
              " 0.03724105656147003,\n",
              " 0.037870366126298904,\n",
              " 0.03722260892391205,\n",
              " 0.03710548207163811,\n",
              " 0.03843086212873459,\n",
              " 0.03751621022820473,\n",
              " 0.0377199724316597,\n",
              " 0.03778911381959915,\n",
              " 0.037418097257614136,\n",
              " 0.03804324194788933,\n",
              " 0.037042830139398575,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 5"
      ],
      "metadata": {
        "id": "1rFGA6jp68mP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gVVKr6m2xRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCmvF6iP22JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model1.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model1(real_features)\n",
        "        loss = criterion(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model1.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model1(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Plot losses\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RNjbZgQK28lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RA5IWHFd2orR",
        "outputId": "bdd44f1d-d6c3-4e3c-8cf7-54fb83c7ac34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVTvuJJ3onsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(generated_features)"
      ],
      "metadata": {
        "id": "_v2NSflfy4ww",
        "outputId": "b7a67862-7b38-49d1-95b5-e6535e7f508b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_features"
      ],
      "metadata": {
        "id": "UqsEt9K34vkW",
        "outputId": "2fabe951-cd0f-46c9-b12d-ba22acb5cf05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[-0.1050486 ,  0.0592591 , -0.04588313, ...,  0.0681432 ,\n",
              "           0.05616908, -0.07822345],\n",
              "         [-0.09180458,  0.10368504, -0.02269186, ...,  0.080788  ,\n",
              "           0.09603249, -0.21644062],\n",
              "         [-0.10137026,  0.10495242, -0.0299967 , ...,  0.05484535,\n",
              "           0.10793833, -0.20948854],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10067847,  0.06771937, -0.04842731, ...,  0.06707394,\n",
              "           0.06730863, -0.09654537],\n",
              "         [-0.09655349,  0.09838504, -0.02307442, ...,  0.08135854,\n",
              "           0.08672763, -0.19937101],\n",
              "         [-0.10654895,  0.09703689, -0.01857823, ...,  0.06867893,\n",
              "           0.08792984, -0.19429311],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10461126,  0.06491963, -0.04714095, ...,  0.06867933,\n",
              "           0.05878128, -0.08669724],\n",
              "         [-0.09168521,  0.10055253, -0.02711318, ...,  0.07499073,\n",
              "           0.08861582, -0.20904362],\n",
              "         [-0.09862316,  0.10182767, -0.02230792, ...,  0.05916616,\n",
              "           0.09867103, -0.19508171],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10567412,  0.05970036, -0.0457128 , ...,  0.06949127,\n",
              "           0.05475235, -0.07977843],\n",
              "         [-0.09103884,  0.10447767, -0.02107649, ...,  0.0839594 ,\n",
              "           0.09703785, -0.2204105 ],\n",
              "         [-0.10220198,  0.10541014, -0.02933083, ...,  0.05980863,\n",
              "           0.11038655, -0.21552387],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10587838,  0.06364392, -0.04662772, ...,  0.06931551,\n",
              "           0.05758016, -0.08501776],\n",
              "         [-0.09029065,  0.10178299, -0.02609139, ...,  0.07634075,\n",
              "           0.09259861, -0.21383733],\n",
              "         [-0.09743474,  0.10364555, -0.02699101, ...,  0.05627059,\n",
              "           0.103205  , -0.20043904],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10188438,  0.06664818, -0.04957206, ...,  0.06674416,\n",
              "           0.06584059, -0.09433237],\n",
              "         [-0.09617442,  0.09826225, -0.02421855, ...,  0.08071016,\n",
              "           0.08580558, -0.20495132],\n",
              "         [-0.10612684,  0.09734742, -0.01805115, ...,  0.06859252,\n",
              "           0.08892216, -0.19750145],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10556963,  0.05969381, -0.04585102, ...,  0.06787232,\n",
              "           0.05477924, -0.07744896],\n",
              "         [-0.08869904,  0.1045911 , -0.02704651, ...,  0.07364191,\n",
              "           0.09365421, -0.21564516],\n",
              "         [-0.09705819,  0.10819812, -0.03152626, ...,  0.04942324,\n",
              "           0.1049196 , -0.20521861],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10582155,  0.05991479, -0.0458133 , ...,  0.06958824,\n",
              "           0.05552268, -0.08061987],\n",
              "         [-0.09252742,  0.10327734, -0.02175931, ...,  0.08419533,\n",
              "           0.09732684, -0.21971416],\n",
              "         [-0.10221012,  0.10384014, -0.02982329, ...,  0.06046731,\n",
              "           0.10918272, -0.21513468],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10498567,  0.06084574, -0.04646   , ...,  0.06743783,\n",
              "           0.05708665, -0.07927202],\n",
              "         [-0.09149438,  0.10337675, -0.02478732, ...,  0.07807736,\n",
              "           0.09423691, -0.2126596 ],\n",
              "         [-0.09883602,  0.10553637, -0.02922338, ...,  0.05268945,\n",
              "           0.10484164, -0.2027598 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10525143,  0.06419624, -0.04678965, ...,  0.06967433,\n",
              "           0.05895508, -0.08661169],\n",
              "         [-0.09203865,  0.09973094, -0.02616289, ...,  0.07775043,\n",
              "           0.09246886, -0.20965868],\n",
              "         [-0.09862547,  0.10100862, -0.02491973, ...,  0.05857493,\n",
              "           0.10214853, -0.19876865],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10578583,  0.05946093, -0.04552498, ...,  0.07047829,\n",
              "           0.05377477, -0.08051266],\n",
              "         [-0.09148811,  0.10638367, -0.01878802, ...,  0.08661988,\n",
              "           0.09852628, -0.22083333],\n",
              "         [-0.10219447,  0.10180168, -0.02874239, ...,  0.07195383,\n",
              "           0.10838732, -0.21930853],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10583545,  0.06362793, -0.04656396, ...,  0.06933975,\n",
              "           0.05758755, -0.08498275],\n",
              "         [-0.09086217,  0.10108474, -0.02632103, ...,  0.07696924,\n",
              "           0.09276228, -0.21251005],\n",
              "         [-0.09768687,  0.10289387, -0.02770893, ...,  0.05669699,\n",
              "           0.10248467, -0.2011539 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10539092,  0.06411511, -0.04699079, ...,  0.06876518,\n",
              "           0.05829835, -0.08558521],\n",
              "         [-0.09094317,  0.1000571 , -0.02704116, ...,  0.07571211,\n",
              "           0.09165069, -0.20984814],\n",
              "         [-0.09769921,  0.10245599, -0.02513464, ...,  0.05692976,\n",
              "           0.10189627, -0.1975829 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10517174,  0.06115534, -0.04620913, ...,  0.06804135,\n",
              "           0.05699155, -0.0799896 ],\n",
              "         [-0.09195904,  0.10299502, -0.02486687, ...,  0.0783838 ,\n",
              "           0.09471983, -0.21206379],\n",
              "         [-0.09890297,  0.10512158, -0.02940559, ...,  0.05275025,\n",
              "           0.10466412, -0.20251232],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.1050486 ,  0.0592591 , -0.04588313, ...,  0.0681432 ,\n",
              "           0.05616908, -0.07822345],\n",
              "         [-0.09180458,  0.10368504, -0.02269186, ...,  0.080788  ,\n",
              "           0.09603249, -0.21644062],\n",
              "         [-0.10137026,  0.10495242, -0.0299967 , ...,  0.05484535,\n",
              "           0.10793833, -0.20948854],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10067847,  0.06771937, -0.04842731, ...,  0.06707394,\n",
              "           0.06730863, -0.09654537],\n",
              "         [-0.09655349,  0.09838504, -0.02307442, ...,  0.08135854,\n",
              "           0.08672763, -0.19937101],\n",
              "         [-0.10654895,  0.09703689, -0.01857823, ...,  0.06867893,\n",
              "           0.08792984, -0.19429311],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10461126,  0.06491963, -0.04714095, ...,  0.06867933,\n",
              "           0.05878128, -0.08669724],\n",
              "         [-0.09168521,  0.10055253, -0.02711318, ...,  0.07499073,\n",
              "           0.08861582, -0.20904362],\n",
              "         [-0.09862316,  0.10182767, -0.02230792, ...,  0.05916616,\n",
              "           0.09867103, -0.19508171],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10567412,  0.05970036, -0.0457128 , ...,  0.06949127,\n",
              "           0.05475235, -0.07977843],\n",
              "         [-0.09103884,  0.10447767, -0.02107649, ...,  0.0839594 ,\n",
              "           0.09703785, -0.2204105 ],\n",
              "         [-0.10220198,  0.10541014, -0.02933083, ...,  0.05980863,\n",
              "           0.11038655, -0.21552387],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10587838,  0.06364392, -0.04662772, ...,  0.06931551,\n",
              "           0.05758016, -0.08501776],\n",
              "         [-0.09029065,  0.10178299, -0.02609139, ...,  0.07634075,\n",
              "           0.09259861, -0.21383733],\n",
              "         [-0.09743474,  0.10364555, -0.02699101, ...,  0.05627059,\n",
              "           0.103205  , -0.20043904],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10188438,  0.06664818, -0.04957206, ...,  0.06674416,\n",
              "           0.06584059, -0.09433237],\n",
              "         [-0.09617442,  0.09826225, -0.02421855, ...,  0.08071016,\n",
              "           0.08580558, -0.20495132],\n",
              "         [-0.10612684,  0.09734742, -0.01805115, ...,  0.06859252,\n",
              "           0.08892216, -0.19750145],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10556963,  0.05969381, -0.04585102, ...,  0.06787232,\n",
              "           0.05477924, -0.07744896],\n",
              "         [-0.08869904,  0.1045911 , -0.02704651, ...,  0.07364191,\n",
              "           0.09365421, -0.21564516],\n",
              "         [-0.09705819,  0.10819812, -0.03152626, ...,  0.04942324,\n",
              "           0.1049196 , -0.20521861],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10582155,  0.05991479, -0.0458133 , ...,  0.06958824,\n",
              "           0.05552268, -0.08061987],\n",
              "         [-0.09252742,  0.10327734, -0.02175931, ...,  0.08419533,\n",
              "           0.09732684, -0.21971416],\n",
              "         [-0.10221012,  0.10384014, -0.02982329, ...,  0.06046731,\n",
              "           0.10918272, -0.21513468],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10498567,  0.06084574, -0.04646   , ...,  0.06743783,\n",
              "           0.05708665, -0.07927202],\n",
              "         [-0.09149438,  0.10337675, -0.02478732, ...,  0.07807736,\n",
              "           0.09423691, -0.2126596 ],\n",
              "         [-0.09883602,  0.10553637, -0.02922338, ...,  0.05268945,\n",
              "           0.10484164, -0.2027598 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10525143,  0.06419624, -0.04678965, ...,  0.06967433,\n",
              "           0.05895508, -0.08661169],\n",
              "         [-0.09203865,  0.09973094, -0.02616289, ...,  0.07775043,\n",
              "           0.09246886, -0.20965868],\n",
              "         [-0.09862547,  0.10100862, -0.02491973, ...,  0.05857493,\n",
              "           0.10214853, -0.19876865],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10578583,  0.05946093, -0.04552498, ...,  0.07047829,\n",
              "           0.05377477, -0.08051266],\n",
              "         [-0.09148811,  0.10638367, -0.01878802, ...,  0.08661988,\n",
              "           0.09852628, -0.22083333],\n",
              "         [-0.10219447,  0.10180168, -0.02874239, ...,  0.07195383,\n",
              "           0.10838732, -0.21930853],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10583545,  0.06362793, -0.04656396, ...,  0.06933975,\n",
              "           0.05758755, -0.08498275],\n",
              "         [-0.09086217,  0.10108474, -0.02632103, ...,  0.07696924,\n",
              "           0.09276228, -0.21251005],\n",
              "         [-0.09768687,  0.10289387, -0.02770893, ...,  0.05669699,\n",
              "           0.10248467, -0.2011539 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10539092,  0.06411511, -0.04699079, ...,  0.06876518,\n",
              "           0.05829835, -0.08558521],\n",
              "         [-0.09094317,  0.1000571 , -0.02704116, ...,  0.07571211,\n",
              "           0.09165069, -0.20984814],\n",
              "         [-0.09769921,  0.10245599, -0.02513464, ...,  0.05692976,\n",
              "           0.10189627, -0.1975829 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10517174,  0.06115534, -0.04620913, ...,  0.06804135,\n",
              "           0.05699155, -0.0799896 ],\n",
              "         [-0.09195904,  0.10299502, -0.02486687, ...,  0.0783838 ,\n",
              "           0.09471983, -0.21206379],\n",
              "         [-0.09890297,  0.10512158, -0.02940559, ...,  0.05275025,\n",
              "           0.10466412, -0.20251232],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[ 0.14715578, -0.16542408,  0.18437177, ..., -0.06599808,\n",
              "          -0.194534  , -0.10618176],\n",
              "         [ 0.10362137, -0.14128314,  0.09954125, ..., -0.05560563,\n",
              "          -0.1580073 , -0.10774528],\n",
              "         [ 0.16606233, -0.15659708,  0.18928455, ..., -0.05213925,\n",
              "          -0.24475367, -0.05628156],\n",
              "         ...,\n",
              "         [ 0.13541538, -0.26515076,  0.13885772, ..., -0.04544246,\n",
              "          -0.16899347, -0.14278817],\n",
              "         [ 0.1359779 , -0.22044528, -0.00206409, ..., -0.10156794,\n",
              "          -0.19889742, -0.11590512],\n",
              "         [ 0.21420138, -0.21500239,  0.00319653, ..., -0.13956453,\n",
              "          -0.24934407, -0.05588746]],\n",
              " \n",
              "        [[ 0.16477555, -0.06135626,  0.09290937, ..., -0.05219459,\n",
              "          -0.1713922 ,  0.0260768 ],\n",
              "         [ 0.09882579, -0.16578633,  0.18301982, ..., -0.11404131,\n",
              "          -0.2243915 , -0.15205419],\n",
              "         [ 0.18069947, -0.08873253,  0.14884457, ..., -0.13759555,\n",
              "          -0.11434382, -0.08739879],\n",
              "         ...,\n",
              "         [ 0.08101115, -0.17590156,  0.14645568, ..., -0.07591494,\n",
              "          -0.14537112, -0.15541542],\n",
              "         [ 0.02297843, -0.16046882,  0.07823843, ...,  0.01271709,\n",
              "          -0.15709174, -0.09212461],\n",
              "         [ 0.15350382, -0.11757664,  0.11475099, ..., -0.08773544,\n",
              "          -0.15228795, -0.15729983]],\n",
              " \n",
              "        [[ 0.19625607, -0.10513404,  0.1720267 , ..., -0.14063212,\n",
              "          -0.10676042, -0.11211985],\n",
              "         [ 0.08202307, -0.15279388,  0.17499691, ..., -0.07344791,\n",
              "          -0.14854023, -0.17358261],\n",
              "         [ 0.13362864, -0.11295694,  0.04033468, ...,  0.0136869 ,\n",
              "          -0.15564333, -0.11587361],\n",
              "         ...,\n",
              "         [ 0.18760253, -0.14409575,  0.15215302, ...,  0.04425725,\n",
              "          -0.10952446, -0.07489967],\n",
              "         [ 0.22584888, -0.02724155,  0.09378228, ..., -0.12253709,\n",
              "          -0.12001681, -0.10705646],\n",
              "         [ 0.14477237, -0.1313594 ,  0.09489768, ..., -0.14119436,\n",
              "          -0.18217444, -0.05178448]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.09340491, -0.09403218,  0.21313003, ..., -0.12483843,\n",
              "          -0.04272227, -0.19625601],\n",
              "         [ 0.12872902, -0.13311672,  0.07659397, ..., -0.07318188,\n",
              "          -0.11709195, -0.15438503],\n",
              "         [ 0.09382847, -0.16081762,  0.05277772, ...,  0.01932165,\n",
              "          -0.11158763, -0.02525219],\n",
              "         ...,\n",
              "         [ 0.18025437, -0.16214299,  0.13609508, ...,  0.01245904,\n",
              "          -0.14663109,  0.01791615],\n",
              "         [ 0.14156541,  0.03468968,  0.12890586, ..., -0.05683227,\n",
              "          -0.06136257, -0.12050888],\n",
              "         [ 0.14283742, -0.21240726,  0.11469093, ..., -0.00893003,\n",
              "          -0.13280156, -0.09480312]],\n",
              " \n",
              "        [[ 0.16953275, -0.11783055,  0.14098072, ..., -0.0295395 ,\n",
              "          -0.13129282, -0.0034175 ],\n",
              "         [ 0.17784333, -0.13633081,  0.12348992, ..., -0.0726242 ,\n",
              "          -0.16142902,  0.14812173],\n",
              "         [ 0.14779486, -0.1364724 ,  0.19508633, ..., -0.20535518,\n",
              "          -0.1571775 ,  0.02822113],\n",
              "         ...,\n",
              "         [ 0.16721046, -0.1335326 ,  0.19241719, ..., -0.10516556,\n",
              "          -0.06357863, -0.07939464],\n",
              "         [ 0.11449449, -0.13916475,  0.26342067, ..., -0.13299777,\n",
              "          -0.10400392, -0.01540275],\n",
              "         [ 0.06741031, -0.10182379,  0.13750848, ..., -0.05598905,\n",
              "          -0.0533461 , -0.04988701]],\n",
              " \n",
              "        [[ 0.09741934, -0.09081461,  0.15483874, ...,  0.07099883,\n",
              "          -0.13650566, -0.09407285],\n",
              "         [ 0.09512539, -0.07514334,  0.13394026, ..., -0.02968398,\n",
              "          -0.11161713, -0.16142334],\n",
              "         [ 0.1698519 , -0.14753851,  0.12901248, ..., -0.07503626,\n",
              "          -0.26054138, -0.04621893],\n",
              "         ...,\n",
              "         [ 0.20279577, -0.1324355 ,  0.19178489, ..., -0.19024551,\n",
              "          -0.25114793, -0.00553855],\n",
              "         [ 0.07407718,  0.03096376,  0.11774819, ..., -0.17163305,\n",
              "           0.0090298 , -0.09045789],\n",
              "         [ 0.04222431, -0.16743204,  0.13460493, ..., -0.09836864,\n",
              "          -0.1803602 , -0.09732246]]], dtype=float32),\n",
              " array([[[ 0.09859009, -0.12221009,  0.10438082, ...,  0.05168626,\n",
              "          -0.11093855,  0.0316366 ],\n",
              "         [ 0.09690251, -0.15892488,  0.17384452, ..., -0.07588841,\n",
              "          -0.08055864, -0.04981975],\n",
              "         [ 0.05540636, -0.16284174,  0.17199364, ..., -0.0532384 ,\n",
              "          -0.1435321 , -0.07243399],\n",
              "         ...,\n",
              "         [ 0.16484535, -0.11541061,  0.07327206, ..., -0.07473288,\n",
              "          -0.15268669, -0.1597471 ],\n",
              "         [ 0.04455029, -0.16593178,  0.01671304, ...,  0.0784879 ,\n",
              "          -0.23621544, -0.06983378],\n",
              "         [ 0.12499263, -0.10027614,  0.23247331, ..., -0.0391896 ,\n",
              "          -0.05232021, -0.10222663]],\n",
              " \n",
              "        [[ 0.23625532, -0.26840812,  0.11314578, ..., -0.03401785,\n",
              "          -0.21604602, -0.1191306 ],\n",
              "         [ 0.14213544, -0.1648449 ,  0.11525565, ..., -0.10953651,\n",
              "          -0.07117928, -0.08638676],\n",
              "         [ 0.06117982, -0.1188499 ,  0.09721801, ..., -0.10393904,\n",
              "          -0.24736364, -0.03515124],\n",
              "         ...,\n",
              "         [ 0.08321212, -0.13384283,  0.23481178, ..., -0.07691306,\n",
              "          -0.03393253, -0.05554521],\n",
              "         [ 0.04809693, -0.12210578,  0.22281578, ...,  0.13761748,\n",
              "          -0.09077245, -0.14999679],\n",
              "         [ 0.13876693, -0.22333488,  0.1518335 , ..., -0.09222537,\n",
              "          -0.18308783, -0.17359829]],\n",
              " \n",
              "        [[ 0.21860178, -0.11732185,  0.1639662 , ..., -0.07501517,\n",
              "          -0.19077758, -0.02103924],\n",
              "         [ 0.20359543, -0.17416131,  0.2434921 , ...,  0.03530541,\n",
              "          -0.17072576, -0.12023363],\n",
              "         [ 0.11417441, -0.08362407,  0.023023  , ..., -0.05230832,\n",
              "          -0.16447605, -0.08625148],\n",
              "         ...,\n",
              "         [ 0.11105423, -0.24224234,  0.06367321, ..., -0.07651259,\n",
              "          -0.20676728,  0.07138773],\n",
              "         [ 0.12582484, -0.02890772,  0.17771897, ..., -0.08823619,\n",
              "          -0.05700698, -0.01358998],\n",
              "         [ 0.11530294, -0.1878736 ,  0.04136715, ..., -0.02722251,\n",
              "          -0.18016127, -0.09424595]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.12150389, -0.10948928,  0.1579941 , ..., -0.01886582,\n",
              "          -0.11819112, -0.10213214],\n",
              "         [ 0.14074248, -0.26773828,  0.22466078, ..., -0.05589716,\n",
              "          -0.22287123, -0.16726924],\n",
              "         [ 0.21268275, -0.15023687,  0.14524569, ..., -0.0579217 ,\n",
              "          -0.1155322 , -0.04548989],\n",
              "         ...,\n",
              "         [ 0.0845108 , -0.07205016,  0.10612622, ..., -0.02651654,\n",
              "          -0.18062365, -0.05875786],\n",
              "         [ 0.1488199 , -0.12312657,  0.16547874, ..., -0.06496854,\n",
              "          -0.11662549,  0.01651549],\n",
              "         [ 0.15713155, -0.178224  ,  0.13025862, ..., -0.02825943,\n",
              "          -0.17415348, -0.01818267]],\n",
              " \n",
              "        [[ 0.0579743 , -0.13146478,  0.20982063, ..., -0.02747923,\n",
              "          -0.14882183, -0.08131647],\n",
              "         [ 0.14483455, -0.12426993,  0.17519495, ..., -0.00328925,\n",
              "          -0.05499515,  0.06566026],\n",
              "         [ 0.1653795 , -0.11508633,  0.08758555, ..., -0.20125914,\n",
              "          -0.12312807, -0.1167995 ],\n",
              "         ...,\n",
              "         [ 0.09202421, -0.09167731,  0.15862745, ..., -0.06211166,\n",
              "          -0.05562861, -0.0888616 ],\n",
              "         [ 0.08484212, -0.07429229,  0.01402993, ..., -0.06260588,\n",
              "          -0.06882398,  0.01344069],\n",
              "         [ 0.01009945, -0.1126553 ,  0.06583668, ...,  0.03019221,\n",
              "          -0.08266883, -0.09070651]],\n",
              " \n",
              "        [[ 0.18001196, -0.14028913,  0.10361789, ..., -0.05694345,\n",
              "          -0.12395208, -0.16387458],\n",
              "         [ 0.099671  , -0.16487148,  0.09311263, ..., -0.19454059,\n",
              "          -0.11937958, -0.08517902],\n",
              "         [ 0.20242554, -0.15035892,  0.12220028, ..., -0.05459357,\n",
              "          -0.14679062, -0.13384148],\n",
              "         ...,\n",
              "         [ 0.03903284, -0.15435494,  0.16050708, ...,  0.00494498,\n",
              "          -0.08751711, -0.12477131],\n",
              "         [ 0.07555862, -0.09049684,  0.09123808, ..., -0.03423328,\n",
              "          -0.11625986, -0.06019301],\n",
              "         [ 0.26732945, -0.18132299,  0.22932678, ..., -0.11349286,\n",
              "          -0.12816544, -0.0749723 ]]], dtype=float32),\n",
              " array([[[ 0.17835227, -0.08346188, -0.03256889, ..., -0.03542718,\n",
              "          -0.13308851, -0.1185603 ],\n",
              "         [ 0.13203472, -0.16974166,  0.09284371, ..., -0.02423416,\n",
              "          -0.18465737, -0.09102242],\n",
              "         [ 0.03339614, -0.09404212,  0.177804  , ..., -0.01341219,\n",
              "          -0.11608868, -0.04646755],\n",
              "         ...,\n",
              "         [ 0.1296753 , -0.10580334,  0.08381587, ..., -0.07480372,\n",
              "          -0.14453068, -0.12506771],\n",
              "         [ 0.05660401, -0.13598913,  0.26875946, ..., -0.08263001,\n",
              "          -0.17877366, -0.0584752 ],\n",
              "         [ 0.25951666, -0.16769794,  0.10125215, ..., -0.14056993,\n",
              "          -0.23172234,  0.01593791]],\n",
              " \n",
              "        [[ 0.11258861, -0.02969231,  0.19633389, ..., -0.1661731 ,\n",
              "          -0.05118945,  0.01293334],\n",
              "         [ 0.09374955, -0.16301638,  0.13102797, ..., -0.0297424 ,\n",
              "          -0.11291413, -0.03768634],\n",
              "         [ 0.07236898, -0.13268651,  0.1048707 , ...,  0.02383941,\n",
              "          -0.24088015, -0.05180275],\n",
              "         ...,\n",
              "         [ 0.08997104, -0.11158589,  0.1869407 , ..., -0.02697894,\n",
              "          -0.10911778, -0.09567507],\n",
              "         [ 0.2010136 , -0.02228302,  0.17669356, ..., -0.10965112,\n",
              "          -0.08982457, -0.0670266 ],\n",
              "         [ 0.09230851, -0.24835476,  0.09801034, ...,  0.01556832,\n",
              "          -0.18170244, -0.09904482]]], dtype=float32),\n",
              " array([[[ 0.17182344, -0.10472631,  0.15874888, ..., -0.02016097,\n",
              "          -0.09651285, -0.06014703],\n",
              "         [ 0.14946869, -0.08265976,  0.04533787, ..., -0.13072701,\n",
              "          -0.10499927, -0.01437055],\n",
              "         [ 0.20935027, -0.11396149,  0.14526904, ..., -0.12531559,\n",
              "          -0.14707106, -0.00748096],\n",
              "         ...,\n",
              "         [ 0.03614266, -0.06195904,  0.07545969, ..., -0.06788902,\n",
              "          -0.07240257, -0.07878032],\n",
              "         [ 0.06778947, -0.17793491,  0.041425  , ..., -0.10014933,\n",
              "          -0.19330001, -0.06514876],\n",
              "         [ 0.11152744, -0.10890283,  0.08568069, ...,  0.04344854,\n",
              "          -0.15475321, -0.08883182]],\n",
              " \n",
              "        [[ 0.01213784, -0.09151769,  0.13004567, ..., -0.0574597 ,\n",
              "          -0.15106596, -0.06517816],\n",
              "         [ 0.1445654 , -0.11037904,  0.02668735, ...,  0.01977268,\n",
              "          -0.1495124 , -0.08659804],\n",
              "         [ 0.22781456, -0.15147367,  0.1523857 , ..., -0.05145472,\n",
              "          -0.25945514, -0.01980021],\n",
              "         ...,\n",
              "         [ 0.10677317, -0.13028926,  0.08802798, ..., -0.12198092,\n",
              "          -0.15922382, -0.13677545],\n",
              "         [ 0.17587592, -0.09712883,  0.13740863, ..., -0.19407296,\n",
              "          -0.12130795, -0.0969681 ],\n",
              "         [ 0.1290344 , -0.10371993,  0.07113956, ..., -0.1110704 ,\n",
              "          -0.13978171, -0.05078616]],\n",
              " \n",
              "        [[ 0.0698506 , -0.09013566,  0.09387176, ...,  0.043043  ,\n",
              "          -0.06869738, -0.19708818],\n",
              "         [ 0.17732151, -0.00455306,  0.18940744, ..., -0.08097533,\n",
              "          -0.07768755, -0.00924706],\n",
              "         [ 0.11482947, -0.07289544,  0.15419456, ..., -0.01826634,\n",
              "          -0.19479054, -0.17501934],\n",
              "         ...,\n",
              "         [ 0.19911611, -0.16262697,  0.18187408, ..., -0.03464466,\n",
              "          -0.1311762 , -0.08888538],\n",
              "         [ 0.13807999,  0.02485246,  0.1049337 , ..., -0.06393988,\n",
              "           0.05035236, -0.00030493],\n",
              "         [ 0.06356546, -0.07063062,  0.05671132, ...,  0.00242703,\n",
              "          -0.11095642,  0.0527093 ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.11342735, -0.0946094 ,  0.05695271, ..., -0.0027043 ,\n",
              "          -0.16674924, -0.05827061],\n",
              "         [ 0.08525057, -0.19867972,  0.1251979 , ..., -0.08924025,\n",
              "          -0.20702551, -0.03779582],\n",
              "         [ 0.12602009, -0.05075734,  0.1112495 , ..., -0.04048313,\n",
              "          -0.06139991, -0.05069529],\n",
              "         ...,\n",
              "         [ 0.16118076, -0.21940872,  0.17665395, ..., -0.08984384,\n",
              "          -0.07469676,  0.03886586],\n",
              "         [ 0.06427282, -0.11525099,  0.16793677, ..., -0.07812503,\n",
              "          -0.09745117, -0.08289573],\n",
              "         [ 0.02395882, -0.12653017,  0.10797857, ..., -0.12128692,\n",
              "          -0.13390137, -0.04323853]],\n",
              " \n",
              "        [[ 0.09642562, -0.11588772,  0.14489186, ..., -0.0179599 ,\n",
              "          -0.11108953, -0.02550048],\n",
              "         [ 0.12938392, -0.17905763,  0.10191969, ..., -0.01670669,\n",
              "          -0.17418   ,  0.00761053],\n",
              "         [ 0.16319832, -0.1396579 ,  0.14445007, ..., -0.05689876,\n",
              "          -0.09382012, -0.05942697],\n",
              "         ...,\n",
              "         [ 0.08647691, -0.04735997,  0.13708186, ..., -0.02488779,\n",
              "          -0.12004843, -0.0267514 ],\n",
              "         [ 0.1430286 , -0.09834951,  0.0796072 , ..., -0.05833963,\n",
              "          -0.1416513 , -0.07063184],\n",
              "         [ 0.09546408, -0.04677101,  0.0974915 , ..., -0.04684762,\n",
              "          -0.098603  , -0.03453708]],\n",
              " \n",
              "        [[ 0.15098517, -0.03184438,  0.22227597, ..., -0.08952178,\n",
              "          -0.01322219, -0.08001678],\n",
              "         [ 0.10745783, -0.14638449,  0.19524223, ..., -0.02689057,\n",
              "          -0.16289434,  0.02321913],\n",
              "         [ 0.10469677, -0.14057212,  0.15694618, ..., -0.11441819,\n",
              "          -0.1641827 , -0.08383467],\n",
              "         ...,\n",
              "         [-0.00282828, -0.10012202,  0.20510733, ..., -0.01689058,\n",
              "          -0.10235155,  0.04311837],\n",
              "         [ 0.2459613 , -0.13236359,  0.11051647, ..., -0.08554365,\n",
              "          -0.18860072, -0.10005952],\n",
              "         [ 0.17496127, -0.2607332 ,  0.19843951, ..., -0.15901092,\n",
              "          -0.20932546, -0.18640335]]], dtype=float32),\n",
              " array([[[ 0.23413976, -0.09397621,  0.21521291, ..., -0.01962303,\n",
              "          -0.09570497, -0.15967093],\n",
              "         [ 0.06479259, -0.19592059,  0.06345567, ..., -0.04483773,\n",
              "          -0.17927071, -0.10579144],\n",
              "         [ 0.15743008, -0.01892035,  0.07855554, ..., -0.08313142,\n",
              "          -0.09493808, -0.08945026],\n",
              "         ...,\n",
              "         [ 0.12588899, -0.09800266, -0.00303846, ..., -0.13116573,\n",
              "          -0.20837706, -0.19006719],\n",
              "         [ 0.07214468, -0.04481093,  0.14991246, ..., -0.14542508,\n",
              "          -0.01617915, -0.01035834],\n",
              "         [ 0.17212826, -0.24291253,  0.25922182, ..., -0.04312539,\n",
              "          -0.20084941, -0.09877289]],\n",
              " \n",
              "        [[ 0.14776477, -0.06429984,  0.2645673 , ...,  0.04025875,\n",
              "          -0.04691679, -0.03748563],\n",
              "         [ 0.21426123, -0.12616867,  0.17227486, ..., -0.08091119,\n",
              "          -0.14091419, -0.01834335],\n",
              "         [ 0.15646368, -0.12676133, -0.03090966, ..., -0.2034134 ,\n",
              "          -0.11094412, -0.06357023],\n",
              "         ...,\n",
              "         [ 0.20149659, -0.06215745,  0.13229744, ..., -0.11155528,\n",
              "          -0.01211721, -0.00874422],\n",
              "         [ 0.12833494, -0.1120006 ,  0.08084871, ..., -0.19283196,\n",
              "          -0.15835007, -0.06467672],\n",
              "         [ 0.20402706, -0.12926266,  0.14368434, ..., -0.04711966,\n",
              "          -0.16774571, -0.08283971]],\n",
              " \n",
              "        [[ 0.14978728, -0.13294676,  0.09633046, ...,  0.05549805,\n",
              "          -0.19051296, -0.06623498],\n",
              "         [ 0.1500722 , -0.11870874,  0.20834872, ..., -0.10817613,\n",
              "          -0.06147897,  0.02690414],\n",
              "         [ 0.16572827, -0.15809879,  0.18727654, ..., -0.1252226 ,\n",
              "          -0.15423849, -0.02753153],\n",
              "         ...,\n",
              "         [ 0.22504589, -0.24592876,  0.08160219, ..., -0.09885668,\n",
              "          -0.20837487, -0.0078943 ],\n",
              "         [-0.0309482 , -0.1786705 ,  0.1139391 , ...,  0.00758974,\n",
              "          -0.13212077,  0.03428467],\n",
              "         [ 0.09815492, -0.08677042,  0.07437263, ...,  0.00813185,\n",
              "          -0.17407665, -0.10015067]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.19023128, -0.09691342,  0.15567774, ..., -0.11052855,\n",
              "          -0.12590079, -0.0163616 ],\n",
              "         [ 0.05137437, -0.12249256,  0.12794988, ..., -0.05043689,\n",
              "          -0.10890789, -0.11437398],\n",
              "         [ 0.0906591 , -0.11646323,  0.04947168, ..., -0.01996741,\n",
              "          -0.08444505, -0.06291138],\n",
              "         ...,\n",
              "         [ 0.17842701, -0.19086182,  0.10482999, ..., -0.20855108,\n",
              "          -0.15805888, -0.12607867],\n",
              "         [ 0.06347732, -0.03257599,  0.09946884, ..., -0.00572381,\n",
              "          -0.07597449, -0.00660505],\n",
              "         [ 0.16626748, -0.1427186 ,  0.08187509, ..., -0.07914829,\n",
              "          -0.19089143, -0.12387828]],\n",
              " \n",
              "        [[ 0.14376779, -0.1623626 ,  0.05868319, ..., -0.05850179,\n",
              "          -0.15608993,  0.01501451],\n",
              "         [ 0.12482509, -0.10135555,  0.08180384, ..., -0.03385772,\n",
              "          -0.18709579, -0.05621662],\n",
              "         [ 0.19653365, -0.23903155,  0.18698819, ..., -0.03043757,\n",
              "          -0.0941631 , -0.09284016],\n",
              "         ...,\n",
              "         [ 0.153306  , -0.14609572,  0.12852658, ..., -0.10441029,\n",
              "          -0.15168966, -0.2026215 ],\n",
              "         [ 0.10944012, -0.20366392,  0.17919964, ..., -0.02466101,\n",
              "          -0.12972575, -0.10877305],\n",
              "         [ 0.26014364, -0.02032997,  0.18487643, ..., -0.06472355,\n",
              "          -0.132086  , -0.03730564]],\n",
              " \n",
              "        [[ 0.03902753, -0.13409778,  0.16751513, ..., -0.09863975,\n",
              "          -0.08659345, -0.1226683 ],\n",
              "         [ 0.02500464,  0.03390354,  0.13960543, ..., -0.02090924,\n",
              "          -0.0678618 , -0.13678421],\n",
              "         [ 0.18685244, -0.12976569,  0.13593946, ..., -0.14548415,\n",
              "          -0.12013298, -0.15940899],\n",
              "         ...,\n",
              "         [ 0.06635512, -0.11523379,  0.1509304 , ..., -0.05091722,\n",
              "          -0.01695318, -0.08135004],\n",
              "         [ 0.19969569, -0.1436018 ,  0.09810222, ..., -0.09655841,\n",
              "          -0.11856742, -0.05741444],\n",
              "         [ 0.1175875 , -0.06830283,  0.04793407, ..., -0.01640657,\n",
              "          -0.12554874, -0.10781009]]], dtype=float32),\n",
              " array([[[ 0.20608893, -0.25116912,  0.22925049, ..., -0.10066096,\n",
              "          -0.18375486, -0.08366905],\n",
              "         [ 0.06536619, -0.15623716,  0.16333228, ..., -0.0745257 ,\n",
              "          -0.15543246, -0.05161423],\n",
              "         [ 0.04304234, -0.00421196,  0.04644145, ...,  0.04611573,\n",
              "          -0.02298844, -0.16432598],\n",
              "         ...,\n",
              "         [ 0.11069582, -0.15486774,  0.21111193, ...,  0.0029071 ,\n",
              "          -0.12811255, -0.12044531],\n",
              "         [ 0.16789642, -0.14073642,  0.19700998, ..., -0.09486002,\n",
              "          -0.0838227 , -0.10618814],\n",
              "         [ 0.06156185, -0.09484993,  0.22884989, ..., -0.11341338,\n",
              "          -0.02193877, -0.09014407]],\n",
              " \n",
              "        [[ 0.17756048, -0.1087626 ,  0.14236873, ..., -0.06465074,\n",
              "          -0.05503491,  0.01848963],\n",
              "         [ 0.05905094, -0.16331407,  0.2237868 , ...,  0.0350264 ,\n",
              "          -0.20565417, -0.17643717],\n",
              "         [ 0.06645425, -0.10145439,  0.03438872, ...,  0.02043489,\n",
              "          -0.15575397, -0.07754795],\n",
              "         ...,\n",
              "         [ 0.19726817,  0.01838776,  0.06628577, ..., -0.03358784,\n",
              "          -0.09921418, -0.11673091],\n",
              "         [ 0.17675698, -0.18348426,  0.04967086, ..., -0.15177307,\n",
              "          -0.19784085, -0.23520054],\n",
              "         [ 0.01676503, -0.03706936,  0.116296  , ..., -0.0271126 ,\n",
              "          -0.09817945, -0.03757925]]], dtype=float32),\n",
              " array([[[ 0.07350589,  0.08540292, -0.11814226, ...,  0.07254045,\n",
              "           0.10022938,  0.12509671],\n",
              "         [ 0.06197687,  0.0440864 , -0.12928753, ...,  0.05345668,\n",
              "           0.10260555,  0.08218579],\n",
              "         [ 0.0617439 ,  0.02928242, -0.114475  , ...,  0.03918806,\n",
              "           0.11854063,  0.06712128],\n",
              "         ...,\n",
              "         [ 0.04968875,  0.07407567, -0.10933887, ...,  0.03510791,\n",
              "           0.11972811,  0.04435126],\n",
              "         [ 0.0494776 ,  0.07397258, -0.10940602, ...,  0.03513123,\n",
              "           0.11959815,  0.04437465],\n",
              "         [ 0.04923359,  0.07373656, -0.10966905, ...,  0.03528228,\n",
              "           0.11963189,  0.04407893]],\n",
              " \n",
              "        [[ 0.08110552,  0.08818956, -0.12014478, ...,  0.07110269,\n",
              "           0.10148961,  0.12481384],\n",
              "         [ 0.06622841,  0.04439364, -0.1290985 , ...,  0.05297282,\n",
              "           0.10818507,  0.08813566],\n",
              "         [ 0.06152562,  0.03142786, -0.11106625, ...,  0.04060686,\n",
              "           0.12266526,  0.06806123],\n",
              "         ...,\n",
              "         [ 0.0516622 ,  0.07252083, -0.11078314, ...,  0.03243639,\n",
              "           0.12366618,  0.0512844 ],\n",
              "         [ 0.05148285,  0.07257087, -0.11048897, ...,  0.03257896,\n",
              "           0.12322013,  0.05132347],\n",
              "         [ 0.05137869,  0.0726167 , -0.11019023, ...,  0.03288185,\n",
              "           0.12302458,  0.05142491]],\n",
              " \n",
              "        [[ 0.07295825,  0.0851263 , -0.11750502, ...,  0.07229646,\n",
              "           0.10103384,  0.12507787],\n",
              "         [ 0.06177049,  0.04417582, -0.1292926 , ...,  0.05297437,\n",
              "           0.10244097,  0.08185343],\n",
              "         [ 0.06188989,  0.02947162, -0.11486745, ...,  0.03868882,\n",
              "           0.11859605,  0.06668917],\n",
              "         ...,\n",
              "         [ 0.04946782,  0.07380189, -0.11048818, ...,  0.03539971,\n",
              "           0.1196399 ,  0.04317548],\n",
              "         [ 0.04916313,  0.0736221 , -0.110658  , ...,  0.03569021,\n",
              "           0.11962245,  0.04301934],\n",
              "         [ 0.04895076,  0.07355638, -0.11086187, ...,  0.0360806 ,\n",
              "           0.11970088,  0.04281446]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.07233965,  0.08486711, -0.11737864, ...,  0.07080016,\n",
              "           0.10197553,  0.12578629],\n",
              "         [ 0.06061181,  0.04308593, -0.12918828, ...,  0.05143397,\n",
              "           0.10102016,  0.08004651],\n",
              "         [ 0.06150599,  0.02713346, -0.11698038, ...,  0.03833746,\n",
              "           0.11697918,  0.06505089],\n",
              "         ...,\n",
              "         [ 0.05278318,  0.07565871, -0.10961752, ...,  0.03766758,\n",
              "           0.12235188,  0.04297913],\n",
              "         [ 0.05259652,  0.07562643, -0.10967648, ...,  0.03802252,\n",
              "           0.12251695,  0.04270146],\n",
              "         [ 0.05241788,  0.07555313, -0.10957758, ...,  0.03828842,\n",
              "           0.12247432,  0.0426279 ]],\n",
              " \n",
              "        [[ 0.06990384,  0.08634295, -0.11764519, ...,  0.07082616,\n",
              "           0.1056544 ,  0.12758787],\n",
              "         [ 0.06418891,  0.04725418, -0.13023831, ...,  0.05140411,\n",
              "           0.10283002,  0.07573909],\n",
              "         [ 0.06467666,  0.03327619, -0.12058782, ...,  0.03840179,\n",
              "           0.11833635,  0.05751907],\n",
              "         ...,\n",
              "         [ 0.06221844,  0.09086054, -0.10306732, ...,  0.04717466,\n",
              "           0.1198059 ,  0.0396966 ],\n",
              "         [ 0.06269441,  0.09110143, -0.10304302, ...,  0.04722216,\n",
              "           0.11983277,  0.03997777],\n",
              "         [ 0.06289172,  0.09130751, -0.10281429, ...,  0.04725643,\n",
              "           0.11980474,  0.03989404]],\n",
              " \n",
              "        [[ 0.08483134,  0.09061311, -0.1188971 , ...,  0.06909028,\n",
              "           0.10140397,  0.12531014],\n",
              "         [ 0.07370955,  0.04591142, -0.13369885, ...,  0.04970519,\n",
              "           0.10968024,  0.09530636],\n",
              "         [ 0.0604308 ,  0.03257699, -0.12132096, ...,  0.04244225,\n",
              "           0.11727296,  0.07656477],\n",
              "         ...,\n",
              "         [ 0.06285052,  0.08728807, -0.13838129, ...,  0.06245077,\n",
              "           0.09377725,  0.03822213],\n",
              "         [ 0.07003292,  0.08336292, -0.14801049, ...,  0.06256022,\n",
              "           0.0935294 ,  0.03964213],\n",
              "         [ 0.07235759,  0.07706353, -0.15249136, ...,  0.05959873,\n",
              "           0.0938057 ,  0.04304297]]], dtype=float32),\n",
              " array([[[ 0.0727218 ,  0.08480687, -0.11723716, ...,  0.07212423,\n",
              "           0.10114763,  0.12508804],\n",
              "         [ 0.06173581,  0.04399473, -0.12944925, ...,  0.05269828,\n",
              "           0.10220062,  0.08159378],\n",
              "         [ 0.0616764 ,  0.02895632, -0.11532217, ...,  0.0387369 ,\n",
              "           0.11829841,  0.06645567],\n",
              "         ...,\n",
              "         [ 0.04933172,  0.07358862, -0.11040686, ...,  0.03568832,\n",
              "           0.12000135,  0.04263116],\n",
              "         [ 0.04906313,  0.07328737, -0.11075093, ...,  0.03586263,\n",
              "           0.12000898,  0.04241762],\n",
              "         [ 0.04889193,  0.072974  , -0.11116786, ...,  0.03593157,\n",
              "           0.1200259 ,  0.04226675]],\n",
              " \n",
              "        [[ 0.08189404,  0.08942689, -0.12035061, ...,  0.07158051,\n",
              "           0.10237537,  0.1252409 ],\n",
              "         [ 0.06787037,  0.04474747, -0.1291291 , ...,  0.05305888,\n",
              "           0.10993835,  0.08959989],\n",
              "         [ 0.06055618,  0.03079783, -0.11110297, ...,  0.04178498,\n",
              "           0.12401915,  0.06759123],\n",
              "         ...,\n",
              "         [ 0.05243253,  0.07053378, -0.11069429, ...,  0.03482747,\n",
              "           0.12670857,  0.05174694],\n",
              "         [ 0.0524004 ,  0.07041875, -0.11060771, ...,  0.03506003,\n",
              "           0.12655371,  0.05171335],\n",
              "         [ 0.05204282,  0.07024039, -0.11026684, ...,  0.03532423,\n",
              "           0.12610714,  0.05154842]],\n",
              " \n",
              "        [[ 0.06603621,  0.08476046, -0.11649495, ...,  0.07170529,\n",
              "           0.11091743,  0.13073516],\n",
              "         [ 0.06995063,  0.05432592, -0.13010935, ...,  0.05052177,\n",
              "           0.10810201,  0.076179  ],\n",
              "         [ 0.07030486,  0.04105988, -0.12371233, ...,  0.04241265,\n",
              "           0.12175079,  0.05286368],\n",
              "         ...,\n",
              "         [ 0.07491899,  0.09603543, -0.10235459, ...,  0.05234284,\n",
              "           0.12692755,  0.04209303],\n",
              "         [ 0.07554228,  0.09624199, -0.10205707, ...,  0.05235577,\n",
              "           0.12738957,  0.04185977],\n",
              "         [ 0.07585385,  0.09631054, -0.10164355, ...,  0.05250722,\n",
              "           0.12762687,  0.04160228]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.08181033,  0.08973382, -0.1201372 , ...,  0.07145228,\n",
              "           0.10174948,  0.12506397],\n",
              "         [ 0.0694163 ,  0.0457495 , -0.12980883, ...,  0.05295496,\n",
              "           0.11028538,  0.09005424],\n",
              "         [ 0.06071762,  0.03142795, -0.11202428, ...,  0.04183044,\n",
              "           0.12364637,  0.06674632],\n",
              "         ...,\n",
              "         [ 0.05248371,  0.07143859, -0.10937146, ...,  0.03657286,\n",
              "           0.12668194,  0.05223943],\n",
              "         [ 0.05224296,  0.07131155, -0.10898827, ...,  0.03680187,\n",
              "           0.12577951,  0.05200994],\n",
              "         [ 0.05216816,  0.07125093, -0.10854112, ...,  0.03715418,\n",
              "           0.12519115,  0.05167744]],\n",
              " \n",
              "        [[ 0.07306269,  0.08535964, -0.11764509, ...,  0.0717776 ,\n",
              "           0.10091959,  0.12580535],\n",
              "         [ 0.06150617,  0.04337137, -0.12898318, ...,  0.05268841,\n",
              "           0.10241353,  0.08088554],\n",
              "         [ 0.06143083,  0.02832611, -0.11550541, ...,  0.0390805 ,\n",
              "           0.11800689,  0.06581895],\n",
              "         ...,\n",
              "         [ 0.05201986,  0.0753033 , -0.10934083, ...,  0.0357906 ,\n",
              "           0.12195551,  0.04401145],\n",
              "         [ 0.05190253,  0.07516053, -0.10926931, ...,  0.03565246,\n",
              "           0.12177624,  0.04420912],\n",
              "         [ 0.05178403,  0.07509346, -0.10922699, ...,  0.0356693 ,\n",
              "           0.12172776,  0.04434417]],\n",
              " \n",
              "        [[ 0.08182983,  0.0897546 , -0.11996727, ...,  0.07159978,\n",
              "           0.10132486,  0.125003  ],\n",
              "         [ 0.06994963,  0.04615651, -0.13035363, ...,  0.05303719,\n",
              "           0.11019199,  0.0904945 ],\n",
              "         [ 0.06047156,  0.03148489, -0.11285411, ...,  0.0420592 ,\n",
              "           0.12307081,  0.06683465],\n",
              "         ...,\n",
              "         [ 0.0523467 ,  0.0716006 , -0.10818477, ...,  0.03698853,\n",
              "           0.12510268,  0.05256998],\n",
              "         [ 0.05191868,  0.07150029, -0.10762212, ...,  0.03744889,\n",
              "           0.12466727,  0.05199569],\n",
              "         [ 0.05166977,  0.07150793, -0.10704714, ...,  0.03793942,\n",
              "           0.12427592,  0.05149204]]], dtype=float32),\n",
              " array([[[ 0.08268864,  0.0896084 , -0.12055501, ...,  0.07145537,\n",
              "           0.10249516,  0.12491141],\n",
              "         [ 0.06801009,  0.04488804, -0.12925248, ...,  0.05311379,\n",
              "           0.11016087,  0.08958603],\n",
              "         [ 0.06003444,  0.03121123, -0.11149111, ...,  0.04212456,\n",
              "           0.12381293,  0.066465  ],\n",
              "         ...,\n",
              "         [ 0.05231944,  0.07067563, -0.11015736, ...,  0.03552641,\n",
              "           0.1266408 ,  0.0513733 ],\n",
              "         [ 0.05219718,  0.0704812 , -0.11015511, ...,  0.03571337,\n",
              "           0.12611221,  0.05131946],\n",
              "         [ 0.05215535,  0.07016012, -0.11005185, ...,  0.03586804,\n",
              "           0.12545586,  0.05104086]],\n",
              " \n",
              "        [[ 0.07058845,  0.08538083, -0.1169364 , ...,  0.07016842,\n",
              "           0.10468835,  0.12656318],\n",
              "         [ 0.06263614,  0.04561147, -0.13040674, ...,  0.05119948,\n",
              "           0.10165679,  0.07830936],\n",
              "         [ 0.06471206,  0.03030997, -0.11969639, ...,  0.0375765 ,\n",
              "           0.117753  ,  0.06221066],\n",
              "         ...,\n",
              "         [ 0.06066427,  0.08580551, -0.10898127, ...,  0.04364588,\n",
              "           0.12275478,  0.04270075],\n",
              "         [ 0.06066652,  0.08590461, -0.1088026 , ...,  0.04383294,\n",
              "           0.1226497 ,  0.04263385],\n",
              "         [ 0.06059234,  0.08578143, -0.10876054, ...,  0.04412516,\n",
              "           0.12252538,  0.04254567]]], dtype=float32),\n",
              " array([[[-0.16506526,  0.20539798,  0.09006439, ..., -0.01518673,\n",
              "          -0.06237338, -0.1120986 ],\n",
              "         [-0.04242339,  0.18857169,  0.07289365, ...,  0.16407612,\n",
              "          -0.13501185, -0.03998402],\n",
              "         [-0.22376104,  0.14630446, -0.03631448, ...,  0.01733238,\n",
              "          -0.11798351, -0.00712513],\n",
              "         ...,\n",
              "         [-0.0013925 ,  0.23903154,  0.02676418, ...,  0.1518349 ,\n",
              "          -0.13168164, -0.05198951],\n",
              "         [-0.16954885,  0.10771735,  0.00625686, ...,  0.17380673,\n",
              "          -0.1089369 , -0.03524779],\n",
              "         [-0.05463796,  0.22484198,  0.04632217, ...,  0.10015103,\n",
              "          -0.07226235, -0.06173892]],\n",
              " \n",
              "        [[-0.13023496,  0.24692836,  0.12751439, ...,  0.05892333,\n",
              "          -0.04483313, -0.110017  ],\n",
              "         [ 0.02381375,  0.20175755,  0.03325775, ...,  0.18479395,\n",
              "          -0.04947454, -0.07114042],\n",
              "         [-0.06691057,  0.2024353 ,  0.01167967, ...,  0.17032915,\n",
              "          -0.05524456, -0.07242762],\n",
              "         ...,\n",
              "         [-0.09349818,  0.3180068 , -0.00886151, ...,  0.05821716,\n",
              "          -0.14485012, -0.11133884],\n",
              "         [-0.01067051,  0.24662976,  0.03530306, ...,  0.1839861 ,\n",
              "          -0.12257318, -0.03193236],\n",
              "         [-0.18435255,  0.32155776,  0.10004552, ...,  0.18058363,\n",
              "          -0.13589731, -0.0821469 ]],\n",
              " \n",
              "        [[-0.1551105 ,  0.22366416,  0.01991571, ...,  0.17691323,\n",
              "          -0.03867662, -0.09314706],\n",
              "         [-0.00849995,  0.2493576 ,  0.03878835, ...,  0.11372554,\n",
              "          -0.14491329,  0.03167394],\n",
              "         [-0.1600903 ,  0.2598812 , -0.0090397 , ...,  0.12859279,\n",
              "          -0.04887685, -0.04801562],\n",
              "         ...,\n",
              "         [-0.13944341,  0.16754504,  0.09757032, ...,  0.20030591,\n",
              "          -0.03350966, -0.16403148],\n",
              "         [-0.18908754,  0.09480138,  0.1311637 , ...,  0.10438014,\n",
              "          -0.1346974 , -0.12908064],\n",
              "         [-0.05762665,  0.2124691 , -0.01423747, ...,  0.10169112,\n",
              "          -0.10190539, -0.15804726]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.16108897,  0.27523562,  0.01253062, ...,  0.0620516 ,\n",
              "          -0.0684005 ,  0.07604842],\n",
              "         [-0.02193987,  0.14786132,  0.02365585, ...,  0.20999548,\n",
              "          -0.15677616, -0.0096595 ],\n",
              "         [-0.09815997,  0.20818253,  0.07823659, ...,  0.20199512,\n",
              "          -0.03793336,  0.02366715],\n",
              "         ...,\n",
              "         [-0.12554944,  0.16963896, -0.02431893, ...,  0.11810724,\n",
              "          -0.16470607, -0.02912222],\n",
              "         [-0.1141832 ,  0.33226317, -0.03655076, ..., -0.00169495,\n",
              "          -0.10212121, -0.03014355],\n",
              "         [-0.14218752,  0.09065378, -0.00673495, ...,  0.15375163,\n",
              "          -0.03060561, -0.03152971]],\n",
              " \n",
              "        [[-0.06933299,  0.29965132,  0.04888276, ...,  0.08633128,\n",
              "          -0.09005368,  0.03173055],\n",
              "         [-0.09824765,  0.15487015, -0.05250108, ...,  0.02894789,\n",
              "          -0.11409768, -0.0483125 ],\n",
              "         [-0.14299345,  0.15234178,  0.11807069, ...,  0.17602718,\n",
              "          -0.03525663,  0.07583968],\n",
              "         ...,\n",
              "         [-0.10871083,  0.16983977,  0.05172712, ...,  0.16053727,\n",
              "          -0.06201909, -0.0395555 ],\n",
              "         [-0.11186669,  0.18972707,  0.09067345, ...,  0.13806237,\n",
              "          -0.0868312 , -0.10789086],\n",
              "         [-0.13546236,  0.16688386,  0.10515251, ...,  0.06403796,\n",
              "          -0.11714996,  0.03220667]],\n",
              " \n",
              "        [[ 0.05266681,  0.21490574,  0.07020059, ...,  0.06364991,\n",
              "          -0.0581899 , -0.09547883],\n",
              "         [-0.14602098,  0.17291853,  0.01084864, ...,  0.17176741,\n",
              "          -0.10035472, -0.06332954],\n",
              "         [-0.10626693,  0.22793338,  0.05879866, ...,  0.15403855,\n",
              "          -0.11216967, -0.1679845 ],\n",
              "         ...,\n",
              "         [-0.06730375,  0.17621058,  0.11020979, ...,  0.19400375,\n",
              "          -0.19977951, -0.01643385],\n",
              "         [-0.20252603,  0.1284414 ,  0.06674216, ...,  0.17163879,\n",
              "          -0.08844489, -0.12170526],\n",
              "         [ 0.0084456 ,  0.29494846,  0.05896871, ...,  0.07355595,\n",
              "          -0.07656398, -0.0080778 ]]], dtype=float32),\n",
              " array([[[-1.00552216e-02,  2.44766712e-01,  7.14123845e-02, ...,\n",
              "           9.54396576e-02, -9.13544968e-02, -8.00447464e-02],\n",
              "         [-1.93945244e-02,  2.62669086e-01,  9.96799618e-02, ...,\n",
              "           1.62010789e-01, -1.05934925e-01, -7.18212426e-02],\n",
              "         [-1.10436842e-01,  1.13598667e-01,  1.63139496e-02, ...,\n",
              "           3.31799090e-02, -1.41079918e-01, -2.63464078e-02],\n",
              "         ...,\n",
              "         [-4.63873334e-02,  2.36228496e-01,  1.24679236e-02, ...,\n",
              "           9.48345363e-02, -1.04941525e-01, -1.30600393e-01],\n",
              "         [-6.17261454e-02,  1.99792147e-01,  3.93899120e-02, ...,\n",
              "           1.01013027e-01, -4.90884334e-02, -1.82538211e-01],\n",
              "         [-1.77431062e-01,  2.56680399e-01,  3.51257510e-02, ...,\n",
              "           9.31093842e-03, -9.74476337e-02, -8.68018046e-02]],\n",
              " \n",
              "        [[-8.42577145e-02,  2.10660875e-01,  1.83530226e-02, ...,\n",
              "           1.57758996e-01, -4.26387042e-02, -1.49473995e-01],\n",
              "         [-3.06269228e-02,  1.67767629e-01,  5.31523116e-02, ...,\n",
              "           1.16008535e-01, -1.80179864e-01, -1.00894824e-01],\n",
              "         [-1.53197423e-01,  1.33808896e-01,  7.43233636e-02, ...,\n",
              "           1.31095961e-01, -4.11070734e-02,  3.95690836e-02],\n",
              "         ...,\n",
              "         [-3.39869857e-02,  2.10949540e-01,  3.77599262e-02, ...,\n",
              "           9.42763984e-02, -1.15239099e-01, -1.45578086e-01],\n",
              "         [ 6.00309819e-02,  1.79349601e-01, -3.00052743e-02, ...,\n",
              "           1.49356037e-01, -1.32494003e-01, -1.42751023e-01],\n",
              "         [-1.06861927e-01,  1.80129781e-01, -4.52007353e-03, ...,\n",
              "           2.06041843e-01, -9.70836803e-02, -1.90606847e-01]],\n",
              " \n",
              "        [[-1.39247403e-01,  2.46429026e-01,  5.14721572e-02, ...,\n",
              "           1.35997623e-01, -1.28317699e-01, -4.29522991e-02],\n",
              "         [-3.37525085e-02,  2.70216584e-01, -6.43392801e-02, ...,\n",
              "           1.55541554e-01, -1.48128226e-01, -1.11298703e-01],\n",
              "         [-8.22464079e-02,  7.70917535e-02,  1.82376796e-04, ...,\n",
              "           1.99139431e-01, -1.88347518e-01, -9.91910845e-02],\n",
              "         ...,\n",
              "         [-9.46259424e-02,  1.05758242e-01, -1.23919053e-02, ...,\n",
              "           2.11932525e-01, -6.20118417e-02, -2.55262107e-03],\n",
              "         [-2.04924494e-01,  2.37124473e-01,  1.73767097e-03, ...,\n",
              "           1.52299583e-01, -2.20575958e-01, -8.96909684e-02],\n",
              "         [-8.91295746e-02,  1.66091397e-01, -3.16449441e-02, ...,\n",
              "           1.02736026e-01, -1.52306646e-01, -2.72391923e-02]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-6.84290081e-02,  9.73446071e-02,  5.28997146e-02, ...,\n",
              "           1.80161223e-01, -5.99373356e-02, -2.55147256e-02],\n",
              "         [-1.20136112e-01,  2.95713127e-01,  7.56732747e-02, ...,\n",
              "           8.20279717e-02, -3.28140408e-02, -8.70313644e-02],\n",
              "         [-1.30956799e-01,  2.30204090e-01, -2.05946416e-02, ...,\n",
              "           1.39709473e-01, -1.16356254e-01, -1.19701773e-01],\n",
              "         ...,\n",
              "         [-1.42757311e-01,  2.12830424e-01, -2.78534275e-02, ...,\n",
              "           1.42460316e-01, -1.39020398e-01, -7.68853575e-02],\n",
              "         [-1.78898692e-01,  2.65978366e-01,  1.11033514e-01, ...,\n",
              "           8.33697915e-02, -1.82362050e-01, -8.35666955e-02],\n",
              "         [-1.43631324e-02,  2.53323793e-01,  3.45522016e-02, ...,\n",
              "           1.47399902e-01, -1.25309780e-01, -1.27955563e-02]],\n",
              " \n",
              "        [[-5.81567287e-02,  2.62430698e-01,  4.91079278e-02, ...,\n",
              "          -1.34258494e-02, -2.82362178e-02, -1.39148265e-01],\n",
              "         [-1.22467250e-01,  2.89830089e-01,  1.61025487e-02, ...,\n",
              "           2.25195840e-01, -7.44714960e-02, -9.55333263e-02],\n",
              "         [ 3.06332856e-03,  3.27725053e-01, -6.65829331e-02, ...,\n",
              "           5.54547310e-02, -8.15373957e-02, -4.74035256e-02],\n",
              "         ...,\n",
              "         [-1.01734936e-01,  2.78893590e-01,  4.76836897e-02, ...,\n",
              "           1.16022348e-01, -1.23044074e-01, -3.31377797e-02],\n",
              "         [-3.74753810e-02,  2.86735654e-01,  7.61380419e-02, ...,\n",
              "           1.71115041e-01, -1.30790174e-01, -1.37274429e-01],\n",
              "         [ 4.37450558e-02,  2.53863275e-01, -9.70986485e-03, ...,\n",
              "           1.90116078e-01, -5.63038252e-02, -2.08551139e-02]],\n",
              " \n",
              "        [[-1.60765946e-01,  2.61925429e-01,  1.14860870e-01, ...,\n",
              "           8.87803733e-04, -1.26908258e-01, -4.95050102e-02],\n",
              "         [-1.62229419e-01,  2.66925871e-01,  2.42935084e-02, ...,\n",
              "           9.73536074e-02, -1.33184969e-01, -7.48549998e-02],\n",
              "         [-6.72388822e-02,  2.54152626e-01, -3.40330116e-02, ...,\n",
              "           1.04065754e-01, -6.52506948e-03, -1.83004022e-01],\n",
              "         ...,\n",
              "         [-6.33759648e-02,  2.30234504e-01,  1.63366228e-01, ...,\n",
              "           1.61964655e-01, -7.03815371e-02, -4.05168235e-02],\n",
              "         [-1.45485982e-01,  2.43004963e-01, -4.39126603e-02, ...,\n",
              "           9.18498561e-02, -1.34548232e-01, -6.07015193e-03],\n",
              "         [-1.41090333e-01,  2.69794226e-01,  2.50102766e-02, ...,\n",
              "           1.95029825e-02,  1.48273110e-02, -6.61521330e-02]]],\n",
              "       dtype=float32),\n",
              " array([[[-0.06306498,  0.2357633 ,  0.144539  , ...,  0.1357031 ,\n",
              "          -0.09911857,  0.09618473],\n",
              "         [-0.14687234,  0.30779004,  0.00588021, ...,  0.16924319,\n",
              "          -0.06753041, -0.07706532],\n",
              "         [-0.16453269,  0.29638508,  0.08602589, ...,  0.15735018,\n",
              "          -0.05467541,  0.03099373],\n",
              "         ...,\n",
              "         [-0.19145605,  0.24275292,  0.04047006, ...,  0.21319613,\n",
              "          -0.02150712, -0.10966603],\n",
              "         [-0.04635255,  0.27446842,  0.02762482, ...,  0.00848101,\n",
              "          -0.15750366, -0.14887078],\n",
              "         [ 0.01567935,  0.23598482,  0.06742214, ...,  0.12729636,\n",
              "          -0.02759198, -0.06032167]],\n",
              " \n",
              "        [[-0.10864505,  0.27250472,  0.14442421, ...,  0.14416002,\n",
              "          -0.02521717,  0.04579343],\n",
              "         [-0.12852946,  0.177228  ,  0.05093628, ...,  0.04232198,\n",
              "          -0.10973053, -0.0735005 ],\n",
              "         [-0.07448094,  0.31467092,  0.09003263, ...,  0.08882602,\n",
              "          -0.11992939, -0.09374761],\n",
              "         ...,\n",
              "         [ 0.02111204,  0.271545  , -0.0316524 , ...,  0.06560164,\n",
              "          -0.21040925, -0.01104302],\n",
              "         [-0.13335523,  0.29249942,  0.08202957, ...,  0.16549507,\n",
              "          -0.07120378, -0.00369573],\n",
              "         [-0.17500308,  0.21583441,  0.02990662, ...,  0.08052534,\n",
              "          -0.01698747,  0.00153136]]], dtype=float32),\n",
              " array([[[ 0.07350589,  0.08540292, -0.11814226, ...,  0.07254045,\n",
              "           0.10022938,  0.12509671],\n",
              "         [ 0.06197687,  0.0440864 , -0.12928753, ...,  0.05345668,\n",
              "           0.10260555,  0.08218579],\n",
              "         [ 0.0617439 ,  0.02928242, -0.114475  , ...,  0.03918806,\n",
              "           0.11854063,  0.06712128],\n",
              "         ...,\n",
              "         [ 0.04968875,  0.07407567, -0.10933887, ...,  0.03510791,\n",
              "           0.11972811,  0.04435126],\n",
              "         [ 0.0494776 ,  0.07397258, -0.10940602, ...,  0.03513123,\n",
              "           0.11959815,  0.04437465],\n",
              "         [ 0.04923359,  0.07373656, -0.10966905, ...,  0.03528228,\n",
              "           0.11963189,  0.04407893]],\n",
              " \n",
              "        [[ 0.08110552,  0.08818956, -0.12014478, ...,  0.07110269,\n",
              "           0.10148961,  0.12481384],\n",
              "         [ 0.06622841,  0.04439364, -0.1290985 , ...,  0.05297282,\n",
              "           0.10818507,  0.08813566],\n",
              "         [ 0.06152562,  0.03142786, -0.11106625, ...,  0.04060686,\n",
              "           0.12266526,  0.06806123],\n",
              "         ...,\n",
              "         [ 0.0516622 ,  0.07252083, -0.11078314, ...,  0.03243639,\n",
              "           0.12366618,  0.0512844 ],\n",
              "         [ 0.05148285,  0.07257087, -0.11048897, ...,  0.03257896,\n",
              "           0.12322013,  0.05132347],\n",
              "         [ 0.05137869,  0.0726167 , -0.11019023, ...,  0.03288185,\n",
              "           0.12302458,  0.05142491]],\n",
              " \n",
              "        [[ 0.07295825,  0.0851263 , -0.11750502, ...,  0.07229646,\n",
              "           0.10103384,  0.12507787],\n",
              "         [ 0.06177049,  0.04417582, -0.1292926 , ...,  0.05297437,\n",
              "           0.10244097,  0.08185343],\n",
              "         [ 0.06188989,  0.02947162, -0.11486745, ...,  0.03868882,\n",
              "           0.11859605,  0.06668917],\n",
              "         ...,\n",
              "         [ 0.04946782,  0.07380189, -0.11048818, ...,  0.03539971,\n",
              "           0.1196399 ,  0.04317548],\n",
              "         [ 0.04916313,  0.0736221 , -0.110658  , ...,  0.03569021,\n",
              "           0.11962245,  0.04301934],\n",
              "         [ 0.04895076,  0.07355638, -0.11086187, ...,  0.0360806 ,\n",
              "           0.11970088,  0.04281446]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.07233965,  0.08486711, -0.11737864, ...,  0.07080016,\n",
              "           0.10197553,  0.12578629],\n",
              "         [ 0.06061181,  0.04308593, -0.12918828, ...,  0.05143397,\n",
              "           0.10102016,  0.08004651],\n",
              "         [ 0.06150599,  0.02713346, -0.11698038, ...,  0.03833746,\n",
              "           0.11697918,  0.06505089],\n",
              "         ...,\n",
              "         [ 0.05278318,  0.07565871, -0.10961752, ...,  0.03766758,\n",
              "           0.12235188,  0.04297913],\n",
              "         [ 0.05259652,  0.07562643, -0.10967648, ...,  0.03802252,\n",
              "           0.12251695,  0.04270146],\n",
              "         [ 0.05241788,  0.07555313, -0.10957758, ...,  0.03828842,\n",
              "           0.12247432,  0.0426279 ]],\n",
              " \n",
              "        [[ 0.06990384,  0.08634295, -0.11764519, ...,  0.07082616,\n",
              "           0.1056544 ,  0.12758787],\n",
              "         [ 0.06418891,  0.04725418, -0.13023831, ...,  0.05140411,\n",
              "           0.10283002,  0.07573909],\n",
              "         [ 0.06467666,  0.03327619, -0.12058782, ...,  0.03840179,\n",
              "           0.11833635,  0.05751907],\n",
              "         ...,\n",
              "         [ 0.06221844,  0.09086054, -0.10306732, ...,  0.04717466,\n",
              "           0.1198059 ,  0.0396966 ],\n",
              "         [ 0.06269441,  0.09110143, -0.10304302, ...,  0.04722216,\n",
              "           0.11983277,  0.03997777],\n",
              "         [ 0.06289172,  0.09130751, -0.10281429, ...,  0.04725643,\n",
              "           0.11980474,  0.03989404]],\n",
              " \n",
              "        [[ 0.08483134,  0.09061311, -0.1188971 , ...,  0.06909028,\n",
              "           0.10140397,  0.12531014],\n",
              "         [ 0.07370955,  0.04591142, -0.13369885, ...,  0.04970519,\n",
              "           0.10968024,  0.09530636],\n",
              "         [ 0.0604308 ,  0.03257699, -0.12132096, ...,  0.04244225,\n",
              "           0.11727296,  0.07656477],\n",
              "         ...,\n",
              "         [ 0.06285052,  0.08728807, -0.13838129, ...,  0.06245077,\n",
              "           0.09377725,  0.03822213],\n",
              "         [ 0.07003292,  0.08336292, -0.14801049, ...,  0.06256022,\n",
              "           0.0935294 ,  0.03964213],\n",
              "         [ 0.07235759,  0.07706353, -0.15249136, ...,  0.05959873,\n",
              "           0.0938057 ,  0.04304297]]], dtype=float32),\n",
              " array([[[ 0.0727218 ,  0.08480687, -0.11723716, ...,  0.07212423,\n",
              "           0.10114763,  0.12508804],\n",
              "         [ 0.06173581,  0.04399473, -0.12944925, ...,  0.05269828,\n",
              "           0.10220062,  0.08159378],\n",
              "         [ 0.0616764 ,  0.02895632, -0.11532217, ...,  0.0387369 ,\n",
              "           0.11829841,  0.06645567],\n",
              "         ...,\n",
              "         [ 0.04933172,  0.07358862, -0.11040686, ...,  0.03568832,\n",
              "           0.12000135,  0.04263116],\n",
              "         [ 0.04906313,  0.07328737, -0.11075093, ...,  0.03586263,\n",
              "           0.12000898,  0.04241762],\n",
              "         [ 0.04889193,  0.072974  , -0.11116786, ...,  0.03593157,\n",
              "           0.1200259 ,  0.04226675]],\n",
              " \n",
              "        [[ 0.08189404,  0.08942689, -0.12035061, ...,  0.07158051,\n",
              "           0.10237537,  0.1252409 ],\n",
              "         [ 0.06787037,  0.04474747, -0.1291291 , ...,  0.05305888,\n",
              "           0.10993835,  0.08959989],\n",
              "         [ 0.06055618,  0.03079783, -0.11110297, ...,  0.04178498,\n",
              "           0.12401915,  0.06759123],\n",
              "         ...,\n",
              "         [ 0.05243253,  0.07053378, -0.11069429, ...,  0.03482747,\n",
              "           0.12670857,  0.05174694],\n",
              "         [ 0.0524004 ,  0.07041875, -0.11060771, ...,  0.03506003,\n",
              "           0.12655371,  0.05171335],\n",
              "         [ 0.05204282,  0.07024039, -0.11026684, ...,  0.03532423,\n",
              "           0.12610714,  0.05154842]],\n",
              " \n",
              "        [[ 0.06603621,  0.08476046, -0.11649495, ...,  0.07170529,\n",
              "           0.11091743,  0.13073516],\n",
              "         [ 0.06995063,  0.05432592, -0.13010935, ...,  0.05052177,\n",
              "           0.10810201,  0.076179  ],\n",
              "         [ 0.07030486,  0.04105988, -0.12371233, ...,  0.04241265,\n",
              "           0.12175079,  0.05286368],\n",
              "         ...,\n",
              "         [ 0.07491899,  0.09603543, -0.10235459, ...,  0.05234284,\n",
              "           0.12692755,  0.04209303],\n",
              "         [ 0.07554228,  0.09624199, -0.10205707, ...,  0.05235577,\n",
              "           0.12738957,  0.04185977],\n",
              "         [ 0.07585385,  0.09631054, -0.10164355, ...,  0.05250722,\n",
              "           0.12762687,  0.04160228]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.08181033,  0.08973382, -0.1201372 , ...,  0.07145228,\n",
              "           0.10174948,  0.12506397],\n",
              "         [ 0.0694163 ,  0.0457495 , -0.12980883, ...,  0.05295496,\n",
              "           0.11028538,  0.09005424],\n",
              "         [ 0.06071762,  0.03142795, -0.11202428, ...,  0.04183044,\n",
              "           0.12364637,  0.06674632],\n",
              "         ...,\n",
              "         [ 0.05248371,  0.07143859, -0.10937146, ...,  0.03657286,\n",
              "           0.12668194,  0.05223943],\n",
              "         [ 0.05224296,  0.07131155, -0.10898827, ...,  0.03680187,\n",
              "           0.12577951,  0.05200994],\n",
              "         [ 0.05216816,  0.07125093, -0.10854112, ...,  0.03715418,\n",
              "           0.12519115,  0.05167744]],\n",
              " \n",
              "        [[ 0.07306269,  0.08535964, -0.11764509, ...,  0.0717776 ,\n",
              "           0.10091959,  0.12580535],\n",
              "         [ 0.06150617,  0.04337137, -0.12898318, ...,  0.05268841,\n",
              "           0.10241353,  0.08088554],\n",
              "         [ 0.06143083,  0.02832611, -0.11550541, ...,  0.0390805 ,\n",
              "           0.11800689,  0.06581895],\n",
              "         ...,\n",
              "         [ 0.05201986,  0.0753033 , -0.10934083, ...,  0.0357906 ,\n",
              "           0.12195551,  0.04401145],\n",
              "         [ 0.05190253,  0.07516053, -0.10926931, ...,  0.03565246,\n",
              "           0.12177624,  0.04420912],\n",
              "         [ 0.05178403,  0.07509346, -0.10922699, ...,  0.0356693 ,\n",
              "           0.12172776,  0.04434417]],\n",
              " \n",
              "        [[ 0.08182983,  0.0897546 , -0.11996727, ...,  0.07159978,\n",
              "           0.10132486,  0.125003  ],\n",
              "         [ 0.06994963,  0.04615651, -0.13035363, ...,  0.05303719,\n",
              "           0.11019199,  0.0904945 ],\n",
              "         [ 0.06047156,  0.03148489, -0.11285411, ...,  0.0420592 ,\n",
              "           0.12307081,  0.06683465],\n",
              "         ...,\n",
              "         [ 0.0523467 ,  0.0716006 , -0.10818477, ...,  0.03698853,\n",
              "           0.12510268,  0.05256998],\n",
              "         [ 0.05191868,  0.07150029, -0.10762212, ...,  0.03744889,\n",
              "           0.12466727,  0.05199569],\n",
              "         [ 0.05166977,  0.07150793, -0.10704714, ...,  0.03793942,\n",
              "           0.12427592,  0.05149204]]], dtype=float32),\n",
              " array([[[ 0.08268864,  0.0896084 , -0.12055501, ...,  0.07145537,\n",
              "           0.10249516,  0.12491141],\n",
              "         [ 0.06801009,  0.04488804, -0.12925248, ...,  0.05311379,\n",
              "           0.11016087,  0.08958603],\n",
              "         [ 0.06003444,  0.03121123, -0.11149111, ...,  0.04212456,\n",
              "           0.12381293,  0.066465  ],\n",
              "         ...,\n",
              "         [ 0.05231944,  0.07067563, -0.11015736, ...,  0.03552641,\n",
              "           0.1266408 ,  0.0513733 ],\n",
              "         [ 0.05219718,  0.0704812 , -0.11015511, ...,  0.03571337,\n",
              "           0.12611221,  0.05131946],\n",
              "         [ 0.05215535,  0.07016012, -0.11005185, ...,  0.03586804,\n",
              "           0.12545586,  0.05104086]],\n",
              " \n",
              "        [[ 0.07058845,  0.08538083, -0.1169364 , ...,  0.07016842,\n",
              "           0.10468835,  0.12656318],\n",
              "         [ 0.06263614,  0.04561147, -0.13040674, ...,  0.05119948,\n",
              "           0.10165679,  0.07830936],\n",
              "         [ 0.06471206,  0.03030997, -0.11969639, ...,  0.0375765 ,\n",
              "           0.117753  ,  0.06221066],\n",
              "         ...,\n",
              "         [ 0.06066427,  0.08580551, -0.10898127, ...,  0.04364588,\n",
              "           0.12275478,  0.04270075],\n",
              "         [ 0.06066652,  0.08590461, -0.1088026 , ...,  0.04383294,\n",
              "           0.1226497 ,  0.04263385],\n",
              "         [ 0.06059234,  0.08578143, -0.10876054, ...,  0.04412516,\n",
              "           0.12252538,  0.04254567]]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch):\n",
        "    \"\"\"Adjusts the learning rate of the optimizer.\"\"\"\n",
        "    lr = initial_lr * (0.1 ** (epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, initial_lr=0.001, lr_decay_epoch=3, device='cuda'):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    scheduler = StepLR(optimizer, step_size=lr_decay_epoch, gamma=0.1)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch)\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
        "\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "                real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "                output = model(real_features)\n",
        "                val_loss += criterion(output, deepfake_features).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "def evaluate_model(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    criterion = nn.MSELoss()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for real_features, deepfake_features in loader:\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model(real_features)\n",
        "            total_loss += criterion(output, deepfake_features).item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "BllmtizSJkaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, 1000)\n",
        "evaluate_model(model, val_loader)"
      ],
      "metadata": {
        "id": "4P7JfXv4JpxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emotion Recognition"
      ],
      "metadata": {
        "id": "DyYz4-9352xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b7pskfUbEyvu",
        "outputId": "f6e4596b-4180-4db3-e6ce-854eafd76672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/session1.zip\n",
        "!unzip /content/drive/MyDrive/session1_video.zip"
      ],
      "metadata": {
        "id": "_Ua795v4wDUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80425d03-2bf8-4785-96aa-3bafd3c64eff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/session1.zip\n",
            "   creating: session1/\n",
            "   creating: session1/S01A/\n",
            "   creating: session1/S01A/P/\n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.wav  \n",
            "   creating: session1/S01A/R/\n",
            "  inflating: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.wav  \n",
            "   creating: session1/S01A/S/\n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.wav  \n",
            "   creating: session1/S01A/T/\n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.wav  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.wav  \n",
            "   creating: session1/S01H/\n",
            "   creating: session1/S01H/P/\n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav  \n",
            "   creating: session1/S01H/R/\n",
            "  inflating: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav  \n",
            "   creating: session1/S01H/S/\n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav  \n",
            "   creating: session1/S01H/T/\n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav  \n",
            "   creating: session1/S01N/\n",
            "   creating: session1/S01N/P/\n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.wav  \n",
            "   creating: session1/S01N/R/\n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.wav  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.wav  \n",
            "   creating: session1/S01N/S/\n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.wav  \n",
            "   creating: session1/S01N/T/\n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.wav  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.wav  \n",
            "   creating: session1/S01S/\n",
            "   creating: session1/S01S/P/\n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav  \n",
            "   creating: session1/S01S/R/\n",
            "  inflating: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav  \n",
            "   creating: session1/S01S/S/\n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav  \n",
            "   creating: session1/S01S/T/\n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav  \n",
            "   creating: session1/S02A/\n",
            "   creating: session1/S02A/P/\n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.wav  \n",
            "   creating: session1/S02A/R/\n",
            "  inflating: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.wav  \n",
            "   creating: session1/S02A/S/\n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.wav  \n",
            "   creating: session1/S02A/T/\n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.wav  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.wav  \n",
            "   creating: session1/S02H/\n",
            "   creating: session1/S02H/P/\n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.wav  \n",
            "   creating: session1/S02H/R/\n",
            "  inflating: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.wav  \n",
            "   creating: session1/S02H/S/\n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.wav  \n",
            "   creating: session1/S02H/T/\n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.wav  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.wav  \n",
            "   creating: session1/S02N/\n",
            "   creating: session1/S02N/P/\n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.wav  \n",
            "   creating: session1/S02N/R/\n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.wav  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.wav  \n",
            "   creating: session1/S02N/S/\n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.wav  \n",
            "   creating: session1/S02N/T/\n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.wav  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.wav  \n",
            "   creating: session1/S02S/\n",
            "   creating: session1/S02S/P/\n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav  \n",
            "   creating: session1/S02S/R/\n",
            "  inflating: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav  \n",
            "   creating: session1/S02S/S/\n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav  \n",
            "   creating: session1/S02S/T/\n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav  \n",
            "   creating: session1/S03A/\n",
            "   creating: session1/S03A/P/\n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav  \n",
            "   creating: session1/S03A/R/\n",
            "  inflating: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav  \n",
            "   creating: session1/S03A/S/\n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav  \n",
            "   creating: session1/S03A/T/\n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav  \n",
            "   creating: session1/S03H/\n",
            "   creating: session1/S03H/P/\n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.wav  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.wav  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.wav  \n",
            "   creating: session1/S03H/R/\n",
            "  inflating: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav  \n",
            "   creating: session1/S03H/S/\n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav  \n",
            "   creating: session1/S03H/T/\n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav  \n",
            "   creating: session1/S03N/\n",
            "   creating: session1/S03N/P/\n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.wav  \n",
            "   creating: session1/S03N/R/\n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.wav  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.wav  \n",
            "   creating: session1/S03N/S/\n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.wav  \n",
            "   creating: session1/S03N/T/\n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.wav  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.wav  \n",
            "   creating: session1/S03S/\n",
            "   creating: session1/S03S/P/\n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.wav  \n",
            "   creating: session1/S03S/R/\n",
            "  inflating: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.wav  \n",
            "   creating: session1/S03S/S/\n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.wav  \n",
            "   creating: session1/S03S/T/\n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.wav  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.wav  \n",
            "   creating: session1/S04A/\n",
            "   creating: session1/S04A/P/\n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.wav  \n",
            "   creating: session1/S04A/R/\n",
            "  inflating: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.wav  \n",
            "   creating: session1/S04A/S/\n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.wav  \n",
            "   creating: session1/S04A/T/\n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.wav  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.wav  \n",
            "   creating: session1/S04H/\n",
            "   creating: session1/S04H/P/\n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav  \n",
            "   creating: session1/S04H/R/\n",
            "  inflating: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav  \n",
            "   creating: session1/S04H/S/\n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav  \n",
            "   creating: session1/S04H/T/\n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav  \n",
            "   creating: session1/S04N/\n",
            "   creating: session1/S04N/P/\n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.wav  \n",
            "   creating: session1/S04N/R/\n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.wav  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.wav  \n",
            "   creating: session1/S04N/S/\n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.wav  \n",
            "   creating: session1/S04N/T/\n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.wav  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.wav  \n",
            "   creating: session1/S04S/\n",
            "   creating: session1/S04S/P/\n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav  \n",
            "   creating: session1/S04S/R/\n",
            "  inflating: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav  \n",
            "   creating: session1/S04S/S/\n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav  \n",
            "   creating: session1/S04S/T/\n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav  \n",
            "   creating: session1/S05A/\n",
            "   creating: session1/S05A/P/\n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.wav  \n",
            "   creating: session1/S05A/R/\n",
            "  inflating: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.wav  \n",
            "   creating: session1/S05A/S/\n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.wav  \n",
            "   creating: session1/S05A/T/\n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.wav  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.wav  \n",
            "   creating: session1/S05H/\n",
            "   creating: session1/S05H/P/\n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.wav  \n",
            "   creating: session1/S05H/R/\n",
            "  inflating: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.wav  \n",
            "   creating: session1/S05H/S/\n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.wav  \n",
            "   creating: session1/S05H/T/\n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.wav  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.wav  \n",
            "   creating: session1/S05N/\n",
            "   creating: session1/S05N/P/\n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav  \n",
            "   creating: session1/S05N/R/\n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav  \n",
            "   creating: session1/S05N/S/\n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav  \n",
            "   creating: session1/S05N/T/\n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav  \n",
            "   creating: session1/S05S/\n",
            "   creating: session1/S05S/P/\n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.wav  \n",
            "   creating: session1/S05S/R/\n",
            "  inflating: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.wav  \n",
            "   creating: session1/S05S/S/\n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.wav  \n",
            "   creating: session1/S05S/T/\n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.wav  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.wav  \n",
            "   creating: session1/S06A/\n",
            "   creating: session1/S06A/P/\n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.wav  \n",
            "   creating: session1/S06A/R/\n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.wav  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.wav  \n",
            "   creating: session1/S06A/S/\n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.wav  \n",
            "   creating: session1/S06A/T/\n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.wav  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.wav  \n",
            "   creating: session1/S06H/\n",
            "   creating: session1/S06H/P/\n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.wav  \n",
            "   creating: session1/S06H/R/\n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.wav  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.wav  \n",
            "   creating: session1/S06H/S/\n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.wav  \n",
            "   creating: session1/S06H/T/\n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.wav  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.wav  \n",
            "   creating: session1/S06N/\n",
            "   creating: session1/S06N/P/\n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.wav  \n",
            "   creating: session1/S06N/R/\n",
            "  inflating: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.wav  \n",
            "   creating: session1/S06N/S/\n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.wav  \n",
            "   creating: session1/S06N/T/\n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.wav  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.wav  \n",
            "   creating: session1/S06S/\n",
            "   creating: session1/S06S/P/\n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav  \n",
            "   creating: session1/S06S/R/\n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav  \n",
            "   creating: session1/S06S/S/\n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav  \n",
            "   creating: session1/S06S/T/\n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav  \n",
            "   creating: session1/S07A/\n",
            "   creating: session1/S07A/P/\n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav  \n",
            "   creating: session1/S07A/R/\n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav  \n",
            "   creating: session1/S07A/S/\n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav  \n",
            "   creating: session1/S07A/T/\n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav  \n",
            "   creating: session1/S07H/\n",
            "   creating: session1/S07H/P/\n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav  \n",
            "   creating: session1/S07H/R/\n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav  \n",
            "   creating: session1/S07H/S/\n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav  \n",
            "   creating: session1/S07H/T/\n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav  \n",
            "   creating: session1/S07N/\n",
            "   creating: session1/S07N/P/\n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.wav  \n",
            "   creating: session1/S07N/R/\n",
            "  inflating: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.wav  \n",
            "   creating: session1/S07N/S/\n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.wav  \n",
            "   creating: session1/S07N/T/\n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.wav  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.wav  \n",
            "   creating: session1/S07S/\n",
            "   creating: session1/S07S/P/\n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav  \n",
            "   creating: session1/S07S/R/\n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav  \n",
            "   creating: session1/S07S/S/\n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav  \n",
            "   creating: session1/S07S/T/\n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav  \n",
            "   creating: session1/S08A/\n",
            "   creating: session1/S08A/P/\n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav  \n",
            "   creating: session1/S08A/R/\n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav  \n",
            "   creating: session1/S08A/S/\n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav  \n",
            "   creating: session1/S08A/T/\n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav  \n",
            "   creating: session1/S08H/\n",
            "   creating: session1/S08H/P/\n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav  \n",
            "   creating: session1/S08H/R/\n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav  \n",
            "   creating: session1/S08H/S/\n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav  \n",
            "   creating: session1/S08H/T/\n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav  \n",
            "   creating: session1/S08N/\n",
            "   creating: session1/S08N/P/\n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.wav  \n",
            "   creating: session1/S08N/R/\n",
            "  inflating: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.wav  \n",
            "   creating: session1/S08N/S/\n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.wav  \n",
            "   creating: session1/S08N/T/\n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.wav  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.wav  \n",
            "   creating: session1/S08S/\n",
            "   creating: session1/S08S/P/\n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav  \n",
            "   creating: session1/S08S/R/\n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav  \n",
            "   creating: session1/S08S/S/\n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav  \n",
            "   creating: session1/S08S/T/\n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav  \n",
            "   creating: session1/S09A/\n",
            "   creating: session1/S09A/P/\n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.wav  \n",
            "   creating: session1/S09A/R/\n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.wav  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.wav  \n",
            "   creating: session1/S09A/S/\n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.wav  \n",
            "   creating: session1/S09A/T/\n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.wav  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.wav  \n",
            "   creating: session1/S09H/\n",
            "   creating: session1/S09H/P/\n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav  \n",
            "   creating: session1/S09H/R/\n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav  \n",
            "   creating: session1/S09H/S/\n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav  \n",
            "   creating: session1/S09H/T/\n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav  \n",
            "   creating: session1/S09N/\n",
            "   creating: session1/S09N/P/\n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav  \n",
            "   creating: session1/S09N/R/\n",
            "  inflating: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav  \n",
            "   creating: session1/S09N/S/\n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav  \n",
            "   creating: session1/S09N/T/\n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav  \n",
            "   creating: session1/S09S/\n",
            "   creating: session1/S09S/P/\n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.wav  \n",
            "   creating: session1/S09S/R/\n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.wav  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.wav  \n",
            "   creating: session1/S09S/S/\n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.wav  \n",
            "   creating: session1/S09S/T/\n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.wav  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.wav  \n",
            "   creating: session1/S10A/\n",
            "   creating: session1/S10A/P/\n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.wav  \n",
            "   creating: session1/S10A/R/\n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.wav  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.wav  \n",
            "   creating: session1/S10A/S/\n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.wav  \n",
            "   creating: session1/S10A/T/\n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.wav  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.wav  \n",
            "   creating: session1/S10H/\n",
            "   creating: session1/S10H/P/\n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav  \n",
            "   creating: session1/S10H/R/\n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav  \n",
            "   creating: session1/S10H/S/\n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav  \n",
            "   creating: session1/S10H/T/\n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav  \n",
            "   creating: session1/S10N/\n",
            "   creating: session1/S10N/P/\n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav  \n",
            "   creating: session1/S10N/R/\n",
            "  inflating: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav  \n",
            "   creating: session1/S10N/S/\n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav  \n",
            "   creating: session1/S10N/T/\n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav  \n",
            "   creating: session1/S10S/\n",
            "   creating: session1/S10S/P/\n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.wav  \n",
            "   creating: session1/S10S/R/\n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.wav  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.wav  \n",
            "   creating: session1/S10S/S/\n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.wav  \n",
            "   creating: session1/S10S/T/\n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.wav  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.wav  \n",
            "   creating: session1/S11A/\n",
            "   creating: session1/S11A/R/\n",
            "  inflating: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.wav  \n",
            "   creating: session1/S11H/\n",
            "   creating: session1/S11H/R/\n",
            "  inflating: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav  \n",
            "   creating: session1/S11N/\n",
            "   creating: session1/S11N/R/\n",
            "  inflating: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.wav  \n",
            "   creating: session1/S11S/\n",
            "   creating: session1/S11S/R/\n",
            "  inflating: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav  \n",
            "   creating: session1/S12A/\n",
            "   creating: session1/S12A/R/\n",
            "  inflating: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav  \n",
            "   creating: session1/S12H/\n",
            "   creating: session1/S12H/R/\n",
            "  inflating: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav  \n",
            "   creating: session1/S12N/\n",
            "   creating: session1/S12N/R/\n",
            "  inflating: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.wav  \n",
            "   creating: session1/S12S/\n",
            "   creating: session1/S12S/R/\n",
            "  inflating: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.wav  \n",
            "   creating: session1/S13A/\n",
            "   creating: session1/S13A/R/\n",
            "  inflating: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.wav  \n",
            "   creating: session1/S13H/\n",
            "   creating: session1/S13H/R/\n",
            "  inflating: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav  \n",
            "   creating: session1/S13N/\n",
            "   creating: session1/S13N/R/\n",
            "  inflating: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav  \n",
            "   creating: session1/S13S/\n",
            "   creating: session1/S13S/R/\n",
            "  inflating: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav  \n",
            "   creating: session1/S14A/\n",
            "   creating: session1/S14A/R/\n",
            "  inflating: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.wav  \n",
            "   creating: session1/S14H/\n",
            "   creating: session1/S14H/R/\n",
            "  inflating: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav  \n",
            "   creating: session1/S14N/\n",
            "   creating: session1/S14N/R/\n",
            "  inflating: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav  \n",
            "   creating: session1/S14S/\n",
            "   creating: session1/S14S/R/\n",
            "  inflating: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav  \n",
            "   creating: session1/S15A/\n",
            "   creating: session1/S15A/R/\n",
            "  inflating: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav  \n",
            "   creating: session1/S15H/\n",
            "   creating: session1/S15H/R/\n",
            "  inflating: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.wav  \n",
            "   creating: session1/S15N/\n",
            "   creating: session1/S15N/R/\n",
            "  inflating: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.wav  \n",
            "   creating: session1/S15S/\n",
            "   creating: session1/S15S/R/\n",
            "  inflating: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav  \n",
            "   creating: session1/S16A/\n",
            "   creating: session1/S16A/R/\n",
            "  inflating: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.wav  \n",
            "   creating: session1/S16H/\n",
            "   creating: session1/S16H/R/\n",
            "  inflating: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav  \n",
            "   creating: session1/S16N/\n",
            "   creating: session1/S16N/R/\n",
            "  inflating: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav  \n",
            "   creating: session1/S16S/\n",
            "   creating: session1/S16S/R/\n",
            "  inflating: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav  \n",
            "   creating: session1/S17A/\n",
            "   creating: session1/S17A/R/\n",
            "  inflating: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.wav  \n",
            "   creating: session1/S17H/\n",
            "   creating: session1/S17H/R/\n",
            "  inflating: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav  \n",
            "   creating: session1/S17N/\n",
            "   creating: session1/S17N/R/\n",
            "  inflating: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav  \n",
            "   creating: session1/S17S/\n",
            "   creating: session1/S17S/R/\n",
            "  inflating: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav  \n",
            "   creating: session1/S18A/\n",
            "   creating: session1/S18A/R/\n",
            "  inflating: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.wav  \n",
            "   creating: session1/S18H/\n",
            "   creating: session1/S18H/R/\n",
            "  inflating: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.wav  \n",
            "   creating: session1/S18N/\n",
            "   creating: session1/S18N/R/\n",
            "  inflating: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.wav  \n",
            "   creating: session1/S18S/\n",
            "   creating: session1/S18S/R/\n",
            "  inflating: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav  \n",
            "   creating: session1/S19A/\n",
            "   creating: session1/S19A/R/\n",
            "  inflating: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav  \n",
            "   creating: session1/S19H/\n",
            "   creating: session1/S19H/R/\n",
            "  inflating: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav  \n",
            "   creating: session1/S19N/\n",
            "   creating: session1/S19N/R/\n",
            "  inflating: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.wav  \n",
            "   creating: session1/S19S/\n",
            "   creating: session1/S19S/R/\n",
            "  inflating: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav  \n",
            "   creating: session1/S20A/\n",
            "   creating: session1/S20A/R/\n",
            "  inflating: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav  \n",
            "   creating: session1/S20H/\n",
            "   creating: session1/S20H/R/\n",
            "  inflating: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.wav  \n",
            "   creating: session1/S20N/\n",
            "   creating: session1/S20N/R/\n",
            "  inflating: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav  \n",
            "   creating: session1/S20S/\n",
            "   creating: session1/S20S/R/\n",
            "  inflating: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav  \n",
            "Archive:  /content/drive/MyDrive/session1_video.zip\n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.avi  \n",
            "  inflating: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.avi  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.avi  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.avi  \n",
            "  inflating: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.avi  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.avi  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.avi  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.avi  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.avi  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.avi  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.avi  \n",
            "  inflating: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.avi  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.avi  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.avi  \n",
            "  inflating: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.avi  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.avi  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.avi  \n",
            "  inflating: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.avi  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.avi  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.avi  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.avi  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.avi  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.avi  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.avi  \n",
            "  inflating: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.avi  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.avi  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.avi  \n",
            "  inflating: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.avi  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.avi  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.avi  \n",
            "  inflating: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.avi  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.avi  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.avi  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.avi  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.avi  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.avi  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.avi  \n",
            "  inflating: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.avi  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.avi  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.avi  \n",
            "  inflating: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.avi  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.avi  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.avi  \n",
            "  inflating: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.avi  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.avi  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.avi  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.avi  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.avi  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.avi  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.avi  \n",
            "  inflating: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.avi  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.avi  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.avi  \n",
            "  inflating: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.avi  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.avi  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.avi  \n",
            "  inflating: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.avi  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.avi  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.avi  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.avi  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.avi  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.avi  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.avi  \n",
            "  inflating: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.avi  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.avi  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.avi  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.avi  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.avi  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.avi  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.avi  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.avi  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.avi  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.avi  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.avi  \n",
            "  inflating: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.avi  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.avi  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.avi  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.avi  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.avi  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.avi  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.avi  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.avi  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.avi  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.avi  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.avi  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.avi  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.avi  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.avi  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.avi  \n",
            "  inflating: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.avi  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.avi  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.avi  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.avi  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.avi  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.avi  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.avi  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.avi  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.avi  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.avi  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.avi  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.avi  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.avi  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.avi  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.avi  \n",
            "  inflating: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.avi  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.avi  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.avi  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.avi  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.avi  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.avi  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.avi  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.avi  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.avi  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.avi  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.avi  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.avi  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.avi  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.avi  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.avi  \n",
            "  inflating: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.avi  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.avi  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.avi  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.avi  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.avi  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.avi  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.avi  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.avi  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.avi  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.avi  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.avi  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.avi  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.avi  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.avi  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.avi  \n",
            "  inflating: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.avi  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.avi  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.avi  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.avi  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.avi  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.avi  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.avi  \n",
            "  inflating: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.avi  \n",
            "  inflating: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.avi  \n",
            "  inflating: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.avi  \n",
            "  inflating: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.avi  \n",
            "  inflating: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.avi  \n",
            "  inflating: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.avi  \n",
            "  inflating: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.avi  \n",
            "  inflating: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.avi  \n",
            "  inflating: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.avi  \n",
            "  inflating: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.avi  \n",
            "  inflating: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.avi  \n",
            "  inflating: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.avi  \n",
            "  inflating: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.avi  \n",
            "  inflating: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.avi  \n",
            "  inflating: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.avi  \n",
            "  inflating: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.avi  \n",
            "  inflating: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.avi  \n",
            "  inflating: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.avi  \n",
            "  inflating: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.avi  \n",
            "  inflating: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.avi  \n",
            "  inflating: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.avi  \n",
            "  inflating: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.avi  \n",
            "  inflating: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.avi  \n",
            "  inflating: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.avi  \n",
            "  inflating: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.avi  \n",
            "  inflating: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.avi  \n",
            "  inflating: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.avi  \n",
            "  inflating: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.avi  \n",
            "  inflating: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.avi  \n",
            "  inflating: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.avi  \n",
            "  inflating: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.avi  \n",
            "  inflating: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.avi  \n",
            "  inflating: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.avi  \n",
            "  inflating: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.avi  \n",
            "  inflating: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.avi  \n",
            "  inflating: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.avi  \n",
            "  inflating: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.avi  \n",
            "  inflating: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.avi  \n",
            "  inflating: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.avi  \n",
            "  inflating: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.avi  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RvsXPF5Y9ChI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_features = []"
      ],
      "metadata": {
        "id": "ajbUG-T8sFrq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory containing video and audio files\n",
        "directory = \"session1\"\n",
        "\n",
        "# Initialize an empty dictionary to store video-audio pairs\n",
        "video_audio_mapping = {}\n",
        "\n",
        "# Iterate through the directory and its subdirectories\n",
        "for root, dirs, files in os.walk(directory):\n",
        "    for file in files:\n",
        "        if file.endswith(\".avi\"):\n",
        "            video_path = os.path.join(root, file)\n",
        "            # Replace .avi with .wav to get corresponding audio path\n",
        "            audio_path = os.path.join(root, file[:-4] + \".wav\")\n",
        "            # Check if corresponding audio file exists\n",
        "            if os.path.exists(audio_path):\n",
        "                video_audio_mapping[video_path] = audio_path\n",
        "\n",
        "# Print the video-audio mapping\n",
        "for video_path, audio_path in video_audio_mapping.items():\n",
        "    print(f\"Video: {video_path}, Audio: {audio_path}\")"
      ],
      "metadata": {
        "id": "IPROVaNy5cxs",
        "outputId": "481721ff-b43b-48d5-b4ef-e7cfe7af9399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav\n",
            "Video: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.avi, Audio: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav\n",
            "Video: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.avi, Audio: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav\n",
            "Video: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.avi, Audio: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav\n",
            "Video: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.avi, Audio: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav\n",
            "Video: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.avi, Audio: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav\n",
            "Video: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.avi, Audio: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav\n",
            "Video: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.avi, Audio: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav\n",
            "Video: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.avi, Audio: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav\n",
            "Video: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.avi, Audio: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav\n",
            "Video: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.avi, Audio: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav\n",
            "Video: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.avi, Audio: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav\n",
            "Video: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.avi, Audio: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav\n",
            "Video: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.avi, Audio: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav\n",
            "Video: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.avi, Audio: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav\n",
            "Video: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.avi, Audio: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav\n",
            "Video: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.avi, Audio: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav\n",
            "Video: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.avi, Audio: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav\n",
            "Video: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.avi, Audio: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav\n",
            "Video: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.avi, Audio: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav\n",
            "Video: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.avi, Audio: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav\n",
            "Video: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.avi, Audio: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav\n",
            "Video: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.avi, Audio: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav\n",
            "Video: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.avi, Audio: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav\n",
            "Video: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.avi, Audio: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav\n",
            "Video: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.avi, Audio: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav\n",
            "Video: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.avi, Audio: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav\n",
            "Video: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.avi, Audio: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav\n",
            "Video: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.avi, Audio: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav\n",
            "Video: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.avi, Audio: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav\n",
            "Video: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.avi, Audio: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav\n",
            "Video: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.avi, Audio: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav\n",
            "Video: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.avi, Audio: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav\n",
            "Video: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.avi, Audio: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav\n",
            "Video: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.avi, Audio: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav\n",
            "Video: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.avi, Audio: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav\n",
            "Video: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.avi, Audio: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav\n",
            "Video: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.avi, Audio: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav\n",
            "Video: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.avi, Audio: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav\n",
            "Video: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.avi, Audio: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav\n",
            "Video: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.avi, Audio: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav\n",
            "Video: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.avi, Audio: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav\n",
            "Video: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.avi, Audio: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav\n",
            "Video: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.avi, Audio: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav\n",
            "Video: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.avi, Audio: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav\n",
            "Video: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.avi, Audio: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav\n",
            "Video: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.avi, Audio: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav\n",
            "Video: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.avi, Audio: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav\n",
            "Video: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.avi, Audio: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav\n",
            "Video: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.avi, Audio: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav\n",
            "Video: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.avi, Audio: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav\n",
            "Video: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.avi, Audio: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav\n",
            "Video: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.avi, Audio: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav\n",
            "Video: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.avi, Audio: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav\n",
            "Video: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.avi, Audio: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav\n",
            "Video: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.avi, Audio: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav\n",
            "Video: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.avi, Audio: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav\n",
            "Video: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.avi, Audio: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav\n",
            "Video: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.avi, Audio: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav\n",
            "Video: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.avi, Audio: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav\n",
            "Video: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.avi, Audio: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav\n",
            "Video: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.avi, Audio: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav\n",
            "Video: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.avi, Audio: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav\n",
            "Video: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.avi, Audio: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav\n",
            "Video: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.avi, Audio: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav\n",
            "Video: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.avi, Audio: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav\n",
            "Video: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.avi, Audio: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav\n",
            "Video: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.avi, Audio: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav\n",
            "Video: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.avi, Audio: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav\n",
            "Video: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.avi, Audio: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav\n",
            "Video: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.avi, Audio: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav\n",
            "Video: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.avi, Audio: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav\n",
            "Video: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.avi, Audio: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav\n",
            "Video: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.avi, Audio: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav\n",
            "Video: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.avi, Audio: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav\n",
            "Video: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.avi, Audio: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav\n",
            "Video: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.avi, Audio: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav\n",
            "Video: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.avi, Audio: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav\n",
            "Video: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.avi, Audio: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav\n",
            "Video: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.avi, Audio: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav\n",
            "Video: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.avi, Audio: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav\n",
            "Video: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.avi, Audio: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav\n",
            "Video: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.avi, Audio: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav\n",
            "Video: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.avi, Audio: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav\n",
            "Video: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.avi, Audio: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav\n",
            "Video: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.avi, Audio: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav\n",
            "Video: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.avi, Audio: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav\n",
            "Video: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.avi, Audio: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav\n",
            "Video: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.avi, Audio: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav\n",
            "Video: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.avi, Audio: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav\n",
            "Video: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.avi, Audio: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav\n",
            "Video: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.avi, Audio: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav\n",
            "Video: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.avi, Audio: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav\n",
            "Video: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.avi, Audio: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav\n",
            "Video: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.avi, Audio: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav\n",
            "Video: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.avi, Audio: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav\n",
            "Video: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.avi, Audio: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav\n",
            "Video: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.avi, Audio: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav\n",
            "Video: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.avi, Audio: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav\n",
            "Video: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.avi, Audio: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav\n",
            "Video: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.avi, Audio: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav\n",
            "Video: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.avi, Audio: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav\n",
            "Video: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.avi, Audio: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav\n",
            "Video: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.avi, Audio: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav\n",
            "Video: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.avi, Audio: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav\n",
            "Video: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.avi, Audio: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav\n",
            "Video: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.avi, Audio: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav\n",
            "Video: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.avi, Audio: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav\n",
            "Video: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.avi, Audio: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav\n",
            "Video: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.avi, Audio: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav\n",
            "Video: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.avi, Audio: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav\n",
            "Video: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.avi, Audio: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav\n",
            "Video: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.avi, Audio: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav\n",
            "Video: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.avi, Audio: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav\n",
            "Video: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.avi, Audio: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav\n",
            "Video: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.avi, Audio: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav\n",
            "Video: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.avi, Audio: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav\n",
            "Video: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.avi, Audio: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav\n",
            "Video: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.avi, Audio: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav\n",
            "Video: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.avi, Audio: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav\n",
            "Video: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.avi, Audio: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav\n",
            "Video: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.avi, Audio: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav\n",
            "Video: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.avi, Audio: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav\n",
            "Video: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.avi, Audio: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav\n",
            "Video: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.avi, Audio: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav\n",
            "Video: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.avi, Audio: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav\n",
            "Video: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.avi, Audio: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav\n",
            "Video: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.avi, Audio: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav\n",
            "Video: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.avi, Audio: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav\n",
            "Video: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.avi, Audio: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav\n",
            "Video: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.avi, Audio: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav\n",
            "Video: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.avi, Audio: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav\n",
            "Video: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.avi, Audio: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav\n",
            "Video: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.avi, Audio: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav\n",
            "Video: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.avi, Audio: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav\n",
            "Video: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.avi, Audio: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav\n",
            "Video: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.avi, Audio: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav\n",
            "Video: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.avi, Audio: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.wav\n",
            "Video: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.avi, Audio: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.wav\n",
            "Video: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.avi, Audio: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.wav\n",
            "Video: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.avi, Audio: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.wav\n",
            "Video: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.avi, Audio: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.wav\n",
            "Video: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.avi, Audio: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.wav\n",
            "Video: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.avi, Audio: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.wav\n",
            "Video: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.avi, Audio: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.wav\n",
            "Video: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.avi, Audio: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.wav\n",
            "Video: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.avi, Audio: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.wav\n",
            "Video: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.avi, Audio: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.wav\n",
            "Video: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.avi, Audio: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.wav\n",
            "Video: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.avi, Audio: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.wav\n",
            "Video: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.avi, Audio: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.wav\n",
            "Video: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.avi, Audio: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.wav\n",
            "Video: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.avi, Audio: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.wav\n",
            "Video: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.avi, Audio: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.wav\n",
            "Video: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.avi, Audio: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.wav\n",
            "Video: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.avi, Audio: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.wav\n",
            "Video: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.avi, Audio: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.wav\n",
            "Video: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.avi, Audio: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.wav\n",
            "Video: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.avi, Audio: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.wav\n",
            "Video: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.avi, Audio: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.wav\n",
            "Video: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.avi, Audio: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.wav\n",
            "Video: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.avi, Audio: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.wav\n",
            "Video: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.avi, Audio: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.wav\n",
            "Video: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.avi, Audio: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.wav\n",
            "Video: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.avi, Audio: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.wav\n",
            "Video: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.avi, Audio: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.wav\n",
            "Video: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.avi, Audio: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.wav\n",
            "Video: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.avi, Audio: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.wav\n",
            "Video: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.avi, Audio: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.wav\n",
            "Video: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.avi, Audio: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.wav\n",
            "Video: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.avi, Audio: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.wav\n",
            "Video: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.avi, Audio: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.wav\n",
            "Video: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.avi, Audio: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.wav\n",
            "Video: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.avi, Audio: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.wav\n",
            "Video: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.avi, Audio: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.wav\n",
            "Video: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.avi, Audio: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.wav\n",
            "Video: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.avi, Audio: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.wav\n",
            "Video: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.avi, Audio: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.wav\n",
            "Video: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.avi, Audio: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.wav\n",
            "Video: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.avi, Audio: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.wav\n",
            "Video: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.avi, Audio: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.wav\n",
            "Video: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.avi, Audio: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.wav\n",
            "Video: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.avi, Audio: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.wav\n",
            "Video: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.avi, Audio: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.wav\n",
            "Video: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.avi, Audio: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.wav\n",
            "Video: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.avi, Audio: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.wav\n",
            "Video: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.avi, Audio: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.wav\n",
            "Video: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.avi, Audio: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.wav\n",
            "Video: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.avi, Audio: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.wav\n",
            "Video: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.avi, Audio: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.wav\n",
            "Video: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.avi, Audio: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.wav\n",
            "Video: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.avi, Audio: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.wav\n",
            "Video: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.avi, Audio: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.wav\n",
            "Video: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.avi, Audio: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.wav\n",
            "Video: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.avi, Audio: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.wav\n",
            "Video: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.avi, Audio: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.wav\n",
            "Video: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.avi, Audio: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.wav\n",
            "Video: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.avi, Audio: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.wav\n",
            "Video: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.avi, Audio: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.wav\n",
            "Video: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.avi, Audio: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.wav\n",
            "Video: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.avi, Audio: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.wav\n",
            "Video: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.avi, Audio: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.wav\n",
            "Video: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.avi, Audio: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.wav\n",
            "Video: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.avi, Audio: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.wav\n",
            "Video: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.avi, Audio: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.wav\n",
            "Video: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.avi, Audio: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.wav\n",
            "Video: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.avi, Audio: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.wav\n",
            "Video: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.avi, Audio: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.wav\n",
            "Video: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.avi, Audio: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.wav\n",
            "Video: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.avi, Audio: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.wav\n",
            "Video: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.avi, Audio: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.wav\n",
            "Video: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.avi, Audio: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.wav\n",
            "Video: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.avi, Audio: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.wav\n",
            "Video: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.avi, Audio: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.wav\n",
            "Video: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.avi, Audio: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.wav\n",
            "Video: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.avi, Audio: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.wav\n",
            "Video: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.avi, Audio: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.wav\n",
            "Video: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.avi, Audio: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.wav\n",
            "Video: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.avi, Audio: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.wav\n",
            "Video: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.avi, Audio: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.wav\n",
            "Video: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.avi, Audio: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.wav\n",
            "Video: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.avi, Audio: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.wav\n",
            "Video: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.avi, Audio: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.wav\n",
            "Video: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.avi, Audio: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.wav\n",
            "Video: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.avi, Audio: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.wav\n",
            "Video: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.avi, Audio: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.wav\n",
            "Video: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.avi, Audio: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.wav\n",
            "Video: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.avi, Audio: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.wav\n",
            "Video: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.avi, Audio: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.wav\n",
            "Video: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.avi, Audio: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.wav\n",
            "Video: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.avi, Audio: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.wav\n",
            "Video: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.avi, Audio: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.wav\n",
            "Video: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.avi, Audio: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.wav\n",
            "Video: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.avi, Audio: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.wav\n",
            "Video: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.avi, Audio: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.wav\n",
            "Video: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.avi, Audio: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.wav\n",
            "Video: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.avi, Audio: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.wav\n",
            "Video: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.avi, Audio: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.wav\n",
            "Video: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.avi, Audio: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.wav\n",
            "Video: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.avi, Audio: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.wav\n",
            "Video: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.avi, Audio: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.wav\n",
            "Video: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.avi, Audio: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.wav\n",
            "Video: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.avi, Audio: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.wav\n",
            "Video: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.avi, Audio: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.wav\n",
            "Video: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.avi, Audio: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.wav\n",
            "Video: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.avi, Audio: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.wav\n",
            "Video: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.avi, Audio: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.wav\n",
            "Video: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.avi, Audio: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.wav\n",
            "Video: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.avi, Audio: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.wav\n",
            "Video: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.avi, Audio: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.wav\n",
            "Video: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.avi, Audio: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.wav\n",
            "Video: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.avi, Audio: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.wav\n",
            "Video: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.avi, Audio: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.wav\n",
            "Video: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.avi, Audio: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.wav\n",
            "Video: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.avi, Audio: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.wav\n",
            "Video: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.avi, Audio: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.wav\n",
            "Video: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.avi, Audio: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.wav\n",
            "Video: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.avi, Audio: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.wav\n",
            "Video: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.avi, Audio: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.wav\n",
            "Video: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.avi, Audio: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.wav\n",
            "Video: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.avi, Audio: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.wav\n",
            "Video: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.avi, Audio: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.wav\n",
            "Video: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.avi, Audio: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.wav\n",
            "Video: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.avi, Audio: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.wav\n",
            "Video: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.avi, Audio: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.wav\n",
            "Video: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.avi, Audio: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.wav\n",
            "Video: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.avi, Audio: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.wav\n",
            "Video: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.avi, Audio: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.wav\n",
            "Video: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.avi, Audio: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.wav\n",
            "Video: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.avi, Audio: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.wav\n",
            "Video: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.avi, Audio: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.wav\n",
            "Video: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.avi, Audio: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.wav\n",
            "Video: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.avi, Audio: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def resize_video(video_path, output_path, width=320, height=240):\n",
        "    # Open the video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        return\n",
        "\n",
        "    # Get original video properties\n",
        "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change this to match your video codec\n",
        "\n",
        "    # Create a VideoWriter object to write the resized video\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        # Resize the frame to the specified dimensions\n",
        "        resized_frame = cv2.resize(frame, (width, height))\n",
        "        out.write(resized_frame)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "ap1oGYNyBwGh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ckpt_path = \"/content/data/finetune-model.pt\"\n",
        "user_dir = \"/content/av_hubert/avhubert\"\n",
        "for video_path, audio_path in video_audio_mapping.items():\n",
        "  label = video_path.split(\"/\")[-3][-1]  # Extract the last character from the third last part of the path\n",
        "  if label == 'A':\n",
        "    label = 0\n",
        "  elif label == 'H':\n",
        "    label = 1\n",
        "  elif label == 'S':\n",
        "    label = 2\n",
        "  else:\n",
        "    label = 3\n",
        "  # Resize the video\n",
        "  output_path = \"resized_video.avi\"\n",
        "  resize_video(video_path, output_path, width=320, height=240)\n",
        "\n",
        "  # Extract visual features\n",
        "  layer_features, feature = extract_visual_feature(output_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "  # Create a tensor for the label\n",
        "  label_tensor = torch.tensor([label] * feature.size(0), dtype=torch.float).unsqueeze(1)  # Repeat the label for each row in feature\n",
        "\n",
        "  # Concatenate the label tensor with the feature tensor along the second dimension (columns)\n",
        "  label_tensor = label_tensor.to(feature.device)\n",
        "  feature_with_label = torch.cat((feature, label_tensor), dim=1)\n",
        "  final_features.append(feature_with_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SDLYlMN5gm5E",
        "outputId": "8bc90bb5-5ed1-42d0-e771-7771af148266"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (48, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 48, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav: shape torch.Size([1, 104, 48])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([48, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (47, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 47, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav: shape torch.Size([1, 104, 47])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([47, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (131, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 131, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav: shape torch.Size([1, 104, 131])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([131, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (46, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav: shape (39, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 46, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav: shape torch.Size([1, 104, 46])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([46, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (139, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav: shape (116, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 139, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav: shape torch.Size([1, 104, 139])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([139, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (159, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 159, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav: shape torch.Size([1, 104, 159])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([159, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (66, 240, 320)\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav: shape (56, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 66, 240, 320])\n",
            "Load audio session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav: shape torch.Size([1, 104, 66])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([66, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (123, 240, 320)\n",
            "Load audio session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav: shape (103, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 123, 240, 320])\n",
            "Load audio session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (146, 240, 320)\n",
            "Load audio session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav: shape (122, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 146, 240, 320])\n",
            "Load audio session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav: shape torch.Size([1, 104, 146])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([146, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (56, 240, 320)\n",
            "Load audio session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav: shape (47, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 56, 240, 320])\n",
            "Load audio session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav: shape torch.Size([1, 104, 56])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([56, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (42, 240, 320)\n",
            "Load audio session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav: shape (36, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 42, 240, 320])\n",
            "Load audio session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav: shape torch.Size([1, 104, 42])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([42, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav: shape (127, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (148, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 148, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav: shape torch.Size([1, 104, 148])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([148, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (92, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav: shape (77, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 92, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (148, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 148, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav: shape torch.Size([1, 104, 148])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([148, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (242, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav: shape (203, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 242, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav: shape torch.Size([1, 104, 242])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([242, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (230, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav: shape (192, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 230, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav: shape torch.Size([1, 104, 230])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([230, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (110, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav: shape (92, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 110, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (223, 240, 320)\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav: shape (186, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 223, 240, 320])\n",
            "Load audio session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav: shape torch.Size([1, 104, 223])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([223, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (43, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav: shape (36, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 43, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav: shape torch.Size([1, 104, 43])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([43, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (89, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav: shape (74, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 89, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (140, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav: shape (117, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 140, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav: shape torch.Size([1, 104, 140])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([140, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (159, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 159, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav: shape torch.Size([1, 104, 159])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([159, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (130, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 130, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav: shape torch.Size([1, 104, 130])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([130, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (82, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav: shape (69, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 82, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (76, 240, 320)\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav: shape (64, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 76, 240, 320])\n",
            "Load audio session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav: shape torch.Size([1, 104, 76])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([76, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (225, 240, 320)\n",
            "Load audio session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav: shape (188, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 225, 240, 320])\n",
            "Load audio session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav: shape torch.Size([1, 104, 225])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([225, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (172, 240, 320)\n",
            "Load audio session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav: shape (144, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 172, 240, 320])\n",
            "Load audio session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav: shape torch.Size([1, 104, 172])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([172, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (124, 240, 320)\n",
            "Load audio session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav: shape (104, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 124, 240, 320])\n",
            "Load audio session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav: shape torch.Size([1, 104, 124])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([124, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (186, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav: shape (155, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 186, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav: shape torch.Size([1, 104, 186])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([186, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (247, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav: shape (206, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 247, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav: shape torch.Size([1, 104, 247])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([247, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (117, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav: shape (98, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 117, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (148, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 148, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav: shape torch.Size([1, 104, 148])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([148, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (355, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav: shape (296, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 355, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav: shape torch.Size([1, 104, 355])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([355, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (104, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav: shape (87, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 104, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (143, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav: shape (120, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 143, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav: shape torch.Size([1, 104, 143])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([143, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (134, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 134, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav: shape torch.Size([1, 104, 134])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([134, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (162, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 162, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav: shape torch.Size([1, 104, 162])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([162, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (193, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 193, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav: shape torch.Size([1, 104, 193])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([193, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (193, 240, 320)\n",
            "Load audio session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 193, 240, 320])\n",
            "Load audio session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav: shape torch.Size([1, 104, 193])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([193, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (169, 240, 320)\n",
            "Load audio session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav: shape (141, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 169, 240, 320])\n",
            "Load audio session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav: shape torch.Size([1, 104, 169])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([169, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (114, 240, 320)\n",
            "Load audio session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav: shape (95, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 114, 240, 320])\n",
            "Load audio session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (146, 240, 320)\n",
            "Load audio session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav: shape (123, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 146, 240, 320])\n",
            "Load audio session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav: shape torch.Size([1, 104, 146])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([146, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (116, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav: shape (97, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 116, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (207, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav: shape (173, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 207, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav: shape torch.Size([1, 104, 207])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([207, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (53, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav: shape (45, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 53, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav: shape torch.Size([1, 104, 53])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([53, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (136, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav: shape (114, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 136, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (265, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav: shape (221, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 265, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav: shape torch.Size([1, 104, 265])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([265, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (184, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav: shape (154, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 184, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav: shape torch.Size([1, 104, 184])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([184, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (280, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav: shape (234, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 280, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav: shape torch.Size([1, 104, 280])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([280, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (168, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 168, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav: shape torch.Size([1, 104, 168])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([168, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (70, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 70, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav: shape torch.Size([1, 104, 70])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([70, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (189, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav: shape (158, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 189, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav: shape torch.Size([1, 104, 189])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([189, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (378, 240, 320)\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav: shape (315, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 378, 240, 320])\n",
            "Load audio session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav: shape torch.Size([1, 104, 378])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([378, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (240, 240, 320)\n",
            "Load audio session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav: shape (201, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 240, 240, 320])\n",
            "Load audio session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav: shape torch.Size([1, 104, 240])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([240, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (196, 240, 320)\n",
            "Load audio session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav: shape (164, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 196, 240, 320])\n",
            "Load audio session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav: shape torch.Size([1, 104, 196])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([196, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav: shape (122, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (161, 240, 320)\n",
            "Load audio session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav: shape (135, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 161, 240, 320])\n",
            "Load audio session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav: shape torch.Size([1, 104, 161])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([161, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (115, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav: shape (96, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 115, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (70, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 70, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav: shape torch.Size([1, 104, 70])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([70, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (132, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav: shape (111, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 132, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav: shape torch.Size([1, 104, 132])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([132, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (45, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav: shape (38, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 45, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav: shape torch.Size([1, 104, 45])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([45, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (36, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav: shape (30, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 36, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav: shape torch.Size([1, 104, 36])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([36, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (179, 240, 320)\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav: shape (150, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 179, 240, 320])\n",
            "Load audio session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav: shape torch.Size([1, 104, 179])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([179, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (224, 240, 320)\n",
            "Load audio session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav: shape (187, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 224, 240, 320])\n",
            "Load audio session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav: shape torch.Size([1, 104, 224])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([224, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (176, 240, 320)\n",
            "Load audio session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav: shape (147, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 176, 240, 320])\n",
            "Load audio session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav: shape torch.Size([1, 104, 176])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([176, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (98, 240, 320)\n",
            "Load audio session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 98, 240, 320])\n",
            "Load audio session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (71, 240, 320)\n",
            "Load audio session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 71, 240, 320])\n",
            "Load audio session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav: shape torch.Size([1, 104, 71])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([71, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (135, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 135, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav: shape torch.Size([1, 104, 135])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([135, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (117, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav: shape (98, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 117, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (124, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav: shape (104, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 124, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav: shape torch.Size([1, 104, 124])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([124, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (127, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 127, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav: shape torch.Size([1, 104, 127])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([127, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (335, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav: shape (280, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 335, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav: shape torch.Size([1, 104, 335])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([335, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (155, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav: shape (130, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 155, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (82, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav: shape (69, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 82, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (220, 240, 320)\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav: shape (184, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 220, 240, 320])\n",
            "Load audio session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav: shape torch.Size([1, 104, 220])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([220, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (137, 240, 320)\n",
            "Load audio session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav: shape (115, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 137, 240, 320])\n",
            "Load audio session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (94, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav: shape (79, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 94, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav: shape torch.Size([1, 104, 94])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([94, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav: shape (137, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (239, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav: shape (200, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 239, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav: shape torch.Size([1, 104, 239])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([239, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (91, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 91, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav: shape torch.Size([1, 104, 91])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([91, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (139, 240, 320)\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav: shape (117, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 139, 240, 320])\n",
            "Load audio session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav: shape torch.Size([1, 104, 139])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([139, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (183, 240, 320)\n",
            "Load audio session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 183, 240, 320])\n",
            "Load audio session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav: shape torch.Size([1, 104, 183])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([183, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (95, 240, 320)\n",
            "Load audio session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav: shape (80, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 95, 240, 320])\n",
            "Load audio session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (57, 240, 320)\n",
            "Load audio session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav: shape (48, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 57, 240, 320])\n",
            "Load audio session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav: shape torch.Size([1, 104, 57])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([57, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (144, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav: shape (121, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 144, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav: shape torch.Size([1, 104, 144])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([144, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (71, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav: shape (60, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 71, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav: shape torch.Size([1, 104, 71])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([71, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (32, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav: shape (27, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 32, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav: shape torch.Size([1, 104, 32])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([32, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (91, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 91, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav: shape torch.Size([1, 104, 91])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([91, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (355, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav: shape (297, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 355, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav: shape torch.Size([1, 104, 355])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([355, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav: shape (66, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (109, 240, 320)\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav: shape (91, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 109, 240, 320])\n",
            "Load audio session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (132, 240, 320)\n",
            "Load audio session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav: shape (111, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 132, 240, 320])\n",
            "Load audio session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav: shape torch.Size([1, 104, 132])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([132, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (171, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav: shape (144, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 171, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav: shape torch.Size([1, 104, 171])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([171, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (344, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav: shape (287, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 344, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav: shape torch.Size([1, 104, 344])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([344, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (109, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav: shape (92, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 109, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (106, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 106, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (141, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav: shape (118, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 141, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav: shape torch.Size([1, 104, 141])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([141, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (90, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 90, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav: shape (121, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav: shape (125, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (342, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav: shape (286, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 342, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav: shape torch.Size([1, 104, 342])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([342, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav: shape (126, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (288, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav: shape (241, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 288, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav: shape torch.Size([1, 104, 288])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([288, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (74, 240, 320)\n",
            "Load audio session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 74, 240, 320])\n",
            "Load audio session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav: shape torch.Size([1, 104, 74])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([74, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (120, 240, 320)\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 120, 240, 320])\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav: shape torch.Size([1, 104, 120])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([120, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (124, 240, 320)\n",
            "Load audio session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav: shape (104, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 124, 240, 320])\n",
            "Load audio session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav: shape torch.Size([1, 104, 124])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([124, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (226, 240, 320)\n",
            "Load audio session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav: shape (189, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 226, 240, 320])\n",
            "Load audio session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav: shape torch.Size([1, 104, 226])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([226, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (93, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav: shape (78, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 93, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (87, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav: shape (73, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 87, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (37, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav: shape (32, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 37, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav: shape torch.Size([1, 104, 37])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([37, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (57, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav: shape (48, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 57, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav: shape torch.Size([1, 104, 57])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([57, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (97, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav: shape (82, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 97, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (67, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav: shape (56, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 67, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav: shape torch.Size([1, 104, 67])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([67, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav: shape (58, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (120, 240, 320)\n",
            "Load audio session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 120, 240, 320])\n",
            "Load audio session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav: shape torch.Size([1, 104, 120])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([120, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (41, 240, 320)\n",
            "Load audio session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav: shape (35, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 41, 240, 320])\n",
            "Load audio session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav: shape torch.Size([1, 104, 41])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([41, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (167, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 167, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav: shape torch.Size([1, 104, 167])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([167, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (45, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav: shape (38, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 45, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav: shape torch.Size([1, 104, 45])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([45, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (193, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 193, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav: shape torch.Size([1, 104, 193])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([193, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (64, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (196, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav: shape (164, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 196, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav: shape torch.Size([1, 104, 196])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([196, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (111, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav: shape (93, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 111, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav: shape torch.Size([1, 104, 111])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([111, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (47, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 47, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav: shape torch.Size([1, 104, 47])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([47, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (173, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav: shape (145, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 173, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav: shape torch.Size([1, 104, 173])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([173, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (58, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav: shape (49, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 58, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav: shape torch.Size([1, 104, 58])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([58, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (162, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 162, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav: shape torch.Size([1, 104, 162])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([162, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (41, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav: shape (35, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 41, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav: shape torch.Size([1, 104, 41])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([41, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav: shape (126, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav: shape (66, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (342, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav: shape (286, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 342, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav: shape torch.Size([1, 104, 342])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([342, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (91, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 91, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav: shape torch.Size([1, 104, 91])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([91, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (39, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav: shape (33, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 39, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav: shape torch.Size([1, 104, 39])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([39, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (177, 240, 320)\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav: shape (148, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 177, 240, 320])\n",
            "Load audio session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav: shape torch.Size([1, 104, 177])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([177, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (90, 240, 320)\n",
            "Load audio session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 90, 240, 320])\n",
            "Load audio session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (180, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav: shape (151, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 180, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav: shape torch.Size([1, 104, 180])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([180, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (164, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 164, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav: shape torch.Size([1, 104, 164])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([164, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (220, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav: shape (184, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 220, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav: shape torch.Size([1, 104, 220])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([220, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (135, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 135, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav: shape torch.Size([1, 104, 135])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([135, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (172, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav: shape (144, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 172, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav: shape torch.Size([1, 104, 172])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([172, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (228, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav: shape (190, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 228, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav: shape torch.Size([1, 104, 228])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([228, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (142, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav: shape (119, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 142, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav: shape torch.Size([1, 104, 142])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([142, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (39, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav: shape (33, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 39, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav: shape torch.Size([1, 104, 39])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([39, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (140, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav: shape (118, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 140, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav: shape torch.Size([1, 104, 140])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([140, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (48, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 48, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav: shape torch.Size([1, 104, 48])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([48, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (111, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 111, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav: shape torch.Size([1, 104, 111])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([111, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (188, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav: shape (158, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 188, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav: shape torch.Size([1, 104, 188])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([188, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (94, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav: shape (79, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 94, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav: shape torch.Size([1, 104, 94])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([94, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (236, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav: shape (198, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 236, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav: shape torch.Size([1, 104, 236])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([236, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (64, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (78, 240, 320)\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav: shape (65, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 78, 240, 320])\n",
            "Load audio session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav: shape torch.Size([1, 104, 78])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([78, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (190, 240, 320)\n",
            "Load audio session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav: shape (159, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 190, 240, 320])\n",
            "Load audio session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav: shape torch.Size([1, 104, 190])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([190, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (78, 240, 320)\n",
            "Load audio session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav: shape (66, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 78, 240, 320])\n",
            "Load audio session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav: shape torch.Size([1, 104, 78])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([78, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (594, 240, 320)\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav: shape (496, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 594, 240, 320])\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav: shape torch.Size([1, 104, 594])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([594, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (241, 240, 320)\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav: shape (201, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 241, 240, 320])\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav: shape torch.Size([1, 104, 241])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([241, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav: shape (121, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav: shape (90, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (191, 240, 320)\n",
            "Load audio session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav: shape (160, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 191, 240, 320])\n",
            "Load audio session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav: shape torch.Size([1, 104, 191])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([191, 768])\n",
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav: shape (61, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n",
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (113, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav: shape (95, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 113, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav: shape torch.Size([1, 104, 113])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([113, 768])\n",
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav: shape (47, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (136, 240, 320)\n",
            "Load audio session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav: shape (114, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 136, 240, 320])\n",
            "Load audio session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (34, 240, 320)\n",
            "Load audio session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav: shape (29, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 34, 240, 320])\n",
            "Load audio session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav: shape torch.Size([1, 104, 34])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([34, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (45, 240, 320)\n",
            "Load audio session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav: shape (38, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 45, 240, 320])\n",
            "Load audio session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav: shape torch.Size([1, 104, 45])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([45, 768])\n",
            "Load video resized_video.avi: shape (235, 240, 320)\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav: shape (196, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 235, 240, 320])\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav: shape torch.Size([1, 104, 235])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([235, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (51, 240, 320)\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav: shape (43, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 51, 240, 320])\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav: shape torch.Size([1, 104, 51])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([51, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (206, 240, 320)\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav: shape (173, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 206, 240, 320])\n",
            "Load audio session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav: shape torch.Size([1, 104, 206])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([206, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (89, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav: shape (74, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 89, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (49, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav: shape (41, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 49, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav: shape torch.Size([1, 104, 49])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([49, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (84, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 84, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav: shape torch.Size([1, 104, 84])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([84, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (127, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 127, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav: shape torch.Size([1, 104, 127])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([127, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (64, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (75, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav: shape (63, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 75, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav: shape torch.Size([1, 104, 75])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([75, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (93, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav: shape (78, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 93, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (23, 240, 320)\n",
            "Load audio session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav: shape (20, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 23, 240, 320])\n",
            "Load audio session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav: shape torch.Size([1, 104, 23])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([23, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (30, 240, 320)\n",
            "Load audio session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav: shape (26, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 30, 240, 320])\n",
            "Load audio session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav: shape torch.Size([1, 104, 30])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([30, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (111, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav: shape (93, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 111, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav: shape torch.Size([1, 104, 111])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([111, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav: shape (132, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (98, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 98, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (66, 240, 320)\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 66, 240, 320])\n",
            "Load audio session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav: shape torch.Size([1, 104, 66])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([66, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (36, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav: shape (30, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 36, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav: shape torch.Size([1, 104, 36])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([36, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (104, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav: shape (87, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 104, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (147, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav: shape (123, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 147, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav: shape torch.Size([1, 104, 147])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([147, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (173, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav: shape (145, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 173, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav: shape torch.Size([1, 104, 173])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([173, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (76, 240, 320)\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav: shape (64, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 76, 240, 320])\n",
            "Load audio session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav: shape torch.Size([1, 104, 76])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([76, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (262, 240, 320)\n",
            "Load audio session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav: shape (219, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 262, 240, 320])\n",
            "Load audio session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav: shape torch.Size([1, 104, 262])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([262, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (92, 240, 320)\n",
            "Load audio session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav: shape (77, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 92, 240, 320])\n",
            "Load audio session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (209, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav: shape (175, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 209, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav: shape torch.Size([1, 104, 209])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([209, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (157, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav: shape (132, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 157, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav: shape torch.Size([1, 104, 157])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([157, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (86, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav: shape (72, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 86, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (88, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav: shape (74, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 88, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (144, 240, 320)\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav: shape (120, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 144, 240, 320])\n",
            "Load audio session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav: shape torch.Size([1, 104, 144])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([144, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (151, 240, 320)\n",
            "Load audio session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav: shape (127, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 151, 240, 320])\n",
            "Load audio session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav: shape torch.Size([1, 104, 151])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([151, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (123, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav: shape (103, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 123, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav: shape (91, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (114, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav: shape (96, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 114, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav: shape (72, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (138, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav: shape (116, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 138, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (127, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 127, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav: shape torch.Size([1, 104, 127])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([127, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (187, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav: shape (157, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 187, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav: shape torch.Size([1, 104, 187])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([187, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav: shape (47, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (171, 240, 320)\n",
            "Load audio session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav: shape (143, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 171, 240, 320])\n",
            "Load audio session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav: shape torch.Size([1, 104, 171])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([171, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (86, 240, 320)\n",
            "Load audio session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav: shape (72, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 86, 240, 320])\n",
            "Load audio session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (175, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav: shape (146, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 175, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav: shape torch.Size([1, 104, 175])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([175, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (117, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav: shape (98, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 117, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (423, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav: shape (354, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 423, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav: shape torch.Size([1, 104, 423])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([423, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (268, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav: shape (224, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 268, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav: shape torch.Size([1, 104, 268])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([268, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (166, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav: shape (139, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 166, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav: shape torch.Size([1, 104, 166])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([166, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (147, 240, 320)\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 147, 240, 320])\n",
            "Load audio session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav: shape torch.Size([1, 104, 147])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([147, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (218, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav: shape (183, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 218, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav: shape torch.Size([1, 104, 218])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([218, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (180, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav: shape (151, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 180, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav: shape torch.Size([1, 104, 180])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([180, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav: shape (152, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (134, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 134, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav: shape torch.Size([1, 104, 134])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([134, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (251, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav: shape (210, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 251, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav: shape torch.Size([1, 104, 251])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([251, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (162, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 162, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav: shape torch.Size([1, 104, 162])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([162, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (168, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav: shape (141, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 168, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav: shape torch.Size([1, 104, 168])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([168, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (111, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav: shape (93, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 111, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav: shape torch.Size([1, 104, 111])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([111, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (151, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav: shape (126, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 151, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav: shape torch.Size([1, 104, 151])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([151, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (77, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav: shape (65, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 77, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav: shape torch.Size([1, 104, 77])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([77, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (209, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav: shape (175, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 209, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav: shape torch.Size([1, 104, 209])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([209, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (198, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav: shape (165, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 198, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav: shape torch.Size([1, 104, 198])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([198, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (132, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav: shape (110, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 132, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav: shape torch.Size([1, 104, 132])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([132, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (125, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 125, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (259, 240, 320)\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav: shape (217, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 259, 240, 320])\n",
            "Load audio session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav: shape torch.Size([1, 104, 259])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([259, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (40, 240, 320)\n",
            "Load audio session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 40, 240, 320])\n",
            "Load audio session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav: shape torch.Size([1, 104, 40])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([40, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (311, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav: shape (260, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 311, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav: shape torch.Size([1, 104, 311])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([311, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (247, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav: shape (207, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 247, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav: shape torch.Size([1, 104, 247])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([247, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav: shape (52, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (530, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav: shape (442, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 530, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav: shape torch.Size([1, 104, 530])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([530, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (239, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav: shape (200, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 239, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav: shape torch.Size([1, 104, 239])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([239, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (167, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 167, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav: shape torch.Size([1, 104, 167])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([167, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav: shape (61, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (332, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav: shape (278, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 332, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav: shape torch.Size([1, 104, 332])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([332, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (294, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav: shape (245, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 294, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav: shape torch.Size([1, 104, 294])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([294, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (130, 240, 320)\n",
            "Load audio session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 130, 240, 320])\n",
            "Load audio session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav: shape torch.Size([1, 104, 130])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([130, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav: shape (90, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (104, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav: shape (87, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 104, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (191, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav: shape (160, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 191, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav: shape torch.Size([1, 104, 191])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([191, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (48, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 48, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav: shape torch.Size([1, 104, 48])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([48, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (117, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav: shape (98, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 117, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (95, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav: shape (80, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 95, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (253, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav: shape (212, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 253, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav: shape torch.Size([1, 104, 253])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([253, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (123, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav: shape (103, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 123, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (77, 240, 320)\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav: shape (65, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 77, 240, 320])\n",
            "Load audio session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav: shape torch.Size([1, 104, 77])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([77, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (176, 240, 320)\n",
            "Load audio session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav: shape (147, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 176, 240, 320])\n",
            "Load audio session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav: shape torch.Size([1, 104, 176])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([176, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (243, 240, 320)\n",
            "Load audio session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav: shape (203, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 243, 240, 320])\n",
            "Load audio session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav: shape torch.Size([1, 104, 243])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([243, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (135, 240, 320)\n",
            "Load audio session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 135, 240, 320])\n",
            "Load audio session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav: shape torch.Size([1, 104, 135])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([135, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (487, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav: shape (407, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 487, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav: shape torch.Size([1, 104, 487])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([487, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav: shape (132, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (147, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav: shape (123, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 147, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav: shape torch.Size([1, 104, 147])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([147, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (350, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav: shape (292, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 350, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav: shape torch.Size([1, 104, 350])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([350, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (194, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 194, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav: shape torch.Size([1, 104, 194])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([194, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (262, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav: shape (219, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 262, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav: shape torch.Size([1, 104, 262])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([262, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav: shape (125, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (230, 240, 320)\n",
            "Load audio session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav: shape (193, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 230, 240, 320])\n",
            "Load audio session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav: shape torch.Size([1, 104, 230])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([230, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav: shape (122, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav: shape (45, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (105, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav: shape (88, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 105, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav: shape torch.Size([1, 104, 105])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([105, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (93, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav: shape (78, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 93, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav: shape (129, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav: shape (45, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (125, 240, 320)\n",
            "Load audio session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 125, 240, 320])\n",
            "Load audio session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (170, 240, 320)\n",
            "Load audio session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav: shape (143, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 170, 240, 320])\n",
            "Load audio session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav: shape torch.Size([1, 104, 170])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([170, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (63, 240, 320)\n",
            "Load audio session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 63, 240, 320])\n",
            "Load audio session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav: shape torch.Size([1, 104, 63])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([63, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (47, 240, 320)\n",
            "Load audio session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 47, 240, 320])\n",
            "Load audio session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav: shape torch.Size([1, 104, 47])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([47, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (107, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 107, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav: shape torch.Size([1, 104, 107])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([107, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (168, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 168, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav: shape torch.Size([1, 104, 168])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([168, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (197, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav: shape (165, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 197, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav: shape torch.Size([1, 104, 197])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([197, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (84, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 84, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav: shape torch.Size([1, 104, 84])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([84, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (75, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav: shape (63, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 75, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav: shape torch.Size([1, 104, 75])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([75, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (162, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 162, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav: shape torch.Size([1, 104, 162])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([162, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav: shape (127, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (155, 240, 320)\n",
            "Load audio session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav: shape (130, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 155, 240, 320])\n",
            "Load audio session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (136, 240, 320)\n",
            "Load audio session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav: shape (114, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 136, 240, 320])\n",
            "Load audio session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (205, 240, 320)\n",
            "Load audio session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav: shape (172, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 205, 240, 320])\n",
            "Load audio session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav: shape torch.Size([1, 104, 205])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([205, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (155, 240, 320)\n",
            "Load audio session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav: shape (130, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 155, 240, 320])\n",
            "Load audio session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (130, 240, 320)\n",
            "Load audio session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 130, 240, 320])\n",
            "Load audio session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav: shape torch.Size([1, 104, 130])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([130, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (148, 240, 320)\n",
            "Load audio session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 148, 240, 320])\n",
            "Load audio session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav: shape torch.Size([1, 104, 148])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([148, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (212, 240, 320)\n",
            "Load audio session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav: shape (177, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 212, 240, 320])\n",
            "Load audio session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav: shape torch.Size([1, 104, 212])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([212, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (138, 240, 320)\n",
            "Load audio session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav: shape (116, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 138, 240, 320])\n",
            "Load audio session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (260, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav: shape (218, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 260, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav: shape torch.Size([1, 104, 260])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([260, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (51, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav: shape (43, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 51, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav: shape torch.Size([1, 104, 51])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([51, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (76, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav: shape (64, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 76, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav: shape torch.Size([1, 104, 76])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([76, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (116, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav: shape (97, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 116, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (174, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav: shape (146, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 174, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav: shape torch.Size([1, 104, 174])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([174, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (120, 240, 320)\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav: shape (101, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 120, 240, 320])\n",
            "Load audio session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav: shape torch.Size([1, 104, 120])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([120, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (191, 240, 320)\n",
            "Load audio session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav: shape (160, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 191, 240, 320])\n",
            "Load audio session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav: shape torch.Size([1, 104, 191])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([191, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (159, 240, 320)\n",
            "Load audio session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 159, 240, 320])\n",
            "Load audio session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav: shape torch.Size([1, 104, 159])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([159, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (87, 240, 320)\n",
            "Load audio session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav: shape (73, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 87, 240, 320])\n",
            "Load audio session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (493, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav: shape (412, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 493, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav: shape torch.Size([1, 104, 493])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([493, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (129, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 129, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav: shape torch.Size([1, 104, 129])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([129, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (114, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav: shape (96, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 114, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (133, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav: shape (112, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 133, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav: shape torch.Size([1, 104, 133])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([133, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (435, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav: shape (363, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 435, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav: shape torch.Size([1, 104, 435])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([435, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (177, 240, 320)\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav: shape (148, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 177, 240, 320])\n",
            "Load audio session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav: shape torch.Size([1, 104, 177])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([177, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (170, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav: shape (142, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 170, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav: shape torch.Size([1, 104, 170])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([170, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (106, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 106, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (137, 240, 320)\n",
            "Load audio session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav: shape (115, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 137, 240, 320])\n",
            "Load audio session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (110, 240, 320)\n",
            "Load audio session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav: shape (92, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 110, 240, 320])\n",
            "Load audio session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (59, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav: shape (50, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 59, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav: shape torch.Size([1, 104, 59])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([59, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (173, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav: shape (145, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 173, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav: shape torch.Size([1, 104, 173])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([173, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (137, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav: shape (114, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 137, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (107, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav: shape (90, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 107, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav: shape torch.Size([1, 104, 107])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([107, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (227, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav: shape (190, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 227, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav: shape torch.Size([1, 104, 227])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([227, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav: shape (127, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (74, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 74, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav: shape torch.Size([1, 104, 74])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([74, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (233, 240, 320)\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav: shape (195, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 233, 240, 320])\n",
            "Load audio session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav: shape torch.Size([1, 104, 233])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([233, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n",
            "Load video resized_video.avi: shape (89, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav: shape (75, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 89, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (110, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav: shape (93, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 110, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (84, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 84, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav: shape torch.Size([1, 104, 84])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([84, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n",
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (92, 240, 320)\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav: shape (77, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 92, 240, 320])\n",
            "Load audio session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (134, 240, 320)\n",
            "Load audio session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 134, 240, 320])\n",
            "Load audio session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav: shape torch.Size([1, 104, 134])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([134, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (60, 240, 320)\n",
            "Load audio session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav: shape (50, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 60, 240, 320])\n",
            "Load audio session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav: shape torch.Size([1, 104, 60])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([60, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (38, 240, 320)\n",
            "Load audio session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav: shape (39, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 38, 240, 320])\n",
            "Load audio session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav: shape torch.Size([1, 104, 39])\n",
            "Checkpoint: fine-tuned\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Expected size 39 but got size 38 for tensor number 1 in the list.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9e2105f8c542>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# Extract visual features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mlayer_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_visual_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# Create a tensor for the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6693a1088c1b>\u001b[0m in \u001b[0;36mextract_visual_feature\u001b[0;34m(video_path, audio_path, ckpt_path, user_dir, is_finetune_ckpt)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlayer_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_finetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0mlayer_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_finetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/av_hubert/avhubert/hubert.py\u001b[0m in \u001b[0;36mextract_finetune\u001b[0;34m(self, source, padding_mask, mask, ret_conv, output_layer)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodality_fuse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'concat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_video\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodality_fuse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_audio\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeatures_video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 39 but got size 38 for tensor number 1 in the list."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_features"
      ],
      "metadata": {
        "id": "JwmnXEf5w3ub",
        "outputId": "bfb15596-49bb-4038-d3ae-8d3aab0c69b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.0237, -0.1337, -0.0260,  ...,  0.0476,  0.2147,  0.0000],\n",
              "         [ 0.1372, -0.0432, -0.0024,  ...,  0.2401,  0.1341,  0.0000],\n",
              "         [ 0.1313,  0.0069,  0.0210,  ...,  0.3173,  0.0016,  0.0000],\n",
              "         ...,\n",
              "         [-0.1168,  0.1427,  0.2446,  ...,  0.0558, -0.0104,  0.0000],\n",
              "         [-0.2561,  0.1333,  0.3373,  ...,  0.0529, -0.0353,  0.0000],\n",
              "         [-0.2929,  0.1004,  0.3020,  ...,  0.0544, -0.0063,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0354, -0.1537, -0.0573,  ...,  0.0593,  0.2086,  0.0000],\n",
              "         [ 0.1363, -0.1162, -0.0760,  ...,  0.2857,  0.1616,  0.0000],\n",
              "         [ 0.0801, -0.1173, -0.0804,  ...,  0.3853,  0.0899,  0.0000],\n",
              "         ...,\n",
              "         [-0.1873,  0.0221,  0.2003,  ...,  0.1090, -0.0396,  0.0000],\n",
              "         [-0.2609,  0.0400,  0.2025,  ...,  0.0870, -0.0689,  0.0000],\n",
              "         [-0.2753,  0.0167,  0.2380,  ...,  0.0235, -0.0379,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0361, -0.1555, -0.0575,  ...,  0.0632,  0.2039,  0.0000],\n",
              "         [ 0.1258, -0.1223, -0.0707,  ...,  0.2859,  0.1542,  0.0000],\n",
              "         [ 0.0615, -0.1171, -0.0765,  ...,  0.3893,  0.0800,  0.0000],\n",
              "         ...,\n",
              "         [-0.2086,  0.0352,  0.1976,  ...,  0.0907, -0.0613,  0.0000],\n",
              "         [-0.2636,  0.0546,  0.1962,  ...,  0.0774, -0.0791,  0.0000],\n",
              "         [-0.2629,  0.0250,  0.2316,  ...,  0.0215, -0.0427,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0250, -0.1242, -0.0231,  ...,  0.0393,  0.2073,  0.0000],\n",
              "         [ 0.1197, -0.0378,  0.0058,  ...,  0.2303,  0.1220,  0.0000],\n",
              "         [ 0.1140,  0.0201,  0.0285,  ...,  0.3092, -0.0142,  0.0000],\n",
              "         ...,\n",
              "         [-0.0854,  0.1339,  0.2422,  ...,  0.0512,  0.0004,  0.0000],\n",
              "         [-0.2525,  0.1309,  0.3621,  ...,  0.0451, -0.0277,  0.0000],\n",
              "         [-0.3028,  0.0978,  0.3151,  ...,  0.0418, -0.0061,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0249, -0.1241, -0.0246,  ...,  0.0384,  0.2066,  0.0000],\n",
              "         [ 0.1184, -0.0353,  0.0084,  ...,  0.2283,  0.1179,  0.0000],\n",
              "         [ 0.1160,  0.0251,  0.0300,  ...,  0.3035, -0.0184,  0.0000],\n",
              "         ...,\n",
              "         [-0.0725,  0.1360,  0.2371,  ...,  0.0460,  0.0070,  0.0000],\n",
              "         [-0.2477,  0.1296,  0.3639,  ...,  0.0405, -0.0234,  0.0000],\n",
              "         [-0.3015,  0.1007,  0.3144,  ...,  0.0364, -0.0042,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0343, -0.1485, -0.0528,  ...,  0.0635,  0.2066,  0.0000],\n",
              "         [ 0.1357, -0.1099, -0.0633,  ...,  0.2780,  0.1643,  0.0000],\n",
              "         [ 0.0723, -0.1003, -0.0633,  ...,  0.3904,  0.0785,  0.0000],\n",
              "         ...,\n",
              "         [-0.2091,  0.0298,  0.2052,  ...,  0.0818, -0.0496,  0.0000],\n",
              "         [-0.2787,  0.0671,  0.2126,  ...,  0.0758, -0.0745,  0.0000],\n",
              "         [-0.2698,  0.0397,  0.2410,  ...,  0.0246, -0.0409,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1285, -0.0322,  ...,  0.0482,  0.2176,  0.0000],\n",
              "         [ 0.1360, -0.0325, -0.0082,  ...,  0.2332,  0.1302,  0.0000],\n",
              "         [ 0.1355,  0.0295,  0.0142,  ...,  0.3111, -0.0152,  0.0000],\n",
              "         ...,\n",
              "         [-0.0516,  0.1437,  0.1949,  ...,  0.0447,  0.0201,  0.0000],\n",
              "         [-0.2334,  0.1454,  0.3280,  ...,  0.0520, -0.0163,  0.0000],\n",
              "         [-0.2830,  0.1018,  0.2986,  ...,  0.0625,  0.0019,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0291, -0.1289, -0.0283,  ...,  0.0516,  0.2128,  0.0000],\n",
              "         [ 0.1365, -0.0401, -0.0061,  ...,  0.2603,  0.1243,  0.0000],\n",
              "         [ 0.1347,  0.0190,  0.0126,  ...,  0.3394, -0.0173,  0.0000],\n",
              "         ...,\n",
              "         [-0.1019,  0.1377,  0.2476,  ...,  0.0721, -0.0202,  0.0000],\n",
              "         [-0.2522,  0.1379,  0.3437,  ...,  0.0637, -0.0398,  0.0000],\n",
              "         [-0.2918,  0.1014,  0.3074,  ...,  0.0579, -0.0040,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0200, -0.1223, -0.0361,  ...,  0.0490,  0.2147,  0.0000],\n",
              "         [ 0.1350, -0.0269, -0.0139,  ...,  0.2515,  0.1138,  0.0000],\n",
              "         [ 0.1420,  0.0441,  0.0055,  ...,  0.3255, -0.0400,  0.0000],\n",
              "         ...,\n",
              "         [-0.0417,  0.1342,  0.1924,  ...,  0.0625,  0.0089,  0.0000],\n",
              "         [-0.2297,  0.1416,  0.3322,  ...,  0.0701, -0.0144,  0.0000],\n",
              "         [-0.2769,  0.1062,  0.3001,  ...,  0.0692,  0.0090,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0328, -0.1324, -0.0324,  ...,  0.0544,  0.2087,  0.0000],\n",
              "         [ 0.1457, -0.0615, -0.0395,  ...,  0.2647,  0.1423,  0.0000],\n",
              "         [ 0.1161, -0.0391, -0.0341,  ...,  0.3546,  0.0374,  0.0000],\n",
              "         ...,\n",
              "         [-0.1300,  0.0716,  0.2228,  ...,  0.0878,  0.0144,  0.0000],\n",
              "         [-0.2499,  0.0681,  0.2849,  ...,  0.0658, -0.0316,  0.0000],\n",
              "         [-0.2984,  0.0725,  0.2800,  ...,  0.0390, -0.0179,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0247, -0.1302, -0.0321,  ...,  0.0554,  0.2143,  0.0000],\n",
              "         [ 0.1482, -0.0377, -0.0143,  ...,  0.2596,  0.1262,  0.0000],\n",
              "         [ 0.1403,  0.0220,  0.0020,  ...,  0.3467, -0.0186,  0.0000],\n",
              "         ...,\n",
              "         [-0.0890,  0.1485,  0.2224,  ...,  0.0796, -0.0016,  0.0000],\n",
              "         [-0.2486,  0.1373,  0.3217,  ...,  0.0742, -0.0273,  0.0000],\n",
              "         [-0.2854,  0.1008,  0.2906,  ...,  0.0719,  0.0030,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1551, -0.0450,  ...,  0.0541,  0.2144,  0.0000],\n",
              "         [ 0.1482, -0.0951, -0.0669,  ...,  0.2824,  0.1572,  0.0000],\n",
              "         [ 0.1025, -0.0870, -0.0704,  ...,  0.3765,  0.0618,  0.0000],\n",
              "         ...,\n",
              "         [-0.1392,  0.0171,  0.2059,  ...,  0.0984,  0.0159,  0.0000],\n",
              "         [-0.2313,  0.0260,  0.2385,  ...,  0.0787, -0.0308,  0.0000],\n",
              "         [-0.2788,  0.0229,  0.2529,  ...,  0.0349, -0.0208,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0191, -0.1301, -0.0271,  ...,  0.0477,  0.2119,  0.0000],\n",
              "         [ 0.1458, -0.0420, -0.0045,  ...,  0.2657,  0.1275,  0.0000],\n",
              "         [ 0.1434,  0.0124,  0.0079,  ...,  0.3454, -0.0004,  0.0000],\n",
              "         ...,\n",
              "         [-0.0703,  0.1238,  0.2317,  ...,  0.0889,  0.0063,  0.0000],\n",
              "         [-0.2333,  0.1247,  0.3360,  ...,  0.0794, -0.0217,  0.0000],\n",
              "         [-0.2801,  0.1019,  0.2960,  ...,  0.0567,  0.0015,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0124, -0.1247, -0.0298,  ...,  0.0475,  0.2116,  0.0000],\n",
              "         [ 0.1578, -0.0259, -0.0103,  ...,  0.2655,  0.1217,  0.0000],\n",
              "         [ 0.1608,  0.0390,  0.0044,  ...,  0.3409, -0.0192,  0.0000],\n",
              "         ...,\n",
              "         [-0.0082,  0.1203,  0.1805,  ...,  0.0807,  0.0337,  0.0000],\n",
              "         [-0.2099,  0.1247,  0.3276,  ...,  0.0835, -0.0040,  0.0000],\n",
              "         [-0.2633,  0.1077,  0.2931,  ...,  0.0621,  0.0078,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0361, -0.1473, -0.0486,  ...,  0.0626,  0.2159,  0.0000],\n",
              "         [ 0.1493, -0.0962, -0.0674,  ...,  0.2875,  0.1645,  0.0000],\n",
              "         [ 0.0968, -0.0918, -0.0690,  ...,  0.3929,  0.0744,  0.0000],\n",
              "         ...,\n",
              "         [-0.1620,  0.0216,  0.2133,  ...,  0.1032, -0.0063,  0.0000],\n",
              "         [-0.2669,  0.0427,  0.2306,  ...,  0.0807, -0.0501,  0.0000],\n",
              "         [-0.2841,  0.0342,  0.2510,  ...,  0.0284, -0.0225,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0321, -0.1531, -0.0583,  ...,  0.0585,  0.1961,  0.0000],\n",
              "         [ 0.1166, -0.1245, -0.0653,  ...,  0.2661,  0.1508,  0.0000],\n",
              "         [ 0.0532, -0.1238, -0.0739,  ...,  0.3622,  0.0891,  0.0000],\n",
              "         ...,\n",
              "         [-0.2312,  0.0484,  0.2015,  ...,  0.0557, -0.0801,  0.0000],\n",
              "         [-0.2720,  0.0626,  0.2069,  ...,  0.0516, -0.0805,  0.0000],\n",
              "         [-0.2533,  0.0353,  0.2381,  ...,  0.0038, -0.0464,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0309, -0.1529, -0.0453,  ...,  0.0562,  0.2145,  0.0000],\n",
              "         [ 0.1507, -0.0932, -0.0734,  ...,  0.2918,  0.1548,  0.0000],\n",
              "         [ 0.1074, -0.0875, -0.0804,  ...,  0.3868,  0.0594,  0.0000],\n",
              "         ...,\n",
              "         [-0.1264,  0.0165,  0.1950,  ...,  0.1084,  0.0187,  0.0000],\n",
              "         [-0.2263,  0.0164,  0.2422,  ...,  0.0827, -0.0239,  0.0000],\n",
              "         [-0.2796,  0.0258,  0.2559,  ...,  0.0380, -0.0177,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0153, -0.1276, -0.0361,  ...,  0.0534,  0.2155,  0.0000],\n",
              "         [ 0.1420, -0.0324, -0.0112,  ...,  0.2497,  0.1276,  0.0000],\n",
              "         [ 0.1437,  0.0344,  0.0084,  ...,  0.3276, -0.0213,  0.0000],\n",
              "         ...,\n",
              "         [-0.0396,  0.1462,  0.1931,  ...,  0.0566,  0.0252,  0.0000],\n",
              "         [-0.2167,  0.1338,  0.3152,  ...,  0.0667, -0.0068,  0.0000],\n",
              "         [-0.2660,  0.1076,  0.2881,  ...,  0.0682,  0.0087,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0202, -0.1632, -0.0508,  ...,  0.0656,  0.2112,  0.0000],\n",
              "         [ 0.1573, -0.1006, -0.0781,  ...,  0.2997,  0.1413,  0.0000],\n",
              "         [ 0.1198, -0.0946, -0.0895,  ...,  0.3907,  0.0476,  0.0000],\n",
              "         ...,\n",
              "         [-0.0912, -0.0010,  0.1614,  ...,  0.1093,  0.0278,  0.0000],\n",
              "         [-0.1890,  0.0061,  0.2076,  ...,  0.0856, -0.0112,  0.0000],\n",
              "         [-0.2444,  0.0065,  0.2274,  ...,  0.0531, -0.0187,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0198, -0.1207, -0.0292,  ...,  0.0363,  0.2076,  0.0000],\n",
              "         [ 0.1248, -0.0244,  0.0018,  ...,  0.2311,  0.1127,  0.0000],\n",
              "         [ 0.1241,  0.0399,  0.0227,  ...,  0.3063, -0.0306,  0.0000],\n",
              "         ...,\n",
              "         [-0.0327,  0.1374,  0.1998,  ...,  0.0444,  0.0210,  0.0000],\n",
              "         [-0.2297,  0.1315,  0.3481,  ...,  0.0471, -0.0156,  0.0000],\n",
              "         [-0.2911,  0.0998,  0.3069,  ...,  0.0435, -0.0055,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0306, -0.1226, -0.0307,  ...,  0.0555,  0.2069,  0.0000],\n",
              "         [ 0.1398, -0.0551, -0.0291,  ...,  0.2579,  0.1410,  0.0000],\n",
              "         [ 0.1216, -0.0240, -0.0148,  ...,  0.3528,  0.0223,  0.0000],\n",
              "         ...,\n",
              "         [-0.1419,  0.1178,  0.2438,  ...,  0.0909, -0.0045,  0.0000],\n",
              "         [-0.2637,  0.1051,  0.3128,  ...,  0.0709, -0.0348,  0.0000],\n",
              "         [-0.3057,  0.0878,  0.2894,  ...,  0.0424, -0.0194,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.0542e-02, -1.3064e-01, -3.2894e-02,  ...,  4.9485e-02,\n",
              "           2.1786e-01,  0.0000e+00],\n",
              "         [ 1.3816e-01, -3.8975e-02, -7.9147e-03,  ...,  2.3706e-01,\n",
              "           1.4166e-01,  0.0000e+00],\n",
              "         [ 1.3443e-01,  1.7652e-02,  1.5984e-02,  ...,  3.1943e-01,\n",
              "          -6.5525e-05,  0.0000e+00],\n",
              "         ...,\n",
              "         [-6.3779e-02,  1.4532e-01,  2.0912e-01,  ...,  6.0059e-02,\n",
              "           2.2322e-02,  0.0000e+00],\n",
              "         [-2.3852e-01,  1.3917e-01,  3.2561e-01,  ...,  5.8596e-02,\n",
              "          -1.8167e-02,  0.0000e+00],\n",
              "         [-2.8478e-01,  9.6209e-02,  2.9193e-01,  ...,  6.1186e-02,\n",
              "          -2.5306e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1263, -0.0329,  ...,  0.0494,  0.2154,  0.0000],\n",
              "         [ 0.1313, -0.0312, -0.0069,  ...,  0.2354,  0.1284,  0.0000],\n",
              "         [ 0.1333,  0.0291,  0.0164,  ...,  0.3109, -0.0212,  0.0000],\n",
              "         ...,\n",
              "         [-0.0418,  0.1381,  0.2005,  ...,  0.0448,  0.0148,  0.0000],\n",
              "         [-0.2305,  0.1431,  0.3354,  ...,  0.0559, -0.0142,  0.0000],\n",
              "         [-0.2790,  0.1052,  0.3024,  ...,  0.0632,  0.0059,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0037, -0.1102, -0.0521,  ...,  0.0341,  0.1952,  0.0000],\n",
              "         [ 0.1669, -0.0027, -0.0375,  ...,  0.2380,  0.0424,  0.0000],\n",
              "         [ 0.1723,  0.0510, -0.0344,  ...,  0.3010, -0.0933,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0642,  0.0870,  0.0605,  ...,  0.0245,  0.0434,  0.0000],\n",
              "         [-0.1615,  0.1197,  0.3084,  ...,  0.0784, -0.0198,  0.0000],\n",
              "         [-0.2613,  0.0885,  0.2943,  ...,  0.0534, -0.0070,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0020, -0.1113, -0.0548,  ...,  0.0375,  0.2088,  0.0000],\n",
              "         [ 0.1487, -0.0012, -0.0341,  ...,  0.2239,  0.0890,  0.0000],\n",
              "         [ 0.1637,  0.0585, -0.0218,  ...,  0.2979, -0.0711,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0502,  0.0987,  0.0710,  ...,  0.0267,  0.0559,  0.0000],\n",
              "         [-0.1649,  0.1369,  0.3017,  ...,  0.0711, -0.0065,  0.0000],\n",
              "         [-0.2574,  0.0966,  0.2936,  ...,  0.0604,  0.0023,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0247, -0.1354, -0.0293,  ...,  0.0497,  0.2111,  0.0000],\n",
              "         [ 0.1430, -0.0474, -0.0189,  ...,  0.2751,  0.1327,  0.0000],\n",
              "         [ 0.1270, -0.0065, -0.0014,  ...,  0.3634,  0.0128,  0.0000],\n",
              "         ...,\n",
              "         [-0.1054,  0.1112,  0.2259,  ...,  0.0882,  0.0043,  0.0000],\n",
              "         [-0.2364,  0.1037,  0.3096,  ...,  0.0749, -0.0304,  0.0000],\n",
              "         [-0.2921,  0.0810,  0.2906,  ...,  0.0578, -0.0135,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0232, -0.1365, -0.0286,  ...,  0.0509,  0.2171,  0.0000],\n",
              "         [ 0.1434, -0.0449, -0.0110,  ...,  0.2471,  0.1420,  0.0000],\n",
              "         [ 0.1339,  0.0032,  0.0142,  ...,  0.3309,  0.0056,  0.0000],\n",
              "         ...,\n",
              "         [-0.1004,  0.1433,  0.2253,  ...,  0.0586,  0.0034,  0.0000],\n",
              "         [-0.2468,  0.1328,  0.3212,  ...,  0.0596, -0.0289,  0.0000],\n",
              "         [-0.2892,  0.0932,  0.2926,  ...,  0.0602, -0.0045,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0088, -0.1126, -0.0463,  ...,  0.0345,  0.1983,  0.0000],\n",
              "         [ 0.1515, -0.0055, -0.0287,  ...,  0.2350,  0.0598,  0.0000],\n",
              "         [ 0.1580,  0.0541, -0.0215,  ...,  0.3032, -0.0802,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0481,  0.0951,  0.0814,  ...,  0.0274,  0.0440,  0.0000],\n",
              "         [-0.1751,  0.1193,  0.3160,  ...,  0.0726, -0.0149,  0.0000],\n",
              "         [-0.2659,  0.0890,  0.2987,  ...,  0.0555, -0.0053,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0326, -0.1582, -0.0613,  ...,  0.0622,  0.1995,  1.0000],\n",
              "         [ 0.1202, -0.1303, -0.0709,  ...,  0.2791,  0.1539,  1.0000],\n",
              "         [ 0.0572, -0.1284, -0.0777,  ...,  0.3761,  0.0896,  1.0000],\n",
              "         ...,\n",
              "         [-0.2129,  0.0401,  0.1906,  ...,  0.0768, -0.0767,  1.0000],\n",
              "         [-0.2602,  0.0483,  0.1909,  ...,  0.0655, -0.0805,  1.0000],\n",
              "         [-0.2536,  0.0182,  0.2288,  ...,  0.0121, -0.0477,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1222, -0.0309,  ...,  0.0557,  0.2066,  1.0000],\n",
              "         [ 0.1367, -0.0576, -0.0351,  ...,  0.2659,  0.1407,  1.0000],\n",
              "         [ 0.1179, -0.0261, -0.0231,  ...,  0.3586,  0.0273,  1.0000],\n",
              "         ...,\n",
              "         [-0.1446,  0.1066,  0.2457,  ...,  0.0940, -0.0048,  1.0000],\n",
              "         [-0.2623,  0.0915,  0.3093,  ...,  0.0744, -0.0348,  1.0000],\n",
              "         [-0.3055,  0.0851,  0.2886,  ...,  0.0390, -0.0175,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0177, -0.1275, -0.0327,  ...,  0.0530,  0.2171,  1.0000],\n",
              "         [ 0.1558, -0.0309, -0.0095,  ...,  0.2654,  0.1264,  1.0000],\n",
              "         [ 0.1533,  0.0374,  0.0122,  ...,  0.3410, -0.0198,  1.0000],\n",
              "         ...,\n",
              "         [-0.0346,  0.1376,  0.1940,  ...,  0.0646,  0.0164,  1.0000],\n",
              "         [-0.2165,  0.1374,  0.3142,  ...,  0.0691, -0.0111,  1.0000],\n",
              "         [-0.2677,  0.1062,  0.2917,  ...,  0.0732,  0.0091,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0137, -0.1219, -0.0336,  ...,  0.0489,  0.2158,  1.0000],\n",
              "         [ 0.1461, -0.0301, -0.0141,  ...,  0.2473,  0.1207,  1.0000],\n",
              "         [ 0.1419,  0.0444,  0.0055,  ...,  0.3200, -0.0318,  1.0000],\n",
              "         ...,\n",
              "         [-0.0218,  0.1426,  0.1831,  ...,  0.0522,  0.0253,  1.0000],\n",
              "         [-0.2148,  0.1392,  0.3211,  ...,  0.0653, -0.0053,  1.0000],\n",
              "         [-0.2638,  0.1097,  0.2939,  ...,  0.0720,  0.0081,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0228, -0.1267, -0.0260,  ...,  0.0398,  0.2074,  1.0000],\n",
              "         [ 0.1241, -0.0335,  0.0032,  ...,  0.2383,  0.1185,  1.0000],\n",
              "         [ 0.1213,  0.0249,  0.0245,  ...,  0.3152, -0.0155,  1.0000],\n",
              "         ...,\n",
              "         [-0.0736,  0.1328,  0.2295,  ...,  0.0573,  0.0050,  1.0000],\n",
              "         [-0.2459,  0.1266,  0.3548,  ...,  0.0500, -0.0254,  1.0000],\n",
              "         [-0.2976,  0.0972,  0.3094,  ...,  0.0425, -0.0083,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0353, -0.1380, -0.0354,  ...,  0.0509,  0.2127,  1.0000],\n",
              "         [ 0.1388, -0.0734, -0.0497,  ...,  0.2633,  0.1588,  1.0000],\n",
              "         [ 0.0975, -0.0595, -0.0464,  ...,  0.3554,  0.0602,  1.0000],\n",
              "         ...,\n",
              "         [-0.1503,  0.0607,  0.2322,  ...,  0.0962,  0.0243,  1.0000],\n",
              "         [-0.2676,  0.0566,  0.2884,  ...,  0.0714, -0.0329,  1.0000],\n",
              "         [-0.3080,  0.0577,  0.2837,  ...,  0.0309, -0.0214,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0357, -0.1312, -0.0325,  ...,  0.0616,  0.2114,  1.0000],\n",
              "         [ 0.1498, -0.0563, -0.0362,  ...,  0.2641,  0.1446,  1.0000],\n",
              "         [ 0.1192, -0.0308, -0.0194,  ...,  0.3550,  0.0385,  1.0000],\n",
              "         ...,\n",
              "         [-0.1629,  0.1013,  0.2586,  ...,  0.0801, -0.0198,  1.0000],\n",
              "         [-0.2721,  0.0827,  0.2998,  ...,  0.0710, -0.0473,  1.0000],\n",
              "         [-0.2957,  0.0840,  0.2810,  ...,  0.0433, -0.0141,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1408, -0.0383,  ...,  0.0630,  0.2154,  1.0000],\n",
              "         [ 0.1719, -0.0628, -0.0424,  ...,  0.2851,  0.1531,  1.0000],\n",
              "         [ 0.1319, -0.0451, -0.0354,  ...,  0.3762,  0.0477,  1.0000],\n",
              "         ...,\n",
              "         [-0.1304,  0.0610,  0.2152,  ...,  0.0905,  0.0011,  1.0000],\n",
              "         [-0.2435,  0.0611,  0.2590,  ...,  0.0769, -0.0385,  1.0000],\n",
              "         [-0.2806,  0.0654,  0.2649,  ...,  0.0460, -0.0114,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0011, -0.1092, -0.0453,  ...,  0.0424,  0.2054,  1.0000],\n",
              "         [ 0.1761, -0.0057, -0.0362,  ...,  0.2539,  0.0712,  1.0000],\n",
              "         [ 0.1870,  0.0583, -0.0331,  ...,  0.3124, -0.0677,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0895,  0.0901,  0.0544,  ...,  0.0536,  0.0659,  1.0000],\n",
              "         [-0.1453,  0.1245,  0.3026,  ...,  0.1113,  0.0016,  1.0000],\n",
              "         [-0.2438,  0.1066,  0.2909,  ...,  0.0677,  0.0089,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.3262e-02, -1.1815e-01, -3.3851e-02,  ...,  4.4813e-02,\n",
              "           2.0823e-01,  1.0000e+00],\n",
              "         [ 1.4425e-01, -2.0388e-02, -1.5973e-02,  ...,  2.5690e-01,\n",
              "           1.0093e-01,  1.0000e+00],\n",
              "         [ 1.5438e-01,  5.0312e-02, -2.8536e-03,  ...,  3.2606e-01,\n",
              "          -4.4117e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 2.4285e-02,  1.1882e-01,  1.4265e-01,  ...,  6.0135e-02,\n",
              "           4.1443e-02,  1.0000e+00],\n",
              "         [-1.9290e-01,  1.2555e-01,  3.2522e-01,  ...,  8.6629e-02,\n",
              "           7.0710e-04,  1.0000e+00],\n",
              "         [-2.5984e-01,  1.0930e-01,  2.9458e-01,  ...,  5.8374e-02,\n",
              "           1.0020e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0224, -0.1319, -0.0300,  ...,  0.0519,  0.2153,  1.0000],\n",
              "         [ 0.1421, -0.0398, -0.0100,  ...,  0.2521,  0.1291,  1.0000],\n",
              "         [ 0.1379,  0.0205,  0.0116,  ...,  0.3329, -0.0157,  1.0000],\n",
              "         ...,\n",
              "         [-0.0849,  0.1389,  0.2282,  ...,  0.0605, -0.0042,  1.0000],\n",
              "         [-0.2396,  0.1339,  0.3316,  ...,  0.0602, -0.0275,  1.0000],\n",
              "         [-0.2814,  0.1007,  0.2976,  ...,  0.0654,  0.0019,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0237, -0.1322, -0.0267,  ...,  0.0456,  0.2089,  1.0000],\n",
              "         [ 0.1333, -0.0495, -0.0099,  ...,  0.2577,  0.1324,  1.0000],\n",
              "         [ 0.1172, -0.0083,  0.0081,  ...,  0.3444,  0.0110,  1.0000],\n",
              "         ...,\n",
              "         [-0.1163,  0.1279,  0.2406,  ...,  0.0860, -0.0052,  1.0000],\n",
              "         [-0.2539,  0.1176,  0.3318,  ...,  0.0674, -0.0362,  1.0000],\n",
              "         [-0.3017,  0.0885,  0.2981,  ...,  0.0479, -0.0181,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0033, -0.1211, -0.0477,  ...,  0.0564,  0.2152,  1.0000],\n",
              "         [ 0.1769, -0.0101, -0.0354,  ...,  0.2632,  0.1106,  1.0000],\n",
              "         [ 0.1747,  0.0506, -0.0208,  ...,  0.3422, -0.0452,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0746,  0.1257,  0.0949,  ...,  0.0444,  0.0414,  1.0000],\n",
              "         [-0.1468,  0.1390,  0.2734,  ...,  0.0747, -0.0015,  1.0000],\n",
              "         [-0.2436,  0.1082,  0.2701,  ...,  0.0765,  0.0046,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0305, -0.1544, -0.0602,  ...,  0.0581,  0.1929,  1.0000],\n",
              "         [ 0.1155, -0.1270, -0.0675,  ...,  0.2580,  0.1505,  1.0000],\n",
              "         [ 0.0492, -0.1228, -0.0770,  ...,  0.3577,  0.0859,  1.0000],\n",
              "         ...,\n",
              "         [-0.2316,  0.0493,  0.1983,  ...,  0.0374, -0.0804,  1.0000],\n",
              "         [-0.2725,  0.0672,  0.2105,  ...,  0.0382, -0.0787,  1.0000],\n",
              "         [-0.2464,  0.0282,  0.2371,  ..., -0.0015, -0.0496,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0217, -0.1310, -0.0279,  ...,  0.0438,  0.2095,  1.0000],\n",
              "         [ 0.1380, -0.0396, -0.0033,  ...,  0.2555,  0.1277,  1.0000],\n",
              "         [ 0.1315,  0.0104,  0.0191,  ...,  0.3365, -0.0018,  1.0000],\n",
              "         ...,\n",
              "         [-0.0828,  0.1302,  0.2253,  ...,  0.0767,  0.0023,  1.0000],\n",
              "         [-0.2397,  0.1242,  0.3326,  ...,  0.0628, -0.0268,  1.0000],\n",
              "         [-0.2931,  0.0944,  0.2970,  ...,  0.0496, -0.0104,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0122, -0.1060, -0.0699,  ...,  0.0392,  0.2070,  1.0000],\n",
              "         [ 0.1633, -0.0081, -0.0524,  ...,  0.2023,  0.0947,  1.0000],\n",
              "         [ 0.1565,  0.0392, -0.0430,  ...,  0.2897, -0.0681,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0784,  0.0920,  0.0507,  ...,  0.0272,  0.0604,  1.0000],\n",
              "         [-0.1464,  0.1351,  0.2700,  ...,  0.0825, -0.0040,  1.0000],\n",
              "         [-0.2538,  0.0865,  0.2819,  ...,  0.0693, -0.0041,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2088e-02, -1.3961e-01, -2.9675e-02,  ...,  5.2898e-02,\n",
              "           2.1755e-01,  1.0000e+00],\n",
              "         [ 1.4421e-01, -4.5334e-02, -1.3991e-02,  ...,  2.4915e-01,\n",
              "           1.3811e-01,  1.0000e+00],\n",
              "         [ 1.3870e-01,  2.8501e-03,  1.0093e-02,  ...,  3.2877e-01,\n",
              "          -3.6414e-04,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.0914e-01,  1.5644e-01,  2.3228e-01,  ...,  5.3608e-02,\n",
              "           5.5486e-04,  1.0000e+00],\n",
              "         [-2.4652e-01,  1.3036e-01,  3.2304e-01,  ...,  5.5969e-02,\n",
              "          -3.0124e-02,  1.0000e+00],\n",
              "         [-2.7765e-01,  9.5361e-02,  2.8860e-01,  ...,  6.7538e-02,\n",
              "          -1.3505e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-8.4661e-03, -1.2919e-01, -3.9027e-02,  ...,  5.8417e-02,\n",
              "           2.2067e-01,  1.0000e+00],\n",
              "         [ 1.7880e-01, -1.8392e-02, -2.3510e-02,  ...,  2.7242e-01,\n",
              "           1.3005e-01,  1.0000e+00],\n",
              "         [ 1.7471e-01,  4.3337e-02, -2.9711e-04,  ...,  3.5223e-01,\n",
              "          -1.5201e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 2.4183e-02,  1.3209e-01,  1.4221e-01,  ...,  4.9197e-02,\n",
              "           1.8376e-02,  1.0000e+00],\n",
              "         [-1.6784e-01,  1.3415e-01,  2.7452e-01,  ...,  6.2237e-02,\n",
              "          -8.1488e-03,  1.0000e+00],\n",
              "         [-2.4097e-01,  1.0654e-01,  2.7321e-01,  ...,  8.1630e-02,\n",
              "           1.0257e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 4.3085e-02, -1.3929e-01, -6.9975e-02,  ...,  1.5390e-02,\n",
              "           1.6877e-01,  1.0000e+00],\n",
              "         [ 2.5271e-01, -2.7825e-02, -6.3207e-02,  ...,  1.9023e-01,\n",
              "           9.1742e-05,  1.0000e+00],\n",
              "         [ 2.5835e-01,  4.1692e-03, -5.7162e-02,  ...,  2.3771e-01,\n",
              "          -1.1812e-01,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4420e-01, -1.1500e-03, -4.6610e-02,  ...,  5.5794e-02,\n",
              "           5.4258e-02,  1.0000e+00],\n",
              "         [-7.2530e-02,  8.0088e-02,  2.5594e-01,  ...,  1.1825e-01,\n",
              "          -4.3181e-02,  1.0000e+00],\n",
              "         [-2.4358e-01,  5.4176e-02,  3.0385e-01,  ...,  7.5914e-02,\n",
              "          -2.7099e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0173, -0.1205, -0.0327,  ...,  0.0368,  0.2065,  1.0000],\n",
              "         [ 0.1285, -0.0185, -0.0048,  ...,  0.2375,  0.1042,  1.0000],\n",
              "         [ 0.1325,  0.0493,  0.0147,  ...,  0.3108, -0.0414,  1.0000],\n",
              "         ...,\n",
              "         [-0.0058,  0.1282,  0.1627,  ...,  0.0447,  0.0320,  1.0000],\n",
              "         [-0.2124,  0.1286,  0.3335,  ...,  0.0581, -0.0092,  1.0000],\n",
              "         [-0.2797,  0.0966,  0.3025,  ...,  0.0478, -0.0036,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0181, -0.1318, -0.0277,  ...,  0.0466,  0.2110,  0.0000],\n",
              "         [ 0.1485, -0.0449, -0.0043,  ...,  0.2636,  0.1281,  0.0000],\n",
              "         [ 0.1437,  0.0052,  0.0083,  ...,  0.3448,  0.0028,  0.0000],\n",
              "         ...,\n",
              "         [-0.0762,  0.1257,  0.2266,  ...,  0.0866,  0.0069,  0.0000],\n",
              "         [-0.2351,  0.1254,  0.3291,  ...,  0.0771, -0.0235,  0.0000],\n",
              "         [-0.2814,  0.1029,  0.2940,  ...,  0.0563, -0.0006,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.5086e-02, -1.3449e-01, -3.0260e-02,  ...,  5.3696e-02,\n",
              "           2.1507e-01,  2.0000e+00],\n",
              "         [ 1.5289e-01, -4.2678e-02, -1.2234e-02,  ...,  2.7263e-01,\n",
              "           1.3531e-01,  2.0000e+00],\n",
              "         [ 1.4037e-01,  1.7184e-03,  1.0744e-02,  ...,  3.5720e-01,\n",
              "           6.9345e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.2240e-01,  1.3046e-01,  2.4647e-01,  ...,  7.6501e-02,\n",
              "          -1.7960e-02,  2.0000e+00],\n",
              "         [-2.4551e-01,  1.2028e-01,  3.1522e-01,  ...,  6.9669e-02,\n",
              "          -3.8634e-02,  2.0000e+00],\n",
              "         [-2.8974e-01,  9.3302e-02,  2.9383e-01,  ...,  5.9886e-02,\n",
              "          -8.8332e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5635e-02, -1.3163e-01, -2.3491e-02,  ...,  4.3845e-02,\n",
              "           2.0827e-01,  2.0000e+00],\n",
              "         [ 1.3166e-01, -4.6823e-02, -1.6898e-03,  ...,  2.4102e-01,\n",
              "           1.3345e-01,  2.0000e+00],\n",
              "         [ 1.1691e-01, -1.6295e-03,  2.2124e-02,  ...,  3.2463e-01,\n",
              "           8.7878e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1909e-01,  1.3493e-01,  2.5349e-01,  ...,  6.4304e-02,\n",
              "           1.1643e-03,  2.0000e+00],\n",
              "         [-2.5898e-01,  1.2534e-01,  3.4155e-01,  ...,  5.5190e-02,\n",
              "          -3.1563e-02,  2.0000e+00],\n",
              "         [-3.0505e-01,  9.3072e-02,  3.0301e-01,  ...,  4.3980e-02,\n",
              "          -1.3878e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0209, -0.1228, -0.0269,  ...,  0.0369,  0.2066,  2.0000],\n",
              "         [ 0.1258, -0.0245,  0.0053,  ...,  0.2310,  0.1104,  2.0000],\n",
              "         [ 0.1247,  0.0386,  0.0244,  ...,  0.3051, -0.0284,  2.0000],\n",
              "         ...,\n",
              "         [-0.0462,  0.1365,  0.2058,  ...,  0.0445,  0.0151,  2.0000],\n",
              "         [-0.2360,  0.1300,  0.3475,  ...,  0.0447, -0.0190,  2.0000],\n",
              "         [-0.2925,  0.1008,  0.3090,  ...,  0.0410, -0.0041,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0247, -0.1312, -0.0300,  ...,  0.0509,  0.2163,  2.0000],\n",
              "         [ 0.1392, -0.0425, -0.0060,  ...,  0.2381,  0.1345,  2.0000],\n",
              "         [ 0.1279,  0.0148,  0.0153,  ...,  0.3140, -0.0095,  2.0000],\n",
              "         ...,\n",
              "         [-0.0672,  0.1616,  0.2074,  ...,  0.0398,  0.0144,  2.0000],\n",
              "         [-0.2409,  0.1459,  0.3193,  ...,  0.0482, -0.0174,  2.0000],\n",
              "         [-0.2795,  0.1079,  0.2907,  ...,  0.0633,  0.0024,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0205, -0.1245, -0.0291,  ...,  0.0465,  0.2141,  2.0000],\n",
              "         [ 0.1501, -0.0265, -0.0032,  ...,  0.2547,  0.1215,  2.0000],\n",
              "         [ 0.1481,  0.0367,  0.0206,  ...,  0.3268, -0.0215,  2.0000],\n",
              "         ...,\n",
              "         [-0.0369,  0.1383,  0.1967,  ...,  0.0522,  0.0128,  2.0000],\n",
              "         [-0.2220,  0.1441,  0.3225,  ...,  0.0545, -0.0200,  2.0000],\n",
              "         [-0.2763,  0.1058,  0.2981,  ...,  0.0590,  0.0023,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.3797e-02, -1.2016e-01, -3.5416e-02,  ...,  4.8263e-02,\n",
              "           2.1311e-01,  2.0000e+00],\n",
              "         [ 1.5868e-01, -1.6915e-02, -1.5069e-02,  ...,  2.6067e-01,\n",
              "           1.1473e-01,  2.0000e+00],\n",
              "         [ 1.6256e-01,  5.0980e-02,  7.5780e-03,  ...,  3.3115e-01,\n",
              "          -3.6620e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 6.0953e-04,  1.3095e-01,  1.6228e-01,  ...,  5.9984e-02,\n",
              "           2.5581e-02,  2.0000e+00],\n",
              "         [-2.0264e-01,  1.3979e-01,  3.1296e-01,  ...,  7.0381e-02,\n",
              "          -9.0336e-03,  2.0000e+00],\n",
              "         [-2.6286e-01,  1.0844e-01,  2.9245e-01,  ...,  6.8445e-02,\n",
              "           7.9985e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-7.9735e-03, -1.1285e-01, -4.4578e-02,  ...,  4.2524e-02,\n",
              "           2.1325e-01,  2.0000e+00],\n",
              "         [ 1.4162e-01, -1.9695e-02, -2.1904e-02,  ...,  2.1681e-01,\n",
              "           1.1504e-01,  2.0000e+00],\n",
              "         [ 1.3837e-01,  4.0215e-02, -6.2585e-03,  ...,  2.8975e-01,\n",
              "          -4.4446e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4959e-02,  1.3840e-01,  1.3266e-01,  ...,  2.0345e-02,\n",
              "           4.3889e-02,  2.0000e+00],\n",
              "         [-1.9478e-01,  1.4935e-01,  3.1308e-01,  ...,  5.5812e-02,\n",
              "           4.4131e-03,  2.0000e+00],\n",
              "         [-2.6969e-01,  1.0017e-01,  2.9795e-01,  ...,  6.3834e-02,\n",
              "          -3.6355e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0167, -0.1199, -0.0336,  ...,  0.0505,  0.2153,  2.0000],\n",
              "         [ 0.1433, -0.0264, -0.0096,  ...,  0.2398,  0.1196,  2.0000],\n",
              "         [ 0.1424,  0.0403,  0.0068,  ...,  0.3093, -0.0314,  2.0000],\n",
              "         ...,\n",
              "         [-0.0128,  0.1468,  0.1755,  ...,  0.0462,  0.0245,  2.0000],\n",
              "         [-0.2198,  0.1479,  0.3215,  ...,  0.0622, -0.0090,  2.0000],\n",
              "         [-0.2721,  0.1136,  0.2989,  ...,  0.0679,  0.0091,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0169, -0.1230, -0.0326,  ...,  0.0378,  0.2065,  2.0000],\n",
              "         [ 0.1330, -0.0177, -0.0064,  ...,  0.2382,  0.1021,  2.0000],\n",
              "         [ 0.1348,  0.0466,  0.0103,  ...,  0.3143, -0.0392,  2.0000],\n",
              "         ...,\n",
              "         [-0.0114,  0.1271,  0.1673,  ...,  0.0471,  0.0265,  2.0000],\n",
              "         [-0.2153,  0.1214,  0.3342,  ...,  0.0584, -0.0106,  2.0000],\n",
              "         [-0.2769,  0.0965,  0.3001,  ...,  0.0475, -0.0043,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.0930e-02, -1.2844e-01, -2.9158e-02,  ...,  4.8414e-02,\n",
              "           2.1772e-01,  2.0000e+00],\n",
              "         [ 1.3872e-01, -3.9547e-02, -1.3350e-03,  ...,  2.2751e-01,\n",
              "           1.3536e-01,  2.0000e+00],\n",
              "         [ 1.3083e-01,  1.9625e-02,  2.4295e-02,  ...,  3.0812e-01,\n",
              "          -1.1761e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.1379e-02,  1.5531e-01,  2.3377e-01,  ...,  3.6299e-02,\n",
              "           1.1029e-02,  2.0000e+00],\n",
              "         [-2.4063e-01,  1.3735e-01,  3.3702e-01,  ...,  4.5994e-02,\n",
              "          -1.7062e-02,  2.0000e+00],\n",
              "         [-2.8299e-01,  1.0349e-01,  2.9873e-01,  ...,  6.1494e-02,\n",
              "           2.3445e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.4223e-02, -1.3116e-01, -2.4558e-02,  ...,  4.3534e-02,\n",
              "           2.0857e-01,  2.0000e+00],\n",
              "         [ 1.2941e-01, -4.3349e-02, -1.2762e-03,  ...,  2.4837e-01,\n",
              "           1.2952e-01,  2.0000e+00],\n",
              "         [ 1.1862e-01,  5.2254e-03,  2.1685e-02,  ...,  3.3014e-01,\n",
              "           5.7044e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1547e-01,  1.3405e-01,  2.5347e-01,  ...,  7.1653e-02,\n",
              "          -5.7646e-03,  2.0000e+00],\n",
              "         [-2.5666e-01,  1.2104e-01,  3.4493e-01,  ...,  6.0746e-02,\n",
              "          -3.2359e-02,  2.0000e+00],\n",
              "         [-3.0159e-01,  9.3421e-02,  3.0522e-01,  ...,  4.7145e-02,\n",
              "          -1.2352e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.9652e-02, -1.2333e-01, -3.0581e-02,  ...,  3.8117e-02,\n",
              "           2.0610e-01,  2.0000e+00],\n",
              "         [ 1.2736e-01, -2.1686e-02, -1.0798e-03,  ...,  2.3913e-01,\n",
              "           1.0617e-01,  2.0000e+00],\n",
              "         [ 1.2626e-01,  4.2886e-02,  1.6070e-02,  ...,  3.1456e-01,\n",
              "          -3.4864e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.4095e-02,  1.3235e-01,  1.8088e-01,  ...,  5.1248e-02,\n",
              "           1.9495e-02,  2.0000e+00],\n",
              "         [-2.2351e-01,  1.2640e-01,  3.3717e-01,  ...,  5.2281e-02,\n",
              "          -1.5423e-02,  2.0000e+00],\n",
              "         [-2.8424e-01,  9.7859e-02,  3.0399e-01,  ...,  4.1581e-02,\n",
              "          -4.8548e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0276, -0.1540, -0.0451,  ...,  0.0576,  0.2099,  2.0000],\n",
              "         [ 0.1509, -0.0910, -0.0679,  ...,  0.2852,  0.1412,  2.0000],\n",
              "         [ 0.1151, -0.0803, -0.0781,  ...,  0.3718,  0.0461,  2.0000],\n",
              "         ...,\n",
              "         [-0.1130,  0.0157,  0.1773,  ...,  0.0959,  0.0256,  2.0000],\n",
              "         [-0.2127,  0.0161,  0.2316,  ...,  0.0726, -0.0162,  2.0000],\n",
              "         [-0.2676,  0.0265,  0.2463,  ...,  0.0416, -0.0189,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-9.4262e-03, -1.1513e-01, -3.6138e-02,  ...,  4.2046e-02,\n",
              "           2.0671e-01,  2.0000e+00],\n",
              "         [ 1.5568e-01, -8.0163e-03, -1.8442e-02,  ...,  2.4968e-01,\n",
              "           8.6938e-02,  2.0000e+00],\n",
              "         [ 1.7083e-01,  6.0994e-02, -1.1455e-02,  ...,  3.1126e-01,\n",
              "          -6.0813e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 4.8484e-02,  1.1477e-01,  1.0883e-01,  ...,  4.5905e-02,\n",
              "           5.1428e-02,  2.0000e+00],\n",
              "         [-1.7460e-01,  1.2905e-01,  3.1988e-01,  ...,  8.8291e-02,\n",
              "          -9.3299e-04,  2.0000e+00],\n",
              "         [-2.5373e-01,  1.0863e-01,  2.9499e-01,  ...,  5.6250e-02,\n",
              "           6.4060e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.6194e-02, -1.1701e-01, -3.3029e-02,  ...,  4.2723e-02,\n",
              "           2.0949e-01,  2.0000e+00],\n",
              "         [ 1.3676e-01, -1.8800e-02, -1.2942e-02,  ...,  2.5243e-01,\n",
              "           1.0177e-01,  2.0000e+00],\n",
              "         [ 1.4855e-01,  5.1985e-02, -1.6112e-04,  ...,  3.2149e-01,\n",
              "          -4.4691e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 3.9199e-03,  1.2074e-01,  1.5953e-01,  ...,  5.7587e-02,\n",
              "           3.4109e-02,  2.0000e+00],\n",
              "         [-2.0438e-01,  1.2526e-01,  3.3438e-01,  ...,  7.8237e-02,\n",
              "          -7.8774e-04,  2.0000e+00],\n",
              "         [-2.6628e-01,  1.0636e-01,  2.9727e-01,  ...,  5.6360e-02,\n",
              "           1.0942e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5308e-02, -1.2975e-01, -2.3012e-02,  ...,  4.2080e-02,\n",
              "           2.0778e-01,  2.0000e+00],\n",
              "         [ 1.2591e-01, -4.5399e-02,  2.6206e-03,  ...,  2.4024e-01,\n",
              "           1.2753e-01,  2.0000e+00],\n",
              "         [ 1.1656e-01,  5.5530e-03,  2.4635e-02,  ...,  3.2155e-01,\n",
              "          -4.0071e-04,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0345e-01,  1.3599e-01,  2.5156e-01,  ...,  6.5069e-02,\n",
              "           5.8878e-04,  2.0000e+00],\n",
              "         [-2.5564e-01,  1.2747e-01,  3.5412e-01,  ...,  5.5925e-02,\n",
              "          -2.6403e-02,  2.0000e+00],\n",
              "         [-3.0359e-01,  9.8206e-02,  3.0831e-01,  ...,  4.3604e-02,\n",
              "          -9.3119e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0213, -0.1241, -0.0330,  ...,  0.0447,  0.2148,  2.0000],\n",
              "         [ 0.1306, -0.0349, -0.0117,  ...,  0.2292,  0.1245,  2.0000],\n",
              "         [ 0.1298,  0.0289,  0.0089,  ...,  0.3060, -0.0313,  2.0000],\n",
              "         ...,\n",
              "         [-0.0405,  0.1459,  0.1929,  ...,  0.0351,  0.0188,  2.0000],\n",
              "         [-0.2313,  0.1454,  0.3298,  ...,  0.0483, -0.0122,  2.0000],\n",
              "         [-0.2839,  0.1083,  0.3004,  ...,  0.0582,  0.0037,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4271e-02, -1.3404e-01, -3.0652e-02,  ...,  5.5746e-02,\n",
              "           2.1675e-01,  2.0000e+00],\n",
              "         [ 1.5485e-01, -3.7665e-02, -1.1799e-02,  ...,  2.6708e-01,\n",
              "           1.3584e-01,  2.0000e+00],\n",
              "         [ 1.4795e-01,  1.6902e-02,  1.1779e-02,  ...,  3.5180e-01,\n",
              "          -1.1204e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-7.7883e-02,  1.3646e-01,  2.2015e-01,  ...,  6.6412e-02,\n",
              "           3.9791e-03,  2.0000e+00],\n",
              "         [-2.3109e-01,  1.2978e-01,  3.1052e-01,  ...,  6.8364e-02,\n",
              "          -2.4345e-02,  2.0000e+00],\n",
              "         [-2.7796e-01,  9.7977e-02,  2.8788e-01,  ...,  6.8832e-02,\n",
              "           3.2928e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0251, -0.1335, -0.0262,  ...,  0.0478,  0.2095,  2.0000],\n",
              "         [ 0.1373, -0.0461, -0.0128,  ...,  0.2627,  0.1345,  2.0000],\n",
              "         [ 0.1217, -0.0061,  0.0054,  ...,  0.3484,  0.0149,  2.0000],\n",
              "         ...,\n",
              "         [-0.1293,  0.1244,  0.2468,  ...,  0.0830, -0.0073,  2.0000],\n",
              "         [-0.2553,  0.1087,  0.3247,  ...,  0.0679, -0.0348,  2.0000],\n",
              "         [-0.3022,  0.0882,  0.2983,  ...,  0.0508, -0.0150,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 1.0437e-03, -1.1255e-01, -5.1275e-02,  ...,  4.9589e-02,\n",
              "           2.1487e-01,  2.0000e+00],\n",
              "         [ 1.6975e-01,  4.8154e-03, -3.6161e-02,  ...,  2.4463e-01,\n",
              "           1.0965e-01,  2.0000e+00],\n",
              "         [ 1.7430e-01,  6.4587e-02, -1.5531e-02,  ...,  3.2472e-01,\n",
              "          -4.8860e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 8.7188e-02,  1.1455e-01,  7.8357e-02,  ...,  4.1148e-02,\n",
              "           5.2270e-02,  2.0000e+00],\n",
              "         [-1.3412e-01,  1.4246e-01,  2.7243e-01,  ...,  7.1054e-02,\n",
              "           9.9147e-05,  2.0000e+00],\n",
              "         [-2.3606e-01,  1.1012e-01,  2.7517e-01,  ...,  7.3812e-02,\n",
              "           4.3841e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0367, -0.1585, -0.0588,  ...,  0.0616,  0.2068,  2.0000],\n",
              "         [ 0.1312, -0.1252, -0.0768,  ...,  0.2977,  0.1532,  2.0000],\n",
              "         [ 0.0720, -0.1230, -0.0835,  ...,  0.3941,  0.0815,  2.0000],\n",
              "         ...,\n",
              "         [-0.1832,  0.0179,  0.1901,  ...,  0.1035, -0.0444,  2.0000],\n",
              "         [-0.2387,  0.0344,  0.1920,  ...,  0.0893, -0.0695,  2.0000],\n",
              "         [-0.2627,  0.0043,  0.2284,  ...,  0.0295, -0.0381,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0226, -0.1272, -0.0265,  ...,  0.0441,  0.2121,  2.0000],\n",
              "         [ 0.1280, -0.0331,  0.0049,  ...,  0.2305,  0.1220,  2.0000],\n",
              "         [ 0.1293,  0.0208,  0.0311,  ...,  0.3016, -0.0170,  2.0000],\n",
              "         ...,\n",
              "         [-0.0617,  0.1437,  0.2248,  ...,  0.0379,  0.0072,  2.0000],\n",
              "         [-0.2395,  0.1405,  0.3516,  ...,  0.0421, -0.0221,  2.0000],\n",
              "         [-0.2928,  0.1035,  0.3088,  ...,  0.0450, -0.0031,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0234, -0.1052, -0.0808,  ...,  0.0393,  0.2043,  2.0000],\n",
              "         [ 0.1702, -0.0184, -0.0657,  ...,  0.2051,  0.0915,  2.0000],\n",
              "         [ 0.1604,  0.0336, -0.0544,  ...,  0.2928, -0.0750,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0910,  0.0911,  0.0432,  ...,  0.0393,  0.0705,  2.0000],\n",
              "         [-0.1314,  0.1354,  0.2537,  ...,  0.0960, -0.0045,  2.0000],\n",
              "         [-0.2422,  0.0752,  0.2790,  ...,  0.0804, -0.0061,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0152, -0.1189, -0.0376,  ...,  0.0368,  0.2017,  2.0000],\n",
              "         [ 0.1375, -0.0107, -0.0150,  ...,  0.2385,  0.0852,  2.0000],\n",
              "         [ 0.1391,  0.0536, -0.0024,  ...,  0.3118, -0.0559,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0127,  0.1280,  0.1395,  ...,  0.0383,  0.0258,  2.0000],\n",
              "         [-0.2031,  0.1214,  0.3264,  ...,  0.0604, -0.0159,  2.0000],\n",
              "         [-0.2706,  0.0921,  0.2989,  ...,  0.0470, -0.0078,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0070, -0.1086, -0.0649,  ...,  0.0216,  0.1958,  2.0000],\n",
              "         [ 0.1717, -0.0076, -0.0419,  ...,  0.2160,  0.0409,  2.0000],\n",
              "         [ 0.1748,  0.0452, -0.0414,  ...,  0.2806, -0.0999,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0743,  0.0569,  0.0337,  ...,  0.0190,  0.0772,  2.0000],\n",
              "         [-0.1405,  0.1195,  0.3078,  ...,  0.0711, -0.0075,  2.0000],\n",
              "         [-0.2632,  0.0847,  0.2979,  ...,  0.0588, -0.0080,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0242, -0.1333, -0.0258,  ...,  0.0460,  0.2114,  2.0000],\n",
              "         [ 0.1370, -0.0456, -0.0093,  ...,  0.2560,  0.1355,  2.0000],\n",
              "         [ 0.1211, -0.0027,  0.0117,  ...,  0.3399,  0.0156,  2.0000],\n",
              "         ...,\n",
              "         [-0.1101,  0.1279,  0.2357,  ...,  0.0696,  0.0031,  2.0000],\n",
              "         [-0.2506,  0.1146,  0.3240,  ...,  0.0588, -0.0272,  2.0000],\n",
              "         [-0.3002,  0.0884,  0.2954,  ...,  0.0496, -0.0133,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0171, -0.1227, -0.0369,  ...,  0.0498,  0.2148,  2.0000],\n",
              "         [ 0.1448, -0.0251, -0.0144,  ...,  0.2351,  0.1248,  2.0000],\n",
              "         [ 0.1351,  0.0338,  0.0079,  ...,  0.3112, -0.0244,  2.0000],\n",
              "         ...,\n",
              "         [-0.0040,  0.1445,  0.1584,  ...,  0.0360,  0.0357,  2.0000],\n",
              "         [-0.2037,  0.1439,  0.3124,  ...,  0.0583, -0.0026,  2.0000],\n",
              "         [-0.2628,  0.1110,  0.2871,  ...,  0.0665,  0.0056,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0191, -0.1323, -0.0317,  ...,  0.0444,  0.2100,  2.0000],\n",
              "         [ 0.1465, -0.0318, -0.0098,  ...,  0.2639,  0.1237,  2.0000],\n",
              "         [ 0.1435,  0.0218,  0.0101,  ...,  0.3442, -0.0102,  2.0000],\n",
              "         ...,\n",
              "         [-0.0477,  0.1265,  0.1908,  ...,  0.0829,  0.0163,  2.0000],\n",
              "         [-0.2219,  0.1190,  0.3159,  ...,  0.0717, -0.0186,  2.0000],\n",
              "         [-0.2798,  0.0921,  0.2893,  ...,  0.0571, -0.0092,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0300, -0.1562, -0.0480,  ...,  0.0555,  0.2128,  2.0000],\n",
              "         [ 0.1482, -0.0973, -0.0748,  ...,  0.2859,  0.1526,  2.0000],\n",
              "         [ 0.1061, -0.0912, -0.0827,  ...,  0.3795,  0.0571,  2.0000],\n",
              "         ...,\n",
              "         [-0.1236,  0.0095,  0.1847,  ...,  0.1068,  0.0234,  2.0000],\n",
              "         [-0.2237,  0.0123,  0.2346,  ...,  0.0789, -0.0224,  2.0000],\n",
              "         [-0.2758,  0.0213,  0.2499,  ...,  0.0369, -0.0185,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0022, -0.1233, -0.0498,  ...,  0.0558,  0.2153,  2.0000],\n",
              "         [ 0.1602, -0.0253, -0.0347,  ...,  0.2327,  0.1212,  2.0000],\n",
              "         [ 0.1522,  0.0314, -0.0132,  ...,  0.3194, -0.0362,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0483,  0.1110,  0.0890,  ...,  0.0431,  0.0647,  2.0000],\n",
              "         [-0.1576,  0.1278,  0.2668,  ...,  0.0701,  0.0107,  2.0000],\n",
              "         [-0.2480,  0.1005,  0.2662,  ...,  0.0738,  0.0063,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0414, -0.1519, -0.0875,  ...,  0.0275,  0.1978,  2.0000],\n",
              "         [ 0.2537, -0.0520, -0.0896,  ...,  0.1934,  0.0316,  2.0000],\n",
              "         [ 0.2416, -0.0105, -0.0818,  ...,  0.2535, -0.1026,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1954, -0.0208, -0.0394,  ...,  0.0500,  0.0328,  2.0000],\n",
              "         [-0.0299,  0.0462,  0.2090,  ...,  0.1033, -0.0431,  2.0000],\n",
              "         [-0.2318,  0.0367,  0.2837,  ...,  0.0798, -0.0204,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.0927e-03, -1.1004e-01, -4.6651e-02,  ...,  4.0331e-02,\n",
              "           2.0486e-01,  3.0000e+00],\n",
              "         [ 1.6821e-01, -4.9000e-03, -3.3103e-02,  ...,  2.5185e-01,\n",
              "           6.7321e-02,  3.0000e+00],\n",
              "         [ 1.8028e-01,  5.5705e-02, -2.8895e-02,  ...,  3.0979e-01,\n",
              "          -7.1985e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 8.9481e-02,  8.1970e-02,  4.6947e-02,  ...,  4.3503e-02,\n",
              "           6.5127e-02,  3.0000e+00],\n",
              "         [-1.4431e-01,  1.2616e-01,  3.0579e-01,  ...,  9.7263e-02,\n",
              "           7.3646e-04,  3.0000e+00],\n",
              "         [-2.4929e-01,  1.0779e-01,  2.9013e-01,  ...,  6.3018e-02,\n",
              "           8.1485e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-8.1504e-03, -1.1439e-01, -3.8759e-02,  ...,  4.1602e-02,\n",
              "           2.0823e-01,  2.0000e+00],\n",
              "         [ 1.5362e-01, -1.0182e-02, -2.1244e-02,  ...,  2.4510e-01,\n",
              "           8.9432e-02,  2.0000e+00],\n",
              "         [ 1.6762e-01,  5.7939e-02, -1.3737e-02,  ...,  3.1199e-01,\n",
              "          -5.9535e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 4.5512e-02,  1.1014e-01,  1.0622e-01,  ...,  4.2231e-02,\n",
              "           5.4060e-02,  2.0000e+00],\n",
              "         [-1.7896e-01,  1.2461e-01,  3.1835e-01,  ...,  8.5544e-02,\n",
              "           1.8733e-03,  2.0000e+00],\n",
              "         [-2.5501e-01,  1.0917e-01,  2.9149e-01,  ...,  5.7722e-02,\n",
              "           7.8117e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0131, -0.1244, -0.0297,  ...,  0.0444,  0.2104,  2.0000],\n",
              "         [ 0.1527, -0.0252, -0.0060,  ...,  0.2632,  0.1173,  2.0000],\n",
              "         [ 0.1576,  0.0388,  0.0076,  ...,  0.3346, -0.0208,  2.0000],\n",
              "         ...,\n",
              "         [-0.0080,  0.1250,  0.1792,  ...,  0.0788,  0.0286,  2.0000],\n",
              "         [-0.2110,  0.1309,  0.3296,  ...,  0.0792, -0.0076,  2.0000],\n",
              "         [-0.2676,  0.1080,  0.2977,  ...,  0.0577,  0.0042,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1957e-02, -1.2129e-01, -3.0159e-02,  ...,  4.2738e-02,\n",
              "           2.1124e-01,  1.0000e+00],\n",
              "         [ 1.5203e-01, -2.1684e-02, -8.5178e-03,  ...,  2.5829e-01,\n",
              "           1.1466e-01,  1.0000e+00],\n",
              "         [ 1.5935e-01,  5.0240e-02,  8.0978e-03,  ...,  3.2774e-01,\n",
              "          -2.9703e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 1.6962e-02,  1.2065e-01,  1.5807e-01,  ...,  6.2185e-02,\n",
              "           3.9500e-02,  1.0000e+00],\n",
              "         [-1.9768e-01,  1.2540e-01,  3.2775e-01,  ...,  7.9300e-02,\n",
              "          -2.3081e-04,  1.0000e+00],\n",
              "         [-2.6102e-01,  1.0925e-01,  2.9696e-01,  ...,  5.8657e-02,\n",
              "           8.6142e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0242, -0.1291, -0.0249,  ...,  0.0434,  0.2080,  1.0000],\n",
              "         [ 0.1255, -0.0453,  0.0014,  ...,  0.2394,  0.1285,  1.0000],\n",
              "         [ 0.1167,  0.0053,  0.0228,  ...,  0.3221, -0.0030,  1.0000],\n",
              "         ...,\n",
              "         [-0.1034,  0.1364,  0.2516,  ...,  0.0687,  0.0011,  1.0000],\n",
              "         [-0.2558,  0.1278,  0.3543,  ...,  0.0564, -0.0280,  1.0000],\n",
              "         [-0.3036,  0.0972,  0.3079,  ...,  0.0429, -0.0110,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0305, -0.1566, -0.0394,  ...,  0.0599,  0.2150,  1.0000],\n",
              "         [ 0.1673, -0.0860, -0.0494,  ...,  0.2919,  0.1549,  1.0000],\n",
              "         [ 0.1254, -0.0736, -0.0472,  ...,  0.3835,  0.0572,  1.0000],\n",
              "         ...,\n",
              "         [-0.1274,  0.0318,  0.2137,  ...,  0.0899,  0.0057,  1.0000],\n",
              "         [-0.2294,  0.0350,  0.2467,  ...,  0.0765, -0.0320,  1.0000],\n",
              "         [-0.2721,  0.0451,  0.2573,  ...,  0.0439, -0.0138,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0187, -0.1315, -0.0322,  ...,  0.0545,  0.2169,  1.0000],\n",
              "         [ 0.1622, -0.0364, -0.0163,  ...,  0.2750,  0.1325,  1.0000],\n",
              "         [ 0.1558,  0.0244,  0.0046,  ...,  0.3626, -0.0117,  1.0000],\n",
              "         ...,\n",
              "         [-0.0615,  0.1324,  0.2068,  ...,  0.0769,  0.0036,  1.0000],\n",
              "         [-0.2202,  0.1302,  0.3062,  ...,  0.0755, -0.0232,  1.0000],\n",
              "         [-0.2706,  0.1000,  0.2875,  ...,  0.0727,  0.0023,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0241, -0.1321, -0.0268,  ...,  0.0449,  0.2097,  1.0000],\n",
              "         [ 0.1337, -0.0476, -0.0089,  ...,  0.2563,  0.1325,  1.0000],\n",
              "         [ 0.1184, -0.0070,  0.0092,  ...,  0.3420,  0.0112,  1.0000],\n",
              "         ...,\n",
              "         [-0.1169,  0.1276,  0.2407,  ...,  0.0839, -0.0029,  1.0000],\n",
              "         [-0.2529,  0.1164,  0.3302,  ...,  0.0649, -0.0332,  1.0000],\n",
              "         [-0.3012,  0.0886,  0.2986,  ...,  0.0477, -0.0167,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0237, -0.1380, -0.0285,  ...,  0.0540,  0.2157,  1.0000],\n",
              "         [ 0.1516, -0.0465, -0.0099,  ...,  0.2576,  0.1387,  1.0000],\n",
              "         [ 0.1364, -0.0012,  0.0135,  ...,  0.3392,  0.0102,  1.0000],\n",
              "         ...,\n",
              "         [-0.1190,  0.1420,  0.2297,  ...,  0.0608, -0.0110,  1.0000],\n",
              "         [-0.2500,  0.1215,  0.3104,  ...,  0.0589, -0.0363,  1.0000],\n",
              "         [-0.2840,  0.0969,  0.2873,  ...,  0.0620, -0.0075,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0201, -0.1275, -0.0279,  ...,  0.0397,  0.2064,  1.0000],\n",
              "         [ 0.1322, -0.0333, -0.0013,  ...,  0.2441,  0.1174,  1.0000],\n",
              "         [ 0.1266,  0.0254,  0.0185,  ...,  0.3250, -0.0171,  1.0000],\n",
              "         ...,\n",
              "         [-0.0567,  0.1315,  0.2083,  ...,  0.0705,  0.0124,  1.0000],\n",
              "         [-0.2351,  0.1251,  0.3405,  ...,  0.0617, -0.0198,  1.0000],\n",
              "         [-0.2894,  0.0976,  0.3030,  ...,  0.0451, -0.0090,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0317, -0.1543, -0.0619,  ...,  0.0683,  0.2048,  1.0000],\n",
              "         [ 0.1537, -0.1161, -0.0619,  ...,  0.2951,  0.1677,  1.0000],\n",
              "         [ 0.0881, -0.1060, -0.0619,  ...,  0.4114,  0.0835,  1.0000],\n",
              "         ...,\n",
              "         [-0.1913,  0.0401,  0.1863,  ...,  0.0898, -0.0565,  1.0000],\n",
              "         [-0.2518,  0.0642,  0.1947,  ...,  0.0779, -0.0665,  1.0000],\n",
              "         [-0.2453,  0.0361,  0.2260,  ...,  0.0243, -0.0356,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0248, -0.1577, -0.0635,  ...,  0.0535,  0.1851,  1.0000],\n",
              "         [ 0.1082, -0.1339, -0.0629,  ...,  0.2433,  0.1504,  1.0000],\n",
              "         [ 0.0413, -0.1344, -0.0802,  ...,  0.3379,  0.0916,  1.0000],\n",
              "         ...,\n",
              "         [-0.2244,  0.0482,  0.2032,  ..., -0.0081, -0.0892,  1.0000],\n",
              "         [-0.2622,  0.0632,  0.2083,  ...,  0.0031, -0.0840,  1.0000],\n",
              "         [-0.2249,  0.0372,  0.2347,  ..., -0.0262, -0.0544,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0153, -0.1184, -0.0391,  ...,  0.0501,  0.2126,  1.0000],\n",
              "         [ 0.1525, -0.0073, -0.0153,  ...,  0.2561,  0.1064,  1.0000],\n",
              "         [ 0.1582,  0.0613,  0.0038,  ...,  0.3272, -0.0486,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0014,  0.1300,  0.1626,  ...,  0.0507,  0.0173,  1.0000],\n",
              "         [-0.1982,  0.1391,  0.3184,  ...,  0.0660, -0.0107,  1.0000],\n",
              "         [-0.2610,  0.1086,  0.2949,  ...,  0.0698,  0.0073,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.6433e-04, -1.1041e-01, -4.3400e-02,  ...,  4.1458e-02,\n",
              "           2.0604e-01,  1.0000e+00],\n",
              "         [ 1.7342e-01, -3.7893e-03, -3.1296e-02,  ...,  2.5113e-01,\n",
              "           7.8199e-02,  1.0000e+00],\n",
              "         [ 1.8435e-01,  6.0367e-02, -2.6252e-02,  ...,  3.1197e-01,\n",
              "          -6.5265e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 8.7696e-02,  8.9452e-02,  5.6419e-02,  ...,  4.6256e-02,\n",
              "           6.6938e-02,  1.0000e+00],\n",
              "         [-1.4948e-01,  1.2462e-01,  3.0494e-01,  ...,  1.0082e-01,\n",
              "           3.0720e-03,  1.0000e+00],\n",
              "         [-2.4475e-01,  1.0899e-01,  2.8915e-01,  ...,  6.3175e-02,\n",
              "           7.3012e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0086, -0.1178, -0.0368,  ...,  0.0457,  0.2085,  1.0000],\n",
              "         [ 0.1571, -0.0141, -0.0217,  ...,  0.2572,  0.1017,  1.0000],\n",
              "         [ 0.1654,  0.0553, -0.0109,  ...,  0.3307, -0.0433,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0320,  0.1196,  0.1339,  ...,  0.0662,  0.0433,  1.0000],\n",
              "         [-0.1896,  0.1208,  0.3189,  ...,  0.0903, -0.0020,  1.0000],\n",
              "         [-0.2548,  0.1079,  0.2879,  ...,  0.0613,  0.0061,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0168, -0.1381, -0.0250,  ...,  0.0546,  0.2138,  1.0000],\n",
              "         [ 0.1549, -0.0597, -0.0155,  ...,  0.2498,  0.1579,  1.0000],\n",
              "         [ 0.1225, -0.0347,  0.0023,  ...,  0.3408,  0.0524,  1.0000],\n",
              "         ...,\n",
              "         [-0.0784,  0.1062,  0.2214,  ...,  0.0968,  0.0397,  1.0000],\n",
              "         [-0.2360,  0.1041,  0.3243,  ...,  0.1053,  0.0043,  1.0000],\n",
              "         [-0.3104,  0.0831,  0.2948,  ...,  0.0743, -0.0033,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0321, -0.1468, -0.0400,  ...,  0.0622,  0.2172,  1.0000],\n",
              "         [ 0.1739, -0.0735, -0.0581,  ...,  0.2955,  0.1548,  1.0000],\n",
              "         [ 0.1321, -0.0630, -0.0538,  ...,  0.3917,  0.0538,  1.0000],\n",
              "         ...,\n",
              "         [-0.1110,  0.0437,  0.1943,  ...,  0.0976,  0.0141,  1.0000],\n",
              "         [-0.2344,  0.0470,  0.2527,  ...,  0.0790, -0.0325,  1.0000],\n",
              "         [-0.2826,  0.0564,  0.2629,  ...,  0.0449, -0.0122,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9687e-02, -1.2634e-01, -2.7777e-02,  ...,  3.9950e-02,\n",
              "           2.0780e-01,  1.0000e+00],\n",
              "         [ 1.3208e-01, -3.1068e-02,  4.3082e-04,  ...,  2.4519e-01,\n",
              "           1.1897e-01,  1.0000e+00],\n",
              "         [ 1.2775e-01,  2.9660e-02,  2.2497e-02,  ...,  3.2357e-01,\n",
              "          -1.9003e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-4.0919e-02,  1.3258e-01,  1.9831e-01,  ...,  6.3558e-02,\n",
              "           1.8096e-02,  1.0000e+00],\n",
              "         [-2.3190e-01,  1.3066e-01,  3.3888e-01,  ...,  5.7592e-02,\n",
              "          -1.5127e-02,  1.0000e+00],\n",
              "         [-2.8986e-01,  9.9407e-02,  3.0165e-01,  ...,  4.7016e-02,\n",
              "          -8.3321e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0230, -0.1283, -0.0251,  ...,  0.0410,  0.2074,  1.0000],\n",
              "         [ 0.1289, -0.0417,  0.0045,  ...,  0.2365,  0.1234,  1.0000],\n",
              "         [ 0.1196,  0.0106,  0.0272,  ...,  0.3162, -0.0058,  1.0000],\n",
              "         ...,\n",
              "         [-0.0978,  0.1400,  0.2423,  ...,  0.0631,  0.0045,  1.0000],\n",
              "         [-0.2518,  0.1344,  0.3476,  ...,  0.0536, -0.0284,  1.0000],\n",
              "         [-0.3006,  0.1001,  0.3062,  ...,  0.0434, -0.0102,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0180, -0.1408, -0.0340,  ...,  0.0518,  0.2161,  1.0000],\n",
              "         [ 0.1497, -0.0443, -0.0124,  ...,  0.2519,  0.1387,  1.0000],\n",
              "         [ 0.1398,  0.0030,  0.0110,  ...,  0.3329,  0.0038,  1.0000],\n",
              "         ...,\n",
              "         [-0.0490,  0.1419,  0.1787,  ...,  0.0473,  0.0315,  1.0000],\n",
              "         [-0.2136,  0.1271,  0.2911,  ...,  0.0572, -0.0090,  1.0000],\n",
              "         [-0.2731,  0.0974,  0.2738,  ...,  0.0657, -0.0034,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0197, -0.1302, -0.0275,  ...,  0.0440,  0.2101,  1.0000],\n",
              "         [ 0.1385, -0.0351, -0.0042,  ...,  0.2534,  0.1273,  1.0000],\n",
              "         [ 0.1355,  0.0203,  0.0172,  ...,  0.3332, -0.0058,  1.0000],\n",
              "         ...,\n",
              "         [-0.0629,  0.1323,  0.2200,  ...,  0.0767,  0.0124,  1.0000],\n",
              "         [-0.2347,  0.1227,  0.3385,  ...,  0.0681, -0.0176,  1.0000],\n",
              "         [-0.2881,  0.0939,  0.2994,  ...,  0.0546, -0.0082,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 3.1198e-02, -1.2628e-01, -8.5836e-02,  ...,  3.7206e-02,\n",
              "           2.0670e-01,  1.0000e+00],\n",
              "         [ 2.2862e-01,  3.3384e-03, -7.0829e-02,  ...,  2.4482e-01,\n",
              "           6.0517e-02,  1.0000e+00],\n",
              "         [ 2.1550e-01,  3.5638e-02, -6.1865e-02,  ...,  3.2317e-01,\n",
              "          -7.5345e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 2.0032e-01,  1.7645e-02, -4.9614e-02,  ...,  5.8436e-02,\n",
              "           8.6401e-02,  1.0000e+00],\n",
              "         [-4.1354e-02,  9.2401e-02,  2.2400e-01,  ...,  1.0432e-01,\n",
              "           5.9990e-03,  1.0000e+00],\n",
              "         [-2.2762e-01,  7.8340e-02,  2.7112e-01,  ...,  7.9205e-02,\n",
              "          -7.9715e-05,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0140, -0.1212, -0.0353,  ...,  0.0480,  0.2185,  1.0000],\n",
              "         [ 0.1475, -0.0240, -0.0134,  ...,  0.2459,  0.1203,  1.0000],\n",
              "         [ 0.1477,  0.0414,  0.0075,  ...,  0.3205, -0.0328,  1.0000],\n",
              "         ...,\n",
              "         [-0.0012,  0.1390,  0.1626,  ...,  0.0508,  0.0309,  1.0000],\n",
              "         [-0.2088,  0.1455,  0.3154,  ...,  0.0677, -0.0093,  1.0000],\n",
              "         [-0.2662,  0.1086,  0.2949,  ...,  0.0712,  0.0048,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0198, -0.1221, -0.0313,  ...,  0.0380,  0.2067,  1.0000],\n",
              "         [ 0.1260, -0.0182, -0.0030,  ...,  0.2361,  0.1047,  1.0000],\n",
              "         [ 0.1287,  0.0488,  0.0164,  ...,  0.3095, -0.0374,  1.0000],\n",
              "         ...,\n",
              "         [-0.0166,  0.1274,  0.1744,  ...,  0.0401,  0.0250,  1.0000],\n",
              "         [-0.2210,  0.1232,  0.3391,  ...,  0.0492, -0.0126,  1.0000],\n",
              "         [-0.2816,  0.0960,  0.3045,  ...,  0.0436, -0.0023,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0254, -0.1477, -0.0439,  ...,  0.0674,  0.2134,  1.0000],\n",
              "         [ 0.1895, -0.0709, -0.0559,  ...,  0.2979,  0.1456,  1.0000],\n",
              "         [ 0.1536, -0.0571, -0.0508,  ...,  0.3899,  0.0424,  1.0000],\n",
              "         ...,\n",
              "         [-0.0908,  0.0345,  0.1849,  ...,  0.0853,  0.0049,  1.0000],\n",
              "         [-0.2047,  0.0477,  0.2256,  ...,  0.0792, -0.0306,  1.0000],\n",
              "         [-0.2516,  0.0513,  0.2440,  ...,  0.0541, -0.0127,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0066, -0.1194, -0.0609,  ...,  0.0528,  0.2090,  1.0000],\n",
              "         [ 0.1695, -0.0108, -0.0515,  ...,  0.2395,  0.1040,  1.0000],\n",
              "         [ 0.1629,  0.0419, -0.0341,  ...,  0.3264, -0.0572,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0685,  0.1003,  0.0837,  ...,  0.0492,  0.0385,  1.0000],\n",
              "         [-0.1381,  0.1342,  0.2607,  ...,  0.0718, -0.0054,  1.0000],\n",
              "         [-0.2400,  0.0983,  0.2613,  ...,  0.0746,  0.0022,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7683e-02, -1.2676e-01, -2.7238e-02,  ...,  4.3559e-02,\n",
              "           2.0887e-01,  2.0000e+00],\n",
              "         [ 1.4465e-01, -3.2036e-02, -9.9876e-04,  ...,  2.5889e-01,\n",
              "           1.1587e-01,  2.0000e+00],\n",
              "         [ 1.4781e-01,  2.7253e-02,  1.2480e-02,  ...,  3.3126e-01,\n",
              "          -1.9285e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.9758e-02,  1.2371e-01,  1.9834e-01,  ...,  7.4788e-02,\n",
              "           1.6878e-02,  2.0000e+00],\n",
              "         [-2.2442e-01,  1.3049e-01,  3.3906e-01,  ...,  7.2767e-02,\n",
              "          -1.4340e-02,  2.0000e+00],\n",
              "         [-2.7424e-01,  1.0867e-01,  2.9856e-01,  ...,  5.1032e-02,\n",
              "           3.8592e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.4253e-02, -1.6101e-01, -4.5420e-02,  ...,  6.5142e-02,\n",
              "           2.1401e-01,  3.0000e+00],\n",
              "         [ 1.7437e-01, -9.7166e-02, -5.5298e-02,  ...,  2.9873e-01,\n",
              "           1.6300e-01,  3.0000e+00],\n",
              "         [ 1.2659e-01, -9.1387e-02, -5.1716e-02,  ...,  3.9249e-01,\n",
              "           7.0780e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3550e-01,  2.8410e-02,  2.0113e-01,  ...,  9.5090e-02,\n",
              "          -2.3947e-03,  3.0000e+00],\n",
              "         [-2.3596e-01,  4.2226e-02,  2.2069e-01,  ...,  7.8525e-02,\n",
              "          -3.9154e-02,  3.0000e+00],\n",
              "         [-2.6465e-01,  3.1058e-02,  2.4167e-01,  ...,  3.9928e-02,\n",
              "          -1.9196e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.9015e-02, -1.2915e-01, -3.1290e-02,  ...,  6.3854e-02,\n",
              "           2.1243e-01,  3.0000e+00],\n",
              "         [ 1.6759e-01, -5.0361e-02, -2.3400e-02,  ...,  2.6735e-01,\n",
              "           1.4466e-01,  3.0000e+00],\n",
              "         [ 1.4375e-01, -1.6144e-02, -2.3081e-03,  ...,  3.6119e-01,\n",
              "           2.5044e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.1283e-01,  1.2245e-01,  2.2500e-01,  ...,  7.7161e-02,\n",
              "          -7.8132e-03,  3.0000e+00],\n",
              "         [-2.4994e-01,  1.0480e-01,  2.9515e-01,  ...,  7.0926e-02,\n",
              "          -3.6025e-02,  3.0000e+00],\n",
              "         [-2.8507e-01,  9.4286e-02,  2.7777e-01,  ...,  5.9934e-02,\n",
              "          -7.6208e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0212, -0.1245, -0.0361,  ...,  0.0507,  0.2120,  3.0000],\n",
              "         [ 0.1342, -0.0207, -0.0107,  ...,  0.2486,  0.1086,  3.0000],\n",
              "         [ 0.1419,  0.0469,  0.0059,  ...,  0.3177, -0.0437,  3.0000],\n",
              "         ...,\n",
              "         [-0.0286,  0.1398,  0.1876,  ...,  0.0480,  0.0058,  3.0000],\n",
              "         [-0.2257,  0.1441,  0.3339,  ...,  0.0604, -0.0197,  3.0000],\n",
              "         [-0.2765,  0.1069,  0.3030,  ...,  0.0675,  0.0054,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.0476e-03, -1.0948e-01, -5.3098e-02,  ...,  2.9424e-02,\n",
              "           1.9743e-01,  3.0000e+00],\n",
              "         [ 1.5029e-01, -8.5247e-03, -2.4856e-02,  ...,  2.2546e-01,\n",
              "           5.3960e-02,  3.0000e+00],\n",
              "         [ 1.5994e-01,  5.3957e-02, -2.1106e-02,  ...,  2.9125e-01,\n",
              "          -8.7839e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 5.2135e-02,  8.2200e-02,  6.7081e-02,  ...,  1.9493e-02,\n",
              "           7.2071e-02,  3.0000e+00],\n",
              "         [-1.6496e-01,  1.2415e-01,  3.1512e-01,  ...,  6.9024e-02,\n",
              "          -4.4335e-04,  3.0000e+00],\n",
              "         [-2.6857e-01,  8.9169e-02,  3.0039e-01,  ...,  5.3649e-02,\n",
              "          -2.2873e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.4525e-02, -1.3999e-01, -3.2226e-02,  ...,  5.3931e-02,\n",
              "           2.1626e-01,  3.0000e+00],\n",
              "         [ 1.6062e-01, -4.3791e-02, -1.4467e-02,  ...,  2.7206e-01,\n",
              "           1.2966e-01,  3.0000e+00],\n",
              "         [ 1.4947e-01,  1.0853e-02,  4.1110e-03,  ...,  3.5141e-01,\n",
              "          -9.2601e-04,  3.0000e+00],\n",
              "         ...,\n",
              "         [-6.9716e-02,  1.3530e-01,  1.9298e-01,  ...,  6.0753e-02,\n",
              "           7.7014e-03,  3.0000e+00],\n",
              "         [-2.2845e-01,  1.2738e-01,  2.9197e-01,  ...,  6.3430e-02,\n",
              "          -2.1261e-02,  3.0000e+00],\n",
              "         [-2.7466e-01,  9.7822e-02,  2.7995e-01,  ...,  6.7880e-02,\n",
              "           2.0904e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0320, -0.1217, -0.0297,  ...,  0.0560,  0.2061,  3.0000],\n",
              "         [ 0.1363, -0.0542, -0.0292,  ...,  0.2577,  0.1413,  3.0000],\n",
              "         [ 0.1171, -0.0234, -0.0150,  ...,  0.3509,  0.0257,  3.0000],\n",
              "         ...,\n",
              "         [-0.1483,  0.1118,  0.2488,  ...,  0.0884, -0.0073,  3.0000],\n",
              "         [-0.2660,  0.0990,  0.3138,  ...,  0.0691, -0.0375,  3.0000],\n",
              "         [-0.3075,  0.0874,  0.2911,  ...,  0.0392, -0.0178,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0346, -0.1396, -0.0361,  ...,  0.0610,  0.2122,  3.0000],\n",
              "         [ 0.1629, -0.0599, -0.0376,  ...,  0.2712,  0.1477,  3.0000],\n",
              "         [ 0.1266, -0.0371, -0.0279,  ...,  0.3569,  0.0428,  3.0000],\n",
              "         ...,\n",
              "         [-0.1360,  0.0757,  0.2232,  ...,  0.0762, -0.0046,  3.0000],\n",
              "         [-0.2576,  0.0661,  0.2678,  ...,  0.0632, -0.0431,  3.0000],\n",
              "         [-0.2854,  0.0704,  0.2680,  ...,  0.0441, -0.0161,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0218, -0.1388, -0.0294,  ...,  0.0483,  0.2106,  3.0000],\n",
              "         [ 0.1481, -0.0498, -0.0182,  ...,  0.2730,  0.1336,  3.0000],\n",
              "         [ 0.1308, -0.0132, -0.0064,  ...,  0.3601,  0.0192,  3.0000],\n",
              "         ...,\n",
              "         [-0.0993,  0.0994,  0.2135,  ...,  0.0877,  0.0070,  3.0000],\n",
              "         [-0.2332,  0.0873,  0.2991,  ...,  0.0692, -0.0262,  3.0000],\n",
              "         [-0.2899,  0.0810,  0.2889,  ...,  0.0553, -0.0139,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.5261e-02, -1.3973e-01, -2.8351e-02,  ...,  5.6229e-02,\n",
              "           2.1721e-01,  3.0000e+00],\n",
              "         [ 1.5506e-01, -4.8734e-02, -1.1684e-02,  ...,  2.5771e-01,\n",
              "           1.4262e-01,  3.0000e+00],\n",
              "         [ 1.4042e-01,  3.4423e-05,  1.0359e-02,  ...,  3.4190e-01,\n",
              "           1.0542e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0371e-01,  1.4230e-01,  2.2241e-01,  ...,  6.3237e-02,\n",
              "          -1.1730e-03,  3.0000e+00],\n",
              "         [-2.4958e-01,  1.2452e-01,  3.0895e-01,  ...,  6.1731e-02,\n",
              "          -2.9106e-02,  3.0000e+00],\n",
              "         [-2.8343e-01,  9.5526e-02,  2.8509e-01,  ...,  6.3509e-02,\n",
              "          -1.9630e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1634e-02, -1.2312e-01, -2.8403e-02,  ...,  3.7666e-02,\n",
              "           2.0537e-01,  3.0000e+00],\n",
              "         [ 1.2429e-01, -3.0135e-02,  2.5529e-03,  ...,  2.3096e-01,\n",
              "           1.1311e-01,  3.0000e+00],\n",
              "         [ 1.1954e-01,  3.0528e-02,  2.0979e-02,  ...,  3.0850e-01,\n",
              "          -2.4331e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-5.0361e-02,  1.3739e-01,  2.0802e-01,  ...,  4.8455e-02,\n",
              "           1.7226e-02,  3.0000e+00],\n",
              "         [-2.3659e-01,  1.3775e-01,  3.4356e-01,  ...,  4.5903e-02,\n",
              "          -1.6156e-02,  3.0000e+00],\n",
              "         [-2.9276e-01,  1.0356e-01,  3.0553e-01,  ...,  3.9527e-02,\n",
              "          -4.7374e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.0075e-02, -1.1768e-01, -3.3948e-02,  ...,  4.3578e-02,\n",
              "           2.0890e-01,  3.0000e+00],\n",
              "         [ 1.5425e-01, -1.1454e-02, -1.3261e-02,  ...,  2.5030e-01,\n",
              "           1.0145e-01,  3.0000e+00],\n",
              "         [ 1.6341e-01,  5.8988e-02, -2.4668e-03,  ...,  3.1795e-01,\n",
              "          -4.5226e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 2.6058e-02,  1.1750e-01,  1.3733e-01,  ...,  4.9546e-02,\n",
              "           4.3086e-02,  3.0000e+00],\n",
              "         [-1.9122e-01,  1.2367e-01,  3.2417e-01,  ...,  7.9467e-02,\n",
              "          -4.3320e-05,  3.0000e+00],\n",
              "         [-2.5601e-01,  1.1117e-01,  2.9205e-01,  ...,  5.5952e-02,\n",
              "           8.1746e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.8699e-02, -1.2608e-01, -2.7833e-02,  ...,  4.7080e-02,\n",
              "           2.0544e-01,  3.0000e+00],\n",
              "         [ 1.3463e-01, -5.3443e-02, -1.7754e-02,  ...,  2.3906e-01,\n",
              "           1.3422e-01,  3.0000e+00],\n",
              "         [ 1.1403e-01, -2.2546e-02,  1.2557e-03,  ...,  3.3101e-01,\n",
              "           1.7095e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3377e-01,  1.2383e-01,  2.3966e-01,  ...,  6.8747e-02,\n",
              "           1.1916e-03,  3.0000e+00],\n",
              "         [-2.6077e-01,  1.1318e-01,  3.1840e-01,  ...,  5.4679e-02,\n",
              "          -3.5782e-02,  3.0000e+00],\n",
              "         [-3.0484e-01,  9.5075e-02,  2.9406e-01,  ...,  3.8459e-02,\n",
              "          -1.7722e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0363, -0.1515, -0.0508,  ...,  0.0661,  0.2128,  3.0000],\n",
              "         [ 0.1603, -0.0983, -0.0691,  ...,  0.3076,  0.1579,  3.0000],\n",
              "         [ 0.1118, -0.0963, -0.0696,  ...,  0.4122,  0.0694,  3.0000],\n",
              "         ...,\n",
              "         [-0.1465,  0.0169,  0.2055,  ...,  0.1171, -0.0104,  3.0000],\n",
              "         [-0.2466,  0.0287,  0.2189,  ...,  0.0893, -0.0439,  3.0000],\n",
              "         [-0.2705,  0.0382,  0.2437,  ...,  0.0377, -0.0182,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4213e-02, -1.3964e-01, -3.1101e-02,  ...,  5.6221e-02,\n",
              "           2.1698e-01,  3.0000e+00],\n",
              "         [ 1.5943e-01, -4.4364e-02, -1.9042e-02,  ...,  2.7151e-01,\n",
              "           1.3747e-01,  3.0000e+00],\n",
              "         [ 1.4533e-01,  3.0791e-04,  4.5246e-03,  ...,  3.5638e-01,\n",
              "           9.0078e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-8.4312e-02,  1.1738e-01,  2.0914e-01,  ...,  6.3467e-02,\n",
              "          -1.6029e-03,  3.0000e+00],\n",
              "         [-2.2802e-01,  1.1191e-01,  2.9549e-01,  ...,  6.5052e-02,\n",
              "          -2.9830e-02,  3.0000e+00],\n",
              "         [-2.7844e-01,  9.0141e-02,  2.8256e-01,  ...,  6.4114e-02,\n",
              "          -3.7446e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1268e-02, -1.2491e-01, -3.8485e-02,  ...,  5.3172e-02,\n",
              "           2.1401e-01,  3.0000e+00],\n",
              "         [ 1.4195e-01, -1.5551e-02, -1.4163e-02,  ...,  2.5241e-01,\n",
              "           1.1551e-01,  3.0000e+00],\n",
              "         [ 1.4647e-01,  4.8173e-02,  2.6318e-03,  ...,  3.2683e-01,\n",
              "          -3.1230e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.7706e-02,  1.3413e-01,  1.7171e-01,  ...,  5.7400e-02,\n",
              "           1.8402e-02,  3.0000e+00],\n",
              "         [-2.1961e-01,  1.3799e-01,  3.2441e-01,  ...,  7.0726e-02,\n",
              "          -1.6185e-02,  3.0000e+00],\n",
              "         [-2.7799e-01,  1.0267e-01,  2.9800e-01,  ...,  6.9232e-02,\n",
              "           4.8588e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0193, -0.1303, -0.0358,  ...,  0.0521,  0.2150,  3.0000],\n",
              "         [ 0.1439, -0.0287, -0.0137,  ...,  0.2509,  0.1260,  3.0000],\n",
              "         [ 0.1420,  0.0349,  0.0076,  ...,  0.3271, -0.0210,  3.0000],\n",
              "         ...,\n",
              "         [-0.0424,  0.1464,  0.1865,  ...,  0.0484,  0.0184,  3.0000],\n",
              "         [-0.2217,  0.1449,  0.3076,  ...,  0.0578, -0.0141,  3.0000],\n",
              "         [-0.2734,  0.1047,  0.2891,  ...,  0.0672,  0.0037,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1592, -0.0561,  ...,  0.0650,  0.2125,  3.0000],\n",
              "         [ 0.1520, -0.1086, -0.0697,  ...,  0.2976,  0.1569,  3.0000],\n",
              "         [ 0.1014, -0.1027, -0.0717,  ...,  0.3963,  0.0654,  3.0000],\n",
              "         ...,\n",
              "         [-0.1516,  0.0079,  0.1981,  ...,  0.0910, -0.0212,  3.0000],\n",
              "         [-0.2269,  0.0347,  0.1975,  ...,  0.0803, -0.0474,  3.0000],\n",
              "         [-0.2519,  0.0147,  0.2272,  ...,  0.0407, -0.0263,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0268, -0.1594, -0.0476,  ...,  0.0570,  0.2125,  3.0000],\n",
              "         [ 0.1516, -0.0993, -0.0759,  ...,  0.2889,  0.1501,  3.0000],\n",
              "         [ 0.1100, -0.0940, -0.0834,  ...,  0.3819,  0.0568,  3.0000],\n",
              "         ...,\n",
              "         [-0.1081,  0.0122,  0.1789,  ...,  0.1061,  0.0280,  3.0000],\n",
              "         [-0.2101,  0.0149,  0.2271,  ...,  0.0790, -0.0159,  3.0000],\n",
              "         [-0.2653,  0.0146,  0.2434,  ...,  0.0434, -0.0226,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0190, -0.1545, -0.0637,  ...,  0.0489,  0.1783,  3.0000],\n",
              "         [ 0.1046, -0.1311, -0.0556,  ...,  0.2294,  0.1457,  3.0000],\n",
              "         [ 0.0381, -0.1336, -0.0758,  ...,  0.3233,  0.0925,  3.0000],\n",
              "         ...,\n",
              "         [-0.2137,  0.0494,  0.2325,  ..., -0.0435, -0.0948,  3.0000],\n",
              "         [-0.2477,  0.0743,  0.2356,  ..., -0.0317, -0.0921,  3.0000],\n",
              "         [-0.2024,  0.0564,  0.2436,  ..., -0.0436, -0.0647,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0316, -0.1262, -0.0310,  ...,  0.0578,  0.2077,  3.0000],\n",
              "         [ 0.1456, -0.0572, -0.0351,  ...,  0.2732,  0.1401,  3.0000],\n",
              "         [ 0.1255, -0.0282, -0.0264,  ...,  0.3679,  0.0286,  3.0000],\n",
              "         ...,\n",
              "         [-0.1224,  0.0919,  0.2270,  ...,  0.0947,  0.0048,  3.0000],\n",
              "         [-0.2491,  0.0799,  0.2957,  ...,  0.0730, -0.0303,  3.0000],\n",
              "         [-0.2994,  0.0810,  0.2854,  ...,  0.0467, -0.0170,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0309, -0.1323, -0.0748,  ...,  0.0095,  0.1781,  3.0000],\n",
              "         [ 0.2250, -0.0183, -0.0606,  ...,  0.1861,  0.0120,  3.0000],\n",
              "         [ 0.2270,  0.0232, -0.0531,  ...,  0.2415, -0.1081,  3.0000],\n",
              "         ...,\n",
              "         [ 0.1246,  0.0036, -0.0373,  ...,  0.0415,  0.0732,  3.0000],\n",
              "         [-0.0834,  0.0928,  0.2606,  ...,  0.1061, -0.0291,  3.0000],\n",
              "         [-0.2611,  0.0638,  0.3033,  ...,  0.0743, -0.0211,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0337, -0.1445, -0.0367,  ...,  0.0623,  0.2158,  3.0000],\n",
              "         [ 0.1719, -0.0666, -0.0443,  ...,  0.2844,  0.1518,  3.0000],\n",
              "         [ 0.1325, -0.0480, -0.0394,  ...,  0.3717,  0.0506,  3.0000],\n",
              "         ...,\n",
              "         [-0.1119,  0.0706,  0.2015,  ...,  0.0868,  0.0129,  3.0000],\n",
              "         [-0.2400,  0.0722,  0.2573,  ...,  0.0743, -0.0328,  3.0000],\n",
              "         [-0.2825,  0.0622,  0.2611,  ...,  0.0495, -0.0172,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2795e-02, -1.3024e-01, -2.7186e-02,  ...,  4.3405e-02,\n",
              "           2.0809e-01,  3.0000e+00],\n",
              "         [ 1.3365e-01, -3.7172e-02, -3.4643e-03,  ...,  2.5278e-01,\n",
              "           1.2426e-01,  3.0000e+00],\n",
              "         [ 1.2673e-01,  1.5627e-02,  1.6685e-02,  ...,  3.3280e-01,\n",
              "          -4.5404e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-8.6425e-02,  1.3408e-01,  2.2706e-01,  ...,  7.8631e-02,\n",
              "           2.3306e-03,  3.0000e+00],\n",
              "         [-2.4403e-01,  1.2292e-01,  3.3969e-01,  ...,  6.4484e-02,\n",
              "          -2.7148e-02,  3.0000e+00],\n",
              "         [-2.9422e-01,  9.5582e-02,  3.0144e-01,  ...,  4.8599e-02,\n",
              "          -1.2111e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.2827e-02, -1.3163e-01, -2.5025e-02,  ...,  4.4901e-02,\n",
              "           2.0993e-01,  3.0000e+00],\n",
              "         [ 1.3657e-01, -4.2842e-02, -5.2258e-03,  ...,  2.5540e-01,\n",
              "           1.3249e-01,  3.0000e+00],\n",
              "         [ 1.2525e-01,  4.1192e-03,  1.6684e-02,  ...,  3.3789e-01,\n",
              "           7.8762e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0421e-01,  1.3221e-01,  2.4400e-01,  ...,  7.9788e-02,\n",
              "          -6.2423e-04,  3.0000e+00],\n",
              "         [-2.5007e-01,  1.2317e-01,  3.3827e-01,  ...,  6.5228e-02,\n",
              "          -2.9376e-02,  3.0000e+00],\n",
              "         [-2.9922e-01,  9.0742e-02,  3.0064e-01,  ...,  5.1766e-02,\n",
              "          -1.4720e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.7651e-02, -1.2788e-01, -2.6913e-02,  ...,  4.5298e-02,\n",
              "           2.1065e-01,  1.0000e+00],\n",
              "         [ 1.4599e-01, -3.4739e-02, -6.1564e-04,  ...,  2.5833e-01,\n",
              "           1.2184e-01,  1.0000e+00],\n",
              "         [ 1.4626e-01,  2.1845e-02,  1.3054e-02,  ...,  3.3289e-01,\n",
              "          -9.6568e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-4.4198e-02,  1.2669e-01,  2.1342e-01,  ...,  7.7864e-02,\n",
              "           1.5560e-02,  1.0000e+00],\n",
              "         [-2.2788e-01,  1.3059e-01,  3.4088e-01,  ...,  7.4922e-02,\n",
              "          -1.6448e-02,  1.0000e+00],\n",
              "         [-2.7630e-01,  1.0688e-01,  2.9991e-01,  ...,  5.3463e-02,\n",
              "           3.6642e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0163, -0.1209, -0.0364,  ...,  0.0371,  0.2042,  2.0000],\n",
              "         [ 0.1337, -0.0162, -0.0095,  ...,  0.2387,  0.0955,  2.0000],\n",
              "         [ 0.1346,  0.0488,  0.0060,  ...,  0.3122, -0.0495,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0055,  0.1254,  0.1484,  ...,  0.0440,  0.0259,  2.0000],\n",
              "         [-0.2074,  0.1233,  0.3240,  ...,  0.0583, -0.0140,  2.0000],\n",
              "         [-0.2761,  0.0934,  0.2971,  ...,  0.0464, -0.0057,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0362, -0.1333, -0.0900,  ...,  0.0385,  0.2058,  2.0000],\n",
              "         [ 0.2320, -0.0456, -0.0890,  ...,  0.2308,  0.0485,  2.0000],\n",
              "         [ 0.2043, -0.0074, -0.0825,  ...,  0.3113, -0.0919,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1987, -0.0029, -0.0021,  ...,  0.0717,  0.0488,  2.0000],\n",
              "         [-0.0360,  0.0553,  0.2147,  ...,  0.1213, -0.0204,  2.0000],\n",
              "         [-0.2290,  0.0531,  0.2678,  ...,  0.0955, -0.0075,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2560e-02, -1.3166e-01, -2.6897e-02,  ...,  4.3019e-02,\n",
              "           2.0855e-01,  2.0000e+00],\n",
              "         [ 1.3778e-01, -4.1344e-02, -5.8061e-03,  ...,  2.4990e-01,\n",
              "           1.2892e-01,  2.0000e+00],\n",
              "         [ 1.2390e-01,  3.5513e-03,  1.5436e-02,  ...,  3.3211e-01,\n",
              "           4.8670e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0793e-01,  1.3183e-01,  2.3164e-01,  ...,  7.1271e-02,\n",
              "          -1.9537e-03,  2.0000e+00],\n",
              "         [-2.5075e-01,  1.1846e-01,  3.2736e-01,  ...,  5.7074e-02,\n",
              "          -3.0976e-02,  2.0000e+00],\n",
              "         [-2.9698e-01,  9.2465e-02,  2.9673e-01,  ...,  4.6778e-02,\n",
              "          -1.5875e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.2766e-02, -1.3413e-01, -2.4521e-02,  ...,  4.5747e-02,\n",
              "           2.0930e-01,  2.0000e+00],\n",
              "         [ 1.3720e-01, -4.5894e-02, -4.7639e-03,  ...,  2.5762e-01,\n",
              "           1.3152e-01,  2.0000e+00],\n",
              "         [ 1.2388e-01,  1.2587e-04,  1.5106e-02,  ...,  3.4184e-01,\n",
              "           1.0979e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0612e-01,  1.2726e-01,  2.3917e-01,  ...,  7.8521e-02,\n",
              "           1.8038e-03,  2.0000e+00],\n",
              "         [-2.4977e-01,  1.1662e-01,  3.3026e-01,  ...,  6.5364e-02,\n",
              "          -2.9447e-02,  2.0000e+00],\n",
              "         [-2.9790e-01,  8.9117e-02,  2.9867e-01,  ...,  5.0005e-02,\n",
              "          -1.3957e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0211, -0.1288, -0.0321,  ...,  0.0490,  0.2160,  2.0000],\n",
              "         [ 0.1406, -0.0325, -0.0106,  ...,  0.2428,  0.1245,  2.0000],\n",
              "         [ 0.1375,  0.0317,  0.0097,  ...,  0.3182, -0.0226,  2.0000],\n",
              "         ...,\n",
              "         [-0.0481,  0.1439,  0.2010,  ...,  0.0468,  0.0124,  2.0000],\n",
              "         [-0.2333,  0.1397,  0.3307,  ...,  0.0560, -0.0176,  2.0000],\n",
              "         [-0.2779,  0.1059,  0.2978,  ...,  0.0669,  0.0046,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1267, -0.0310,  ...,  0.0546,  0.2079,  2.0000],\n",
              "         [ 0.1417, -0.0545, -0.0336,  ...,  0.2617,  0.1396,  2.0000],\n",
              "         [ 0.1199, -0.0271, -0.0230,  ...,  0.3554,  0.0261,  2.0000],\n",
              "         ...,\n",
              "         [-0.1311,  0.0942,  0.2297,  ...,  0.0840,  0.0055,  2.0000],\n",
              "         [-0.2541,  0.0830,  0.2971,  ...,  0.0641, -0.0327,  2.0000],\n",
              "         [-0.3023,  0.0811,  0.2861,  ...,  0.0422, -0.0190,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9021e-02, -1.2923e-01, -2.7758e-02,  ...,  3.7909e-02,\n",
              "           2.0823e-01,  2.0000e+00],\n",
              "         [ 1.3137e-01, -2.6107e-02, -3.2612e-04,  ...,  2.4896e-01,\n",
              "           1.1185e-01,  2.0000e+00],\n",
              "         [ 1.3286e-01,  3.9283e-02,  2.0128e-02,  ...,  3.2355e-01,\n",
              "          -2.1107e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.6038e-02,  1.2899e-01,  1.8877e-01,  ...,  6.1093e-02,\n",
              "           2.5850e-02,  2.0000e+00],\n",
              "         [-2.2116e-01,  1.2436e-01,  3.3565e-01,  ...,  6.0197e-02,\n",
              "          -1.1308e-02,  2.0000e+00],\n",
              "         [-2.8066e-01,  9.7210e-02,  3.0026e-01,  ...,  5.0231e-02,\n",
              "          -7.4003e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0171, -0.1232, -0.0353,  ...,  0.0502,  0.2166,  2.0000],\n",
              "         [ 0.1416, -0.0323, -0.0132,  ...,  0.2407,  0.1272,  2.0000],\n",
              "         [ 0.1350,  0.0337,  0.0106,  ...,  0.3175, -0.0255,  2.0000],\n",
              "         ...,\n",
              "         [-0.0296,  0.1454,  0.1880,  ...,  0.0452,  0.0297,  2.0000],\n",
              "         [-0.2198,  0.1428,  0.3226,  ...,  0.0603, -0.0062,  2.0000],\n",
              "         [-0.2717,  0.1103,  0.2940,  ...,  0.0694,  0.0070,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0290, -0.1250, -0.0859,  ...,  0.0251,  0.2024,  2.0000],\n",
              "         [ 0.2174, -0.0145, -0.0750,  ...,  0.2076,  0.0533,  2.0000],\n",
              "         [ 0.2076,  0.0217, -0.0709,  ...,  0.2859, -0.0882,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1581,  0.0106, -0.0391,  ...,  0.0451,  0.0688,  2.0000],\n",
              "         [-0.0750,  0.0910,  0.2355,  ...,  0.0965, -0.0164,  2.0000],\n",
              "         [-0.2501,  0.0740,  0.2822,  ...,  0.0821, -0.0066,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0189, -0.1232, -0.0316,  ...,  0.0386,  0.2070,  2.0000],\n",
              "         [ 0.1308, -0.0238, -0.0055,  ...,  0.2426,  0.1101,  2.0000],\n",
              "         [ 0.1283,  0.0403,  0.0131,  ...,  0.3182, -0.0305,  2.0000],\n",
              "         ...,\n",
              "         [-0.0226,  0.1299,  0.1834,  ...,  0.0538,  0.0194,  2.0000],\n",
              "         [-0.2243,  0.1251,  0.3377,  ...,  0.0569, -0.0147,  2.0000],\n",
              "         [-0.2836,  0.0945,  0.3017,  ...,  0.0460, -0.0051,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0132, -0.1250, -0.0639,  ...,  0.0586,  0.2124,  2.0000],\n",
              "         [ 0.1993, -0.0521, -0.0744,  ...,  0.2364,  0.0648,  2.0000],\n",
              "         [ 0.1662, -0.0177, -0.0664,  ...,  0.3301, -0.0789,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1573,  0.0352,  0.0701,  ...,  0.0546,  0.0107,  2.0000],\n",
              "         [-0.0750,  0.0766,  0.2629,  ...,  0.0982, -0.0431,  2.0000],\n",
              "         [-0.2265,  0.0744,  0.2791,  ...,  0.0852, -0.0055,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1318e-02, -1.1868e-01, -4.0237e-02,  ...,  5.3455e-02,\n",
              "           2.1968e-01,  2.0000e+00],\n",
              "         [ 1.3110e-01, -3.0719e-02, -1.4011e-02,  ...,  2.1109e-01,\n",
              "           1.3537e-01,  2.0000e+00],\n",
              "         [ 1.1837e-01,  3.0246e-02,  3.5626e-03,  ...,  2.9685e-01,\n",
              "          -2.8865e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.8748e-02,  1.6133e-01,  1.8530e-01,  ...,  2.9623e-02,\n",
              "           3.3347e-02,  2.0000e+00],\n",
              "         [-2.1712e-01,  1.5489e-01,  3.2685e-01,  ...,  5.1605e-02,\n",
              "           1.2756e-03,  2.0000e+00],\n",
              "         [-2.6642e-01,  1.0771e-01,  2.9688e-01,  ...,  7.0202e-02,\n",
              "           4.8998e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0127, -0.1216, -0.0311,  ...,  0.0438,  0.2089,  2.0000],\n",
              "         [ 0.1544, -0.0210, -0.0091,  ...,  0.2595,  0.1122,  2.0000],\n",
              "         [ 0.1589,  0.0466,  0.0046,  ...,  0.3298, -0.0326,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0073,  0.1242,  0.1661,  ...,  0.0684,  0.0336,  2.0000],\n",
              "         [-0.2021,  0.1277,  0.3278,  ...,  0.0777, -0.0038,  2.0000],\n",
              "         [-0.2620,  0.1096,  0.2945,  ...,  0.0564,  0.0066,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1366, -0.0376,  ...,  0.0578,  0.2110,  2.0000],\n",
              "         [ 0.1455, -0.0681, -0.0559,  ...,  0.2840,  0.1445,  2.0000],\n",
              "         [ 0.1158, -0.0514, -0.0587,  ...,  0.3762,  0.0388,  2.0000],\n",
              "         ...,\n",
              "         [-0.1248,  0.0545,  0.2064,  ...,  0.1038,  0.0150,  2.0000],\n",
              "         [-0.2412,  0.0536,  0.2682,  ...,  0.0792, -0.0297,  2.0000],\n",
              "         [-0.2936,  0.0585,  0.2711,  ...,  0.0445, -0.0180,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0300, -0.1513, -0.0372,  ...,  0.0610,  0.2128,  2.0000],\n",
              "         [ 0.1779, -0.0807, -0.0490,  ...,  0.2867,  0.1520,  2.0000],\n",
              "         [ 0.1363, -0.0630, -0.0432,  ...,  0.3796,  0.0521,  2.0000],\n",
              "         ...,\n",
              "         [-0.1143,  0.0528,  0.2006,  ...,  0.0960,  0.0105,  2.0000],\n",
              "         [-0.2329,  0.0535,  0.2520,  ...,  0.0794, -0.0352,  2.0000],\n",
              "         [-0.2758,  0.0568,  0.2587,  ...,  0.0473, -0.0159,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9414e-02, -1.4073e-01, -3.5082e-02,  ...,  5.9848e-02,\n",
              "           2.1916e-01,  2.0000e+00],\n",
              "         [ 1.5785e-01, -4.3787e-02, -1.6448e-02,  ...,  2.6331e-01,\n",
              "           1.4113e-01,  2.0000e+00],\n",
              "         [ 1.5155e-01,  1.1739e-03,  6.7312e-03,  ...,  3.4524e-01,\n",
              "           6.0516e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-5.0785e-02,  1.3751e-01,  1.8169e-01,  ...,  4.9754e-02,\n",
              "           1.8641e-02,  2.0000e+00],\n",
              "         [-2.1173e-01,  1.2433e-01,  2.8827e-01,  ...,  5.7694e-02,\n",
              "          -1.6036e-02,  2.0000e+00],\n",
              "         [-2.6769e-01,  1.0080e-01,  2.7465e-01,  ...,  7.1708e-02,\n",
              "           1.0296e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0206, -0.1327, -0.0287,  ...,  0.0440,  0.2095,  2.0000],\n",
              "         [ 0.1412, -0.0410, -0.0064,  ...,  0.2558,  0.1276,  2.0000],\n",
              "         [ 0.1354,  0.0097,  0.0134,  ...,  0.3367, -0.0029,  2.0000],\n",
              "         ...,\n",
              "         [-0.0781,  0.1298,  0.2233,  ...,  0.0835,  0.0035,  2.0000],\n",
              "         [-0.2412,  0.1224,  0.3346,  ...,  0.0697, -0.0252,  2.0000],\n",
              "         [-0.2895,  0.0938,  0.2960,  ...,  0.0543, -0.0101,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.4145e-03, -1.2167e-01, -4.7680e-02,  ...,  6.0639e-02,\n",
              "           2.1816e-01,  2.0000e+00],\n",
              "         [ 1.5121e-01, -2.3073e-02, -2.3102e-02,  ...,  2.3384e-01,\n",
              "           1.2366e-01,  2.0000e+00],\n",
              "         [ 1.4249e-01,  3.9092e-02, -7.7623e-03,  ...,  3.1643e-01,\n",
              "          -3.7366e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 3.3381e-03,  1.5160e-01,  1.5183e-01,  ...,  4.5814e-02,\n",
              "           3.2058e-02,  2.0000e+00],\n",
              "         [-1.9351e-01,  1.4528e-01,  3.0571e-01,  ...,  6.9021e-02,\n",
              "          -7.8032e-03,  2.0000e+00],\n",
              "         [-2.5202e-01,  1.0123e-01,  2.8372e-01,  ...,  7.6615e-02,\n",
              "           1.3154e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0169, -0.1306, -0.0265,  ...,  0.0463,  0.2116,  1.0000],\n",
              "         [ 0.1487, -0.0393, -0.0026,  ...,  0.2638,  0.1262,  1.0000],\n",
              "         [ 0.1475,  0.0152,  0.0110,  ...,  0.3431, -0.0022,  1.0000],\n",
              "         ...,\n",
              "         [-0.0660,  0.1252,  0.2275,  ...,  0.0887,  0.0104,  1.0000],\n",
              "         [-0.2335,  0.1251,  0.3372,  ...,  0.0812, -0.0204,  1.0000],\n",
              "         [-0.2788,  0.1031,  0.2975,  ...,  0.0584,  0.0015,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.2131e-03, -1.1010e-01, -4.5651e-02,  ...,  4.0397e-02,\n",
              "           2.0484e-01,  0.0000e+00],\n",
              "         [ 1.6480e-01, -5.8393e-03, -3.3269e-02,  ...,  2.5311e-01,\n",
              "           7.0650e-02,  0.0000e+00],\n",
              "         [ 1.7694e-01,  5.8720e-02, -2.8135e-02,  ...,  3.1287e-01,\n",
              "          -7.0608e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 8.2056e-02,  8.8127e-02,  5.3565e-02,  ...,  5.0242e-02,\n",
              "           6.4516e-02,  0.0000e+00],\n",
              "         [-1.5230e-01,  1.2416e-01,  3.0677e-01,  ...,  1.0338e-01,\n",
              "          -1.0906e-04,  0.0000e+00],\n",
              "         [-2.5094e-01,  1.0480e-01,  2.9222e-01,  ...,  6.6992e-02,\n",
              "           7.4237e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0166, -0.1299, -0.0275,  ...,  0.0469,  0.2115,  2.0000],\n",
              "         [ 0.1516, -0.0353, -0.0050,  ...,  0.2701,  0.1242,  2.0000],\n",
              "         [ 0.1524,  0.0225,  0.0089,  ...,  0.3481, -0.0054,  2.0000],\n",
              "         ...,\n",
              "         [-0.0456,  0.1198,  0.2098,  ...,  0.0914,  0.0180,  2.0000],\n",
              "         [-0.2248,  0.1236,  0.3310,  ...,  0.0839, -0.0149,  2.0000],\n",
              "         [-0.2750,  0.1024,  0.2955,  ...,  0.0608,  0.0031,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0279, -0.1305, -0.0314,  ...,  0.0625,  0.2110,  1.0000],\n",
              "         [ 0.1677, -0.0512, -0.0256,  ...,  0.2810,  0.1412,  1.0000],\n",
              "         [ 0.1479, -0.0127, -0.0044,  ...,  0.3760,  0.0161,  1.0000],\n",
              "         ...,\n",
              "         [-0.1183,  0.1124,  0.2322,  ...,  0.0892, -0.0101,  1.0000],\n",
              "         [-0.2453,  0.1016,  0.2894,  ...,  0.0799, -0.0352,  1.0000],\n",
              "         [-0.2852,  0.0908,  0.2784,  ...,  0.0606, -0.0093,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0337, -0.1300, -0.0319,  ...,  0.0661,  0.2121,  1.0000],\n",
              "         [ 0.1642, -0.0506, -0.0302,  ...,  0.2748,  0.1430,  1.0000],\n",
              "         [ 0.1374, -0.0194, -0.0096,  ...,  0.3668,  0.0327,  1.0000],\n",
              "         ...,\n",
              "         [-0.1425,  0.1085,  0.2468,  ...,  0.0787, -0.0160,  1.0000],\n",
              "         [-0.2580,  0.0933,  0.2913,  ...,  0.0731, -0.0401,  1.0000],\n",
              "         [-0.2866,  0.0886,  0.2777,  ...,  0.0514, -0.0104,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0343, -0.1551, -0.0518,  ...,  0.0668,  0.2112,  1.0000],\n",
              "         [ 0.1635, -0.1083, -0.0609,  ...,  0.3058,  0.1657,  1.0000],\n",
              "         [ 0.1089, -0.1012, -0.0603,  ...,  0.4115,  0.0765,  1.0000],\n",
              "         ...,\n",
              "         [-0.1695,  0.0325,  0.2091,  ...,  0.1072, -0.0197,  1.0000],\n",
              "         [-0.2513,  0.0533,  0.2124,  ...,  0.0892, -0.0501,  1.0000],\n",
              "         [-0.2630,  0.0339,  0.2376,  ...,  0.0363, -0.0249,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0292, -0.1532, -0.0586,  ...,  0.0533,  0.1885,  1.0000],\n",
              "         [ 0.0991, -0.1273, -0.0626,  ...,  0.2390,  0.1454,  1.0000],\n",
              "         [ 0.0313, -0.1271, -0.0772,  ...,  0.3359,  0.0844,  1.0000],\n",
              "         ...,\n",
              "         [-0.2386,  0.0591,  0.2185,  ..., -0.0057, -0.0878,  1.0000],\n",
              "         [-0.2699,  0.0752,  0.2247,  ...,  0.0018, -0.0813,  1.0000],\n",
              "         [-0.2310,  0.0390,  0.2450,  ..., -0.0189, -0.0555,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0331, -0.1567, -0.0530,  ...,  0.0678,  0.2119,  1.0000],\n",
              "         [ 0.1717, -0.1066, -0.0629,  ...,  0.3148,  0.1650,  1.0000],\n",
              "         [ 0.1159, -0.1017, -0.0618,  ...,  0.4224,  0.0793,  1.0000],\n",
              "         ...,\n",
              "         [-0.1570,  0.0167,  0.2001,  ...,  0.1062, -0.0243,  1.0000],\n",
              "         [-0.2323,  0.0398,  0.2011,  ...,  0.0879, -0.0477,  1.0000],\n",
              "         [-0.2534,  0.0244,  0.2306,  ...,  0.0359, -0.0218,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0274, -0.1298, -0.0245,  ...,  0.0416,  0.2078,  1.0000],\n",
              "         [ 0.1235, -0.0506, -0.0032,  ...,  0.2377,  0.1328,  1.0000],\n",
              "         [ 0.1070, -0.0097,  0.0176,  ...,  0.3214,  0.0120,  1.0000],\n",
              "         ...,\n",
              "         [-0.1413,  0.1364,  0.2633,  ...,  0.0664, -0.0038,  1.0000],\n",
              "         [-0.2646,  0.1256,  0.3408,  ...,  0.0531, -0.0372,  1.0000],\n",
              "         [-0.3062,  0.0923,  0.3045,  ...,  0.0395, -0.0197,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0299, -0.1539, -0.0448,  ...,  0.0519,  0.2112,  1.0000],\n",
              "         [ 0.1462, -0.0936, -0.0666,  ...,  0.2780,  0.1492,  1.0000],\n",
              "         [ 0.1049, -0.0846, -0.0747,  ...,  0.3689,  0.0527,  1.0000],\n",
              "         ...,\n",
              "         [-0.1212,  0.0211,  0.1895,  ...,  0.1018,  0.0291,  1.0000],\n",
              "         [-0.2223,  0.0196,  0.2453,  ...,  0.0751, -0.0182,  1.0000],\n",
              "         [-0.2772,  0.0250,  0.2560,  ...,  0.0352, -0.0192,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0336, -0.1436, -0.0383,  ...,  0.0527,  0.2136,  1.0000],\n",
              "         [ 0.1444, -0.0806, -0.0551,  ...,  0.2711,  0.1578,  1.0000],\n",
              "         [ 0.1019, -0.0693, -0.0573,  ...,  0.3659,  0.0634,  1.0000],\n",
              "         ...,\n",
              "         [-0.1473,  0.0543,  0.2218,  ...,  0.0988,  0.0227,  1.0000],\n",
              "         [-0.2548,  0.0487,  0.2765,  ...,  0.0756, -0.0296,  1.0000],\n",
              "         [-0.3016,  0.0480,  0.2774,  ...,  0.0322, -0.0201,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0231, -0.1281, -0.0284,  ...,  0.0538,  0.2167,  1.0000],\n",
              "         [ 0.1456, -0.0386, -0.0062,  ...,  0.2574,  0.1332,  1.0000],\n",
              "         [ 0.1423,  0.0195,  0.0141,  ...,  0.3359, -0.0072,  1.0000],\n",
              "         ...,\n",
              "         [-0.0871,  0.1418,  0.2389,  ...,  0.0655,  0.0021,  1.0000],\n",
              "         [-0.2440,  0.1363,  0.3348,  ...,  0.0627, -0.0256,  1.0000],\n",
              "         [-0.2848,  0.1035,  0.2991,  ...,  0.0634,  0.0028,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1191, -0.0325,  ...,  0.0475,  0.2147,  1.0000],\n",
              "         [ 0.1286, -0.0291, -0.0081,  ...,  0.2329,  0.1224,  1.0000],\n",
              "         [ 0.1309,  0.0361,  0.0141,  ...,  0.3060, -0.0274,  1.0000],\n",
              "         ...,\n",
              "         [-0.0543,  0.1385,  0.2137,  ...,  0.0440,  0.0146,  1.0000],\n",
              "         [-0.2345,  0.1372,  0.3463,  ...,  0.0522, -0.0088,  1.0000],\n",
              "         [-0.2808,  0.1047,  0.3078,  ...,  0.0563,  0.0100,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.6696e-02, -1.6541e-01, -5.1131e-02,  ...,  5.7619e-02,\n",
              "           2.1149e-01,  1.0000e+00],\n",
              "         [ 1.4382e-01, -1.1364e-01, -7.6276e-02,  ...,  2.9033e-01,\n",
              "           1.5253e-01,  1.0000e+00],\n",
              "         [ 9.7758e-02, -1.1011e-01, -8.5728e-02,  ...,  3.8092e-01,\n",
              "           6.6300e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1388e-01,  2.2965e-03,  1.8245e-01,  ...,  1.0755e-01,\n",
              "           1.7556e-02,  1.0000e+00],\n",
              "         [-2.0440e-01,  4.8180e-03,  2.1598e-01,  ...,  7.9929e-02,\n",
              "          -2.1813e-02,  1.0000e+00],\n",
              "         [-2.5630e-01, -3.1329e-04,  2.3727e-01,  ...,  3.9413e-02,\n",
              "          -2.3884e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0191, -0.1383, -0.0306,  ...,  0.0541,  0.2136,  1.0000],\n",
              "         [ 0.1592, -0.0516, -0.0204,  ...,  0.2867,  0.1361,  1.0000],\n",
              "         [ 0.1463, -0.0163, -0.0149,  ...,  0.3738,  0.0251,  1.0000],\n",
              "         ...,\n",
              "         [-0.0906,  0.1003,  0.2126,  ...,  0.1030,  0.0057,  1.0000],\n",
              "         [-0.2274,  0.0945,  0.2937,  ...,  0.0870, -0.0238,  1.0000],\n",
              "         [-0.2777,  0.0888,  0.2814,  ...,  0.0620, -0.0033,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6523e-02, -1.3222e-01, -2.7395e-02,  ...,  4.7982e-02,\n",
              "           2.1117e-01,  1.0000e+00],\n",
              "         [ 1.5347e-01, -3.9929e-02, -4.4112e-03,  ...,  2.7143e-01,\n",
              "           1.2739e-01,  1.0000e+00],\n",
              "         [ 1.5178e-01,  1.1739e-02,  8.4930e-03,  ...,  3.5086e-01,\n",
              "           2.5353e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-6.7650e-02,  1.2357e-01,  2.2321e-01,  ...,  9.4973e-02,\n",
              "           8.3041e-03,  1.0000e+00],\n",
              "         [-2.2989e-01,  1.2257e-01,  3.2909e-01,  ...,  8.3137e-02,\n",
              "          -2.2678e-02,  1.0000e+00],\n",
              "         [-2.7687e-01,  1.0197e-01,  2.9493e-01,  ...,  5.9376e-02,\n",
              "          -8.4860e-05,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0350, -0.1399, -0.0370,  ...,  0.0569,  0.2130,  1.0000],\n",
              "         [ 0.1524, -0.0655, -0.0409,  ...,  0.2675,  0.1480,  1.0000],\n",
              "         [ 0.1203, -0.0440, -0.0325,  ...,  0.3542,  0.0402,  1.0000],\n",
              "         ...,\n",
              "         [-0.1398,  0.0759,  0.2281,  ...,  0.0804,  0.0075,  1.0000],\n",
              "         [-0.2579,  0.0644,  0.2804,  ...,  0.0661, -0.0368,  1.0000],\n",
              "         [-0.2920,  0.0714,  0.2744,  ...,  0.0427, -0.0137,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.3328e-02, -1.5626e-01, -5.9978e-02,  ...,  5.7159e-02,\n",
              "           1.9439e-01,  1.0000e+00],\n",
              "         [ 1.0895e-01, -1.2957e-01, -6.8535e-02,  ...,  2.5934e-01,\n",
              "           1.4805e-01,  1.0000e+00],\n",
              "         [ 4.3156e-02, -1.2530e-01, -7.9347e-02,  ...,  3.5849e-01,\n",
              "           7.8263e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-2.2392e-01,  4.4601e-02,  1.9500e-01,  ...,  3.5661e-02,\n",
              "          -7.9435e-02,  1.0000e+00],\n",
              "         [-2.6788e-01,  6.4107e-02,  2.0860e-01,  ...,  4.1396e-02,\n",
              "          -7.9675e-02,  1.0000e+00],\n",
              "         [-2.4929e-01,  2.5005e-02,  2.3824e-01,  ...,  9.5191e-05,\n",
              "          -5.0961e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0095, -0.1275, -0.0427,  ...,  0.0560,  0.2169,  1.0000],\n",
              "         [ 0.1528, -0.0228, -0.0198,  ...,  0.2488,  0.1198,  1.0000],\n",
              "         [ 0.1564,  0.0439, -0.0074,  ...,  0.3262, -0.0352,  1.0000],\n",
              "         ...,\n",
              "         [-0.0105,  0.1456,  0.1674,  ...,  0.0515,  0.0199,  1.0000],\n",
              "         [-0.1986,  0.1494,  0.3089,  ...,  0.0638, -0.0122,  1.0000],\n",
              "         [-0.2601,  0.1081,  0.2896,  ...,  0.0729,  0.0049,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0346, -0.1547, -0.0585,  ...,  0.0617,  0.2043,  1.0000],\n",
              "         [ 0.1248, -0.1200, -0.0703,  ...,  0.2789,  0.1564,  1.0000],\n",
              "         [ 0.0612, -0.1165, -0.0757,  ...,  0.3842,  0.0815,  1.0000],\n",
              "         ...,\n",
              "         [-0.2091,  0.0383,  0.1981,  ...,  0.0898, -0.0607,  1.0000],\n",
              "         [-0.2651,  0.0518,  0.1993,  ...,  0.0762, -0.0783,  1.0000],\n",
              "         [-0.2652,  0.0204,  0.2349,  ...,  0.0214, -0.0456,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0314, -0.1554, -0.0479,  ...,  0.0629,  0.2142,  1.0000],\n",
              "         [ 0.1714, -0.0928, -0.0604,  ...,  0.2918,  0.1602,  1.0000],\n",
              "         [ 0.1231, -0.0903, -0.0583,  ...,  0.3927,  0.0658,  1.0000],\n",
              "         ...,\n",
              "         [-0.1422,  0.0175,  0.2096,  ...,  0.0903, -0.0095,  1.0000],\n",
              "         [-0.2351,  0.0349,  0.2223,  ...,  0.0778, -0.0413,  1.0000],\n",
              "         [-0.2624,  0.0336,  0.2433,  ...,  0.0396, -0.0177,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0146, -0.1222, -0.0455,  ...,  0.0520,  0.2118,  1.0000],\n",
              "         [ 0.1518, -0.0020, -0.0223,  ...,  0.2501,  0.1041,  1.0000],\n",
              "         [ 0.1609,  0.0581, -0.0091,  ...,  0.3220, -0.0485,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0136,  0.1329,  0.1370,  ...,  0.0512,  0.0106,  1.0000],\n",
              "         [-0.1939,  0.1395,  0.3059,  ...,  0.0681, -0.0175,  1.0000],\n",
              "         [-0.2592,  0.1070,  0.2877,  ...,  0.0711,  0.0096,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.1026e-02, -1.3103e-01, -2.8167e-02,  ...,  5.0617e-02,\n",
              "           2.1748e-01,  1.0000e+00],\n",
              "         [ 1.4529e-01, -4.0043e-02, -9.2392e-03,  ...,  2.5473e-01,\n",
              "           1.3721e-01,  1.0000e+00],\n",
              "         [ 1.3975e-01,  1.2278e-02,  1.6940e-02,  ...,  3.3400e-01,\n",
              "          -2.6381e-05,  1.0000e+00],\n",
              "         ...,\n",
              "         [-7.6460e-02,  1.3616e-01,  2.2697e-01,  ...,  6.3197e-02,\n",
              "           3.0261e-03,  1.0000e+00],\n",
              "         [-2.3608e-01,  1.3349e-01,  3.2723e-01,  ...,  6.2308e-02,\n",
              "          -2.5806e-02,  1.0000e+00],\n",
              "         [-2.8561e-01,  9.8338e-02,  2.9817e-01,  ...,  6.0455e-02,\n",
              "          -3.0898e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0359, -0.1521, -0.0462,  ...,  0.0555,  0.2134,  1.0000],\n",
              "         [ 0.1444, -0.0947, -0.0696,  ...,  0.2905,  0.1564,  1.0000],\n",
              "         [ 0.1010, -0.0983, -0.0756,  ...,  0.3787,  0.0827,  1.0000],\n",
              "         ...,\n",
              "         [-0.1538,  0.0228,  0.2128,  ...,  0.1036,  0.0071,  1.0000],\n",
              "         [-0.2439,  0.0207,  0.2417,  ...,  0.0810, -0.0325,  1.0000],\n",
              "         [-0.2860,  0.0220,  0.2574,  ...,  0.0339, -0.0241,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.3385e-03, -1.1578e-01, -4.7484e-02,  ...,  4.4507e-02,\n",
              "           2.1443e-01,  1.0000e+00],\n",
              "         [ 1.4462e-01, -1.4231e-02, -2.5859e-02,  ...,  2.2055e-01,\n",
              "           1.1745e-01,  1.0000e+00],\n",
              "         [ 1.5034e-01,  4.7062e-02, -8.8807e-03,  ...,  3.0102e-01,\n",
              "          -4.4745e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 2.0952e-02,  1.2637e-01,  1.1913e-01,  ...,  3.6991e-02,\n",
              "           4.1455e-02,  1.0000e+00],\n",
              "         [-1.8404e-01,  1.4338e-01,  3.0185e-01,  ...,  6.2631e-02,\n",
              "           7.5482e-04,  1.0000e+00],\n",
              "         [-2.5896e-01,  9.9830e-02,  2.9071e-01,  ...,  6.6234e-02,\n",
              "           2.7202e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0242, -0.1304, -0.0259,  ...,  0.0448,  0.2100,  1.0000],\n",
              "         [ 0.1329, -0.0427, -0.0051,  ...,  0.2549,  0.1314,  1.0000],\n",
              "         [ 0.1218,  0.0065,  0.0173,  ...,  0.3376,  0.0056,  1.0000],\n",
              "         ...,\n",
              "         [-0.1066,  0.1330,  0.2426,  ...,  0.0787, -0.0014,  1.0000],\n",
              "         [-0.2518,  0.1246,  0.3373,  ...,  0.0642, -0.0297,  1.0000],\n",
              "         [-0.3010,  0.0922,  0.3007,  ...,  0.0508, -0.0128,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1297, -0.0320,  ...,  0.0602,  0.2127,  1.0000],\n",
              "         [ 0.1504, -0.0538, -0.0285,  ...,  0.2534,  0.1538,  1.0000],\n",
              "         [ 0.1219, -0.0275, -0.0093,  ...,  0.3464,  0.0436,  1.0000],\n",
              "         ...,\n",
              "         [-0.1449,  0.1117,  0.2424,  ...,  0.0640, -0.0045,  1.0000],\n",
              "         [-0.2640,  0.0896,  0.2999,  ...,  0.0577, -0.0383,  1.0000],\n",
              "         [-0.2941,  0.0810,  0.2800,  ...,  0.0471, -0.0133,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.5071e-02, -1.2282e-01, -4.0168e-02,  ...,  5.2793e-02,\n",
              "           2.1252e-01,  1.0000e+00],\n",
              "         [ 1.5500e-01, -7.5142e-03, -1.4603e-02,  ...,  2.5368e-01,\n",
              "           1.0721e-01,  1.0000e+00],\n",
              "         [ 1.6214e-01,  6.0011e-02, -3.1024e-04,  ...,  3.2260e-01,\n",
              "          -4.6217e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-9.3618e-03,  1.3699e-01,  1.6625e-01,  ...,  5.1106e-02,\n",
              "           1.3161e-02,  1.0000e+00],\n",
              "         [-2.0509e-01,  1.4008e-01,  3.1328e-01,  ...,  6.5253e-02,\n",
              "          -1.7372e-02,  1.0000e+00],\n",
              "         [-2.6455e-01,  1.1029e-01,  2.8798e-01,  ...,  7.2578e-02,\n",
              "           1.0673e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0365, -0.1569, -0.0588,  ...,  0.0650,  0.2015,  1.0000],\n",
              "         [ 0.1190, -0.1246, -0.0702,  ...,  0.2929,  0.1489,  1.0000],\n",
              "         [ 0.0536, -0.1198, -0.0785,  ...,  0.3926,  0.0793,  1.0000],\n",
              "         ...,\n",
              "         [-0.2111,  0.0399,  0.1959,  ...,  0.0866, -0.0755,  1.0000],\n",
              "         [-0.2577,  0.0523,  0.1930,  ...,  0.0741, -0.0820,  1.0000],\n",
              "         [-0.2559,  0.0239,  0.2290,  ...,  0.0200, -0.0448,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6256e-02, -1.2161e-01, -3.7984e-02,  ...,  3.8554e-02,\n",
              "           2.0470e-01,  1.0000e+00],\n",
              "         [ 1.3729e-01, -1.2842e-02, -1.4170e-02,  ...,  2.4340e-01,\n",
              "           9.4996e-02,  1.0000e+00],\n",
              "         [ 1.3982e-01,  4.9073e-02, -3.8791e-04,  ...,  3.1733e-01,\n",
              "          -4.5886e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 7.3176e-03,  1.2901e-01,  1.4277e-01,  ...,  4.8720e-02,\n",
              "           2.6581e-02,  1.0000e+00],\n",
              "         [-2.0645e-01,  1.2010e-01,  3.2379e-01,  ...,  6.4577e-02,\n",
              "          -1.5529e-02,  1.0000e+00],\n",
              "         [-2.7200e-01,  9.5134e-02,  2.9535e-01,  ...,  4.9895e-02,\n",
              "          -6.5187e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0352, -0.1564, -0.0547,  ...,  0.0585,  0.2126,  1.0000],\n",
              "         [ 0.1380, -0.1107, -0.0788,  ...,  0.2973,  0.1555,  1.0000],\n",
              "         [ 0.0871, -0.1131, -0.0859,  ...,  0.3945,  0.0786,  1.0000],\n",
              "         ...,\n",
              "         [-0.1423,  0.0100,  0.1969,  ...,  0.1129, -0.0040,  1.0000],\n",
              "         [-0.2281,  0.0186,  0.2110,  ...,  0.0905, -0.0422,  1.0000],\n",
              "         [-0.2710,  0.0025,  0.2398,  ...,  0.0351, -0.0313,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0208, -0.1334, -0.0269,  ...,  0.0444,  0.2091,  1.0000],\n",
              "         [ 0.1413, -0.0421, -0.0061,  ...,  0.2583,  0.1287,  1.0000],\n",
              "         [ 0.1297,  0.0078,  0.0142,  ...,  0.3410,  0.0045,  1.0000],\n",
              "         ...,\n",
              "         [-0.0946,  0.1272,  0.2237,  ...,  0.0791,  0.0035,  1.0000],\n",
              "         [-0.2434,  0.1158,  0.3246,  ...,  0.0647, -0.0277,  1.0000],\n",
              "         [-0.2933,  0.0914,  0.2975,  ...,  0.0512, -0.0131,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.0133e-02, -1.1921e-01, -3.3439e-02,  ...,  4.3928e-02,\n",
              "           2.0861e-01,  2.0000e+00],\n",
              "         [ 1.5277e-01, -1.4220e-02, -1.2712e-02,  ...,  2.5586e-01,\n",
              "           1.0270e-01,  2.0000e+00],\n",
              "         [ 1.6249e-01,  5.5318e-02, -2.4052e-03,  ...,  3.2524e-01,\n",
              "          -4.1395e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 2.9333e-02,  1.1887e-01,  1.3880e-01,  ...,  5.4067e-02,\n",
              "           4.1468e-02,  2.0000e+00],\n",
              "         [-1.9090e-01,  1.2427e-01,  3.2428e-01,  ...,  8.1373e-02,\n",
              "          -1.6119e-03,  2.0000e+00],\n",
              "         [-2.5579e-01,  1.0987e-01,  2.9267e-01,  ...,  5.6394e-02,\n",
              "           7.3016e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0182e-02, -1.1906e-01, -3.0874e-02,  ...,  3.6401e-02,\n",
              "           2.0510e-01,  2.0000e+00],\n",
              "         [ 1.2488e-01, -2.0762e-02,  3.0539e-04,  ...,  2.3219e-01,\n",
              "           1.0172e-01,  2.0000e+00],\n",
              "         [ 1.2544e-01,  4.6820e-02,  2.0333e-02,  ...,  3.0480e-01,\n",
              "          -4.1127e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1954e-02,  1.3155e-01,  1.7603e-01,  ...,  3.5523e-02,\n",
              "           3.2140e-02,  2.0000e+00],\n",
              "         [-2.2045e-01,  1.3058e-01,  3.4237e-01,  ...,  4.7130e-02,\n",
              "          -9.6722e-03,  2.0000e+00],\n",
              "         [-2.8630e-01,  9.9680e-02,  3.0685e-01,  ...,  4.2495e-02,\n",
              "          -1.7347e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0331, -0.1557, -0.0582,  ...,  0.0589,  0.1923,  2.0000],\n",
              "         [ 0.1120, -0.1289, -0.0648,  ...,  0.2601,  0.1477,  2.0000],\n",
              "         [ 0.0449, -0.1246, -0.0760,  ...,  0.3577,  0.0833,  2.0000],\n",
              "         ...,\n",
              "         [-0.2409,  0.0532,  0.2040,  ...,  0.0351, -0.0865,  2.0000],\n",
              "         [-0.2758,  0.0682,  0.2113,  ...,  0.0344, -0.0820,  2.0000],\n",
              "         [-0.2464,  0.0339,  0.2387,  ..., -0.0057, -0.0505,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0204, -0.1215, -0.0275,  ...,  0.0365,  0.2061,  2.0000],\n",
              "         [ 0.1271, -0.0220,  0.0062,  ...,  0.2330,  0.1078,  2.0000],\n",
              "         [ 0.1277,  0.0426,  0.0278,  ...,  0.3061, -0.0312,  2.0000],\n",
              "         ...,\n",
              "         [-0.0328,  0.1330,  0.1946,  ...,  0.0397,  0.0219,  2.0000],\n",
              "         [-0.2266,  0.1285,  0.3462,  ...,  0.0422, -0.0140,  2.0000],\n",
              "         [-0.2887,  0.1022,  0.3076,  ...,  0.0382, -0.0025,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0314, -0.1569, -0.0594,  ...,  0.0568,  0.1916,  2.0000],\n",
              "         [ 0.1137, -0.1309, -0.0645,  ...,  0.2578,  0.1487,  2.0000],\n",
              "         [ 0.0456, -0.1256, -0.0745,  ...,  0.3575,  0.0833,  2.0000],\n",
              "         ...,\n",
              "         [-0.2220,  0.0472,  0.1923,  ...,  0.0258, -0.0834,  2.0000],\n",
              "         [-0.2673,  0.0708,  0.2098,  ...,  0.0311, -0.0791,  2.0000],\n",
              "         [-0.2435,  0.0317,  0.2360,  ..., -0.0065, -0.0515,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0354, -0.1353, -0.0333,  ...,  0.0622,  0.2128,  2.0000],\n",
              "         [ 0.1623, -0.0603, -0.0299,  ...,  0.2753,  0.1537,  2.0000],\n",
              "         [ 0.1254, -0.0332, -0.0182,  ...,  0.3673,  0.0443,  2.0000],\n",
              "         ...,\n",
              "         [-0.1647,  0.0993,  0.2531,  ...,  0.0863, -0.0185,  2.0000],\n",
              "         [-0.2673,  0.0842,  0.2858,  ...,  0.0762, -0.0419,  2.0000],\n",
              "         [-0.2931,  0.0784,  0.2762,  ...,  0.0485, -0.0123,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0211, -0.1289, -0.0795,  ...,  0.0327,  0.1896,  2.0000],\n",
              "         [ 0.2157,  0.0091, -0.0632,  ...,  0.2325,  0.0455,  2.0000],\n",
              "         [ 0.1987,  0.0422, -0.0591,  ...,  0.3093, -0.0915,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1631,  0.0109, -0.0027,  ...,  0.0726,  0.0357,  2.0000],\n",
              "         [-0.0731,  0.0813,  0.2595,  ...,  0.1191, -0.0249,  2.0000],\n",
              "         [-0.2481,  0.0764,  0.2872,  ...,  0.0831, -0.0225,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1346, -0.0323,  ...,  0.0686,  0.2115,  2.0000],\n",
              "         [ 0.1743, -0.0526, -0.0304,  ...,  0.2801,  0.1439,  2.0000],\n",
              "         [ 0.1467, -0.0213, -0.0112,  ...,  0.3723,  0.0304,  2.0000],\n",
              "         ...,\n",
              "         [-0.1322,  0.1185,  0.2355,  ...,  0.0869, -0.0153,  2.0000],\n",
              "         [-0.2602,  0.0962,  0.2890,  ...,  0.0765, -0.0382,  2.0000],\n",
              "         [-0.2838,  0.0934,  0.2736,  ...,  0.0636, -0.0078,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0276, -0.1486, -0.0605,  ...,  0.0586,  0.1974,  2.0000],\n",
              "         [ 0.1316, -0.1209, -0.0616,  ...,  0.2521,  0.1648,  2.0000],\n",
              "         [ 0.0636, -0.1088, -0.0662,  ...,  0.3631,  0.0824,  2.0000],\n",
              "         ...,\n",
              "         [-0.2266,  0.0528,  0.1876,  ...,  0.0327, -0.0748,  2.0000],\n",
              "         [-0.2760,  0.0719,  0.2121,  ...,  0.0441, -0.0762,  2.0000],\n",
              "         [-0.2485,  0.0387,  0.2365,  ...,  0.0060, -0.0520,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0173, -0.1180, -0.0384,  ...,  0.0461,  0.2117,  2.0000],\n",
              "         [ 0.1406, -0.0105, -0.0117,  ...,  0.2457,  0.1058,  2.0000],\n",
              "         [ 0.1517,  0.0585,  0.0077,  ...,  0.3146, -0.0492,  2.0000],\n",
              "         ...,\n",
              "         [-0.0057,  0.1345,  0.1621,  ...,  0.0389,  0.0251,  2.0000],\n",
              "         [-0.2045,  0.1424,  0.3281,  ...,  0.0604, -0.0109,  2.0000],\n",
              "         [-0.2697,  0.1062,  0.2995,  ...,  0.0629,  0.0044,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-9.5237e-03, -1.2093e-01, -3.2614e-02,  ...,  4.7070e-02,\n",
              "           2.1186e-01,  2.0000e+00],\n",
              "         [ 1.5748e-01, -1.8730e-02, -1.4563e-02,  ...,  2.6256e-01,\n",
              "           1.1626e-01,  2.0000e+00],\n",
              "         [ 1.6440e-01,  5.0777e-02, -1.1762e-03,  ...,  3.3539e-01,\n",
              "          -2.6076e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.5188e-02,  1.1900e-01,  1.5543e-01,  ...,  7.3396e-02,\n",
              "           4.0777e-02,  2.0000e+00],\n",
              "         [-1.9608e-01,  1.2173e-01,  3.2399e-01,  ...,  8.8040e-02,\n",
              "           8.6427e-04,  2.0000e+00],\n",
              "         [-2.5671e-01,  1.0759e-01,  2.9277e-01,  ...,  6.3280e-02,\n",
              "           8.8380e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3606e-02, -1.2205e-01, -3.0467e-02,  ...,  4.6560e-02,\n",
              "           2.1192e-01,  2.0000e+00],\n",
              "         [ 1.5123e-01, -2.2259e-02, -9.8322e-03,  ...,  2.6271e-01,\n",
              "           1.1838e-01,  2.0000e+00],\n",
              "         [ 1.5652e-01,  4.4932e-02,  4.2715e-03,  ...,  3.3490e-01,\n",
              "          -2.3295e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.7384e-03,  1.2186e-01,  1.7576e-01,  ...,  7.3139e-02,\n",
              "           3.2754e-02,  2.0000e+00],\n",
              "         [-2.0785e-01,  1.2519e-01,  3.3087e-01,  ...,  8.0411e-02,\n",
              "          -2.4656e-03,  2.0000e+00],\n",
              "         [-2.6274e-01,  1.0844e-01,  2.9496e-01,  ...,  5.9403e-02,\n",
              "           9.9570e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0321, -0.1302, -0.0296,  ...,  0.0530,  0.2055,  2.0000],\n",
              "         [ 0.1445, -0.0562, -0.0257,  ...,  0.2550,  0.1388,  2.0000],\n",
              "         [ 0.1225, -0.0271, -0.0117,  ...,  0.3450,  0.0282,  2.0000],\n",
              "         ...,\n",
              "         [-0.1200,  0.0997,  0.2201,  ...,  0.0723,  0.0120,  2.0000],\n",
              "         [-0.2514,  0.0928,  0.2948,  ...,  0.0587, -0.0309,  2.0000],\n",
              "         [-0.2975,  0.0876,  0.2845,  ...,  0.0394, -0.0177,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0278, -0.1421, -0.0371,  ...,  0.0675,  0.2163,  2.0000],\n",
              "         [ 0.1844, -0.0704, -0.0441,  ...,  0.2824,  0.1631,  2.0000],\n",
              "         [ 0.1428, -0.0472, -0.0360,  ...,  0.3812,  0.0557,  2.0000],\n",
              "         ...,\n",
              "         [-0.0980,  0.0833,  0.2039,  ...,  0.1138,  0.0079,  2.0000],\n",
              "         [-0.2389,  0.0806,  0.2736,  ...,  0.0941, -0.0255,  2.0000],\n",
              "         [-0.2832,  0.0777,  0.2629,  ...,  0.0700, -0.0089,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0294, -0.1475, -0.0426,  ...,  0.0623,  0.2125,  2.0000],\n",
              "         [ 0.1569, -0.0769, -0.0648,  ...,  0.2986,  0.1437,  2.0000],\n",
              "         [ 0.1256, -0.0653, -0.0710,  ...,  0.3890,  0.0429,  2.0000],\n",
              "         ...,\n",
              "         [-0.1092,  0.0301,  0.1855,  ...,  0.0998,  0.0231,  2.0000],\n",
              "         [-0.2155,  0.0311,  0.2419,  ...,  0.0830, -0.0190,  2.0000],\n",
              "         [-0.2740,  0.0395,  0.2535,  ...,  0.0535, -0.0172,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0188, -0.1189, -0.0331,  ...,  0.0360,  0.2038,  2.0000],\n",
              "         [ 0.1271, -0.0114, -0.0031,  ...,  0.2320,  0.0904,  2.0000],\n",
              "         [ 0.1346,  0.0566,  0.0125,  ...,  0.3030, -0.0533,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0027,  0.1259,  0.1487,  ...,  0.0273,  0.0336,  2.0000],\n",
              "         [-0.2095,  0.1228,  0.3369,  ...,  0.0488, -0.0134,  2.0000],\n",
              "         [-0.2778,  0.0964,  0.3046,  ...,  0.0423, -0.0036,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0183, -0.1229, -0.0384,  ...,  0.0498,  0.2140,  2.0000],\n",
              "         [ 0.1386, -0.0240, -0.0109,  ...,  0.2317,  0.1220,  2.0000],\n",
              "         [ 0.1357,  0.0434,  0.0083,  ...,  0.3100, -0.0291,  2.0000],\n",
              "         ...,\n",
              "         [-0.0355,  0.1498,  0.1886,  ...,  0.0446,  0.0196,  2.0000],\n",
              "         [-0.2276,  0.1413,  0.3252,  ...,  0.0586, -0.0109,  2.0000],\n",
              "         [-0.2714,  0.1069,  0.2925,  ...,  0.0700,  0.0088,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7766e-03, -1.0828e-01, -5.7397e-02,  ...,  4.3883e-02,\n",
              "           2.1150e-01,  2.0000e+00],\n",
              "         [ 1.4394e-01, -1.5603e-03, -2.9774e-02,  ...,  2.2204e-01,\n",
              "           9.8536e-02,  2.0000e+00],\n",
              "         [ 1.5350e-01,  5.4808e-02, -1.9417e-02,  ...,  2.9737e-01,\n",
              "          -6.3422e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 3.6797e-02,  1.2707e-01,  1.1575e-01,  ...,  2.2642e-02,\n",
              "           4.0440e-02,  2.0000e+00],\n",
              "         [-1.7509e-01,  1.4473e-01,  3.1112e-01,  ...,  6.1675e-02,\n",
              "          -9.9694e-03,  2.0000e+00],\n",
              "         [-2.5923e-01,  9.9434e-02,  2.9439e-01,  ...,  6.5401e-02,\n",
              "          -2.7272e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0480e-02, -1.3206e-01, -3.3850e-02,  ...,  5.3427e-02,\n",
              "           2.1492e-01,  2.0000e+00],\n",
              "         [ 1.4095e-01, -3.4104e-02, -1.2636e-02,  ...,  2.5200e-01,\n",
              "           1.2735e-01,  2.0000e+00],\n",
              "         [ 1.4076e-01,  3.0157e-02,  7.1172e-03,  ...,  3.3444e-01,\n",
              "          -2.0593e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-6.0958e-02,  1.4041e-01,  2.0808e-01,  ...,  6.7428e-02,\n",
              "           8.9350e-03,  2.0000e+00],\n",
              "         [-2.3238e-01,  1.4156e-01,  3.2480e-01,  ...,  6.8771e-02,\n",
              "          -2.0778e-02,  2.0000e+00],\n",
              "         [-2.8188e-01,  1.0170e-01,  2.9643e-01,  ...,  6.8373e-02,\n",
              "           1.3287e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0189, -0.1494, -0.0344,  ...,  0.0628,  0.2212,  2.0000],\n",
              "         [ 0.1779, -0.0496, -0.0307,  ...,  0.2824,  0.1431,  2.0000],\n",
              "         [ 0.1598, -0.0125, -0.0086,  ...,  0.3689,  0.0216,  2.0000],\n",
              "         ...,\n",
              "         [-0.0660,  0.0961,  0.1838,  ...,  0.0748,  0.0084,  2.0000],\n",
              "         [-0.2067,  0.0887,  0.2664,  ...,  0.0745, -0.0260,  2.0000],\n",
              "         [-0.2670,  0.0808,  0.2661,  ...,  0.0732, -0.0054,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7641e-02, -1.1689e-01, -3.0395e-02,  ...,  3.3185e-02,\n",
              "           2.0425e-01,  2.0000e+00],\n",
              "         [ 1.2676e-01, -1.5169e-02, -8.8881e-04,  ...,  2.2432e-01,\n",
              "           9.7902e-02,  2.0000e+00],\n",
              "         [ 1.3022e-01,  5.1865e-02,  1.9130e-02,  ...,  2.9601e-01,\n",
              "          -5.0081e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1041e-02,  1.3217e-01,  1.7239e-01,  ...,  1.9780e-02,\n",
              "           3.2907e-02,  2.0000e+00],\n",
              "         [-2.1649e-01,  1.3611e-01,  3.4205e-01,  ...,  3.8540e-02,\n",
              "          -1.0245e-02,  2.0000e+00],\n",
              "         [-2.8335e-01,  9.9604e-02,  3.0914e-01,  ...,  4.1974e-02,\n",
              "          -6.2849e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-9.8420e-03, -1.0931e-01, -4.7014e-02,  ...,  2.9070e-02,\n",
              "           1.9950e-01,  2.0000e+00],\n",
              "         [ 1.3874e-01, -5.3800e-03, -1.6613e-02,  ...,  2.2245e-01,\n",
              "           6.8134e-02,  2.0000e+00],\n",
              "         [ 1.5082e-01,  5.6004e-02, -7.8898e-03,  ...,  2.9096e-01,\n",
              "          -7.7944e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 3.7561e-02,  9.2704e-02,  8.6146e-02,  ...,  1.1380e-02,\n",
              "           6.2928e-02,  2.0000e+00],\n",
              "         [-1.7834e-01,  1.3126e-01,  3.2465e-01,  ...,  5.3703e-02,\n",
              "          -1.1417e-03,  2.0000e+00],\n",
              "         [-2.7345e-01,  9.6321e-02,  3.0470e-01,  ...,  4.7671e-02,\n",
              "          -4.4984e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0233, -0.1322, -0.0290,  ...,  0.0474,  0.2166,  2.0000],\n",
              "         [ 0.1420, -0.0388, -0.0057,  ...,  0.2510,  0.1315,  2.0000],\n",
              "         [ 0.1422,  0.0217,  0.0194,  ...,  0.3242, -0.0056,  2.0000],\n",
              "         ...,\n",
              "         [-0.0892,  0.1484,  0.2343,  ...,  0.0535, -0.0099,  2.0000],\n",
              "         [-0.2390,  0.1375,  0.3330,  ...,  0.0531, -0.0310,  2.0000],\n",
              "         [-0.2852,  0.0999,  0.3014,  ...,  0.0574, -0.0062,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.3879e-02, -1.2151e-01, -3.7799e-02,  ...,  4.9614e-02,\n",
              "           2.1951e-01,  0.0000e+00],\n",
              "         [ 1.3172e-01, -3.8523e-02, -1.3612e-02,  ...,  2.2842e-01,\n",
              "           1.4104e-01,  0.0000e+00],\n",
              "         [ 1.3200e-01,  2.5007e-02,  5.8169e-03,  ...,  3.0963e-01,\n",
              "          -1.6314e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [-5.8885e-02,  1.4851e-01,  2.0884e-01,  ...,  5.7920e-02,\n",
              "           1.1769e-02,  0.0000e+00],\n",
              "         [-2.3365e-01,  1.3986e-01,  3.3589e-01,  ...,  6.1363e-02,\n",
              "          -1.6435e-02,  0.0000e+00],\n",
              "         [-2.8083e-01,  1.0071e-01,  3.0285e-01,  ...,  6.0071e-02,\n",
              "          -1.5618e-04,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0275, -0.1481, -0.0588,  ...,  0.0618,  0.2020,  0.0000],\n",
              "         [ 0.1369, -0.1174, -0.0624,  ...,  0.2624,  0.1660,  0.0000],\n",
              "         [ 0.0705, -0.1075, -0.0649,  ...,  0.3749,  0.0884,  0.0000],\n",
              "         ...,\n",
              "         [-0.2117,  0.0496,  0.1904,  ...,  0.0513, -0.0649,  0.0000],\n",
              "         [-0.2719,  0.0597,  0.2104,  ...,  0.0625, -0.0695,  0.0000],\n",
              "         [-0.2568,  0.0423,  0.2404,  ...,  0.0131, -0.0430,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0172, -0.1285, -0.0317,  ...,  0.0395,  0.2059,  0.0000],\n",
              "         [ 0.1336, -0.0329, -0.0071,  ...,  0.2486,  0.1120,  0.0000],\n",
              "         [ 0.1302,  0.0277,  0.0130,  ...,  0.3285, -0.0280,  0.0000],\n",
              "         ...,\n",
              "         [-0.0294,  0.1289,  0.1851,  ...,  0.0727,  0.0180,  0.0000],\n",
              "         [-0.2223,  0.1273,  0.3303,  ...,  0.0626, -0.0141,  0.0000],\n",
              "         [-0.2789,  0.0965,  0.2944,  ...,  0.0463, -0.0077,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0362, -0.1545, -0.0566,  ...,  0.0608,  0.2081,  0.0000],\n",
              "         [ 0.1375, -0.1180, -0.0785,  ...,  0.2888,  0.1611,  0.0000],\n",
              "         [ 0.0758, -0.1153, -0.0831,  ...,  0.3956,  0.0826,  0.0000],\n",
              "         ...,\n",
              "         [-0.1858,  0.0223,  0.1973,  ...,  0.1095, -0.0385,  0.0000],\n",
              "         [-0.2598,  0.0437,  0.1987,  ...,  0.0872, -0.0691,  0.0000],\n",
              "         [-0.2721,  0.0195,  0.2364,  ...,  0.0235, -0.0380,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1362, -0.0289,  ...,  0.0495,  0.2163,  0.0000],\n",
              "         [ 0.1506, -0.0484, -0.0107,  ...,  0.2488,  0.1374,  0.0000],\n",
              "         [ 0.1383,  0.0046,  0.0124,  ...,  0.3310, -0.0051,  0.0000],\n",
              "         ...,\n",
              "         [-0.0895,  0.1520,  0.2159,  ...,  0.0488,  0.0023,  0.0000],\n",
              "         [-0.2354,  0.1327,  0.3086,  ...,  0.0537, -0.0274,  0.0000],\n",
              "         [-0.2758,  0.0979,  0.2858,  ...,  0.0648, -0.0055,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.0883e-04, -1.1717e-01, -4.6158e-02,  ...,  5.7584e-02,\n",
              "           2.1865e-01,  0.0000e+00],\n",
              "         [ 1.4678e-01, -2.8229e-02, -2.8800e-02,  ...,  2.2544e-01,\n",
              "           1.2648e-01,  0.0000e+00],\n",
              "         [ 1.3577e-01,  3.2728e-02, -1.1863e-02,  ...,  3.1247e-01,\n",
              "          -3.8442e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2534e-02,  1.4765e-01,  1.3062e-01,  ...,  4.5345e-02,\n",
              "           4.0157e-02,  0.0000e+00],\n",
              "         [-1.8987e-01,  1.4854e-01,  2.9651e-01,  ...,  7.1456e-02,\n",
              "           2.8959e-03,  0.0000e+00],\n",
              "         [-2.4815e-01,  1.0712e-01,  2.8137e-01,  ...,  7.5892e-02,\n",
              "           5.3222e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0320, -0.1362, -0.0391,  ...,  0.0547,  0.2097,  0.0000],\n",
              "         [ 0.1443, -0.0725, -0.0530,  ...,  0.2704,  0.1395,  0.0000],\n",
              "         [ 0.1180, -0.0534, -0.0554,  ...,  0.3644,  0.0279,  0.0000],\n",
              "         ...,\n",
              "         [-0.1234,  0.0584,  0.2015,  ...,  0.0995,  0.0172,  0.0000],\n",
              "         [-0.2416,  0.0537,  0.2710,  ...,  0.0719, -0.0274,  0.0000],\n",
              "         [-0.2910,  0.0593,  0.2699,  ...,  0.0381, -0.0196,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0338, -0.1606, -0.0518,  ...,  0.0577,  0.2122,  0.0000],\n",
              "         [ 0.1419, -0.1097, -0.0736,  ...,  0.2911,  0.1528,  0.0000],\n",
              "         [ 0.0932, -0.1134, -0.0801,  ...,  0.3803,  0.0774,  0.0000],\n",
              "         ...,\n",
              "         [-0.1393,  0.0056,  0.1971,  ...,  0.1083,  0.0055,  0.0000],\n",
              "         [-0.2330,  0.0209,  0.2135,  ...,  0.0869, -0.0418,  0.0000],\n",
              "         [-0.2708,  0.0080,  0.2409,  ...,  0.0343, -0.0281,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0282, -0.1239, -0.0316,  ...,  0.0516,  0.2072,  0.0000],\n",
              "         [ 0.1371, -0.0618, -0.0343,  ...,  0.2624,  0.1375,  0.0000],\n",
              "         [ 0.1196, -0.0295, -0.0238,  ...,  0.3620,  0.0147,  0.0000],\n",
              "         ...,\n",
              "         [-0.1283,  0.1030,  0.2354,  ...,  0.0938, -0.0028,  0.0000],\n",
              "         [-0.2527,  0.0944,  0.3068,  ...,  0.0705, -0.0316,  0.0000],\n",
              "         [-0.2997,  0.0828,  0.2886,  ...,  0.0449, -0.0185,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0139, -0.1103, -0.0614,  ...,  0.0538,  0.2072,  0.0000],\n",
              "         [ 0.1674, -0.0143, -0.0544,  ...,  0.2175,  0.0998,  0.0000],\n",
              "         [ 0.1565,  0.0394, -0.0437,  ...,  0.3000, -0.0630,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0718,  0.1139,  0.0745,  ...,  0.0459,  0.0487,  0.0000],\n",
              "         [-0.1503,  0.1326,  0.2699,  ...,  0.0862, -0.0023,  0.0000],\n",
              "         [-0.2419,  0.0966,  0.2715,  ...,  0.0696,  0.0006,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0342, -0.1471, -0.0382,  ...,  0.0611,  0.2155,  0.0000],\n",
              "         [ 0.1653, -0.0831, -0.0491,  ...,  0.2877,  0.1609,  0.0000],\n",
              "         [ 0.1170, -0.0792, -0.0449,  ...,  0.3840,  0.0712,  0.0000],\n",
              "         ...,\n",
              "         [-0.1512,  0.0549,  0.2242,  ...,  0.1001,  0.0026,  0.0000],\n",
              "         [-0.2636,  0.0533,  0.2578,  ...,  0.0805, -0.0440,  0.0000],\n",
              "         [-0.2897,  0.0542,  0.2642,  ...,  0.0384, -0.0213,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0333, -0.1400, -0.0366,  ...,  0.0549,  0.2113,  0.0000],\n",
              "         [ 0.1483, -0.0713, -0.0500,  ...,  0.2789,  0.1475,  0.0000],\n",
              "         [ 0.1144, -0.0565, -0.0522,  ...,  0.3697,  0.0469,  0.0000],\n",
              "         ...,\n",
              "         [-0.1416,  0.0571,  0.2242,  ...,  0.0868,  0.0100,  0.0000],\n",
              "         [-0.2452,  0.0558,  0.2706,  ...,  0.0698, -0.0260,  0.0000],\n",
              "         [-0.2935,  0.0561,  0.2751,  ...,  0.0394, -0.0181,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0083, -0.1145, -0.0347,  ...,  0.0433,  0.2079,  0.0000],\n",
              "         [ 0.1606, -0.0110, -0.0163,  ...,  0.2575,  0.0965,  0.0000],\n",
              "         [ 0.1723,  0.0599, -0.0057,  ...,  0.3212, -0.0509,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0522,  0.1133,  0.1084,  ...,  0.0530,  0.0549,  0.0000],\n",
              "         [-0.1732,  0.1249,  0.3137,  ...,  0.0910,  0.0030,  0.0000],\n",
              "         [-0.2530,  0.1119,  0.2926,  ...,  0.0602,  0.0095,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0326, -0.1438, -0.0353,  ...,  0.0629,  0.2147,  0.0000],\n",
              "         [ 0.1669, -0.0710, -0.0383,  ...,  0.2783,  0.1527,  0.0000],\n",
              "         [ 0.1234, -0.0516, -0.0292,  ...,  0.3707,  0.0508,  0.0000],\n",
              "         ...,\n",
              "         [-0.1408,  0.0754,  0.2336,  ...,  0.0946, -0.0009,  0.0000],\n",
              "         [-0.2556,  0.0622,  0.2768,  ...,  0.0767, -0.0418,  0.0000],\n",
              "         [-0.2823,  0.0708,  0.2691,  ...,  0.0485, -0.0170,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0339, -0.1354, -0.0362,  ...,  0.0526,  0.2099,  0.0000],\n",
              "         [ 0.1371, -0.0674, -0.0421,  ...,  0.2685,  0.1467,  0.0000],\n",
              "         [ 0.1081, -0.0477, -0.0410,  ...,  0.3593,  0.0411,  0.0000],\n",
              "         ...,\n",
              "         [-0.1604,  0.0699,  0.2474,  ...,  0.0889,  0.0023,  0.0000],\n",
              "         [-0.2605,  0.0660,  0.2881,  ...,  0.0702, -0.0332,  0.0000],\n",
              "         [-0.3013,  0.0660,  0.2831,  ...,  0.0346, -0.0194,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0625, -0.2272, -0.1456,  ..., -0.0333,  0.1875,  0.0000],\n",
              "         [ 0.2969,  0.0071, -0.0937,  ..., -0.0363,  0.0344,  0.0000],\n",
              "         [ 0.3230,  0.0223, -0.0766,  ...,  0.0126, -0.0026,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1850, -0.0193, -0.1481,  ...,  0.0253,  0.0927,  0.0000],\n",
              "         [ 0.0839,  0.0330,  0.0438,  ...,  0.0960,  0.0184,  0.0000],\n",
              "         [-0.0987, -0.0140,  0.2586,  ...,  0.0200,  0.0381,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0077, -0.1099, -0.0512,  ...,  0.0300,  0.1974,  0.0000],\n",
              "         [ 0.1473, -0.0045, -0.0249,  ...,  0.2294,  0.0530,  0.0000],\n",
              "         [ 0.1592,  0.0555, -0.0205,  ...,  0.2982, -0.0912,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0513,  0.0868,  0.0702,  ...,  0.0170,  0.0557,  0.0000],\n",
              "         [-0.1681,  0.1239,  0.3209,  ...,  0.0639, -0.0087,  0.0000],\n",
              "         [-0.2676,  0.0931,  0.2998,  ...,  0.0503, -0.0040,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0189, -0.1235, -0.0322,  ...,  0.0473,  0.2173,  0.0000],\n",
              "         [ 0.1288, -0.0347, -0.0071,  ...,  0.2384,  0.1342,  0.0000],\n",
              "         [ 0.1265,  0.0262,  0.0147,  ...,  0.3136, -0.0160,  0.0000],\n",
              "         ...,\n",
              "         [-0.0348,  0.1400,  0.1950,  ...,  0.0470,  0.0283,  0.0000],\n",
              "         [-0.2229,  0.1448,  0.3309,  ...,  0.0561, -0.0061,  0.0000],\n",
              "         [-0.2844,  0.1004,  0.3012,  ...,  0.0566,  0.0003,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4243e-02, -1.3168e-01, -2.5890e-02,  ...,  4.3192e-02,\n",
              "           2.0882e-01,  0.0000e+00],\n",
              "         [ 1.3033e-01, -4.5713e-02, -2.2975e-04,  ...,  2.4609e-01,\n",
              "           1.3186e-01,  0.0000e+00],\n",
              "         [ 1.1984e-01,  1.7142e-04,  1.9868e-02,  ...,  3.2859e-01,\n",
              "           5.5061e-03,  0.0000e+00],\n",
              "         ...,\n",
              "         [-1.0918e-01,  1.3348e-01,  2.5376e-01,  ...,  8.0832e-02,\n",
              "          -4.0907e-03,  0.0000e+00],\n",
              "         [-2.5441e-01,  1.2491e-01,  3.4788e-01,  ...,  6.2181e-02,\n",
              "          -3.2565e-02,  0.0000e+00],\n",
              "         [-3.0228e-01,  9.1507e-02,  3.0338e-01,  ...,  4.7431e-02,\n",
              "          -1.5735e-02,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0086, -0.1154, -0.0358,  ...,  0.0434,  0.2093,  1.0000],\n",
              "         [ 0.1586, -0.0104, -0.0188,  ...,  0.2569,  0.0966,  1.0000],\n",
              "         [ 0.1705,  0.0608, -0.0075,  ...,  0.3206, -0.0513,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0550,  0.1120,  0.1072,  ...,  0.0519,  0.0531,  1.0000],\n",
              "         [-0.1733,  0.1246,  0.3171,  ...,  0.0910,  0.0020,  1.0000],\n",
              "         [-0.2525,  0.1092,  0.2935,  ...,  0.0624,  0.0092,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0305, -0.1552, -0.0607,  ...,  0.0580,  0.1912,  1.0000],\n",
              "         [ 0.1091, -0.1294, -0.0685,  ...,  0.2616,  0.1454,  1.0000],\n",
              "         [ 0.0406, -0.1277, -0.0828,  ...,  0.3602,  0.0818,  1.0000],\n",
              "         ...,\n",
              "         [-0.2322,  0.0524,  0.1981,  ...,  0.0335, -0.0855,  1.0000],\n",
              "         [-0.2681,  0.0613,  0.2041,  ...,  0.0336, -0.0821,  1.0000],\n",
              "         [-0.2425,  0.0306,  0.2365,  ..., -0.0061, -0.0507,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0314, -0.1325, -0.0361,  ...,  0.0548,  0.2159,  1.0000],\n",
              "         [ 0.1443, -0.0666, -0.0418,  ...,  0.2619,  0.1601,  1.0000],\n",
              "         [ 0.1083, -0.0456, -0.0334,  ...,  0.3583,  0.0486,  1.0000],\n",
              "         ...,\n",
              "         [-0.1723,  0.0822,  0.2538,  ...,  0.0821, -0.0121,  1.0000],\n",
              "         [-0.2733,  0.0709,  0.2908,  ...,  0.0698, -0.0447,  1.0000],\n",
              "         [-0.3016,  0.0724,  0.2816,  ...,  0.0401, -0.0176,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0194, -0.1399, -0.0436,  ...,  0.0745,  0.2111,  1.0000],\n",
              "         [ 0.1913, -0.0826, -0.0724,  ...,  0.3104,  0.1602,  1.0000],\n",
              "         [ 0.1606, -0.0701, -0.0795,  ...,  0.4165,  0.0620,  1.0000],\n",
              "         ...,\n",
              "         [-0.0610,  0.0310,  0.1492,  ...,  0.1700,  0.0293,  1.0000],\n",
              "         [-0.2097,  0.0506,  0.2574,  ...,  0.1393, -0.0053,  1.0000],\n",
              "         [-0.2830,  0.0569,  0.2500,  ...,  0.0730, -0.0086,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0328, -0.1350, -0.0310,  ...,  0.0646,  0.2140,  1.0000],\n",
              "         [ 0.1687, -0.0602, -0.0278,  ...,  0.2684,  0.1501,  1.0000],\n",
              "         [ 0.1372, -0.0309, -0.0154,  ...,  0.3635,  0.0417,  1.0000],\n",
              "         ...,\n",
              "         [-0.1260,  0.1120,  0.2290,  ...,  0.0819, -0.0019,  1.0000],\n",
              "         [-0.2546,  0.0920,  0.2861,  ...,  0.0684, -0.0344,  1.0000],\n",
              "         [-0.2847,  0.0875,  0.2728,  ...,  0.0534, -0.0108,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0315, -0.1609, -0.0497,  ...,  0.0565,  0.2115,  1.0000],\n",
              "         [ 0.1458, -0.1076, -0.0718,  ...,  0.2930,  0.1552,  1.0000],\n",
              "         [ 0.1097, -0.1125, -0.0765,  ...,  0.3717,  0.0943,  1.0000],\n",
              "         ...,\n",
              "         [-0.1389,  0.0057,  0.1988,  ...,  0.1088,  0.0054,  1.0000],\n",
              "         [-0.2241,  0.0082,  0.2227,  ...,  0.0853, -0.0303,  1.0000],\n",
              "         [-0.2712,  0.0081,  0.2448,  ...,  0.0369, -0.0218,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0227, -0.1368, -0.0304,  ...,  0.0579,  0.2173,  1.0000],\n",
              "         [ 0.1527, -0.0453, -0.0143,  ...,  0.2615,  0.1365,  1.0000],\n",
              "         [ 0.1411,  0.0070,  0.0038,  ...,  0.3461, -0.0064,  1.0000],\n",
              "         ...,\n",
              "         [-0.0967,  0.1533,  0.2261,  ...,  0.0719, -0.0045,  1.0000],\n",
              "         [-0.2437,  0.1341,  0.3155,  ...,  0.0672, -0.0315,  1.0000],\n",
              "         [-0.2791,  0.1026,  0.2887,  ...,  0.0724, -0.0013,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0024, -0.1822, -0.0832,  ...,  0.0868,  0.2113,  1.0000],\n",
              "         [ 0.2184, -0.1499, -0.1397,  ...,  0.3405,  0.1578,  1.0000],\n",
              "         [ 0.1883, -0.1481, -0.1563,  ...,  0.4455,  0.0864,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0028, -0.0693,  0.0537,  ...,  0.2012,  0.0220,  1.0000],\n",
              "         [-0.1268, -0.0352,  0.1391,  ...,  0.1672, -0.0112,  1.0000],\n",
              "         [-0.2258, -0.0357,  0.1806,  ...,  0.0807, -0.0199,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0223, -0.1391, -0.0300,  ...,  0.0485,  0.2101,  1.0000],\n",
              "         [ 0.1472, -0.0494, -0.0206,  ...,  0.2751,  0.1305,  1.0000],\n",
              "         [ 0.1304, -0.0094, -0.0060,  ...,  0.3630,  0.0120,  1.0000],\n",
              "         ...,\n",
              "         [-0.0866,  0.0957,  0.2034,  ...,  0.0898,  0.0071,  1.0000],\n",
              "         [-0.2261,  0.0884,  0.2986,  ...,  0.0714, -0.0269,  1.0000],\n",
              "         [-0.2880,  0.0811,  0.2898,  ...,  0.0562, -0.0147,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0230, -0.1291, -0.0295,  ...,  0.0492,  0.2164,  1.0000],\n",
              "         [ 0.1270, -0.0475, -0.0078,  ...,  0.2306,  0.1382,  1.0000],\n",
              "         [ 0.1229,  0.0083,  0.0151,  ...,  0.3108, -0.0091,  1.0000],\n",
              "         ...,\n",
              "         [-0.1200,  0.1552,  0.2584,  ...,  0.0524, -0.0062,  1.0000],\n",
              "         [-0.2531,  0.1388,  0.3468,  ...,  0.0529, -0.0309,  1.0000],\n",
              "         [-0.2921,  0.1007,  0.3056,  ...,  0.0550, -0.0032,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0178, -0.1265, -0.0266,  ...,  0.0445,  0.2115,  1.0000],\n",
              "         [ 0.1455, -0.0351, -0.0019,  ...,  0.2597,  0.1222,  1.0000],\n",
              "         [ 0.1481,  0.0259,  0.0130,  ...,  0.3342, -0.0134,  1.0000],\n",
              "         ...,\n",
              "         [-0.0408,  0.1226,  0.2110,  ...,  0.0780,  0.0154,  1.0000],\n",
              "         [-0.2269,  0.1282,  0.3409,  ...,  0.0770, -0.0132,  1.0000],\n",
              "         [-0.2758,  0.1076,  0.2997,  ...,  0.0560,  0.0055,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0244, -0.1548, -0.0607,  ...,  0.0491,  0.1810,  1.0000],\n",
              "         [ 0.1004, -0.1331, -0.0546,  ...,  0.2349,  0.1448,  1.0000],\n",
              "         [ 0.0311, -0.1349, -0.0766,  ...,  0.3291,  0.0884,  1.0000],\n",
              "         ...,\n",
              "         [-0.2164,  0.0547,  0.2233,  ..., -0.0354, -0.0913,  1.0000],\n",
              "         [-0.2482,  0.0744,  0.2285,  ..., -0.0276, -0.0877,  1.0000],\n",
              "         [-0.2098,  0.0558,  0.2460,  ..., -0.0406, -0.0598,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1501, -0.0529,  ...,  0.0615,  0.2065,  1.0000],\n",
              "         [ 0.1365, -0.1111, -0.0617,  ...,  0.2790,  0.1637,  1.0000],\n",
              "         [ 0.0751, -0.1082, -0.0590,  ...,  0.3839,  0.0878,  1.0000],\n",
              "         ...,\n",
              "         [-0.1943,  0.0303,  0.2049,  ...,  0.0939, -0.0393,  1.0000],\n",
              "         [-0.2709,  0.0517,  0.2116,  ...,  0.0804, -0.0661,  1.0000],\n",
              "         [-0.2716,  0.0433,  0.2423,  ...,  0.0249, -0.0347,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0090, -0.1089, -0.0491,  ...,  0.0296,  0.1976,  1.0000],\n",
              "         [ 0.1476, -0.0013, -0.0242,  ...,  0.2312,  0.0548,  1.0000],\n",
              "         [ 0.1607,  0.0584, -0.0205,  ...,  0.2955, -0.0869,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0485,  0.0933,  0.0717,  ...,  0.0200,  0.0449,  1.0000],\n",
              "         [-0.1706,  0.1285,  0.3241,  ...,  0.0633, -0.0167,  1.0000],\n",
              "         [-0.2690,  0.0923,  0.3049,  ...,  0.0510, -0.0070,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0367, -0.1583, -0.0618,  ...,  0.0636,  0.2067,  1.0000],\n",
              "         [ 0.1261, -0.1288, -0.0805,  ...,  0.2977,  0.1514,  1.0000],\n",
              "         [ 0.0664, -0.1263, -0.0899,  ...,  0.3986,  0.0772,  1.0000],\n",
              "         ...,\n",
              "         [-0.1823,  0.0181,  0.1853,  ...,  0.1065, -0.0486,  1.0000],\n",
              "         [-0.2371,  0.0323,  0.1856,  ...,  0.0898, -0.0704,  1.0000],\n",
              "         [-0.2600,  0.0048,  0.2252,  ...,  0.0274, -0.0372,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0045, -0.1181, -0.0528,  ...,  0.0487,  0.2133,  1.0000],\n",
              "         [ 0.1482, -0.0078, -0.0335,  ...,  0.2257,  0.1095,  1.0000],\n",
              "         [ 0.1523,  0.0480, -0.0192,  ...,  0.3086, -0.0531,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0482,  0.1221,  0.0952,  ...,  0.0288,  0.0465,  1.0000],\n",
              "         [-0.1746,  0.1430,  0.2963,  ...,  0.0665, -0.0037,  1.0000],\n",
              "         [-0.2580,  0.1045,  0.2846,  ...,  0.0669,  0.0025,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.2556e-02, -1.2572e-01, -2.8697e-02,  ...,  6.1144e-02,\n",
              "           2.1114e-01,  1.0000e+00],\n",
              "         [ 1.4668e-01, -5.2171e-02, -2.2656e-02,  ...,  2.5333e-01,\n",
              "           1.4532e-01,  1.0000e+00],\n",
              "         [ 1.2513e-01, -2.1004e-02, -1.7909e-04,  ...,  3.4524e-01,\n",
              "           3.1612e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.5078e-01,  1.2665e-01,  2.5810e-01,  ...,  6.8863e-02,\n",
              "          -1.7656e-02,  1.0000e+00],\n",
              "         [-2.6117e-01,  1.0680e-01,  3.1330e-01,  ...,  6.5198e-02,\n",
              "          -4.1195e-02,  1.0000e+00],\n",
              "         [-2.9526e-01,  9.1232e-02,  2.8735e-01,  ...,  4.3076e-02,\n",
              "          -1.3017e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0334, -0.1465, -0.0411,  ...,  0.0550,  0.2145,  1.0000],\n",
              "         [ 0.1485, -0.0831, -0.0655,  ...,  0.2836,  0.1563,  1.0000],\n",
              "         [ 0.1065, -0.0750, -0.0708,  ...,  0.3785,  0.0592,  1.0000],\n",
              "         ...,\n",
              "         [-0.1342,  0.0370,  0.2058,  ...,  0.1069,  0.0242,  1.0000],\n",
              "         [-0.2447,  0.0356,  0.2605,  ...,  0.0804, -0.0276,  1.0000],\n",
              "         [-0.2945,  0.0401,  0.2669,  ...,  0.0372, -0.0197,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0372, -0.1549, -0.0543,  ...,  0.0600,  0.2101,  1.0000],\n",
              "         [ 0.1409, -0.1159, -0.0748,  ...,  0.2889,  0.1629,  1.0000],\n",
              "         [ 0.0826, -0.1147, -0.0787,  ...,  0.3913,  0.0874,  1.0000],\n",
              "         ...,\n",
              "         [-0.1773,  0.0184,  0.2040,  ...,  0.1133, -0.0253,  1.0000],\n",
              "         [-0.2584,  0.0415,  0.2086,  ...,  0.0889, -0.0639,  1.0000],\n",
              "         [-0.2762,  0.0198,  0.2422,  ...,  0.0258, -0.0345,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0336, -0.1254, -0.0315,  ...,  0.0548,  0.2075,  1.0000],\n",
              "         [ 0.1357, -0.0615, -0.0373,  ...,  0.2708,  0.1400,  1.0000],\n",
              "         [ 0.1087, -0.0377, -0.0329,  ...,  0.3665,  0.0333,  1.0000],\n",
              "         ...,\n",
              "         [-0.1454,  0.0873,  0.2399,  ...,  0.0965, -0.0022,  1.0000],\n",
              "         [-0.2609,  0.0772,  0.2986,  ...,  0.0747, -0.0360,  1.0000],\n",
              "         [-0.3053,  0.0795,  0.2850,  ...,  0.0366, -0.0173,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0310, -0.1498, -0.0573,  ...,  0.0567,  0.1979,  1.0000],\n",
              "         [ 0.1198, -0.1199, -0.0638,  ...,  0.2464,  0.1587,  1.0000],\n",
              "         [ 0.0539, -0.1103, -0.0673,  ...,  0.3558,  0.0816,  1.0000],\n",
              "         ...,\n",
              "         [-0.2261,  0.0461,  0.1938,  ...,  0.0379, -0.0726,  1.0000],\n",
              "         [-0.2788,  0.0647,  0.2129,  ...,  0.0472, -0.0738,  1.0000],\n",
              "         [-0.2569,  0.0443,  0.2424,  ...,  0.0039, -0.0473,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0208, -0.1330, -0.0281,  ...,  0.0510,  0.2134,  1.0000],\n",
              "         [ 0.1399, -0.0439, -0.0074,  ...,  0.2460,  0.1304,  1.0000],\n",
              "         [ 0.1381,  0.0175,  0.0126,  ...,  0.3249, -0.0153,  1.0000],\n",
              "         ...,\n",
              "         [-0.0768,  0.1485,  0.2203,  ...,  0.0572,  0.0109,  1.0000],\n",
              "         [-0.2410,  0.1381,  0.3311,  ...,  0.0599, -0.0164,  1.0000],\n",
              "         [-0.2815,  0.1036,  0.2963,  ...,  0.0633,  0.0040,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.1872e-02, -1.3559e-01, -2.8791e-02,  ...,  5.0659e-02,\n",
              "           2.1625e-01,  1.0000e+00],\n",
              "         [ 1.3820e-01, -3.6319e-02, -3.9881e-05,  ...,  2.3540e-01,\n",
              "           1.2789e-01,  1.0000e+00],\n",
              "         [ 1.3594e-01,  2.2483e-02,  2.3177e-02,  ...,  3.0771e-01,\n",
              "          -9.7790e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-6.3691e-02,  1.5105e-01,  2.1280e-01,  ...,  4.6792e-02,\n",
              "           8.4836e-03,  1.0000e+00],\n",
              "         [-2.3571e-01,  1.4274e-01,  3.2911e-01,  ...,  5.1271e-02,\n",
              "          -2.3928e-02,  1.0000e+00],\n",
              "         [-2.7759e-01,  1.0504e-01,  2.9768e-01,  ...,  5.9459e-02,\n",
              "          -6.6379e-04,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0275, -0.1390, -0.0277,  ...,  0.0535,  0.2159,  1.0000],\n",
              "         [ 0.1460, -0.0490, -0.0114,  ...,  0.2495,  0.1433,  1.0000],\n",
              "         [ 0.1335, -0.0046,  0.0137,  ...,  0.3302,  0.0135,  1.0000],\n",
              "         ...,\n",
              "         [-0.1264,  0.1450,  0.2406,  ...,  0.0515, -0.0068,  1.0000],\n",
              "         [-0.2508,  0.1221,  0.3149,  ...,  0.0531, -0.0331,  1.0000],\n",
              "         [-0.2885,  0.0951,  0.2906,  ...,  0.0557, -0.0074,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0382, -0.1490, -0.0448,  ...,  0.0611,  0.2163,  1.0000],\n",
              "         [ 0.1509, -0.0978, -0.0582,  ...,  0.2817,  0.1693,  1.0000],\n",
              "         [ 0.0978, -0.0879, -0.0572,  ...,  0.3811,  0.0800,  1.0000],\n",
              "         ...,\n",
              "         [-0.1681,  0.0284,  0.2265,  ...,  0.0939, -0.0029,  1.0000],\n",
              "         [-0.2686,  0.0415,  0.2412,  ...,  0.0739, -0.0453,  1.0000],\n",
              "         [-0.2865,  0.0434,  0.2580,  ...,  0.0290, -0.0224,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.7631e-02, -1.6313e-01, -5.4386e-02,  ...,  5.9113e-02,\n",
              "           2.1107e-01,  1.0000e+00],\n",
              "         [ 1.4845e-01, -1.1357e-01, -7.9745e-02,  ...,  2.9588e-01,\n",
              "           1.5301e-01,  1.0000e+00],\n",
              "         [ 1.0435e-01, -1.1743e-01, -8.5544e-02,  ...,  3.8766e-01,\n",
              "           7.9048e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1741e-01, -2.5597e-03,  1.8525e-01,  ...,  1.2008e-01,\n",
              "           1.0535e-02,  1.0000e+00],\n",
              "         [-2.1244e-01,  6.5126e-03,  2.0720e-01,  ...,  9.1751e-02,\n",
              "          -3.2471e-02,  1.0000e+00],\n",
              "         [-2.5996e-01,  8.8598e-04,  2.3458e-01,  ...,  3.9577e-02,\n",
              "          -2.5760e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0341, -0.1385, -0.0351,  ...,  0.0512,  0.2098,  1.0000],\n",
              "         [ 0.1426, -0.0741, -0.0521,  ...,  0.2703,  0.1489,  1.0000],\n",
              "         [ 0.1040, -0.0607, -0.0546,  ...,  0.3604,  0.0540,  1.0000],\n",
              "         ...,\n",
              "         [-0.1448,  0.0603,  0.2246,  ...,  0.0931,  0.0176,  1.0000],\n",
              "         [-0.2528,  0.0478,  0.2784,  ...,  0.0681, -0.0274,  1.0000],\n",
              "         [-0.3013,  0.0568,  0.2780,  ...,  0.0349, -0.0195,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0289, -0.1245, -0.0304,  ...,  0.0563,  0.2067,  1.0000],\n",
              "         [ 0.1412, -0.0602, -0.0324,  ...,  0.2699,  0.1371,  1.0000],\n",
              "         [ 0.1213, -0.0302, -0.0217,  ...,  0.3695,  0.0191,  1.0000],\n",
              "         ...,\n",
              "         [-0.1177,  0.0991,  0.2218,  ...,  0.0999,  0.0052,  1.0000],\n",
              "         [-0.2507,  0.0938,  0.3013,  ...,  0.0774, -0.0306,  1.0000],\n",
              "         [-0.3003,  0.0856,  0.2855,  ...,  0.0473, -0.0166,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0222, -0.1439, -0.0277,  ...,  0.0542,  0.2187,  1.0000],\n",
              "         [ 0.1599, -0.0516, -0.0135,  ...,  0.2564,  0.1436,  1.0000],\n",
              "         [ 0.1396, -0.0090,  0.0112,  ...,  0.3399,  0.0165,  1.0000],\n",
              "         ...,\n",
              "         [-0.0906,  0.1315,  0.2102,  ...,  0.0537,  0.0078,  1.0000],\n",
              "         [-0.2304,  0.1147,  0.2950,  ...,  0.0550, -0.0279,  1.0000],\n",
              "         [-0.2772,  0.0922,  0.2806,  ...,  0.0647, -0.0071,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6255e-02, -1.3116e-01, -2.7601e-02,  ...,  4.9364e-02,\n",
              "           2.1231e-01,  1.0000e+00],\n",
              "         [ 1.5492e-01, -3.9901e-02, -8.4701e-03,  ...,  2.7334e-01,\n",
              "           1.2969e-01,  1.0000e+00],\n",
              "         [ 1.5339e-01,  1.4719e-02,  4.6807e-03,  ...,  3.5616e-01,\n",
              "           4.8762e-04,  1.0000e+00],\n",
              "         ...,\n",
              "         [-6.1114e-02,  1.2092e-01,  2.1708e-01,  ...,  9.6013e-02,\n",
              "           1.5194e-02,  1.0000e+00],\n",
              "         [-2.2612e-01,  1.1956e-01,  3.2569e-01,  ...,  8.7038e-02,\n",
              "          -1.8172e-02,  1.0000e+00],\n",
              "         [-2.7562e-01,  1.0075e-01,  2.9283e-01,  ...,  6.3019e-02,\n",
              "           2.0946e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0020, -0.1443, -0.0725,  ...,  0.0365,  0.1673,  1.0000],\n",
              "         [ 0.0961, -0.1222, -0.0700,  ...,  0.1959,  0.1386,  1.0000],\n",
              "         [ 0.0358, -0.1201, -0.0961,  ...,  0.2737,  0.0952,  1.0000],\n",
              "         ...,\n",
              "         [-0.1293,  0.0280,  0.2881,  ..., -0.0491, -0.1084,  1.0000],\n",
              "         [-0.2231,  0.0918,  0.2523,  ..., -0.0457, -0.0988,  1.0000],\n",
              "         [-0.1706,  0.1142,  0.2579,  ..., -0.0724, -0.0784,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0170, -0.1470, -0.0685,  ...,  0.0464,  0.1808,  1.0000],\n",
              "         [ 0.1044, -0.1260, -0.0627,  ...,  0.2152,  0.1498,  1.0000],\n",
              "         [ 0.0360, -0.1248, -0.0772,  ...,  0.3229,  0.0883,  1.0000],\n",
              "         ...,\n",
              "         [-0.2056,  0.0468,  0.2363,  ..., -0.0484, -0.0927,  1.0000],\n",
              "         [-0.2479,  0.0743,  0.2416,  ..., -0.0393, -0.0891,  1.0000],\n",
              "         [-0.1976,  0.0782,  0.2526,  ..., -0.0404, -0.0650,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0325, -0.1484, -0.0352,  ...,  0.0600,  0.2168,  1.0000],\n",
              "         [ 0.1653, -0.0729, -0.0410,  ...,  0.2721,  0.1664,  1.0000],\n",
              "         [ 0.1194, -0.0532, -0.0307,  ...,  0.3618,  0.0675,  1.0000],\n",
              "         ...,\n",
              "         [-0.1319,  0.0783,  0.2223,  ...,  0.0823,  0.0140,  1.0000],\n",
              "         [-0.2573,  0.0649,  0.2716,  ...,  0.0656, -0.0382,  1.0000],\n",
              "         [-0.2907,  0.0575,  0.2693,  ...,  0.0427, -0.0213,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0236, -0.1296, -0.0244,  ...,  0.0434,  0.2087,  1.0000],\n",
              "         [ 0.1329, -0.0411, -0.0029,  ...,  0.2525,  0.1281,  1.0000],\n",
              "         [ 0.1222,  0.0094,  0.0204,  ...,  0.3345,  0.0034,  1.0000],\n",
              "         ...,\n",
              "         [-0.1073,  0.1306,  0.2461,  ...,  0.0741, -0.0050,  1.0000],\n",
              "         [-0.2543,  0.1203,  0.3426,  ...,  0.0613, -0.0324,  1.0000],\n",
              "         [-0.3015,  0.0928,  0.3051,  ...,  0.0480, -0.0136,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0148, -0.1228, -0.0357,  ...,  0.0455,  0.2155,  1.0000],\n",
              "         [ 0.1363, -0.0211, -0.0144,  ...,  0.2330,  0.1247,  1.0000],\n",
              "         [ 0.1411,  0.0406,  0.0081,  ...,  0.3128, -0.0300,  1.0000],\n",
              "         ...,\n",
              "         [-0.0137,  0.1322,  0.1655,  ...,  0.0429,  0.0233,  1.0000],\n",
              "         [-0.2080,  0.1377,  0.3220,  ...,  0.0526, -0.0106,  1.0000],\n",
              "         [-0.2691,  0.0997,  0.2953,  ...,  0.0606, -0.0037,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0188, -0.1476, -0.0345,  ...,  0.0568,  0.2204,  1.0000],\n",
              "         [ 0.1673, -0.0487, -0.0293,  ...,  0.2723,  0.1422,  1.0000],\n",
              "         [ 0.1469, -0.0138, -0.0092,  ...,  0.3558,  0.0170,  1.0000],\n",
              "         ...,\n",
              "         [-0.0514,  0.1012,  0.1589,  ...,  0.0611,  0.0227,  1.0000],\n",
              "         [-0.2069,  0.0970,  0.2656,  ...,  0.0599, -0.0292,  1.0000],\n",
              "         [-0.2666,  0.0747,  0.2689,  ...,  0.0672, -0.0141,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.2078e-02, -1.5022e-01, -4.0993e-02,  ...,  6.1971e-02,\n",
              "           2.1797e-01,  1.0000e+00],\n",
              "         [ 1.6834e-01, -7.9375e-02, -5.4503e-02,  ...,  2.8697e-01,\n",
              "           1.6514e-01,  1.0000e+00],\n",
              "         [ 1.2340e-01, -6.6018e-02, -4.8858e-02,  ...,  3.8119e-01,\n",
              "           6.7405e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.4040e-01,  4.8622e-02,  2.1850e-01,  ...,  8.2022e-02,\n",
              "           2.5784e-04,  1.0000e+00],\n",
              "         [-2.4322e-01,  5.2371e-02,  2.5003e-01,  ...,  7.3669e-02,\n",
              "          -3.8192e-02,  1.0000e+00],\n",
              "         [-2.8261e-01,  4.0713e-02,  2.5855e-01,  ...,  3.8048e-02,\n",
              "          -2.0552e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.1726e-02, -1.2283e-01, -3.0922e-02,  ...,  4.5595e-02,\n",
              "           2.1106e-01,  2.0000e+00],\n",
              "         [ 1.5588e-01, -2.3347e-02, -1.1526e-02,  ...,  2.6295e-01,\n",
              "           1.1734e-01,  2.0000e+00],\n",
              "         [ 1.6154e-01,  4.3036e-02,  2.1518e-03,  ...,  3.3611e-01,\n",
              "          -2.4011e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.7558e-03,  1.2030e-01,  1.7112e-01,  ...,  7.5577e-02,\n",
              "           3.3277e-02,  2.0000e+00],\n",
              "         [-2.0500e-01,  1.2425e-01,  3.2863e-01,  ...,  8.2974e-02,\n",
              "          -2.3121e-03,  2.0000e+00],\n",
              "         [-2.6202e-01,  1.0717e-01,  2.9384e-01,  ...,  6.0992e-02,\n",
              "           7.0301e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0245, -0.1581, -0.0633,  ...,  0.0535,  0.1844,  2.0000],\n",
              "         [ 0.1113, -0.1333, -0.0628,  ...,  0.2435,  0.1495,  2.0000],\n",
              "         [ 0.0436, -0.1337, -0.0792,  ...,  0.3411,  0.0898,  2.0000],\n",
              "         ...,\n",
              "         [-0.2242,  0.0497,  0.2027,  ..., -0.0074, -0.0887,  2.0000],\n",
              "         [-0.2627,  0.0676,  0.2095,  ...,  0.0041, -0.0833,  2.0000],\n",
              "         [-0.2258,  0.0374,  0.2347,  ..., -0.0252, -0.0555,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0363, -0.1516, -0.0490,  ...,  0.0653,  0.2116,  2.0000],\n",
              "         [ 0.1587, -0.1027, -0.0586,  ...,  0.2983,  0.1659,  2.0000],\n",
              "         [ 0.1050, -0.0955, -0.0567,  ...,  0.4015,  0.0779,  2.0000],\n",
              "         ...,\n",
              "         [-0.1647,  0.0344,  0.2158,  ...,  0.1075, -0.0112,  2.0000],\n",
              "         [-0.2610,  0.0564,  0.2225,  ...,  0.0865, -0.0522,  2.0000],\n",
              "         [-0.2709,  0.0403,  0.2441,  ...,  0.0338, -0.0255,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4939e-02, -1.3293e-01, -2.4407e-02,  ...,  4.4255e-02,\n",
              "           2.0842e-01,  2.0000e+00],\n",
              "         [ 1.3504e-01, -4.5279e-02, -2.4269e-03,  ...,  2.4952e-01,\n",
              "           1.3071e-01,  2.0000e+00],\n",
              "         [ 1.2007e-01, -8.3314e-04,  2.0618e-02,  ...,  3.3244e-01,\n",
              "           9.1180e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1248e-01,  1.2969e-01,  2.4567e-01,  ...,  7.3087e-02,\n",
              "          -2.1623e-03,  2.0000e+00],\n",
              "         [-2.5572e-01,  1.2217e-01,  3.3721e-01,  ...,  5.9610e-02,\n",
              "          -3.2654e-02,  2.0000e+00],\n",
              "         [-3.0304e-01,  9.3343e-02,  3.0124e-01,  ...,  4.5532e-02,\n",
              "          -1.4060e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5712e-02, -1.3768e-01, -2.7582e-02,  ...,  5.2898e-02,\n",
              "           2.1514e-01,  2.0000e+00],\n",
              "         [ 1.5153e-01, -4.7089e-02, -8.1242e-03,  ...,  2.5808e-01,\n",
              "           1.3593e-01,  2.0000e+00],\n",
              "         [ 1.3576e-01,  5.8730e-04,  1.7075e-02,  ...,  3.3903e-01,\n",
              "           9.9539e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.2469e-01,  1.4247e-01,  2.4638e-01,  ...,  6.1758e-02,\n",
              "          -1.1523e-02,  2.0000e+00],\n",
              "         [-2.5020e-01,  1.2549e-01,  3.2038e-01,  ...,  5.9976e-02,\n",
              "          -3.7186e-02,  2.0000e+00],\n",
              "         [-2.9029e-01,  9.3792e-02,  2.9537e-01,  ...,  5.7936e-02,\n",
              "          -1.1005e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0208, -0.1245, -0.0265,  ...,  0.0375,  0.2076,  2.0000],\n",
              "         [ 0.1236, -0.0242,  0.0064,  ...,  0.2285,  0.1129,  2.0000],\n",
              "         [ 0.1225,  0.0363,  0.0272,  ...,  0.3028, -0.0225,  2.0000],\n",
              "         ...,\n",
              "         [-0.0438,  0.1359,  0.2087,  ...,  0.0391,  0.0234,  2.0000],\n",
              "         [-0.2319,  0.1269,  0.3518,  ...,  0.0439, -0.0129,  2.0000],\n",
              "         [-0.2912,  0.0990,  0.3094,  ...,  0.0406, -0.0039,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0165, -0.1161, -0.0378,  ...,  0.0473,  0.2129,  2.0000],\n",
              "         [ 0.1355, -0.0204, -0.0156,  ...,  0.2428,  0.1123,  2.0000],\n",
              "         [ 0.1435,  0.0484,  0.0052,  ...,  0.3124, -0.0454,  2.0000],\n",
              "         ...,\n",
              "         [-0.0217,  0.1364,  0.1818,  ...,  0.0481,  0.0100,  2.0000],\n",
              "         [-0.2190,  0.1376,  0.3357,  ...,  0.0658, -0.0150,  2.0000],\n",
              "         [-0.2717,  0.1078,  0.3050,  ...,  0.0680,  0.0067,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0340, -0.1445, -0.0332,  ...,  0.0588,  0.2117,  2.0000],\n",
              "         [ 0.1643, -0.0691, -0.0358,  ...,  0.2685,  0.1522,  2.0000],\n",
              "         [ 0.1224, -0.0481, -0.0234,  ...,  0.3540,  0.0519,  2.0000],\n",
              "         ...,\n",
              "         [-0.1478,  0.0856,  0.2391,  ...,  0.0732, -0.0036,  2.0000],\n",
              "         [-0.2619,  0.0680,  0.2791,  ...,  0.0639, -0.0417,  2.0000],\n",
              "         [-0.2877,  0.0714,  0.2710,  ...,  0.0457, -0.0191,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0066, -0.1093, -0.0544,  ...,  0.0396,  0.2051,  2.0000],\n",
              "         [ 0.1857, -0.0024, -0.0463,  ...,  0.2552,  0.0565,  2.0000],\n",
              "         [ 0.1981,  0.0563, -0.0450,  ...,  0.3148, -0.0784,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1131,  0.0679,  0.0157,  ...,  0.0641,  0.0724,  2.0000],\n",
              "         [-0.1241,  0.1211,  0.2882,  ...,  0.1128, -0.0050,  2.0000],\n",
              "         [-0.2370,  0.1029,  0.2821,  ...,  0.0684,  0.0050,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1984e-02, -1.2134e-01, -3.2038e-02,  ...,  4.6397e-02,\n",
              "           2.0974e-01,  2.0000e+00],\n",
              "         [ 1.4985e-01, -2.2323e-02, -1.3322e-02,  ...,  2.5942e-01,\n",
              "           1.1283e-01,  2.0000e+00],\n",
              "         [ 1.5735e-01,  4.6191e-02, -8.2761e-04,  ...,  3.3204e-01,\n",
              "          -3.0997e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 5.1403e-03,  1.2272e-01,  1.6690e-01,  ...,  6.9443e-02,\n",
              "           3.3369e-02,  2.0000e+00],\n",
              "         [-2.0625e-01,  1.2513e-01,  3.2933e-01,  ...,  8.2635e-02,\n",
              "          -1.0463e-03,  2.0000e+00],\n",
              "         [-2.6111e-01,  1.0775e-01,  2.9328e-01,  ...,  6.0071e-02,\n",
              "           8.6579e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.4596e-02, -1.3074e-01, -2.8557e-02,  ...,  5.7997e-02,\n",
              "           2.1015e-01,  2.0000e+00],\n",
              "         [ 1.5636e-01, -5.4878e-02, -2.4236e-02,  ...,  2.5508e-01,\n",
              "           1.4573e-01,  2.0000e+00],\n",
              "         [ 1.2734e-01, -2.3958e-02, -9.5521e-04,  ...,  3.4167e-01,\n",
              "           3.8848e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.6026e-01,  1.2411e-01,  2.5883e-01,  ...,  6.5361e-02,\n",
              "          -9.2375e-03,  2.0000e+00],\n",
              "         [-2.6896e-01,  1.0609e-01,  3.0502e-01,  ...,  6.3294e-02,\n",
              "          -3.9318e-02,  2.0000e+00],\n",
              "         [-2.9957e-01,  8.8913e-02,  2.8474e-01,  ...,  4.2924e-02,\n",
              "          -1.6787e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.0829e-02, -1.2323e-01, -2.8626e-02,  ...,  5.4743e-02,\n",
              "           2.0678e-01,  2.0000e+00],\n",
              "         [ 1.3885e-01, -5.5296e-02, -2.8257e-02,  ...,  2.5526e-01,\n",
              "           1.4201e-01,  2.0000e+00],\n",
              "         [ 1.1861e-01, -2.5559e-02, -1.3235e-02,  ...,  3.5060e-01,\n",
              "           2.4364e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.3116e-01,  1.1082e-01,  2.3713e-01,  ...,  8.3624e-02,\n",
              "           1.7482e-03,  2.0000e+00],\n",
              "         [-2.6023e-01,  1.0017e-01,  3.1038e-01,  ...,  6.7005e-02,\n",
              "          -3.2659e-02,  2.0000e+00],\n",
              "         [-3.0487e-01,  8.8763e-02,  2.8856e-01,  ...,  4.4172e-02,\n",
              "          -1.7646e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-5.0604e-03, -1.1046e-01, -5.2190e-02,  ...,  4.6181e-02,\n",
              "           2.1384e-01,  2.0000e+00],\n",
              "         [ 1.5506e-01, -2.1549e-03, -3.6107e-02,  ...,  2.3563e-01,\n",
              "           1.0781e-01,  2.0000e+00],\n",
              "         [ 1.6190e-01,  5.4964e-02, -1.7825e-02,  ...,  3.1288e-01,\n",
              "          -5.5066e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 5.7091e-02,  1.1605e-01,  9.1366e-02,  ...,  3.2839e-02,\n",
              "           4.4908e-02,  2.0000e+00],\n",
              "         [-1.6714e-01,  1.4378e-01,  2.9216e-01,  ...,  6.8425e-02,\n",
              "          -1.2240e-03,  2.0000e+00],\n",
              "         [-2.5569e-01,  1.0733e-01,  2.8324e-01,  ...,  7.0209e-02,\n",
              "           8.0639e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0188, -0.1235, -0.0316,  ...,  0.0387,  0.2053,  2.0000],\n",
              "         [ 0.1335, -0.0177, -0.0033,  ...,  0.2401,  0.1035,  2.0000],\n",
              "         [ 0.1339,  0.0447,  0.0137,  ...,  0.3126, -0.0375,  2.0000],\n",
              "         ...,\n",
              "         [-0.0108,  0.1307,  0.1687,  ...,  0.0460,  0.0268,  2.0000],\n",
              "         [-0.2173,  0.1243,  0.3334,  ...,  0.0538, -0.0134,  2.0000],\n",
              "         [-0.2807,  0.0978,  0.3019,  ...,  0.0435, -0.0040,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3231e-02, -1.2982e-01, -2.4877e-02,  ...,  4.2592e-02,\n",
              "           2.0886e-01,  2.0000e+00],\n",
              "         [ 1.3311e-01, -3.9097e-02,  6.7494e-04,  ...,  2.4580e-01,\n",
              "           1.2721e-01,  2.0000e+00],\n",
              "         [ 1.2548e-01,  1.4029e-02,  2.4024e-02,  ...,  3.2486e-01,\n",
              "          -1.4632e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.8011e-02,  1.3423e-01,  2.3489e-01,  ...,  6.7458e-02,\n",
              "           3.4733e-03,  2.0000e+00],\n",
              "         [-2.4968e-01,  1.2661e-01,  3.4450e-01,  ...,  5.5368e-02,\n",
              "          -2.5290e-02,  2.0000e+00],\n",
              "         [-2.9829e-01,  9.5765e-02,  3.0265e-01,  ...,  4.5720e-02,\n",
              "          -9.8562e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0252, -0.1448, -0.0445,  ...,  0.0673,  0.2117,  2.0000],\n",
              "         [ 0.1598, -0.0789, -0.0687,  ...,  0.3030,  0.1385,  2.0000],\n",
              "         [ 0.1357, -0.0655, -0.0760,  ...,  0.3957,  0.0339,  2.0000],\n",
              "         ...,\n",
              "         [-0.0898,  0.0206,  0.1698,  ...,  0.1085,  0.0313,  2.0000],\n",
              "         [-0.2009,  0.0267,  0.2392,  ...,  0.0909, -0.0147,  2.0000],\n",
              "         [-0.2649,  0.0370,  0.2491,  ...,  0.0599, -0.0158,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4922e-02, -1.3081e-01, -2.6352e-02,  ...,  4.6255e-02,\n",
              "           2.1583e-01,  2.0000e+00],\n",
              "         [ 1.3070e-01, -3.8605e-02,  1.3306e-03,  ...,  2.2448e-01,\n",
              "           1.3563e-01,  2.0000e+00],\n",
              "         [ 1.2452e-01,  1.4932e-02,  2.5047e-02,  ...,  3.0116e-01,\n",
              "          -3.6785e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-7.2134e-02,  1.4919e-01,  2.2002e-01,  ...,  2.7902e-02,\n",
              "           1.6318e-02,  2.0000e+00],\n",
              "         [-2.4213e-01,  1.4129e-01,  3.3572e-01,  ...,  3.9758e-02,\n",
              "          -1.5150e-02,  2.0000e+00],\n",
              "         [-2.9299e-01,  1.0035e-01,  2.9963e-01,  ...,  5.0832e-02,\n",
              "           1.0510e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.2962e-02, -1.2390e-01, -3.0649e-02,  ...,  5.5100e-02,\n",
              "           2.0648e-01,  2.0000e+00],\n",
              "         [ 1.3820e-01, -5.5824e-02, -2.8857e-02,  ...,  2.6068e-01,\n",
              "           1.3870e-01,  2.0000e+00],\n",
              "         [ 1.1663e-01, -2.5453e-02, -1.4355e-02,  ...,  3.5409e-01,\n",
              "           2.5178e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.3713e-01,  1.0337e-01,  2.3865e-01,  ...,  8.7545e-02,\n",
              "          -1.2755e-03,  2.0000e+00],\n",
              "         [-2.5957e-01,  9.2517e-02,  3.0815e-01,  ...,  6.7634e-02,\n",
              "          -3.6932e-02,  2.0000e+00],\n",
              "         [-3.0457e-01,  8.7668e-02,  2.8941e-01,  ...,  3.7361e-02,\n",
              "          -1.6185e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.7306e-02, -1.2980e-01, -3.8083e-02,  ...,  5.0144e-02,\n",
              "           2.1947e-01,  2.0000e+00],\n",
              "         [ 1.4095e-01, -3.1096e-02, -1.2579e-02,  ...,  2.4793e-01,\n",
              "           1.3041e-01,  2.0000e+00],\n",
              "         [ 1.4303e-01,  3.1507e-02,  7.9717e-03,  ...,  3.2391e-01,\n",
              "          -1.7213e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-3.3926e-02,  1.4427e-01,  1.7871e-01,  ...,  5.6713e-02,\n",
              "           2.7999e-02,  2.0000e+00],\n",
              "         [-2.1521e-01,  1.4332e-01,  3.1769e-01,  ...,  6.6155e-02,\n",
              "          -1.3734e-02,  2.0000e+00],\n",
              "         [-2.7182e-01,  1.0166e-01,  2.9328e-01,  ...,  7.1439e-02,\n",
              "          -8.7512e-05,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3148e-02, -1.2475e-01, -3.1023e-02,  ...,  4.4498e-02,\n",
              "           2.0978e-01,  2.0000e+00],\n",
              "         [ 1.5402e-01, -2.2239e-02, -9.3845e-03,  ...,  2.6601e-01,\n",
              "           1.1311e-01,  2.0000e+00],\n",
              "         [ 1.5964e-01,  4.1097e-02,  3.5404e-03,  ...,  3.3764e-01,\n",
              "          -2.4569e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.5522e-04,  1.2109e-01,  1.6885e-01,  ...,  7.9213e-02,\n",
              "           3.0084e-02,  2.0000e+00],\n",
              "         [-2.0465e-01,  1.2581e-01,  3.2465e-01,  ...,  8.1333e-02,\n",
              "          -5.2720e-03,  2.0000e+00],\n",
              "         [-2.6283e-01,  1.0673e-01,  2.9270e-01,  ...,  5.8748e-02,\n",
              "           5.9541e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0222, -0.1284, -0.0255,  ...,  0.0410,  0.2073,  2.0000],\n",
              "         [ 0.1360, -0.0347,  0.0028,  ...,  0.2486,  0.1203,  2.0000],\n",
              "         [ 0.1294,  0.0196,  0.0241,  ...,  0.3273, -0.0086,  2.0000],\n",
              "         ...,\n",
              "         [-0.0746,  0.1308,  0.2241,  ...,  0.0682,  0.0060,  2.0000],\n",
              "         [-0.2441,  0.1282,  0.3411,  ...,  0.0565, -0.0247,  2.0000],\n",
              "         [-0.2956,  0.0998,  0.3022,  ...,  0.0445, -0.0078,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2339e-02, -1.3110e-01, -2.5337e-02,  ...,  4.1697e-02,\n",
              "           2.0757e-01,  2.0000e+00],\n",
              "         [ 1.3233e-01, -4.4484e-02,  2.1060e-03,  ...,  2.4623e-01,\n",
              "           1.2548e-01,  2.0000e+00],\n",
              "         [ 1.1824e-01,  2.6403e-04,  2.2444e-02,  ...,  3.2792e-01,\n",
              "           3.6892e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0991e-01,  1.2991e-01,  2.4036e-01,  ...,  6.7970e-02,\n",
              "          -3.8002e-03,  2.0000e+00],\n",
              "         [-2.5257e-01,  1.2724e-01,  3.3676e-01,  ...,  5.5437e-02,\n",
              "          -3.3992e-02,  2.0000e+00],\n",
              "         [-2.9851e-01,  9.6625e-02,  3.0338e-01,  ...,  4.3106e-02,\n",
              "          -1.2182e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3413e-02, -1.2490e-01, -4.0770e-02,  ...,  4.9924e-02,\n",
              "           2.1406e-01,  2.0000e+00],\n",
              "         [ 1.4806e-01, -2.7620e-02, -1.9114e-02,  ...,  2.4698e-01,\n",
              "           1.1850e-01,  2.0000e+00],\n",
              "         [ 1.5002e-01,  4.1256e-02,  6.6162e-04,  ...,  3.2726e-01,\n",
              "          -3.9629e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.6199e-02,  1.3264e-01,  1.6590e-01,  ...,  5.7536e-02,\n",
              "           2.6442e-02,  2.0000e+00],\n",
              "         [-2.0870e-01,  1.3474e-01,  3.0956e-01,  ...,  7.0885e-02,\n",
              "          -6.9911e-03,  2.0000e+00],\n",
              "         [-2.6709e-01,  1.0661e-01,  2.8726e-01,  ...,  7.5745e-02,\n",
              "           9.0951e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0722e-02, -1.3747e-01, -3.1743e-02,  ...,  5.7660e-02,\n",
              "           2.1764e-01,  2.0000e+00],\n",
              "         [ 1.4835e-01, -4.6859e-02, -9.9836e-03,  ...,  2.4558e-01,\n",
              "           1.4118e-01,  2.0000e+00],\n",
              "         [ 1.3866e-01,  4.4170e-04,  1.0193e-02,  ...,  3.2885e-01,\n",
              "           3.8390e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1326e-01,  1.5543e-01,  2.3918e-01,  ...,  6.7616e-02,\n",
              "          -5.3251e-03,  2.0000e+00],\n",
              "         [-2.4819e-01,  1.3277e-01,  3.2345e-01,  ...,  6.3906e-02,\n",
              "          -3.2443e-02,  2.0000e+00],\n",
              "         [-2.7730e-01,  1.0432e-01,  2.8786e-01,  ...,  6.9137e-02,\n",
              "          -2.5377e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0203, -0.1292, -0.0285,  ...,  0.0428,  0.2080,  2.0000],\n",
              "         [ 0.1376, -0.0356, -0.0065,  ...,  0.2515,  0.1227,  2.0000],\n",
              "         [ 0.1319,  0.0208,  0.0146,  ...,  0.3342, -0.0148,  2.0000],\n",
              "         ...,\n",
              "         [-0.0526,  0.1271,  0.2034,  ...,  0.0752,  0.0145,  2.0000],\n",
              "         [-0.2332,  0.1246,  0.3337,  ...,  0.0659, -0.0175,  2.0000],\n",
              "         [-0.2886,  0.0945,  0.2977,  ...,  0.0516, -0.0085,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.0038e-02, -1.1978e-01, -3.0170e-02,  ...,  3.5418e-02,\n",
              "           2.0429e-01,  2.0000e+00],\n",
              "         [ 1.2174e-01, -2.5462e-02,  2.1717e-03,  ...,  2.2962e-01,\n",
              "           1.0187e-01,  2.0000e+00],\n",
              "         [ 1.2630e-01,  4.3784e-02,  2.3069e-02,  ...,  3.0228e-01,\n",
              "          -4.4056e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.9575e-02,  1.3173e-01,  1.9335e-01,  ...,  3.7330e-02,\n",
              "           2.3410e-02,  2.0000e+00],\n",
              "         [-2.2570e-01,  1.3060e-01,  3.4722e-01,  ...,  4.5026e-02,\n",
              "          -1.2066e-02,  2.0000e+00],\n",
              "         [-2.8838e-01,  9.9009e-02,  3.0709e-01,  ...,  3.9304e-02,\n",
              "          -1.5556e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5140e-02, -1.2950e-01, -2.3249e-02,  ...,  4.0600e-02,\n",
              "           2.0807e-01,  2.0000e+00],\n",
              "         [ 1.2812e-01, -4.5036e-02, -1.5362e-04,  ...,  2.3949e-01,\n",
              "           1.3001e-01,  2.0000e+00],\n",
              "         [ 1.1218e-01, -1.1442e-03,  2.2888e-02,  ...,  3.2011e-01,\n",
              "           9.2831e-03,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.2808e-01,  1.3241e-01,  2.5897e-01,  ...,  6.0271e-02,\n",
              "          -7.9105e-03,  2.0000e+00],\n",
              "         [-2.6024e-01,  1.2853e-01,  3.4525e-01,  ...,  5.0657e-02,\n",
              "          -3.7894e-02,  2.0000e+00],\n",
              "         [-3.0402e-01,  9.4691e-02,  3.0927e-01,  ...,  4.1007e-02,\n",
              "          -1.6148e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.1330e-02, -1.3249e-01, -3.6487e-02,  ...,  6.9723e-02,\n",
              "           2.1432e-01,  2.0000e+00],\n",
              "         [ 1.7167e-01, -5.2387e-02, -3.9597e-02,  ...,  2.9093e-01,\n",
              "           1.4308e-01,  2.0000e+00],\n",
              "         [ 1.4459e-01, -2.7026e-02, -2.7210e-02,  ...,  3.8596e-01,\n",
              "           3.4624e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1478e-01,  9.5964e-02,  2.2172e-01,  ...,  9.5825e-02,\n",
              "          -1.1568e-03,  2.0000e+00],\n",
              "         [-2.5147e-01,  8.2127e-02,  2.8214e-01,  ...,  7.9910e-02,\n",
              "          -3.8357e-02,  2.0000e+00],\n",
              "         [-2.8393e-01,  8.6258e-02,  2.7468e-01,  ...,  5.6678e-02,\n",
              "          -1.4903e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.3716e-02, -1.3651e-01, -2.7361e-02,  ...,  4.7711e-02,\n",
              "           2.0980e-01,  2.0000e+00],\n",
              "         [ 1.4140e-01, -4.7996e-02, -1.2587e-02,  ...,  2.6462e-01,\n",
              "           1.3506e-01,  2.0000e+00],\n",
              "         [ 1.2449e-01, -8.8251e-03,  4.8812e-03,  ...,  3.5186e-01,\n",
              "           1.3921e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.0908e-01,  1.1869e-01,  2.3137e-01,  ...,  8.6558e-02,\n",
              "          -1.8466e-03,  2.0000e+00],\n",
              "         [-2.4555e-01,  1.0760e-01,  3.1717e-01,  ...,  6.8155e-02,\n",
              "          -3.1597e-02,  2.0000e+00],\n",
              "         [-2.9704e-01,  8.5623e-02,  2.9229e-01,  ...,  5.1454e-02,\n",
              "          -1.6154e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0168, -0.1324, -0.0327,  ...,  0.0526,  0.2189,  2.0000],\n",
              "         [ 0.1489, -0.0421, -0.0079,  ...,  0.2280,  0.1362,  2.0000],\n",
              "         [ 0.1342,  0.0154,  0.0143,  ...,  0.3078, -0.0168,  2.0000],\n",
              "         ...,\n",
              "         [-0.0318,  0.1654,  0.1808,  ...,  0.0304,  0.0264,  2.0000],\n",
              "         [-0.2139,  0.1436,  0.3080,  ...,  0.0432, -0.0078,  2.0000],\n",
              "         [-0.2628,  0.1078,  0.2841,  ...,  0.0695,  0.0033,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0232, -0.1311, -0.0296,  ...,  0.0506,  0.2178,  2.0000],\n",
              "         [ 0.1350, -0.0428, -0.0060,  ...,  0.2415,  0.1334,  2.0000],\n",
              "         [ 0.1327,  0.0151,  0.0152,  ...,  0.3206, -0.0091,  2.0000],\n",
              "         ...,\n",
              "         [-0.0849,  0.1437,  0.2286,  ...,  0.0548,  0.0048,  2.0000],\n",
              "         [-0.2472,  0.1374,  0.3402,  ...,  0.0560, -0.0229,  2.0000],\n",
              "         [-0.2875,  0.1026,  0.3005,  ...,  0.0633,  0.0034,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-7.7940e-03, -1.1644e-01, -4.3583e-02,  ...,  5.3988e-02,\n",
              "           2.1529e-01,  2.0000e+00],\n",
              "         [ 1.4510e-01, -2.8724e-02, -2.1688e-02,  ...,  2.2320e-01,\n",
              "           1.2777e-01,  2.0000e+00],\n",
              "         [ 1.3413e-01,  3.0275e-02, -3.5851e-03,  ...,  3.0367e-01,\n",
              "          -3.3799e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.8159e-03,  1.5033e-01,  1.5748e-01,  ...,  4.3064e-02,\n",
              "           3.6916e-02,  2.0000e+00],\n",
              "         [-1.9866e-01,  1.4177e-01,  3.1284e-01,  ...,  7.0267e-02,\n",
              "           2.0794e-03,  2.0000e+00],\n",
              "         [-2.6059e-01,  1.0730e-01,  2.8934e-01,  ...,  7.2476e-02,\n",
              "           6.2500e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1546, -0.0549,  ...,  0.0676,  0.2118,  2.0000],\n",
              "         [ 0.1550, -0.1088, -0.0716,  ...,  0.3008,  0.1534,  2.0000],\n",
              "         [ 0.0998, -0.1045, -0.0717,  ...,  0.4085,  0.0659,  2.0000],\n",
              "         ...,\n",
              "         [-0.1523,  0.0220,  0.2003,  ...,  0.1122, -0.0119,  2.0000],\n",
              "         [-0.2452,  0.0473,  0.2093,  ...,  0.0946, -0.0532,  2.0000],\n",
              "         [-0.2646,  0.0296,  0.2369,  ...,  0.0357, -0.0292,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.0961e-02, -1.1829e-01, -3.2807e-02,  ...,  4.4311e-02,\n",
              "           2.0977e-01,  2.0000e+00],\n",
              "         [ 1.4979e-01, -1.9967e-02, -1.3982e-02,  ...,  2.5453e-01,\n",
              "           1.0565e-01,  2.0000e+00],\n",
              "         [ 1.6013e-01,  5.0606e-02, -1.6476e-03,  ...,  3.2396e-01,\n",
              "          -4.1054e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.7676e-02,  1.2082e-01,  1.5175e-01,  ...,  6.2007e-02,\n",
              "           3.9840e-02,  2.0000e+00],\n",
              "         [-1.9552e-01,  1.2543e-01,  3.2777e-01,  ...,  8.4084e-02,\n",
              "           9.3515e-04,  2.0000e+00],\n",
              "         [-2.5974e-01,  1.0983e-01,  2.9543e-01,  ...,  5.8481e-02,\n",
              "           8.4541e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1232, -0.0305,  ...,  0.0530,  0.2052,  2.0000],\n",
              "         [ 0.1313, -0.0592, -0.0301,  ...,  0.2544,  0.1392,  2.0000],\n",
              "         [ 0.1099, -0.0305, -0.0187,  ...,  0.3472,  0.0252,  2.0000],\n",
              "         ...,\n",
              "         [-0.1538,  0.1074,  0.2495,  ...,  0.0962, -0.0082,  2.0000],\n",
              "         [-0.2704,  0.1008,  0.3127,  ...,  0.0733, -0.0401,  2.0000],\n",
              "         [-0.3086,  0.0884,  0.2907,  ...,  0.0343, -0.0195,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0219, -0.1414, -0.0350,  ...,  0.0599,  0.2181,  2.0000],\n",
              "         [ 0.1617, -0.0477, -0.0246,  ...,  0.2805,  0.1385,  2.0000],\n",
              "         [ 0.1474, -0.0059, -0.0042,  ...,  0.3728,  0.0086,  2.0000],\n",
              "         ...,\n",
              "         [-0.0876,  0.1180,  0.2035,  ...,  0.0837,  0.0038,  2.0000],\n",
              "         [-0.2271,  0.1099,  0.2867,  ...,  0.0785, -0.0296,  2.0000],\n",
              "         [-0.2783,  0.0937,  0.2781,  ...,  0.0718, -0.0057,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7028e-02, -1.1831e-01, -3.5715e-02,  ...,  3.4030e-02,\n",
              "           2.0591e-01,  2.0000e+00],\n",
              "         [ 1.2871e-01, -1.4642e-02, -6.8186e-03,  ...,  2.3101e-01,\n",
              "           9.6917e-02,  2.0000e+00],\n",
              "         [ 1.3247e-01,  5.2233e-02,  8.5223e-03,  ...,  3.0200e-01,\n",
              "          -4.9011e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4099e-03,  1.2597e-01,  1.5044e-01,  ...,  3.3086e-02,\n",
              "           3.1827e-02,  2.0000e+00],\n",
              "         [-2.1058e-01,  1.2719e-01,  3.3521e-01,  ...,  4.9593e-02,\n",
              "          -9.6608e-03,  2.0000e+00],\n",
              "         [-2.7849e-01,  9.3981e-02,  3.0178e-01,  ...,  4.5628e-02,\n",
              "          -5.0128e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1031e-02, -1.3325e-01, -2.7742e-02,  ...,  4.5719e-02,\n",
              "           2.0959e-01,  2.0000e+00],\n",
              "         [ 1.4122e-01, -3.8571e-02, -5.7447e-03,  ...,  2.6215e-01,\n",
              "           1.2744e-01,  2.0000e+00],\n",
              "         [ 1.3642e-01,  1.2067e-02,  1.4370e-02,  ...,  3.4108e-01,\n",
              "           2.0093e-04,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.8149e-02,  1.2823e-01,  2.3427e-01,  ...,  9.0642e-02,\n",
              "           9.2994e-04,  2.0000e+00],\n",
              "         [-2.4301e-01,  1.1623e-01,  3.3800e-01,  ...,  7.5918e-02,\n",
              "          -2.7880e-02,  2.0000e+00],\n",
              "         [-2.9056e-01,  9.2302e-02,  2.9836e-01,  ...,  5.4757e-02,\n",
              "          -1.0007e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 4.5428e-02, -1.6993e-01, -9.3658e-02,  ..., -7.8688e-04,\n",
              "           1.8093e-01,  2.0000e+00],\n",
              "         [ 2.7410e-01, -2.7278e-03, -8.5768e-02,  ...,  1.3621e-01,\n",
              "           1.3454e-02,  2.0000e+00],\n",
              "         [ 2.7260e-01,  4.0870e-02, -6.9693e-02,  ...,  1.8284e-01,\n",
              "          -1.0142e-01,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.3804e-01,  5.9146e-03, -1.1371e-01,  ...,  5.2360e-02,\n",
              "           7.0726e-02,  2.0000e+00],\n",
              "         [-3.3494e-02,  8.6783e-02,  1.8364e-01,  ...,  1.1102e-01,\n",
              "          -3.5677e-02,  2.0000e+00],\n",
              "         [-2.2920e-01,  4.2773e-02,  2.9708e-01,  ...,  6.8888e-02,\n",
              "          -1.8977e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0078, -0.1099, -0.0583,  ...,  0.0303,  0.1914,  2.0000],\n",
              "         [ 0.1847, -0.0022, -0.0439,  ...,  0.2320,  0.0345,  2.0000],\n",
              "         [ 0.1867,  0.0452, -0.0421,  ...,  0.2945, -0.1002,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0857,  0.0643,  0.0410,  ...,  0.0333,  0.0589,  2.0000],\n",
              "         [-0.1344,  0.1189,  0.3021,  ...,  0.0888, -0.0166,  2.0000],\n",
              "         [-0.2508,  0.0884,  0.2915,  ...,  0.0576, -0.0114,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1572e-02, -1.2247e-01, -4.0037e-02,  ...,  4.9952e-02,\n",
              "           2.1378e-01,  2.0000e+00],\n",
              "         [ 1.3534e-01, -2.5063e-02, -1.7213e-02,  ...,  2.3468e-01,\n",
              "           1.2515e-01,  2.0000e+00],\n",
              "         [ 1.3789e-01,  3.6888e-02,  1.7329e-03,  ...,  3.1211e-01,\n",
              "          -3.0578e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.1464e-02,  1.4188e-01,  1.5880e-01,  ...,  4.3698e-02,\n",
              "           3.8517e-02,  2.0000e+00],\n",
              "         [-2.0999e-01,  1.4381e-01,  3.1989e-01,  ...,  6.1799e-02,\n",
              "          -4.4498e-03,  2.0000e+00],\n",
              "         [-2.6768e-01,  1.0274e-01,  2.9668e-01,  ...,  6.4014e-02,\n",
              "          -1.6516e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0173, -0.1301, -0.0378,  ...,  0.0536,  0.2165,  2.0000],\n",
              "         [ 0.1526, -0.0236, -0.0165,  ...,  0.2579,  0.1245,  2.0000],\n",
              "         [ 0.1562,  0.0424,  0.0041,  ...,  0.3369, -0.0253,  2.0000],\n",
              "         ...,\n",
              "         [-0.0429,  0.1470,  0.1831,  ...,  0.0536,  0.0133,  2.0000],\n",
              "         [-0.2110,  0.1376,  0.2997,  ...,  0.0581, -0.0163,  2.0000],\n",
              "         [-0.2643,  0.1041,  0.2835,  ...,  0.0708,  0.0053,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 2.5490e-03, -1.0965e-01, -5.5241e-02,  ...,  5.1992e-02,\n",
              "           2.1344e-01,  2.0000e+00],\n",
              "         [ 1.5691e-01, -1.5913e-02, -4.4943e-02,  ...,  2.1470e-01,\n",
              "           1.0983e-01,  2.0000e+00],\n",
              "         [ 1.4194e-01,  3.4917e-02, -2.8971e-02,  ...,  3.0597e-01,\n",
              "          -5.5129e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 4.6027e-02,  1.2864e-01,  1.0077e-01,  ...,  3.5889e-02,\n",
              "           4.5141e-02,  2.0000e+00],\n",
              "         [-1.7029e-01,  1.3945e-01,  2.8464e-01,  ...,  8.3933e-02,\n",
              "           1.4604e-04,  2.0000e+00],\n",
              "         [-2.5175e-01,  1.0465e-01,  2.8016e-01,  ...,  6.9823e-02,\n",
              "           1.0412e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.4290e-02, -1.2287e-01, -2.3046e-02,  ...,  3.6889e-02,\n",
              "           2.0695e-01,  2.0000e+00],\n",
              "         [ 1.2150e-01, -3.4252e-02,  7.6022e-03,  ...,  2.2980e-01,\n",
              "           1.1759e-01,  2.0000e+00],\n",
              "         [ 1.1703e-01,  2.6899e-02,  3.1514e-02,  ...,  3.0478e-01,\n",
              "          -1.7810e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.0579e-02,  1.3730e-01,  2.4167e-01,  ...,  4.5756e-02,\n",
              "           7.9500e-04,  2.0000e+00],\n",
              "         [-2.4896e-01,  1.3533e-01,  3.6338e-01,  ...,  3.8714e-02,\n",
              "          -2.7157e-02,  2.0000e+00],\n",
              "         [-3.0220e-01,  1.0099e-01,  3.1705e-01,  ...,  4.0998e-02,\n",
              "          -7.5018e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3810e-02, -1.1889e-01, -3.9098e-02,  ...,  4.8548e-02,\n",
              "           2.1145e-01,  2.0000e+00],\n",
              "         [ 1.4557e-01, -1.8813e-02, -1.3514e-02,  ...,  2.2778e-01,\n",
              "           1.1437e-01,  2.0000e+00],\n",
              "         [ 1.4174e-01,  4.4162e-02,  5.5522e-04,  ...,  2.9854e-01,\n",
              "          -3.7994e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2443e-02,  1.5231e-01,  1.4814e-01,  ...,  3.3390e-02,\n",
              "           2.9892e-02,  2.0000e+00],\n",
              "         [-2.0692e-01,  1.5662e-01,  3.1663e-01,  ...,  6.2999e-02,\n",
              "          -7.5167e-03,  2.0000e+00],\n",
              "         [-2.6943e-01,  1.1167e-01,  2.9508e-01,  ...,  7.2192e-02,\n",
              "           4.0485e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0087, -0.1169, -0.0425,  ...,  0.0559,  0.2180,  2.0000],\n",
              "         [ 0.1378, -0.0338, -0.0233,  ...,  0.2228,  0.1329,  2.0000],\n",
              "         [ 0.1213,  0.0265, -0.0043,  ...,  0.3072, -0.0315,  2.0000],\n",
              "         ...,\n",
              "         [-0.0068,  0.1493,  0.1648,  ...,  0.0371,  0.0358,  2.0000],\n",
              "         [-0.1974,  0.1464,  0.3121,  ...,  0.0635,  0.0044,  2.0000],\n",
              "         [-0.2605,  0.1058,  0.2906,  ...,  0.0782,  0.0090,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0185, -0.1376, -0.0360,  ...,  0.0605,  0.2218,  2.0000],\n",
              "         [ 0.1494, -0.0479, -0.0140,  ...,  0.2416,  0.1404,  2.0000],\n",
              "         [ 0.1302,  0.0039,  0.0040,  ...,  0.3248, -0.0127,  2.0000],\n",
              "         ...,\n",
              "         [-0.0262,  0.1666,  0.1727,  ...,  0.0355,  0.0323,  2.0000],\n",
              "         [-0.2023,  0.1423,  0.2961,  ...,  0.0462, -0.0059,  2.0000],\n",
              "         [-0.2557,  0.1039,  0.2727,  ...,  0.0767,  0.0039,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0035, -0.1080, -0.0525,  ...,  0.0250,  0.1935,  2.0000],\n",
              "         [ 0.1602, -0.0037, -0.0275,  ...,  0.2220,  0.0456,  2.0000],\n",
              "         [ 0.1666,  0.0519, -0.0244,  ...,  0.2875, -0.0950,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0526,  0.0837,  0.0751,  ...,  0.0143,  0.0571,  2.0000],\n",
              "         [-0.1616,  0.1253,  0.3225,  ...,  0.0597, -0.0087,  2.0000],\n",
              "         [-0.2652,  0.0906,  0.3036,  ...,  0.0472, -0.0075,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0163, -0.1196, -0.0373,  ...,  0.0468,  0.2148,  2.0000],\n",
              "         [ 0.1356, -0.0192, -0.0116,  ...,  0.2346,  0.1154,  2.0000],\n",
              "         [ 0.1417,  0.0477,  0.0065,  ...,  0.3069, -0.0388,  2.0000],\n",
              "         ...,\n",
              "         [-0.0375,  0.1368,  0.1811,  ...,  0.0484,  0.0167,  2.0000],\n",
              "         [-0.2237,  0.1447,  0.3277,  ...,  0.0586, -0.0131,  2.0000],\n",
              "         [-0.2757,  0.1066,  0.3009,  ...,  0.0625,  0.0080,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7690e-02, -1.2181e-01, -3.2545e-02,  ...,  3.5468e-02,\n",
              "           2.0617e-01,  2.0000e+00],\n",
              "         [ 1.2637e-01, -1.9489e-02,  1.0287e-03,  ...,  2.2450e-01,\n",
              "           9.9126e-02,  2.0000e+00],\n",
              "         [ 1.3061e-01,  4.5677e-02,  1.9239e-02,  ...,  2.9434e-01,\n",
              "          -4.7298e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-9.9646e-03,  1.3373e-01,  1.7011e-01,  ...,  2.6888e-02,\n",
              "           3.7022e-02,  2.0000e+00],\n",
              "         [-2.1454e-01,  1.3413e-01,  3.3880e-01,  ...,  4.1748e-02,\n",
              "          -4.6949e-03,  2.0000e+00],\n",
              "         [-2.8085e-01,  9.9306e-02,  3.0357e-01,  ...,  3.9221e-02,\n",
              "           7.7687e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1205e-02, -1.3972e-01, -3.0338e-02,  ...,  5.3432e-02,\n",
              "           2.1527e-01,  2.0000e+00],\n",
              "         [ 1.5428e-01, -5.0313e-02, -1.3504e-02,  ...,  2.6827e-01,\n",
              "           1.3207e-01,  2.0000e+00],\n",
              "         [ 1.4423e-01,  2.8957e-03,  7.1141e-03,  ...,  3.5667e-01,\n",
              "          -9.1216e-04,  2.0000e+00],\n",
              "         ...,\n",
              "         [-9.0625e-02,  1.3788e-01,  2.1999e-01,  ...,  7.2307e-02,\n",
              "          -3.6512e-03,  2.0000e+00],\n",
              "         [-2.3623e-01,  1.2528e-01,  3.0821e-01,  ...,  7.1654e-02,\n",
              "          -3.0164e-02,  2.0000e+00],\n",
              "         [-2.7840e-01,  9.8382e-02,  2.8577e-01,  ...,  7.0395e-02,\n",
              "          -3.6510e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.8464e-02, -1.2514e-01, -2.9122e-02,  ...,  3.7433e-02,\n",
              "           2.0785e-01,  2.0000e+00],\n",
              "         [ 1.2785e-01, -2.4001e-02,  1.9812e-03,  ...,  2.2785e-01,\n",
              "           1.0980e-01,  2.0000e+00],\n",
              "         [ 1.2988e-01,  3.8749e-02,  2.2096e-02,  ...,  2.9983e-01,\n",
              "          -3.1654e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-3.1614e-02,  1.3289e-01,  1.9568e-01,  ...,  4.1008e-02,\n",
              "           2.8233e-02,  2.0000e+00],\n",
              "         [-2.2535e-01,  1.2887e-01,  3.4664e-01,  ...,  4.6783e-02,\n",
              "          -7.7082e-03,  2.0000e+00],\n",
              "         [-2.8447e-01,  9.8042e-02,  3.0432e-01,  ...,  4.2053e-02,\n",
              "          -9.7061e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0179, -0.1229, -0.0373,  ...,  0.0560,  0.2197,  2.0000],\n",
              "         [ 0.1394, -0.0372, -0.0163,  ...,  0.2190,  0.1370,  2.0000],\n",
              "         [ 0.1215,  0.0182,  0.0045,  ...,  0.3053, -0.0212,  2.0000],\n",
              "         ...,\n",
              "         [-0.0178,  0.1562,  0.1643,  ...,  0.0365,  0.0404,  2.0000],\n",
              "         [-0.2096,  0.1484,  0.3087,  ...,  0.0569,  0.0027,  2.0000],\n",
              "         [-0.2659,  0.1089,  0.2843,  ...,  0.0762,  0.0079,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0337, -0.1349, -0.0330,  ...,  0.0518,  0.2088,  2.0000],\n",
              "         [ 0.1418, -0.0673, -0.0406,  ...,  0.2670,  0.1453,  2.0000],\n",
              "         [ 0.1071, -0.0471, -0.0375,  ...,  0.3556,  0.0443,  2.0000],\n",
              "         ...,\n",
              "         [-0.1389,  0.0724,  0.2294,  ...,  0.0936,  0.0134,  2.0000],\n",
              "         [-0.2559,  0.0629,  0.2891,  ...,  0.0704, -0.0344,  2.0000],\n",
              "         [-0.3032,  0.0704,  0.2857,  ...,  0.0349, -0.0172,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-6.7493e-03, -1.1480e-01, -4.2911e-02,  ...,  3.9044e-02,\n",
              "           2.0293e-01,  2.0000e+00],\n",
              "         [ 1.5185e-01, -9.5941e-03, -2.3678e-02,  ...,  2.2730e-01,\n",
              "           8.0150e-02,  2.0000e+00],\n",
              "         [ 1.5488e-01,  5.1056e-02, -1.3971e-02,  ...,  3.0234e-01,\n",
              "          -6.7802e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 4.3428e-02,  1.0975e-01,  1.0019e-01,  ...,  2.2119e-02,\n",
              "           5.9476e-02,  2.0000e+00],\n",
              "         [-1.8133e-01,  1.2128e-01,  3.1275e-01,  ...,  6.3963e-02,\n",
              "           2.2175e-03,  2.0000e+00],\n",
              "         [-2.6029e-01,  9.4994e-02,  2.8864e-01,  ...,  4.9347e-02,\n",
              "          -1.5888e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.2105e-02, -1.1883e-01, -3.9811e-02,  ...,  5.5059e-02,\n",
              "           2.1786e-01,  2.0000e+00],\n",
              "         [ 1.3777e-01, -3.3254e-02, -1.8441e-02,  ...,  2.1038e-01,\n",
              "           1.3194e-01,  2.0000e+00],\n",
              "         [ 1.1775e-01,  2.3548e-02, -1.9077e-03,  ...,  2.9811e-01,\n",
              "          -2.8714e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-3.6912e-03,  1.5432e-01,  1.5920e-01,  ...,  2.7145e-02,\n",
              "           4.2476e-02,  2.0000e+00],\n",
              "         [-1.9672e-01,  1.5245e-01,  3.1455e-01,  ...,  5.5940e-02,\n",
              "           5.4145e-03,  2.0000e+00],\n",
              "         [-2.5936e-01,  1.0915e-01,  2.8944e-01,  ...,  7.3259e-02,\n",
              "           5.2172e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0175, -0.1130, -0.0363,  ...,  0.0288,  0.2000,  2.0000],\n",
              "         [ 0.1291, -0.0073, -0.0045,  ...,  0.2228,  0.0769,  2.0000],\n",
              "         [ 0.1432,  0.0608,  0.0101,  ...,  0.2881, -0.0720,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0050,  0.1180,  0.1420,  ...,  0.0126,  0.0360,  2.0000],\n",
              "         [-0.2019,  0.1319,  0.3471,  ...,  0.0403, -0.0112,  2.0000],\n",
              "         [-0.2786,  0.0957,  0.3152,  ...,  0.0385, -0.0046,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0243, -0.1233, -0.0241,  ...,  0.0377,  0.2076,  2.0000],\n",
              "         [ 0.1204, -0.0354,  0.0040,  ...,  0.2300,  0.1178,  2.0000],\n",
              "         [ 0.1166,  0.0242,  0.0273,  ...,  0.3095, -0.0201,  2.0000],\n",
              "         ...,\n",
              "         [-0.0747,  0.1330,  0.2354,  ...,  0.0471,  0.0050,  2.0000],\n",
              "         [-0.2475,  0.1345,  0.3616,  ...,  0.0413, -0.0231,  2.0000],\n",
              "         [-0.3006,  0.1004,  0.3147,  ...,  0.0399, -0.0044,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0238, -0.1297, -0.0246,  ...,  0.0400,  0.2083,  2.0000],\n",
              "         [ 0.1276, -0.0370,  0.0067,  ...,  0.2336,  0.1237,  2.0000],\n",
              "         [ 0.1237,  0.0180,  0.0296,  ...,  0.3095, -0.0111,  2.0000],\n",
              "         ...,\n",
              "         [-0.0872,  0.1401,  0.2455,  ...,  0.0560,  0.0035,  2.0000],\n",
              "         [-0.2492,  0.1304,  0.3575,  ...,  0.0482, -0.0247,  2.0000],\n",
              "         [-0.2969,  0.0974,  0.3075,  ...,  0.0414, -0.0072,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0087, -0.1160, -0.0581,  ...,  0.0459,  0.2102,  2.0000],\n",
              "         [ 0.1858, -0.0180, -0.0478,  ...,  0.2281,  0.0789,  2.0000],\n",
              "         [ 0.1705,  0.0332, -0.0399,  ...,  0.3090, -0.0673,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0936,  0.0829,  0.0805,  ...,  0.0289,  0.0430,  2.0000],\n",
              "         [-0.1346,  0.1198,  0.2907,  ...,  0.0837, -0.0131,  2.0000],\n",
              "         [-0.2419,  0.1053,  0.2813,  ...,  0.0600, -0.0038,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0165, -0.1295, -0.0272,  ...,  0.0472,  0.2114,  2.0000],\n",
              "         [ 0.1533, -0.0356, -0.0056,  ...,  0.2681,  0.1264,  2.0000],\n",
              "         [ 0.1525,  0.0215,  0.0088,  ...,  0.3473, -0.0023,  2.0000],\n",
              "         ...,\n",
              "         [-0.0480,  0.1225,  0.2101,  ...,  0.0872,  0.0201,  2.0000],\n",
              "         [-0.2258,  0.1229,  0.3310,  ...,  0.0816, -0.0143,  2.0000],\n",
              "         [-0.2751,  0.1021,  0.2953,  ...,  0.0604,  0.0033,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0308, -0.1519, -0.0584,  ...,  0.0569,  0.1935,  2.0000],\n",
              "         [ 0.1203, -0.1203, -0.0611,  ...,  0.2601,  0.1541,  2.0000],\n",
              "         [ 0.0536, -0.1170, -0.0694,  ...,  0.3623,  0.0879,  2.0000],\n",
              "         ...,\n",
              "         [-0.2323,  0.0487,  0.1988,  ...,  0.0368, -0.0775,  2.0000],\n",
              "         [-0.2752,  0.0650,  0.2113,  ...,  0.0378, -0.0770,  2.0000],\n",
              "         [-0.2460,  0.0413,  0.2389,  ..., -0.0054, -0.0472,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.9280e-02, -1.5122e-01, -5.9372e-02,  ...,  6.2077e-02,\n",
              "           1.9499e-01,  2.0000e+00],\n",
              "         [ 1.2925e-01, -1.2245e-01, -6.3685e-02,  ...,  2.7155e-01,\n",
              "           1.5743e-01,  2.0000e+00],\n",
              "         [ 5.9785e-02, -1.1626e-01, -6.7772e-02,  ...,  3.7841e-01,\n",
              "           8.8319e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-2.1433e-01,  5.3360e-02,  1.8225e-01,  ...,  3.0329e-02,\n",
              "          -7.5391e-02,  2.0000e+00],\n",
              "         [-2.6526e-01,  6.8738e-02,  2.0451e-01,  ...,  4.0626e-02,\n",
              "          -6.9451e-02,  2.0000e+00],\n",
              "         [-2.4212e-01,  4.5409e-02,  2.3320e-01,  ..., -2.5430e-04,\n",
              "          -4.2872e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0259, -0.1326, -0.0796,  ...,  0.0560,  0.2064,  2.0000],\n",
              "         [ 0.2101, -0.0069, -0.0705,  ...,  0.2409,  0.0608,  2.0000],\n",
              "         [ 0.1807,  0.0252, -0.0664,  ...,  0.3348, -0.0938,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1643,  0.0467,  0.0411,  ...,  0.0580,  0.0425,  2.0000],\n",
              "         [-0.0804,  0.1157,  0.2504,  ...,  0.0996, -0.0086,  2.0000],\n",
              "         [-0.2105,  0.0748,  0.2647,  ...,  0.0787, -0.0103,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.5702e-03, -1.0781e-01, -5.6410e-02,  ...,  2.4482e-02,\n",
              "           1.9899e-01,  2.0000e+00],\n",
              "         [ 1.5230e-01, -6.6181e-03, -2.8903e-02,  ...,  2.1732e-01,\n",
              "           6.0890e-02,  2.0000e+00],\n",
              "         [ 1.6242e-01,  5.0100e-02, -2.5909e-02,  ...,  2.8655e-01,\n",
              "          -8.7928e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 5.6397e-02,  8.5168e-02,  6.7812e-02,  ...,  1.5956e-02,\n",
              "           6.6211e-02,  2.0000e+00],\n",
              "         [-1.6055e-01,  1.2702e-01,  3.0842e-01,  ...,  6.2838e-02,\n",
              "          -2.1741e-03,  2.0000e+00],\n",
              "         [-2.6350e-01,  8.7669e-02,  3.0036e-01,  ...,  5.3290e-02,\n",
              "          -4.6338e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0306, -0.1608, -0.0560,  ...,  0.0654,  0.2162,  2.0000],\n",
              "         [ 0.1555, -0.1060, -0.0763,  ...,  0.3045,  0.1575,  2.0000],\n",
              "         [ 0.1062, -0.1053, -0.0830,  ...,  0.4059,  0.0690,  2.0000],\n",
              "         ...,\n",
              "         [-0.1242,  0.0021,  0.1917,  ...,  0.0994, -0.0085,  2.0000],\n",
              "         [-0.2160,  0.0239,  0.2007,  ...,  0.0866, -0.0409,  2.0000],\n",
              "         [-0.2557,  0.0100,  0.2297,  ...,  0.0413, -0.0223,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 5.1773e-02, -2.1937e-01, -1.1740e-01,  ..., -1.6688e-02,\n",
              "           1.9865e-01,  2.0000e+00],\n",
              "         [ 3.1094e-01,  2.5892e-02, -9.5518e-02,  ...,  2.8491e-02,\n",
              "           1.0018e-02,  2.0000e+00],\n",
              "         [ 3.2185e-01,  5.9332e-02, -7.9205e-02,  ...,  8.7513e-02,\n",
              "          -6.4950e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.7097e-01, -7.2549e-03, -1.3598e-01,  ...,  5.0914e-02,\n",
              "           5.9646e-02,  2.0000e+00],\n",
              "         [ 3.3077e-02,  5.8913e-02,  1.0115e-01,  ...,  1.1072e-01,\n",
              "          -9.1227e-03,  2.0000e+00],\n",
              "         [-1.4379e-01,  1.6279e-02,  2.8412e-01,  ...,  4.6764e-02,\n",
              "           1.6116e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0119, -0.1113, -0.0602,  ...,  0.0541,  0.2099,  2.0000],\n",
              "         [ 0.1680, -0.0161, -0.0550,  ...,  0.2268,  0.0944,  2.0000],\n",
              "         [ 0.1598,  0.0333, -0.0427,  ...,  0.3074, -0.0662,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0911,  0.1039,  0.0559,  ...,  0.0321,  0.0576,  2.0000],\n",
              "         [-0.1420,  0.1344,  0.2700,  ...,  0.0881, -0.0044,  2.0000],\n",
              "         [-0.2425,  0.0958,  0.2793,  ...,  0.0682, -0.0040,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7437e-02, -1.1978e-01, -3.3694e-02,  ...,  3.7298e-02,\n",
              "           2.0646e-01,  2.0000e+00],\n",
              "         [ 1.3302e-01, -1.7104e-02, -2.1081e-03,  ...,  2.2806e-01,\n",
              "           1.0216e-01,  2.0000e+00],\n",
              "         [ 1.3106e-01,  4.6633e-02,  1.5624e-02,  ...,  3.0166e-01,\n",
              "          -4.1645e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.3698e-02,  1.3226e-01,  1.7164e-01,  ...,  3.5925e-02,\n",
              "           3.4884e-02,  2.0000e+00],\n",
              "         [-2.1978e-01,  1.2691e-01,  3.3781e-01,  ...,  4.9526e-02,\n",
              "          -5.3309e-03,  2.0000e+00],\n",
              "         [-2.7924e-01,  9.8086e-02,  2.9809e-01,  ...,  4.1989e-02,\n",
              "           1.7447e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0298, -0.1466, -0.0357,  ...,  0.0604,  0.2158,  2.0000],\n",
              "         [ 0.1645, -0.0760, -0.0424,  ...,  0.2738,  0.1583,  2.0000],\n",
              "         [ 0.1207, -0.0588, -0.0352,  ...,  0.3685,  0.0563,  2.0000],\n",
              "         ...,\n",
              "         [-0.1172,  0.0535,  0.2167,  ...,  0.0854,  0.0087,  2.0000],\n",
              "         [-0.2357,  0.0499,  0.2646,  ...,  0.0696, -0.0347,  2.0000],\n",
              "         [-0.2773,  0.0610,  0.2631,  ...,  0.0441, -0.0121,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0361, -0.1267, -0.0867,  ...,  0.0285,  0.1934,  2.0000],\n",
              "         [ 0.2119, -0.0331, -0.0793,  ...,  0.2088,  0.0619,  2.0000],\n",
              "         [ 0.1999,  0.0071, -0.0645,  ...,  0.2908, -0.0872,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1620,  0.0251,  0.0031,  ...,  0.0635,  0.0652,  2.0000],\n",
              "         [-0.0632,  0.0795,  0.2345,  ...,  0.1159, -0.0179,  2.0000],\n",
              "         [-0.2290,  0.0624,  0.2816,  ...,  0.0874, -0.0150,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0175, -0.1163, -0.0628,  ...,  0.0227,  0.1893,  2.0000],\n",
              "         [ 0.1956, -0.0138, -0.0462,  ...,  0.2216,  0.0280,  2.0000],\n",
              "         [ 0.1914,  0.0315, -0.0437,  ...,  0.2802, -0.1022,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0943,  0.0379,  0.0357,  ...,  0.0415,  0.0726,  2.0000],\n",
              "         [-0.1219,  0.1062,  0.3042,  ...,  0.0919, -0.0104,  2.0000],\n",
              "         [-0.2503,  0.0772,  0.3020,  ...,  0.0578, -0.0130,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0330, -0.1302, -0.0327,  ...,  0.0557,  0.2105,  2.0000],\n",
              "         [ 0.1457, -0.0549, -0.0297,  ...,  0.2558,  0.1488,  2.0000],\n",
              "         [ 0.1141, -0.0326, -0.0117,  ...,  0.3443,  0.0456,  2.0000],\n",
              "         ...,\n",
              "         [-0.1586,  0.0914,  0.2613,  ...,  0.0783, -0.0116,  2.0000],\n",
              "         [-0.2688,  0.0770,  0.3045,  ...,  0.0675, -0.0477,  2.0000],\n",
              "         [-0.3001,  0.0850,  0.2844,  ...,  0.0379, -0.0186,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0164, -0.1289, -0.0273,  ...,  0.0466,  0.2111,  3.0000],\n",
              "         [ 0.1497, -0.0377, -0.0059,  ...,  0.2625,  0.1258,  3.0000],\n",
              "         [ 0.1495,  0.0208,  0.0103,  ...,  0.3421, -0.0113,  3.0000],\n",
              "         ...,\n",
              "         [-0.0404,  0.1206,  0.2044,  ...,  0.0816,  0.0198,  3.0000],\n",
              "         [-0.2248,  0.1260,  0.3333,  ...,  0.0773, -0.0144,  3.0000],\n",
              "         [-0.2746,  0.1054,  0.2956,  ...,  0.0560,  0.0035,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0224, -0.1379, -0.0285,  ...,  0.0546,  0.2170,  0.0000],\n",
              "         [ 0.1473, -0.0489, -0.0107,  ...,  0.2529,  0.1395,  0.0000],\n",
              "         [ 0.1360,  0.0012,  0.0110,  ...,  0.3382,  0.0071,  0.0000],\n",
              "         ...,\n",
              "         [-0.0906,  0.1423,  0.2212,  ...,  0.0659,  0.0017,  0.0000],\n",
              "         [-0.2468,  0.1325,  0.3204,  ...,  0.0654, -0.0289,  0.0000],\n",
              "         [-0.2872,  0.0974,  0.2923,  ...,  0.0652, -0.0029,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4256e-02, -1.3307e-01, -2.5236e-02,  ...,  4.6853e-02,\n",
              "           2.0928e-01,  0.0000e+00],\n",
              "         [ 1.3533e-01, -4.8141e-02, -1.0653e-02,  ...,  2.5765e-01,\n",
              "           1.3190e-01,  0.0000e+00],\n",
              "         [ 1.2112e-01, -2.6900e-03,  8.1858e-03,  ...,  3.4413e-01,\n",
              "           9.8992e-03,  0.0000e+00],\n",
              "         ...,\n",
              "         [-1.1674e-01,  1.2686e-01,  2.4206e-01,  ...,  8.1840e-02,\n",
              "          -3.1412e-04,  0.0000e+00],\n",
              "         [-2.5419e-01,  1.1399e-01,  3.2987e-01,  ...,  6.7813e-02,\n",
              "          -2.9945e-02,  0.0000e+00],\n",
              "         [-2.9978e-01,  9.0953e-02,  2.9832e-01,  ...,  4.8419e-02,\n",
              "          -1.1663e-02,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.8644e-02, -1.1440e-01, -3.6687e-02,  ...,  3.4454e-02,\n",
              "           2.0254e-01,  0.0000e+00],\n",
              "         [ 1.2894e-01, -1.3468e-02, -7.2628e-03,  ...,  2.3262e-01,\n",
              "           7.8771e-02,  0.0000e+00],\n",
              "         [ 1.3821e-01,  5.7225e-02,  7.1747e-03,  ...,  3.0166e-01,\n",
              "          -6.7157e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4627e-02,  1.1876e-01,  1.2776e-01,  ...,  2.6344e-02,\n",
              "           5.1717e-02,  0.0000e+00],\n",
              "         [-2.0250e-01,  1.2849e-01,  3.3314e-01,  ...,  5.4244e-02,\n",
              "          -4.6622e-03,  0.0000e+00],\n",
              "         [-2.8052e-01,  9.7224e-02,  3.0364e-01,  ...,  4.7005e-02,\n",
              "           2.8506e-04,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0352, -0.1527, -0.0564,  ...,  0.0595,  0.2096,  0.0000],\n",
              "         [ 0.1377, -0.1137, -0.0760,  ...,  0.2843,  0.1625,  0.0000],\n",
              "         [ 0.0798, -0.1138, -0.0803,  ...,  0.3898,  0.0853,  0.0000],\n",
              "         ...,\n",
              "         [-0.1852,  0.0225,  0.2020,  ...,  0.1069, -0.0376,  0.0000],\n",
              "         [-0.2602,  0.0372,  0.2051,  ...,  0.0858, -0.0675,  0.0000],\n",
              "         [-0.2766,  0.0196,  0.2411,  ...,  0.0224, -0.0363,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0220, -0.1344, -0.0289,  ...,  0.0507,  0.2175,  0.0000],\n",
              "         [ 0.1423, -0.0464, -0.0077,  ...,  0.2442,  0.1361,  0.0000],\n",
              "         [ 0.1329,  0.0096,  0.0165,  ...,  0.3242, -0.0022,  0.0000],\n",
              "         ...,\n",
              "         [-0.0777,  0.1487,  0.2150,  ...,  0.0527,  0.0110,  0.0000],\n",
              "         [-0.2380,  0.1417,  0.3174,  ...,  0.0590, -0.0224,  0.0000],\n",
              "         [-0.2837,  0.1011,  0.2917,  ...,  0.0650, -0.0019,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0250, -0.1293, -0.0236,  ...,  0.0435,  0.2070,  0.0000],\n",
              "         [ 0.1287, -0.0418,  0.0007,  ...,  0.2469,  0.1265,  0.0000],\n",
              "         [ 0.1165,  0.0050,  0.0217,  ...,  0.3276,  0.0035,  0.0000],\n",
              "         ...,\n",
              "         [-0.1118,  0.1337,  0.2523,  ...,  0.0702, -0.0032,  0.0000],\n",
              "         [-0.2562,  0.1223,  0.3491,  ...,  0.0583, -0.0322,  0.0000],\n",
              "         [-0.3024,  0.0949,  0.3072,  ...,  0.0428, -0.0119,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0291, -0.1234, -0.0262,  ...,  0.0490,  0.2048,  0.0000],\n",
              "         [ 0.1328, -0.0539, -0.0161,  ...,  0.2471,  0.1366,  0.0000],\n",
              "         [ 0.1141, -0.0196,  0.0032,  ...,  0.3404,  0.0139,  0.0000],\n",
              "         ...,\n",
              "         [-0.1464,  0.1237,  0.2553,  ...,  0.0826, -0.0092,  0.0000],\n",
              "         [-0.2667,  0.1103,  0.3268,  ...,  0.0654, -0.0394,  0.0000],\n",
              "         [-0.3082,  0.0938,  0.2971,  ...,  0.0397, -0.0175,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0233, -0.1300, -0.0298,  ...,  0.0492,  0.2133,  0.0000],\n",
              "         [ 0.1383, -0.0414, -0.0063,  ...,  0.2477,  0.1277,  0.0000],\n",
              "         [ 0.1349,  0.0170,  0.0177,  ...,  0.3262, -0.0144,  0.0000],\n",
              "         ...,\n",
              "         [-0.0945,  0.1465,  0.2368,  ...,  0.0639, -0.0016,  0.0000],\n",
              "         [-0.2505,  0.1384,  0.3396,  ...,  0.0582, -0.0319,  0.0000],\n",
              "         [-0.2894,  0.1031,  0.3011,  ...,  0.0587, -0.0039,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0031, -0.1035, -0.0643,  ...,  0.0337,  0.2023,  0.0000],\n",
              "         [ 0.1641,  0.0082, -0.0370,  ...,  0.2244,  0.0757,  0.0000],\n",
              "         [ 0.1686,  0.0625, -0.0276,  ...,  0.3052, -0.0809,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0783,  0.0856,  0.0495,  ...,  0.0434,  0.0562,  0.0000],\n",
              "         [-0.1463,  0.1371,  0.3006,  ...,  0.0813, -0.0070,  0.0000],\n",
              "         [-0.2540,  0.0985,  0.2927,  ...,  0.0630, -0.0027,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0341, -0.1246, -0.0312,  ...,  0.0520,  0.2074,  0.0000],\n",
              "         [ 0.1340, -0.0559, -0.0325,  ...,  0.2553,  0.1470,  0.0000],\n",
              "         [ 0.1056, -0.0313, -0.0217,  ...,  0.3465,  0.0391,  0.0000],\n",
              "         ...,\n",
              "         [-0.1580,  0.0970,  0.2501,  ...,  0.0876,  0.0005,  0.0000],\n",
              "         [-0.2715,  0.0825,  0.3075,  ...,  0.0661, -0.0379,  0.0000],\n",
              "         [-0.3113,  0.0830,  0.2901,  ...,  0.0311, -0.0193,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0232, -0.1283, -0.0248,  ...,  0.0404,  0.2083,  0.0000],\n",
              "         [ 0.1264, -0.0383,  0.0034,  ...,  0.2400,  0.1227,  0.0000],\n",
              "         [ 0.1215,  0.0183,  0.0261,  ...,  0.3170, -0.0109,  0.0000],\n",
              "         ...,\n",
              "         [-0.0813,  0.1367,  0.2388,  ...,  0.0615,  0.0078,  0.0000],\n",
              "         [-0.2469,  0.1305,  0.3531,  ...,  0.0531, -0.0246,  0.0000],\n",
              "         [-0.2990,  0.0971,  0.3077,  ...,  0.0445, -0.0086,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0219, -0.1695, -0.0467,  ...,  0.0680,  0.2112,  0.0000],\n",
              "         [ 0.1901, -0.0971, -0.0590,  ...,  0.3103,  0.1469,  0.0000],\n",
              "         [ 0.1486, -0.0918, -0.0605,  ...,  0.3985,  0.0616,  0.0000],\n",
              "         ...,\n",
              "         [-0.0805,  0.0067,  0.1612,  ...,  0.0992,  0.0149,  0.0000],\n",
              "         [-0.1906,  0.0227,  0.1989,  ...,  0.0859, -0.0205,  0.0000],\n",
              "         [-0.2409,  0.0220,  0.2274,  ...,  0.0570, -0.0145,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.4400e-02, -1.1612e-01, -3.4176e-02,  ...,  4.3112e-02,\n",
              "           2.0755e-01,  0.0000e+00],\n",
              "         [ 1.3994e-01, -2.0908e-02, -1.4896e-02,  ...,  2.4936e-01,\n",
              "           9.8451e-02,  0.0000e+00],\n",
              "         [ 1.5063e-01,  4.8895e-02, -2.9921e-03,  ...,  3.1883e-01,\n",
              "          -4.9630e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2370e-02,  1.2092e-01,  1.5319e-01,  ...,  5.5114e-02,\n",
              "           3.8253e-02,  0.0000e+00],\n",
              "         [-1.9987e-01,  1.2629e-01,  3.3233e-01,  ...,  8.0706e-02,\n",
              "           2.2220e-04,  0.0000e+00],\n",
              "         [-2.6457e-01,  1.0794e-01,  2.9638e-01,  ...,  5.5214e-02,\n",
              "           9.5783e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 2.4156e-05, -1.0934e-01, -5.0658e-02,  ...,  4.1157e-02,\n",
              "           2.0335e-01,  0.0000e+00],\n",
              "         [ 1.8036e-01, -3.9352e-03, -4.2006e-02,  ...,  2.5587e-01,\n",
              "           5.7387e-02,  0.0000e+00],\n",
              "         [ 1.9044e-01,  5.6964e-02, -3.9533e-02,  ...,  3.1345e-01,\n",
              "          -7.7240e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 9.6291e-02,  7.9824e-02,  3.8125e-02,  ...,  5.7790e-02,\n",
              "           6.1378e-02,  0.0000e+00],\n",
              "         [-1.3779e-01,  1.2347e-01,  3.0012e-01,  ...,  1.1301e-01,\n",
              "          -6.5573e-03,  0.0000e+00],\n",
              "         [-2.4416e-01,  1.0363e-01,  2.8937e-01,  ...,  6.7810e-02,\n",
              "           5.9282e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0235, -0.1304, -0.0298,  ...,  0.0471,  0.2147,  0.0000],\n",
              "         [ 0.1260, -0.0382, -0.0084,  ...,  0.2424,  0.1240,  0.0000],\n",
              "         [ 0.1307,  0.0253,  0.0150,  ...,  0.3206, -0.0206,  0.0000],\n",
              "         ...,\n",
              "         [-0.0672,  0.1402,  0.2185,  ...,  0.0514,  0.0038,  0.0000],\n",
              "         [-0.2417,  0.1413,  0.3408,  ...,  0.0534, -0.0226,  0.0000],\n",
              "         [-0.2872,  0.1006,  0.3039,  ...,  0.0590,  0.0011,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0213, -0.1221, -0.0295,  ...,  0.0389,  0.2065,  0.0000],\n",
              "         [ 0.1225, -0.0244, -0.0022,  ...,  0.2341,  0.1076,  0.0000],\n",
              "         [ 0.1225,  0.0402,  0.0159,  ...,  0.3083, -0.0327,  0.0000],\n",
              "         ...,\n",
              "         [-0.0283,  0.1320,  0.1909,  ...,  0.0388,  0.0280,  0.0000],\n",
              "         [-0.2298,  0.1298,  0.3467,  ...,  0.0468, -0.0094,  0.0000],\n",
              "         [-0.2890,  0.1003,  0.3063,  ...,  0.0438, -0.0009,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0535, -0.2047, -0.1066,  ..., -0.0114,  0.1881,  0.0000],\n",
              "         [ 0.3147,  0.0192, -0.0984,  ...,  0.0740,  0.0099,  0.0000],\n",
              "         [ 0.3124,  0.0551, -0.0798,  ...,  0.1220, -0.0947,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1642, -0.0119, -0.1623,  ...,  0.0352,  0.0770,  0.0000],\n",
              "         [ 0.0181,  0.0531,  0.1295,  ...,  0.1096, -0.0213,  0.0000],\n",
              "         [-0.1744,  0.0257,  0.2822,  ...,  0.0539, -0.0138,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0075, -0.1179, -0.0457,  ...,  0.0496,  0.2136,  0.0000],\n",
              "         [ 0.1457, -0.0153, -0.0263,  ...,  0.2389,  0.1168,  0.0000],\n",
              "         [ 0.1504,  0.0503, -0.0098,  ...,  0.3195, -0.0466,  0.0000],\n",
              "         ...,\n",
              "         [-0.0015,  0.1400,  0.1429,  ...,  0.0489,  0.0231,  0.0000],\n",
              "         [-0.1992,  0.1496,  0.3064,  ...,  0.0682, -0.0096,  0.0000],\n",
              "         [-0.2611,  0.1047,  0.2895,  ...,  0.0709,  0.0033,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0167, -0.1187, -0.0353,  ...,  0.0441,  0.2155,  0.0000],\n",
              "         [ 0.1271, -0.0228, -0.0081,  ...,  0.2276,  0.1253,  0.0000],\n",
              "         [ 0.1316,  0.0400,  0.0164,  ...,  0.2996, -0.0267,  0.0000],\n",
              "         ...,\n",
              "         [-0.0368,  0.1425,  0.1974,  ...,  0.0462,  0.0193,  0.0000],\n",
              "         [-0.2223,  0.1394,  0.3401,  ...,  0.0561, -0.0109,  0.0000],\n",
              "         [-0.2815,  0.0987,  0.3087,  ...,  0.0559, -0.0013,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0012, -0.1246, -0.0471,  ...,  0.0552,  0.2146,  0.0000],\n",
              "         [ 0.1636, -0.0111, -0.0261,  ...,  0.2388,  0.1176,  0.0000],\n",
              "         [ 0.1647,  0.0520, -0.0074,  ...,  0.3215, -0.0404,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0417,  0.1274,  0.1119,  ...,  0.0366,  0.0380,  0.0000],\n",
              "         [-0.1661,  0.1372,  0.2792,  ...,  0.0567, -0.0065,  0.0000],\n",
              "         [-0.2454,  0.1086,  0.2738,  ...,  0.0709,  0.0024,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0214, -0.1212, -0.0280,  ...,  0.0383,  0.2062,  0.0000],\n",
              "         [ 0.1223, -0.0290,  0.0007,  ...,  0.2336,  0.1112,  0.0000],\n",
              "         [ 0.1220,  0.0358,  0.0214,  ...,  0.3095, -0.0313,  0.0000],\n",
              "         ...,\n",
              "         [-0.0362,  0.1298,  0.2035,  ...,  0.0451,  0.0156,  0.0000],\n",
              "         [-0.2274,  0.1283,  0.3484,  ...,  0.0519, -0.0185,  0.0000],\n",
              "         [-0.2912,  0.1006,  0.3136,  ...,  0.0450, -0.0021,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0292, -0.1303, -0.0739,  ...,  0.0116,  0.1807,  0.0000],\n",
              "         [ 0.2226, -0.0191, -0.0643,  ...,  0.1910,  0.0146,  0.0000],\n",
              "         [ 0.2259,  0.0220, -0.0560,  ...,  0.2429, -0.1098,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1309, -0.0015, -0.0549,  ...,  0.0395,  0.0710,  0.0000],\n",
              "         [-0.0787,  0.0953,  0.2607,  ...,  0.1044, -0.0320,  0.0000],\n",
              "         [-0.2603,  0.0647,  0.3039,  ...,  0.0720, -0.0182,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0150, -0.1265, -0.0364,  ...,  0.0475,  0.2172,  0.0000],\n",
              "         [ 0.1352, -0.0277, -0.0156,  ...,  0.2356,  0.1275,  0.0000],\n",
              "         [ 0.1349,  0.0369,  0.0056,  ...,  0.3131, -0.0264,  0.0000],\n",
              "         ...,\n",
              "         [-0.0198,  0.1400,  0.1591,  ...,  0.0466,  0.0377,  0.0000],\n",
              "         [-0.2146,  0.1437,  0.3136,  ...,  0.0576, -0.0051,  0.0000],\n",
              "         [-0.2718,  0.1045,  0.2905,  ...,  0.0627,  0.0043,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0051, -0.1169, -0.0483,  ...,  0.0530,  0.2169,  0.0000],\n",
              "         [ 0.1465, -0.0135, -0.0324,  ...,  0.2353,  0.1190,  0.0000],\n",
              "         [ 0.1536,  0.0467, -0.0157,  ...,  0.3156, -0.0406,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0409,  0.1203,  0.0968,  ...,  0.0460,  0.0460,  0.0000],\n",
              "         [-0.1738,  0.1355,  0.2867,  ...,  0.0762,  0.0005,  0.0000],\n",
              "         [-0.2549,  0.1085,  0.2849,  ...,  0.0754,  0.0105,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1282, -0.0324,  ...,  0.0549,  0.2091,  0.0000],\n",
              "         [ 0.1386, -0.0597, -0.0388,  ...,  0.2703,  0.1470,  0.0000],\n",
              "         [ 0.1098, -0.0368, -0.0308,  ...,  0.3621,  0.0419,  0.0000],\n",
              "         ...,\n",
              "         [-0.1434,  0.0886,  0.2388,  ...,  0.0936, -0.0022,  0.0000],\n",
              "         [-0.2618,  0.0742,  0.2982,  ...,  0.0710, -0.0371,  0.0000],\n",
              "         [-0.3074,  0.0799,  0.2869,  ...,  0.0367, -0.0176,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0154, -0.1119, -0.0671,  ...,  0.0388,  0.2088,  0.0000],\n",
              "         [ 0.1798, -0.0051, -0.0553,  ...,  0.2187,  0.0765,  0.0000],\n",
              "         [ 0.1821,  0.0411, -0.0446,  ...,  0.2990, -0.0781,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1076,  0.0687,  0.0225,  ...,  0.0395,  0.0732,  0.0000],\n",
              "         [-0.1280,  0.1276,  0.2704,  ...,  0.0832,  0.0008,  0.0000],\n",
              "         [-0.2412,  0.0966,  0.2793,  ...,  0.0638, -0.0003,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0177, -0.1260, -0.0295,  ...,  0.0384,  0.2076,  0.0000],\n",
              "         [ 0.1330, -0.0238, -0.0025,  ...,  0.2429,  0.1106,  0.0000],\n",
              "         [ 0.1318,  0.0403,  0.0183,  ...,  0.3215, -0.0251,  0.0000],\n",
              "         ...,\n",
              "         [-0.0185,  0.1264,  0.1792,  ...,  0.0543,  0.0300,  0.0000],\n",
              "         [-0.2192,  0.1251,  0.3350,  ...,  0.0588, -0.0073,  0.0000],\n",
              "         [-0.2808,  0.0982,  0.2994,  ...,  0.0502, -0.0050,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0161, -0.1319, -0.0355,  ...,  0.0544,  0.2199,  0.0000],\n",
              "         [ 0.1476, -0.0460, -0.0292,  ...,  0.2617,  0.1428,  0.0000],\n",
              "         [ 0.1402,  0.0093, -0.0097,  ...,  0.3563, -0.0064,  0.0000],\n",
              "         ...,\n",
              "         [-0.0474,  0.1297,  0.1732,  ...,  0.0653,  0.0188,  0.0000],\n",
              "         [-0.2127,  0.1276,  0.2878,  ...,  0.0696, -0.0128,  0.0000],\n",
              "         [-0.2699,  0.0939,  0.2770,  ...,  0.0741, -0.0017,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.4112e-03, -1.0944e-01, -4.5478e-02,  ...,  4.0911e-02,\n",
              "           2.0352e-01,  0.0000e+00],\n",
              "         [ 1.6268e-01, -4.2804e-03, -2.8469e-02,  ...,  2.5074e-01,\n",
              "           7.0833e-02,  0.0000e+00],\n",
              "         [ 1.7561e-01,  6.2414e-02, -2.2814e-02,  ...,  3.1190e-01,\n",
              "          -7.2397e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 7.8194e-02,  9.0089e-02,  5.8105e-02,  ...,  4.0209e-02,\n",
              "           6.1770e-02,  0.0000e+00],\n",
              "         [-1.5522e-01,  1.2608e-01,  3.0857e-01,  ...,  9.5037e-02,\n",
              "           2.9690e-04,  0.0000e+00],\n",
              "         [-2.5203e-01,  1.1048e-01,  2.9003e-01,  ...,  5.8311e-02,\n",
              "           6.4105e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0148, -0.1240, -0.0291,  ...,  0.0449,  0.2120,  3.0000],\n",
              "         [ 0.1515, -0.0254, -0.0060,  ...,  0.2607,  0.1217,  3.0000],\n",
              "         [ 0.1545,  0.0382,  0.0086,  ...,  0.3315, -0.0161,  3.0000],\n",
              "         ...,\n",
              "         [-0.0127,  0.1240,  0.1863,  ...,  0.0741,  0.0272,  3.0000],\n",
              "         [-0.2127,  0.1259,  0.3338,  ...,  0.0766, -0.0065,  3.0000],\n",
              "         [-0.2668,  0.1063,  0.2968,  ...,  0.0561,  0.0071,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9664e-02, -1.3145e-01, -3.2571e-02,  ...,  5.1461e-02,\n",
              "           2.1638e-01,  1.0000e+00],\n",
              "         [ 1.4737e-01, -3.7810e-02, -1.9346e-02,  ...,  2.5276e-01,\n",
              "           1.3345e-01,  1.0000e+00],\n",
              "         [ 1.4332e-01,  2.0879e-02,  2.5516e-03,  ...,  3.3811e-01,\n",
              "          -1.4501e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-6.5361e-02,  1.4596e-01,  1.9768e-01,  ...,  5.5706e-02,\n",
              "           7.6979e-03,  1.0000e+00],\n",
              "         [-2.3336e-01,  1.3565e-01,  3.1647e-01,  ...,  5.9482e-02,\n",
              "          -2.3942e-02,  1.0000e+00],\n",
              "         [-2.7526e-01,  9.9644e-02,  2.8983e-01,  ...,  6.7294e-02,\n",
              "           5.3237e-04,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0334, -0.1595, -0.0520,  ...,  0.0654,  0.2107,  1.0000],\n",
              "         [ 0.1732, -0.1171, -0.0657,  ...,  0.3178,  0.1696,  1.0000],\n",
              "         [ 0.1207, -0.1099, -0.0656,  ...,  0.4220,  0.0854,  1.0000],\n",
              "         ...,\n",
              "         [-0.1525,  0.0225,  0.1976,  ...,  0.1164, -0.0133,  1.0000],\n",
              "         [-0.2391,  0.0387,  0.2044,  ...,  0.0912, -0.0409,  1.0000],\n",
              "         [-0.2612,  0.0262,  0.2341,  ...,  0.0364, -0.0205,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0226, -0.1334, -0.0300,  ...,  0.0553,  0.2168,  1.0000],\n",
              "         [ 0.1531, -0.0459, -0.0139,  ...,  0.2652,  0.1403,  1.0000],\n",
              "         [ 0.1421,  0.0039,  0.0090,  ...,  0.3546,  0.0016,  1.0000],\n",
              "         ...,\n",
              "         [-0.1219,  0.1323,  0.2507,  ...,  0.0823, -0.0206,  1.0000],\n",
              "         [-0.2484,  0.1217,  0.3233,  ...,  0.0741, -0.0385,  1.0000],\n",
              "         [-0.2854,  0.0954,  0.2947,  ...,  0.0644, -0.0053,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0237, -0.1322, -0.0252,  ...,  0.0459,  0.2090,  1.0000],\n",
              "         [ 0.1337, -0.0490, -0.0053,  ...,  0.2574,  0.1338,  1.0000],\n",
              "         [ 0.1172, -0.0080,  0.0147,  ...,  0.3398,  0.0175,  1.0000],\n",
              "         ...,\n",
              "         [-0.1266,  0.1295,  0.2551,  ...,  0.0782, -0.0059,  1.0000],\n",
              "         [-0.2562,  0.1146,  0.3371,  ...,  0.0653, -0.0325,  1.0000],\n",
              "         [-0.3038,  0.0894,  0.3022,  ...,  0.0472, -0.0141,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.7890e-02, -1.2406e-01, -3.1280e-02,  ...,  5.3790e-02,\n",
              "           2.0561e-01,  1.0000e+00],\n",
              "         [ 1.4015e-01, -5.5312e-02, -2.5742e-02,  ...,  2.6102e-01,\n",
              "           1.3800e-01,  1.0000e+00],\n",
              "         [ 1.2219e-01, -2.4567e-02, -1.3632e-02,  ...,  3.5716e-01,\n",
              "           1.9122e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.2463e-01,  1.0392e-01,  2.2411e-01,  ...,  9.7227e-02,\n",
              "          -2.3523e-04,  1.0000e+00],\n",
              "         [-2.5289e-01,  1.0061e-01,  3.0596e-01,  ...,  7.2027e-02,\n",
              "          -3.5059e-02,  1.0000e+00],\n",
              "         [-3.0133e-01,  8.7991e-02,  2.8772e-01,  ...,  4.4313e-02,\n",
              "          -1.8574e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0175, -0.1239, -0.0343,  ...,  0.0509,  0.2140,  1.0000],\n",
              "         [ 0.1483, -0.0219, -0.0135,  ...,  0.2542,  0.1169,  1.0000],\n",
              "         [ 0.1522,  0.0443,  0.0062,  ...,  0.3268, -0.0348,  1.0000],\n",
              "         ...,\n",
              "         [-0.0389,  0.1380,  0.1959,  ...,  0.0579,  0.0022,  1.0000],\n",
              "         [-0.2235,  0.1388,  0.3236,  ...,  0.0640, -0.0202,  1.0000],\n",
              "         [-0.2697,  0.1094,  0.2959,  ...,  0.0706,  0.0088,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4567e-02, -1.3431e-01, -2.7553e-02,  ...,  4.6845e-02,\n",
              "           2.0861e-01,  1.0000e+00],\n",
              "         [ 1.3687e-01, -4.7448e-02, -1.1938e-02,  ...,  2.6672e-01,\n",
              "           1.3105e-01,  1.0000e+00],\n",
              "         [ 1.1786e-01, -8.1432e-03,  4.6420e-03,  ...,  3.5136e-01,\n",
              "           1.7723e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1732e-01,  1.1975e-01,  2.3599e-01,  ...,  8.4581e-02,\n",
              "          -7.6023e-04,  1.0000e+00],\n",
              "         [-2.4946e-01,  1.0518e-01,  3.2167e-01,  ...,  6.8490e-02,\n",
              "          -3.1764e-02,  1.0000e+00],\n",
              "         [-2.9911e-01,  8.6555e-02,  2.9626e-01,  ...,  4.8950e-02,\n",
              "          -1.5008e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0338, -0.1574, -0.0585,  ...,  0.0621,  0.2109,  1.0000],\n",
              "         [ 0.1391, -0.1191, -0.0816,  ...,  0.3050,  0.1552,  1.0000],\n",
              "         [ 0.0852, -0.1194, -0.0892,  ...,  0.4072,  0.0801,  1.0000],\n",
              "         ...,\n",
              "         [-0.1575,  0.0094,  0.1916,  ...,  0.1134, -0.0277,  1.0000],\n",
              "         [-0.2279,  0.0225,  0.1927,  ...,  0.0923, -0.0544,  1.0000],\n",
              "         [-0.2637,  0.0042,  0.2289,  ...,  0.0319, -0.0327,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0205, -0.1326, -0.0341,  ...,  0.0566,  0.2176,  1.0000],\n",
              "         [ 0.1595, -0.0342, -0.0144,  ...,  0.2680,  0.1289,  1.0000],\n",
              "         [ 0.1517,  0.0246,  0.0047,  ...,  0.3479, -0.0131,  1.0000],\n",
              "         ...,\n",
              "         [-0.0485,  0.1467,  0.2051,  ...,  0.0733,  0.0094,  1.0000],\n",
              "         [-0.2256,  0.1367,  0.3135,  ...,  0.0724, -0.0180,  1.0000],\n",
              "         [-0.2708,  0.1042,  0.2886,  ...,  0.0742,  0.0040,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0244, -0.1318, -0.0263,  ...,  0.0433,  0.2100,  1.0000],\n",
              "         [ 0.1307, -0.0480, -0.0039,  ...,  0.2473,  0.1329,  1.0000],\n",
              "         [ 0.1157, -0.0040,  0.0180,  ...,  0.3318,  0.0082,  1.0000],\n",
              "         ...,\n",
              "         [-0.1212,  0.1315,  0.2473,  ...,  0.0709, -0.0035,  1.0000],\n",
              "         [-0.2560,  0.1216,  0.3359,  ...,  0.0566, -0.0342,  1.0000],\n",
              "         [-0.3024,  0.0921,  0.3011,  ...,  0.0441, -0.0159,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6471e-02, -1.2901e-01, -3.0476e-02,  ...,  4.9564e-02,\n",
              "           2.1028e-01,  1.0000e+00],\n",
              "         [ 1.5126e-01, -3.8261e-02, -1.3206e-02,  ...,  2.7598e-01,\n",
              "           1.2491e-01,  1.0000e+00],\n",
              "         [ 1.5028e-01,  1.4688e-02, -8.8313e-04,  ...,  3.5979e-01,\n",
              "          -7.4569e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-4.7852e-02,  1.1868e-01,  1.9786e-01,  ...,  1.0035e-01,\n",
              "           1.6160e-02,  1.0000e+00],\n",
              "         [-2.2367e-01,  1.1934e-01,  3.2165e-01,  ...,  8.7382e-02,\n",
              "          -1.7734e-02,  1.0000e+00],\n",
              "         [-2.7250e-01,  1.0222e-01,  2.8911e-01,  ...,  5.9059e-02,\n",
              "           1.9843e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-9.2304e-03, -1.1847e-01, -3.3539e-02,  ...,  4.3784e-02,\n",
              "           2.0902e-01,  1.0000e+00],\n",
              "         [ 1.5776e-01, -1.7370e-02, -1.4774e-02,  ...,  2.5961e-01,\n",
              "           1.0696e-01,  1.0000e+00],\n",
              "         [ 1.6547e-01,  5.2687e-02, -2.1852e-04,  ...,  3.2864e-01,\n",
              "          -3.9927e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [ 3.1178e-02,  1.2141e-01,  1.4081e-01,  ...,  6.3977e-02,\n",
              "           4.2776e-02,  1.0000e+00],\n",
              "         [-1.8793e-01,  1.2622e-01,  3.1939e-01,  ...,  8.4126e-02,\n",
              "          -8.8949e-08,  1.0000e+00],\n",
              "         [-2.5644e-01,  1.1001e-01,  2.9264e-01,  ...,  5.9298e-02,\n",
              "           7.1333e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0322, -0.1582, -0.0438,  ...,  0.0602,  0.2117,  1.0000],\n",
              "         [ 0.1659, -0.0961, -0.0540,  ...,  0.3027,  0.1570,  1.0000],\n",
              "         [ 0.1190, -0.0946, -0.0540,  ...,  0.3878,  0.0853,  1.0000],\n",
              "         ...,\n",
              "         [-0.1320,  0.0197,  0.2087,  ...,  0.1140,  0.0100,  1.0000],\n",
              "         [-0.2346,  0.0332,  0.2335,  ...,  0.0940, -0.0381,  1.0000],\n",
              "         [-0.2743,  0.0333,  0.2526,  ...,  0.0390, -0.0182,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0378, -0.1529, -0.0574,  ...,  0.0612,  0.2040,  1.0000],\n",
              "         [ 0.1194, -0.1214, -0.0739,  ...,  0.2833,  0.1513,  1.0000],\n",
              "         [ 0.0541, -0.1178, -0.0813,  ...,  0.3870,  0.0783,  1.0000],\n",
              "         ...,\n",
              "         [-0.2085,  0.0345,  0.1997,  ...,  0.0924, -0.0580,  1.0000],\n",
              "         [-0.2631,  0.0509,  0.1988,  ...,  0.0783, -0.0788,  1.0000],\n",
              "         [-0.2677,  0.0228,  0.2344,  ...,  0.0210, -0.0429,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3038e-02, -1.3275e-01, -2.4410e-02,  ...,  4.5871e-02,\n",
              "           2.0883e-01,  1.0000e+00],\n",
              "         [ 1.3580e-01, -4.5902e-02, -3.2553e-03,  ...,  2.5413e-01,\n",
              "           1.3302e-01,  1.0000e+00],\n",
              "         [ 1.2124e-01, -2.9262e-03,  1.6434e-02,  ...,  3.3625e-01,\n",
              "           1.6171e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1661e-01,  1.3043e-01,  2.5291e-01,  ...,  7.8278e-02,\n",
              "          -7.7681e-04,  1.0000e+00],\n",
              "         [-2.5582e-01,  1.1685e-01,  3.3968e-01,  ...,  6.5751e-02,\n",
              "          -2.9008e-02,  1.0000e+00],\n",
              "         [-3.0165e-01,  9.1063e-02,  3.0190e-01,  ...,  4.8656e-02,\n",
              "          -1.2671e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0246, -0.1302, -0.0248,  ...,  0.0444,  0.2077,  1.0000],\n",
              "         [ 0.1271, -0.0508, -0.0034,  ...,  0.2466,  0.1328,  1.0000],\n",
              "         [ 0.1108, -0.0087,  0.0163,  ...,  0.3334,  0.0080,  1.0000],\n",
              "         ...,\n",
              "         [-0.1276,  0.1341,  0.2630,  ...,  0.0794, -0.0071,  1.0000],\n",
              "         [-0.2633,  0.1243,  0.3478,  ...,  0.0622, -0.0356,  1.0000],\n",
              "         [-0.3080,  0.0929,  0.3059,  ...,  0.0451, -0.0178,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0162, -0.1177, -0.0352,  ...,  0.0436,  0.2142,  1.0000],\n",
              "         [ 0.1408, -0.0222, -0.0149,  ...,  0.2424,  0.1210,  1.0000],\n",
              "         [ 0.1456,  0.0483,  0.0110,  ...,  0.3173, -0.0336,  1.0000],\n",
              "         ...,\n",
              "         [-0.0174,  0.1293,  0.1786,  ...,  0.0490,  0.0208,  1.0000],\n",
              "         [-0.2084,  0.1397,  0.3281,  ...,  0.0629, -0.0076,  1.0000],\n",
              "         [-0.2690,  0.1045,  0.3028,  ...,  0.0632,  0.0073,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0142, -0.1202, -0.0381,  ...,  0.0465,  0.2153,  1.0000],\n",
              "         [ 0.1317, -0.0195, -0.0113,  ...,  0.2262,  0.1226,  1.0000],\n",
              "         [ 0.1348,  0.0457,  0.0044,  ...,  0.3019, -0.0346,  1.0000],\n",
              "         ...,\n",
              "         [-0.0232,  0.1435,  0.1623,  ...,  0.0308,  0.0319,  1.0000],\n",
              "         [-0.2167,  0.1494,  0.3256,  ...,  0.0477, -0.0046,  1.0000],\n",
              "         [-0.2713,  0.1016,  0.2974,  ...,  0.0629,  0.0033,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0126, -0.1167, -0.0407,  ...,  0.0371,  0.2004,  1.0000],\n",
              "         [ 0.1472, -0.0093, -0.0192,  ...,  0.2394,  0.0726,  1.0000],\n",
              "         [ 0.1504,  0.0555, -0.0094,  ...,  0.3101, -0.0688,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0378,  0.1157,  0.1053,  ...,  0.0330,  0.0401,  1.0000],\n",
              "         [-0.1915,  0.1196,  0.3167,  ...,  0.0662, -0.0134,  1.0000],\n",
              "         [-0.2682,  0.0917,  0.2960,  ...,  0.0466, -0.0061,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.4119e-02, -1.2610e-01, -3.2122e-02,  ...,  5.3747e-02,\n",
              "           2.0741e-01,  1.0000e+00],\n",
              "         [ 1.3607e-01, -5.7571e-02, -3.5891e-02,  ...,  2.5657e-01,\n",
              "           1.4182e-01,  1.0000e+00],\n",
              "         [ 1.1186e-01, -3.0388e-02, -2.5419e-02,  ...,  3.5008e-01,\n",
              "           3.0079e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.4986e-01,  9.2534e-02,  2.4263e-01,  ...,  9.1341e-02,\n",
              "           9.5852e-04,  1.0000e+00],\n",
              "         [-2.6687e-01,  8.6919e-02,  3.0241e-01,  ...,  7.0062e-02,\n",
              "          -3.9380e-02,  1.0000e+00],\n",
              "         [-3.0663e-01,  8.3335e-02,  2.8769e-01,  ...,  3.4783e-02,\n",
              "          -1.9950e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.2608e-02, -1.3059e-01, -2.5755e-02,  ...,  4.3271e-02,\n",
              "           2.0921e-01,  1.0000e+00],\n",
              "         [ 1.3325e-01, -4.5270e-02, -4.3164e-03,  ...,  2.5233e-01,\n",
              "           1.2839e-01,  1.0000e+00],\n",
              "         [ 1.2333e-01,  6.4068e-03,  1.5882e-02,  ...,  3.3775e-01,\n",
              "          -9.0039e-04,  1.0000e+00],\n",
              "         ...,\n",
              "         [-9.7444e-02,  1.3516e-01,  2.3558e-01,  ...,  7.8424e-02,\n",
              "           6.2723e-03,  1.0000e+00],\n",
              "         [-2.4839e-01,  1.2595e-01,  3.3849e-01,  ...,  6.5060e-02,\n",
              "          -2.6763e-02,  1.0000e+00],\n",
              "         [-2.9806e-01,  9.4082e-02,  3.0059e-01,  ...,  4.9112e-02,\n",
              "          -1.1457e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0294, -0.1505, -0.0435,  ...,  0.0578,  0.2136,  1.0000],\n",
              "         [ 0.1540, -0.0829, -0.0681,  ...,  0.2949,  0.1483,  1.0000],\n",
              "         [ 0.1191, -0.0732, -0.0741,  ...,  0.3877,  0.0488,  1.0000],\n",
              "         ...,\n",
              "         [-0.1194,  0.0270,  0.1920,  ...,  0.0999,  0.0234,  1.0000],\n",
              "         [-0.2193,  0.0264,  0.2420,  ...,  0.0793, -0.0179,  1.0000],\n",
              "         [-0.2762,  0.0340,  0.2537,  ...,  0.0460, -0.0173,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0155, -0.1164, -0.0374,  ...,  0.0441,  0.2170,  1.0000],\n",
              "         [ 0.1389, -0.0225, -0.0168,  ...,  0.2408,  0.1225,  1.0000],\n",
              "         [ 0.1454,  0.0459,  0.0071,  ...,  0.3151, -0.0334,  1.0000],\n",
              "         ...,\n",
              "         [-0.0177,  0.1304,  0.1688,  ...,  0.0497,  0.0288,  1.0000],\n",
              "         [-0.2075,  0.1446,  0.3180,  ...,  0.0612, -0.0046,  1.0000],\n",
              "         [-0.2729,  0.1067,  0.2980,  ...,  0.0632,  0.0086,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0367, -0.1552, -0.0556,  ...,  0.0616,  0.2114,  1.0000],\n",
              "         [ 0.1399, -0.1118, -0.0786,  ...,  0.3021,  0.1575,  1.0000],\n",
              "         [ 0.0860, -0.1121, -0.0859,  ...,  0.4009,  0.0815,  1.0000],\n",
              "         ...,\n",
              "         [-0.1689,  0.0162,  0.2008,  ...,  0.1056, -0.0315,  1.0000],\n",
              "         [-0.2367,  0.0230,  0.2045,  ...,  0.0875, -0.0534,  1.0000],\n",
              "         [-0.2713,  0.0096,  0.2374,  ...,  0.0298, -0.0329,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.6870e-02, -1.2340e-01, -3.6243e-02,  ...,  4.5904e-02,\n",
              "           2.1689e-01,  1.0000e+00],\n",
              "         [ 1.3711e-01, -2.3872e-02, -1.5155e-02,  ...,  2.4206e-01,\n",
              "           1.2592e-01,  1.0000e+00],\n",
              "         [ 1.3922e-01,  3.9824e-02,  5.6119e-03,  ...,  3.1896e-01,\n",
              "          -2.1928e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-3.0807e-02,  1.3593e-01,  1.7692e-01,  ...,  5.0101e-02,\n",
              "           2.4297e-02,  1.0000e+00],\n",
              "         [-2.1536e-01,  1.3658e-01,  3.1885e-01,  ...,  5.6071e-02,\n",
              "          -9.8005e-03,  1.0000e+00],\n",
              "         [-2.7425e-01,  9.7145e-02,  2.9468e-01,  ...,  5.9895e-02,\n",
              "          -5.4130e-04,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0222, -0.1491, -0.0440,  ...,  0.0735,  0.2157,  1.0000],\n",
              "         [ 0.1951, -0.0683, -0.0582,  ...,  0.3007,  0.1509,  1.0000],\n",
              "         [ 0.1602, -0.0562, -0.0509,  ...,  0.3967,  0.0486,  1.0000],\n",
              "         ...,\n",
              "         [-0.0809,  0.0357,  0.1769,  ...,  0.0854,  0.0110,  1.0000],\n",
              "         [-0.1935,  0.0499,  0.2245,  ...,  0.0835, -0.0241,  1.0000],\n",
              "         [-0.2467,  0.0524,  0.2395,  ...,  0.0638, -0.0104,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0133, -0.1225, -0.0306,  ...,  0.0441,  0.2102,  1.0000],\n",
              "         [ 0.1470, -0.0244, -0.0106,  ...,  0.2613,  0.1121,  1.0000],\n",
              "         [ 0.1554,  0.0433,  0.0035,  ...,  0.3330, -0.0308,  1.0000],\n",
              "         ...,\n",
              "         [-0.0027,  0.1226,  0.1744,  ...,  0.0737,  0.0277,  1.0000],\n",
              "         [-0.2079,  0.1269,  0.3336,  ...,  0.0811, -0.0049,  1.0000],\n",
              "         [-0.2656,  0.1071,  0.2978,  ...,  0.0594,  0.0063,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0152, -0.1274, -0.0280,  ...,  0.0463,  0.2108,  1.0000],\n",
              "         [ 0.1498, -0.0318, -0.0038,  ...,  0.2631,  0.1212,  1.0000],\n",
              "         [ 0.1521,  0.0274,  0.0094,  ...,  0.3386, -0.0134,  1.0000],\n",
              "         ...,\n",
              "         [-0.0330,  0.1241,  0.2018,  ...,  0.0824,  0.0215,  1.0000],\n",
              "         [-0.2215,  0.1277,  0.3359,  ...,  0.0812, -0.0118,  1.0000],\n",
              "         [-0.2712,  0.1074,  0.2975,  ...,  0.0580,  0.0052,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0039, -0.1130, -0.0418,  ...,  0.0414,  0.2050,  0.0000],\n",
              "         [ 0.1620, -0.0053, -0.0257,  ...,  0.2439,  0.0849,  0.0000],\n",
              "         [ 0.1726,  0.0608, -0.0182,  ...,  0.3116, -0.0623,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0587,  0.1072,  0.0900,  ...,  0.0395,  0.0580,  0.0000],\n",
              "         [-0.1735,  0.1236,  0.3100,  ...,  0.0842, -0.0017,  0.0000],\n",
              "         [-0.2512,  0.1087,  0.2865,  ...,  0.0538,  0.0015,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.4219e-02, -1.2175e-01, -2.9181e-02,  ...,  4.3344e-02,\n",
              "           2.1078e-01,  3.0000e+00],\n",
              "         [ 1.4834e-01, -2.5468e-02, -5.5164e-03,  ...,  2.5455e-01,\n",
              "           1.1507e-01,  3.0000e+00],\n",
              "         [ 1.5480e-01,  4.3260e-02,  9.9949e-03,  ...,  3.2512e-01,\n",
              "          -2.9679e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0345e-03,  1.2299e-01,  1.7566e-01,  ...,  6.1047e-02,\n",
              "           3.4322e-02,  3.0000e+00],\n",
              "         [-2.0815e-01,  1.2842e-01,  3.3401e-01,  ...,  7.3798e-02,\n",
              "          -2.1062e-03,  3.0000e+00],\n",
              "         [-2.6619e-01,  1.0981e-01,  2.9750e-01,  ...,  5.4964e-02,\n",
              "           8.8542e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0163, -0.1292, -0.0274,  ...,  0.0471,  0.2123,  3.0000],\n",
              "         [ 0.1528, -0.0349, -0.0049,  ...,  0.2672,  0.1261,  3.0000],\n",
              "         [ 0.1535,  0.0243,  0.0097,  ...,  0.3445, -0.0060,  3.0000],\n",
              "         ...,\n",
              "         [-0.0398,  0.1207,  0.2052,  ...,  0.0879,  0.0195,  3.0000],\n",
              "         [-0.2229,  0.1240,  0.3319,  ...,  0.0820, -0.0137,  3.0000],\n",
              "         [-0.2727,  0.1044,  0.2953,  ...,  0.0592,  0.0038,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.1244e-02, -1.2388e-01, -3.1590e-02,  ...,  4.6442e-02,\n",
              "           2.1178e-01,  2.0000e+00],\n",
              "         [ 1.6004e-01, -2.5183e-02, -1.3287e-02,  ...,  2.6863e-01,\n",
              "           1.2068e-01,  2.0000e+00],\n",
              "         [ 1.6377e-01,  3.9865e-02,  1.0767e-03,  ...,  3.4389e-01,\n",
              "          -2.0728e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-3.8820e-05,  1.1779e-01,  1.6473e-01,  ...,  8.4437e-02,\n",
              "           3.4670e-02,  2.0000e+00],\n",
              "         [-2.0279e-01,  1.2246e-01,  3.1819e-01,  ...,  8.5033e-02,\n",
              "          -2.8407e-03,  2.0000e+00],\n",
              "         [-2.6161e-01,  1.0688e-01,  2.8986e-01,  ...,  6.2090e-02,\n",
              "           7.8389e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.6948e-03, -1.1182e-01, -4.3777e-02,  ...,  4.2017e-02,\n",
              "           2.0616e-01,  2.0000e+00],\n",
              "         [ 1.6692e-01, -5.2793e-03, -3.2044e-02,  ...,  2.5161e-01,\n",
              "           7.5452e-02,  2.0000e+00],\n",
              "         [ 1.8099e-01,  6.1328e-02, -2.7214e-02,  ...,  3.1572e-01,\n",
              "          -6.6988e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 7.4787e-02,  9.8017e-02,  7.0732e-02,  ...,  5.3158e-02,\n",
              "           6.0429e-02,  2.0000e+00],\n",
              "         [-1.5940e-01,  1.2447e-01,  3.0593e-01,  ...,  1.0162e-01,\n",
              "          -5.5901e-04,  2.0000e+00],\n",
              "         [-2.4758e-01,  1.0698e-01,  2.8904e-01,  ...,  6.4208e-02,\n",
              "           6.4128e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0157, -0.1253, -0.0289,  ...,  0.0459,  0.2113,  1.0000],\n",
              "         [ 0.1497, -0.0295, -0.0065,  ...,  0.2626,  0.1213,  1.0000],\n",
              "         [ 0.1524,  0.0322,  0.0082,  ...,  0.3377, -0.0174,  1.0000],\n",
              "         ...,\n",
              "         [-0.0292,  0.1231,  0.1981,  ...,  0.0828,  0.0203,  1.0000],\n",
              "         [-0.2228,  0.1268,  0.3370,  ...,  0.0799, -0.0116,  1.0000],\n",
              "         [-0.2713,  0.1074,  0.2975,  ...,  0.0572,  0.0053,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 2.2371e-02, -1.1991e-01, -7.3738e-02,  ...,  5.9432e-02,\n",
              "           2.1319e-01,  3.0000e+00],\n",
              "         [ 1.8996e-01, -6.0434e-03, -6.3577e-02,  ...,  2.3767e-01,\n",
              "           8.0129e-02,  3.0000e+00],\n",
              "         [ 1.8640e-01,  4.5667e-02, -5.4642e-02,  ...,  3.2559e-01,\n",
              "          -8.1245e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2682e-01,  8.6782e-02,  3.1183e-02,  ...,  4.7552e-02,\n",
              "           5.8178e-02,  3.0000e+00],\n",
              "         [-1.1126e-01,  1.3227e-01,  2.4113e-01,  ...,  8.6950e-02,\n",
              "          -1.9247e-03,  3.0000e+00],\n",
              "         [-2.1966e-01,  9.2953e-02,  2.6023e-01,  ...,  7.7063e-02,\n",
              "           2.0106e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0358, -0.1484, -0.0447,  ...,  0.0634,  0.2124,  3.0000],\n",
              "         [ 0.1512, -0.1016, -0.0531,  ...,  0.2825,  0.1746,  3.0000],\n",
              "         [ 0.0962, -0.0886, -0.0520,  ...,  0.3856,  0.0830,  3.0000],\n",
              "         ...,\n",
              "         [-0.1800,  0.0418,  0.2277,  ...,  0.0882, -0.0161,  3.0000],\n",
              "         [-0.2772,  0.0680,  0.2352,  ...,  0.0712, -0.0552,  3.0000],\n",
              "         [-0.2798,  0.0487,  0.2535,  ...,  0.0276, -0.0304,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0304, -0.1456, -0.0420,  ...,  0.0537,  0.2118,  3.0000],\n",
              "         [ 0.1500, -0.0793, -0.0626,  ...,  0.2811,  0.1459,  3.0000],\n",
              "         [ 0.1155, -0.0675, -0.0679,  ...,  0.3744,  0.0433,  3.0000],\n",
              "         ...,\n",
              "         [-0.1175,  0.0414,  0.1888,  ...,  0.1012,  0.0241,  3.0000],\n",
              "         [-0.2305,  0.0382,  0.2532,  ...,  0.0743, -0.0238,  3.0000],\n",
              "         [-0.2854,  0.0435,  0.2612,  ...,  0.0398, -0.0206,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.1627e-02, -1.3172e-01, -2.6288e-02,  ...,  4.3969e-02,\n",
              "           2.0898e-01,  3.0000e+00],\n",
              "         [ 1.3300e-01, -4.3993e-02, -2.9461e-03,  ...,  2.5160e-01,\n",
              "           1.2983e-01,  3.0000e+00],\n",
              "         [ 1.2326e-01,  5.0390e-03,  1.6760e-02,  ...,  3.3316e-01,\n",
              "           1.3758e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-9.1378e-02,  1.3080e-01,  2.3385e-01,  ...,  7.9772e-02,\n",
              "           3.1774e-03,  3.0000e+00],\n",
              "         [-2.4769e-01,  1.2437e-01,  3.3977e-01,  ...,  6.6058e-02,\n",
              "          -2.8038e-02,  3.0000e+00],\n",
              "         [-2.9532e-01,  9.2913e-02,  2.9995e-01,  ...,  4.9302e-02,\n",
              "          -1.1177e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.7994e-02, -1.1825e-01, -3.3485e-02,  ...,  3.6057e-02,\n",
              "           2.0291e-01,  3.0000e+00],\n",
              "         [ 1.2742e-01, -1.4870e-02, -5.1988e-03,  ...,  2.3581e-01,\n",
              "           9.3139e-02,  3.0000e+00],\n",
              "         [ 1.2897e-01,  5.2035e-02,  1.0208e-02,  ...,  3.1012e-01,\n",
              "          -4.7779e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 8.4958e-05,  1.2821e-01,  1.5704e-01,  ...,  3.4265e-02,\n",
              "           3.0449e-02,  3.0000e+00],\n",
              "         [-2.1336e-01,  1.2317e-01,  3.3690e-01,  ...,  5.1978e-02,\n",
              "          -1.2413e-02,  3.0000e+00],\n",
              "         [-2.7951e-01,  9.5463e-02,  3.0481e-01,  ...,  4.2471e-02,\n",
              "          -4.2152e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.5128e-02, -1.3240e-01, -2.5378e-02,  ...,  4.5786e-02,\n",
              "           2.0891e-01,  3.0000e+00],\n",
              "         [ 1.3484e-01, -4.4367e-02, -8.5357e-03,  ...,  2.5421e-01,\n",
              "           1.3238e-01,  3.0000e+00],\n",
              "         [ 1.1862e-01, -1.7318e-03,  1.1974e-02,  ...,  3.3871e-01,\n",
              "           1.1563e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.2464e-01,  1.2765e-01,  2.4528e-01,  ...,  7.6957e-02,\n",
              "          -7.5911e-03,  3.0000e+00],\n",
              "         [-2.5711e-01,  1.1278e-01,  3.3198e-01,  ...,  6.0573e-02,\n",
              "          -3.5985e-02,  3.0000e+00],\n",
              "         [-3.0272e-01,  8.9220e-02,  3.0084e-01,  ...,  4.4763e-02,\n",
              "          -1.6630e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0323e-02, -1.3773e-01, -2.9961e-02,  ...,  5.5056e-02,\n",
              "           2.1913e-01,  3.0000e+00],\n",
              "         [ 1.4841e-01, -4.4756e-02, -8.8664e-03,  ...,  2.4057e-01,\n",
              "           1.4160e-01,  3.0000e+00],\n",
              "         [ 1.3593e-01,  4.1494e-03,  1.2184e-02,  ...,  3.2485e-01,\n",
              "          -8.5827e-05,  3.0000e+00],\n",
              "         ...,\n",
              "         [-5.9595e-02,  1.5465e-01,  2.0001e-01,  ...,  4.6890e-02,\n",
              "           2.1218e-02,  3.0000e+00],\n",
              "         [-2.2963e-01,  1.4431e-01,  3.0870e-01,  ...,  5.3202e-02,\n",
              "          -1.4656e-02,  3.0000e+00],\n",
              "         [-2.7719e-01,  1.0699e-01,  2.8687e-01,  ...,  7.1913e-02,\n",
              "           2.0159e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-9.6663e-03, -1.1324e-01, -3.4764e-02,  ...,  4.2411e-02,\n",
              "           2.0851e-01,  3.0000e+00],\n",
              "         [ 1.5299e-01, -1.0524e-02, -1.3203e-02,  ...,  2.4594e-01,\n",
              "           1.0086e-01,  3.0000e+00],\n",
              "         [ 1.6282e-01,  6.0498e-02, -2.8194e-04,  ...,  3.1144e-01,\n",
              "          -4.9245e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 3.5228e-02,  1.1680e-01,  1.2289e-01,  ...,  3.8100e-02,\n",
              "           5.0202e-02,  3.0000e+00],\n",
              "         [-1.8547e-01,  1.2706e-01,  3.2413e-01,  ...,  7.6058e-02,\n",
              "           3.4856e-03,  3.0000e+00],\n",
              "         [-2.5680e-01,  1.1157e-01,  2.9449e-01,  ...,  5.4932e-02,\n",
              "           7.3290e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.3215e-02, -1.2043e-01, -3.1706e-02,  ...,  4.4977e-02,\n",
              "           2.1061e-01,  3.0000e+00],\n",
              "         [ 1.4992e-01, -2.2157e-02, -1.2832e-02,  ...,  2.5777e-01,\n",
              "           1.1213e-01,  3.0000e+00],\n",
              "         [ 1.5634e-01,  4.6152e-02,  1.4670e-03,  ...,  3.2888e-01,\n",
              "          -3.2741e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 7.4715e-03,  1.2219e-01,  1.6499e-01,  ...,  6.6342e-02,\n",
              "           3.5533e-02,  3.0000e+00],\n",
              "         [-2.0301e-01,  1.2664e-01,  3.2963e-01,  ...,  8.0326e-02,\n",
              "          -9.3541e-04,  3.0000e+00],\n",
              "         [-2.6309e-01,  1.0916e-01,  2.9554e-01,  ...,  5.8799e-02,\n",
              "           9.0280e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0377, -0.1262, -0.0391,  ...,  0.0675,  0.2068,  3.0000],\n",
              "         [ 0.1743,  0.0179, -0.0315,  ...,  0.2917,  0.1234,  3.0000],\n",
              "         [ 0.1868,  0.0567, -0.0086,  ...,  0.3595,  0.0546,  3.0000],\n",
              "         ...,\n",
              "         [-0.0846,  0.1027,  0.2275,  ...,  0.1402, -0.0142,  3.0000],\n",
              "         [-0.2140,  0.0975,  0.3091,  ...,  0.1120, -0.0385,  3.0000],\n",
              "         [-0.2786,  0.0857,  0.2803,  ...,  0.0578, -0.0188,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0372, -0.1406, -0.0314,  ...,  0.0615,  0.2144,  3.0000],\n",
              "         [ 0.1582, -0.0616, -0.0362,  ...,  0.2622,  0.1514,  3.0000],\n",
              "         [ 0.1211, -0.0406, -0.0206,  ...,  0.3530,  0.0504,  3.0000],\n",
              "         ...,\n",
              "         [-0.1288,  0.1011,  0.2290,  ...,  0.0666,  0.0096,  3.0000],\n",
              "         [-0.2609,  0.0886,  0.2866,  ...,  0.0582, -0.0350,  3.0000],\n",
              "         [-0.2952,  0.0801,  0.2768,  ...,  0.0465, -0.0149,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0561, -0.2066, -0.1145,  ..., -0.0132,  0.1891,  3.0000],\n",
              "         [ 0.3201,  0.0222, -0.1070,  ...,  0.0609,  0.0181,  3.0000],\n",
              "         [ 0.3167,  0.0574, -0.0884,  ...,  0.1153, -0.0830,  3.0000],\n",
              "         ...,\n",
              "         [ 0.1674, -0.0213, -0.1772,  ...,  0.0360,  0.0796,  3.0000],\n",
              "         [ 0.0270,  0.0436,  0.1019,  ...,  0.1178, -0.0152,  3.0000],\n",
              "         [-0.1685,  0.0225,  0.2783,  ...,  0.0568, -0.0096,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9721e-02, -1.3122e-01, -3.3558e-02,  ...,  5.5476e-02,\n",
              "           2.1867e-01,  3.0000e+00],\n",
              "         [ 1.3666e-01, -4.3382e-02, -9.6612e-03,  ...,  2.4290e-01,\n",
              "           1.4167e-01,  3.0000e+00],\n",
              "         [ 1.3261e-01,  1.4724e-02,  1.4606e-02,  ...,  3.2238e-01,\n",
              "          -7.5058e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-6.0629e-02,  1.4186e-01,  2.2085e-01,  ...,  6.6256e-02,\n",
              "           8.5436e-03,  3.0000e+00],\n",
              "         [-2.3723e-01,  1.3362e-01,  3.3586e-01,  ...,  6.7132e-02,\n",
              "          -2.1998e-02,  3.0000e+00],\n",
              "         [-2.7940e-01,  1.0054e-01,  2.9655e-01,  ...,  6.7259e-02,\n",
              "           1.2493e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.9286e-02, -1.3475e-01, -3.3612e-02,  ...,  5.3176e-02,\n",
              "           2.2093e-01,  3.0000e+00],\n",
              "         [ 1.4775e-01, -4.0117e-02, -1.2729e-02,  ...,  2.6014e-01,\n",
              "           1.4269e-01,  3.0000e+00],\n",
              "         [ 1.4002e-01,  1.5891e-02,  1.1442e-02,  ...,  3.4370e-01,\n",
              "           2.5741e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-7.5331e-02,  1.4801e-01,  2.1302e-01,  ...,  7.5469e-02,\n",
              "           5.4081e-03,  3.0000e+00],\n",
              "         [-2.3136e-01,  1.3398e-01,  3.1465e-01,  ...,  6.7555e-02,\n",
              "          -3.0757e-02,  3.0000e+00],\n",
              "         [-2.8190e-01,  9.0157e-02,  2.8920e-01,  ...,  6.8510e-02,\n",
              "          -1.3500e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0175, -0.1303, -0.0322,  ...,  0.0430,  0.2096,  3.0000],\n",
              "         [ 0.1455, -0.0308, -0.0084,  ...,  0.2599,  0.1221,  3.0000],\n",
              "         [ 0.1421,  0.0251,  0.0108,  ...,  0.3397, -0.0135,  3.0000],\n",
              "         ...,\n",
              "         [-0.0361,  0.1265,  0.1864,  ...,  0.0831,  0.0170,  3.0000],\n",
              "         [-0.2189,  0.1229,  0.3203,  ...,  0.0726, -0.0171,  3.0000],\n",
              "         [-0.2798,  0.0924,  0.2909,  ...,  0.0557, -0.0098,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 6.0791e-02, -1.7408e-01, -1.0676e-01,  ...,  5.6695e-02,\n",
              "           2.0970e-01,  3.0000e+00],\n",
              "         [ 2.8853e-01, -3.8610e-03, -1.1436e-01,  ...,  1.9058e-01,\n",
              "           3.1892e-02,  3.0000e+00],\n",
              "         [ 2.6733e-01,  2.0961e-02, -8.5681e-02,  ...,  2.6974e-01,\n",
              "          -9.2270e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 2.1513e-01, -8.2696e-03, -1.1079e-02,  ...,  9.3773e-02,\n",
              "          -5.0770e-03,  3.0000e+00],\n",
              "         [-1.0343e-03,  3.2727e-02,  1.6716e-01,  ...,  1.4075e-01,\n",
              "          -5.0802e-02,  3.0000e+00],\n",
              "         [-1.4433e-01,  2.0009e-02,  2.6709e-01,  ...,  8.1126e-02,\n",
              "          -1.4698e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0164, -0.1193, -0.0357,  ...,  0.0368,  0.2033,  3.0000],\n",
              "         [ 0.1347, -0.0095, -0.0088,  ...,  0.2391,  0.0879,  3.0000],\n",
              "         [ 0.1404,  0.0586,  0.0058,  ...,  0.3106, -0.0555,  3.0000],\n",
              "         ...,\n",
              "         [ 0.0123,  0.1262,  0.1377,  ...,  0.0375,  0.0294,  3.0000],\n",
              "         [-0.2026,  0.1229,  0.3268,  ...,  0.0575, -0.0141,  3.0000],\n",
              "         [-0.2725,  0.0961,  0.2998,  ...,  0.0456, -0.0049,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-6.4763e-03, -1.2219e-01, -4.6383e-02,  ...,  5.1405e-02,\n",
              "           2.1882e-01,  3.0000e+00],\n",
              "         [ 1.4130e-01, -2.0348e-02, -1.9490e-02,  ...,  2.3117e-01,\n",
              "           1.2408e-01,  3.0000e+00],\n",
              "         [ 1.4063e-01,  4.3200e-02, -2.1278e-04,  ...,  3.1301e-01,\n",
              "          -3.9623e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3793e-02,  1.6009e-01,  1.6358e-01,  ...,  2.9728e-02,\n",
              "           2.7345e-02,  3.0000e+00],\n",
              "         [-1.9604e-01,  1.5173e-01,  3.0936e-01,  ...,  4.5174e-02,\n",
              "          -1.1982e-02,  3.0000e+00],\n",
              "         [-2.5160e-01,  9.5183e-02,  2.8646e-01,  ...,  6.8294e-02,\n",
              "          -6.4460e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0158, -0.1188, -0.0353,  ...,  0.0461,  0.2151,  3.0000],\n",
              "         [ 0.1343, -0.0172, -0.0111,  ...,  0.2336,  0.1170,  3.0000],\n",
              "         [ 0.1394,  0.0523,  0.0087,  ...,  0.3036, -0.0364,  3.0000],\n",
              "         ...,\n",
              "         [-0.0163,  0.1429,  0.1667,  ...,  0.0344,  0.0266,  3.0000],\n",
              "         [-0.2161,  0.1499,  0.3287,  ...,  0.0562, -0.0047,  3.0000],\n",
              "         [-0.2722,  0.1080,  0.3016,  ...,  0.0663,  0.0079,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3998e-02, -1.3364e-01, -2.6830e-02,  ...,  5.1873e-02,\n",
              "           2.1704e-01,  3.0000e+00],\n",
              "         [ 1.3587e-01, -4.6482e-02, -2.3429e-03,  ...,  2.4037e-01,\n",
              "           1.3885e-01,  3.0000e+00],\n",
              "         [ 1.2833e-01,  7.7182e-03,  2.0040e-02,  ...,  3.1846e-01,\n",
              "          -2.1702e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0650e-01,  1.5271e-01,  2.4588e-01,  ...,  4.9637e-02,\n",
              "          -1.0513e-03,  3.0000e+00],\n",
              "         [-2.5036e-01,  1.3690e-01,  3.3493e-01,  ...,  5.5419e-02,\n",
              "          -2.7272e-02,  3.0000e+00],\n",
              "         [-2.8558e-01,  1.0478e-01,  2.9731e-01,  ...,  6.2726e-02,\n",
              "           1.0776e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.4364e-02, -1.3286e-01, -2.4839e-02,  ...,  4.4475e-02,\n",
              "           2.0864e-01,  3.0000e+00],\n",
              "         [ 1.3264e-01, -4.5923e-02, -3.7947e-03,  ...,  2.5445e-01,\n",
              "           1.3248e-01,  3.0000e+00],\n",
              "         [ 1.1780e-01, -2.3134e-03,  1.4644e-02,  ...,  3.3672e-01,\n",
              "           1.3868e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.2228e-01,  1.3263e-01,  2.4992e-01,  ...,  7.8226e-02,\n",
              "          -3.8005e-03,  3.0000e+00],\n",
              "         [-2.5722e-01,  1.1711e-01,  3.3677e-01,  ...,  6.5320e-02,\n",
              "          -3.1647e-02,  3.0000e+00],\n",
              "         [-3.0188e-01,  9.1062e-02,  3.0186e-01,  ...,  4.8232e-02,\n",
              "          -1.5337e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0326, -0.1486, -0.0363,  ...,  0.0620,  0.2163,  3.0000],\n",
              "         [ 0.1662, -0.0790, -0.0490,  ...,  0.2794,  0.1594,  3.0000],\n",
              "         [ 0.1211, -0.0636, -0.0434,  ...,  0.3736,  0.0596,  3.0000],\n",
              "         ...,\n",
              "         [-0.1352,  0.0595,  0.2230,  ...,  0.0846,  0.0031,  3.0000],\n",
              "         [-0.2518,  0.0554,  0.2623,  ...,  0.0702, -0.0392,  3.0000],\n",
              "         [-0.2843,  0.0563,  0.2662,  ...,  0.0413, -0.0181,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0240, -0.1318, -0.0270,  ...,  0.0451,  0.2102,  3.0000],\n",
              "         [ 0.1342, -0.0482, -0.0102,  ...,  0.2522,  0.1357,  3.0000],\n",
              "         [ 0.1182, -0.0058,  0.0107,  ...,  0.3389,  0.0107,  3.0000],\n",
              "         ...,\n",
              "         [-0.1230,  0.1294,  0.2456,  ...,  0.0825, -0.0034,  3.0000],\n",
              "         [-0.2550,  0.1192,  0.3301,  ...,  0.0645, -0.0344,  3.0000],\n",
              "         [-0.3039,  0.0874,  0.2982,  ...,  0.0474, -0.0177,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0345, -0.1324, -0.0335,  ...,  0.0548,  0.2084,  3.0000],\n",
              "         [ 0.1429, -0.0633, -0.0438,  ...,  0.2717,  0.1434,  3.0000],\n",
              "         [ 0.1123, -0.0419, -0.0396,  ...,  0.3617,  0.0409,  3.0000],\n",
              "         ...,\n",
              "         [-0.1424,  0.0716,  0.2285,  ...,  0.0879,  0.0089,  3.0000],\n",
              "         [-0.2539,  0.0610,  0.2847,  ...,  0.0671, -0.0318,  3.0000],\n",
              "         [-0.3020,  0.0717,  0.2811,  ...,  0.0365, -0.0179,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0156, -0.1258, -0.0289,  ...,  0.0446,  0.2109,  3.0000],\n",
              "         [ 0.1507, -0.0322, -0.0065,  ...,  0.2601,  0.1217,  3.0000],\n",
              "         [ 0.1525,  0.0284,  0.0093,  ...,  0.3363, -0.0178,  3.0000],\n",
              "         ...,\n",
              "         [-0.0263,  0.1228,  0.1912,  ...,  0.0788,  0.0226,  3.0000],\n",
              "         [-0.2208,  0.1273,  0.3308,  ...,  0.0759, -0.0106,  3.0000],\n",
              "         [-0.2716,  0.1080,  0.2946,  ...,  0.0554,  0.0053,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4310e-02, -1.3009e-01, -2.4987e-02,  ...,  4.1997e-02,\n",
              "           2.0871e-01,  3.0000e+00],\n",
              "         [ 1.2828e-01, -4.5904e-02, -2.2938e-03,  ...,  2.3934e-01,\n",
              "           1.3285e-01,  3.0000e+00],\n",
              "         [ 1.1580e-01,  1.7489e-03,  1.9784e-02,  ...,  3.2264e-01,\n",
              "           5.1778e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.1411e-01,  1.3883e-01,  2.5377e-01,  ...,  7.0265e-02,\n",
              "           1.7180e-03,  3.0000e+00],\n",
              "         [-2.5895e-01,  1.2621e-01,  3.4691e-01,  ...,  5.7236e-02,\n",
              "          -2.9413e-02,  3.0000e+00],\n",
              "         [-3.0536e-01,  9.1187e-02,  3.0351e-01,  ...,  4.6030e-02,\n",
              "          -1.5327e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0330, -0.1557, -0.0381,  ...,  0.0603,  0.2150,  3.0000],\n",
              "         [ 0.1702, -0.0849, -0.0499,  ...,  0.2766,  0.1529,  3.0000],\n",
              "         [ 0.1253, -0.0672, -0.0457,  ...,  0.3638,  0.0520,  3.0000],\n",
              "         ...,\n",
              "         [-0.1062,  0.0617,  0.2007,  ...,  0.0765,  0.0170,  3.0000],\n",
              "         [-0.2307,  0.0622,  0.2486,  ...,  0.0621, -0.0327,  3.0000],\n",
              "         [-0.2735,  0.0526,  0.2576,  ...,  0.0454, -0.0191,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.2111e-02, -1.5866e-01, -5.6272e-02,  ...,  6.0367e-02,\n",
              "           2.1104e-01,  3.0000e+00],\n",
              "         [ 1.4067e-01, -1.1448e-01, -7.7314e-02,  ...,  3.0453e-01,\n",
              "           1.5274e-01,  3.0000e+00],\n",
              "         [ 8.9430e-02, -1.1576e-01, -8.4571e-02,  ...,  4.0139e-01,\n",
              "           7.7006e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.4446e-01,  8.3808e-03,  1.9559e-01,  ...,  1.1467e-01,\n",
              "          -1.4623e-02,  3.0000e+00],\n",
              "         [-2.2110e-01,  1.7425e-02,  2.0098e-01,  ...,  9.3214e-02,\n",
              "          -4.5059e-02,  3.0000e+00],\n",
              "         [-2.6194e-01,  1.7050e-03,  2.3219e-01,  ...,  3.7674e-02,\n",
              "          -2.9915e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.6702e-02, -1.1914e-01, -3.4183e-02,  ...,  3.4926e-02,\n",
              "           2.0414e-01,  3.0000e+00],\n",
              "         [ 1.3140e-01, -1.4045e-02, -3.9802e-03,  ...,  2.3261e-01,\n",
              "           9.4971e-02,  3.0000e+00],\n",
              "         [ 1.3270e-01,  5.0988e-02,  1.1913e-02,  ...,  3.0392e-01,\n",
              "          -4.8162e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 2.9067e-03,  1.2873e-01,  1.5135e-01,  ...,  3.3766e-02,\n",
              "           3.4194e-02,  3.0000e+00],\n",
              "         [-2.1156e-01,  1.2527e-01,  3.3241e-01,  ...,  5.0294e-02,\n",
              "          -1.1998e-02,  3.0000e+00],\n",
              "         [-2.8082e-01,  9.6174e-02,  3.0452e-01,  ...,  4.2615e-02,\n",
              "          -3.9451e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1396e-02, -1.2506e-01, -2.6745e-02,  ...,  3.9018e-02,\n",
              "           2.0785e-01,  3.0000e+00],\n",
              "         [ 1.2667e-01, -3.1451e-02,  2.7752e-04,  ...,  2.3245e-01,\n",
              "           1.1869e-01,  3.0000e+00],\n",
              "         [ 1.2329e-01,  2.8911e-02,  2.0697e-02,  ...,  3.0932e-01,\n",
              "          -1.9827e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-5.3940e-02,  1.3436e-01,  2.1559e-01,  ...,  4.9713e-02,\n",
              "           2.0290e-02,  3.0000e+00],\n",
              "         [-2.3744e-01,  1.3071e-01,  3.5054e-01,  ...,  4.8844e-02,\n",
              "          -1.3905e-02,  3.0000e+00],\n",
              "         [-2.9443e-01,  9.7564e-02,  3.0894e-01,  ...,  4.2614e-02,\n",
              "          -5.5649e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0265, -0.1358, -0.0262,  ...,  0.0513,  0.2144,  3.0000],\n",
              "         [ 0.1437, -0.0461, -0.0065,  ...,  0.2459,  0.1361,  3.0000],\n",
              "         [ 0.1320,  0.0060,  0.0193,  ...,  0.3238,  0.0045,  3.0000],\n",
              "         ...,\n",
              "         [-0.1275,  0.1507,  0.2511,  ...,  0.0586, -0.0119,  3.0000],\n",
              "         [-0.2604,  0.1309,  0.3314,  ...,  0.0550, -0.0358,  3.0000],\n",
              "         [-0.2917,  0.0949,  0.2984,  ...,  0.0590, -0.0075,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 5.0999e-03, -1.1186e-01, -5.7125e-02,  ...,  5.0795e-02,\n",
              "           2.1115e-01,  3.0000e+00],\n",
              "         [ 1.5807e-01, -1.8330e-02, -4.7397e-02,  ...,  2.1432e-01,\n",
              "           1.1152e-01,  3.0000e+00],\n",
              "         [ 1.4636e-01,  2.9186e-02, -3.2059e-02,  ...,  3.0116e-01,\n",
              "          -5.1060e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 7.1943e-02,  1.1100e-01,  7.6417e-02,  ...,  3.1494e-02,\n",
              "           5.4771e-02,  3.0000e+00],\n",
              "         [-1.5250e-01,  1.4285e-01,  2.7436e-01,  ...,  7.6558e-02,\n",
              "           1.3761e-03,  3.0000e+00],\n",
              "         [-2.5300e-01,  9.4362e-02,  2.7620e-01,  ...,  6.9654e-02,\n",
              "          -1.1768e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.0311e-02, -1.2581e-01, -2.8642e-02,  ...,  3.5458e-02,\n",
              "           2.0701e-01,  3.0000e+00],\n",
              "         [ 1.2231e-01, -2.7709e-02,  1.0738e-03,  ...,  2.3894e-01,\n",
              "           1.0830e-01,  3.0000e+00],\n",
              "         [ 1.2804e-01,  4.1664e-02,  2.3461e-02,  ...,  3.1473e-01,\n",
              "          -3.3459e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-2.6617e-02,  1.2958e-01,  1.8790e-01,  ...,  4.7080e-02,\n",
              "           3.1141e-02,  3.0000e+00],\n",
              "         [-2.2262e-01,  1.2875e-01,  3.4144e-01,  ...,  5.2259e-02,\n",
              "          -7.8532e-03,  3.0000e+00],\n",
              "         [-2.8459e-01,  9.7861e-02,  3.0253e-01,  ...,  4.4318e-02,\n",
              "          -4.7737e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1417, -0.0386,  ...,  0.0542,  0.2126,  3.0000],\n",
              "         [ 0.1481, -0.0737, -0.0591,  ...,  0.2800,  0.1520,  3.0000],\n",
              "         [ 0.1118, -0.0615, -0.0615,  ...,  0.3728,  0.0504,  3.0000],\n",
              "         ...,\n",
              "         [-0.1317,  0.0499,  0.2118,  ...,  0.0972,  0.0198,  3.0000],\n",
              "         [-0.2418,  0.0441,  0.2668,  ...,  0.0726, -0.0253,  3.0000],\n",
              "         [-0.2935,  0.0500,  0.2695,  ...,  0.0385, -0.0186,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 6.6921e-06, -1.0930e-01, -5.8084e-02,  ...,  4.3424e-02,\n",
              "           2.1007e-01,  3.0000e+00],\n",
              "         [ 1.5179e-01, -6.2386e-03, -4.0219e-02,  ...,  2.1846e-01,\n",
              "           9.1796e-02,  3.0000e+00],\n",
              "         [ 1.5764e-01,  4.8820e-02, -2.9057e-02,  ...,  2.9691e-01,\n",
              "          -6.8260e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 5.1278e-02,  1.0718e-01,  8.1310e-02,  ...,  2.2210e-02,\n",
              "           3.9378e-02,  3.0000e+00],\n",
              "         [-1.7112e-01,  1.3738e-01,  3.0061e-01,  ...,  7.0909e-02,\n",
              "          -1.1220e-02,  3.0000e+00],\n",
              "         [-2.6196e-01,  1.0321e-01,  2.9061e-01,  ...,  6.1537e-02,\n",
              "           3.0911e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0317, -0.1404, -0.0387,  ...,  0.0587,  0.2100,  1.0000],\n",
              "         [ 0.1490, -0.0741, -0.0580,  ...,  0.2870,  0.1399,  1.0000],\n",
              "         [ 0.1208, -0.0572, -0.0624,  ...,  0.3760,  0.0370,  1.0000],\n",
              "         ...,\n",
              "         [-0.1154,  0.0419,  0.1951,  ...,  0.0964,  0.0219,  1.0000],\n",
              "         [-0.2290,  0.0391,  0.2591,  ...,  0.0748, -0.0233,  1.0000],\n",
              "         [-0.2839,  0.0521,  0.2651,  ...,  0.0431, -0.0168,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.9671e-02, -1.6565e-01, -5.4881e-02,  ...,  5.8644e-02,\n",
              "           2.0933e-01,  1.0000e+00],\n",
              "         [ 1.4092e-01, -1.2349e-01, -7.3862e-02,  ...,  2.9936e-01,\n",
              "           1.5091e-01,  1.0000e+00],\n",
              "         [ 9.6781e-02, -1.2497e-01, -8.1546e-02,  ...,  3.8225e-01,\n",
              "           8.7865e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.2778e-01,  4.8147e-04,  1.8947e-01,  ...,  1.1494e-01,\n",
              "           1.3039e-03,  1.0000e+00],\n",
              "         [-2.1135e-01,  9.7101e-03,  2.0280e-01,  ...,  9.2157e-02,\n",
              "          -3.7781e-02,  1.0000e+00],\n",
              "         [-2.5840e-01, -2.5433e-03,  2.3244e-01,  ...,  3.5913e-02,\n",
              "          -2.8575e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0352, -0.1569, -0.0586,  ...,  0.0621,  0.2108,  1.0000],\n",
              "         [ 0.1359, -0.1175, -0.0816,  ...,  0.3035,  0.1556,  1.0000],\n",
              "         [ 0.0820, -0.1173, -0.0906,  ...,  0.4032,  0.0793,  1.0000],\n",
              "         ...,\n",
              "         [-0.1613,  0.0093,  0.1914,  ...,  0.1085, -0.0322,  1.0000],\n",
              "         [-0.2277,  0.0188,  0.1947,  ...,  0.0882, -0.0544,  1.0000],\n",
              "         [-0.2632,  0.0041,  0.2312,  ...,  0.0306, -0.0318,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0273, -0.1357, -0.0380,  ...,  0.0614,  0.2089,  1.0000],\n",
              "         [ 0.1537, -0.0722, -0.0557,  ...,  0.2865,  0.1346,  1.0000],\n",
              "         [ 0.1351, -0.0506, -0.0593,  ...,  0.3789,  0.0233,  1.0000],\n",
              "         ...,\n",
              "         [-0.0962,  0.0554,  0.1871,  ...,  0.1052,  0.0188,  1.0000],\n",
              "         [-0.2225,  0.0560,  0.2634,  ...,  0.0827, -0.0238,  1.0000],\n",
              "         [-0.2804,  0.0628,  0.2663,  ...,  0.0496, -0.0192,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2219e-02, -1.3671e-01, -3.0924e-02,  ...,  5.4142e-02,\n",
              "           2.1606e-01,  1.0000e+00],\n",
              "         [ 1.4187e-01, -4.8140e-02, -9.7058e-03,  ...,  2.4891e-01,\n",
              "           1.3668e-01,  1.0000e+00],\n",
              "         [ 1.3318e-01, -8.3086e-04,  1.3964e-02,  ...,  3.2744e-01,\n",
              "          -1.0226e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.1401e-01,  1.5167e-01,  2.3717e-01,  ...,  5.4468e-02,\n",
              "          -1.0227e-02,  1.0000e+00],\n",
              "         [-2.4387e-01,  1.2755e-01,  3.1924e-01,  ...,  5.5935e-02,\n",
              "          -3.5379e-02,  1.0000e+00],\n",
              "         [-2.7901e-01,  1.0096e-01,  2.8922e-01,  ...,  6.0974e-02,\n",
              "          -6.1557e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0233, -0.1346, -0.0280,  ...,  0.0516,  0.2148,  1.0000],\n",
              "         [ 0.1419, -0.0472, -0.0098,  ...,  0.2527,  0.1371,  1.0000],\n",
              "         [ 0.1293, -0.0027,  0.0162,  ...,  0.3366,  0.0053,  1.0000],\n",
              "         ...,\n",
              "         [-0.1277,  0.1457,  0.2462,  ...,  0.0609, -0.0125,  1.0000],\n",
              "         [-0.2498,  0.1244,  0.3238,  ...,  0.0580, -0.0381,  1.0000],\n",
              "         [-0.2887,  0.0962,  0.2952,  ...,  0.0562, -0.0116,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0325, -0.1262, -0.0314,  ...,  0.0633,  0.2125,  1.0000],\n",
              "         [ 0.1515, -0.0567, -0.0319,  ...,  0.2580,  0.1501,  1.0000],\n",
              "         [ 0.1223, -0.0309, -0.0134,  ...,  0.3532,  0.0379,  1.0000],\n",
              "         ...,\n",
              "         [-0.1698,  0.1108,  0.2665,  ...,  0.0798, -0.0219,  1.0000],\n",
              "         [-0.2766,  0.0955,  0.3094,  ...,  0.0734, -0.0470,  1.0000],\n",
              "         [-0.2964,  0.0905,  0.2823,  ...,  0.0488, -0.0131,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0361, -0.1553, -0.0553,  ...,  0.0582,  0.2129,  1.0000],\n",
              "         [ 0.1407, -0.1133, -0.0799,  ...,  0.2937,  0.1591,  1.0000],\n",
              "         [ 0.0880, -0.1154, -0.0857,  ...,  0.3924,  0.0827,  1.0000],\n",
              "         ...,\n",
              "         [-0.1560,  0.0053,  0.1989,  ...,  0.1138, -0.0095,  1.0000],\n",
              "         [-0.2375,  0.0178,  0.2101,  ...,  0.0905, -0.0479,  1.0000],\n",
              "         [-0.2766,  0.0069,  0.2416,  ...,  0.0291, -0.0296,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1317, -0.0356,  ...,  0.0582,  0.2102,  1.0000],\n",
              "         [ 0.1423, -0.0650, -0.0506,  ...,  0.2802,  0.1440,  1.0000],\n",
              "         [ 0.1137, -0.0456, -0.0507,  ...,  0.3742,  0.0343,  1.0000],\n",
              "         ...,\n",
              "         [-0.1345,  0.0698,  0.2220,  ...,  0.1009,  0.0065,  1.0000],\n",
              "         [-0.2507,  0.0618,  0.2809,  ...,  0.0759, -0.0330,  1.0000],\n",
              "         [-0.2997,  0.0686,  0.2780,  ...,  0.0419, -0.0204,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0310, -0.1339, -0.0280,  ...,  0.0610,  0.2104,  1.0000],\n",
              "         [ 0.1567, -0.0569, -0.0173,  ...,  0.2639,  0.1413,  1.0000],\n",
              "         [ 0.1311, -0.0253, -0.0021,  ...,  0.3546,  0.0384,  1.0000],\n",
              "         ...,\n",
              "         [-0.1307,  0.1239,  0.2411,  ...,  0.0726, -0.0025,  1.0000],\n",
              "         [-0.2589,  0.1010,  0.3050,  ...,  0.0675, -0.0331,  1.0000],\n",
              "         [-0.2905,  0.0927,  0.2823,  ...,  0.0564, -0.0089,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0147, -0.1280, -0.0294,  ...,  0.0462,  0.2116,  1.0000],\n",
              "         [ 0.1544, -0.0318, -0.0075,  ...,  0.2699,  0.1237,  1.0000],\n",
              "         [ 0.1557,  0.0264,  0.0056,  ...,  0.3465, -0.0097,  1.0000],\n",
              "         ...,\n",
              "         [-0.0323,  0.1224,  0.1925,  ...,  0.0879,  0.0206,  1.0000],\n",
              "         [-0.2160,  0.1257,  0.3246,  ...,  0.0814, -0.0132,  1.0000],\n",
              "         [-0.2687,  0.1055,  0.2925,  ...,  0.0599,  0.0035,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0357, -0.1463, -0.0415,  ...,  0.0617,  0.2174,  1.0000],\n",
              "         [ 0.1575, -0.0853, -0.0538,  ...,  0.2866,  0.1671,  1.0000],\n",
              "         [ 0.1069, -0.0783, -0.0534,  ...,  0.3861,  0.0760,  1.0000],\n",
              "         ...,\n",
              "         [-0.1507,  0.0394,  0.2295,  ...,  0.0914, -0.0022,  1.0000],\n",
              "         [-0.2644,  0.0489,  0.2497,  ...,  0.0737, -0.0431,  1.0000],\n",
              "         [-0.2876,  0.0486,  0.2620,  ...,  0.0357, -0.0176,  1.0000]],\n",
              "        device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert the list of tensors to a list of NumPy arrays\n",
        "final_features_numpy = [tensor.cpu().numpy() for tensor in final_features]\n",
        "\n",
        "# Save the list of NumPy arrays using NumPy's save function\n",
        "np.save('/content/session1.npy', final_features_numpy)"
      ],
      "metadata": {
        "id": "jSWYc1yLxVA4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class EmotionAVDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            features (list of Tensors): List where each element is a tensor of shape [sequence_length, feature_dim]\n",
        "            labels (list of int): List of labels corresponding to each feature set\n",
        "        \"\"\"\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "yy2NdF1ZzuJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Separate features and labels\n",
        "    features, labels = zip(*batch)\n",
        "    # Pad features\n",
        "    features_padded = pad_sequence(features, batch_first=True, padding_value=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    return features_padded, labels\n",
        "\n",
        "# Example usage\n",
        "dataset = EmotionAVDataset(final_features, labels)\n",
        "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn, shuffle=True)"
      ],
      "metadata": {
        "id": "uIfkpUZwzyoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self, feature_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(feature_dim, hidden_dim, batch_first=True)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        out = self.classifier(hidden[-1])\n",
        "        return out"
      ],
      "metadata": {
        "id": "HZoO5LY6z5zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple LSTM-based model for emotion classification\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self, feature_dim, hidden_dim, num_classes):\n",
        "        super(EmotionClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(feature_dim, hidden_dim, batch_first=True)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        out = self.classifier(hidden[-1])  # Use the last hidden state\n",
        "        return out\n",
        "\n",
        "# Assume num_features and num_classes are defined based on your dataset\n",
        "feature_dim = 768  # Feature dimension for each timestep\n",
        "hidden_dim = 128  # Hidden dimension for LSTM\n",
        "num_classes = 2   # Example: 5 different emotion classes\n",
        "\n",
        "model = EmotionClassifier(feature_dim, hidden_dim, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "vz_gLVcS0BMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "SQa_RFYJ0VvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EmotionClassifier(feature_dim, hidden_dim, num_classes).to(device)"
      ],
      "metadata": {
        "id": "6qXp_DZp0mbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay_epoch epochs\"\"\"\n",
        "    lr = initial_lr * (0.1**(epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def train_model(num_epochs, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch)\n",
        "        for features, labels in loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Optional: Print average gradients per epoch to check for vanishing/exploding gradients\n",
        "        avg_gradients = {name: torch.mean(param.grad.abs()).item() for name, param in model.named_parameters() if param.grad is not None}\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(loader)}, Avg Gradients: {avg_gradients}\")\n",
        "\n",
        "        # Check for NaN loss\n",
        "        if torch.isnan(loss).any():\n",
        "            print(\"NaN loss detected\")\n",
        "            break\n",
        "\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "I1nsJZ3a0oqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(50)\n",
        "evaluate_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqi6fr7x0s80",
        "outputId": "23427e20-2fe2-4ea7-988d-0c425ea6717c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7050982117652893, Avg Gradients: {'lstm.weight_ih_l0': 0.00015319950762204826, 'lstm.weight_hh_l0': 0.0001138313818955794, 'lstm.bias_ih_l0': 0.00045707906247116625, 'lstm.bias_hh_l0': 0.00045707906247116625, 'classifier.weight': 0.010660267435014248, 'classifier.bias': 0.004405215382575989}\n",
            "Epoch 2, Loss: 0.6446354389190674, Avg Gradients: {'lstm.weight_ih_l0': 0.00011407291458453983, 'lstm.weight_hh_l0': 9.138100722339004e-05, 'lstm.bias_ih_l0': 0.0005290161934681237, 'lstm.bias_hh_l0': 0.0005290161934681237, 'classifier.weight': 0.010138976387679577, 'classifier.bias': 0.028205230832099915}\n",
            "Epoch 3, Loss: 0.6003038883209229, Avg Gradients: {'lstm.weight_ih_l0': 8.434417395619676e-05, 'lstm.weight_hh_l0': 8.907501614885405e-05, 'lstm.bias_ih_l0': 0.0007479123887605965, 'lstm.bias_hh_l0': 0.0007479123887605965, 'classifier.weight': 0.010165289044380188, 'classifier.bias': 0.055923957377672195}\n",
            "Epoch 4, Loss: 0.5680534839630127, Avg Gradients: {'lstm.weight_ih_l0': 5.7642406318336725e-05, 'lstm.weight_hh_l0': 8.380445069633424e-05, 'lstm.bias_ih_l0': 0.0009154333965852857, 'lstm.bias_hh_l0': 0.0009154333965852857, 'classifier.weight': 0.009360942989587784, 'classifier.bias': 0.07788243889808655}\n",
            "Epoch 5, Loss: 0.5654211640357971, Avg Gradients: {'lstm.weight_ih_l0': 5.526038512471132e-05, 'lstm.weight_hh_l0': 8.30204226076603e-05, 'lstm.bias_ih_l0': 0.0009281523525714874, 'lstm.bias_hh_l0': 0.0009281523525714874, 'classifier.weight': 0.009229740127921104, 'classifier.bias': 0.0796666294336319}\n",
            "Epoch 6, Loss: 0.5628683567047119, Avg Gradients: {'lstm.weight_ih_l0': 5.2991508709965274e-05, 'lstm.weight_hh_l0': 8.228303340729326e-05, 'lstm.bias_ih_l0': 0.0009401073330081999, 'lstm.bias_hh_l0': 0.0009401073330081999, 'classifier.weight': 0.009092732332646847, 'classifier.bias': 0.08135106414556503}\n",
            "Epoch 7, Loss: 0.5603942275047302, Avg Gradients: {'lstm.weight_ih_l0': 5.0801823817892e-05, 'lstm.weight_hh_l0': 8.154720126185566e-05, 'lstm.bias_ih_l0': 0.0009514251141808927, 'lstm.bias_hh_l0': 0.0009514251141808927, 'classifier.weight': 0.008949346840381622, 'classifier.bias': 0.08294837176799774}\n",
            "Epoch 8, Loss: 0.5601511597633362, Avg Gradients: {'lstm.weight_ih_l0': 5.058874376118183e-05, 'lstm.weight_hh_l0': 8.14757077023387e-05, 'lstm.bias_ih_l0': 0.0009525122586637735, 'lstm.bias_hh_l0': 0.0009525122586637735, 'classifier.weight': 0.008934767916798592, 'classifier.bias': 0.08310237526893616}\n",
            "Epoch 9, Loss: 0.5599085688591003, Avg Gradients: {'lstm.weight_ih_l0': 5.037964365328662e-05, 'lstm.weight_hh_l0': 8.140889985952526e-05, 'lstm.bias_ih_l0': 0.000953582813963294, 'lstm.bias_hh_l0': 0.000953582813963294, 'classifier.weight': 0.008920280262827873, 'classifier.bias': 0.0832539051771164}\n",
            "Epoch 10, Loss: 0.559666633605957, Avg Gradients: {'lstm.weight_ih_l0': 5.017354851588607e-05, 'lstm.weight_hh_l0': 8.134573727147654e-05, 'lstm.bias_ih_l0': 0.0009546603541821241, 'lstm.bias_hh_l0': 0.0009546603541821241, 'classifier.weight': 0.008905836381018162, 'classifier.bias': 0.08340348303318024}\n",
            "Epoch 11, Loss: 0.5596424341201782, Avg Gradients: {'lstm.weight_ih_l0': 5.0153186748502776e-05, 'lstm.weight_hh_l0': 8.133973460644484e-05, 'lstm.bias_ih_l0': 0.0009547670488245785, 'lstm.bias_hh_l0': 0.0009547670488245785, 'classifier.weight': 0.008904400281608105, 'classifier.bias': 0.08341828733682632}\n",
            "Epoch 12, Loss: 0.5596181750297546, Avg Gradients: {'lstm.weight_ih_l0': 5.01329886901658e-05, 'lstm.weight_hh_l0': 8.133399387588724e-05, 'lstm.bias_ih_l0': 0.0009548733360134065, 'lstm.bias_hh_l0': 0.0009548733360134065, 'classifier.weight': 0.008902967907488346, 'classifier.bias': 0.08343301713466644}\n",
            "Epoch 13, Loss: 0.5595939755439758, Avg Gradients: {'lstm.weight_ih_l0': 5.011292523704469e-05, 'lstm.weight_hh_l0': 8.132847142405808e-05, 'lstm.bias_ih_l0': 0.0009549791575409472, 'lstm.bias_hh_l0': 0.0009549791575409472, 'classifier.weight': 0.00890154018998146, 'classifier.bias': 0.08344767242670059}\n",
            "Epoch 14, Loss: 0.55959153175354, Avg Gradients: {'lstm.weight_ih_l0': 5.0110946176573634e-05, 'lstm.weight_hh_l0': 8.132794755510986e-05, 'lstm.bias_ih_l0': 0.0009549895767122507, 'lstm.bias_hh_l0': 0.0009549895767122507, 'classifier.weight': 0.008901399560272694, 'classifier.bias': 0.08344912528991699}\n",
            "Epoch 15, Loss: 0.5595890879631042, Avg Gradients: {'lstm.weight_ih_l0': 5.0108945288229734e-05, 'lstm.weight_hh_l0': 8.132740913424641e-05, 'lstm.bias_ih_l0': 0.0009550002869218588, 'lstm.bias_hh_l0': 0.0009550002869218588, 'classifier.weight': 0.008901255205273628, 'classifier.bias': 0.08345059305429459}\n",
            "Epoch 16, Loss: 0.5595866441726685, Avg Gradients: {'lstm.weight_ih_l0': 5.010697350371629e-05, 'lstm.weight_hh_l0': 8.132692892104387e-05, 'lstm.bias_ih_l0': 0.0009550107643008232, 'lstm.bias_hh_l0': 0.0009550107643008232, 'classifier.weight': 0.008901115506887436, 'classifier.bias': 0.08345203846693039}\n",
            "Epoch 17, Loss: 0.5595864057540894, Avg Gradients: {'lstm.weight_ih_l0': 5.010676977690309e-05, 'lstm.weight_hh_l0': 8.132685616146773e-05, 'lstm.bias_ih_l0': 0.0009550119284540415, 'lstm.bias_hh_l0': 0.0009550119284540415, 'classifier.weight': 0.008901100605726242, 'classifier.bias': 0.08345219492912292}\n",
            "Epoch 18, Loss: 0.559586226940155, Avg Gradients: {'lstm.weight_ih_l0': 5.010657332604751e-05, 'lstm.weight_hh_l0': 8.132679795380682e-05, 'lstm.bias_ih_l0': 0.0009550127433612943, 'lstm.bias_hh_l0': 0.0009550127433612943, 'classifier.weight': 0.008901085704565048, 'classifier.bias': 0.08345231413841248}\n",
            "Epoch 19, Loss: 0.5595859885215759, Avg Gradients: {'lstm.weight_ih_l0': 5.010638778912835e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550138493068516, 'lstm.bias_hh_l0': 0.0009550138493068516, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345246315002441}\n",
            "Epoch 20, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132675429806113e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 21, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 22, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 23, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132677612593397e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.0834524855017662}\n",
            "Epoch 24, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 25, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 26, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 27, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132677612593397e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 28, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 29, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 30, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 31, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 32, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 33, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 34, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 35, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 36, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 37, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 38, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 39, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 40, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 41, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 42, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 43, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 44, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 45, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 46, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 47, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 48, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 49, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 50, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GO0bvm6a02Fu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}