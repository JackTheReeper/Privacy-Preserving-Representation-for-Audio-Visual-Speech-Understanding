{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "IRcv11EWEled"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyAgarwal11/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/blob/main/diffrence_pr2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dependancies"
      ],
      "metadata": {
        "id": "qBmn_DkCFAFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.23.5"
      ],
      "metadata": {
        "id": "JxlYZMCuNefB",
        "outputId": "bcca1b83-b91e-4f32-b770-76c8fbf084ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c3a0323e288242538cb2b2fc0425c85a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GABUf90oBGy3",
        "outputId": "2d1254f1-1d8b-426b-dceb-90bbb6f25f1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding'...\n",
            "remote: Enumerating objects: 104890, done.\u001b[K\n",
            "remote: Counting objects: 100% (1185/1185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1103/1103), done.\u001b[K\n",
            "remote: Total 104890 (delta 105), reused 1136 (delta 82), pack-reused 103705\u001b[K\n",
            "Receiving objects: 100% (104890/104890), 3.13 GiB | 27.17 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "Updating files: 100% (104377/104377), done.\n",
            "/content\n",
            "Cloning into 'av_hubert'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 149 (delta 18), reused 22 (delta 14), pack-reused 111\u001b[K\n",
            "Receiving objects: 100% (149/149), 4.65 MiB | 21.53 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content/av_hubert\n",
            "Submodule 'fairseq' (https://github.com/pytorch/fairseq) registered for path 'fairseq'\n",
            "Cloning into '/content/av_hubert/fairseq'...\n",
            "Submodule path 'fairseq': checked out 'afc77bdf4bb51453ce76f1572ef2ee6ddcda8eeb'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=f484bead1c1bc9e4e2c11a19ff6750e7dbc456673d04d96a4c43640c25a09817\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n",
            "Collecting scikit-video\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.11.4)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n",
            "/content/av_hubert/fairseq\n",
            "Processing /content/av_hubert/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (3.0.10)\n",
            "Collecting hydra-core<1.1 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.23.5)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (4.11.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (4.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==1.0.0a0+afc77bd) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq==1.0.0a0+afc77bd)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq==1.0.0a0+afc77bd) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq==1.0.0a0+afc77bd) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+afc77bd-cp310-cp310-linux_x86_64.whl size=2472386 sha256=079d9fe5abf648b19b9f53ad34eeeb87463857a8d22c34313c1306d7316712e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fb4_11a0/wheels/9d/d5/16/2858bd41b3c8f8a9994060d9742bf0c2277ddbd72d53c55737\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=c03927f14ece41b0b8fbdf554c128690e2b5a6414e90905e2595360d6cbf1633\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 colorama-0.4.6 fairseq-1.0.0a0+afc77bd hydra-core-1.0.7 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ShreyAgarwal11/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding.git\n",
        "%cd /content/\n",
        "!git clone https://github.com/facebookresearch/av_hubert.git\n",
        "\n",
        "%cd av_hubert\n",
        "!git submodule init\n",
        "!git submodule update\n",
        "!pip install scipy\n",
        "!pip install sentencepiece\n",
        "!pip install python_speech_features\n",
        "!pip install scikit-video\n",
        "\n",
        "%cd fairseq\n",
        "!pip install ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data/misc/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -O /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!wget --content-disposition https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy -O /content/data/misc/20words_mean_face.npy"
      ],
      "metadata": {
        "id": "Z8VUJ4WLkHoK",
        "outputId": "b38dfe8a-c082-4c09-e3df-5d1b322a54c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-06 21:28:58--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]  61.07M  31.7MB/s    in 1.9s    \n",
            "\n",
            "2024-05-06 21:29:00 (31.7 MB/s) - ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "--2024-05-06 21:29:15--  https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy [following]\n",
            "--2024-05-06 21:29:15--  https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1168 (1.1K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/misc/20words_mean_face.npy’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]   1.14K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-05-06 21:29:15 (1.88 MB/s) - ‘/content/data/misc/20words_mean_face.npy’ saved [1168/1168]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import a pre-trained model**"
      ],
      "metadata": {
        "id": "B1Mx4qTIG1AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuned model -> Noise-Augmented AV-HuBERT Base"
      ],
      "metadata": {
        "id": "k9u9TinFIF3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%mkdir -p /content/data/\n",
        "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/avsr/base_noise_pt_noise_ft_433h.pt -O /content/data/finetune-model.pt"
      ],
      "metadata": {
        "id": "1e8mNAjvFS9U",
        "outputId": "0cc0dd47-21fa-49af-e9dd-99cead336987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/fairseq\n",
            "--2024-05-06 21:29:15--  https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/avsr/base_noise_pt_noise_ft_433h.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.173.166.74, 18.173.166.48, 18.173.166.51, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.173.166.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1928060481 (1.8G) [binary/octet-stream]\n",
            "Saving to: ‘/content/data/finetune-model.pt’\n",
            "\n",
            "/content/data/finet 100%[===================>]   1.79G  91.0MB/s    in 19s     \n",
            "\n",
            "2024-05-06 21:29:34 (96.8 MB/s) - ‘/content/data/finetune-model.pt’ saved [1928060481/1928060481]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shrey's Video frame creation"
      ],
      "metadata": {
        "id": "IRcv11EWEled"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "frame_folder = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mwbt0/video/sa1'\n",
        "\n",
        "output_video_path = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/output_video.mp4'\n",
        "\n",
        "frame_rate = 25\n",
        "\n",
        "frame_files = [f for f in os.listdir(frame_folder) if os.path.isfile(os.path.join(frame_folder, f))]\n",
        "\n",
        "frame_files.sort()\n",
        "\n",
        "video_resolution = (512, 384)\n",
        "\n",
        "if video_resolution is None:\n",
        "    first_frame_path = os.path.join(frame_folder, frame_files[0])\n",
        "    first_frame = cv2.imread(first_frame_path)\n",
        "    video_resolution = (first_frame.shape[1], first_frame.shape[0])\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, video_resolution)\n",
        "\n",
        "for frame_file in frame_files:\n",
        "    frame_path = os.path.join(frame_folder, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "    if (frame.shape[1], frame.shape[0]) != video_resolution:\n",
        "        frame = cv2.resize(frame, video_resolution)\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "91haYEVIZtYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Frame creation and Deepfake video segregation"
      ],
      "metadata": {
        "id": "vYrFJ2tuZloT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video from VidTIMIT that coincide with deepfake in folder comman_data"
      ],
      "metadata": {
        "id": "6pa-2ocfE0b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "%mkdir -p /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/\n",
        "%mkdir -p /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/"
      ],
      "metadata": {
        "id": "x-h8uaJNix4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_output_video(frame_folder, frame_rate=25, video_resolution=(512, 384)):\n",
        "    frame_files = [f for f in os.listdir(frame_folder) if os.path.isfile(os.path.join(frame_folder, f))]\n",
        "    frame_files.sort()\n",
        "\n",
        "    if video_resolution is None:\n",
        "        first_frame_path = os.path.join(frame_folder, frame_files[0])\n",
        "        first_frame = cv2.imread(first_frame_path)\n",
        "        video_resolution = (first_frame.shape[1], first_frame.shape[0])\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "\n",
        "    # Split the input path and extract the necessary components\n",
        "    parts = frame_folder.split('/')\n",
        "    speaker = parts[-3]  # Get the speaker ID (e.g., fadg0)\n",
        "    video_name = parts[-1]  # Get the video name (e.g., sa1)\n",
        "\n",
        "    # Define the output path\n",
        "    output_video_path = os.path.join('/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/', f\"{video_name}-video-{speaker}.mp4\")\n",
        "\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, video_resolution)\n",
        "\n",
        "    for frame_file in frame_files:\n",
        "        frame_path = os.path.join(frame_folder, frame_file)\n",
        "        frame = cv2.imread(frame_path)\n",
        "        if (frame.shape[1], frame.shape[0]) != video_resolution:\n",
        "            frame = cv2.resize(frame, video_resolution)\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "omNF8lSLWhP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder1 = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/DeepfakeTIMIT/higher_quality/'\n",
        "folder2 = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/'\n",
        "output_vdtimit = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/'\n",
        "\n",
        "\n",
        "# Get list of files in each folder\n",
        "files1 = os.listdir(folder1)\n",
        "files2 = os.listdir(folder2)\n",
        "\n",
        "# Extract filenames without extensions\n",
        "file_names1 = [os.path.splitext(file)[0] for file in files1]\n",
        "file_names2 = [os.path.splitext(file)[0] for file in files2]\n",
        "\n",
        "# Find common filenames\n",
        "common_file_names = set(file_names1).intersection(file_names2)\n",
        "\n",
        "# Process files with common names\n",
        "for common_name in common_file_names:\n",
        "\n",
        "    check_folder = os.path.join(folder2, common_name)\n",
        "\n",
        "    file_path2_audio = os.path.join(check_folder + '/audio')\n",
        "    try:\n",
        "        files2_in_audio = os.listdir(file_path2_audio)\n",
        "        # print(files2_in_audio)\n",
        "    except FileNotFoundError:\n",
        "        # If directory does not exist, delete it and continue to the next directory\n",
        "        shutil.rmtree(check_folder)\n",
        "        print(\"Removed dir :\",  check_folder)\n",
        "        continue\n",
        "\n",
        "    file_path1 = os.path.join(folder1, common_name)\n",
        "    file_path2 = os.path.join(folder2, common_name + '/video')\n",
        "    files1_in = os.listdir(file_path1)\n",
        "    files2_in = os.listdir(file_path2)\n",
        "\n",
        "    # Extract filenames without extensions\n",
        "    file_names1_in = [file.split('-')[0] for file in files1_in if 'video' in file]\n",
        "    # print(file_names1_in)\n",
        "    file_names2_in = [file.split('-')[0] for file in files2_in]\n",
        "    # print(file_names2_in)\n",
        "    files2_audio_in = [file.split('.')[0] for file in files2_in_audio]\n",
        "    # print(files2_audio_in)\n",
        "\n",
        "    # # Find common filenames\n",
        "    common_file_names_in = set(file_names1_in).intersection(file_names2_in)\n",
        "    # print(common_file_names_in)\n",
        "    common_audio_file = set(common_file_names_in).intersection(files2_audio_in)\n",
        "    # print(\"Printed Audio -\",common_audio_file)\n",
        "\n",
        "    for filename in common_audio_file:\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename_audio = filename + '-audio-' + common_name + '.wav'\n",
        "        # print(new_filename_audio)\n",
        "        file_path = os.path.join(output_vdtimit, new_filename_audio)\n",
        "        # print(\"New file path -\",file_path)\n",
        "        shift_path = os.path.join(check_folder + '/audio/' + filename + '.wav')\n",
        "        if os.path.exists(shift_path):\n",
        "                # print(\"Shift_path -\",shift_path)\n",
        "                shutil.copy(shift_path, file_path)\n",
        "                # print(f\"File copied successfully! '{file_path}'\")\n",
        "        else:\n",
        "          print(\"Does not exits\")\n",
        "\n",
        "    for common_name_in in common_file_names_in:\n",
        "\n",
        "      file_path1_in1 = os.path.join(file_path1, common_name_in)\n",
        "      file_path2_in2 = os.path.join(file_path2, common_name_in)\n",
        "\n",
        "      # Check if both files exist before proceeding\n",
        "\n",
        "      if os.path.exists(file_path2_in2):\n",
        "          create_output_video(file_path2_in2)\n",
        "          # Do something with the files, such as processing or using them in your code\n",
        "          # print(f\"Files with name '{common_name_in}' exist in both folders:\")\n",
        "          # print(f\"File path in folder1: {file_path1_in1}\")\n",
        "          # print(f\"File path in folder2: {file_path2_in2}\")\n",
        "          # Your code to process or use the files goes here\n",
        "      else:\n",
        "          print(f\"Files with name '{common_name_in}' do not exist in both folders.\")\n",
        "          print(f\"File path in folder1: {file_path1_in1}\")\n",
        "          print(f\"File path in folder2: {file_path2_in2}\")"
      ],
      "metadata": {
        "id": "oyOJtvRJFO4Q",
        "outputId": "02478b1a-7f35-44d7-a1e2-d092364f5d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/fcmh0\n",
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mdld0\n",
            "Removed dir : /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/VidTIMIT/mrgg0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video from DeepfakeTIMIT that coincide with VidTIMIT in folder comman_data_deep"
      ],
      "metadata": {
        "id": "2SrP046UFBLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_folder = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/DeepfakeTIMIT/higher_quality/'\n",
        "output_video_path = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/'\n",
        "\n",
        "# Get list of directories in the frame_folder\n",
        "directories = [os.path.join(frame_folder, name) for name in os.listdir(frame_folder) if os.path.isdir(os.path.join(frame_folder, name))]\n",
        "\n",
        "# Process files in each directory\n",
        "for directory in directories:\n",
        "    # Get list of files in each directory\n",
        "    files_in_directory = os.listdir(directory)\n",
        "    # print(\"directory -\", directory)\n",
        "    intial = directory.split('/')\n",
        "    speaker = intial[-1]\n",
        "    # print(intial[-1])\n",
        "\n",
        "    # Process each file\n",
        "    for filename in files_in_directory:\n",
        "\n",
        "      if filename.startswith('.'):\n",
        "          continue\n",
        "\n",
        "      if 'video' not in filename:\n",
        "        # print(filename)\n",
        "        file_path_audio = os.path.join(directory, filename)\n",
        "        # print(file_path)\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        # print(name)\n",
        "\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename_audio = name + '-audio-' + speaker + ext\n",
        "        # print(new_filename_audio)\n",
        "\n",
        "        # Construct the new path\n",
        "        new_path_audio = os.path.join(output_video_path, new_filename_audio)\n",
        "        # print(new_path_audio)\n",
        "\n",
        "        # Copy the file to the new path\n",
        "        shutil.copy(file_path_audio, new_path_audio)\n",
        "\n",
        "        # print(f\"File copied successfully! '{new_path_audio}'\")\n",
        "\n",
        "      if 'video' in filename:\n",
        "        # print(filename)\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        # print(file_path)\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        # print(name)\n",
        "\n",
        "        # Split the name into parts separated by '-'\n",
        "        parts = name.split('-')\n",
        "        # print(\"Parts -\",parts)\n",
        "\n",
        "        # Rearrange the parts to get the desired filename\n",
        "        new_filename = parts[0] + '-video-' + speaker + ext\n",
        "        # print(new_filename)\n",
        "\n",
        "        # Construct the new path\n",
        "        new_path = os.path.join(output_video_path, new_filename)\n",
        "        print(new_path)\n",
        "\n",
        "        # Copy the file to the new path\n",
        "        shutil.copy(file_path, new_path)\n",
        "\n",
        "        # print(f\"File copied successfully! '{new_path}'\")"
      ],
      "metadata": {
        "id": "EQzAaXQh_u6q",
        "outputId": "3e3556d0-dba8-4421-d511-b5f0ecd5484d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si913-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx193-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1543-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx103-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2173-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx373-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx283-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx13-video-mdld0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx410-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1490-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si860-video-fkms0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si569-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1199-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx209-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx119-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1829-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx29-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx299-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx389-video-mrgg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si824-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1454-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2084-video-fcmh0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx389-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1469-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx119-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si839-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx209-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx299-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2099-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx29-video-mccs0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx95-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx1625-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx275-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si995-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2255-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx5-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx12-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx282-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1542-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2172-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si912-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx372-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx192-video-mpdf0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1010-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2270-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx290-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx380-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1640-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx20-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx409-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx319-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx229-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx49-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1039-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1669-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2299-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx139-video-mdab0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1894-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si634-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx274-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx4-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx364-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx94-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1264-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx95-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx275-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si635-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx5-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjwb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx99-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx279-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx369-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1539-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si909-video-mgwt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx101-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx191-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx371-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si911-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx11-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1541-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2171-video-mrcz0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx188-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx278-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si548-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx98-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx8-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx368-video-fcft0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx293-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx383-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx113-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2183-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si923-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx203-video-mwbt0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1398-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx228-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si768-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx48-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx408-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx138-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2028-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx318-video-mcem0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx403-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si943-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx313-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx43-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1573-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2203-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx133-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si734-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1624-video-mrjo0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx304-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx34-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2222-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx214-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1024-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx124-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx394-video-mstk0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx19-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1909-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx379-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx199-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si649-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1279-video-fadg0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx372-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx282-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1425-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx12-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1555-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx192-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2028-video-mmdm2.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si469-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx199-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx379-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx19-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1729-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mpgl0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx205-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx385-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx295-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx25-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1825-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx1195-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si565-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx115-video-mdbb0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx188-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx98-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx368-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx8-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1988-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2247-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx278-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si728-video-mjar0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx410-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2030-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1400-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si770-video-fjas0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx190-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si522-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx370-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si730-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx100-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx10-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1899-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si639-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx369-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx279-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx99-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si869-video-msjs1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx34-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx214-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx394-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2104-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx304-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx124-video-fdac1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1746-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx126-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx36-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1587-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx396-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1566-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx14-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx194-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2149-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx374-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx284-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx36-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si756-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx126-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx396-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2016-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1386-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-felc0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1714-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx274-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx4-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx364-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1653-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx94-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1084-video-fedw0.avi\n",
            "/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fedw0.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AVHubert functions"
      ],
      "metadata": {
        "id": "7ZrRghxYFfWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/av_hubert/avhubert\n",
        "import cv2\n",
        "import tempfile\n",
        "import torch\n",
        "import utils as avhubert_utils\n",
        "from argparse import Namespace\n",
        "import fairseq\n",
        "from fairseq import checkpoint_utils, options, tasks, utils\n",
        "from IPython.display import HTML\n",
        "from python_speech_features import logfbank\n",
        "from scipy.io import wavfile"
      ],
      "metadata": {
        "id": "LjBk19NqG-X0",
        "outputId": "082b28e7-e35d-4ee4-e471-c1ed437a3f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/avhubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction using AV-HUBERT**"
      ],
      "metadata": {
        "id": "LZm64rT1hyRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stacker(feats, stack_order):\n",
        "            \"\"\"\n",
        "            Concatenating consecutive audio frames\n",
        "            Args:\n",
        "            feats - numpy.ndarray of shape [T, F]\n",
        "            stack_order - int (number of neighboring frames to concatenate\n",
        "            Returns:\n",
        "            feats - numpy.ndarray of shape [T', F']\n",
        "            \"\"\"\n",
        "            feat_dim = feats.shape[1]\n",
        "            if len(feats) % stack_order != 0:\n",
        "                res = stack_order - len(feats) % stack_order\n",
        "                res = np.zeros([res, feat_dim]).astype(feats.dtype)\n",
        "                feats = np.concatenate([feats, res], axis=0)\n",
        "            feats = feats.reshape((-1, stack_order, feat_dim)).reshape(-1, stack_order*feat_dim)\n",
        "            return feats"
      ],
      "metadata": {
        "id": "KVK2SUGkWZED"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_visual_feature(video_path, audio_path, ckpt_path, user_dir, is_finetune_ckpt=False):\n",
        "  utils.import_user_module(Namespace(user_dir=user_dir))\n",
        "  models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
        "  transform = avhubert_utils.Compose([\n",
        "      avhubert_utils.Normalize(0.0, 255.0),\n",
        "      avhubert_utils.CenterCrop((task.cfg.image_crop_size, task.cfg.image_crop_size)),\n",
        "      avhubert_utils.Normalize(task.cfg.image_mean, task.cfg.image_std)])\n",
        "  frames = avhubert_utils.load_video(video_path)\n",
        "  print(f\"Load video {video_path}: shape {frames.shape}\")\n",
        "  sample_rate, wav_data = wavfile.read(audio_path)\n",
        "  audio_features = logfbank(wav_data, sample_rate).astype(np.float32)\n",
        "  audio_features = stacker(audio_features, 4)\n",
        "  print(f\"Load audio {audio_path}: shape {audio_features.shape}\")\n",
        "  audio_features = torch.FloatTensor(audio_features).unsqueeze(dim=0).permute(0, 2, 1).cuda()\n",
        "  frames = torch.FloatTensor(frames).unsqueeze(dim=0).unsqueeze(dim=0).cuda()\n",
        "  if audio_features.shape[2] < frames.shape[2]:\n",
        "    # Pad features_audio\n",
        "    padding_size = frames.shape[2] - audio_features.shape[2]\n",
        "    padding = torch.zeros((audio_features.shape[0], audio_features.shape[1], padding_size)).cuda()\n",
        "    audio_features = torch.cat([audio_features, padding], dim=2)\n",
        "  print(f\"Load video {video_path}: shape {frames.shape}\")\n",
        "  print(f\"Load audio {audio_path}: shape {audio_features.shape}\")\n",
        "  model = models[0]\n",
        "  if hasattr(models[0], 'decoder'):\n",
        "    print(f\"Checkpoint: fine-tuned\")\n",
        "    model = models[0].encoder.w2v_model\n",
        "  else:\n",
        "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")\n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # Specify output_layer if you want to extract feature of an intermediate layer\n",
        "    layer_features = []\n",
        "    for i in range(12):\n",
        "      feature, _ = model.extract_finetune(source={'video': frames, 'audio': audio_features}, padding_mask=None, output_layer=(i+1))\n",
        "      layer_features.append(feature)\n",
        "    feature, _ = model.extract_finetune(source={'video': frames, 'audio': audio_features}, padding_mask=None, output_layer=None)\n",
        "    feature = feature.squeeze(dim=0)\n",
        "  print(f\"AvHuBert Feature shape: {feature.shape}\")\n",
        "  return layer_features, feature\n"
      ],
      "metadata": {
        "id": "C6RNFXKwIfqN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_real = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/'\n",
        "folder_path_deep = '/content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/'\n",
        "\n",
        "# Initialize an empty list to store pairs of file paths\n",
        "real_file_pairs = []\n",
        "deep_file_pairs = []\n",
        "\n",
        "# Get the list of files in the real folder\n",
        "files_real = os.listdir(folder_path_real)\n",
        "\n",
        "# Get the list of files in the deep folder\n",
        "files_deep = os.listdir(folder_path_deep)\n",
        "\n",
        "# Iterate over each file in the real folder\n",
        "for file_real in files_real:\n",
        "    # Split the filename and extension\n",
        "    name, ext_real = os.path.splitext(file_real)\n",
        "    # print(file_real)\n",
        "\n",
        "    # Check if the file is an audio file\n",
        "    if ext_real == '.wav':\n",
        "        # Construct the expected video filename\n",
        "        audio_filename_real = name\n",
        "        video_filename_real = name.replace('-audio-', '-video-')\n",
        "        # print(video_filename)\n",
        "\n",
        "        # Check if the video file exists in the deep folder\n",
        "        for file_deep in files_deep:\n",
        "            name_deep, ext_deep = os.path.splitext(file_deep)\n",
        "            # print(name_deep)\n",
        "                # Check if the file is an audio file\n",
        "            if ext_deep == '.wav':\n",
        "                # Construct the expected video filename\n",
        "                audio_filename_deep = name_deep\n",
        "                video_filename_deep = name_deep.replace('-audio-', '-video-')\n",
        "                if video_filename_deep == video_filename_real:\n",
        "                    # Construct the paths for the audio and video files in both folders\n",
        "                    audio_path_real = os.path.join(folder_path_real, audio_filename_real + ext_deep)\n",
        "                    # print(audio_path_real)\n",
        "                    video_path_real = os.path.join(folder_path_real, video_filename_real + '.mp4')\n",
        "                    audio_path_deep = os.path.join(folder_path_deep, audio_filename_deep + ext_deep)\n",
        "                    # print(audio_path_deep)\n",
        "                    video_path_deep = os.path.join(folder_path_deep, video_filename_real + '.avi')\n",
        "\n",
        "                    # Check if both audio and video files exist in both folders\n",
        "                    if os.path.exists(audio_path_real) and os.path.exists(video_path_real) and \\\n",
        "                      os.path.exists(audio_path_deep) and os.path.exists(video_path_deep):\n",
        "                        # Add the pair of paths to the list\n",
        "                        real_file_pairs.append((audio_path_real, video_path_real))\n",
        "                        deep_file_pairs.append((audio_path_deep, video_path_deep))\n",
        "\n",
        "# Print the number of file pairs found\n",
        "print(len(os.listdir(folder_path_real)))\n",
        "print(len(os.listdir(folder_path_deep)))\n",
        "print(len(real_file_pairs))\n",
        "print(len(deep_file_pairs))\n"
      ],
      "metadata": {
        "id": "QkWDR7zwuVOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8129e1-5f2d-4759-8511-113499ab2e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "580\n",
            "640\n",
            "290\n",
            "290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = \"/content/data/finetune-model.pt\"\n",
        "user_dir = \"/content/av_hubert/avhubert\"\n",
        "\n",
        "feature_real = {}\n",
        "feature_deep = {}\n",
        "\n",
        "# Counter variables to keep track of iterations\n",
        "count_real = 0\n",
        "count_deep = 0\n",
        "\n",
        "# Loop over real_file_pairs\n",
        "for pair in real_file_pairs:\n",
        "    # Increment the counter\n",
        "    count_real += 1\n",
        "\n",
        "    audio_path = pair[0]\n",
        "    mouth_roi_path = pair[1]\n",
        "    name_r, ext_r = os.path.splitext(pair[0])\n",
        "    index_data_r = name_r.split('/')[-1].replace('-audio-', '')\n",
        "\n",
        "    # Check if the index is not already in feature_real\n",
        "    if index_data_r not in feature_real:\n",
        "        layer_features, feature_real[index_data_r] = extract_visual_feature(mouth_roi_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "    # # Break after every 5 iterations\n",
        "    if count_real == 50:\n",
        "        break\n",
        "\n",
        "# Loop over deep_file_pairs\n",
        "for pair in deep_file_pairs:\n",
        "    # Increment the counter\n",
        "    count_deep += 1\n",
        "\n",
        "    audio_path = pair[0]\n",
        "    mouth_roi_path = pair[1]\n",
        "    name_d, ext_d = os.path.splitext(pair[0])\n",
        "    index_data_d = name_d.split('/')[-1].replace('-audio-', '')\n",
        "\n",
        "    # Check if the index is not already in feature_deep\n",
        "    if index_data_d not in feature_deep:\n",
        "        layer_features, feature_deep[index_data_d] = extract_visual_feature(mouth_roi_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "    # Break after every 5 iterations\n",
        "    if count_deep == 50:\n",
        "        break"
      ],
      "metadata": {
        "id": "6j5un1rYER11",
        "outputId": "90070275-5dc3-4a15-a7f1-ca22dcd0a98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-video-mrjo0.mp4: shape (138, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-audio-mrjo0.wav: shape (138, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-video-mrjo0.mp4: shape torch.Size([1, 1, 138, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1364-audio-mrjo0.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-video-fdac1.mp4: shape (137, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-audio-fdac1.wav: shape (137, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-video-fdac1.mp4: shape torch.Size([1, 1, 137, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si844-audio-fdac1.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-video-fram1.mp4: shape (114, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-audio-fram1.wav: shape (114, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-video-fram1.mp4: shape torch.Size([1, 1, 114, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1360-audio-fram1.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-video-fkms0.mp4: shape (102, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-audio-fkms0.wav: shape (102, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-video-fkms0.mp4: shape torch.Size([1, 1, 102, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx320-audio-fkms0.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-video-msjs1.mp4: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-audio-msjs1.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-video-msjs1.mp4: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx189-audio-msjs1.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-video-fjre0.mp4: shape (82, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-audio-fjre0.wav: shape (82, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-video-fjre0.mp4: shape torch.Size([1, 1, 82, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx216-audio-fjre0.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mwbt0.mp4: shape (104, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mwbt0.wav: shape (104, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mwbt0.mp4: shape torch.Size([1, 1, 104, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mwbt0.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjas0.mp4: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjas0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjas0.mp4: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjas0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-video-fjwb0.mp4: shape (123, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-audio-fjwb0.wav: shape (123, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-video-fjwb0.mp4: shape torch.Size([1, 1, 123, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1265-audio-fjwb0.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-video-mpgl0.mp4: shape (98, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-audio-mpgl0.wav: shape (98, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-video-mpgl0.mp4: shape torch.Size([1, 1, 98, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx289-audio-mpgl0.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-video-mpgl0.mp4: shape (72, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-audio-mpgl0.wav: shape (72, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-video-mpgl0.mp4: shape torch.Size([1, 1, 72, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1099-audio-mpgl0.wav: shape torch.Size([1, 104, 72])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([72, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fedw0.mp4: shape (92, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fedw0.wav: shape (92, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fedw0.mp4: shape torch.Size([1, 1, 92, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fedw0.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-video-felc0.mp4: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-audio-felc0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-video-felc0.mp4: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx306-audio-felc0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-video-faks0.mp4: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-video-faks0.mp4: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx223-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjwb0.mp4: shape (99, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjwb0.wav: shape (99, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-fjwb0.mp4: shape torch.Size([1, 1, 99, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-fjwb0.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-video-mjsw0.mp4: shape (90, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-audio-mjsw0.wav: shape (90, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-video-mjsw0.mp4: shape torch.Size([1, 1, 90, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx200-audio-mjsw0.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-video-mwbt0.mp4: shape (101, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-audio-mwbt0.wav: shape (101, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-video-mwbt0.mp4: shape torch.Size([1, 1, 101, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx23-audio-mwbt0.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-mstk0.mp4: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-mstk0.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-mstk0.mp4: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-mstk0.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-video-fjre0.mp4: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-audio-fjre0.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-video-fjre0.mp4: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1116-audio-fjre0.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-video-mgwt0.mp4: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-audio-mgwt0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-video-mgwt0.mp4: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx9-audio-mgwt0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-video-mrjo0.mp4: shape (86, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-audio-mrjo0.wav: shape (86, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-video-mrjo0.mp4: shape torch.Size([1, 1, 86, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx104-audio-mrjo0.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-video-mgwt0.mp4: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-audio-mgwt0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-video-mgwt0.mp4: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2169-audio-mgwt0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-video-mwbt0.mp4: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-audio-mwbt0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-video-mwbt0.mp4: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1553-audio-mwbt0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-msjs1.mp4: shape (121, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-msjs1.wav: shape (121, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-msjs1.mp4: shape torch.Size([1, 1, 121, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-msjs1.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-video-fkms0.mp4: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-audio-fkms0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-video-fkms0.mp4: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx230-audio-fkms0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-video-fdac1.mp4: shape (88, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-audio-fdac1.wav: shape (88, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-video-fdac1.mp4: shape torch.Size([1, 1, 88, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1474-audio-fdac1.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mgwt0.mp4: shape (125, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mgwt0.wav: shape (125, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mgwt0.mp4: shape torch.Size([1, 1, 125, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mgwt0.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-video-fkms0.mp4: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-video-fkms0.mp4: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx140-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-video-mpgl0.mp4: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-audio-mpgl0.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-video-mpgl0.mp4: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx109-audio-mpgl0.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fram1.mp4: shape (117, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fram1.wav: shape (117, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fram1.mp4: shape torch.Size([1, 1, 117, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fram1.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-video-fdrd1.mp4: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-audio-fdrd1.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-video-fdrd1.mp4: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1544-audio-fdrd1.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-video-mrcz0.mp4: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-audio-mrcz0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-video-mrcz0.mp4: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx281-audio-mrcz0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-video-mmdm2.mp4: shape (116, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-audio-mmdm2.wav: shape (116, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-video-mmdm2.mp4: shape torch.Size([1, 1, 116, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx102-audio-mmdm2.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-video-mmdb1.mp4: shape (97, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-audio-mmdb1.wav: shape (97, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-video-mmdb1.mp4: shape torch.Size([1, 1, 97, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx185-audio-mmdb1.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-video-fjem0.mp4: shape (155, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-audio-fjem0.wav: shape (155, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-video-fjem0.mp4: shape torch.Size([1, 1, 155, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx184-audio-fjem0.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-video-mmdb1.mp4: shape (128, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-audio-mmdb1.wav: shape (128, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-video-mmdb1.mp4: shape torch.Size([1, 1, 128, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx365-audio-mmdb1.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fdac1.mp4: shape (95, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fdac1.wav: shape (95, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-fdac1.mp4: shape torch.Size([1, 1, 95, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-fdac1.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mjar0.mp4: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mjar0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mjar0.mp4: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mjar0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-faks0.mp4: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-faks0.mp4: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-video-mjsw0.mp4: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-audio-mjsw0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-video-mjsw0.mp4: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx110-audio-mjsw0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-faks0.mp4: shape (81, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-faks0.wav: shape (81, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-video-faks0.mp4: shape torch.Size([1, 1, 81, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa2-audio-faks0.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-video-fjwb0.mp4: shape (182, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-audio-fjwb0.wav: shape (182, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-video-fjwb0.mp4: shape torch.Size([1, 1, 182, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si992-audio-fjwb0.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-video-fram1.mp4: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-audio-fram1.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-video-fram1.mp4: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx280-audio-fram1.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-video-fkms0.mp4: shape (106, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-audio-fkms0.wav: shape (106, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-video-fkms0.mp4: shape torch.Size([1, 1, 106, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2120-audio-fkms0.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-video-fcft0.mp4: shape (112, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-audio-fcft0.wav: shape (112, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-video-fcft0.mp4: shape torch.Size([1, 1, 112, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1808-audio-fcft0.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-video-fcft0.mp4: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-audio-fcft0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-video-fcft0.mp4: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si1178-audio-fcft0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mdab0.mp4: shape (149, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mdab0.wav: shape (149, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mdab0.mp4: shape torch.Size([1, 1, 149, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mdab0.wav: shape torch.Size([1, 104, 149])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([149, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mstk0.mp4: shape (93, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mstk0.wav: shape (93, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-video-mstk0.mp4: shape torch.Size([1, 1, 93, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sa1-audio-mstk0.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-video-mstk0.mp4: shape (69, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-audio-mstk0.wav: shape (69, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-video-mstk0.mp4: shape torch.Size([1, 1, 69, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/si2284-audio-mstk0.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-video-fkms0.mp4: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-video-fkms0.mp4: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data/sx50-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi: shape (138, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-audio-mrjo0.wav: shape (138, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-video-mrjo0.avi: shape torch.Size([1, 1, 138, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1364-audio-mrjo0.wav: shape torch.Size([1, 104, 138])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([138, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi: shape (137, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-audio-fdac1.wav: shape (137, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-video-fdac1.avi: shape torch.Size([1, 1, 137, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si844-audio-fdac1.wav: shape torch.Size([1, 104, 137])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([137, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-audio-fram1.wav: shape (114, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-video-fram1.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1360-audio-fram1.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi: shape (102, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-audio-fkms0.wav: shape (102, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-video-fkms0.avi: shape torch.Size([1, 1, 102, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx320-audio-fkms0.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-audio-msjs1.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-video-msjs1.avi: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx189-audio-msjs1.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi: shape (82, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-audio-fjre0.wav: shape (82, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-video-fjre0.avi: shape torch.Size([1, 1, 82, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx216-audio-fjre0.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi: shape (104, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mwbt0.wav: shape (104, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mwbt0.avi: shape torch.Size([1, 1, 104, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mwbt0.wav: shape torch.Size([1, 104, 104])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([104, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjas0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjas0.avi: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjas0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi: shape (123, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-audio-fjwb0.wav: shape (123, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-video-fjwb0.avi: shape torch.Size([1, 1, 123, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1265-audio-fjwb0.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi: shape (98, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-audio-mpgl0.wav: shape (98, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-video-mpgl0.avi: shape torch.Size([1, 1, 98, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx289-audio-mpgl0.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi: shape (72, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-audio-mpgl0.wav: shape (72, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-video-mpgl0.avi: shape torch.Size([1, 1, 72, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1099-audio-mpgl0.wav: shape torch.Size([1, 104, 72])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([72, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi: shape (92, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fedw0.wav: shape (92, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fedw0.avi: shape torch.Size([1, 1, 92, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fedw0.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-audio-felc0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-video-felc0.avi: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx306-audio-felc0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-video-faks0.avi: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx223-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi: shape (99, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjwb0.wav: shape (99, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-fjwb0.avi: shape torch.Size([1, 1, 99, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-fjwb0.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi: shape (90, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-audio-mjsw0.wav: shape (90, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-video-mjsw0.avi: shape torch.Size([1, 1, 90, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx200-audio-mjsw0.wav: shape torch.Size([1, 104, 90])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([90, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi: shape (101, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-audio-mwbt0.wav: shape (101, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-video-mwbt0.avi: shape torch.Size([1, 1, 101, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx23-audio-mwbt0.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-mstk0.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-mstk0.avi: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-mstk0.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-audio-fjre0.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-video-fjre0.avi: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1116-audio-fjre0.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi: shape (80, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-audio-mgwt0.wav: shape (80, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-video-mgwt0.avi: shape torch.Size([1, 1, 80, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx9-audio-mgwt0.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi: shape (86, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-audio-mrjo0.wav: shape (86, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-video-mrjo0.avi: shape torch.Size([1, 1, 86, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx104-audio-mrjo0.wav: shape torch.Size([1, 104, 86])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([86, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-audio-mgwt0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-video-mgwt0.avi: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2169-audio-mgwt0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-audio-mwbt0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-video-mwbt0.avi: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1553-audio-mwbt0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi: shape (121, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-msjs1.wav: shape (121, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-msjs1.avi: shape torch.Size([1, 1, 121, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-msjs1.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-audio-fkms0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-video-fkms0.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx230-audio-fkms0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi: shape (88, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-audio-fdac1.wav: shape (88, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-video-fdac1.avi: shape torch.Size([1, 1, 88, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1474-audio-fdac1.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi: shape (125, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mgwt0.wav: shape (125, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mgwt0.avi: shape torch.Size([1, 1, 125, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mgwt0.wav: shape torch.Size([1, 104, 125])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([125, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-video-fkms0.avi: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx140-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi: shape (110, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-audio-mpgl0.wav: shape (110, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-video-mpgl0.avi: shape torch.Size([1, 1, 110, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx109-audio-mpgl0.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi: shape (117, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fram1.wav: shape (117, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fram1.avi: shape torch.Size([1, 1, 117, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fram1.wav: shape torch.Size([1, 104, 117])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([117, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi: shape (87, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-audio-fdrd1.wav: shape (87, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-video-fdrd1.avi: shape torch.Size([1, 1, 87, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1544-audio-fdrd1.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi: shape (115, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-audio-mrcz0.wav: shape (115, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-video-mrcz0.avi: shape torch.Size([1, 1, 115, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx281-audio-mrcz0.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi: shape (116, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-audio-mmdm2.wav: shape (116, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-video-mmdm2.avi: shape torch.Size([1, 1, 116, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx102-audio-mmdm2.wav: shape torch.Size([1, 104, 116])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([116, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi: shape (97, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-audio-mmdb1.wav: shape (97, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-video-mmdb1.avi: shape torch.Size([1, 1, 97, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx185-audio-mmdb1.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi: shape (155, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-audio-fjem0.wav: shape (155, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-video-fjem0.avi: shape torch.Size([1, 1, 155, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx184-audio-fjem0.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi: shape (128, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-audio-mmdb1.wav: shape (128, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-video-mmdb1.avi: shape torch.Size([1, 1, 128, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx365-audio-mmdb1.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi: shape (95, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fdac1.wav: shape (95, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-fdac1.avi: shape torch.Size([1, 1, 95, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-fdac1.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi: shape (150, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mjar0.wav: shape (150, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mjar0.avi: shape torch.Size([1, 1, 150, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mjar0.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi: shape (89, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-faks0.wav: shape (89, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-faks0.avi: shape torch.Size([1, 1, 89, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-faks0.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi: shape (83, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-audio-mjsw0.wav: shape (83, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-video-mjsw0.avi: shape torch.Size([1, 1, 83, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx110-audio-mjsw0.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi: shape (81, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-faks0.wav: shape (81, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-video-faks0.avi: shape torch.Size([1, 1, 81, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa2-audio-faks0.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi: shape (182, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-audio-fjwb0.wav: shape (182, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-video-fjwb0.avi: shape torch.Size([1, 1, 182, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si992-audio-fjwb0.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi: shape (85, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-audio-fram1.wav: shape (85, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-video-fram1.avi: shape torch.Size([1, 1, 85, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx280-audio-fram1.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi: shape (106, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-audio-fkms0.wav: shape (106, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-video-fkms0.avi: shape torch.Size([1, 1, 106, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2120-audio-fkms0.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi: shape (113, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-audio-fcft0.wav: shape (112, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-video-fcft0.avi: shape torch.Size([1, 1, 113, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1808-audio-fcft0.wav: shape torch.Size([1, 104, 113])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([113, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi: shape (136, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-audio-fcft0.wav: shape (136, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-video-fcft0.avi: shape torch.Size([1, 1, 136, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si1178-audio-fcft0.wav: shape torch.Size([1, 104, 136])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([136, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi: shape (149, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mdab0.wav: shape (149, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mdab0.avi: shape torch.Size([1, 1, 149, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mdab0.wav: shape torch.Size([1, 104, 149])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([149, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi: shape (93, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mstk0.wav: shape (93, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-video-mstk0.avi: shape torch.Size([1, 1, 93, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sa1-audio-mstk0.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi: shape (69, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-audio-mstk0.wav: shape (69, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-video-mstk0.avi: shape torch.Size([1, 1, 69, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/si2284-audio-mstk0.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi: shape (109, 384, 512)\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-audio-fkms0.wav: shape (109, 104)\n",
            "Load video /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-video-fkms0.avi: shape torch.Size([1, 1, 109, 384, 512])\n",
            "Load audio /content/Privacy-Preserving-Representation-for-Audio-Visual-Speech-Understanding/comman_data_deep/sx50-audio-fkms0.wav: shape torch.Size([1, 104, 109])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([109, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_real"
      ],
      "metadata": {
        "id": "AkbrG_-FsY5B",
        "outputId": "4e9570bf-879f-4ecc-8e2f-14c8501dc351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'si1364mrjo0': tensor([[ 0.0337, -0.1497, -0.0243,  ...,  0.2315,  0.0290,  0.1629],\n",
              "         [ 0.1824, -0.0650, -0.0055,  ..., -0.1429,  0.1406,  0.1006],\n",
              "         [ 0.1506, -0.0165,  0.0294,  ..., -0.2116,  0.1907, -0.0434],\n",
              "         ...,\n",
              "         [-0.0669,  0.0628,  0.3312,  ..., -0.1542, -0.0586, -0.0743],\n",
              "         [-0.1628,  0.0195,  0.3841,  ..., -0.0440,  0.0142, -0.0896],\n",
              "         [-0.1855,  0.0034,  0.3307,  ...,  0.1063,  0.0212, -0.1072]],\n",
              "        device='cuda:0'),\n",
              " 'si844fdac1': tensor([[ 0.0372, -0.1600, -0.0227,  ...,  0.2216,  0.0322,  0.1591],\n",
              "         [ 0.1889, -0.0792, -0.0043,  ..., -0.1479,  0.1435,  0.0944],\n",
              "         [ 0.1673, -0.0344,  0.0250,  ..., -0.2216,  0.1901, -0.0467],\n",
              "         ...,\n",
              "         [-0.0475,  0.0446,  0.3250,  ..., -0.1681, -0.0527, -0.0792],\n",
              "         [-0.1483,  0.0048,  0.3779,  ..., -0.0552,  0.0187, -0.0937],\n",
              "         [-0.1741, -0.0109,  0.3278,  ...,  0.0910,  0.0260, -0.1122]],\n",
              "        device='cuda:0'),\n",
              " 'si1360fram1': tensor([[ 0.0072, -0.1443, -0.0176,  ...,  0.2343,  0.0249,  0.1746],\n",
              "         [ 0.1128, -0.0520,  0.0250,  ..., -0.1086,  0.1449,  0.0915],\n",
              "         [ 0.0819, -0.0033,  0.0516,  ..., -0.1755,  0.2143, -0.0359],\n",
              "         ...,\n",
              "         [-0.1347,  0.0525,  0.3527,  ..., -0.1316, -0.0646, -0.0771],\n",
              "         [-0.2172,  0.0200,  0.4000,  ..., -0.0223,  0.0024, -0.0948],\n",
              "         [-0.2141,  0.0228,  0.3412,  ...,  0.1099,  0.0125, -0.1113]],\n",
              "        device='cuda:0'),\n",
              " 'sx320fkms0': tensor([[ 0.0043, -0.1467, -0.0145,  ...,  0.2350,  0.0253,  0.1789],\n",
              "         [ 0.1053, -0.0555,  0.0263,  ..., -0.1069,  0.1434,  0.0925],\n",
              "         [ 0.0755, -0.0106,  0.0526,  ..., -0.1696,  0.2176, -0.0276],\n",
              "         ...,\n",
              "         [-0.1449,  0.0434,  0.3575,  ..., -0.1262, -0.0627, -0.0716],\n",
              "         [-0.2193,  0.0163,  0.4002,  ..., -0.0195, -0.0012, -0.0921],\n",
              "         [-0.2154,  0.0206,  0.3437,  ...,  0.1059,  0.0113, -0.1087]],\n",
              "        device='cuda:0'),\n",
              " 'sx189msjs1': tensor([[ 0.0073, -0.1462, -0.0172,  ...,  0.2339,  0.0259,  0.1749],\n",
              "         [ 0.1164, -0.0526,  0.0255,  ..., -0.1054,  0.1460,  0.0934],\n",
              "         [ 0.0841, -0.0058,  0.0518,  ..., -0.1719,  0.2144, -0.0297],\n",
              "         ...,\n",
              "         [-0.1339,  0.0520,  0.3575,  ..., -0.1268, -0.0617, -0.0753],\n",
              "         [-0.2142,  0.0194,  0.4013,  ..., -0.0187,  0.0036, -0.0943],\n",
              "         [-0.2130,  0.0214,  0.3415,  ...,  0.1103,  0.0151, -0.1123]],\n",
              "        device='cuda:0'),\n",
              " 'sx216fjre0': tensor([[-0.0231, -0.1300, -0.0133,  ...,  0.2515,  0.0321,  0.1874],\n",
              "         [ 0.0805, -0.0770,  0.0007,  ..., -0.1145,  0.1688,  0.1001],\n",
              "         [ 0.0564, -0.0450,  0.0237,  ..., -0.1578,  0.2528, -0.0095],\n",
              "         ...,\n",
              "         [-0.1780,  0.0075,  0.3169,  ..., -0.1198, -0.0118, -0.0391],\n",
              "         [-0.2610, -0.0017,  0.3806,  ..., -0.0011,  0.0166, -0.0714],\n",
              "         [-0.2458,  0.0212,  0.3312,  ...,  0.1370,  0.0110, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mwbt0': tensor([[ 0.0039, -0.1435, -0.0142,  ...,  0.2401,  0.0269,  0.1794],\n",
              "         [ 0.1137, -0.0542,  0.0234,  ..., -0.1071,  0.1480,  0.0953],\n",
              "         [ 0.0819, -0.0101,  0.0506,  ..., -0.1676,  0.2249, -0.0256],\n",
              "         ...,\n",
              "         [-0.1467,  0.0447,  0.3564,  ..., -0.1232, -0.0552, -0.0701],\n",
              "         [-0.2228,  0.0163,  0.3984,  ..., -0.0144,  0.0051, -0.0914],\n",
              "         [-0.2210,  0.0221,  0.3417,  ...,  0.1137,  0.0125, -0.1075]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjas0': tensor([[-0.0228, -0.1282, -0.0134,  ...,  0.2526,  0.0328,  0.1881],\n",
              "         [ 0.0863, -0.0750,  0.0033,  ..., -0.1139,  0.1672,  0.1024],\n",
              "         [ 0.0622, -0.0422,  0.0269,  ..., -0.1575,  0.2518, -0.0062],\n",
              "         ...,\n",
              "         [-0.1783,  0.0096,  0.3180,  ..., -0.1156, -0.0099, -0.0376],\n",
              "         [-0.2621,  0.0028,  0.3819,  ...,  0.0036,  0.0165, -0.0723],\n",
              "         [-0.2488,  0.0257,  0.3320,  ...,  0.1455,  0.0125, -0.0875]],\n",
              "        device='cuda:0'),\n",
              " 'si1265fjwb0': tensor([[ 0.0141, -0.1428, -0.0217,  ...,  0.2342,  0.0244,  0.1698],\n",
              "         [ 0.1297, -0.0460,  0.0175,  ..., -0.1117,  0.1411,  0.0958],\n",
              "         [ 0.0944,  0.0059,  0.0498,  ..., -0.1780,  0.2037, -0.0392],\n",
              "         ...,\n",
              "         [-0.1180,  0.0671,  0.3516,  ..., -0.1309, -0.0684, -0.0763],\n",
              "         [-0.2057,  0.0284,  0.4017,  ..., -0.0255,  0.0017, -0.0923],\n",
              "         [-0.2078,  0.0242,  0.3402,  ...,  0.1092,  0.0144, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx289mpgl0': tensor([[ 0.0091, -0.1472, -0.0139,  ...,  0.2412,  0.0297,  0.1820],\n",
              "         [ 0.1253, -0.0425,  0.0244,  ..., -0.0961,  0.1475,  0.1031],\n",
              "         [ 0.0838,  0.0024,  0.0587,  ..., -0.1476,  0.2263, -0.0181],\n",
              "         ...,\n",
              "         [-0.1254,  0.0581,  0.3635,  ..., -0.1057, -0.0637, -0.0620],\n",
              "         [-0.2037,  0.0297,  0.4090,  ..., -0.0036,  0.0025, -0.0869],\n",
              "         [-0.2093,  0.0301,  0.3528,  ...,  0.1138,  0.0200, -0.1104]],\n",
              "        device='cuda:0'),\n",
              " 'si1099mpgl0': tensor([[-0.0186, -0.1369, -0.0121,  ...,  0.2543,  0.0388,  0.1961],\n",
              "         [ 0.0951, -0.0746, -0.0009,  ..., -0.1204,  0.1830,  0.1259],\n",
              "         [ 0.0627, -0.0512,  0.0245,  ..., -0.1554,  0.2666,  0.0121],\n",
              "         ...,\n",
              "         [-0.1634,  0.0064,  0.3123,  ..., -0.1153, -0.0189, -0.0218],\n",
              "         [-0.2512,  0.0022,  0.3781,  ..., -0.0008,  0.0212, -0.0631],\n",
              "         [-0.2526,  0.0166,  0.3380,  ...,  0.1396,  0.0252, -0.0845]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fedw0': tensor([[-0.0159, -0.1243, -0.0121,  ...,  0.2576,  0.0311,  0.1828],\n",
              "         [ 0.0940, -0.0663,  0.0100,  ..., -0.1000,  0.1616,  0.0936],\n",
              "         [ 0.0694, -0.0253,  0.0391,  ..., -0.1477,  0.2515, -0.0189],\n",
              "         ...,\n",
              "         [-0.1754,  0.0226,  0.3289,  ..., -0.1140, -0.0240, -0.0498],\n",
              "         [-0.2544,  0.0087,  0.3896,  ...,  0.0032,  0.0102, -0.0778],\n",
              "         [-0.2409,  0.0304,  0.3369,  ...,  0.1420,  0.0090, -0.0946]],\n",
              "        device='cuda:0'),\n",
              " 'sx306felc0': tensor([[-0.0230, -0.1318, -0.0134,  ...,  0.2511,  0.0324,  0.1886],\n",
              "         [ 0.0821, -0.0792,  0.0004,  ..., -0.1165,  0.1715,  0.1039],\n",
              "         [ 0.0571, -0.0495,  0.0221,  ..., -0.1593,  0.2543, -0.0052],\n",
              "         ...,\n",
              "         [-0.1783,  0.0068,  0.3163,  ..., -0.1184, -0.0096, -0.0371],\n",
              "         [-0.2611, -0.0022,  0.3793,  ..., -0.0020,  0.0187, -0.0710],\n",
              "         [-0.2485,  0.0195,  0.3311,  ...,  0.1379,  0.0142, -0.0877]],\n",
              "        device='cuda:0'),\n",
              " 'sx223faks0': tensor([[-0.0198, -0.1216, -0.0138,  ...,  0.2569,  0.0346,  0.1875],\n",
              "         [ 0.0946, -0.0660,  0.0030,  ..., -0.1066,  0.1677,  0.0958],\n",
              "         [ 0.0709, -0.0275,  0.0338,  ..., -0.1508,  0.2570, -0.0169],\n",
              "         ...,\n",
              "         [-0.1764,  0.0195,  0.3217,  ..., -0.1083, -0.0122, -0.0469],\n",
              "         [-0.2584,  0.0097,  0.3857,  ...,  0.0078,  0.0144, -0.0763],\n",
              "         [-0.2453,  0.0337,  0.3332,  ...,  0.1524,  0.0100, -0.0880]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjwb0': tensor([[ 0.0014, -0.1457, -0.0121,  ...,  0.2378,  0.0261,  0.1801],\n",
              "         [ 0.1052, -0.0560,  0.0262,  ..., -0.1053,  0.1472,  0.0952],\n",
              "         [ 0.0755, -0.0118,  0.0525,  ..., -0.1633,  0.2234, -0.0224],\n",
              "         ...,\n",
              "         [-0.1497,  0.0418,  0.3587,  ..., -0.1237, -0.0549, -0.0682],\n",
              "         [-0.2238,  0.0164,  0.4016,  ..., -0.0134,  0.0036, -0.0915],\n",
              "         [-0.2197,  0.0221,  0.3468,  ...,  0.1102,  0.0137, -0.1092]],\n",
              "        device='cuda:0'),\n",
              " 'sx200mjsw0': tensor([[-2.0566e-02, -1.2432e-01, -1.3577e-02,  ...,  2.5526e-01,\n",
              "           2.9607e-02,  1.8338e-01],\n",
              "         [ 8.5371e-02, -7.2390e-02,  8.2970e-03,  ..., -1.0220e-01,\n",
              "           1.6294e-01,  9.3353e-02],\n",
              "         [ 6.5961e-02, -3.3431e-02,  3.3400e-02,  ..., -1.5043e-01,\n",
              "           2.4809e-01, -1.6579e-02],\n",
              "         ...,\n",
              "         [-1.7590e-01,  1.7300e-02,  3.2030e-01,  ..., -1.2037e-01,\n",
              "          -1.7848e-02, -4.6448e-02],\n",
              "         [-2.5933e-01,  5.5850e-03,  3.8638e-01,  ...,  1.4496e-04,\n",
              "           1.0303e-02, -7.5431e-02],\n",
              "         [-2.4106e-01,  3.0342e-02,  3.3469e-01,  ...,  1.4170e-01,\n",
              "           7.1860e-03, -9.2562e-02]], device='cuda:0'),\n",
              " 'sx23mwbt0': tensor([[ 0.0025, -0.1439, -0.0123,  ...,  0.2402,  0.0273,  0.1814],\n",
              "         [ 0.1076, -0.0529,  0.0255,  ..., -0.1038,  0.1501,  0.0953],\n",
              "         [ 0.0778, -0.0080,  0.0524,  ..., -0.1622,  0.2277, -0.0226],\n",
              "         ...,\n",
              "         [-0.1494,  0.0452,  0.3583,  ..., -0.1193, -0.0559, -0.0675],\n",
              "         [-0.2243,  0.0191,  0.4006,  ..., -0.0101,  0.0037, -0.0907],\n",
              "         [-0.2220,  0.0256,  0.3449,  ...,  0.1151,  0.0124, -0.1069]],\n",
              "        device='cuda:0'),\n",
              " 'sa2mstk0': tensor([[-0.0211, -0.1248, -0.0130,  ...,  0.2558,  0.0336,  0.1869],\n",
              "         [ 0.0907, -0.0702,  0.0030,  ..., -0.1069,  0.1693,  0.0951],\n",
              "         [ 0.0679, -0.0337,  0.0314,  ..., -0.1502,  0.2568, -0.0152],\n",
              "         ...,\n",
              "         [-0.1768,  0.0129,  0.3190,  ..., -0.1128, -0.0107, -0.0433],\n",
              "         [-0.2592,  0.0036,  0.3837,  ...,  0.0052,  0.0164, -0.0740],\n",
              "         [-0.2457,  0.0303,  0.3320,  ...,  0.1474,  0.0099, -0.0883]],\n",
              "        device='cuda:0'),\n",
              " 'si1116fjre0': tensor([[-2.2373e-02, -1.2633e-01, -1.4098e-02,  ...,  2.5344e-01,\n",
              "           3.2464e-02,  1.8662e-01],\n",
              "         [ 8.4849e-02, -7.4590e-02,  1.6153e-03,  ..., -1.1096e-01,\n",
              "           1.6800e-01,  9.7663e-02],\n",
              "         [ 6.1451e-02, -4.0138e-02,  2.6897e-02,  ..., -1.5533e-01,\n",
              "           2.5327e-01, -1.1467e-02],\n",
              "         ...,\n",
              "         [-1.7874e-01,  1.2468e-02,  3.1842e-01,  ..., -1.1770e-01,\n",
              "          -9.5204e-03, -4.1744e-02],\n",
              "         [-2.6057e-01,  2.8049e-03,  3.8228e-01,  ..., -1.7838e-04,\n",
              "           1.6679e-02, -7.1759e-02],\n",
              "         [-2.4418e-01,  2.4986e-02,  3.3159e-01,  ...,  1.4010e-01,\n",
              "           1.0695e-02, -8.9632e-02]], device='cuda:0'),\n",
              " 'sx9mgwt0': tensor([[-0.0214, -0.1309, -0.0114,  ...,  0.2514,  0.0360,  0.1900],\n",
              "         [ 0.0898, -0.0733,  0.0032,  ..., -0.1140,  0.1782,  0.1056],\n",
              "         [ 0.0645, -0.0435,  0.0266,  ..., -0.1557,  0.2635, -0.0037],\n",
              "         ...,\n",
              "         [-0.1762,  0.0087,  0.3198,  ..., -0.1089, -0.0044, -0.0383],\n",
              "         [-0.2592,  0.0020,  0.3801,  ...,  0.0061,  0.0232, -0.0721],\n",
              "         [-0.2493,  0.0244,  0.3318,  ...,  0.1488,  0.0175, -0.0859]],\n",
              "        device='cuda:0'),\n",
              " 'sx104mrjo0': tensor([[-0.0209, -0.1245, -0.0134,  ...,  0.2543,  0.0339,  0.1876],\n",
              "         [ 0.0898, -0.0705,  0.0030,  ..., -0.1103,  0.1670,  0.0977],\n",
              "         [ 0.0675, -0.0334,  0.0315,  ..., -0.1537,  0.2549, -0.0150],\n",
              "         ...,\n",
              "         [-0.1774,  0.0134,  0.3200,  ..., -0.1134, -0.0119, -0.0443],\n",
              "         [-0.2589,  0.0043,  0.3837,  ...,  0.0036,  0.0148, -0.0749],\n",
              "         [-0.2459,  0.0297,  0.3325,  ...,  0.1470,  0.0103, -0.0886]],\n",
              "        device='cuda:0'),\n",
              " 'si2169mgwt0': tensor([[ 0.0336, -0.1531, -0.0254,  ...,  0.2263,  0.0281,  0.1603],\n",
              "         [ 0.1838, -0.0674, -0.0029,  ..., -0.1395,  0.1383,  0.0999],\n",
              "         [ 0.1569, -0.0172,  0.0318,  ..., -0.2119,  0.1815, -0.0405],\n",
              "         ...,\n",
              "         [-0.0598,  0.0635,  0.3335,  ..., -0.1544, -0.0612, -0.0745],\n",
              "         [-0.1578,  0.0195,  0.3855,  ..., -0.0457,  0.0113, -0.0903],\n",
              "         [-0.1800,  0.0007,  0.3317,  ...,  0.0994,  0.0243, -0.1105]],\n",
              "        device='cuda:0'),\n",
              " 'si1553mwbt0': tensor([[ 6.1505e-02, -1.8270e-01, -2.2577e-02,  ...,  2.0218e-01,\n",
              "           4.1628e-02,  1.4101e-01],\n",
              "         [ 2.3370e-01, -1.0931e-01, -2.6595e-02,  ..., -1.7940e-01,\n",
              "           1.5029e-01,  8.2723e-02],\n",
              "         [ 2.1353e-01, -7.0665e-02,  6.1105e-03,  ..., -2.4896e-01,\n",
              "           1.8864e-01, -6.0677e-02],\n",
              "         ...,\n",
              "         [ 6.7605e-03,  2.2074e-04,  2.9472e-01,  ..., -1.9426e-01,\n",
              "          -1.9625e-02, -9.0448e-02],\n",
              "         [-1.0311e-01, -2.8520e-02,  3.5607e-01,  ..., -8.0391e-02,\n",
              "           3.5491e-02, -1.0273e-01],\n",
              "         [-1.3965e-01, -5.1976e-02,  3.1431e-01,  ...,  6.6258e-02,\n",
              "           4.4224e-02, -1.2452e-01]], device='cuda:0'),\n",
              " 'sa2msjs1': tensor([[ 1.4235e-02, -1.4513e-01, -2.1532e-02,  ...,  2.3095e-01,\n",
              "           2.5181e-02,  1.6905e-01],\n",
              "         [ 1.2928e-01, -4.6622e-02,  1.9454e-02,  ..., -1.0818e-01,\n",
              "           1.4347e-01,  9.6025e-02],\n",
              "         [ 9.5176e-02,  6.3880e-03,  5.1152e-02,  ..., -1.7624e-01,\n",
              "           2.0259e-01, -3.6020e-02],\n",
              "         ...,\n",
              "         [-1.1317e-01,  7.3411e-02,  3.5462e-01,  ..., -1.2877e-01,\n",
              "          -7.1437e-02, -7.5461e-02],\n",
              "         [-2.0168e-01,  3.3741e-02,  4.0441e-01,  ..., -2.5533e-02,\n",
              "           3.2468e-04, -9.1011e-02],\n",
              "         [-2.0372e-01,  2.4952e-02,  3.4008e-01,  ...,  1.0835e-01,\n",
              "           1.7668e-02, -1.1255e-01]], device='cuda:0'),\n",
              " 'sx230fkms0': tensor([[ 0.0099, -0.1432, -0.0189,  ...,  0.2350,  0.0241,  0.1734],\n",
              "         [ 0.1157, -0.0471,  0.0227,  ..., -0.1075,  0.1401,  0.0927],\n",
              "         [ 0.0787,  0.0032,  0.0529,  ..., -0.1737,  0.2096, -0.0391],\n",
              "         ...,\n",
              "         [-0.1323,  0.0580,  0.3581,  ..., -0.1272, -0.0680, -0.0772],\n",
              "         [-0.2130,  0.0245,  0.4033,  ..., -0.0235, -0.0026, -0.0933],\n",
              "         [-0.2112,  0.0247,  0.3416,  ...,  0.1081,  0.0125, -0.1114]],\n",
              "        device='cuda:0'),\n",
              " 'si1474fdac1': tensor([[-0.0223, -0.1241, -0.0143,  ...,  0.2549,  0.0315,  0.1851],\n",
              "         [ 0.0852, -0.0735,  0.0039,  ..., -0.1076,  0.1661,  0.0936],\n",
              "         [ 0.0636, -0.0357,  0.0295,  ..., -0.1536,  0.2516, -0.0161],\n",
              "         ...,\n",
              "         [-0.1792,  0.0141,  0.3181,  ..., -0.1202, -0.0127, -0.0437],\n",
              "         [-0.2618,  0.0035,  0.3835,  ...,  0.0013,  0.0143, -0.0738],\n",
              "         [-0.2431,  0.0288,  0.3322,  ...,  0.1423,  0.0074, -0.0901]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mgwt0': tensor([[ 0.0157, -0.1426, -0.0225,  ...,  0.2340,  0.0251,  0.1705],\n",
              "         [ 0.1358, -0.0458,  0.0164,  ..., -0.1124,  0.1431,  0.0963],\n",
              "         [ 0.1002,  0.0073,  0.0487,  ..., -0.1790,  0.2041, -0.0384],\n",
              "         ...,\n",
              "         [-0.1153,  0.0727,  0.3511,  ..., -0.1286, -0.0679, -0.0758],\n",
              "         [-0.2035,  0.0304,  0.3997,  ..., -0.0248,  0.0038, -0.0912],\n",
              "         [-0.2067,  0.0258,  0.3377,  ...,  0.1121,  0.0160, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx140fkms0': tensor([[ 0.0077, -0.1453, -0.0176,  ...,  0.2353,  0.0241,  0.1758],\n",
              "         [ 0.1138, -0.0524,  0.0235,  ..., -0.1104,  0.1378,  0.0935],\n",
              "         [ 0.0793, -0.0042,  0.0529,  ..., -0.1748,  0.2106, -0.0350],\n",
              "         ...,\n",
              "         [-0.1374,  0.0492,  0.3580,  ..., -0.1281, -0.0658, -0.0750],\n",
              "         [-0.2139,  0.0186,  0.4009,  ..., -0.0234, -0.0023, -0.0930],\n",
              "         [-0.2123,  0.0201,  0.3418,  ...,  0.1057,  0.0116, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx109mpgl0': tensor([[ 0.0125, -0.1453, -0.0172,  ...,  0.2368,  0.0287,  0.1775],\n",
              "         [ 0.1243, -0.0357,  0.0251,  ..., -0.0919,  0.1434,  0.1002],\n",
              "         [ 0.0819,  0.0137,  0.0616,  ..., -0.1489,  0.2137, -0.0226],\n",
              "         ...,\n",
              "         [-0.1216,  0.0779,  0.3657,  ..., -0.1059, -0.0737, -0.0661],\n",
              "         [-0.2051,  0.0424,  0.4145,  ..., -0.0041, -0.0017, -0.0865],\n",
              "         [-0.2074,  0.0359,  0.3505,  ...,  0.1167,  0.0193, -0.1128]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fram1': tensor([[ 0.0096, -0.1445, -0.0188,  ...,  0.2341,  0.0255,  0.1731],\n",
              "         [ 0.1209, -0.0516,  0.0236,  ..., -0.1100,  0.1445,  0.0923],\n",
              "         [ 0.0881, -0.0040,  0.0508,  ..., -0.1765,  0.2108, -0.0340],\n",
              "         ...,\n",
              "         [-0.1282,  0.0568,  0.3528,  ..., -0.1327, -0.0645, -0.0769],\n",
              "         [-0.2121,  0.0227,  0.4002,  ..., -0.0256,  0.0025, -0.0935],\n",
              "         [-0.2117,  0.0225,  0.3407,  ...,  0.1086,  0.0131, -0.1112]],\n",
              "        device='cuda:0'),\n",
              " 'si1544fdrd1': tensor([[-0.0228, -0.1244, -0.0136,  ...,  0.2544,  0.0333,  0.1861],\n",
              "         [ 0.0877, -0.0725,  0.0032,  ..., -0.1052,  0.1718,  0.0950],\n",
              "         [ 0.0657, -0.0362,  0.0284,  ..., -0.1505,  0.2579, -0.0136],\n",
              "         ...,\n",
              "         [-0.1788,  0.0141,  0.3192,  ..., -0.1124, -0.0072, -0.0425],\n",
              "         [-0.2622,  0.0046,  0.3836,  ...,  0.0074,  0.0181, -0.0730],\n",
              "         [-0.2453,  0.0315,  0.3318,  ...,  0.1485,  0.0100, -0.0877]],\n",
              "        device='cuda:0'),\n",
              " 'sx281mrcz0': tensor([[ 0.0108, -0.1414, -0.0185,  ...,  0.2367,  0.0239,  0.1747],\n",
              "         [ 0.1197, -0.0464,  0.0243,  ..., -0.1049,  0.1416,  0.0954],\n",
              "         [ 0.0828,  0.0042,  0.0540,  ..., -0.1708,  0.2113, -0.0317],\n",
              "         ...,\n",
              "         [-0.1299,  0.0612,  0.3583,  ..., -0.1256, -0.0695, -0.0740],\n",
              "         [-0.2127,  0.0282,  0.4048,  ..., -0.0185, -0.0025, -0.0921],\n",
              "         [-0.2130,  0.0293,  0.3430,  ...,  0.1139,  0.0109, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'sx102mmdm2': tensor([[ 0.0099, -0.1444, -0.0191,  ...,  0.2345,  0.0243,  0.1732],\n",
              "         [ 0.1206, -0.0480,  0.0227,  ..., -0.1083,  0.1412,  0.0937],\n",
              "         [ 0.0851,  0.0026,  0.0520,  ..., -0.1747,  0.2084, -0.0363],\n",
              "         ...,\n",
              "         [-0.1286,  0.0593,  0.3556,  ..., -0.1282, -0.0657, -0.0769],\n",
              "         [-0.2117,  0.0249,  0.4013,  ..., -0.0229,  0.0014, -0.0929],\n",
              "         [-0.2112,  0.0226,  0.3404,  ...,  0.1090,  0.0144, -0.1116]],\n",
              "        device='cuda:0'),\n",
              " 'sx185mmdb1': tensor([[-0.0008, -0.1455, -0.0117,  ...,  0.2385,  0.0272,  0.1809],\n",
              "         [ 0.1028, -0.0586,  0.0260,  ..., -0.1037,  0.1539,  0.0951],\n",
              "         [ 0.0756, -0.0155,  0.0496,  ..., -0.1623,  0.2313, -0.0202],\n",
              "         ...,\n",
              "         [-0.1540,  0.0379,  0.3549,  ..., -0.1217, -0.0499, -0.0673],\n",
              "         [-0.2266,  0.0131,  0.3980,  ..., -0.0109,  0.0073, -0.0911],\n",
              "         [-0.2216,  0.0204,  0.3448,  ...,  0.1126,  0.0151, -0.1079]],\n",
              "        device='cuda:0'),\n",
              " 'sx184fjem0': tensor([[ 0.0627, -0.1800, -0.0228,  ...,  0.2009,  0.0405,  0.1383],\n",
              "         [ 0.2294, -0.1084, -0.0298,  ..., -0.1753,  0.1510,  0.0822],\n",
              "         [ 0.2121, -0.0680,  0.0026,  ..., -0.2462,  0.1867, -0.0631],\n",
              "         ...,\n",
              "         [ 0.0105, -0.0010,  0.2849,  ..., -0.1989, -0.0188, -0.0953],\n",
              "         [-0.1019, -0.0282,  0.3538,  ..., -0.0850,  0.0350, -0.1082],\n",
              "         [-0.1363, -0.0527,  0.3155,  ...,  0.0635,  0.0465, -0.1290]],\n",
              "        device='cuda:0'),\n",
              " 'sx365mmdb1': tensor([[ 0.0189, -0.1429, -0.0273,  ...,  0.2287,  0.0198,  0.1659],\n",
              "         [ 0.1387, -0.0433,  0.0144,  ..., -0.1126,  0.1343,  0.0973],\n",
              "         [ 0.1041,  0.0092,  0.0482,  ..., -0.1829,  0.1884, -0.0393],\n",
              "         ...,\n",
              "         [-0.1017,  0.0791,  0.3475,  ..., -0.1311, -0.0814, -0.0719],\n",
              "         [-0.1917,  0.0361,  0.4035,  ..., -0.0290, -0.0074, -0.0912],\n",
              "         [-0.1993,  0.0261,  0.3404,  ...,  0.1044,  0.0148, -0.1118]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fdac1': tensor([[-0.0096, -0.1351, -0.0107,  ...,  0.2502,  0.0263,  0.1819],\n",
              "         [ 0.0917, -0.0663,  0.0195,  ..., -0.1041,  0.1569,  0.0924],\n",
              "         [ 0.0691, -0.0242,  0.0439,  ..., -0.1581,  0.2405, -0.0214],\n",
              "         ...,\n",
              "         [-0.1706,  0.0274,  0.3375,  ..., -0.1245, -0.0385, -0.0582],\n",
              "         [-0.2457,  0.0081,  0.3919,  ..., -0.0069,  0.0091, -0.0836],\n",
              "         [-0.2371,  0.0232,  0.3402,  ...,  0.1232,  0.0100, -0.1003]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mjar0': tensor([[ 0.0532, -0.1684, -0.0249,  ...,  0.2132,  0.0353,  0.1472],\n",
              "         [ 0.2159, -0.0904, -0.0206,  ..., -0.1643,  0.1445,  0.0897],\n",
              "         [ 0.1917, -0.0461,  0.0133,  ..., -0.2360,  0.1837, -0.0566],\n",
              "         ...,\n",
              "         [-0.0119,  0.0267,  0.3048,  ..., -0.1833, -0.0404, -0.0861],\n",
              "         [-0.1189, -0.0074,  0.3655,  ..., -0.0693,  0.0234, -0.0999],\n",
              "         [-0.1514, -0.0314,  0.3202,  ...,  0.0800,  0.0357, -0.1196]],\n",
              "        device='cuda:0'),\n",
              " 'sa1faks0': tensor([[-0.0211, -0.1240, -0.0142,  ...,  0.2552,  0.0333,  0.1860],\n",
              "         [ 0.0910, -0.0726,  0.0039,  ..., -0.1054,  0.1680,  0.0934],\n",
              "         [ 0.0694, -0.0339,  0.0302,  ..., -0.1517,  0.2542, -0.0162],\n",
              "         ...,\n",
              "         [-0.1796,  0.0163,  0.3204,  ..., -0.1158, -0.0099, -0.0448],\n",
              "         [-0.2614,  0.0051,  0.3837,  ...,  0.0039,  0.0168, -0.0745],\n",
              "         [-0.2445,  0.0309,  0.3306,  ...,  0.1469,  0.0087, -0.0886]],\n",
              "        device='cuda:0'),\n",
              " 'sx110mjsw0': tensor([[-0.0230, -0.1272, -0.0126,  ...,  0.2527,  0.0312,  0.1872],\n",
              "         [ 0.0824, -0.0747,  0.0043,  ..., -0.1114,  0.1686,  0.1000],\n",
              "         [ 0.0599, -0.0402,  0.0278,  ..., -0.1552,  0.2525, -0.0095],\n",
              "         ...,\n",
              "         [-0.1771,  0.0112,  0.3174,  ..., -0.1171, -0.0092, -0.0384],\n",
              "         [-0.2614,  0.0028,  0.3823,  ...,  0.0014,  0.0166, -0.0713],\n",
              "         [-0.2464,  0.0251,  0.3335,  ...,  0.1426,  0.0131, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa2faks0': tensor([[-2.2797e-02, -1.3038e-01, -1.4583e-02,  ...,  2.5046e-01,\n",
              "           3.3861e-02,  1.9000e-01],\n",
              "         [ 8.7162e-02, -7.9114e-02, -2.3932e-03,  ..., -1.1778e-01,\n",
              "           1.7294e-01,  1.0336e-01],\n",
              "         [ 6.2019e-02, -4.9000e-02,  1.9768e-02,  ..., -1.5948e-01,\n",
              "           2.5668e-01, -5.8069e-03],\n",
              "         ...,\n",
              "         [-1.8025e-01,  6.4512e-03,  3.1554e-01,  ..., -1.1420e-01,\n",
              "          -1.4576e-03, -3.9848e-02],\n",
              "         [-2.6216e-01, -2.3430e-03,  3.7725e-01,  ...,  3.1153e-04,\n",
              "           2.3854e-02, -7.2195e-02],\n",
              "         [-2.5041e-01,  2.1052e-02,  3.2726e-01,  ...,  1.4220e-01,\n",
              "           1.5340e-02, -8.4601e-02]], device='cuda:0'),\n",
              " 'si992fjwb0': tensor([[ 0.1106, -0.2704, -0.0029,  ...,  0.1403,  0.0545,  0.0792],\n",
              "         [ 0.2836, -0.2338, -0.0565,  ..., -0.2338,  0.1671,  0.0300],\n",
              "         [ 0.2622, -0.2131, -0.0345,  ..., -0.2746,  0.2050, -0.1089],\n",
              "         ...,\n",
              "         [ 0.0525, -0.1699,  0.1857,  ..., -0.2776,  0.0535, -0.1642],\n",
              "         [-0.0541, -0.1844,  0.2951,  ..., -0.1654,  0.0956, -0.1783],\n",
              "         [-0.0763, -0.1990,  0.3075,  ...,  0.0047,  0.0933, -0.1868]],\n",
              "        device='cuda:0'),\n",
              " 'sx280fram1': tensor([[-0.0245, -0.1269, -0.0143,  ...,  0.2529,  0.0314,  0.1862],\n",
              "         [ 0.0812, -0.0773,  0.0037,  ..., -0.1113,  0.1689,  0.0971],\n",
              "         [ 0.0591, -0.0439,  0.0255,  ..., -0.1558,  0.2508, -0.0092],\n",
              "         ...,\n",
              "         [-0.1792,  0.0124,  0.3177,  ..., -0.1220, -0.0104, -0.0404],\n",
              "         [-0.2623,  0.0022,  0.3823,  ..., -0.0024,  0.0153, -0.0712],\n",
              "         [-0.2448,  0.0259,  0.3310,  ...,  0.1388,  0.0093, -0.0890]],\n",
              "        device='cuda:0'),\n",
              " 'si2120fkms0': tensor([[ 0.0054, -0.1454, -0.0156,  ...,  0.2354,  0.0253,  0.1782],\n",
              "         [ 0.1074, -0.0538,  0.0252,  ..., -0.1072,  0.1432,  0.0924],\n",
              "         [ 0.0770, -0.0072,  0.0515,  ..., -0.1712,  0.2175, -0.0318],\n",
              "         ...,\n",
              "         [-0.1448,  0.0452,  0.3572,  ..., -0.1270, -0.0615, -0.0736],\n",
              "         [-0.2198,  0.0166,  0.4000,  ..., -0.0196,  0.0007, -0.0936],\n",
              "         [-0.2160,  0.0224,  0.3418,  ...,  0.1089,  0.0110, -0.1090]],\n",
              "        device='cuda:0'),\n",
              " 'si1808fcft0': tensor([[ 0.0073, -0.1452, -0.0176,  ...,  0.2340,  0.0252,  0.1749],\n",
              "         [ 0.1147, -0.0546,  0.0241,  ..., -0.1093,  0.1452,  0.0916],\n",
              "         [ 0.0851, -0.0077,  0.0499,  ..., -0.1764,  0.2149, -0.0355],\n",
              "         ...,\n",
              "         [-0.1363,  0.0507,  0.3540,  ..., -0.1306, -0.0620, -0.0764],\n",
              "         [-0.2164,  0.0180,  0.3983,  ..., -0.0218,  0.0038, -0.0939],\n",
              "         [-0.2141,  0.0207,  0.3396,  ...,  0.1078,  0.0122, -0.1108]],\n",
              "        device='cuda:0'),\n",
              " 'si1178fcft0': tensor([[ 3.6749e-02, -1.5935e-01, -2.1553e-02,  ...,  2.2148e-01,\n",
              "           3.0667e-02,  1.6090e-01],\n",
              "         [ 1.8511e-01, -8.0462e-02,  7.8195e-05,  ..., -1.4571e-01,\n",
              "           1.4074e-01,  9.4329e-02],\n",
              "         [ 1.6743e-01, -3.5364e-02,  2.7424e-02,  ..., -2.2293e-01,\n",
              "           1.8783e-01, -4.5636e-02],\n",
              "         ...,\n",
              "         [-5.2479e-02,  4.4527e-02,  3.2721e-01,  ..., -1.6802e-01,\n",
              "          -5.3071e-02, -7.9380e-02],\n",
              "         [-1.5103e-01,  4.8072e-03,  3.7890e-01,  ..., -5.5657e-02,\n",
              "           1.8111e-02, -9.3312e-02],\n",
              "         [-1.7642e-01, -9.1262e-03,  3.2792e-01,  ...,  9.2908e-02,\n",
              "           2.3915e-02, -1.1017e-01]], device='cuda:0'),\n",
              " 'sa1mdab0': tensor([[ 0.0612, -0.1850, -0.0193,  ...,  0.2024,  0.0413,  0.1423],\n",
              "         [ 0.2303, -0.1170, -0.0235,  ..., -0.1787,  0.1497,  0.0797],\n",
              "         [ 0.2144, -0.0805,  0.0057,  ..., -0.2491,  0.1912, -0.0640],\n",
              "         ...,\n",
              "         [ 0.0039, -0.0100,  0.2945,  ..., -0.1990, -0.0182, -0.0910],\n",
              "         [-0.1054, -0.0354,  0.3551,  ..., -0.0832,  0.0373, -0.1030],\n",
              "         [-0.1422, -0.0545,  0.3141,  ...,  0.0671,  0.0413, -0.1223]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mstk0': tensor([[-0.0148, -0.1270, -0.0115,  ...,  0.2550,  0.0294,  0.1838],\n",
              "         [ 0.0945, -0.0673,  0.0117,  ..., -0.1015,  0.1606,  0.0923],\n",
              "         [ 0.0725, -0.0254,  0.0402,  ..., -0.1516,  0.2492, -0.0209],\n",
              "         ...,\n",
              "         [-0.1737,  0.0220,  0.3287,  ..., -0.1149, -0.0252, -0.0524],\n",
              "         [-0.2525,  0.0080,  0.3890,  ...,  0.0017,  0.0114, -0.0795],\n",
              "         [-0.2423,  0.0296,  0.3361,  ...,  0.1401,  0.0086, -0.0935]],\n",
              "        device='cuda:0'),\n",
              " 'si2284mstk0': tensor([[-0.0221, -0.1369, -0.0167,  ...,  0.2465,  0.0372,  0.1958],\n",
              "         [ 0.0826, -0.0840, -0.0174,  ..., -0.1343,  0.1787,  0.1211],\n",
              "         [ 0.0510, -0.0636,  0.0007,  ..., -0.1726,  0.2626,  0.0089],\n",
              "         ...,\n",
              "         [-0.1771, -0.0130,  0.3044,  ..., -0.1168,  0.0019, -0.0271],\n",
              "         [-0.2629, -0.0142,  0.3658,  ..., -0.0056,  0.0308, -0.0659],\n",
              "         [-0.2576,  0.0076,  0.3243,  ...,  0.1383,  0.0224, -0.0805]],\n",
              "        device='cuda:0'),\n",
              " 'sx50fkms0': tensor([[ 0.0080, -0.1466, -0.0177,  ...,  0.2326,  0.0248,  0.1749],\n",
              "         [ 0.1131, -0.0524,  0.0254,  ..., -0.1085,  0.1394,  0.0936],\n",
              "         [ 0.0793, -0.0036,  0.0533,  ..., -0.1747,  0.2085, -0.0322],\n",
              "         ...,\n",
              "         [-0.1352,  0.0526,  0.3588,  ..., -0.1280, -0.0657, -0.0756],\n",
              "         [-0.2123,  0.0204,  0.4024,  ..., -0.0239, -0.0013, -0.0933],\n",
              "         [-0.2105,  0.0205,  0.3413,  ...,  0.1054,  0.0132, -0.1110]],\n",
              "        device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_deep"
      ],
      "metadata": {
        "id": "X6xDeKtVscGP",
        "outputId": "8bc846d7-5fd9-43af-d6ef-756bb3406569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'si1364mrjo0': tensor([[ 0.0321, -0.1495, -0.0234,  ...,  0.2316,  0.0286,  0.1641],\n",
              "         [ 0.1767, -0.0651, -0.0033,  ..., -0.1411,  0.1404,  0.0989],\n",
              "         [ 0.1460, -0.0175,  0.0306,  ..., -0.2103,  0.1939, -0.0450],\n",
              "         ...,\n",
              "         [-0.0735,  0.0599,  0.3316,  ..., -0.1554, -0.0606, -0.0764],\n",
              "         [-0.1686,  0.0165,  0.3847,  ..., -0.0434,  0.0144, -0.0920],\n",
              "         [-0.1892,  0.0049,  0.3314,  ...,  0.1092,  0.0190, -0.1077]],\n",
              "        device='cuda:0'),\n",
              " 'si844fdac1': tensor([[ 0.0344, -0.1576, -0.0225,  ...,  0.2241,  0.0302,  0.1604],\n",
              "         [ 0.1824, -0.0761, -0.0015,  ..., -0.1453,  0.1417,  0.0947],\n",
              "         [ 0.1597, -0.0310,  0.0280,  ..., -0.2187,  0.1911, -0.0478],\n",
              "         ...,\n",
              "         [-0.0572,  0.0468,  0.3266,  ..., -0.1675, -0.0557, -0.0794],\n",
              "         [-0.1559,  0.0062,  0.3804,  ..., -0.0533,  0.0173, -0.0945],\n",
              "         [-0.1803, -0.0074,  0.3302,  ...,  0.0945,  0.0230, -0.1122]],\n",
              "        device='cuda:0'),\n",
              " 'si1360fram1': tensor([[-0.0308, -0.1419, -0.0235,  ...,  0.2269,  0.0422,  0.1903],\n",
              "         [ 0.0971, -0.0689,  0.0105,  ..., -0.1291,  0.1926,  0.0746],\n",
              "         [ 0.1010, -0.0227,  0.0086,  ..., -0.2004,  0.2591, -0.0281],\n",
              "         ...,\n",
              "         [-0.1573,  0.0333,  0.3409,  ..., -0.0660, -0.0106, -0.0604],\n",
              "         [-0.2623,  0.0215,  0.3735,  ...,  0.0580,  0.0306, -0.0942],\n",
              "         [-0.2394,  0.0821,  0.3034,  ...,  0.2322,  0.0225, -0.0251]],\n",
              "        device='cuda:0'),\n",
              " 'sx320fkms0': tensor([[ 0.0033, -0.1466, -0.0141,  ...,  0.2357,  0.0249,  0.1795],\n",
              "         [ 0.1015, -0.0565,  0.0264,  ..., -0.1074,  0.1423,  0.0924],\n",
              "         [ 0.0730, -0.0114,  0.0520,  ..., -0.1699,  0.2185, -0.0294],\n",
              "         ...,\n",
              "         [-0.1478,  0.0408,  0.3555,  ..., -0.1286, -0.0634, -0.0718],\n",
              "         [-0.2213,  0.0149,  0.4005,  ..., -0.0199, -0.0023, -0.0930],\n",
              "         [-0.2178,  0.0209,  0.3446,  ...,  0.1070,  0.0110, -0.1091]],\n",
              "        device='cuda:0'),\n",
              " 'sx189msjs1': tensor([[ 0.0042, -0.1437, -0.0151,  ...,  0.2371,  0.0259,  0.1774],\n",
              "         [ 0.1066, -0.0525,  0.0262,  ..., -0.1054,  0.1465,  0.0919],\n",
              "         [ 0.0773, -0.0061,  0.0519,  ..., -0.1691,  0.2214, -0.0330],\n",
              "         ...,\n",
              "         [-0.1467,  0.0469,  0.3552,  ..., -0.1283, -0.0615, -0.0755],\n",
              "         [-0.2243,  0.0172,  0.4010,  ..., -0.0161,  0.0024, -0.0957],\n",
              "         [-0.2213,  0.0255,  0.3425,  ...,  0.1165,  0.0116, -0.1106]],\n",
              "        device='cuda:0'),\n",
              " 'sx216fjre0': tensor([[-0.0236, -0.1295, -0.0137,  ...,  0.2521,  0.0314,  0.1868],\n",
              "         [ 0.0791, -0.0777,  0.0005,  ..., -0.1153,  0.1660,  0.1001],\n",
              "         [ 0.0555, -0.0443,  0.0233,  ..., -0.1594,  0.2500, -0.0101],\n",
              "         ...,\n",
              "         [-0.1790,  0.0073,  0.3151,  ..., -0.1219, -0.0127, -0.0392],\n",
              "         [-0.2623, -0.0021,  0.3807,  ..., -0.0025,  0.0152, -0.0719],\n",
              "         [-0.2463,  0.0214,  0.3320,  ...,  0.1376,  0.0098, -0.0898]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mwbt0': tensor([[ 0.0031, -0.1445, -0.0142,  ...,  0.2392,  0.0263,  0.1791],\n",
              "         [ 0.1084, -0.0542,  0.0242,  ..., -0.1078,  0.1457,  0.0941],\n",
              "         [ 0.0775, -0.0099,  0.0515,  ..., -0.1679,  0.2235, -0.0284],\n",
              "         ...,\n",
              "         [-0.1477,  0.0425,  0.3550,  ..., -0.1259, -0.0583, -0.0712],\n",
              "         [-0.2236,  0.0154,  0.3998,  ..., -0.0153,  0.0029, -0.0936],\n",
              "         [-0.2208,  0.0217,  0.3439,  ...,  0.1126,  0.0125, -0.1097]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjas0': tensor([[-0.0230, -0.1290, -0.0131,  ...,  0.2524,  0.0320,  0.1879],\n",
              "         [ 0.0839, -0.0755,  0.0037,  ..., -0.1131,  0.1666,  0.1012],\n",
              "         [ 0.0607, -0.0419,  0.0271,  ..., -0.1571,  0.2509, -0.0081],\n",
              "         ...,\n",
              "         [-0.1770,  0.0097,  0.3169,  ..., -0.1166, -0.0121, -0.0385],\n",
              "         [-0.2614,  0.0028,  0.3825,  ...,  0.0018,  0.0150, -0.0729],\n",
              "         [-0.2487,  0.0262,  0.3330,  ...,  0.1455,  0.0117, -0.0884]],\n",
              "        device='cuda:0'),\n",
              " 'si1265fjwb0': tensor([[ 0.0138, -0.1436, -0.0218,  ...,  0.2345,  0.0243,  0.1699],\n",
              "         [ 0.1300, -0.0487,  0.0172,  ..., -0.1144,  0.1404,  0.0950],\n",
              "         [ 0.0960,  0.0017,  0.0485,  ..., -0.1810,  0.2043, -0.0406],\n",
              "         ...,\n",
              "         [-0.1192,  0.0622,  0.3496,  ..., -0.1352, -0.0676, -0.0770],\n",
              "         [-0.2061,  0.0241,  0.3997,  ..., -0.0279,  0.0023, -0.0928],\n",
              "         [-0.2087,  0.0219,  0.3392,  ...,  0.1090,  0.0135, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx289mpgl0': tensor([[ 0.0067, -0.1468, -0.0138,  ...,  0.2424,  0.0296,  0.1823],\n",
              "         [ 0.1197, -0.0448,  0.0236,  ..., -0.0981,  0.1496,  0.1020],\n",
              "         [ 0.0805, -0.0008,  0.0562,  ..., -0.1495,  0.2295, -0.0192],\n",
              "         ...,\n",
              "         [-0.1326,  0.0536,  0.3615,  ..., -0.1093, -0.0615, -0.0624],\n",
              "         [-0.2088,  0.0253,  0.4066,  ..., -0.0050,  0.0031, -0.0876],\n",
              "         [-0.2124,  0.0284,  0.3515,  ...,  0.1142,  0.0193, -0.1103]],\n",
              "        device='cuda:0'),\n",
              " 'si1099mpgl0': tensor([[-0.0200, -0.1367, -0.0128,  ...,  0.2536,  0.0387,  0.1959],\n",
              "         [ 0.0926, -0.0763, -0.0027,  ..., -0.1226,  0.1849,  0.1244],\n",
              "         [ 0.0613, -0.0527,  0.0213,  ..., -0.1576,  0.2684,  0.0109],\n",
              "         ...,\n",
              "         [-0.1648,  0.0023,  0.3086,  ..., -0.1171, -0.0151, -0.0211],\n",
              "         [-0.2534, -0.0016,  0.3757,  ..., -0.0013,  0.0238, -0.0634],\n",
              "         [-0.2530,  0.0152,  0.3364,  ...,  0.1407,  0.0246, -0.0845]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fedw0': tensor([[-0.0169, -0.1245, -0.0130,  ...,  0.2566,  0.0309,  0.1835],\n",
              "         [ 0.0929, -0.0679,  0.0081,  ..., -0.1033,  0.1603,  0.0930],\n",
              "         [ 0.0704, -0.0266,  0.0370,  ..., -0.1508,  0.2497, -0.0202],\n",
              "         ...,\n",
              "         [-0.1761,  0.0210,  0.3257,  ..., -0.1154, -0.0213, -0.0500],\n",
              "         [-0.2561,  0.0078,  0.3880,  ...,  0.0029,  0.0115, -0.0780],\n",
              "         [-0.2421,  0.0300,  0.3354,  ...,  0.1433,  0.0085, -0.0936]],\n",
              "        device='cuda:0'),\n",
              " 'sx306felc0': tensor([[-0.0240, -0.1317, -0.0146,  ...,  0.2502,  0.0328,  0.1892],\n",
              "         [ 0.0806, -0.0807, -0.0024,  ..., -0.1192,  0.1713,  0.1043],\n",
              "         [ 0.0566, -0.0505,  0.0187,  ..., -0.1625,  0.2546, -0.0061],\n",
              "         ...,\n",
              "         [-0.1796,  0.0053,  0.3140,  ..., -0.1190, -0.0064, -0.0374],\n",
              "         [-0.2628, -0.0031,  0.3776,  ..., -0.0025,  0.0204, -0.0715],\n",
              "         [-0.2495,  0.0187,  0.3296,  ...,  0.1377,  0.0141, -0.0870]],\n",
              "        device='cuda:0'),\n",
              " 'sx223faks0': tensor([[-0.0200, -0.1223, -0.0142,  ...,  0.2563,  0.0337,  0.1870],\n",
              "         [ 0.0926, -0.0685,  0.0018,  ..., -0.1081,  0.1645,  0.0956],\n",
              "         [ 0.0700, -0.0290,  0.0319,  ..., -0.1528,  0.2535, -0.0179],\n",
              "         ...,\n",
              "         [-0.1771,  0.0176,  0.3188,  ..., -0.1118, -0.0135, -0.0468],\n",
              "         [-0.2602,  0.0082,  0.3849,  ...,  0.0060,  0.0134, -0.0764],\n",
              "         [-0.2459,  0.0322,  0.3324,  ...,  0.1510,  0.0090, -0.0888]],\n",
              "        device='cuda:0'),\n",
              " 'sa2fjwb0': tensor([[-0.0008, -0.1453, -0.0118,  ...,  0.2387,  0.0262,  0.1808],\n",
              "         [ 0.1013, -0.0575,  0.0264,  ..., -0.1065,  0.1495,  0.0939],\n",
              "         [ 0.0748, -0.0143,  0.0510,  ..., -0.1645,  0.2261, -0.0232],\n",
              "         ...,\n",
              "         [-0.1543,  0.0391,  0.3539,  ..., -0.1272, -0.0537, -0.0672],\n",
              "         [-0.2283,  0.0144,  0.3993,  ..., -0.0139,  0.0052, -0.0914],\n",
              "         [-0.2232,  0.0218,  0.3454,  ...,  0.1118,  0.0130, -0.1083]],\n",
              "        device='cuda:0'),\n",
              " 'sx200mjsw0': tensor([[-2.1014e-02, -1.2408e-01, -1.2605e-02,  ...,  2.5589e-01,\n",
              "           2.9466e-02,  1.8257e-01],\n",
              "         [ 8.3613e-02, -7.0768e-02,  9.0826e-03,  ..., -1.0080e-01,\n",
              "           1.6260e-01,  9.1813e-02],\n",
              "         [ 6.3595e-02, -3.2072e-02,  3.4370e-02,  ..., -1.4866e-01,\n",
              "           2.4855e-01, -1.7632e-02],\n",
              "         ...,\n",
              "         [-1.7604e-01,  1.6261e-02,  3.1865e-01,  ..., -1.2207e-01,\n",
              "          -2.0170e-02, -4.4449e-02],\n",
              "         [-2.5951e-01,  5.0842e-03,  3.8657e-01,  ...,  1.8064e-04,\n",
              "           1.0752e-02, -7.4890e-02],\n",
              "         [-2.4036e-01,  3.0519e-02,  3.3597e-01,  ...,  1.4265e-01,\n",
              "           6.8874e-03, -9.3277e-02]], device='cuda:0'),\n",
              " 'sx23mwbt0': tensor([[ 0.0023, -0.1446, -0.0126,  ...,  0.2393,  0.0263,  0.1808],\n",
              "         [ 0.1036, -0.0541,  0.0260,  ..., -0.1059,  0.1456,  0.0945],\n",
              "         [ 0.0744, -0.0090,  0.0531,  ..., -0.1643,  0.2244, -0.0265],\n",
              "         ...,\n",
              "         [-0.1494,  0.0430,  0.3565,  ..., -0.1250, -0.0616, -0.0681],\n",
              "         [-0.2245,  0.0178,  0.4014,  ..., -0.0138, -0.0004, -0.0917],\n",
              "         [-0.2217,  0.0242,  0.3459,  ...,  0.1130,  0.0114, -0.1082]],\n",
              "        device='cuda:0'),\n",
              " 'sa2mstk0': tensor([[-0.0224, -0.1248, -0.0142,  ...,  0.2551,  0.0338,  0.1873],\n",
              "         [ 0.0883, -0.0715,  0.0008,  ..., -0.1095,  0.1678,  0.0949],\n",
              "         [ 0.0667, -0.0342,  0.0286,  ..., -0.1532,  0.2556, -0.0168],\n",
              "         ...,\n",
              "         [-0.1775,  0.0119,  0.3157,  ..., -0.1155, -0.0102, -0.0430],\n",
              "         [-0.2611,  0.0033,  0.3822,  ...,  0.0043,  0.0163, -0.0743],\n",
              "         [-0.2459,  0.0300,  0.3312,  ...,  0.1479,  0.0091, -0.0880]],\n",
              "        device='cuda:0'),\n",
              " 'si1116fjre0': tensor([[-2.2920e-02, -1.2627e-01, -1.4684e-02,  ...,  2.5352e-01,\n",
              "           3.2366e-02,  1.8685e-01],\n",
              "         [ 8.2940e-02, -7.5871e-02,  3.0879e-04,  ..., -1.1319e-01,\n",
              "           1.6595e-01,  9.8150e-02],\n",
              "         [ 6.0528e-02, -4.0918e-02,  2.4898e-02,  ..., -1.5813e-01,\n",
              "           2.5163e-01, -1.2298e-02],\n",
              "         ...,\n",
              "         [-1.7897e-01,  1.1056e-02,  3.1452e-01,  ..., -1.1976e-01,\n",
              "          -8.6734e-03, -4.2062e-02],\n",
              "         [-2.6200e-01,  1.7057e-03,  3.8109e-01,  ..., -9.4267e-04,\n",
              "           1.6593e-02, -7.2813e-02],\n",
              "         [-2.4542e-01,  2.4561e-02,  3.3150e-01,  ...,  1.4080e-01,\n",
              "           1.0509e-02, -9.0239e-02]], device='cuda:0'),\n",
              " 'sx9mgwt0': tensor([[-2.1855e-02, -1.3138e-01, -1.2213e-02,  ...,  2.5026e-01,\n",
              "           3.4956e-02,  1.9002e-01],\n",
              "         [ 8.7677e-02, -7.5929e-02,  8.6759e-04,  ..., -1.1736e-01,\n",
              "           1.7456e-01,  1.0564e-01],\n",
              "         [ 6.3008e-02, -4.5173e-02,  2.4336e-02,  ..., -1.5946e-01,\n",
              "           2.5998e-01, -5.2715e-03],\n",
              "         ...,\n",
              "         [-1.7735e-01,  6.5645e-03,  3.1645e-01,  ..., -1.1292e-01,\n",
              "          -4.5673e-03, -3.8324e-02],\n",
              "         [-2.6069e-01, -3.7497e-05,  3.7912e-01,  ...,  2.8420e-03,\n",
              "           2.2369e-02, -7.2859e-02],\n",
              "         [-2.5039e-01,  2.2066e-02,  3.3089e-01,  ...,  1.4717e-01,\n",
              "           1.6807e-02, -8.6532e-02]], device='cuda:0'),\n",
              " 'sx104mrjo0': tensor([[-0.0218, -0.1248, -0.0138,  ...,  0.2536,  0.0333,  0.1875],\n",
              "         [ 0.0873, -0.0721,  0.0017,  ..., -0.1114,  0.1656,  0.0971],\n",
              "         [ 0.0658, -0.0347,  0.0286,  ..., -0.1557,  0.2529, -0.0154],\n",
              "         ...,\n",
              "         [-0.1783,  0.0116,  0.3175,  ..., -0.1152, -0.0116, -0.0433],\n",
              "         [-0.2609,  0.0029,  0.3827,  ...,  0.0030,  0.0148, -0.0751],\n",
              "         [-0.2467,  0.0292,  0.3319,  ...,  0.1480,  0.0105, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'si2169mgwt0': tensor([[ 0.0350, -0.1551, -0.0236,  ...,  0.2265,  0.0283,  0.1604],\n",
              "         [ 0.1857, -0.0725, -0.0037,  ..., -0.1450,  0.1373,  0.0978],\n",
              "         [ 0.1597, -0.0266,  0.0296,  ..., -0.2173,  0.1852, -0.0444],\n",
              "         ...,\n",
              "         [-0.0585,  0.0537,  0.3309,  ..., -0.1620, -0.0606, -0.0771],\n",
              "         [-0.1557,  0.0115,  0.3823,  ..., -0.0512,  0.0127, -0.0923],\n",
              "         [-0.1799, -0.0040,  0.3299,  ...,  0.0977,  0.0215, -0.1101]],\n",
              "        device='cuda:0'),\n",
              " 'si1553mwbt0': tensor([[ 0.0572, -0.1743, -0.0238,  ...,  0.2073,  0.0371,  0.1427],\n",
              "         [ 0.2236, -0.0999, -0.0236,  ..., -0.1736,  0.1439,  0.0865],\n",
              "         [ 0.2013, -0.0586,  0.0131,  ..., -0.2442,  0.1833, -0.0615],\n",
              "         ...,\n",
              "         [-0.0022,  0.0115,  0.2976,  ..., -0.1929, -0.0334, -0.0900],\n",
              "         [-0.1106, -0.0212,  0.3616,  ..., -0.0766,  0.0272, -0.1042],\n",
              "         [-0.1449, -0.0429,  0.3194,  ...,  0.0708,  0.0391, -0.1244]],\n",
              "        device='cuda:0'),\n",
              " 'sa2msjs1': tensor([[ 0.0108, -0.1425, -0.0198,  ...,  0.2347,  0.0247,  0.1717],\n",
              "         [ 0.1176, -0.0448,  0.0222,  ..., -0.1042,  0.1445,  0.0928],\n",
              "         [ 0.0830,  0.0066,  0.0522,  ..., -0.1719,  0.2097, -0.0403],\n",
              "         ...,\n",
              "         [-0.1263,  0.0652,  0.3532,  ..., -0.1279, -0.0687, -0.0792],\n",
              "         [-0.2126,  0.0293,  0.4033,  ..., -0.0212,  0.0006, -0.0945],\n",
              "         [-0.2114,  0.0278,  0.3420,  ...,  0.1131,  0.0149, -0.1128]],\n",
              "        device='cuda:0'),\n",
              " 'sx230fkms0': tensor([[ 0.0086, -0.1434, -0.0184,  ...,  0.2356,  0.0240,  0.1743],\n",
              "         [ 0.1120, -0.0486,  0.0241,  ..., -0.1069,  0.1399,  0.0918],\n",
              "         [ 0.0774,  0.0008,  0.0526,  ..., -0.1743,  0.2107, -0.0384],\n",
              "         ...,\n",
              "         [-0.1355,  0.0544,  0.3562,  ..., -0.1297, -0.0689, -0.0775],\n",
              "         [-0.2158,  0.0226,  0.4023,  ..., -0.0230, -0.0030, -0.0943],\n",
              "         [-0.2134,  0.0244,  0.3422,  ...,  0.1090,  0.0110, -0.1113]],\n",
              "        device='cuda:0'),\n",
              " 'si1474fdac1': tensor([[-0.0227, -0.1247, -0.0144,  ...,  0.2537,  0.0315,  0.1852],\n",
              "         [ 0.0839, -0.0748,  0.0032,  ..., -0.1093,  0.1643,  0.0931],\n",
              "         [ 0.0637, -0.0366,  0.0282,  ..., -0.1554,  0.2498, -0.0173],\n",
              "         ...,\n",
              "         [-0.1795,  0.0118,  0.3152,  ..., -0.1223, -0.0122, -0.0448],\n",
              "         [-0.2628,  0.0021,  0.3826,  ..., -0.0009,  0.0140, -0.0751],\n",
              "         [-0.2443,  0.0287,  0.3313,  ...,  0.1434,  0.0067, -0.0902]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mgwt0': tensor([[ 0.0153, -0.1433, -0.0225,  ...,  0.2338,  0.0236,  0.1698],\n",
              "         [ 0.1347, -0.0479,  0.0157,  ..., -0.1159,  0.1395,  0.0948],\n",
              "         [ 0.0999,  0.0033,  0.0481,  ..., -0.1821,  0.2021, -0.0416],\n",
              "         ...,\n",
              "         [-0.1151,  0.0666,  0.3484,  ..., -0.1347, -0.0705, -0.0771],\n",
              "         [-0.2029,  0.0261,  0.3989,  ..., -0.0283,  0.0016, -0.0929],\n",
              "         [-0.2072,  0.0224,  0.3379,  ...,  0.1100,  0.0139, -0.1114]],\n",
              "        device='cuda:0'),\n",
              " 'sx140fkms0': tensor([[ 0.0061, -0.1455, -0.0172,  ...,  0.2358,  0.0242,  0.1764],\n",
              "         [ 0.1085, -0.0534,  0.0243,  ..., -0.1096,  0.1385,  0.0927],\n",
              "         [ 0.0762, -0.0060,  0.0523,  ..., -0.1744,  0.2127, -0.0355],\n",
              "         ...,\n",
              "         [-0.1414,  0.0466,  0.3558,  ..., -0.1308, -0.0664, -0.0748],\n",
              "         [-0.2174,  0.0168,  0.4002,  ..., -0.0231, -0.0024, -0.0940],\n",
              "         [-0.2153,  0.0202,  0.3422,  ...,  0.1059,  0.0110, -0.1109]],\n",
              "        device='cuda:0'),\n",
              " 'sx109mpgl0': tensor([[ 0.0114, -0.1466, -0.0176,  ...,  0.2362,  0.0281,  0.1766],\n",
              "         [ 0.1222, -0.0390,  0.0244,  ..., -0.0945,  0.1438,  0.0984],\n",
              "         [ 0.0805,  0.0086,  0.0589,  ..., -0.1530,  0.2140, -0.0247],\n",
              "         ...,\n",
              "         [-0.1220,  0.0708,  0.3627,  ..., -0.1106, -0.0730, -0.0687],\n",
              "         [-0.2051,  0.0362,  0.4128,  ..., -0.0075, -0.0015, -0.0882],\n",
              "         [-0.2071,  0.0317,  0.3494,  ...,  0.1145,  0.0196, -0.1144]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fram1': tensor([[ 0.0081, -0.1443, -0.0187,  ...,  0.2346,  0.0255,  0.1741],\n",
              "         [ 0.1182, -0.0538,  0.0234,  ..., -0.1128,  0.1448,  0.0912],\n",
              "         [ 0.0883, -0.0077,  0.0489,  ..., -0.1791,  0.2137, -0.0363],\n",
              "         ...,\n",
              "         [-0.1334,  0.0511,  0.3499,  ..., -0.1357, -0.0630, -0.0783],\n",
              "         [-0.2152,  0.0177,  0.3970,  ..., -0.0267,  0.0034, -0.0946],\n",
              "         [-0.2151,  0.0212,  0.3387,  ...,  0.1097,  0.0109, -0.1107]],\n",
              "        device='cuda:0'),\n",
              " 'si1544fdrd1': tensor([[-0.0227, -0.1250, -0.0146,  ...,  0.2530,  0.0332,  0.1866],\n",
              "         [ 0.0862, -0.0745,  0.0009,  ..., -0.1086,  0.1695,  0.0951],\n",
              "         [ 0.0650, -0.0384,  0.0258,  ..., -0.1536,  0.2554, -0.0144],\n",
              "         ...,\n",
              "         [-0.1793,  0.0125,  0.3164,  ..., -0.1160, -0.0070, -0.0434],\n",
              "         [-0.2626,  0.0034,  0.3821,  ...,  0.0038,  0.0182, -0.0737],\n",
              "         [-0.2455,  0.0297,  0.3305,  ...,  0.1463,  0.0092, -0.0883]],\n",
              "        device='cuda:0'),\n",
              " 'sx281mrcz0': tensor([[ 0.0085, -0.1414, -0.0176,  ...,  0.2371,  0.0243,  0.1760],\n",
              "         [ 0.1144, -0.0475,  0.0251,  ..., -0.1053,  0.1441,  0.0931],\n",
              "         [ 0.0795,  0.0019,  0.0527,  ..., -0.1708,  0.2167, -0.0338],\n",
              "         ...,\n",
              "         [-0.1353,  0.0564,  0.3562,  ..., -0.1286, -0.0687, -0.0753],\n",
              "         [-0.2168,  0.0244,  0.4036,  ..., -0.0197, -0.0022, -0.0934],\n",
              "         [-0.2166,  0.0292,  0.3428,  ...,  0.1147,  0.0092, -0.1098]],\n",
              "        device='cuda:0'),\n",
              " 'sx102mmdm2': tensor([[ 0.0084, -0.1437, -0.0185,  ...,  0.2353,  0.0234,  0.1736],\n",
              "         [ 0.1143, -0.0485,  0.0247,  ..., -0.1072,  0.1396,  0.0921],\n",
              "         [ 0.0804,  0.0019,  0.0534,  ..., -0.1743,  0.2091, -0.0383],\n",
              "         ...,\n",
              "         [-0.1328,  0.0543,  0.3544,  ..., -0.1321, -0.0682, -0.0776],\n",
              "         [-0.2147,  0.0221,  0.4022,  ..., -0.0239, -0.0015, -0.0945],\n",
              "         [-0.2133,  0.0230,  0.3420,  ...,  0.1100,  0.0127, -0.1125]],\n",
              "        device='cuda:0'),\n",
              " 'sx185mmdb1': tensor([[-0.0021, -0.1455, -0.0116,  ...,  0.2389,  0.0267,  0.1814],\n",
              "         [ 0.0977, -0.0606,  0.0252,  ..., -0.1058,  0.1529,  0.0938],\n",
              "         [ 0.0726, -0.0186,  0.0479,  ..., -0.1639,  0.2310, -0.0224],\n",
              "         ...,\n",
              "         [-0.1574,  0.0351,  0.3499,  ..., -0.1251, -0.0500, -0.0672],\n",
              "         [-0.2304,  0.0114,  0.3963,  ..., -0.0117,  0.0079, -0.0918],\n",
              "         [-0.2242,  0.0192,  0.3441,  ...,  0.1136,  0.0145, -0.1077]],\n",
              "        device='cuda:0'),\n",
              " 'sx184fjem0': tensor([[ 0.0633, -0.1824, -0.0211,  ...,  0.1995,  0.0395,  0.1378],\n",
              "         [ 0.2279, -0.1120, -0.0271,  ..., -0.1770,  0.1490,  0.0798],\n",
              "         [ 0.2119, -0.0731,  0.0047,  ..., -0.2480,  0.1865, -0.0662],\n",
              "         ...,\n",
              "         [ 0.0114, -0.0050,  0.2846,  ..., -0.2016, -0.0198, -0.0965],\n",
              "         [-0.1011, -0.0315,  0.3541,  ..., -0.0860,  0.0358, -0.1090],\n",
              "         [-0.1367, -0.0555,  0.3162,  ...,  0.0630,  0.0445, -0.1290]],\n",
              "        device='cuda:0'),\n",
              " 'sx365mmdb1': tensor([[ 0.0181, -0.1434, -0.0263,  ...,  0.2299,  0.0203,  0.1660],\n",
              "         [ 0.1355, -0.0453,  0.0148,  ..., -0.1132,  0.1355,  0.0958],\n",
              "         [ 0.1015,  0.0073,  0.0476,  ..., -0.1843,  0.1912, -0.0429],\n",
              "         ...,\n",
              "         [-0.1045,  0.0739,  0.3463,  ..., -0.1351, -0.0812, -0.0743],\n",
              "         [-0.1947,  0.0320,  0.4025,  ..., -0.0310, -0.0065, -0.0929],\n",
              "         [-0.2009,  0.0247,  0.3401,  ...,  0.1052,  0.0140, -0.1127]],\n",
              "        device='cuda:0'),\n",
              " 'sa1fdac1': tensor([[-0.0107, -0.1352, -0.0108,  ...,  0.2502,  0.0262,  0.1821],\n",
              "         [ 0.0896, -0.0669,  0.0191,  ..., -0.1052,  0.1552,  0.0917],\n",
              "         [ 0.0690, -0.0235,  0.0434,  ..., -0.1590,  0.2401, -0.0239],\n",
              "         ...,\n",
              "         [-0.1712,  0.0256,  0.3354,  ..., -0.1258, -0.0379, -0.0580],\n",
              "         [-0.2467,  0.0069,  0.3918,  ..., -0.0075,  0.0084, -0.0837],\n",
              "         [-0.2386,  0.0234,  0.3400,  ...,  0.1253,  0.0099, -0.1002]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mjar0': tensor([[ 0.0525, -0.1695, -0.0234,  ...,  0.2136,  0.0354,  0.1481],\n",
              "         [ 0.2144, -0.0923, -0.0188,  ..., -0.1645,  0.1453,  0.0875],\n",
              "         [ 0.1918, -0.0501,  0.0134,  ..., -0.2360,  0.1870, -0.0584],\n",
              "         ...,\n",
              "         [-0.0159,  0.0239,  0.3049,  ..., -0.1848, -0.0404, -0.0863],\n",
              "         [-0.1215, -0.0099,  0.3654,  ..., -0.0690,  0.0244, -0.1007],\n",
              "         [-0.1540, -0.0315,  0.3213,  ...,  0.0815,  0.0347, -0.1194]],\n",
              "        device='cuda:0'),\n",
              " 'sa1faks0': tensor([[-2.1034e-02, -1.2466e-01, -1.4833e-02,  ...,  2.5455e-01,\n",
              "           3.2707e-02,  1.8555e-01],\n",
              "         [ 8.7882e-02, -7.4265e-02,  1.9939e-03,  ..., -1.0809e-01,\n",
              "           1.6368e-01,  9.3794e-02],\n",
              "         [ 6.6562e-02, -3.5678e-02,  2.8359e-02,  ..., -1.5450e-01,\n",
              "           2.5045e-01, -1.7240e-02],\n",
              "         ...,\n",
              "         [-1.8020e-01,  1.4047e-02,  3.1849e-01,  ..., -1.1973e-01,\n",
              "          -1.1978e-02, -4.6564e-02],\n",
              "         [-2.6155e-01,  2.8232e-03,  3.8337e-01,  ...,  2.7419e-04,\n",
              "           1.4559e-02, -7.4942e-02],\n",
              "         [-2.4422e-01,  2.8756e-02,  3.3078e-01,  ...,  1.4380e-01,\n",
              "           7.5664e-03, -8.9859e-02]], device='cuda:0'),\n",
              " 'sx110mjsw0': tensor([[-0.0236, -0.1280, -0.0131,  ...,  0.2519,  0.0311,  0.1872],\n",
              "         [ 0.0809, -0.0769,  0.0034,  ..., -0.1129,  0.1690,  0.1001],\n",
              "         [ 0.0591, -0.0429,  0.0255,  ..., -0.1577,  0.2519, -0.0087],\n",
              "         ...,\n",
              "         [-0.1774,  0.0101,  0.3152,  ..., -0.1200, -0.0087, -0.0386],\n",
              "         [-0.2618,  0.0016,  0.3809,  ..., -0.0006,  0.0172, -0.0718],\n",
              "         [-0.2469,  0.0238,  0.3323,  ...,  0.1415,  0.0128, -0.0885]],\n",
              "        device='cuda:0'),\n",
              " 'sa2faks0': tensor([[-0.0231, -0.1307, -0.0150,  ...,  0.2503,  0.0333,  0.1897],\n",
              "         [ 0.0836, -0.0809, -0.0037,  ..., -0.1190,  0.1701,  0.1030],\n",
              "         [ 0.0591, -0.0507,  0.0177,  ..., -0.1614,  0.2541, -0.0066],\n",
              "         ...,\n",
              "         [-0.1813,  0.0051,  0.3138,  ..., -0.1168, -0.0029, -0.0402],\n",
              "         [-0.2630, -0.0033,  0.3771,  ..., -0.0016,  0.0231, -0.0722],\n",
              "         [-0.2509,  0.0195,  0.3275,  ...,  0.1407,  0.0144, -0.0860]],\n",
              "        device='cuda:0'),\n",
              " 'si992fjwb0': tensor([[ 0.1117, -0.2771, -0.0015,  ...,  0.1391,  0.0547,  0.0795],\n",
              "         [ 0.2824, -0.2419, -0.0550,  ..., -0.2368,  0.1682,  0.0279],\n",
              "         [ 0.2602, -0.2234, -0.0363,  ..., -0.2759,  0.2083, -0.1080],\n",
              "         ...,\n",
              "         [ 0.0500, -0.1794,  0.1812,  ..., -0.2817,  0.0572, -0.1670],\n",
              "         [-0.0552, -0.1936,  0.2924,  ..., -0.1668,  0.0985, -0.1790],\n",
              "         [-0.0781, -0.2067,  0.3075,  ...,  0.0047,  0.0945, -0.1872]],\n",
              "        device='cuda:0'),\n",
              " 'sx280fram1': tensor([[-0.0246, -0.1274, -0.0152,  ...,  0.2514,  0.0314,  0.1868],\n",
              "         [ 0.0809, -0.0794,  0.0010,  ..., -0.1141,  0.1673,  0.0975],\n",
              "         [ 0.0595, -0.0461,  0.0225,  ..., -0.1589,  0.2494, -0.0103],\n",
              "         ...,\n",
              "         [-0.1799,  0.0099,  0.3139,  ..., -0.1234, -0.0076, -0.0416],\n",
              "         [-0.2637,  0.0006,  0.3798,  ..., -0.0031,  0.0168, -0.0726],\n",
              "         [-0.2459,  0.0242,  0.3294,  ...,  0.1389,  0.0091, -0.0887]],\n",
              "        device='cuda:0'),\n",
              " 'si2120fkms0': tensor([[ 0.0044, -0.1465, -0.0156,  ...,  0.2341,  0.0243,  0.1785],\n",
              "         [ 0.1041, -0.0561,  0.0258,  ..., -0.1097,  0.1404,  0.0918],\n",
              "         [ 0.0751, -0.0095,  0.0510,  ..., -0.1747,  0.2153, -0.0330],\n",
              "         ...,\n",
              "         [-0.1461,  0.0431,  0.3555,  ..., -0.1298, -0.0636, -0.0746],\n",
              "         [-0.2205,  0.0150,  0.3992,  ..., -0.0206, -0.0007, -0.0946],\n",
              "         [-0.2171,  0.0196,  0.3420,  ...,  0.1071,  0.0107, -0.1093]],\n",
              "        device='cuda:0'),\n",
              " 'si1808fcft0': tensor([[-0.0314, -0.1414, -0.0240,  ...,  0.2280,  0.0426,  0.1899],\n",
              "         [ 0.0972, -0.0725,  0.0071,  ..., -0.1292,  0.1952,  0.0769],\n",
              "         [ 0.0996, -0.0297,  0.0055,  ..., -0.1996,  0.2614, -0.0247],\n",
              "         ...,\n",
              "         [-0.1567,  0.0294,  0.3382,  ..., -0.0691, -0.0068, -0.0591],\n",
              "         [-0.2610,  0.0176,  0.3739,  ...,  0.0556,  0.0328, -0.0945],\n",
              "         [-0.2405,  0.0823,  0.3048,  ...,  0.2330,  0.0239, -0.0271]],\n",
              "        device='cuda:0'),\n",
              " 'si1178fcft0': tensor([[ 0.0355, -0.1606, -0.0216,  ...,  0.2211,  0.0296,  0.1600],\n",
              "         [ 0.1830, -0.0821,  0.0005,  ..., -0.1461,  0.1389,  0.0934],\n",
              "         [ 0.1671, -0.0382,  0.0274,  ..., -0.2233,  0.1869, -0.0475],\n",
              "         ...,\n",
              "         [-0.0514,  0.0407,  0.3246,  ..., -0.1730, -0.0544, -0.0803],\n",
              "         [-0.1506,  0.0015,  0.3783,  ..., -0.0584,  0.0180, -0.0954],\n",
              "         [-0.1776, -0.0121,  0.3288,  ...,  0.0913,  0.0237, -0.1126]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mdab0': tensor([[ 0.0622, -0.1898, -0.0188,  ...,  0.1982,  0.0397,  0.1384],\n",
              "         [ 0.2319, -0.1232, -0.0240,  ..., -0.1824,  0.1457,  0.0763],\n",
              "         [ 0.2178, -0.0888,  0.0049,  ..., -0.2538,  0.1866, -0.0677],\n",
              "         ...,\n",
              "         [ 0.0098, -0.0191,  0.2881,  ..., -0.2070, -0.0183, -0.0939],\n",
              "         [-0.1001, -0.0432,  0.3532,  ..., -0.0900,  0.0370, -0.1070],\n",
              "         [-0.1391, -0.0639,  0.3143,  ...,  0.0611,  0.0426, -0.1273]],\n",
              "        device='cuda:0'),\n",
              " 'sa1mstk0': tensor([[-0.0151, -0.1271, -0.0124,  ...,  0.2544,  0.0294,  0.1840],\n",
              "         [ 0.0925, -0.0688,  0.0097,  ..., -0.1047,  0.1585,  0.0929],\n",
              "         [ 0.0709, -0.0278,  0.0380,  ..., -0.1544,  0.2476, -0.0215],\n",
              "         ...,\n",
              "         [-0.1736,  0.0210,  0.3258,  ..., -0.1188, -0.0260, -0.0525],\n",
              "         [-0.2534,  0.0073,  0.3878,  ..., -0.0006,  0.0102, -0.0798],\n",
              "         [-0.2429,  0.0284,  0.3352,  ...,  0.1384,  0.0081, -0.0937]],\n",
              "        device='cuda:0'),\n",
              " 'si2284mstk0': tensor([[-0.0229, -0.1371, -0.0174,  ...,  0.2457,  0.0369,  0.1957],\n",
              "         [ 0.0808, -0.0853, -0.0189,  ..., -0.1357,  0.1782,  0.1211],\n",
              "         [ 0.0503, -0.0644, -0.0014,  ..., -0.1744,  0.2625,  0.0075],\n",
              "         ...,\n",
              "         [-0.1762, -0.0138,  0.3007,  ..., -0.1199,  0.0004, -0.0256],\n",
              "         [-0.2638, -0.0148,  0.3648,  ..., -0.0070,  0.0303, -0.0662],\n",
              "         [-0.2582,  0.0072,  0.3242,  ...,  0.1376,  0.0223, -0.0810]],\n",
              "        device='cuda:0'),\n",
              " 'sx50fkms0': tensor([[ 0.0064, -0.1465, -0.0172,  ...,  0.2337,  0.0247,  0.1757],\n",
              "         [ 0.1099, -0.0532,  0.0255,  ..., -0.1096,  0.1394,  0.0929],\n",
              "         [ 0.0780, -0.0061,  0.0526,  ..., -0.1756,  0.2107, -0.0327],\n",
              "         ...,\n",
              "         [-0.1385,  0.0483,  0.3564,  ..., -0.1321, -0.0655, -0.0750],\n",
              "         [-0.2159,  0.0176,  0.4009,  ..., -0.0243, -0.0011, -0.0941],\n",
              "         [-0.2136,  0.0195,  0.3419,  ...,  0.1055,  0.0126, -0.1114]],\n",
              "        device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Diffrential Privacy filter"
      ],
      "metadata": {
        "id": "vsuSDhRQEYF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "8O3flG4_EhHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "input_size = 768  # Size of input features\n",
        "hidden_size = 384  # Size of hidden layer\n",
        "output_size = 768  # Size of output features (deepfake-like features)\n",
        "batch_size = 24\n",
        "num_layers = 2\n",
        "noise_multiplier = 0.1\n",
        "max_grad_norm = 1.0\n",
        "num_epochs = 1000\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "0yStXMpSFxez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom dataset\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, real_features, deepfake_features):\n",
        "        self.real_features = real_features\n",
        "        self.deepfake_features = deepfake_features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.real_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.real_features[idx], self.deepfake_features[idx]"
      ],
      "metadata": {
        "id": "fl_CPzqaF4Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Uss5bl6OuqmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dict_to_tensor(feature_real, feature_deep, desired_size, device):\n",
        "  \"\"\"\n",
        "  Processes dictionaries of real and deepfake feature sequences into tensors.\n",
        "\n",
        "  Args:\n",
        "      feature_real: A dictionary of real feature sequences (tensors).\n",
        "      feature_deep: A dictionary of deepfake feature sequences (tensors).\n",
        "      desired_size: The desired size for the output tensors.\n",
        "      device: The device to move the tensors to (e.g., 'cuda:0' for GPU).\n",
        "\n",
        "  Returns:\n",
        "      A tuple of tensors representing the processed real and deepfake features.\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine keys from both dictionaries\n",
        "  all_keys = set(feature_real.keys()) | set(feature_deep.keys())\n",
        "\n",
        "  # Find minimum sequence length across all features (using chain)\n",
        "  min_length = min(len(seq) for seq in chain(feature_real.values(), feature_deep.values()))\n",
        "\n",
        "  # Process each feature sequence, considering minimum length\n",
        "  tensor_list_real = {key: None for key in all_keys}  # Initialize empty dict\n",
        "  tensor_list_deep = {key: None for key in all_keys}  # Initialize empty dict\n",
        "  for key in all_keys:\n",
        "    real_seq = feature_real.get(key)\n",
        "    deep_seq = feature_deep.get(key)\n",
        "    if real_seq is not None:\n",
        "      tensor_list_real[key] = F.interpolate(\n",
        "          real_seq[:min_length].unsqueeze(0), size=(desired_size,), mode='nearest').squeeze(0)\n",
        "    if deep_seq is not None:\n",
        "      tensor_list_deep[key] = F.interpolate(\n",
        "          deep_seq[:min_length].unsqueeze(0), size=(desired_size,), mode='nearest').squeeze(0)\n",
        "\n",
        "  # Stack and move to desired device\n",
        "  real_features_tensor = torch.stack([tensor_list_real[key] for key in feature_real.keys()]).to(device)\n",
        "  deepfake_features_tensor = torch.stack([tensor_list_deep[key] for key in feature_deep.keys()]).to(device)\n",
        "  return real_features_tensor, deepfake_features_tensor"
      ],
      "metadata": {
        "id": "FbaYoCPuLzOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic dataset\n",
        "# Convert dictionary to tensor and resize features\n",
        "real_features, deepfake_features = dict_to_tensor(feature_real, feature_deep, input_size, device)"
      ],
      "metadata": {
        "id": "hSdQOER2L2Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_features"
      ],
      "metadata": {
        "id": "rcWkNwCOxeaA",
        "outputId": "81528df5-88d3-4b1d-e376-00d80fd612b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0337, -0.1497, -0.0243,  ...,  0.2315,  0.0290,  0.1629],\n",
              "         [ 0.1824, -0.0650, -0.0055,  ..., -0.1429,  0.1406,  0.1006],\n",
              "         [ 0.1506, -0.0165,  0.0294,  ..., -0.2116,  0.1907, -0.0434],\n",
              "         ...,\n",
              "         [ 0.2791,  0.0735,  0.0227,  ..., -0.1190, -0.4003,  0.0074],\n",
              "         [ 0.2787,  0.0734,  0.0228,  ..., -0.1215, -0.4004,  0.0088],\n",
              "         [ 0.2786,  0.0735,  0.0229,  ..., -0.1232, -0.4015,  0.0099]],\n",
              "\n",
              "        [[ 0.0372, -0.1600, -0.0227,  ...,  0.2216,  0.0322,  0.1591],\n",
              "         [ 0.1889, -0.0792, -0.0043,  ..., -0.1479,  0.1435,  0.0944],\n",
              "         [ 0.1673, -0.0344,  0.0250,  ..., -0.2216,  0.1901, -0.0467],\n",
              "         ...,\n",
              "         [ 0.2975,  0.0570,  0.0192,  ..., -0.1471, -0.3939, -0.0063],\n",
              "         [ 0.2970,  0.0565,  0.0197,  ..., -0.1460, -0.3938, -0.0063],\n",
              "         [ 0.2970,  0.0560,  0.0199,  ..., -0.1455, -0.3936, -0.0058]],\n",
              "\n",
              "        [[ 0.0072, -0.1443, -0.0176,  ...,  0.2343,  0.0249,  0.1746],\n",
              "         [ 0.1128, -0.0520,  0.0250,  ..., -0.1086,  0.1449,  0.0915],\n",
              "         [ 0.0819, -0.0033,  0.0516,  ..., -0.1755,  0.2143, -0.0359],\n",
              "         ...,\n",
              "         [ 0.2232,  0.1251,  0.0354,  ..., -0.0600, -0.3834, -0.0033],\n",
              "         [ 0.2233,  0.1243,  0.0348,  ..., -0.0594, -0.3838, -0.0035],\n",
              "         [ 0.2240,  0.1234,  0.0345,  ..., -0.0599, -0.3843, -0.0041]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.0148, -0.1270, -0.0115,  ...,  0.2550,  0.0294,  0.1838],\n",
              "         [ 0.0945, -0.0673,  0.0117,  ..., -0.1015,  0.1606,  0.0923],\n",
              "         [ 0.0725, -0.0254,  0.0402,  ..., -0.1516,  0.2492, -0.0209],\n",
              "         ...,\n",
              "         [ 0.1946,  0.1038,  0.0346,  ..., -0.0725, -0.4455,  0.0026],\n",
              "         [ 0.1923,  0.1032,  0.0350,  ..., -0.0735, -0.4495,  0.0035],\n",
              "         [ 0.1899,  0.1025,  0.0358,  ..., -0.0756, -0.4555,  0.0049]],\n",
              "\n",
              "        [[-0.0221, -0.1369, -0.0167,  ...,  0.2465,  0.0372,  0.1958],\n",
              "         [ 0.0826, -0.0840, -0.0174,  ..., -0.1343,  0.1787,  0.1211],\n",
              "         [ 0.0510, -0.0636,  0.0007,  ..., -0.1726,  0.2626,  0.0089],\n",
              "         ...,\n",
              "         [-0.1771, -0.0130,  0.3044,  ..., -0.1168,  0.0019, -0.0271],\n",
              "         [-0.2629, -0.0142,  0.3658,  ..., -0.0056,  0.0308, -0.0659],\n",
              "         [-0.2576,  0.0076,  0.3243,  ...,  0.1383,  0.0224, -0.0805]],\n",
              "\n",
              "        [[ 0.0080, -0.1466, -0.0177,  ...,  0.2326,  0.0248,  0.1749],\n",
              "         [ 0.1131, -0.0524,  0.0254,  ..., -0.1085,  0.1394,  0.0936],\n",
              "         [ 0.0793, -0.0036,  0.0533,  ..., -0.1747,  0.2085, -0.0322],\n",
              "         ...,\n",
              "         [ 0.2216,  0.1213,  0.0409,  ..., -0.0617, -0.3851, -0.0047],\n",
              "         [ 0.2227,  0.1206,  0.0416,  ..., -0.0644, -0.3863, -0.0039],\n",
              "         [ 0.2225,  0.1200,  0.0427,  ..., -0.0659, -0.3888, -0.0037]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deepfake_features"
      ],
      "metadata": {
        "id": "0XsTUh5gVEOn",
        "outputId": "439e0c14-27b5-4a3c-b476-5744f91b81e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 3.2117e-02, -1.4953e-01, -2.3393e-02,  ...,  2.3164e-01,\n",
              "           2.8560e-02,  1.6406e-01],\n",
              "         [ 1.7674e-01, -6.5082e-02, -3.2546e-03,  ..., -1.4112e-01,\n",
              "           1.4044e-01,  9.8912e-02],\n",
              "         [ 1.4602e-01, -1.7526e-02,  3.0644e-02,  ..., -2.1033e-01,\n",
              "           1.9388e-01, -4.4958e-02],\n",
              "         ...,\n",
              "         [ 2.7445e-01,  7.3909e-02,  1.9542e-02,  ..., -1.1725e-01,\n",
              "          -4.0546e-01,  6.8320e-03],\n",
              "         [ 2.7438e-01,  7.4162e-02,  1.9759e-02,  ..., -1.1950e-01,\n",
              "          -4.0531e-01,  7.9358e-03],\n",
              "         [ 2.7426e-01,  7.4530e-02,  2.0117e-02,  ..., -1.2073e-01,\n",
              "          -4.0587e-01,  9.0176e-03]],\n",
              "\n",
              "        [[ 3.4436e-02, -1.5756e-01, -2.2521e-02,  ...,  2.2409e-01,\n",
              "           3.0163e-02,  1.6043e-01],\n",
              "         [ 1.8238e-01, -7.6064e-02, -1.5109e-03,  ..., -1.4532e-01,\n",
              "           1.4173e-01,  9.4654e-02],\n",
              "         [ 1.5974e-01, -3.0997e-02,  2.7993e-02,  ..., -2.1875e-01,\n",
              "           1.9105e-01, -4.7759e-02],\n",
              "         ...,\n",
              "         [ 2.8726e-01,  6.2903e-02,  1.9651e-02,  ..., -1.3937e-01,\n",
              "          -4.0017e-01, -3.9510e-03],\n",
              "         [ 2.8700e-01,  6.1975e-02,  1.9243e-02,  ..., -1.3787e-01,\n",
              "          -4.0011e-01, -4.0791e-03],\n",
              "         [ 2.8739e-01,  6.1736e-02,  1.9519e-02,  ..., -1.3767e-01,\n",
              "          -3.9945e-01, -4.3995e-03]],\n",
              "\n",
              "        [[-3.0757e-02, -1.4190e-01, -2.3544e-02,  ...,  2.2695e-01,\n",
              "           4.2190e-02,  1.9027e-01],\n",
              "         [ 9.7086e-02, -6.8938e-02,  1.0541e-02,  ..., -1.2914e-01,\n",
              "           1.9258e-01,  7.4643e-02],\n",
              "         [ 1.0102e-01, -2.2707e-02,  8.6362e-03,  ..., -2.0044e-01,\n",
              "           2.5908e-01, -2.8121e-02],\n",
              "         ...,\n",
              "         [ 2.2486e-01,  9.8309e-02, -2.1018e-02,  ..., -1.2990e-01,\n",
              "          -3.3694e-01,  1.9893e-02],\n",
              "         [ 2.2561e-01,  9.8580e-02, -2.1355e-02,  ..., -1.2795e-01,\n",
              "          -3.3861e-01,  1.9287e-02],\n",
              "         [ 2.2661e-01,  9.8659e-02, -2.1357e-02,  ..., -1.2761e-01,\n",
              "          -3.3955e-01,  1.9011e-02]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.5143e-02, -1.2709e-01, -1.2373e-02,  ...,  2.5443e-01,\n",
              "           2.9362e-02,  1.8401e-01],\n",
              "         [ 9.2547e-02, -6.8764e-02,  9.6828e-03,  ..., -1.0467e-01,\n",
              "           1.5845e-01,  9.2928e-02],\n",
              "         [ 7.0905e-02, -2.7753e-02,  3.8029e-02,  ..., -1.5436e-01,\n",
              "           2.4760e-01, -2.1508e-02],\n",
              "         ...,\n",
              "         [ 1.9314e-01,  1.0059e-01,  3.1117e-02,  ..., -7.6773e-02,\n",
              "          -4.4561e-01, -5.1245e-04],\n",
              "         [ 1.9095e-01,  1.0028e-01,  3.2421e-02,  ..., -7.8042e-02,\n",
              "          -4.4945e-01,  6.0385e-04],\n",
              "         [ 1.8873e-01,  9.9352e-02,  3.3595e-02,  ..., -7.9798e-02,\n",
              "          -4.5578e-01,  1.7091e-03]],\n",
              "\n",
              "        [[-2.2943e-02, -1.3709e-01, -1.7439e-02,  ...,  2.4568e-01,\n",
              "           3.6937e-02,  1.9565e-01],\n",
              "         [ 8.0793e-02, -8.5318e-02, -1.8878e-02,  ..., -1.3566e-01,\n",
              "           1.7817e-01,  1.2112e-01],\n",
              "         [ 5.0304e-02, -6.4362e-02, -1.3710e-03,  ..., -1.7443e-01,\n",
              "           2.6246e-01,  7.4737e-03],\n",
              "         ...,\n",
              "         [-1.7623e-01, -1.3758e-02,  3.0073e-01,  ..., -1.1994e-01,\n",
              "           3.9272e-04, -2.5592e-02],\n",
              "         [-2.6376e-01, -1.4785e-02,  3.6478e-01,  ..., -6.9887e-03,\n",
              "           3.0288e-02, -6.6200e-02],\n",
              "         [-2.5825e-01,  7.2269e-03,  3.2424e-01,  ...,  1.3763e-01,\n",
              "           2.2313e-02, -8.0961e-02]],\n",
              "\n",
              "        [[ 6.4495e-03, -1.4651e-01, -1.7213e-02,  ...,  2.3372e-01,\n",
              "           2.4673e-02,  1.7573e-01],\n",
              "         [ 1.0992e-01, -5.3213e-02,  2.5519e-02,  ..., -1.0958e-01,\n",
              "           1.3935e-01,  9.2881e-02],\n",
              "         [ 7.7984e-02, -6.0822e-03,  5.2618e-02,  ..., -1.7556e-01,\n",
              "           2.1070e-01, -3.2668e-02],\n",
              "         ...,\n",
              "         [ 2.2052e-01,  1.1893e-01,  3.8744e-02,  ..., -6.4763e-02,\n",
              "          -3.8759e-01, -6.3891e-03],\n",
              "         [ 2.2097e-01,  1.1824e-01,  3.9431e-02,  ..., -6.6059e-02,\n",
              "          -3.8941e-01, -5.9452e-03],\n",
              "         [ 2.2158e-01,  1.1787e-01,  4.0339e-02,  ..., -6.8050e-02,\n",
              "          -3.9135e-01, -6.2366e-03]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(real_features))\n",
        "val_size = len(real_features) - train_size\n",
        "train_real, val_real = random_split(real_features, [train_size, val_size])\n",
        "train_deepfake, val_deepfake = random_split(deepfake_features, [train_size, val_size])\n"
      ],
      "metadata": {
        "id": "mhkvrReAF-1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for training and validation sets\n",
        "train_dataset = MyDataset(train_real, train_deepfake)\n",
        "val_dataset = MyDataset(val_real, val_deepfake)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "bYcpZR0xGBVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation metrics function\n",
        "def evaluate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay_epoch epochs\"\"\"\n",
        "    lr = initial_lr * (0.1**(epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Define a function to calculate moving averages\n",
        "def moving_average(data, window_size):\n",
        "    \"\"\"Calculate the moving average of data using a window size.\"\"\"\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')"
      ],
      "metadata": {
        "id": "C-Z8UlyQMvn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 1"
      ],
      "metadata": {
        "id": "lRtud1lE5luq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "    super(Generator, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Define the layers\n",
        "    self.layers = nn.ModuleList()\n",
        "    self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "    self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers[:-1]:\n",
        "      x = F.relu(layer(x))\n",
        "    x = self.layers[-1](x)\n",
        "    return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator(Generator):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm):\n",
        "        super(DPGenerator, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.noise_multiplier = noise_multiplier\n",
        "\n",
        "  def forward(self, x):\n",
        "      return super(DPGenerator, self).forward(x)\n",
        "\n",
        "  def backward(self, loss):\n",
        "      loss.backward()\n",
        "      for param in self.parameters():\n",
        "          if param.grad is not None:\n",
        "              param.grad += torch.randn_like(param.grad) * self.noise_multiplier\n",
        "              param.grad = torch.clamp(param.grad, -self.max_grad_norm, self.max_grad_norm)"
      ],
      "metadata": {
        "id": "8zObOanL5erP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = DPGenerator(input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "nteMvITmGC8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "ZCi7BmmdGJeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model(real_features)\n",
        "        loss = criterion(output, deepfake_features)\n",
        "        model.backward(loss)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SdmPbTeYYZw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 2"
      ],
      "metadata": {
        "id": "heneizAW8hUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator2, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator2(Generator2):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, max_grad_norm):\n",
        "          super(DPGenerator2, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.noise_log_std = nn.Parameter(torch.zeros(1))  # Trainable log std for noise\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "\n",
        "    def forward(self, x):\n",
        "      return super(DPGenerator2, self).forward(x)\n",
        "\n",
        "    def backward(self, loss):\n",
        "      loss.backward()\n",
        "      for param in self.parameters():\n",
        "        if param.grad is not None:\n",
        "          noise = torch.randn_like(param.grad) * torch.exp(self.noise_log_std)\n",
        "          param.grad += noise\n",
        "          param.grad = torch.clamp(param.grad, -self.max_grad_norm, self.max_grad_norm)"
      ],
      "metadata": {
        "id": "-d1UL-x58g_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model2 = DPGenerator2(input_size, hidden_size, output_size, num_layers, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer2 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion2 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "kL6oUuJm8g7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "MH8-MXJe8g0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer2.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model2(real_features)\n",
        "        loss = criterion2(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model2.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model2(real_features)\n",
        "            loss = criterion2(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fpVeqHQyBvMi",
        "outputId": "ca3f6219-4f95-4918-97ca-aa018c15f404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [1/1000], Validation Loss: 0.0297\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [2/1000], Validation Loss: 0.0297\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [3/1000], Validation Loss: 0.0297\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [4/1000], Validation Loss: 0.0297\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [5/1000], Validation Loss: 0.0297\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [6/1000], Validation Loss: 0.0297\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [7/1000], Validation Loss: 0.0297\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [8/1000], Validation Loss: 0.0297\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [9/1000], Validation Loss: 0.0297\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [10/1000], Validation Loss: 0.0297\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [11/1000], Validation Loss: 0.0297\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [12/1000], Validation Loss: 0.0297\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [13/1000], Validation Loss: 0.0297\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [14/1000], Validation Loss: 0.0297\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [15/1000], Validation Loss: 0.0297\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [16/1000], Validation Loss: 0.0297\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [17/1000], Validation Loss: 0.0297\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [18/1000], Validation Loss: 0.0297\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [19/1000], Validation Loss: 0.0297\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [20/1000], Validation Loss: 0.0297\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [21/1000], Validation Loss: 0.0297\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [22/1000], Validation Loss: 0.0297\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [23/1000], Validation Loss: 0.0297\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [24/1000], Validation Loss: 0.0297\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [25/1000], Validation Loss: 0.0297\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [26/1000], Validation Loss: 0.0297\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [27/1000], Validation Loss: 0.0297\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [28/1000], Validation Loss: 0.0297\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [29/1000], Validation Loss: 0.0297\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [30/1000], Validation Loss: 0.0297\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [31/1000], Validation Loss: 0.0297\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [32/1000], Validation Loss: 0.0297\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [33/1000], Validation Loss: 0.0297\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [34/1000], Validation Loss: 0.0297\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [35/1000], Validation Loss: 0.0297\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [36/1000], Validation Loss: 0.0297\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [37/1000], Validation Loss: 0.0297\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [38/1000], Validation Loss: 0.0297\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [39/1000], Validation Loss: 0.0297\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [40/1000], Validation Loss: 0.0297\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [41/1000], Validation Loss: 0.0297\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [42/1000], Validation Loss: 0.0297\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [43/1000], Validation Loss: 0.0297\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [44/1000], Validation Loss: 0.0297\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [45/1000], Validation Loss: 0.0297\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [46/1000], Validation Loss: 0.0297\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [47/1000], Validation Loss: 0.0297\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [48/1000], Validation Loss: 0.0297\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [49/1000], Validation Loss: 0.0297\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [50/1000], Validation Loss: 0.0297\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [51/1000], Validation Loss: 0.0297\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [52/1000], Validation Loss: 0.0297\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [53/1000], Validation Loss: 0.0297\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [54/1000], Validation Loss: 0.0297\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [55/1000], Validation Loss: 0.0297\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [56/1000], Validation Loss: 0.0297\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [57/1000], Validation Loss: 0.0297\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [58/1000], Validation Loss: 0.0297\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [59/1000], Validation Loss: 0.0297\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [60/1000], Validation Loss: 0.0297\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [61/1000], Validation Loss: 0.0297\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [62/1000], Validation Loss: 0.0297\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [63/1000], Validation Loss: 0.0297\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [64/1000], Validation Loss: 0.0297\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [65/1000], Validation Loss: 0.0297\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [66/1000], Validation Loss: 0.0297\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [67/1000], Validation Loss: 0.0297\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [68/1000], Validation Loss: 0.0297\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [69/1000], Validation Loss: 0.0297\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [70/1000], Validation Loss: 0.0297\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [71/1000], Validation Loss: 0.0297\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [72/1000], Validation Loss: 0.0297\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [73/1000], Validation Loss: 0.0297\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [74/1000], Validation Loss: 0.0297\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [75/1000], Validation Loss: 0.0297\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [76/1000], Validation Loss: 0.0297\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [77/1000], Validation Loss: 0.0297\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [78/1000], Validation Loss: 0.0297\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [79/1000], Validation Loss: 0.0297\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [80/1000], Validation Loss: 0.0297\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [81/1000], Validation Loss: 0.0297\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [82/1000], Validation Loss: 0.0297\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [83/1000], Validation Loss: 0.0297\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [84/1000], Validation Loss: 0.0297\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [85/1000], Validation Loss: 0.0297\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [86/1000], Validation Loss: 0.0297\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [87/1000], Validation Loss: 0.0297\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [88/1000], Validation Loss: 0.0297\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [89/1000], Validation Loss: 0.0297\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [90/1000], Validation Loss: 0.0297\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [91/1000], Validation Loss: 0.0297\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [92/1000], Validation Loss: 0.0297\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [93/1000], Validation Loss: 0.0297\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [94/1000], Validation Loss: 0.0297\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [95/1000], Validation Loss: 0.0297\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [96/1000], Validation Loss: 0.0297\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [97/1000], Validation Loss: 0.0297\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [98/1000], Validation Loss: 0.0297\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [99/1000], Validation Loss: 0.0297\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [100/1000], Validation Loss: 0.0297\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [101/1000], Validation Loss: 0.0297\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [102/1000], Validation Loss: 0.0297\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [103/1000], Validation Loss: 0.0297\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [104/1000], Validation Loss: 0.0297\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [105/1000], Validation Loss: 0.0297\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [106/1000], Validation Loss: 0.0297\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [107/1000], Validation Loss: 0.0297\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [108/1000], Validation Loss: 0.0297\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [109/1000], Validation Loss: 0.0297\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [110/1000], Validation Loss: 0.0297\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [111/1000], Validation Loss: 0.0297\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [112/1000], Validation Loss: 0.0297\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [113/1000], Validation Loss: 0.0297\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [114/1000], Validation Loss: 0.0297\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [115/1000], Validation Loss: 0.0297\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [116/1000], Validation Loss: 0.0297\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [117/1000], Validation Loss: 0.0297\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [118/1000], Validation Loss: 0.0297\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [119/1000], Validation Loss: 0.0297\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [120/1000], Validation Loss: 0.0297\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [121/1000], Validation Loss: 0.0297\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [122/1000], Validation Loss: 0.0297\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [123/1000], Validation Loss: 0.0297\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [124/1000], Validation Loss: 0.0297\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [125/1000], Validation Loss: 0.0297\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [126/1000], Validation Loss: 0.0297\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [127/1000], Validation Loss: 0.0297\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [128/1000], Validation Loss: 0.0297\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [129/1000], Validation Loss: 0.0297\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [130/1000], Validation Loss: 0.0297\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [131/1000], Validation Loss: 0.0297\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [132/1000], Validation Loss: 0.0297\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [133/1000], Validation Loss: 0.0297\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [134/1000], Validation Loss: 0.0297\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [135/1000], Validation Loss: 0.0297\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [136/1000], Validation Loss: 0.0297\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [137/1000], Validation Loss: 0.0297\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [138/1000], Validation Loss: 0.0297\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [139/1000], Validation Loss: 0.0297\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [140/1000], Validation Loss: 0.0297\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [141/1000], Validation Loss: 0.0297\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [142/1000], Validation Loss: 0.0297\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [143/1000], Validation Loss: 0.0297\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [144/1000], Validation Loss: 0.0297\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [145/1000], Validation Loss: 0.0297\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [146/1000], Validation Loss: 0.0297\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [147/1000], Validation Loss: 0.0297\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [148/1000], Validation Loss: 0.0297\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [149/1000], Validation Loss: 0.0297\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [150/1000], Validation Loss: 0.0297\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [151/1000], Validation Loss: 0.0297\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [152/1000], Validation Loss: 0.0297\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [153/1000], Validation Loss: 0.0297\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [154/1000], Validation Loss: 0.0297\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [155/1000], Validation Loss: 0.0297\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [156/1000], Validation Loss: 0.0297\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [157/1000], Validation Loss: 0.0297\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [158/1000], Validation Loss: 0.0297\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [159/1000], Validation Loss: 0.0297\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [160/1000], Validation Loss: 0.0297\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [161/1000], Validation Loss: 0.0297\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [162/1000], Validation Loss: 0.0297\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [163/1000], Validation Loss: 0.0297\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [164/1000], Validation Loss: 0.0297\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [165/1000], Validation Loss: 0.0297\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [166/1000], Validation Loss: 0.0297\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [167/1000], Validation Loss: 0.0297\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [168/1000], Validation Loss: 0.0297\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [169/1000], Validation Loss: 0.0297\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [170/1000], Validation Loss: 0.0297\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [171/1000], Validation Loss: 0.0297\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [172/1000], Validation Loss: 0.0297\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [173/1000], Validation Loss: 0.0297\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [174/1000], Validation Loss: 0.0297\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [175/1000], Validation Loss: 0.0297\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [176/1000], Validation Loss: 0.0297\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [177/1000], Validation Loss: 0.0297\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [178/1000], Validation Loss: 0.0297\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [179/1000], Validation Loss: 0.0297\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [180/1000], Validation Loss: 0.0297\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [181/1000], Validation Loss: 0.0297\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [182/1000], Validation Loss: 0.0297\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [183/1000], Validation Loss: 0.0297\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [184/1000], Validation Loss: 0.0297\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [185/1000], Validation Loss: 0.0297\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [186/1000], Validation Loss: 0.0297\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [187/1000], Validation Loss: 0.0297\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [188/1000], Validation Loss: 0.0297\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [189/1000], Validation Loss: 0.0297\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [190/1000], Validation Loss: 0.0297\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [191/1000], Validation Loss: 0.0297\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [192/1000], Validation Loss: 0.0297\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [193/1000], Validation Loss: 0.0297\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [194/1000], Validation Loss: 0.0297\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [195/1000], Validation Loss: 0.0297\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [196/1000], Validation Loss: 0.0297\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [197/1000], Validation Loss: 0.0297\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [198/1000], Validation Loss: 0.0297\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [199/1000], Validation Loss: 0.0297\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [200/1000], Validation Loss: 0.0297\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [201/1000], Validation Loss: 0.0297\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [202/1000], Validation Loss: 0.0297\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [203/1000], Validation Loss: 0.0297\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [204/1000], Validation Loss: 0.0297\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [205/1000], Validation Loss: 0.0297\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [206/1000], Validation Loss: 0.0297\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [207/1000], Validation Loss: 0.0297\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [208/1000], Validation Loss: 0.0297\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [209/1000], Validation Loss: 0.0297\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [210/1000], Validation Loss: 0.0297\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [211/1000], Validation Loss: 0.0297\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [212/1000], Validation Loss: 0.0297\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [213/1000], Validation Loss: 0.0297\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [214/1000], Validation Loss: 0.0297\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [215/1000], Validation Loss: 0.0297\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0285\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [216/1000], Validation Loss: 0.0297\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [217/1000], Validation Loss: 0.0297\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [218/1000], Validation Loss: 0.0297\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [219/1000], Validation Loss: 0.0297\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [220/1000], Validation Loss: 0.0297\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [221/1000], Validation Loss: 0.0297\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [222/1000], Validation Loss: 0.0297\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [223/1000], Validation Loss: 0.0297\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [224/1000], Validation Loss: 0.0297\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [225/1000], Validation Loss: 0.0297\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [226/1000], Validation Loss: 0.0297\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [227/1000], Validation Loss: 0.0297\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [228/1000], Validation Loss: 0.0297\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [229/1000], Validation Loss: 0.0297\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [230/1000], Validation Loss: 0.0297\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [231/1000], Validation Loss: 0.0297\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [232/1000], Validation Loss: 0.0297\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [233/1000], Validation Loss: 0.0297\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [234/1000], Validation Loss: 0.0297\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [235/1000], Validation Loss: 0.0297\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [236/1000], Validation Loss: 0.0297\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [237/1000], Validation Loss: 0.0297\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [238/1000], Validation Loss: 0.0297\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [239/1000], Validation Loss: 0.0297\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [240/1000], Validation Loss: 0.0297\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [241/1000], Validation Loss: 0.0297\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [242/1000], Validation Loss: 0.0297\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [243/1000], Validation Loss: 0.0297\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [244/1000], Validation Loss: 0.0297\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [245/1000], Validation Loss: 0.0297\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [246/1000], Validation Loss: 0.0297\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [247/1000], Validation Loss: 0.0297\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [248/1000], Validation Loss: 0.0297\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [249/1000], Validation Loss: 0.0297\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [250/1000], Validation Loss: 0.0297\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [251/1000], Validation Loss: 0.0297\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [252/1000], Validation Loss: 0.0297\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [253/1000], Validation Loss: 0.0297\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [254/1000], Validation Loss: 0.0297\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0284\n",
            "Epoch [255/1000], Validation Loss: 0.0297\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [256/1000], Validation Loss: 0.0297\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [257/1000], Validation Loss: 0.0297\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [258/1000], Validation Loss: 0.0297\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [259/1000], Validation Loss: 0.0297\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [260/1000], Validation Loss: 0.0297\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [261/1000], Validation Loss: 0.0297\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [262/1000], Validation Loss: 0.0297\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [263/1000], Validation Loss: 0.0297\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [264/1000], Validation Loss: 0.0297\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [265/1000], Validation Loss: 0.0297\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [266/1000], Validation Loss: 0.0297\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [267/1000], Validation Loss: 0.0297\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [268/1000], Validation Loss: 0.0297\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [269/1000], Validation Loss: 0.0297\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [270/1000], Validation Loss: 0.0297\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [271/1000], Validation Loss: 0.0297\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [272/1000], Validation Loss: 0.0297\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [273/1000], Validation Loss: 0.0297\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [274/1000], Validation Loss: 0.0297\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [275/1000], Validation Loss: 0.0297\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [276/1000], Validation Loss: 0.0297\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [277/1000], Validation Loss: 0.0297\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [278/1000], Validation Loss: 0.0297\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [279/1000], Validation Loss: 0.0297\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [280/1000], Validation Loss: 0.0297\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [281/1000], Validation Loss: 0.0297\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [282/1000], Validation Loss: 0.0297\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [283/1000], Validation Loss: 0.0297\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [284/1000], Validation Loss: 0.0297\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [285/1000], Validation Loss: 0.0297\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [286/1000], Validation Loss: 0.0297\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [287/1000], Validation Loss: 0.0297\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [288/1000], Validation Loss: 0.0297\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [289/1000], Validation Loss: 0.0297\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [290/1000], Validation Loss: 0.0297\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [291/1000], Validation Loss: 0.0297\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [292/1000], Validation Loss: 0.0297\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [293/1000], Validation Loss: 0.0297\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [294/1000], Validation Loss: 0.0297\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [295/1000], Validation Loss: 0.0297\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [296/1000], Validation Loss: 0.0297\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [297/1000], Validation Loss: 0.0297\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [298/1000], Validation Loss: 0.0297\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [299/1000], Validation Loss: 0.0297\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [300/1000], Validation Loss: 0.0297\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [301/1000], Validation Loss: 0.0297\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [302/1000], Validation Loss: 0.0297\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [303/1000], Validation Loss: 0.0297\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [304/1000], Validation Loss: 0.0297\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [305/1000], Validation Loss: 0.0297\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [306/1000], Validation Loss: 0.0297\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [307/1000], Validation Loss: 0.0297\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [308/1000], Validation Loss: 0.0297\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [309/1000], Validation Loss: 0.0297\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [310/1000], Validation Loss: 0.0297\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [311/1000], Validation Loss: 0.0297\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [312/1000], Validation Loss: 0.0297\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [313/1000], Validation Loss: 0.0297\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [314/1000], Validation Loss: 0.0297\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [315/1000], Validation Loss: 0.0297\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [316/1000], Validation Loss: 0.0297\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [317/1000], Validation Loss: 0.0297\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [318/1000], Validation Loss: 0.0297\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [319/1000], Validation Loss: 0.0297\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [320/1000], Validation Loss: 0.0297\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [321/1000], Validation Loss: 0.0297\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [322/1000], Validation Loss: 0.0297\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [323/1000], Validation Loss: 0.0297\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [324/1000], Validation Loss: 0.0297\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [325/1000], Validation Loss: 0.0297\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [326/1000], Validation Loss: 0.0297\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [327/1000], Validation Loss: 0.0297\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [328/1000], Validation Loss: 0.0297\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [329/1000], Validation Loss: 0.0297\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [330/1000], Validation Loss: 0.0297\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [331/1000], Validation Loss: 0.0297\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [332/1000], Validation Loss: 0.0297\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [333/1000], Validation Loss: 0.0297\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [334/1000], Validation Loss: 0.0297\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [335/1000], Validation Loss: 0.0297\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [336/1000], Validation Loss: 0.0297\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [337/1000], Validation Loss: 0.0297\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [338/1000], Validation Loss: 0.0297\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [339/1000], Validation Loss: 0.0297\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [340/1000], Validation Loss: 0.0297\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [341/1000], Validation Loss: 0.0297\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [342/1000], Validation Loss: 0.0297\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [343/1000], Validation Loss: 0.0297\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [344/1000], Validation Loss: 0.0297\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [345/1000], Validation Loss: 0.0297\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [346/1000], Validation Loss: 0.0297\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [347/1000], Validation Loss: 0.0297\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [348/1000], Validation Loss: 0.0297\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [349/1000], Validation Loss: 0.0297\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [350/1000], Validation Loss: 0.0297\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [351/1000], Validation Loss: 0.0297\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [352/1000], Validation Loss: 0.0297\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [353/1000], Validation Loss: 0.0297\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [354/1000], Validation Loss: 0.0297\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [355/1000], Validation Loss: 0.0297\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [356/1000], Validation Loss: 0.0297\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [357/1000], Validation Loss: 0.0297\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [358/1000], Validation Loss: 0.0297\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [359/1000], Validation Loss: 0.0297\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [360/1000], Validation Loss: 0.0297\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [361/1000], Validation Loss: 0.0297\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [362/1000], Validation Loss: 0.0297\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [363/1000], Validation Loss: 0.0297\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [364/1000], Validation Loss: 0.0297\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [365/1000], Validation Loss: 0.0297\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [366/1000], Validation Loss: 0.0297\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [367/1000], Validation Loss: 0.0297\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [368/1000], Validation Loss: 0.0297\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [369/1000], Validation Loss: 0.0297\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [370/1000], Validation Loss: 0.0297\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [371/1000], Validation Loss: 0.0297\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [372/1000], Validation Loss: 0.0297\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [373/1000], Validation Loss: 0.0297\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [374/1000], Validation Loss: 0.0297\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [375/1000], Validation Loss: 0.0297\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [376/1000], Validation Loss: 0.0297\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [377/1000], Validation Loss: 0.0297\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [378/1000], Validation Loss: 0.0297\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [379/1000], Validation Loss: 0.0297\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [380/1000], Validation Loss: 0.0297\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [381/1000], Validation Loss: 0.0297\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [382/1000], Validation Loss: 0.0297\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [383/1000], Validation Loss: 0.0297\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [384/1000], Validation Loss: 0.0297\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [385/1000], Validation Loss: 0.0297\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [386/1000], Validation Loss: 0.0297\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [387/1000], Validation Loss: 0.0297\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [388/1000], Validation Loss: 0.0297\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [389/1000], Validation Loss: 0.0297\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [390/1000], Validation Loss: 0.0297\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [391/1000], Validation Loss: 0.0297\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [392/1000], Validation Loss: 0.0297\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [393/1000], Validation Loss: 0.0297\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [394/1000], Validation Loss: 0.0297\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [395/1000], Validation Loss: 0.0297\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [396/1000], Validation Loss: 0.0297\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [397/1000], Validation Loss: 0.0297\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [398/1000], Validation Loss: 0.0297\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [399/1000], Validation Loss: 0.0297\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [400/1000], Validation Loss: 0.0297\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [401/1000], Validation Loss: 0.0297\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [402/1000], Validation Loss: 0.0297\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [403/1000], Validation Loss: 0.0297\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [404/1000], Validation Loss: 0.0297\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [405/1000], Validation Loss: 0.0297\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [406/1000], Validation Loss: 0.0297\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [407/1000], Validation Loss: 0.0297\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [408/1000], Validation Loss: 0.0297\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [409/1000], Validation Loss: 0.0297\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [410/1000], Validation Loss: 0.0297\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [411/1000], Validation Loss: 0.0297\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [412/1000], Validation Loss: 0.0297\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [413/1000], Validation Loss: 0.0297\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [414/1000], Validation Loss: 0.0297\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [415/1000], Validation Loss: 0.0297\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [416/1000], Validation Loss: 0.0297\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [417/1000], Validation Loss: 0.0297\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [418/1000], Validation Loss: 0.0297\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [419/1000], Validation Loss: 0.0297\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [420/1000], Validation Loss: 0.0297\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [421/1000], Validation Loss: 0.0297\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [422/1000], Validation Loss: 0.0297\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [423/1000], Validation Loss: 0.0297\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [424/1000], Validation Loss: 0.0297\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [425/1000], Validation Loss: 0.0297\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [426/1000], Validation Loss: 0.0297\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [427/1000], Validation Loss: 0.0297\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [428/1000], Validation Loss: 0.0297\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [429/1000], Validation Loss: 0.0297\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [430/1000], Validation Loss: 0.0297\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [431/1000], Validation Loss: 0.0297\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [432/1000], Validation Loss: 0.0297\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [433/1000], Validation Loss: 0.0297\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [434/1000], Validation Loss: 0.0297\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [435/1000], Validation Loss: 0.0297\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [436/1000], Validation Loss: 0.0297\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [437/1000], Validation Loss: 0.0297\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [438/1000], Validation Loss: 0.0297\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [439/1000], Validation Loss: 0.0297\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [440/1000], Validation Loss: 0.0297\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [441/1000], Validation Loss: 0.0297\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [442/1000], Validation Loss: 0.0297\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [443/1000], Validation Loss: 0.0297\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [444/1000], Validation Loss: 0.0297\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [445/1000], Validation Loss: 0.0297\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [446/1000], Validation Loss: 0.0297\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [447/1000], Validation Loss: 0.0297\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [448/1000], Validation Loss: 0.0297\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [449/1000], Validation Loss: 0.0297\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [450/1000], Validation Loss: 0.0297\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [451/1000], Validation Loss: 0.0297\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [452/1000], Validation Loss: 0.0297\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [453/1000], Validation Loss: 0.0297\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [454/1000], Validation Loss: 0.0297\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [455/1000], Validation Loss: 0.0297\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [456/1000], Validation Loss: 0.0297\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [457/1000], Validation Loss: 0.0297\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [458/1000], Validation Loss: 0.0297\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [459/1000], Validation Loss: 0.0297\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [460/1000], Validation Loss: 0.0297\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [461/1000], Validation Loss: 0.0297\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [462/1000], Validation Loss: 0.0297\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [463/1000], Validation Loss: 0.0297\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [464/1000], Validation Loss: 0.0297\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [465/1000], Validation Loss: 0.0297\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [466/1000], Validation Loss: 0.0297\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [467/1000], Validation Loss: 0.0297\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [468/1000], Validation Loss: 0.0297\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [469/1000], Validation Loss: 0.0297\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [470/1000], Validation Loss: 0.0297\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [471/1000], Validation Loss: 0.0297\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [472/1000], Validation Loss: 0.0297\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [473/1000], Validation Loss: 0.0297\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [474/1000], Validation Loss: 0.0297\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [475/1000], Validation Loss: 0.0297\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [476/1000], Validation Loss: 0.0297\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [477/1000], Validation Loss: 0.0297\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [478/1000], Validation Loss: 0.0297\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [479/1000], Validation Loss: 0.0297\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [480/1000], Validation Loss: 0.0297\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [481/1000], Validation Loss: 0.0297\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [482/1000], Validation Loss: 0.0297\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [483/1000], Validation Loss: 0.0297\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [484/1000], Validation Loss: 0.0297\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [485/1000], Validation Loss: 0.0297\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [486/1000], Validation Loss: 0.0297\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [487/1000], Validation Loss: 0.0297\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [488/1000], Validation Loss: 0.0297\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [489/1000], Validation Loss: 0.0297\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [490/1000], Validation Loss: 0.0297\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [491/1000], Validation Loss: 0.0297\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [492/1000], Validation Loss: 0.0297\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [493/1000], Validation Loss: 0.0297\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [494/1000], Validation Loss: 0.0297\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [495/1000], Validation Loss: 0.0297\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [496/1000], Validation Loss: 0.0297\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [497/1000], Validation Loss: 0.0297\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [498/1000], Validation Loss: 0.0297\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [499/1000], Validation Loss: 0.0297\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [500/1000], Validation Loss: 0.0297\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [501/1000], Validation Loss: 0.0297\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [502/1000], Validation Loss: 0.0297\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [503/1000], Validation Loss: 0.0297\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [504/1000], Validation Loss: 0.0297\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [505/1000], Validation Loss: 0.0297\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [506/1000], Validation Loss: 0.0297\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [507/1000], Validation Loss: 0.0297\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [508/1000], Validation Loss: 0.0297\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [509/1000], Validation Loss: 0.0297\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [510/1000], Validation Loss: 0.0297\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [511/1000], Validation Loss: 0.0297\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [512/1000], Validation Loss: 0.0297\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [513/1000], Validation Loss: 0.0297\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [514/1000], Validation Loss: 0.0297\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [515/1000], Validation Loss: 0.0297\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [516/1000], Validation Loss: 0.0297\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [517/1000], Validation Loss: 0.0297\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [518/1000], Validation Loss: 0.0297\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [519/1000], Validation Loss: 0.0297\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [520/1000], Validation Loss: 0.0297\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [521/1000], Validation Loss: 0.0297\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [522/1000], Validation Loss: 0.0297\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [523/1000], Validation Loss: 0.0297\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [524/1000], Validation Loss: 0.0297\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [525/1000], Validation Loss: 0.0297\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [526/1000], Validation Loss: 0.0297\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [527/1000], Validation Loss: 0.0297\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [528/1000], Validation Loss: 0.0297\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [529/1000], Validation Loss: 0.0297\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [530/1000], Validation Loss: 0.0297\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [531/1000], Validation Loss: 0.0297\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [532/1000], Validation Loss: 0.0297\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [533/1000], Validation Loss: 0.0297\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [534/1000], Validation Loss: 0.0297\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [535/1000], Validation Loss: 0.0297\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [536/1000], Validation Loss: 0.0297\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [537/1000], Validation Loss: 0.0297\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [538/1000], Validation Loss: 0.0297\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [539/1000], Validation Loss: 0.0297\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [540/1000], Validation Loss: 0.0297\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [541/1000], Validation Loss: 0.0297\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [542/1000], Validation Loss: 0.0297\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [543/1000], Validation Loss: 0.0297\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [544/1000], Validation Loss: 0.0297\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [545/1000], Validation Loss: 0.0297\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [546/1000], Validation Loss: 0.0297\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [547/1000], Validation Loss: 0.0297\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [548/1000], Validation Loss: 0.0297\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [549/1000], Validation Loss: 0.0297\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [550/1000], Validation Loss: 0.0297\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [551/1000], Validation Loss: 0.0297\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [552/1000], Validation Loss: 0.0297\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [553/1000], Validation Loss: 0.0297\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [554/1000], Validation Loss: 0.0297\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [555/1000], Validation Loss: 0.0297\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [556/1000], Validation Loss: 0.0297\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [557/1000], Validation Loss: 0.0297\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [558/1000], Validation Loss: 0.0297\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [559/1000], Validation Loss: 0.0297\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [560/1000], Validation Loss: 0.0297\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [561/1000], Validation Loss: 0.0297\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [562/1000], Validation Loss: 0.0297\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [563/1000], Validation Loss: 0.0297\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [564/1000], Validation Loss: 0.0297\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [565/1000], Validation Loss: 0.0297\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [566/1000], Validation Loss: 0.0297\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [567/1000], Validation Loss: 0.0297\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [568/1000], Validation Loss: 0.0297\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [569/1000], Validation Loss: 0.0297\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [570/1000], Validation Loss: 0.0297\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [571/1000], Validation Loss: 0.0297\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [572/1000], Validation Loss: 0.0297\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [573/1000], Validation Loss: 0.0297\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [574/1000], Validation Loss: 0.0297\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [575/1000], Validation Loss: 0.0297\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [576/1000], Validation Loss: 0.0297\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [577/1000], Validation Loss: 0.0297\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [578/1000], Validation Loss: 0.0297\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [579/1000], Validation Loss: 0.0297\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [580/1000], Validation Loss: 0.0297\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [581/1000], Validation Loss: 0.0297\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [582/1000], Validation Loss: 0.0297\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [583/1000], Validation Loss: 0.0297\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [584/1000], Validation Loss: 0.0297\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [585/1000], Validation Loss: 0.0297\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [586/1000], Validation Loss: 0.0297\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [587/1000], Validation Loss: 0.0297\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [588/1000], Validation Loss: 0.0297\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [589/1000], Validation Loss: 0.0297\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [590/1000], Validation Loss: 0.0297\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [591/1000], Validation Loss: 0.0297\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [592/1000], Validation Loss: 0.0297\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [593/1000], Validation Loss: 0.0297\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [594/1000], Validation Loss: 0.0297\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [595/1000], Validation Loss: 0.0297\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [596/1000], Validation Loss: 0.0297\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [597/1000], Validation Loss: 0.0297\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [598/1000], Validation Loss: 0.0297\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [599/1000], Validation Loss: 0.0297\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [600/1000], Validation Loss: 0.0297\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [601/1000], Validation Loss: 0.0297\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [602/1000], Validation Loss: 0.0297\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [603/1000], Validation Loss: 0.0297\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [604/1000], Validation Loss: 0.0297\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [605/1000], Validation Loss: 0.0297\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [606/1000], Validation Loss: 0.0297\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [607/1000], Validation Loss: 0.0297\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [608/1000], Validation Loss: 0.0297\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [609/1000], Validation Loss: 0.0297\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [610/1000], Validation Loss: 0.0297\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [611/1000], Validation Loss: 0.0297\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [612/1000], Validation Loss: 0.0297\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [613/1000], Validation Loss: 0.0297\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [614/1000], Validation Loss: 0.0297\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [615/1000], Validation Loss: 0.0297\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [616/1000], Validation Loss: 0.0297\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [617/1000], Validation Loss: 0.0297\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [618/1000], Validation Loss: 0.0297\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [619/1000], Validation Loss: 0.0297\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [620/1000], Validation Loss: 0.0297\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [621/1000], Validation Loss: 0.0297\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [622/1000], Validation Loss: 0.0297\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [623/1000], Validation Loss: 0.0297\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [624/1000], Validation Loss: 0.0297\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [625/1000], Validation Loss: 0.0297\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [626/1000], Validation Loss: 0.0297\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [627/1000], Validation Loss: 0.0297\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [628/1000], Validation Loss: 0.0297\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [629/1000], Validation Loss: 0.0297\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [630/1000], Validation Loss: 0.0297\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [631/1000], Validation Loss: 0.0297\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [632/1000], Validation Loss: 0.0297\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [633/1000], Validation Loss: 0.0297\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [634/1000], Validation Loss: 0.0297\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [635/1000], Validation Loss: 0.0297\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [636/1000], Validation Loss: 0.0297\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [637/1000], Validation Loss: 0.0297\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [638/1000], Validation Loss: 0.0297\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [639/1000], Validation Loss: 0.0297\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [640/1000], Validation Loss: 0.0297\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [641/1000], Validation Loss: 0.0297\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [642/1000], Validation Loss: 0.0297\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [643/1000], Validation Loss: 0.0297\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [644/1000], Validation Loss: 0.0297\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [645/1000], Validation Loss: 0.0297\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [646/1000], Validation Loss: 0.0297\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [647/1000], Validation Loss: 0.0297\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [648/1000], Validation Loss: 0.0297\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [649/1000], Validation Loss: 0.0297\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [650/1000], Validation Loss: 0.0297\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [651/1000], Validation Loss: 0.0297\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [652/1000], Validation Loss: 0.0297\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [653/1000], Validation Loss: 0.0297\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [654/1000], Validation Loss: 0.0297\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [655/1000], Validation Loss: 0.0297\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [656/1000], Validation Loss: 0.0297\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [657/1000], Validation Loss: 0.0297\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [658/1000], Validation Loss: 0.0297\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [659/1000], Validation Loss: 0.0297\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [660/1000], Validation Loss: 0.0297\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [661/1000], Validation Loss: 0.0297\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [662/1000], Validation Loss: 0.0297\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [663/1000], Validation Loss: 0.0297\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [664/1000], Validation Loss: 0.0297\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [665/1000], Validation Loss: 0.0297\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [666/1000], Validation Loss: 0.0297\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [667/1000], Validation Loss: 0.0297\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [668/1000], Validation Loss: 0.0297\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [669/1000], Validation Loss: 0.0297\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [670/1000], Validation Loss: 0.0297\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [671/1000], Validation Loss: 0.0297\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [672/1000], Validation Loss: 0.0297\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [673/1000], Validation Loss: 0.0297\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [674/1000], Validation Loss: 0.0297\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [675/1000], Validation Loss: 0.0297\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [676/1000], Validation Loss: 0.0297\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [677/1000], Validation Loss: 0.0297\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [678/1000], Validation Loss: 0.0297\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [679/1000], Validation Loss: 0.0297\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [680/1000], Validation Loss: 0.0297\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [681/1000], Validation Loss: 0.0297\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [682/1000], Validation Loss: 0.0297\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [683/1000], Validation Loss: 0.0297\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [684/1000], Validation Loss: 0.0297\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [685/1000], Validation Loss: 0.0297\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [686/1000], Validation Loss: 0.0297\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [687/1000], Validation Loss: 0.0297\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [688/1000], Validation Loss: 0.0297\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [689/1000], Validation Loss: 0.0297\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [690/1000], Validation Loss: 0.0297\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [691/1000], Validation Loss: 0.0297\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [692/1000], Validation Loss: 0.0297\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [693/1000], Validation Loss: 0.0297\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [694/1000], Validation Loss: 0.0297\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [695/1000], Validation Loss: 0.0297\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [696/1000], Validation Loss: 0.0297\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [697/1000], Validation Loss: 0.0297\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [698/1000], Validation Loss: 0.0297\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [699/1000], Validation Loss: 0.0297\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [700/1000], Validation Loss: 0.0297\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [701/1000], Validation Loss: 0.0297\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [702/1000], Validation Loss: 0.0297\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [703/1000], Validation Loss: 0.0297\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [704/1000], Validation Loss: 0.0297\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [705/1000], Validation Loss: 0.0297\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [706/1000], Validation Loss: 0.0297\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [707/1000], Validation Loss: 0.0297\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [708/1000], Validation Loss: 0.0297\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [709/1000], Validation Loss: 0.0297\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0286\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [710/1000], Validation Loss: 0.0297\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [711/1000], Validation Loss: 0.0297\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [712/1000], Validation Loss: 0.0297\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [713/1000], Validation Loss: 0.0297\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [714/1000], Validation Loss: 0.0297\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [715/1000], Validation Loss: 0.0297\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [716/1000], Validation Loss: 0.0297\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [717/1000], Validation Loss: 0.0297\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [718/1000], Validation Loss: 0.0297\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [719/1000], Validation Loss: 0.0297\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [720/1000], Validation Loss: 0.0297\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [721/1000], Validation Loss: 0.0297\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [722/1000], Validation Loss: 0.0297\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [723/1000], Validation Loss: 0.0297\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [724/1000], Validation Loss: 0.0297\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [725/1000], Validation Loss: 0.0297\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [726/1000], Validation Loss: 0.0297\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [727/1000], Validation Loss: 0.0297\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [728/1000], Validation Loss: 0.0297\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [729/1000], Validation Loss: 0.0297\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [730/1000], Validation Loss: 0.0297\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0287\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [731/1000], Validation Loss: 0.0297\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [732/1000], Validation Loss: 0.0297\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [733/1000], Validation Loss: 0.0297\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [734/1000], Validation Loss: 0.0297\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [735/1000], Validation Loss: 0.0297\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [736/1000], Validation Loss: 0.0297\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [737/1000], Validation Loss: 0.0297\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [738/1000], Validation Loss: 0.0297\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [739/1000], Validation Loss: 0.0297\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [740/1000], Validation Loss: 0.0297\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [741/1000], Validation Loss: 0.0297\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [742/1000], Validation Loss: 0.0297\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [743/1000], Validation Loss: 0.0297\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [744/1000], Validation Loss: 0.0297\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [745/1000], Validation Loss: 0.0297\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [746/1000], Validation Loss: 0.0297\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [747/1000], Validation Loss: 0.0297\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [748/1000], Validation Loss: 0.0297\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [749/1000], Validation Loss: 0.0297\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [750/1000], Validation Loss: 0.0297\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [751/1000], Validation Loss: 0.0297\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [752/1000], Validation Loss: 0.0297\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [753/1000], Validation Loss: 0.0297\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [754/1000], Validation Loss: 0.0297\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [755/1000], Validation Loss: 0.0297\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [756/1000], Validation Loss: 0.0297\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [757/1000], Validation Loss: 0.0297\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [758/1000], Validation Loss: 0.0297\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [759/1000], Validation Loss: 0.0297\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [760/1000], Validation Loss: 0.0297\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [761/1000], Validation Loss: 0.0297\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [762/1000], Validation Loss: 0.0297\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [763/1000], Validation Loss: 0.0297\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [764/1000], Validation Loss: 0.0297\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [765/1000], Validation Loss: 0.0297\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [766/1000], Validation Loss: 0.0297\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [767/1000], Validation Loss: 0.0297\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [768/1000], Validation Loss: 0.0297\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [769/1000], Validation Loss: 0.0297\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [770/1000], Validation Loss: 0.0297\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [771/1000], Validation Loss: 0.0297\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0283\n",
            "Epoch [772/1000], Validation Loss: 0.0297\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [773/1000], Validation Loss: 0.0297\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [774/1000], Validation Loss: 0.0297\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [775/1000], Validation Loss: 0.0297\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [776/1000], Validation Loss: 0.0297\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [777/1000], Validation Loss: 0.0297\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [778/1000], Validation Loss: 0.0297\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [779/1000], Validation Loss: 0.0297\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [780/1000], Validation Loss: 0.0297\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [781/1000], Validation Loss: 0.0297\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [782/1000], Validation Loss: 0.0297\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [783/1000], Validation Loss: 0.0297\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [784/1000], Validation Loss: 0.0297\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [785/1000], Validation Loss: 0.0297\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [786/1000], Validation Loss: 0.0297\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [787/1000], Validation Loss: 0.0297\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [788/1000], Validation Loss: 0.0297\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [789/1000], Validation Loss: 0.0297\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [790/1000], Validation Loss: 0.0297\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [791/1000], Validation Loss: 0.0297\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [792/1000], Validation Loss: 0.0297\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [793/1000], Validation Loss: 0.0297\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [794/1000], Validation Loss: 0.0297\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [795/1000], Validation Loss: 0.0297\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [796/1000], Validation Loss: 0.0297\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [797/1000], Validation Loss: 0.0297\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [798/1000], Validation Loss: 0.0297\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [799/1000], Validation Loss: 0.0297\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [800/1000], Validation Loss: 0.0297\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [801/1000], Validation Loss: 0.0297\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [802/1000], Validation Loss: 0.0297\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [803/1000], Validation Loss: 0.0297\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [804/1000], Validation Loss: 0.0297\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [805/1000], Validation Loss: 0.0297\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [806/1000], Validation Loss: 0.0297\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [807/1000], Validation Loss: 0.0297\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [808/1000], Validation Loss: 0.0297\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [809/1000], Validation Loss: 0.0297\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [810/1000], Validation Loss: 0.0297\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [811/1000], Validation Loss: 0.0297\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [812/1000], Validation Loss: 0.0297\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [813/1000], Validation Loss: 0.0297\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [814/1000], Validation Loss: 0.0297\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [815/1000], Validation Loss: 0.0297\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [816/1000], Validation Loss: 0.0297\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [817/1000], Validation Loss: 0.0297\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [818/1000], Validation Loss: 0.0297\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [819/1000], Validation Loss: 0.0297\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [820/1000], Validation Loss: 0.0297\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [821/1000], Validation Loss: 0.0297\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [822/1000], Validation Loss: 0.0297\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [823/1000], Validation Loss: 0.0297\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [824/1000], Validation Loss: 0.0297\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [825/1000], Validation Loss: 0.0297\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [826/1000], Validation Loss: 0.0297\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [827/1000], Validation Loss: 0.0297\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [828/1000], Validation Loss: 0.0297\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [829/1000], Validation Loss: 0.0297\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [830/1000], Validation Loss: 0.0297\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [831/1000], Validation Loss: 0.0297\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [832/1000], Validation Loss: 0.0297\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [833/1000], Validation Loss: 0.0297\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [834/1000], Validation Loss: 0.0297\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [835/1000], Validation Loss: 0.0297\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [836/1000], Validation Loss: 0.0297\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [837/1000], Validation Loss: 0.0297\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [838/1000], Validation Loss: 0.0297\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0288\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [839/1000], Validation Loss: 0.0297\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [840/1000], Validation Loss: 0.0297\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [841/1000], Validation Loss: 0.0297\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [842/1000], Validation Loss: 0.0297\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [843/1000], Validation Loss: 0.0297\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [844/1000], Validation Loss: 0.0297\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [845/1000], Validation Loss: 0.0297\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [846/1000], Validation Loss: 0.0297\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [847/1000], Validation Loss: 0.0297\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [848/1000], Validation Loss: 0.0297\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [849/1000], Validation Loss: 0.0297\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [850/1000], Validation Loss: 0.0297\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0285\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [851/1000], Validation Loss: 0.0297\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [852/1000], Validation Loss: 0.0297\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [853/1000], Validation Loss: 0.0297\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [854/1000], Validation Loss: 0.0297\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [855/1000], Validation Loss: 0.0297\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [856/1000], Validation Loss: 0.0297\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [857/1000], Validation Loss: 0.0297\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [858/1000], Validation Loss: 0.0297\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [859/1000], Validation Loss: 0.0297\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [860/1000], Validation Loss: 0.0297\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [861/1000], Validation Loss: 0.0297\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [862/1000], Validation Loss: 0.0297\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [863/1000], Validation Loss: 0.0297\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [864/1000], Validation Loss: 0.0297\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [865/1000], Validation Loss: 0.0297\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [866/1000], Validation Loss: 0.0297\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [867/1000], Validation Loss: 0.0297\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [868/1000], Validation Loss: 0.0297\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [869/1000], Validation Loss: 0.0297\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [870/1000], Validation Loss: 0.0297\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [871/1000], Validation Loss: 0.0297\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [872/1000], Validation Loss: 0.0297\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [873/1000], Validation Loss: 0.0297\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [874/1000], Validation Loss: 0.0297\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [875/1000], Validation Loss: 0.0297\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [876/1000], Validation Loss: 0.0297\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [877/1000], Validation Loss: 0.0297\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0289\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [878/1000], Validation Loss: 0.0297\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [879/1000], Validation Loss: 0.0297\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [880/1000], Validation Loss: 0.0297\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [881/1000], Validation Loss: 0.0297\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [882/1000], Validation Loss: 0.0297\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [883/1000], Validation Loss: 0.0297\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [884/1000], Validation Loss: 0.0297\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [885/1000], Validation Loss: 0.0297\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [886/1000], Validation Loss: 0.0297\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [887/1000], Validation Loss: 0.0297\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [888/1000], Validation Loss: 0.0297\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [889/1000], Validation Loss: 0.0297\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [890/1000], Validation Loss: 0.0297\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [891/1000], Validation Loss: 0.0297\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [892/1000], Validation Loss: 0.0297\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [893/1000], Validation Loss: 0.0297\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [894/1000], Validation Loss: 0.0297\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [895/1000], Validation Loss: 0.0297\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [896/1000], Validation Loss: 0.0297\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [897/1000], Validation Loss: 0.0297\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [898/1000], Validation Loss: 0.0297\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [899/1000], Validation Loss: 0.0297\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [900/1000], Validation Loss: 0.0297\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [901/1000], Validation Loss: 0.0297\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [902/1000], Validation Loss: 0.0297\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [903/1000], Validation Loss: 0.0297\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [904/1000], Validation Loss: 0.0297\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [905/1000], Validation Loss: 0.0297\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [906/1000], Validation Loss: 0.0297\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [907/1000], Validation Loss: 0.0297\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [908/1000], Validation Loss: 0.0297\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [909/1000], Validation Loss: 0.0297\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [910/1000], Validation Loss: 0.0297\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [911/1000], Validation Loss: 0.0297\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [912/1000], Validation Loss: 0.0297\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [913/1000], Validation Loss: 0.0297\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [914/1000], Validation Loss: 0.0297\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [915/1000], Validation Loss: 0.0297\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [916/1000], Validation Loss: 0.0297\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [917/1000], Validation Loss: 0.0297\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [918/1000], Validation Loss: 0.0297\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [919/1000], Validation Loss: 0.0297\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [920/1000], Validation Loss: 0.0297\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [921/1000], Validation Loss: 0.0297\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [922/1000], Validation Loss: 0.0297\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [923/1000], Validation Loss: 0.0297\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [924/1000], Validation Loss: 0.0297\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [925/1000], Validation Loss: 0.0297\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [926/1000], Validation Loss: 0.0297\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [927/1000], Validation Loss: 0.0297\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [928/1000], Validation Loss: 0.0297\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [929/1000], Validation Loss: 0.0297\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [930/1000], Validation Loss: 0.0297\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [931/1000], Validation Loss: 0.0297\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [932/1000], Validation Loss: 0.0297\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [933/1000], Validation Loss: 0.0297\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [934/1000], Validation Loss: 0.0297\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [935/1000], Validation Loss: 0.0297\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [936/1000], Validation Loss: 0.0297\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [937/1000], Validation Loss: 0.0297\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [938/1000], Validation Loss: 0.0297\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [939/1000], Validation Loss: 0.0297\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [940/1000], Validation Loss: 0.0297\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [941/1000], Validation Loss: 0.0297\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [942/1000], Validation Loss: 0.0297\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [943/1000], Validation Loss: 0.0297\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [944/1000], Validation Loss: 0.0297\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [945/1000], Validation Loss: 0.0297\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0285\n",
            "Epoch [946/1000], Validation Loss: 0.0297\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [947/1000], Validation Loss: 0.0297\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [948/1000], Validation Loss: 0.0297\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [949/1000], Validation Loss: 0.0297\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [950/1000], Validation Loss: 0.0297\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [951/1000], Validation Loss: 0.0297\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0298\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0287\n",
            "Epoch [952/1000], Validation Loss: 0.0297\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [953/1000], Validation Loss: 0.0297\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [954/1000], Validation Loss: 0.0297\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [955/1000], Validation Loss: 0.0297\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [956/1000], Validation Loss: 0.0297\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [957/1000], Validation Loss: 0.0297\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [958/1000], Validation Loss: 0.0297\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [959/1000], Validation Loss: 0.0297\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [960/1000], Validation Loss: 0.0297\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [961/1000], Validation Loss: 0.0297\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [962/1000], Validation Loss: 0.0297\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [963/1000], Validation Loss: 0.0297\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [964/1000], Validation Loss: 0.0297\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [965/1000], Validation Loss: 0.0297\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0289\n",
            "Epoch [966/1000], Validation Loss: 0.0297\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [967/1000], Validation Loss: 0.0297\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [968/1000], Validation Loss: 0.0297\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [969/1000], Validation Loss: 0.0297\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [970/1000], Validation Loss: 0.0297\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [971/1000], Validation Loss: 0.0297\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [972/1000], Validation Loss: 0.0297\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0297\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0288\n",
            "Epoch [973/1000], Validation Loss: 0.0297\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [974/1000], Validation Loss: 0.0297\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [975/1000], Validation Loss: 0.0297\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0299\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0286\n",
            "Epoch [976/1000], Validation Loss: 0.0297\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [977/1000], Validation Loss: 0.0297\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [978/1000], Validation Loss: 0.0297\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [979/1000], Validation Loss: 0.0297\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [980/1000], Validation Loss: 0.0297\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0290\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [981/1000], Validation Loss: 0.0297\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [982/1000], Validation Loss: 0.0297\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0293\n",
            "Epoch [983/1000], Validation Loss: 0.0297\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [984/1000], Validation Loss: 0.0297\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [985/1000], Validation Loss: 0.0297\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0297\n",
            "Epoch [986/1000], Validation Loss: 0.0297\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0295\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0292\n",
            "Epoch [987/1000], Validation Loss: 0.0297\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [988/1000], Validation Loss: 0.0297\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0295\n",
            "Epoch [989/1000], Validation Loss: 0.0297\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0291\n",
            "Epoch [990/1000], Validation Loss: 0.0297\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [991/1000], Validation Loss: 0.0297\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [992/1000], Validation Loss: 0.0297\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [993/1000], Validation Loss: 0.0297\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0293\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [994/1000], Validation Loss: 0.0297\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [995/1000], Validation Loss: 0.0297\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [996/1000], Validation Loss: 0.0297\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0294\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0294\n",
            "Epoch [997/1000], Validation Loss: 0.0297\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0292\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0296\n",
            "Epoch [998/1000], Validation Loss: 0.0297\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0296\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0290\n",
            "Epoch [999/1000], Validation Loss: 0.0297\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0291\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [1000/1000], Validation Loss: 0.0297\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 3"
      ],
      "metadata": {
        "id": "8v7yjLSS51TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator3(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator3, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator3(Generator3):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, max_grad_norm):\n",
        "          super(DPGenerator3, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "          self.noise_multiplier = nn.Parameter(torch.tensor(1.0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = F.relu(layer(x))\n",
        "            # Add noise proportional to the noise multiplier\n",
        "            noise = torch.randn_like(x) * self.noise_multiplier\n",
        "            x = x + noise  # Use x = x + noise instead of inplace operation x += noise\n",
        "        x = self.layers[-1](x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GhQGwJUW5s05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model3 = DPGenerator3(input_size, hidden_size, output_size, num_layers, max_grad_norm).to(device)\n",
        "model3.noise_multiplier.data.fill_(noise_multiplier)\n",
        "\n",
        "\n",
        "# Define the loss function\n",
        "optimizer3 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion3 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "V5TCXM3o50Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []"
      ],
      "metadata": {
        "id": "VaVk1xZK6Dgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model3.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer3.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model3(real_features)\n",
        "        loss = criterion3(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer3.step()\n",
        "        train_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model3.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model3(real_features)\n",
        "            loss = criterion3(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bJjjJ0PrGMdm",
        "outputId": "7728e7f3-623e-4c65-e623-58acd21df6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [1/1000], Validation Loss: 0.0315\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [2/1000], Validation Loss: 0.0314\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [3/1000], Validation Loss: 0.0315\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [4/1000], Validation Loss: 0.0314\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [5/1000], Validation Loss: 0.0314\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [6/1000], Validation Loss: 0.0315\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [7/1000], Validation Loss: 0.0315\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [8/1000], Validation Loss: 0.0314\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [9/1000], Validation Loss: 0.0314\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [10/1000], Validation Loss: 0.0315\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [11/1000], Validation Loss: 0.0315\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [12/1000], Validation Loss: 0.0314\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [13/1000], Validation Loss: 0.0314\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [14/1000], Validation Loss: 0.0315\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [15/1000], Validation Loss: 0.0315\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [16/1000], Validation Loss: 0.0315\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [17/1000], Validation Loss: 0.0315\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [18/1000], Validation Loss: 0.0314\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [19/1000], Validation Loss: 0.0314\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [20/1000], Validation Loss: 0.0313\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [21/1000], Validation Loss: 0.0315\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [22/1000], Validation Loss: 0.0315\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [23/1000], Validation Loss: 0.0315\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [24/1000], Validation Loss: 0.0315\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [25/1000], Validation Loss: 0.0315\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [26/1000], Validation Loss: 0.0314\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [27/1000], Validation Loss: 0.0314\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [28/1000], Validation Loss: 0.0314\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [29/1000], Validation Loss: 0.0315\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [30/1000], Validation Loss: 0.0314\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [31/1000], Validation Loss: 0.0315\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [32/1000], Validation Loss: 0.0314\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [33/1000], Validation Loss: 0.0315\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [34/1000], Validation Loss: 0.0314\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [35/1000], Validation Loss: 0.0315\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [36/1000], Validation Loss: 0.0314\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [37/1000], Validation Loss: 0.0315\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [38/1000], Validation Loss: 0.0314\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [39/1000], Validation Loss: 0.0314\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [40/1000], Validation Loss: 0.0315\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [41/1000], Validation Loss: 0.0315\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [42/1000], Validation Loss: 0.0314\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [43/1000], Validation Loss: 0.0315\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [44/1000], Validation Loss: 0.0315\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [45/1000], Validation Loss: 0.0315\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [46/1000], Validation Loss: 0.0315\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [47/1000], Validation Loss: 0.0315\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [48/1000], Validation Loss: 0.0314\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [49/1000], Validation Loss: 0.0315\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [50/1000], Validation Loss: 0.0315\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [51/1000], Validation Loss: 0.0315\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [52/1000], Validation Loss: 0.0314\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [53/1000], Validation Loss: 0.0315\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [54/1000], Validation Loss: 0.0314\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [55/1000], Validation Loss: 0.0314\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [56/1000], Validation Loss: 0.0315\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [57/1000], Validation Loss: 0.0314\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [58/1000], Validation Loss: 0.0314\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [59/1000], Validation Loss: 0.0315\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [60/1000], Validation Loss: 0.0314\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [61/1000], Validation Loss: 0.0315\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [62/1000], Validation Loss: 0.0314\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [63/1000], Validation Loss: 0.0315\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [64/1000], Validation Loss: 0.0315\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [65/1000], Validation Loss: 0.0315\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [66/1000], Validation Loss: 0.0314\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [67/1000], Validation Loss: 0.0314\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [68/1000], Validation Loss: 0.0315\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [69/1000], Validation Loss: 0.0315\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [70/1000], Validation Loss: 0.0315\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [71/1000], Validation Loss: 0.0314\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [72/1000], Validation Loss: 0.0314\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [73/1000], Validation Loss: 0.0314\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [74/1000], Validation Loss: 0.0315\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [75/1000], Validation Loss: 0.0315\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [76/1000], Validation Loss: 0.0315\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [77/1000], Validation Loss: 0.0314\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [78/1000], Validation Loss: 0.0314\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [79/1000], Validation Loss: 0.0315\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [80/1000], Validation Loss: 0.0314\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [81/1000], Validation Loss: 0.0314\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [82/1000], Validation Loss: 0.0314\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [83/1000], Validation Loss: 0.0315\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [84/1000], Validation Loss: 0.0314\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [85/1000], Validation Loss: 0.0315\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [86/1000], Validation Loss: 0.0314\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [87/1000], Validation Loss: 0.0314\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [88/1000], Validation Loss: 0.0314\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [89/1000], Validation Loss: 0.0315\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [90/1000], Validation Loss: 0.0315\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [91/1000], Validation Loss: 0.0314\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [92/1000], Validation Loss: 0.0315\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [93/1000], Validation Loss: 0.0315\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [94/1000], Validation Loss: 0.0314\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [95/1000], Validation Loss: 0.0314\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [96/1000], Validation Loss: 0.0314\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [97/1000], Validation Loss: 0.0315\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [98/1000], Validation Loss: 0.0314\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [99/1000], Validation Loss: 0.0314\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [100/1000], Validation Loss: 0.0314\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [101/1000], Validation Loss: 0.0314\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [102/1000], Validation Loss: 0.0314\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [103/1000], Validation Loss: 0.0314\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [104/1000], Validation Loss: 0.0315\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [105/1000], Validation Loss: 0.0315\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [106/1000], Validation Loss: 0.0314\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [107/1000], Validation Loss: 0.0315\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [108/1000], Validation Loss: 0.0314\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [109/1000], Validation Loss: 0.0315\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [110/1000], Validation Loss: 0.0314\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [111/1000], Validation Loss: 0.0314\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [112/1000], Validation Loss: 0.0314\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [113/1000], Validation Loss: 0.0314\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [114/1000], Validation Loss: 0.0315\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [115/1000], Validation Loss: 0.0315\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [116/1000], Validation Loss: 0.0314\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [117/1000], Validation Loss: 0.0315\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [118/1000], Validation Loss: 0.0315\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [119/1000], Validation Loss: 0.0315\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [120/1000], Validation Loss: 0.0315\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [121/1000], Validation Loss: 0.0314\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [122/1000], Validation Loss: 0.0315\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [123/1000], Validation Loss: 0.0314\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [124/1000], Validation Loss: 0.0314\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [125/1000], Validation Loss: 0.0314\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [126/1000], Validation Loss: 0.0314\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [127/1000], Validation Loss: 0.0315\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [128/1000], Validation Loss: 0.0314\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [129/1000], Validation Loss: 0.0314\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [130/1000], Validation Loss: 0.0314\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [131/1000], Validation Loss: 0.0315\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [132/1000], Validation Loss: 0.0315\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [133/1000], Validation Loss: 0.0314\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [134/1000], Validation Loss: 0.0314\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [135/1000], Validation Loss: 0.0315\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [136/1000], Validation Loss: 0.0315\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [137/1000], Validation Loss: 0.0314\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [138/1000], Validation Loss: 0.0315\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [139/1000], Validation Loss: 0.0315\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [140/1000], Validation Loss: 0.0314\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [141/1000], Validation Loss: 0.0315\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [142/1000], Validation Loss: 0.0314\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [143/1000], Validation Loss: 0.0314\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [144/1000], Validation Loss: 0.0314\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [145/1000], Validation Loss: 0.0315\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [146/1000], Validation Loss: 0.0313\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [147/1000], Validation Loss: 0.0314\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [148/1000], Validation Loss: 0.0314\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [149/1000], Validation Loss: 0.0313\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [150/1000], Validation Loss: 0.0314\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [151/1000], Validation Loss: 0.0314\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [152/1000], Validation Loss: 0.0315\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [153/1000], Validation Loss: 0.0315\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [154/1000], Validation Loss: 0.0315\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [155/1000], Validation Loss: 0.0314\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [156/1000], Validation Loss: 0.0315\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [157/1000], Validation Loss: 0.0315\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [158/1000], Validation Loss: 0.0314\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [159/1000], Validation Loss: 0.0314\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [160/1000], Validation Loss: 0.0314\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [161/1000], Validation Loss: 0.0314\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [162/1000], Validation Loss: 0.0314\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [163/1000], Validation Loss: 0.0314\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [164/1000], Validation Loss: 0.0315\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [165/1000], Validation Loss: 0.0315\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [166/1000], Validation Loss: 0.0315\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [167/1000], Validation Loss: 0.0314\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [168/1000], Validation Loss: 0.0314\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [169/1000], Validation Loss: 0.0315\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [170/1000], Validation Loss: 0.0315\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [171/1000], Validation Loss: 0.0314\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [172/1000], Validation Loss: 0.0315\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [173/1000], Validation Loss: 0.0315\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [174/1000], Validation Loss: 0.0314\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [175/1000], Validation Loss: 0.0315\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [176/1000], Validation Loss: 0.0315\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [177/1000], Validation Loss: 0.0315\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [178/1000], Validation Loss: 0.0314\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [179/1000], Validation Loss: 0.0315\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [180/1000], Validation Loss: 0.0314\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [181/1000], Validation Loss: 0.0315\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [182/1000], Validation Loss: 0.0315\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [183/1000], Validation Loss: 0.0315\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [184/1000], Validation Loss: 0.0315\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [185/1000], Validation Loss: 0.0315\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [186/1000], Validation Loss: 0.0314\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [187/1000], Validation Loss: 0.0315\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [188/1000], Validation Loss: 0.0314\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [189/1000], Validation Loss: 0.0315\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [190/1000], Validation Loss: 0.0314\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [191/1000], Validation Loss: 0.0314\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [192/1000], Validation Loss: 0.0315\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [193/1000], Validation Loss: 0.0315\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [194/1000], Validation Loss: 0.0315\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [195/1000], Validation Loss: 0.0315\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [196/1000], Validation Loss: 0.0315\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [197/1000], Validation Loss: 0.0314\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [198/1000], Validation Loss: 0.0314\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [199/1000], Validation Loss: 0.0314\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [200/1000], Validation Loss: 0.0314\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [201/1000], Validation Loss: 0.0314\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [202/1000], Validation Loss: 0.0314\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [203/1000], Validation Loss: 0.0314\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [204/1000], Validation Loss: 0.0315\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [205/1000], Validation Loss: 0.0314\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [206/1000], Validation Loss: 0.0314\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [207/1000], Validation Loss: 0.0315\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [208/1000], Validation Loss: 0.0314\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [209/1000], Validation Loss: 0.0315\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [210/1000], Validation Loss: 0.0315\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [211/1000], Validation Loss: 0.0314\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [212/1000], Validation Loss: 0.0314\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [213/1000], Validation Loss: 0.0314\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [214/1000], Validation Loss: 0.0314\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [215/1000], Validation Loss: 0.0314\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [216/1000], Validation Loss: 0.0315\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [217/1000], Validation Loss: 0.0314\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [218/1000], Validation Loss: 0.0315\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [219/1000], Validation Loss: 0.0315\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [220/1000], Validation Loss: 0.0314\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [221/1000], Validation Loss: 0.0314\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [222/1000], Validation Loss: 0.0314\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [223/1000], Validation Loss: 0.0315\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [224/1000], Validation Loss: 0.0314\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [225/1000], Validation Loss: 0.0315\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [226/1000], Validation Loss: 0.0315\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [227/1000], Validation Loss: 0.0314\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [228/1000], Validation Loss: 0.0314\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [229/1000], Validation Loss: 0.0315\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [230/1000], Validation Loss: 0.0314\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [231/1000], Validation Loss: 0.0315\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [232/1000], Validation Loss: 0.0315\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [233/1000], Validation Loss: 0.0315\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [234/1000], Validation Loss: 0.0315\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [235/1000], Validation Loss: 0.0315\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [236/1000], Validation Loss: 0.0315\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [237/1000], Validation Loss: 0.0315\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [238/1000], Validation Loss: 0.0314\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [239/1000], Validation Loss: 0.0315\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [240/1000], Validation Loss: 0.0314\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [241/1000], Validation Loss: 0.0315\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [242/1000], Validation Loss: 0.0315\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [243/1000], Validation Loss: 0.0315\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [244/1000], Validation Loss: 0.0314\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [245/1000], Validation Loss: 0.0315\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [246/1000], Validation Loss: 0.0315\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [247/1000], Validation Loss: 0.0315\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [248/1000], Validation Loss: 0.0314\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [249/1000], Validation Loss: 0.0314\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [250/1000], Validation Loss: 0.0314\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [251/1000], Validation Loss: 0.0314\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [252/1000], Validation Loss: 0.0314\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [253/1000], Validation Loss: 0.0314\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [254/1000], Validation Loss: 0.0315\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [255/1000], Validation Loss: 0.0315\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [256/1000], Validation Loss: 0.0315\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [257/1000], Validation Loss: 0.0315\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [258/1000], Validation Loss: 0.0314\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [259/1000], Validation Loss: 0.0315\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [260/1000], Validation Loss: 0.0315\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [261/1000], Validation Loss: 0.0314\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [262/1000], Validation Loss: 0.0314\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [263/1000], Validation Loss: 0.0315\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [264/1000], Validation Loss: 0.0315\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [265/1000], Validation Loss: 0.0315\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [266/1000], Validation Loss: 0.0314\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [267/1000], Validation Loss: 0.0315\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [268/1000], Validation Loss: 0.0314\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [269/1000], Validation Loss: 0.0315\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [270/1000], Validation Loss: 0.0315\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [271/1000], Validation Loss: 0.0315\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [272/1000], Validation Loss: 0.0315\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [273/1000], Validation Loss: 0.0314\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [274/1000], Validation Loss: 0.0314\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [275/1000], Validation Loss: 0.0314\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [276/1000], Validation Loss: 0.0314\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [277/1000], Validation Loss: 0.0315\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [278/1000], Validation Loss: 0.0314\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [279/1000], Validation Loss: 0.0314\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [280/1000], Validation Loss: 0.0315\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [281/1000], Validation Loss: 0.0315\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [282/1000], Validation Loss: 0.0315\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [283/1000], Validation Loss: 0.0315\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [284/1000], Validation Loss: 0.0314\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [285/1000], Validation Loss: 0.0314\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [286/1000], Validation Loss: 0.0314\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [287/1000], Validation Loss: 0.0315\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [288/1000], Validation Loss: 0.0314\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [289/1000], Validation Loss: 0.0314\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [290/1000], Validation Loss: 0.0315\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [291/1000], Validation Loss: 0.0314\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [292/1000], Validation Loss: 0.0315\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [293/1000], Validation Loss: 0.0314\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [294/1000], Validation Loss: 0.0315\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [295/1000], Validation Loss: 0.0315\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [296/1000], Validation Loss: 0.0315\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [297/1000], Validation Loss: 0.0314\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [298/1000], Validation Loss: 0.0315\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [299/1000], Validation Loss: 0.0314\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [300/1000], Validation Loss: 0.0314\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [301/1000], Validation Loss: 0.0315\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [302/1000], Validation Loss: 0.0314\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [303/1000], Validation Loss: 0.0314\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [304/1000], Validation Loss: 0.0315\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [305/1000], Validation Loss: 0.0315\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [306/1000], Validation Loss: 0.0314\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [307/1000], Validation Loss: 0.0315\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [308/1000], Validation Loss: 0.0315\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [309/1000], Validation Loss: 0.0314\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [310/1000], Validation Loss: 0.0315\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [311/1000], Validation Loss: 0.0314\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [312/1000], Validation Loss: 0.0314\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [313/1000], Validation Loss: 0.0314\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [314/1000], Validation Loss: 0.0314\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [315/1000], Validation Loss: 0.0314\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [316/1000], Validation Loss: 0.0314\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [317/1000], Validation Loss: 0.0315\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [318/1000], Validation Loss: 0.0315\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [319/1000], Validation Loss: 0.0314\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [320/1000], Validation Loss: 0.0315\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [321/1000], Validation Loss: 0.0314\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [322/1000], Validation Loss: 0.0314\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [323/1000], Validation Loss: 0.0315\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [324/1000], Validation Loss: 0.0314\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [325/1000], Validation Loss: 0.0314\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [326/1000], Validation Loss: 0.0315\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [327/1000], Validation Loss: 0.0315\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [328/1000], Validation Loss: 0.0315\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [329/1000], Validation Loss: 0.0315\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [330/1000], Validation Loss: 0.0315\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [331/1000], Validation Loss: 0.0314\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [332/1000], Validation Loss: 0.0314\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [333/1000], Validation Loss: 0.0314\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [334/1000], Validation Loss: 0.0314\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [335/1000], Validation Loss: 0.0314\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [336/1000], Validation Loss: 0.0314\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [337/1000], Validation Loss: 0.0314\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [338/1000], Validation Loss: 0.0315\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [339/1000], Validation Loss: 0.0315\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [340/1000], Validation Loss: 0.0315\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [341/1000], Validation Loss: 0.0315\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [342/1000], Validation Loss: 0.0315\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [343/1000], Validation Loss: 0.0314\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [344/1000], Validation Loss: 0.0315\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [345/1000], Validation Loss: 0.0315\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [346/1000], Validation Loss: 0.0315\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [347/1000], Validation Loss: 0.0315\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [348/1000], Validation Loss: 0.0315\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [349/1000], Validation Loss: 0.0314\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [350/1000], Validation Loss: 0.0315\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [351/1000], Validation Loss: 0.0315\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [352/1000], Validation Loss: 0.0314\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [353/1000], Validation Loss: 0.0315\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [354/1000], Validation Loss: 0.0315\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [355/1000], Validation Loss: 0.0315\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [356/1000], Validation Loss: 0.0315\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [357/1000], Validation Loss: 0.0314\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [358/1000], Validation Loss: 0.0315\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [359/1000], Validation Loss: 0.0314\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [360/1000], Validation Loss: 0.0314\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [361/1000], Validation Loss: 0.0314\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [362/1000], Validation Loss: 0.0314\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [363/1000], Validation Loss: 0.0314\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [364/1000], Validation Loss: 0.0314\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [365/1000], Validation Loss: 0.0314\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [366/1000], Validation Loss: 0.0315\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [367/1000], Validation Loss: 0.0314\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [368/1000], Validation Loss: 0.0314\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [369/1000], Validation Loss: 0.0315\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [370/1000], Validation Loss: 0.0315\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [371/1000], Validation Loss: 0.0315\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [372/1000], Validation Loss: 0.0315\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [373/1000], Validation Loss: 0.0314\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [374/1000], Validation Loss: 0.0314\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [375/1000], Validation Loss: 0.0314\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [376/1000], Validation Loss: 0.0315\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [377/1000], Validation Loss: 0.0315\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [378/1000], Validation Loss: 0.0314\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [379/1000], Validation Loss: 0.0314\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [380/1000], Validation Loss: 0.0315\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [381/1000], Validation Loss: 0.0314\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [382/1000], Validation Loss: 0.0314\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [383/1000], Validation Loss: 0.0315\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [384/1000], Validation Loss: 0.0314\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [385/1000], Validation Loss: 0.0314\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [386/1000], Validation Loss: 0.0314\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [387/1000], Validation Loss: 0.0314\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [388/1000], Validation Loss: 0.0315\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [389/1000], Validation Loss: 0.0314\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [390/1000], Validation Loss: 0.0315\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [391/1000], Validation Loss: 0.0315\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [392/1000], Validation Loss: 0.0314\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [393/1000], Validation Loss: 0.0315\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [394/1000], Validation Loss: 0.0314\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [395/1000], Validation Loss: 0.0314\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [396/1000], Validation Loss: 0.0315\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [397/1000], Validation Loss: 0.0314\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [398/1000], Validation Loss: 0.0314\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [399/1000], Validation Loss: 0.0315\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [400/1000], Validation Loss: 0.0315\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [401/1000], Validation Loss: 0.0315\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [402/1000], Validation Loss: 0.0314\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [403/1000], Validation Loss: 0.0315\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [404/1000], Validation Loss: 0.0315\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [405/1000], Validation Loss: 0.0315\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [406/1000], Validation Loss: 0.0315\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [407/1000], Validation Loss: 0.0315\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [408/1000], Validation Loss: 0.0314\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [409/1000], Validation Loss: 0.0315\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [410/1000], Validation Loss: 0.0315\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [411/1000], Validation Loss: 0.0314\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [412/1000], Validation Loss: 0.0315\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [413/1000], Validation Loss: 0.0314\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [414/1000], Validation Loss: 0.0315\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [415/1000], Validation Loss: 0.0315\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [416/1000], Validation Loss: 0.0315\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [417/1000], Validation Loss: 0.0315\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [418/1000], Validation Loss: 0.0315\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [419/1000], Validation Loss: 0.0315\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [420/1000], Validation Loss: 0.0314\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [421/1000], Validation Loss: 0.0314\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [422/1000], Validation Loss: 0.0314\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [423/1000], Validation Loss: 0.0315\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [424/1000], Validation Loss: 0.0315\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [425/1000], Validation Loss: 0.0314\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [426/1000], Validation Loss: 0.0314\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [427/1000], Validation Loss: 0.0314\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [428/1000], Validation Loss: 0.0314\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [429/1000], Validation Loss: 0.0314\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [430/1000], Validation Loss: 0.0315\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [431/1000], Validation Loss: 0.0315\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [432/1000], Validation Loss: 0.0314\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [433/1000], Validation Loss: 0.0315\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [434/1000], Validation Loss: 0.0314\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [435/1000], Validation Loss: 0.0315\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [436/1000], Validation Loss: 0.0315\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [437/1000], Validation Loss: 0.0314\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [438/1000], Validation Loss: 0.0315\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [439/1000], Validation Loss: 0.0315\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [440/1000], Validation Loss: 0.0315\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [441/1000], Validation Loss: 0.0314\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [442/1000], Validation Loss: 0.0314\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [443/1000], Validation Loss: 0.0315\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [444/1000], Validation Loss: 0.0314\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [445/1000], Validation Loss: 0.0315\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [446/1000], Validation Loss: 0.0314\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [447/1000], Validation Loss: 0.0314\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [448/1000], Validation Loss: 0.0315\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [449/1000], Validation Loss: 0.0315\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [450/1000], Validation Loss: 0.0314\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [451/1000], Validation Loss: 0.0314\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [452/1000], Validation Loss: 0.0315\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [453/1000], Validation Loss: 0.0314\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [454/1000], Validation Loss: 0.0314\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [455/1000], Validation Loss: 0.0315\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [456/1000], Validation Loss: 0.0315\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [457/1000], Validation Loss: 0.0315\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [458/1000], Validation Loss: 0.0314\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [459/1000], Validation Loss: 0.0314\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [460/1000], Validation Loss: 0.0314\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [461/1000], Validation Loss: 0.0315\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [462/1000], Validation Loss: 0.0315\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [463/1000], Validation Loss: 0.0314\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [464/1000], Validation Loss: 0.0315\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [465/1000], Validation Loss: 0.0315\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [466/1000], Validation Loss: 0.0315\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [467/1000], Validation Loss: 0.0314\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [468/1000], Validation Loss: 0.0314\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [469/1000], Validation Loss: 0.0315\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [470/1000], Validation Loss: 0.0315\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [471/1000], Validation Loss: 0.0314\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [472/1000], Validation Loss: 0.0314\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [473/1000], Validation Loss: 0.0314\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [474/1000], Validation Loss: 0.0315\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [475/1000], Validation Loss: 0.0315\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [476/1000], Validation Loss: 0.0315\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [477/1000], Validation Loss: 0.0314\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [478/1000], Validation Loss: 0.0314\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [479/1000], Validation Loss: 0.0315\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [480/1000], Validation Loss: 0.0314\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [481/1000], Validation Loss: 0.0315\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [482/1000], Validation Loss: 0.0314\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [483/1000], Validation Loss: 0.0314\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [484/1000], Validation Loss: 0.0314\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [485/1000], Validation Loss: 0.0314\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [486/1000], Validation Loss: 0.0315\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [487/1000], Validation Loss: 0.0314\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [488/1000], Validation Loss: 0.0315\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [489/1000], Validation Loss: 0.0315\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [490/1000], Validation Loss: 0.0315\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [491/1000], Validation Loss: 0.0315\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [492/1000], Validation Loss: 0.0315\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [493/1000], Validation Loss: 0.0315\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [494/1000], Validation Loss: 0.0315\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [495/1000], Validation Loss: 0.0315\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [496/1000], Validation Loss: 0.0315\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [497/1000], Validation Loss: 0.0315\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [498/1000], Validation Loss: 0.0314\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [499/1000], Validation Loss: 0.0314\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [500/1000], Validation Loss: 0.0314\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [501/1000], Validation Loss: 0.0315\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [502/1000], Validation Loss: 0.0314\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [503/1000], Validation Loss: 0.0315\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [504/1000], Validation Loss: 0.0314\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [505/1000], Validation Loss: 0.0314\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [506/1000], Validation Loss: 0.0315\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [507/1000], Validation Loss: 0.0314\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [508/1000], Validation Loss: 0.0314\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [509/1000], Validation Loss: 0.0314\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [510/1000], Validation Loss: 0.0314\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [511/1000], Validation Loss: 0.0315\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [512/1000], Validation Loss: 0.0315\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [513/1000], Validation Loss: 0.0315\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [514/1000], Validation Loss: 0.0315\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [515/1000], Validation Loss: 0.0315\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [516/1000], Validation Loss: 0.0315\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [517/1000], Validation Loss: 0.0314\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [518/1000], Validation Loss: 0.0314\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [519/1000], Validation Loss: 0.0314\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [520/1000], Validation Loss: 0.0315\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [521/1000], Validation Loss: 0.0314\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [522/1000], Validation Loss: 0.0314\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [523/1000], Validation Loss: 0.0314\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [524/1000], Validation Loss: 0.0315\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [525/1000], Validation Loss: 0.0315\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [526/1000], Validation Loss: 0.0315\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [527/1000], Validation Loss: 0.0315\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [528/1000], Validation Loss: 0.0315\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [529/1000], Validation Loss: 0.0314\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [530/1000], Validation Loss: 0.0315\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [531/1000], Validation Loss: 0.0315\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [532/1000], Validation Loss: 0.0315\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [533/1000], Validation Loss: 0.0314\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [534/1000], Validation Loss: 0.0315\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [535/1000], Validation Loss: 0.0315\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [536/1000], Validation Loss: 0.0315\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [537/1000], Validation Loss: 0.0314\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [538/1000], Validation Loss: 0.0314\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [539/1000], Validation Loss: 0.0315\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [540/1000], Validation Loss: 0.0314\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [541/1000], Validation Loss: 0.0315\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [542/1000], Validation Loss: 0.0315\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [543/1000], Validation Loss: 0.0315\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [544/1000], Validation Loss: 0.0314\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [545/1000], Validation Loss: 0.0315\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [546/1000], Validation Loss: 0.0315\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [547/1000], Validation Loss: 0.0314\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [548/1000], Validation Loss: 0.0315\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [549/1000], Validation Loss: 0.0314\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [550/1000], Validation Loss: 0.0314\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [551/1000], Validation Loss: 0.0314\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [552/1000], Validation Loss: 0.0314\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [553/1000], Validation Loss: 0.0315\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [554/1000], Validation Loss: 0.0314\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [555/1000], Validation Loss: 0.0314\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [556/1000], Validation Loss: 0.0314\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [557/1000], Validation Loss: 0.0314\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [558/1000], Validation Loss: 0.0314\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [559/1000], Validation Loss: 0.0314\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [560/1000], Validation Loss: 0.0315\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [561/1000], Validation Loss: 0.0314\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [562/1000], Validation Loss: 0.0314\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [563/1000], Validation Loss: 0.0315\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [564/1000], Validation Loss: 0.0315\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [565/1000], Validation Loss: 0.0315\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [566/1000], Validation Loss: 0.0315\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [567/1000], Validation Loss: 0.0314\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [568/1000], Validation Loss: 0.0314\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [569/1000], Validation Loss: 0.0315\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [570/1000], Validation Loss: 0.0315\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [571/1000], Validation Loss: 0.0314\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [572/1000], Validation Loss: 0.0314\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [573/1000], Validation Loss: 0.0314\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [574/1000], Validation Loss: 0.0315\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [575/1000], Validation Loss: 0.0315\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [576/1000], Validation Loss: 0.0314\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [577/1000], Validation Loss: 0.0314\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [578/1000], Validation Loss: 0.0314\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [579/1000], Validation Loss: 0.0315\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [580/1000], Validation Loss: 0.0315\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [581/1000], Validation Loss: 0.0314\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [582/1000], Validation Loss: 0.0315\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [583/1000], Validation Loss: 0.0315\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [584/1000], Validation Loss: 0.0314\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [585/1000], Validation Loss: 0.0315\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [586/1000], Validation Loss: 0.0314\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [587/1000], Validation Loss: 0.0315\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [588/1000], Validation Loss: 0.0315\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [589/1000], Validation Loss: 0.0314\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [590/1000], Validation Loss: 0.0315\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [591/1000], Validation Loss: 0.0315\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [592/1000], Validation Loss: 0.0314\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [593/1000], Validation Loss: 0.0314\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [594/1000], Validation Loss: 0.0315\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [595/1000], Validation Loss: 0.0315\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [596/1000], Validation Loss: 0.0315\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [597/1000], Validation Loss: 0.0314\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [598/1000], Validation Loss: 0.0315\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [599/1000], Validation Loss: 0.0315\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [600/1000], Validation Loss: 0.0315\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [601/1000], Validation Loss: 0.0315\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [602/1000], Validation Loss: 0.0314\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [603/1000], Validation Loss: 0.0315\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [604/1000], Validation Loss: 0.0314\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [605/1000], Validation Loss: 0.0315\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [606/1000], Validation Loss: 0.0314\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [607/1000], Validation Loss: 0.0314\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [608/1000], Validation Loss: 0.0314\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [609/1000], Validation Loss: 0.0315\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [610/1000], Validation Loss: 0.0314\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [611/1000], Validation Loss: 0.0315\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [612/1000], Validation Loss: 0.0315\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [613/1000], Validation Loss: 0.0314\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [614/1000], Validation Loss: 0.0314\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [615/1000], Validation Loss: 0.0315\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [616/1000], Validation Loss: 0.0314\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [617/1000], Validation Loss: 0.0314\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [618/1000], Validation Loss: 0.0315\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [619/1000], Validation Loss: 0.0314\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [620/1000], Validation Loss: 0.0314\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [621/1000], Validation Loss: 0.0315\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [622/1000], Validation Loss: 0.0315\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [623/1000], Validation Loss: 0.0314\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [624/1000], Validation Loss: 0.0315\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [625/1000], Validation Loss: 0.0315\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [626/1000], Validation Loss: 0.0314\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [627/1000], Validation Loss: 0.0314\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [628/1000], Validation Loss: 0.0315\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [629/1000], Validation Loss: 0.0314\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [630/1000], Validation Loss: 0.0314\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [631/1000], Validation Loss: 0.0315\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [632/1000], Validation Loss: 0.0315\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [633/1000], Validation Loss: 0.0314\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [634/1000], Validation Loss: 0.0314\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [635/1000], Validation Loss: 0.0314\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [636/1000], Validation Loss: 0.0314\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [637/1000], Validation Loss: 0.0314\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [638/1000], Validation Loss: 0.0314\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [639/1000], Validation Loss: 0.0314\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [640/1000], Validation Loss: 0.0314\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [641/1000], Validation Loss: 0.0315\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [642/1000], Validation Loss: 0.0315\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [643/1000], Validation Loss: 0.0314\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [644/1000], Validation Loss: 0.0314\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [645/1000], Validation Loss: 0.0315\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [646/1000], Validation Loss: 0.0314\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [647/1000], Validation Loss: 0.0314\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [648/1000], Validation Loss: 0.0314\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [649/1000], Validation Loss: 0.0314\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [650/1000], Validation Loss: 0.0314\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [651/1000], Validation Loss: 0.0314\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [652/1000], Validation Loss: 0.0315\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [653/1000], Validation Loss: 0.0314\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [654/1000], Validation Loss: 0.0314\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [655/1000], Validation Loss: 0.0314\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [656/1000], Validation Loss: 0.0315\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [657/1000], Validation Loss: 0.0315\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [658/1000], Validation Loss: 0.0314\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [659/1000], Validation Loss: 0.0314\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [660/1000], Validation Loss: 0.0314\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [661/1000], Validation Loss: 0.0315\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [662/1000], Validation Loss: 0.0314\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [663/1000], Validation Loss: 0.0315\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [664/1000], Validation Loss: 0.0314\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [665/1000], Validation Loss: 0.0315\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [666/1000], Validation Loss: 0.0315\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [667/1000], Validation Loss: 0.0314\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [668/1000], Validation Loss: 0.0315\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [669/1000], Validation Loss: 0.0315\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [670/1000], Validation Loss: 0.0315\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [671/1000], Validation Loss: 0.0314\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [672/1000], Validation Loss: 0.0314\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [673/1000], Validation Loss: 0.0315\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [674/1000], Validation Loss: 0.0314\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [675/1000], Validation Loss: 0.0315\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [676/1000], Validation Loss: 0.0314\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [677/1000], Validation Loss: 0.0315\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [678/1000], Validation Loss: 0.0314\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [679/1000], Validation Loss: 0.0315\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [680/1000], Validation Loss: 0.0314\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [681/1000], Validation Loss: 0.0314\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [682/1000], Validation Loss: 0.0314\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [683/1000], Validation Loss: 0.0314\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [684/1000], Validation Loss: 0.0314\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [685/1000], Validation Loss: 0.0314\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [686/1000], Validation Loss: 0.0314\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [687/1000], Validation Loss: 0.0314\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [688/1000], Validation Loss: 0.0315\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [689/1000], Validation Loss: 0.0315\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [690/1000], Validation Loss: 0.0315\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [691/1000], Validation Loss: 0.0315\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [692/1000], Validation Loss: 0.0314\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [693/1000], Validation Loss: 0.0314\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [694/1000], Validation Loss: 0.0314\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [695/1000], Validation Loss: 0.0315\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [696/1000], Validation Loss: 0.0315\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [697/1000], Validation Loss: 0.0315\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [698/1000], Validation Loss: 0.0314\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [699/1000], Validation Loss: 0.0314\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [700/1000], Validation Loss: 0.0314\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [701/1000], Validation Loss: 0.0314\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [702/1000], Validation Loss: 0.0315\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [703/1000], Validation Loss: 0.0314\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [704/1000], Validation Loss: 0.0314\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [705/1000], Validation Loss: 0.0315\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [706/1000], Validation Loss: 0.0315\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [707/1000], Validation Loss: 0.0314\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [708/1000], Validation Loss: 0.0314\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [709/1000], Validation Loss: 0.0315\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [710/1000], Validation Loss: 0.0314\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [711/1000], Validation Loss: 0.0315\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [712/1000], Validation Loss: 0.0314\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [713/1000], Validation Loss: 0.0314\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [714/1000], Validation Loss: 0.0314\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [715/1000], Validation Loss: 0.0315\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [716/1000], Validation Loss: 0.0314\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [717/1000], Validation Loss: 0.0314\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [718/1000], Validation Loss: 0.0315\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [719/1000], Validation Loss: 0.0315\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [720/1000], Validation Loss: 0.0315\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [721/1000], Validation Loss: 0.0315\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [722/1000], Validation Loss: 0.0315\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [723/1000], Validation Loss: 0.0314\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [724/1000], Validation Loss: 0.0315\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [725/1000], Validation Loss: 0.0315\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [726/1000], Validation Loss: 0.0314\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [727/1000], Validation Loss: 0.0315\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [728/1000], Validation Loss: 0.0315\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [729/1000], Validation Loss: 0.0314\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [730/1000], Validation Loss: 0.0314\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [731/1000], Validation Loss: 0.0314\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [732/1000], Validation Loss: 0.0315\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [733/1000], Validation Loss: 0.0315\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [734/1000], Validation Loss: 0.0314\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [735/1000], Validation Loss: 0.0315\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [736/1000], Validation Loss: 0.0314\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [737/1000], Validation Loss: 0.0314\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [738/1000], Validation Loss: 0.0315\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [739/1000], Validation Loss: 0.0314\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [740/1000], Validation Loss: 0.0314\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [741/1000], Validation Loss: 0.0315\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [742/1000], Validation Loss: 0.0315\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [743/1000], Validation Loss: 0.0314\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [744/1000], Validation Loss: 0.0315\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [745/1000], Validation Loss: 0.0314\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [746/1000], Validation Loss: 0.0314\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [747/1000], Validation Loss: 0.0315\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [748/1000], Validation Loss: 0.0314\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [749/1000], Validation Loss: 0.0315\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [750/1000], Validation Loss: 0.0314\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [751/1000], Validation Loss: 0.0315\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [752/1000], Validation Loss: 0.0315\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [753/1000], Validation Loss: 0.0315\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [754/1000], Validation Loss: 0.0314\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [755/1000], Validation Loss: 0.0315\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [756/1000], Validation Loss: 0.0315\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [757/1000], Validation Loss: 0.0314\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [758/1000], Validation Loss: 0.0314\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [759/1000], Validation Loss: 0.0314\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [760/1000], Validation Loss: 0.0315\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [761/1000], Validation Loss: 0.0315\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [762/1000], Validation Loss: 0.0315\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [763/1000], Validation Loss: 0.0315\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [764/1000], Validation Loss: 0.0315\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [765/1000], Validation Loss: 0.0315\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [766/1000], Validation Loss: 0.0314\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [767/1000], Validation Loss: 0.0315\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [768/1000], Validation Loss: 0.0315\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [769/1000], Validation Loss: 0.0314\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [770/1000], Validation Loss: 0.0315\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [771/1000], Validation Loss: 0.0315\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [772/1000], Validation Loss: 0.0315\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [773/1000], Validation Loss: 0.0314\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [774/1000], Validation Loss: 0.0314\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [775/1000], Validation Loss: 0.0315\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [776/1000], Validation Loss: 0.0314\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [777/1000], Validation Loss: 0.0314\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [778/1000], Validation Loss: 0.0314\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [779/1000], Validation Loss: 0.0315\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [780/1000], Validation Loss: 0.0314\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [781/1000], Validation Loss: 0.0314\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [782/1000], Validation Loss: 0.0314\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [783/1000], Validation Loss: 0.0315\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [784/1000], Validation Loss: 0.0315\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [785/1000], Validation Loss: 0.0315\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [786/1000], Validation Loss: 0.0315\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [787/1000], Validation Loss: 0.0315\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [788/1000], Validation Loss: 0.0315\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [789/1000], Validation Loss: 0.0315\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [790/1000], Validation Loss: 0.0314\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [791/1000], Validation Loss: 0.0315\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [792/1000], Validation Loss: 0.0315\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [793/1000], Validation Loss: 0.0315\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [794/1000], Validation Loss: 0.0314\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [795/1000], Validation Loss: 0.0314\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [796/1000], Validation Loss: 0.0314\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [797/1000], Validation Loss: 0.0314\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [798/1000], Validation Loss: 0.0314\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [799/1000], Validation Loss: 0.0314\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [800/1000], Validation Loss: 0.0314\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [801/1000], Validation Loss: 0.0314\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [802/1000], Validation Loss: 0.0314\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [803/1000], Validation Loss: 0.0314\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [804/1000], Validation Loss: 0.0315\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [805/1000], Validation Loss: 0.0315\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [806/1000], Validation Loss: 0.0315\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [807/1000], Validation Loss: 0.0315\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [808/1000], Validation Loss: 0.0315\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [809/1000], Validation Loss: 0.0315\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [810/1000], Validation Loss: 0.0314\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [811/1000], Validation Loss: 0.0314\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [812/1000], Validation Loss: 0.0314\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [813/1000], Validation Loss: 0.0314\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [814/1000], Validation Loss: 0.0314\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [815/1000], Validation Loss: 0.0314\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [816/1000], Validation Loss: 0.0314\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [817/1000], Validation Loss: 0.0315\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [818/1000], Validation Loss: 0.0315\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [819/1000], Validation Loss: 0.0315\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [820/1000], Validation Loss: 0.0314\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [821/1000], Validation Loss: 0.0314\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [822/1000], Validation Loss: 0.0314\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [823/1000], Validation Loss: 0.0314\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [824/1000], Validation Loss: 0.0315\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [825/1000], Validation Loss: 0.0314\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [826/1000], Validation Loss: 0.0315\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [827/1000], Validation Loss: 0.0315\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [828/1000], Validation Loss: 0.0314\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [829/1000], Validation Loss: 0.0315\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [830/1000], Validation Loss: 0.0314\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [831/1000], Validation Loss: 0.0315\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [832/1000], Validation Loss: 0.0315\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [833/1000], Validation Loss: 0.0314\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [834/1000], Validation Loss: 0.0314\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [835/1000], Validation Loss: 0.0315\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [836/1000], Validation Loss: 0.0314\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [837/1000], Validation Loss: 0.0314\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [838/1000], Validation Loss: 0.0314\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [839/1000], Validation Loss: 0.0314\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [840/1000], Validation Loss: 0.0315\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [841/1000], Validation Loss: 0.0314\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [842/1000], Validation Loss: 0.0315\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [843/1000], Validation Loss: 0.0315\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [844/1000], Validation Loss: 0.0314\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [845/1000], Validation Loss: 0.0314\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [846/1000], Validation Loss: 0.0314\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [847/1000], Validation Loss: 0.0314\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0298\n",
            "Epoch [848/1000], Validation Loss: 0.0314\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [849/1000], Validation Loss: 0.0314\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [850/1000], Validation Loss: 0.0314\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [851/1000], Validation Loss: 0.0315\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [852/1000], Validation Loss: 0.0315\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [853/1000], Validation Loss: 0.0314\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [854/1000], Validation Loss: 0.0314\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [855/1000], Validation Loss: 0.0314\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [856/1000], Validation Loss: 0.0314\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [857/1000], Validation Loss: 0.0315\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [858/1000], Validation Loss: 0.0315\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [859/1000], Validation Loss: 0.0314\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [860/1000], Validation Loss: 0.0314\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [861/1000], Validation Loss: 0.0315\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [862/1000], Validation Loss: 0.0314\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [863/1000], Validation Loss: 0.0314\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [864/1000], Validation Loss: 0.0314\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [865/1000], Validation Loss: 0.0315\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [866/1000], Validation Loss: 0.0314\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [867/1000], Validation Loss: 0.0314\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [868/1000], Validation Loss: 0.0315\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [869/1000], Validation Loss: 0.0315\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [870/1000], Validation Loss: 0.0314\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [871/1000], Validation Loss: 0.0315\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [872/1000], Validation Loss: 0.0315\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [873/1000], Validation Loss: 0.0314\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [874/1000], Validation Loss: 0.0315\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [875/1000], Validation Loss: 0.0315\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0300\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0321\n",
            "Epoch [876/1000], Validation Loss: 0.0315\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [877/1000], Validation Loss: 0.0314\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [878/1000], Validation Loss: 0.0315\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [879/1000], Validation Loss: 0.0315\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [880/1000], Validation Loss: 0.0315\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [881/1000], Validation Loss: 0.0314\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0320\n",
            "Epoch [882/1000], Validation Loss: 0.0315\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [883/1000], Validation Loss: 0.0314\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [884/1000], Validation Loss: 0.0315\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [885/1000], Validation Loss: 0.0314\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [886/1000], Validation Loss: 0.0314\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [887/1000], Validation Loss: 0.0314\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0302\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0318\n",
            "Epoch [888/1000], Validation Loss: 0.0315\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [889/1000], Validation Loss: 0.0315\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0314\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [890/1000], Validation Loss: 0.0315\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [891/1000], Validation Loss: 0.0315\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [892/1000], Validation Loss: 0.0315\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [893/1000], Validation Loss: 0.0314\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [894/1000], Validation Loss: 0.0314\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [895/1000], Validation Loss: 0.0315\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [896/1000], Validation Loss: 0.0315\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [897/1000], Validation Loss: 0.0314\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [898/1000], Validation Loss: 0.0315\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [899/1000], Validation Loss: 0.0315\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [900/1000], Validation Loss: 0.0314\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [901/1000], Validation Loss: 0.0314\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [902/1000], Validation Loss: 0.0314\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [903/1000], Validation Loss: 0.0315\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [904/1000], Validation Loss: 0.0314\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [905/1000], Validation Loss: 0.0314\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [906/1000], Validation Loss: 0.0315\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [907/1000], Validation Loss: 0.0314\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [908/1000], Validation Loss: 0.0314\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [909/1000], Validation Loss: 0.0315\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [910/1000], Validation Loss: 0.0314\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [911/1000], Validation Loss: 0.0314\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [912/1000], Validation Loss: 0.0314\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [913/1000], Validation Loss: 0.0315\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [914/1000], Validation Loss: 0.0314\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [915/1000], Validation Loss: 0.0314\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [916/1000], Validation Loss: 0.0315\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [917/1000], Validation Loss: 0.0315\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [918/1000], Validation Loss: 0.0315\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [919/1000], Validation Loss: 0.0314\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [920/1000], Validation Loss: 0.0314\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [921/1000], Validation Loss: 0.0315\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [922/1000], Validation Loss: 0.0314\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [923/1000], Validation Loss: 0.0314\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [924/1000], Validation Loss: 0.0315\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [925/1000], Validation Loss: 0.0315\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [926/1000], Validation Loss: 0.0314\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [927/1000], Validation Loss: 0.0314\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [928/1000], Validation Loss: 0.0314\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [929/1000], Validation Loss: 0.0314\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [930/1000], Validation Loss: 0.0314\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [931/1000], Validation Loss: 0.0314\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [932/1000], Validation Loss: 0.0315\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [933/1000], Validation Loss: 0.0315\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [934/1000], Validation Loss: 0.0314\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [935/1000], Validation Loss: 0.0314\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [936/1000], Validation Loss: 0.0314\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [937/1000], Validation Loss: 0.0314\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0317\n",
            "Epoch [938/1000], Validation Loss: 0.0314\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [939/1000], Validation Loss: 0.0314\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [940/1000], Validation Loss: 0.0314\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [941/1000], Validation Loss: 0.0315\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [942/1000], Validation Loss: 0.0314\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [943/1000], Validation Loss: 0.0315\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [944/1000], Validation Loss: 0.0314\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [945/1000], Validation Loss: 0.0314\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [946/1000], Validation Loss: 0.0314\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [947/1000], Validation Loss: 0.0314\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [948/1000], Validation Loss: 0.0315\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [949/1000], Validation Loss: 0.0314\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [950/1000], Validation Loss: 0.0315\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [951/1000], Validation Loss: 0.0314\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [952/1000], Validation Loss: 0.0315\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0314\n",
            "Epoch [953/1000], Validation Loss: 0.0315\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [954/1000], Validation Loss: 0.0315\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [955/1000], Validation Loss: 0.0314\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [956/1000], Validation Loss: 0.0315\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0303\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0316\n",
            "Epoch [957/1000], Validation Loss: 0.0314\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [958/1000], Validation Loss: 0.0315\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [959/1000], Validation Loss: 0.0315\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [960/1000], Validation Loss: 0.0314\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [961/1000], Validation Loss: 0.0315\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [962/1000], Validation Loss: 0.0315\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [963/1000], Validation Loss: 0.0315\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [964/1000], Validation Loss: 0.0315\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [965/1000], Validation Loss: 0.0315\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0301\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0319\n",
            "Epoch [966/1000], Validation Loss: 0.0315\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [967/1000], Validation Loss: 0.0315\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [968/1000], Validation Loss: 0.0314\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [969/1000], Validation Loss: 0.0314\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [970/1000], Validation Loss: 0.0315\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [971/1000], Validation Loss: 0.0315\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0301\n",
            "Epoch [972/1000], Validation Loss: 0.0314\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [973/1000], Validation Loss: 0.0315\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [974/1000], Validation Loss: 0.0314\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0300\n",
            "Epoch [975/1000], Validation Loss: 0.0315\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [976/1000], Validation Loss: 0.0315\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0305\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [977/1000], Validation Loss: 0.0314\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [978/1000], Validation Loss: 0.0314\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [979/1000], Validation Loss: 0.0314\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0313\n",
            "Epoch [980/1000], Validation Loss: 0.0315\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [981/1000], Validation Loss: 0.0315\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [982/1000], Validation Loss: 0.0314\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0308\n",
            "Epoch [983/1000], Validation Loss: 0.0314\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0312\n",
            "Epoch [984/1000], Validation Loss: 0.0315\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0309\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0307\n",
            "Epoch [985/1000], Validation Loss: 0.0315\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [986/1000], Validation Loss: 0.0314\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [987/1000], Validation Loss: 0.0314\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [988/1000], Validation Loss: 0.0314\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0313\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0302\n",
            "Epoch [989/1000], Validation Loss: 0.0316\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0306\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0311\n",
            "Epoch [990/1000], Validation Loss: 0.0314\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0315\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0299\n",
            "Epoch [991/1000], Validation Loss: 0.0314\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [992/1000], Validation Loss: 0.0314\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0304\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0315\n",
            "Epoch [993/1000], Validation Loss: 0.0314\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [994/1000], Validation Loss: 0.0314\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0304\n",
            "Epoch [995/1000], Validation Loss: 0.0314\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0311\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0305\n",
            "Epoch [996/1000], Validation Loss: 0.0315\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0308\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0310\n",
            "Epoch [997/1000], Validation Loss: 0.0314\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0307\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0309\n",
            "Epoch [998/1000], Validation Loss: 0.0314\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0310\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0306\n",
            "Epoch [999/1000], Validation Loss: 0.0314\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0312\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0303\n",
            "Epoch [1000/1000], Validation Loss: 0.0315\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 4"
      ],
      "metadata": {
        "id": "NJExqqSw6IdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture for feature generation\n",
        "class Generator4(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "      super(Generator4, self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.output_size = output_size\n",
        "      self.num_layers = num_layers\n",
        "\n",
        "      # Define the layers\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(nn.Linear(input_size, hidden_size))\n",
        "      for _ in range(num_layers - 2):\n",
        "        self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers[:-1]:\n",
        "        x = F.relu(layer(x))\n",
        "      x = self.layers[-1](x)\n",
        "      return x\n",
        "\n",
        "# Define the differential privacy mechanism\n",
        "class DPGenerator4(Generator4):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm):\n",
        "          super(DPGenerator4, self).__init__(input_size, hidden_size, output_size, num_layers)\n",
        "          self.noise_multiplier = noise_multiplier\n",
        "          self.max_grad_norm = max_grad_norm\n",
        "\n",
        "          # Ensure all parameters have requires_grad=True\n",
        "          for param in self.parameters():\n",
        "              param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add noise during forward pass for privacy\n",
        "        with torch.no_grad():\n",
        "            x = super().forward(x)\n",
        "            x += torch.randn_like(x) * self.noise_multiplier\n",
        "        return x"
      ],
      "metadata": {
        "id": "tS7S0E8a6KTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model4 = DPGenerator4(input_size, hidden_size, output_size, num_layers, noise_multiplier, max_grad_norm).to(device)\n",
        "\n",
        "# Define the loss function\n",
        "optimizer4 = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion4 = nn.MSELoss()"
      ],
      "metadata": {
        "id": "CMz0aC9Q62Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty list to store generated features\n",
        "generated_features = []\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n"
      ],
      "metadata": {
        "id": "fCCdDGKS6Jsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model4.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer4.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device).float(), deepfake_features.to(device).float()\n",
        "        real_features.requires_grad = True  # Ensure gradients are tracked for inputs\n",
        "        deepfake_features.requires_grad = True\n",
        "        output = model4(real_features)\n",
        "        loss = criterion4(output, deepfake_features)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer4.step()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model4.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model4(real_features)\n",
        "            loss = criterion4(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Define the window size for smoothing\n",
        "window_size = 10\n",
        "\n",
        "# Smooth the train and validation losses\n",
        "smooth_train_losses = moving_average(train_losses, window_size)\n",
        "smooth_val_losses = moving_average(val_losses, window_size)\n",
        "\n",
        "# Plot the smoothed losses\n",
        "plt.plot(smooth_train_losses, label='Smoothed Train Loss')\n",
        "plt.plot(smooth_val_losses, label='Smoothed Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iUHQ830T67Xp",
        "outputId": "7e5a6040-75ec-42d1-86e3-f28facea5d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [1/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [1/1000], Validation Loss: 0.0382\n",
            "Epoch [2/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [2/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [2/1000], Validation Loss: 0.0383\n",
            "Epoch [3/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [3/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [3/1000], Validation Loss: 0.0383\n",
            "Epoch [4/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [4/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [4/1000], Validation Loss: 0.0382\n",
            "Epoch [5/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [5/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [5/1000], Validation Loss: 0.0382\n",
            "Epoch [6/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [6/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [6/1000], Validation Loss: 0.0382\n",
            "Epoch [7/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [7/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [7/1000], Validation Loss: 0.0382\n",
            "Epoch [8/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [8/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [8/1000], Validation Loss: 0.0382\n",
            "Epoch [9/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [9/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [9/1000], Validation Loss: 0.0382\n",
            "Epoch [10/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [10/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [10/1000], Validation Loss: 0.0382\n",
            "Epoch [11/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [11/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [11/1000], Validation Loss: 0.0383\n",
            "Epoch [12/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [12/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [12/1000], Validation Loss: 0.0383\n",
            "Epoch [13/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [13/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [13/1000], Validation Loss: 0.0382\n",
            "Epoch [14/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [14/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [14/1000], Validation Loss: 0.0382\n",
            "Epoch [15/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [15/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [15/1000], Validation Loss: 0.0382\n",
            "Epoch [16/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [16/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [16/1000], Validation Loss: 0.0382\n",
            "Epoch [17/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [17/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [17/1000], Validation Loss: 0.0384\n",
            "Epoch [18/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [18/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [18/1000], Validation Loss: 0.0383\n",
            "Epoch [19/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [19/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [19/1000], Validation Loss: 0.0383\n",
            "Epoch [20/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [20/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [20/1000], Validation Loss: 0.0382\n",
            "Epoch [21/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [21/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [21/1000], Validation Loss: 0.0383\n",
            "Epoch [22/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [22/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [22/1000], Validation Loss: 0.0381\n",
            "Epoch [23/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [23/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [23/1000], Validation Loss: 0.0382\n",
            "Epoch [24/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [24/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [24/1000], Validation Loss: 0.0381\n",
            "Epoch [25/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [25/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [25/1000], Validation Loss: 0.0381\n",
            "Epoch [26/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [26/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [26/1000], Validation Loss: 0.0383\n",
            "Epoch [27/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [27/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [27/1000], Validation Loss: 0.0382\n",
            "Epoch [28/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [28/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [28/1000], Validation Loss: 0.0381\n",
            "Epoch [29/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [29/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [29/1000], Validation Loss: 0.0382\n",
            "Epoch [30/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [30/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [30/1000], Validation Loss: 0.0382\n",
            "Epoch [31/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [31/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [31/1000], Validation Loss: 0.0382\n",
            "Epoch [32/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [32/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [32/1000], Validation Loss: 0.0383\n",
            "Epoch [33/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [33/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [33/1000], Validation Loss: 0.0383\n",
            "Epoch [34/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [34/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [34/1000], Validation Loss: 0.0382\n",
            "Epoch [35/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [35/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [35/1000], Validation Loss: 0.0382\n",
            "Epoch [36/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [36/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [36/1000], Validation Loss: 0.0383\n",
            "Epoch [37/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [37/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [37/1000], Validation Loss: 0.0382\n",
            "Epoch [38/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [38/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [38/1000], Validation Loss: 0.0382\n",
            "Epoch [39/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [39/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [39/1000], Validation Loss: 0.0382\n",
            "Epoch [40/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [40/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [40/1000], Validation Loss: 0.0381\n",
            "Epoch [41/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [41/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [41/1000], Validation Loss: 0.0382\n",
            "Epoch [42/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [42/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [42/1000], Validation Loss: 0.0383\n",
            "Epoch [43/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [43/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [43/1000], Validation Loss: 0.0382\n",
            "Epoch [44/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [44/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [44/1000], Validation Loss: 0.0383\n",
            "Epoch [45/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [45/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [45/1000], Validation Loss: 0.0382\n",
            "Epoch [46/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [46/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [46/1000], Validation Loss: 0.0381\n",
            "Epoch [47/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [47/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [47/1000], Validation Loss: 0.0383\n",
            "Epoch [48/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [48/1000], Batch [2/2], Train Loss: 0.0388\n",
            "Epoch [48/1000], Validation Loss: 0.0383\n",
            "Epoch [49/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [49/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [49/1000], Validation Loss: 0.0382\n",
            "Epoch [50/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [50/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [50/1000], Validation Loss: 0.0382\n",
            "Epoch [51/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [51/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [51/1000], Validation Loss: 0.0382\n",
            "Epoch [52/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [52/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [52/1000], Validation Loss: 0.0383\n",
            "Epoch [53/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [53/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [53/1000], Validation Loss: 0.0383\n",
            "Epoch [54/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [54/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [54/1000], Validation Loss: 0.0383\n",
            "Epoch [55/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [55/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [55/1000], Validation Loss: 0.0383\n",
            "Epoch [56/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [56/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [56/1000], Validation Loss: 0.0382\n",
            "Epoch [57/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [57/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [57/1000], Validation Loss: 0.0382\n",
            "Epoch [58/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [58/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [58/1000], Validation Loss: 0.0383\n",
            "Epoch [59/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [59/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [59/1000], Validation Loss: 0.0381\n",
            "Epoch [60/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [60/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [60/1000], Validation Loss: 0.0382\n",
            "Epoch [61/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [61/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [61/1000], Validation Loss: 0.0383\n",
            "Epoch [62/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [62/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [62/1000], Validation Loss: 0.0383\n",
            "Epoch [63/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [63/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [63/1000], Validation Loss: 0.0383\n",
            "Epoch [64/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [64/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [64/1000], Validation Loss: 0.0383\n",
            "Epoch [65/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [65/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [65/1000], Validation Loss: 0.0382\n",
            "Epoch [66/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [66/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [66/1000], Validation Loss: 0.0383\n",
            "Epoch [67/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [67/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [67/1000], Validation Loss: 0.0382\n",
            "Epoch [68/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [68/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [68/1000], Validation Loss: 0.0382\n",
            "Epoch [69/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [69/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [69/1000], Validation Loss: 0.0382\n",
            "Epoch [70/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [70/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [70/1000], Validation Loss: 0.0382\n",
            "Epoch [71/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [71/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [71/1000], Validation Loss: 0.0382\n",
            "Epoch [72/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [72/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [72/1000], Validation Loss: 0.0382\n",
            "Epoch [73/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [73/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [73/1000], Validation Loss: 0.0382\n",
            "Epoch [74/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [74/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [74/1000], Validation Loss: 0.0382\n",
            "Epoch [75/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [75/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [75/1000], Validation Loss: 0.0382\n",
            "Epoch [76/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [76/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [76/1000], Validation Loss: 0.0382\n",
            "Epoch [77/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [77/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [77/1000], Validation Loss: 0.0382\n",
            "Epoch [78/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [78/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [78/1000], Validation Loss: 0.0382\n",
            "Epoch [79/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [79/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [79/1000], Validation Loss: 0.0383\n",
            "Epoch [80/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [80/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [80/1000], Validation Loss: 0.0382\n",
            "Epoch [81/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [81/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [81/1000], Validation Loss: 0.0383\n",
            "Epoch [82/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [82/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [82/1000], Validation Loss: 0.0383\n",
            "Epoch [83/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [83/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [83/1000], Validation Loss: 0.0383\n",
            "Epoch [84/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [84/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [84/1000], Validation Loss: 0.0383\n",
            "Epoch [85/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [85/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [85/1000], Validation Loss: 0.0382\n",
            "Epoch [86/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [86/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [86/1000], Validation Loss: 0.0382\n",
            "Epoch [87/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [87/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [87/1000], Validation Loss: 0.0383\n",
            "Epoch [88/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [88/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [88/1000], Validation Loss: 0.0382\n",
            "Epoch [89/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [89/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [89/1000], Validation Loss: 0.0384\n",
            "Epoch [90/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [90/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [90/1000], Validation Loss: 0.0383\n",
            "Epoch [91/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [91/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [91/1000], Validation Loss: 0.0381\n",
            "Epoch [92/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [92/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [92/1000], Validation Loss: 0.0381\n",
            "Epoch [93/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [93/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [93/1000], Validation Loss: 0.0383\n",
            "Epoch [94/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [94/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [94/1000], Validation Loss: 0.0383\n",
            "Epoch [95/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [95/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [95/1000], Validation Loss: 0.0382\n",
            "Epoch [96/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [96/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [96/1000], Validation Loss: 0.0382\n",
            "Epoch [97/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [97/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [97/1000], Validation Loss: 0.0382\n",
            "Epoch [98/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [98/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [98/1000], Validation Loss: 0.0382\n",
            "Epoch [99/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [99/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [99/1000], Validation Loss: 0.0383\n",
            "Epoch [100/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [100/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [100/1000], Validation Loss: 0.0381\n",
            "Epoch [101/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [101/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [101/1000], Validation Loss: 0.0382\n",
            "Epoch [102/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [102/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [102/1000], Validation Loss: 0.0382\n",
            "Epoch [103/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [103/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [103/1000], Validation Loss: 0.0382\n",
            "Epoch [104/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [104/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [104/1000], Validation Loss: 0.0382\n",
            "Epoch [105/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [105/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [105/1000], Validation Loss: 0.0382\n",
            "Epoch [106/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [106/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [106/1000], Validation Loss: 0.0383\n",
            "Epoch [107/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [107/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [107/1000], Validation Loss: 0.0382\n",
            "Epoch [108/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [108/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [108/1000], Validation Loss: 0.0382\n",
            "Epoch [109/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [109/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [109/1000], Validation Loss: 0.0383\n",
            "Epoch [110/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [110/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [110/1000], Validation Loss: 0.0382\n",
            "Epoch [111/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [111/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [111/1000], Validation Loss: 0.0381\n",
            "Epoch [112/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [112/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [112/1000], Validation Loss: 0.0382\n",
            "Epoch [113/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [113/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [113/1000], Validation Loss: 0.0382\n",
            "Epoch [114/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [114/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [114/1000], Validation Loss: 0.0383\n",
            "Epoch [115/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [115/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [115/1000], Validation Loss: 0.0382\n",
            "Epoch [116/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [116/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [116/1000], Validation Loss: 0.0382\n",
            "Epoch [117/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [117/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [117/1000], Validation Loss: 0.0383\n",
            "Epoch [118/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [118/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [118/1000], Validation Loss: 0.0382\n",
            "Epoch [119/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [119/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [119/1000], Validation Loss: 0.0383\n",
            "Epoch [120/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [120/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [120/1000], Validation Loss: 0.0382\n",
            "Epoch [121/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [121/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [121/1000], Validation Loss: 0.0383\n",
            "Epoch [122/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [122/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [122/1000], Validation Loss: 0.0383\n",
            "Epoch [123/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [123/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [123/1000], Validation Loss: 0.0383\n",
            "Epoch [124/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [124/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [124/1000], Validation Loss: 0.0383\n",
            "Epoch [125/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [125/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [125/1000], Validation Loss: 0.0382\n",
            "Epoch [126/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [126/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [126/1000], Validation Loss: 0.0382\n",
            "Epoch [127/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [127/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [127/1000], Validation Loss: 0.0383\n",
            "Epoch [128/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [128/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [128/1000], Validation Loss: 0.0382\n",
            "Epoch [129/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [129/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [129/1000], Validation Loss: 0.0382\n",
            "Epoch [130/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [130/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [130/1000], Validation Loss: 0.0383\n",
            "Epoch [131/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [131/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [131/1000], Validation Loss: 0.0382\n",
            "Epoch [132/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [132/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [132/1000], Validation Loss: 0.0383\n",
            "Epoch [133/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [133/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [133/1000], Validation Loss: 0.0382\n",
            "Epoch [134/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [134/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [134/1000], Validation Loss: 0.0382\n",
            "Epoch [135/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [135/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [135/1000], Validation Loss: 0.0382\n",
            "Epoch [136/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [136/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [136/1000], Validation Loss: 0.0382\n",
            "Epoch [137/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [137/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [137/1000], Validation Loss: 0.0382\n",
            "Epoch [138/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [138/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [138/1000], Validation Loss: 0.0381\n",
            "Epoch [139/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [139/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [139/1000], Validation Loss: 0.0383\n",
            "Epoch [140/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [140/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [140/1000], Validation Loss: 0.0383\n",
            "Epoch [141/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [141/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [141/1000], Validation Loss: 0.0382\n",
            "Epoch [142/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [142/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [142/1000], Validation Loss: 0.0382\n",
            "Epoch [143/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [143/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [143/1000], Validation Loss: 0.0383\n",
            "Epoch [144/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [144/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [144/1000], Validation Loss: 0.0382\n",
            "Epoch [145/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [145/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [145/1000], Validation Loss: 0.0383\n",
            "Epoch [146/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [146/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [146/1000], Validation Loss: 0.0382\n",
            "Epoch [147/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [147/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [147/1000], Validation Loss: 0.0382\n",
            "Epoch [148/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [148/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [148/1000], Validation Loss: 0.0382\n",
            "Epoch [149/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [149/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [149/1000], Validation Loss: 0.0382\n",
            "Epoch [150/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [150/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [150/1000], Validation Loss: 0.0382\n",
            "Epoch [151/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [151/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [151/1000], Validation Loss: 0.0383\n",
            "Epoch [152/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [152/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [152/1000], Validation Loss: 0.0383\n",
            "Epoch [153/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [153/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [153/1000], Validation Loss: 0.0383\n",
            "Epoch [154/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [154/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [154/1000], Validation Loss: 0.0383\n",
            "Epoch [155/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [155/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [155/1000], Validation Loss: 0.0382\n",
            "Epoch [156/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [156/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [156/1000], Validation Loss: 0.0382\n",
            "Epoch [157/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [157/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [157/1000], Validation Loss: 0.0381\n",
            "Epoch [158/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [158/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [158/1000], Validation Loss: 0.0383\n",
            "Epoch [159/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [159/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [159/1000], Validation Loss: 0.0382\n",
            "Epoch [160/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [160/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [160/1000], Validation Loss: 0.0381\n",
            "Epoch [161/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [161/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [161/1000], Validation Loss: 0.0382\n",
            "Epoch [162/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [162/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [162/1000], Validation Loss: 0.0383\n",
            "Epoch [163/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [163/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [163/1000], Validation Loss: 0.0382\n",
            "Epoch [164/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [164/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [164/1000], Validation Loss: 0.0382\n",
            "Epoch [165/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [165/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [165/1000], Validation Loss: 0.0383\n",
            "Epoch [166/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [166/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [166/1000], Validation Loss: 0.0382\n",
            "Epoch [167/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [167/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [167/1000], Validation Loss: 0.0382\n",
            "Epoch [168/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [168/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [168/1000], Validation Loss: 0.0382\n",
            "Epoch [169/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [169/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [169/1000], Validation Loss: 0.0382\n",
            "Epoch [170/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [170/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [170/1000], Validation Loss: 0.0382\n",
            "Epoch [171/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [171/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [171/1000], Validation Loss: 0.0382\n",
            "Epoch [172/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [172/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [172/1000], Validation Loss: 0.0382\n",
            "Epoch [173/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [173/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [173/1000], Validation Loss: 0.0381\n",
            "Epoch [174/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [174/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [174/1000], Validation Loss: 0.0381\n",
            "Epoch [175/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [175/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [175/1000], Validation Loss: 0.0383\n",
            "Epoch [176/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [176/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [176/1000], Validation Loss: 0.0383\n",
            "Epoch [177/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [177/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [177/1000], Validation Loss: 0.0382\n",
            "Epoch [178/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [178/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [178/1000], Validation Loss: 0.0382\n",
            "Epoch [179/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [179/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [179/1000], Validation Loss: 0.0382\n",
            "Epoch [180/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [180/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [180/1000], Validation Loss: 0.0382\n",
            "Epoch [181/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [181/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [181/1000], Validation Loss: 0.0381\n",
            "Epoch [182/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [182/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [182/1000], Validation Loss: 0.0383\n",
            "Epoch [183/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [183/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [183/1000], Validation Loss: 0.0382\n",
            "Epoch [184/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [184/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [184/1000], Validation Loss: 0.0383\n",
            "Epoch [185/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [185/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [185/1000], Validation Loss: 0.0382\n",
            "Epoch [186/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [186/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [186/1000], Validation Loss: 0.0382\n",
            "Epoch [187/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [187/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [187/1000], Validation Loss: 0.0383\n",
            "Epoch [188/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [188/1000], Batch [2/2], Train Loss: 0.0387\n",
            "Epoch [188/1000], Validation Loss: 0.0383\n",
            "Epoch [189/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [189/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [189/1000], Validation Loss: 0.0381\n",
            "Epoch [190/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [190/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [190/1000], Validation Loss: 0.0383\n",
            "Epoch [191/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [191/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [191/1000], Validation Loss: 0.0382\n",
            "Epoch [192/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [192/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [192/1000], Validation Loss: 0.0382\n",
            "Epoch [193/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [193/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [193/1000], Validation Loss: 0.0383\n",
            "Epoch [194/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [194/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [194/1000], Validation Loss: 0.0382\n",
            "Epoch [195/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [195/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [195/1000], Validation Loss: 0.0383\n",
            "Epoch [196/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [196/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [196/1000], Validation Loss: 0.0382\n",
            "Epoch [197/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [197/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [197/1000], Validation Loss: 0.0382\n",
            "Epoch [198/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [198/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [198/1000], Validation Loss: 0.0382\n",
            "Epoch [199/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [199/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [199/1000], Validation Loss: 0.0381\n",
            "Epoch [200/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [200/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [200/1000], Validation Loss: 0.0382\n",
            "Epoch [201/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [201/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [201/1000], Validation Loss: 0.0382\n",
            "Epoch [202/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [202/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [202/1000], Validation Loss: 0.0383\n",
            "Epoch [203/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [203/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [203/1000], Validation Loss: 0.0383\n",
            "Epoch [204/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [204/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [204/1000], Validation Loss: 0.0382\n",
            "Epoch [205/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [205/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [205/1000], Validation Loss: 0.0383\n",
            "Epoch [206/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [206/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [206/1000], Validation Loss: 0.0382\n",
            "Epoch [207/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [207/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [207/1000], Validation Loss: 0.0383\n",
            "Epoch [208/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [208/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [208/1000], Validation Loss: 0.0383\n",
            "Epoch [209/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [209/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [209/1000], Validation Loss: 0.0382\n",
            "Epoch [210/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [210/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [210/1000], Validation Loss: 0.0381\n",
            "Epoch [211/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [211/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [211/1000], Validation Loss: 0.0382\n",
            "Epoch [212/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [212/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [212/1000], Validation Loss: 0.0383\n",
            "Epoch [213/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [213/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [213/1000], Validation Loss: 0.0382\n",
            "Epoch [214/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [214/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [214/1000], Validation Loss: 0.0382\n",
            "Epoch [215/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [215/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [215/1000], Validation Loss: 0.0382\n",
            "Epoch [216/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [216/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [216/1000], Validation Loss: 0.0382\n",
            "Epoch [217/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [217/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [217/1000], Validation Loss: 0.0382\n",
            "Epoch [218/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [218/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [218/1000], Validation Loss: 0.0383\n",
            "Epoch [219/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [219/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [219/1000], Validation Loss: 0.0382\n",
            "Epoch [220/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [220/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [220/1000], Validation Loss: 0.0382\n",
            "Epoch [221/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [221/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [221/1000], Validation Loss: 0.0382\n",
            "Epoch [222/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [222/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [222/1000], Validation Loss: 0.0382\n",
            "Epoch [223/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [223/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [223/1000], Validation Loss: 0.0382\n",
            "Epoch [224/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [224/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [224/1000], Validation Loss: 0.0383\n",
            "Epoch [225/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [225/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [225/1000], Validation Loss: 0.0383\n",
            "Epoch [226/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [226/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [226/1000], Validation Loss: 0.0383\n",
            "Epoch [227/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [227/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [227/1000], Validation Loss: 0.0383\n",
            "Epoch [228/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [228/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [228/1000], Validation Loss: 0.0382\n",
            "Epoch [229/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [229/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [229/1000], Validation Loss: 0.0381\n",
            "Epoch [230/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [230/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [230/1000], Validation Loss: 0.0383\n",
            "Epoch [231/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [231/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [231/1000], Validation Loss: 0.0383\n",
            "Epoch [232/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [232/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [232/1000], Validation Loss: 0.0382\n",
            "Epoch [233/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [233/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [233/1000], Validation Loss: 0.0382\n",
            "Epoch [234/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [234/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [234/1000], Validation Loss: 0.0382\n",
            "Epoch [235/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [235/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [235/1000], Validation Loss: 0.0382\n",
            "Epoch [236/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [236/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [236/1000], Validation Loss: 0.0382\n",
            "Epoch [237/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [237/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [237/1000], Validation Loss: 0.0382\n",
            "Epoch [238/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [238/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [238/1000], Validation Loss: 0.0382\n",
            "Epoch [239/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [239/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [239/1000], Validation Loss: 0.0382\n",
            "Epoch [240/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [240/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [240/1000], Validation Loss: 0.0383\n",
            "Epoch [241/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [241/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [241/1000], Validation Loss: 0.0382\n",
            "Epoch [242/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [242/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [242/1000], Validation Loss: 0.0382\n",
            "Epoch [243/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [243/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [243/1000], Validation Loss: 0.0382\n",
            "Epoch [244/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [244/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [244/1000], Validation Loss: 0.0382\n",
            "Epoch [245/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [245/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [245/1000], Validation Loss: 0.0382\n",
            "Epoch [246/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [246/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [246/1000], Validation Loss: 0.0382\n",
            "Epoch [247/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [247/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [247/1000], Validation Loss: 0.0383\n",
            "Epoch [248/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [248/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [248/1000], Validation Loss: 0.0382\n",
            "Epoch [249/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [249/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [249/1000], Validation Loss: 0.0383\n",
            "Epoch [250/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [250/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [250/1000], Validation Loss: 0.0382\n",
            "Epoch [251/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [251/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [251/1000], Validation Loss: 0.0382\n",
            "Epoch [252/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [252/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [252/1000], Validation Loss: 0.0383\n",
            "Epoch [253/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [253/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [253/1000], Validation Loss: 0.0382\n",
            "Epoch [254/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [254/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [254/1000], Validation Loss: 0.0382\n",
            "Epoch [255/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [255/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [255/1000], Validation Loss: 0.0382\n",
            "Epoch [256/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [256/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [256/1000], Validation Loss: 0.0382\n",
            "Epoch [257/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [257/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [257/1000], Validation Loss: 0.0383\n",
            "Epoch [258/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [258/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [258/1000], Validation Loss: 0.0382\n",
            "Epoch [259/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [259/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [259/1000], Validation Loss: 0.0382\n",
            "Epoch [260/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [260/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [260/1000], Validation Loss: 0.0382\n",
            "Epoch [261/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [261/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [261/1000], Validation Loss: 0.0382\n",
            "Epoch [262/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [262/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [262/1000], Validation Loss: 0.0383\n",
            "Epoch [263/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [263/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [263/1000], Validation Loss: 0.0382\n",
            "Epoch [264/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [264/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [264/1000], Validation Loss: 0.0382\n",
            "Epoch [265/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [265/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [265/1000], Validation Loss: 0.0382\n",
            "Epoch [266/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [266/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [266/1000], Validation Loss: 0.0383\n",
            "Epoch [267/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [267/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [267/1000], Validation Loss: 0.0382\n",
            "Epoch [268/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [268/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [268/1000], Validation Loss: 0.0382\n",
            "Epoch [269/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [269/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [269/1000], Validation Loss: 0.0382\n",
            "Epoch [270/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [270/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [270/1000], Validation Loss: 0.0382\n",
            "Epoch [271/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [271/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [271/1000], Validation Loss: 0.0382\n",
            "Epoch [272/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [272/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [272/1000], Validation Loss: 0.0382\n",
            "Epoch [273/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [273/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [273/1000], Validation Loss: 0.0381\n",
            "Epoch [274/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [274/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [274/1000], Validation Loss: 0.0382\n",
            "Epoch [275/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [275/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [275/1000], Validation Loss: 0.0382\n",
            "Epoch [276/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [276/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [276/1000], Validation Loss: 0.0383\n",
            "Epoch [277/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [277/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [277/1000], Validation Loss: 0.0382\n",
            "Epoch [278/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [278/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [278/1000], Validation Loss: 0.0382\n",
            "Epoch [279/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [279/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [279/1000], Validation Loss: 0.0383\n",
            "Epoch [280/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [280/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [280/1000], Validation Loss: 0.0381\n",
            "Epoch [281/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [281/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [281/1000], Validation Loss: 0.0381\n",
            "Epoch [282/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [282/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [282/1000], Validation Loss: 0.0383\n",
            "Epoch [283/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [283/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [283/1000], Validation Loss: 0.0382\n",
            "Epoch [284/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [284/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [284/1000], Validation Loss: 0.0382\n",
            "Epoch [285/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [285/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [285/1000], Validation Loss: 0.0383\n",
            "Epoch [286/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [286/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [286/1000], Validation Loss: 0.0383\n",
            "Epoch [287/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [287/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [287/1000], Validation Loss: 0.0383\n",
            "Epoch [288/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [288/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [288/1000], Validation Loss: 0.0382\n",
            "Epoch [289/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [289/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [289/1000], Validation Loss: 0.0382\n",
            "Epoch [290/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [290/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [290/1000], Validation Loss: 0.0383\n",
            "Epoch [291/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [291/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [291/1000], Validation Loss: 0.0382\n",
            "Epoch [292/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [292/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [292/1000], Validation Loss: 0.0382\n",
            "Epoch [293/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [293/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [293/1000], Validation Loss: 0.0382\n",
            "Epoch [294/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [294/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [294/1000], Validation Loss: 0.0382\n",
            "Epoch [295/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [295/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [295/1000], Validation Loss: 0.0382\n",
            "Epoch [296/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [296/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [296/1000], Validation Loss: 0.0382\n",
            "Epoch [297/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [297/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [297/1000], Validation Loss: 0.0381\n",
            "Epoch [298/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [298/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [298/1000], Validation Loss: 0.0383\n",
            "Epoch [299/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [299/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [299/1000], Validation Loss: 0.0382\n",
            "Epoch [300/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [300/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [300/1000], Validation Loss: 0.0382\n",
            "Epoch [301/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [301/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [301/1000], Validation Loss: 0.0382\n",
            "Epoch [302/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [302/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [302/1000], Validation Loss: 0.0382\n",
            "Epoch [303/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [303/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [303/1000], Validation Loss: 0.0382\n",
            "Epoch [304/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [304/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [304/1000], Validation Loss: 0.0381\n",
            "Epoch [305/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [305/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [305/1000], Validation Loss: 0.0382\n",
            "Epoch [306/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [306/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [306/1000], Validation Loss: 0.0382\n",
            "Epoch [307/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [307/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [307/1000], Validation Loss: 0.0383\n",
            "Epoch [308/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [308/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [308/1000], Validation Loss: 0.0383\n",
            "Epoch [309/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [309/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [309/1000], Validation Loss: 0.0382\n",
            "Epoch [310/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [310/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [310/1000], Validation Loss: 0.0382\n",
            "Epoch [311/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [311/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [311/1000], Validation Loss: 0.0382\n",
            "Epoch [312/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [312/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [312/1000], Validation Loss: 0.0381\n",
            "Epoch [313/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [313/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [313/1000], Validation Loss: 0.0383\n",
            "Epoch [314/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [314/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [314/1000], Validation Loss: 0.0383\n",
            "Epoch [315/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [315/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [315/1000], Validation Loss: 0.0381\n",
            "Epoch [316/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [316/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [316/1000], Validation Loss: 0.0383\n",
            "Epoch [317/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [317/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [317/1000], Validation Loss: 0.0383\n",
            "Epoch [318/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [318/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [318/1000], Validation Loss: 0.0382\n",
            "Epoch [319/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [319/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [319/1000], Validation Loss: 0.0383\n",
            "Epoch [320/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [320/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [320/1000], Validation Loss: 0.0382\n",
            "Epoch [321/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [321/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [321/1000], Validation Loss: 0.0383\n",
            "Epoch [322/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [322/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [322/1000], Validation Loss: 0.0383\n",
            "Epoch [323/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [323/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [323/1000], Validation Loss: 0.0381\n",
            "Epoch [324/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [324/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [324/1000], Validation Loss: 0.0383\n",
            "Epoch [325/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [325/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [325/1000], Validation Loss: 0.0383\n",
            "Epoch [326/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [326/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [326/1000], Validation Loss: 0.0383\n",
            "Epoch [327/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [327/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [327/1000], Validation Loss: 0.0382\n",
            "Epoch [328/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [328/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [328/1000], Validation Loss: 0.0382\n",
            "Epoch [329/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [329/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [329/1000], Validation Loss: 0.0382\n",
            "Epoch [330/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [330/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [330/1000], Validation Loss: 0.0383\n",
            "Epoch [331/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [331/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [331/1000], Validation Loss: 0.0383\n",
            "Epoch [332/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [332/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [332/1000], Validation Loss: 0.0382\n",
            "Epoch [333/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [333/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [333/1000], Validation Loss: 0.0383\n",
            "Epoch [334/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [334/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [334/1000], Validation Loss: 0.0383\n",
            "Epoch [335/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [335/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [335/1000], Validation Loss: 0.0382\n",
            "Epoch [336/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [336/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [336/1000], Validation Loss: 0.0382\n",
            "Epoch [337/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [337/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [337/1000], Validation Loss: 0.0383\n",
            "Epoch [338/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [338/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [338/1000], Validation Loss: 0.0382\n",
            "Epoch [339/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [339/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [339/1000], Validation Loss: 0.0382\n",
            "Epoch [340/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [340/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [340/1000], Validation Loss: 0.0382\n",
            "Epoch [341/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [341/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [341/1000], Validation Loss: 0.0382\n",
            "Epoch [342/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [342/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [342/1000], Validation Loss: 0.0382\n",
            "Epoch [343/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [343/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [343/1000], Validation Loss: 0.0382\n",
            "Epoch [344/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [344/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [344/1000], Validation Loss: 0.0382\n",
            "Epoch [345/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [345/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [345/1000], Validation Loss: 0.0382\n",
            "Epoch [346/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [346/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [346/1000], Validation Loss: 0.0382\n",
            "Epoch [347/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [347/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [347/1000], Validation Loss: 0.0384\n",
            "Epoch [348/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [348/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [348/1000], Validation Loss: 0.0383\n",
            "Epoch [349/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [349/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [349/1000], Validation Loss: 0.0382\n",
            "Epoch [350/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [350/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [350/1000], Validation Loss: 0.0382\n",
            "Epoch [351/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [351/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [351/1000], Validation Loss: 0.0382\n",
            "Epoch [352/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [352/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [352/1000], Validation Loss: 0.0382\n",
            "Epoch [353/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [353/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [353/1000], Validation Loss: 0.0382\n",
            "Epoch [354/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [354/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [354/1000], Validation Loss: 0.0382\n",
            "Epoch [355/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [355/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [355/1000], Validation Loss: 0.0383\n",
            "Epoch [356/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [356/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [356/1000], Validation Loss: 0.0382\n",
            "Epoch [357/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [357/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [357/1000], Validation Loss: 0.0382\n",
            "Epoch [358/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [358/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [358/1000], Validation Loss: 0.0383\n",
            "Epoch [359/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [359/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [359/1000], Validation Loss: 0.0383\n",
            "Epoch [360/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [360/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [360/1000], Validation Loss: 0.0382\n",
            "Epoch [361/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [361/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [361/1000], Validation Loss: 0.0382\n",
            "Epoch [362/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [362/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [362/1000], Validation Loss: 0.0382\n",
            "Epoch [363/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [363/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [363/1000], Validation Loss: 0.0381\n",
            "Epoch [364/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [364/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [364/1000], Validation Loss: 0.0381\n",
            "Epoch [365/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [365/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [365/1000], Validation Loss: 0.0382\n",
            "Epoch [366/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [366/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [366/1000], Validation Loss: 0.0383\n",
            "Epoch [367/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [367/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [367/1000], Validation Loss: 0.0382\n",
            "Epoch [368/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [368/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [368/1000], Validation Loss: 0.0383\n",
            "Epoch [369/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [369/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [369/1000], Validation Loss: 0.0383\n",
            "Epoch [370/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [370/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [370/1000], Validation Loss: 0.0382\n",
            "Epoch [371/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [371/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [371/1000], Validation Loss: 0.0383\n",
            "Epoch [372/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [372/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [372/1000], Validation Loss: 0.0383\n",
            "Epoch [373/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [373/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [373/1000], Validation Loss: 0.0382\n",
            "Epoch [374/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [374/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [374/1000], Validation Loss: 0.0382\n",
            "Epoch [375/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [375/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [375/1000], Validation Loss: 0.0382\n",
            "Epoch [376/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [376/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [376/1000], Validation Loss: 0.0382\n",
            "Epoch [377/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [377/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [377/1000], Validation Loss: 0.0382\n",
            "Epoch [378/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [378/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [378/1000], Validation Loss: 0.0383\n",
            "Epoch [379/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [379/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [379/1000], Validation Loss: 0.0383\n",
            "Epoch [380/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [380/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [380/1000], Validation Loss: 0.0383\n",
            "Epoch [381/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [381/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [381/1000], Validation Loss: 0.0382\n",
            "Epoch [382/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [382/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [382/1000], Validation Loss: 0.0382\n",
            "Epoch [383/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [383/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [383/1000], Validation Loss: 0.0382\n",
            "Epoch [384/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [384/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [384/1000], Validation Loss: 0.0382\n",
            "Epoch [385/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [385/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [385/1000], Validation Loss: 0.0382\n",
            "Epoch [386/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [386/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [386/1000], Validation Loss: 0.0382\n",
            "Epoch [387/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [387/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [387/1000], Validation Loss: 0.0382\n",
            "Epoch [388/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [388/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [388/1000], Validation Loss: 0.0383\n",
            "Epoch [389/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [389/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [389/1000], Validation Loss: 0.0382\n",
            "Epoch [390/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [390/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [390/1000], Validation Loss: 0.0383\n",
            "Epoch [391/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [391/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [391/1000], Validation Loss: 0.0382\n",
            "Epoch [392/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [392/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [392/1000], Validation Loss: 0.0382\n",
            "Epoch [393/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [393/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [393/1000], Validation Loss: 0.0382\n",
            "Epoch [394/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [394/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [394/1000], Validation Loss: 0.0383\n",
            "Epoch [395/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [395/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [395/1000], Validation Loss: 0.0382\n",
            "Epoch [396/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [396/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [396/1000], Validation Loss: 0.0383\n",
            "Epoch [397/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [397/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [397/1000], Validation Loss: 0.0383\n",
            "Epoch [398/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [398/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [398/1000], Validation Loss: 0.0383\n",
            "Epoch [399/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [399/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [399/1000], Validation Loss: 0.0382\n",
            "Epoch [400/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [400/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [400/1000], Validation Loss: 0.0382\n",
            "Epoch [401/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [401/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [401/1000], Validation Loss: 0.0383\n",
            "Epoch [402/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [402/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [402/1000], Validation Loss: 0.0383\n",
            "Epoch [403/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [403/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [403/1000], Validation Loss: 0.0382\n",
            "Epoch [404/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [404/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [404/1000], Validation Loss: 0.0382\n",
            "Epoch [405/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [405/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [405/1000], Validation Loss: 0.0382\n",
            "Epoch [406/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [406/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [406/1000], Validation Loss: 0.0382\n",
            "Epoch [407/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [407/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [407/1000], Validation Loss: 0.0383\n",
            "Epoch [408/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [408/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [408/1000], Validation Loss: 0.0382\n",
            "Epoch [409/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [409/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [409/1000], Validation Loss: 0.0382\n",
            "Epoch [410/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [410/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [410/1000], Validation Loss: 0.0383\n",
            "Epoch [411/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [411/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [411/1000], Validation Loss: 0.0383\n",
            "Epoch [412/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [412/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [412/1000], Validation Loss: 0.0383\n",
            "Epoch [413/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [413/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [413/1000], Validation Loss: 0.0381\n",
            "Epoch [414/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [414/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [414/1000], Validation Loss: 0.0382\n",
            "Epoch [415/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [415/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [415/1000], Validation Loss: 0.0382\n",
            "Epoch [416/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [416/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [416/1000], Validation Loss: 0.0382\n",
            "Epoch [417/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [417/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [417/1000], Validation Loss: 0.0382\n",
            "Epoch [418/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [418/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [418/1000], Validation Loss: 0.0382\n",
            "Epoch [419/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [419/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [419/1000], Validation Loss: 0.0383\n",
            "Epoch [420/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [420/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [420/1000], Validation Loss: 0.0383\n",
            "Epoch [421/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [421/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [421/1000], Validation Loss: 0.0383\n",
            "Epoch [422/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [422/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [422/1000], Validation Loss: 0.0382\n",
            "Epoch [423/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [423/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [423/1000], Validation Loss: 0.0382\n",
            "Epoch [424/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [424/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [424/1000], Validation Loss: 0.0382\n",
            "Epoch [425/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [425/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [425/1000], Validation Loss: 0.0383\n",
            "Epoch [426/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [426/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [426/1000], Validation Loss: 0.0382\n",
            "Epoch [427/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [427/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [427/1000], Validation Loss: 0.0383\n",
            "Epoch [428/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [428/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [428/1000], Validation Loss: 0.0382\n",
            "Epoch [429/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [429/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [429/1000], Validation Loss: 0.0381\n",
            "Epoch [430/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [430/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [430/1000], Validation Loss: 0.0382\n",
            "Epoch [431/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [431/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [431/1000], Validation Loss: 0.0381\n",
            "Epoch [432/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [432/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [432/1000], Validation Loss: 0.0382\n",
            "Epoch [433/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [433/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [433/1000], Validation Loss: 0.0382\n",
            "Epoch [434/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [434/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [434/1000], Validation Loss: 0.0383\n",
            "Epoch [435/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [435/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [435/1000], Validation Loss: 0.0382\n",
            "Epoch [436/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [436/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [436/1000], Validation Loss: 0.0383\n",
            "Epoch [437/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [437/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [437/1000], Validation Loss: 0.0382\n",
            "Epoch [438/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [438/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [438/1000], Validation Loss: 0.0382\n",
            "Epoch [439/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [439/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [439/1000], Validation Loss: 0.0383\n",
            "Epoch [440/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [440/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [440/1000], Validation Loss: 0.0382\n",
            "Epoch [441/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [441/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [441/1000], Validation Loss: 0.0382\n",
            "Epoch [442/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [442/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [442/1000], Validation Loss: 0.0382\n",
            "Epoch [443/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [443/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [443/1000], Validation Loss: 0.0382\n",
            "Epoch [444/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [444/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [444/1000], Validation Loss: 0.0383\n",
            "Epoch [445/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [445/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [445/1000], Validation Loss: 0.0382\n",
            "Epoch [446/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [446/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [446/1000], Validation Loss: 0.0383\n",
            "Epoch [447/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [447/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [447/1000], Validation Loss: 0.0381\n",
            "Epoch [448/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [448/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [448/1000], Validation Loss: 0.0382\n",
            "Epoch [449/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [449/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [449/1000], Validation Loss: 0.0382\n",
            "Epoch [450/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [450/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [450/1000], Validation Loss: 0.0382\n",
            "Epoch [451/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [451/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [451/1000], Validation Loss: 0.0382\n",
            "Epoch [452/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [452/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [452/1000], Validation Loss: 0.0382\n",
            "Epoch [453/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [453/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [453/1000], Validation Loss: 0.0382\n",
            "Epoch [454/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [454/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [454/1000], Validation Loss: 0.0383\n",
            "Epoch [455/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [455/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [455/1000], Validation Loss: 0.0382\n",
            "Epoch [456/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [456/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [456/1000], Validation Loss: 0.0382\n",
            "Epoch [457/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [457/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [457/1000], Validation Loss: 0.0382\n",
            "Epoch [458/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [458/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [458/1000], Validation Loss: 0.0382\n",
            "Epoch [459/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [459/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [459/1000], Validation Loss: 0.0382\n",
            "Epoch [460/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [460/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [460/1000], Validation Loss: 0.0383\n",
            "Epoch [461/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [461/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [461/1000], Validation Loss: 0.0382\n",
            "Epoch [462/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [462/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [462/1000], Validation Loss: 0.0382\n",
            "Epoch [463/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [463/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [463/1000], Validation Loss: 0.0382\n",
            "Epoch [464/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [464/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [464/1000], Validation Loss: 0.0382\n",
            "Epoch [465/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [465/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [465/1000], Validation Loss: 0.0383\n",
            "Epoch [466/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [466/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [466/1000], Validation Loss: 0.0383\n",
            "Epoch [467/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [467/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [467/1000], Validation Loss: 0.0382\n",
            "Epoch [468/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [468/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [468/1000], Validation Loss: 0.0383\n",
            "Epoch [469/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [469/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [469/1000], Validation Loss: 0.0382\n",
            "Epoch [470/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [470/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [470/1000], Validation Loss: 0.0382\n",
            "Epoch [471/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [471/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [471/1000], Validation Loss: 0.0382\n",
            "Epoch [472/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [472/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [472/1000], Validation Loss: 0.0382\n",
            "Epoch [473/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [473/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [473/1000], Validation Loss: 0.0382\n",
            "Epoch [474/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [474/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [474/1000], Validation Loss: 0.0381\n",
            "Epoch [475/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [475/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [475/1000], Validation Loss: 0.0382\n",
            "Epoch [476/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [476/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [476/1000], Validation Loss: 0.0382\n",
            "Epoch [477/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [477/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [477/1000], Validation Loss: 0.0383\n",
            "Epoch [478/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [478/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [478/1000], Validation Loss: 0.0382\n",
            "Epoch [479/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [479/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [479/1000], Validation Loss: 0.0382\n",
            "Epoch [480/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [480/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [480/1000], Validation Loss: 0.0382\n",
            "Epoch [481/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [481/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [481/1000], Validation Loss: 0.0382\n",
            "Epoch [482/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [482/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [482/1000], Validation Loss: 0.0383\n",
            "Epoch [483/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [483/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [483/1000], Validation Loss: 0.0381\n",
            "Epoch [484/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [484/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [484/1000], Validation Loss: 0.0382\n",
            "Epoch [485/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [485/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [485/1000], Validation Loss: 0.0382\n",
            "Epoch [486/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [486/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [486/1000], Validation Loss: 0.0382\n",
            "Epoch [487/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [487/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [487/1000], Validation Loss: 0.0383\n",
            "Epoch [488/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [488/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [488/1000], Validation Loss: 0.0382\n",
            "Epoch [489/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [489/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [489/1000], Validation Loss: 0.0382\n",
            "Epoch [490/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [490/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [490/1000], Validation Loss: 0.0383\n",
            "Epoch [491/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [491/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [491/1000], Validation Loss: 0.0382\n",
            "Epoch [492/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [492/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [492/1000], Validation Loss: 0.0381\n",
            "Epoch [493/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [493/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [493/1000], Validation Loss: 0.0382\n",
            "Epoch [494/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [494/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [494/1000], Validation Loss: 0.0383\n",
            "Epoch [495/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [495/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [495/1000], Validation Loss: 0.0382\n",
            "Epoch [496/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [496/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [496/1000], Validation Loss: 0.0382\n",
            "Epoch [497/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [497/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [497/1000], Validation Loss: 0.0382\n",
            "Epoch [498/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [498/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [498/1000], Validation Loss: 0.0383\n",
            "Epoch [499/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [499/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [499/1000], Validation Loss: 0.0382\n",
            "Epoch [500/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [500/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [500/1000], Validation Loss: 0.0382\n",
            "Epoch [501/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [501/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [501/1000], Validation Loss: 0.0383\n",
            "Epoch [502/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [502/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [502/1000], Validation Loss: 0.0382\n",
            "Epoch [503/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [503/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [503/1000], Validation Loss: 0.0381\n",
            "Epoch [504/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [504/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [504/1000], Validation Loss: 0.0382\n",
            "Epoch [505/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [505/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [505/1000], Validation Loss: 0.0382\n",
            "Epoch [506/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [506/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [506/1000], Validation Loss: 0.0382\n",
            "Epoch [507/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [507/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [507/1000], Validation Loss: 0.0383\n",
            "Epoch [508/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [508/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [508/1000], Validation Loss: 0.0382\n",
            "Epoch [509/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [509/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [509/1000], Validation Loss: 0.0382\n",
            "Epoch [510/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [510/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [510/1000], Validation Loss: 0.0383\n",
            "Epoch [511/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [511/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [511/1000], Validation Loss: 0.0382\n",
            "Epoch [512/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [512/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [512/1000], Validation Loss: 0.0383\n",
            "Epoch [513/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [513/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [513/1000], Validation Loss: 0.0382\n",
            "Epoch [514/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [514/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [514/1000], Validation Loss: 0.0382\n",
            "Epoch [515/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [515/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [515/1000], Validation Loss: 0.0383\n",
            "Epoch [516/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [516/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [516/1000], Validation Loss: 0.0382\n",
            "Epoch [517/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [517/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [517/1000], Validation Loss: 0.0381\n",
            "Epoch [518/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [518/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [518/1000], Validation Loss: 0.0382\n",
            "Epoch [519/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [519/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [519/1000], Validation Loss: 0.0383\n",
            "Epoch [520/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [520/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [520/1000], Validation Loss: 0.0382\n",
            "Epoch [521/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [521/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [521/1000], Validation Loss: 0.0383\n",
            "Epoch [522/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [522/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [522/1000], Validation Loss: 0.0382\n",
            "Epoch [523/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [523/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [523/1000], Validation Loss: 0.0382\n",
            "Epoch [524/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [524/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [524/1000], Validation Loss: 0.0383\n",
            "Epoch [525/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [525/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [525/1000], Validation Loss: 0.0382\n",
            "Epoch [526/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [526/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [526/1000], Validation Loss: 0.0383\n",
            "Epoch [527/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [527/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [527/1000], Validation Loss: 0.0383\n",
            "Epoch [528/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [528/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [528/1000], Validation Loss: 0.0382\n",
            "Epoch [529/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [529/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [529/1000], Validation Loss: 0.0383\n",
            "Epoch [530/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [530/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [530/1000], Validation Loss: 0.0383\n",
            "Epoch [531/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [531/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [531/1000], Validation Loss: 0.0383\n",
            "Epoch [532/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [532/1000], Batch [2/2], Train Loss: 0.0387\n",
            "Epoch [532/1000], Validation Loss: 0.0382\n",
            "Epoch [533/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [533/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [533/1000], Validation Loss: 0.0383\n",
            "Epoch [534/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [534/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [534/1000], Validation Loss: 0.0382\n",
            "Epoch [535/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [535/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [535/1000], Validation Loss: 0.0382\n",
            "Epoch [536/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [536/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [536/1000], Validation Loss: 0.0383\n",
            "Epoch [537/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [537/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [537/1000], Validation Loss: 0.0383\n",
            "Epoch [538/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [538/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [538/1000], Validation Loss: 0.0382\n",
            "Epoch [539/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [539/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [539/1000], Validation Loss: 0.0383\n",
            "Epoch [540/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [540/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [540/1000], Validation Loss: 0.0382\n",
            "Epoch [541/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [541/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [541/1000], Validation Loss: 0.0382\n",
            "Epoch [542/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [542/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [542/1000], Validation Loss: 0.0383\n",
            "Epoch [543/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [543/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [543/1000], Validation Loss: 0.0383\n",
            "Epoch [544/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [544/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [544/1000], Validation Loss: 0.0382\n",
            "Epoch [545/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [545/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [545/1000], Validation Loss: 0.0382\n",
            "Epoch [546/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [546/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [546/1000], Validation Loss: 0.0382\n",
            "Epoch [547/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [547/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [547/1000], Validation Loss: 0.0383\n",
            "Epoch [548/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [548/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [548/1000], Validation Loss: 0.0382\n",
            "Epoch [549/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [549/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [549/1000], Validation Loss: 0.0382\n",
            "Epoch [550/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [550/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [550/1000], Validation Loss: 0.0382\n",
            "Epoch [551/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [551/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [551/1000], Validation Loss: 0.0382\n",
            "Epoch [552/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [552/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [552/1000], Validation Loss: 0.0382\n",
            "Epoch [553/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [553/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [553/1000], Validation Loss: 0.0382\n",
            "Epoch [554/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [554/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [554/1000], Validation Loss: 0.0382\n",
            "Epoch [555/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [555/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [555/1000], Validation Loss: 0.0383\n",
            "Epoch [556/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [556/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [556/1000], Validation Loss: 0.0383\n",
            "Epoch [557/1000], Batch [1/2], Train Loss: 0.0383\n",
            "Epoch [557/1000], Batch [2/2], Train Loss: 0.0366\n",
            "Epoch [557/1000], Validation Loss: 0.0383\n",
            "Epoch [558/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [558/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [558/1000], Validation Loss: 0.0383\n",
            "Epoch [559/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [559/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [559/1000], Validation Loss: 0.0383\n",
            "Epoch [560/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [560/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [560/1000], Validation Loss: 0.0382\n",
            "Epoch [561/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [561/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [561/1000], Validation Loss: 0.0382\n",
            "Epoch [562/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [562/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [562/1000], Validation Loss: 0.0383\n",
            "Epoch [563/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [563/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [563/1000], Validation Loss: 0.0382\n",
            "Epoch [564/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [564/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [564/1000], Validation Loss: 0.0382\n",
            "Epoch [565/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [565/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [565/1000], Validation Loss: 0.0381\n",
            "Epoch [566/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [566/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [566/1000], Validation Loss: 0.0383\n",
            "Epoch [567/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [567/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [567/1000], Validation Loss: 0.0382\n",
            "Epoch [568/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [568/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [568/1000], Validation Loss: 0.0383\n",
            "Epoch [569/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [569/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [569/1000], Validation Loss: 0.0383\n",
            "Epoch [570/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [570/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [570/1000], Validation Loss: 0.0383\n",
            "Epoch [571/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [571/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [571/1000], Validation Loss: 0.0382\n",
            "Epoch [572/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [572/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [572/1000], Validation Loss: 0.0382\n",
            "Epoch [573/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [573/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [573/1000], Validation Loss: 0.0383\n",
            "Epoch [574/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [574/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [574/1000], Validation Loss: 0.0382\n",
            "Epoch [575/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [575/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [575/1000], Validation Loss: 0.0382\n",
            "Epoch [576/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [576/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [576/1000], Validation Loss: 0.0383\n",
            "Epoch [577/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [577/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [577/1000], Validation Loss: 0.0382\n",
            "Epoch [578/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [578/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [578/1000], Validation Loss: 0.0383\n",
            "Epoch [579/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [579/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [579/1000], Validation Loss: 0.0383\n",
            "Epoch [580/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [580/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [580/1000], Validation Loss: 0.0381\n",
            "Epoch [581/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [581/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [581/1000], Validation Loss: 0.0383\n",
            "Epoch [582/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [582/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [582/1000], Validation Loss: 0.0381\n",
            "Epoch [583/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [583/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [583/1000], Validation Loss: 0.0383\n",
            "Epoch [584/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [584/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [584/1000], Validation Loss: 0.0383\n",
            "Epoch [585/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [585/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [585/1000], Validation Loss: 0.0382\n",
            "Epoch [586/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [586/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [586/1000], Validation Loss: 0.0383\n",
            "Epoch [587/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [587/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [587/1000], Validation Loss: 0.0383\n",
            "Epoch [588/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [588/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [588/1000], Validation Loss: 0.0382\n",
            "Epoch [589/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [589/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [589/1000], Validation Loss: 0.0382\n",
            "Epoch [590/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [590/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [590/1000], Validation Loss: 0.0383\n",
            "Epoch [591/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [591/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [591/1000], Validation Loss: 0.0381\n",
            "Epoch [592/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [592/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [592/1000], Validation Loss: 0.0382\n",
            "Epoch [593/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [593/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [593/1000], Validation Loss: 0.0382\n",
            "Epoch [594/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [594/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [594/1000], Validation Loss: 0.0382\n",
            "Epoch [595/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [595/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [595/1000], Validation Loss: 0.0382\n",
            "Epoch [596/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [596/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [596/1000], Validation Loss: 0.0383\n",
            "Epoch [597/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [597/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [597/1000], Validation Loss: 0.0382\n",
            "Epoch [598/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [598/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [598/1000], Validation Loss: 0.0382\n",
            "Epoch [599/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [599/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [599/1000], Validation Loss: 0.0383\n",
            "Epoch [600/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [600/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [600/1000], Validation Loss: 0.0382\n",
            "Epoch [601/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [601/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [601/1000], Validation Loss: 0.0383\n",
            "Epoch [602/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [602/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [602/1000], Validation Loss: 0.0382\n",
            "Epoch [603/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [603/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [603/1000], Validation Loss: 0.0382\n",
            "Epoch [604/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [604/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [604/1000], Validation Loss: 0.0382\n",
            "Epoch [605/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [605/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [605/1000], Validation Loss: 0.0382\n",
            "Epoch [606/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [606/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [606/1000], Validation Loss: 0.0382\n",
            "Epoch [607/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [607/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [607/1000], Validation Loss: 0.0383\n",
            "Epoch [608/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [608/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [608/1000], Validation Loss: 0.0382\n",
            "Epoch [609/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [609/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [609/1000], Validation Loss: 0.0382\n",
            "Epoch [610/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [610/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [610/1000], Validation Loss: 0.0383\n",
            "Epoch [611/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [611/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [611/1000], Validation Loss: 0.0383\n",
            "Epoch [612/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [612/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [612/1000], Validation Loss: 0.0382\n",
            "Epoch [613/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [613/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [613/1000], Validation Loss: 0.0383\n",
            "Epoch [614/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [614/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [614/1000], Validation Loss: 0.0382\n",
            "Epoch [615/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [615/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [615/1000], Validation Loss: 0.0381\n",
            "Epoch [616/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [616/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [616/1000], Validation Loss: 0.0382\n",
            "Epoch [617/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [617/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [617/1000], Validation Loss: 0.0382\n",
            "Epoch [618/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [618/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [618/1000], Validation Loss: 0.0382\n",
            "Epoch [619/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [619/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [619/1000], Validation Loss: 0.0382\n",
            "Epoch [620/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [620/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [620/1000], Validation Loss: 0.0382\n",
            "Epoch [621/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [621/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [621/1000], Validation Loss: 0.0383\n",
            "Epoch [622/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [622/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [622/1000], Validation Loss: 0.0382\n",
            "Epoch [623/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [623/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [623/1000], Validation Loss: 0.0383\n",
            "Epoch [624/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [624/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [624/1000], Validation Loss: 0.0382\n",
            "Epoch [625/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [625/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [625/1000], Validation Loss: 0.0382\n",
            "Epoch [626/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [626/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [626/1000], Validation Loss: 0.0382\n",
            "Epoch [627/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [627/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [627/1000], Validation Loss: 0.0383\n",
            "Epoch [628/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [628/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [628/1000], Validation Loss: 0.0382\n",
            "Epoch [629/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [629/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [629/1000], Validation Loss: 0.0383\n",
            "Epoch [630/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [630/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [630/1000], Validation Loss: 0.0382\n",
            "Epoch [631/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [631/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [631/1000], Validation Loss: 0.0383\n",
            "Epoch [632/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [632/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [632/1000], Validation Loss: 0.0382\n",
            "Epoch [633/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [633/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [633/1000], Validation Loss: 0.0382\n",
            "Epoch [634/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [634/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [634/1000], Validation Loss: 0.0382\n",
            "Epoch [635/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [635/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [635/1000], Validation Loss: 0.0382\n",
            "Epoch [636/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [636/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [636/1000], Validation Loss: 0.0383\n",
            "Epoch [637/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [637/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [637/1000], Validation Loss: 0.0382\n",
            "Epoch [638/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [638/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [638/1000], Validation Loss: 0.0382\n",
            "Epoch [639/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [639/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [639/1000], Validation Loss: 0.0382\n",
            "Epoch [640/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [640/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [640/1000], Validation Loss: 0.0382\n",
            "Epoch [641/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [641/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [641/1000], Validation Loss: 0.0383\n",
            "Epoch [642/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [642/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [642/1000], Validation Loss: 0.0383\n",
            "Epoch [643/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [643/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [643/1000], Validation Loss: 0.0382\n",
            "Epoch [644/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [644/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [644/1000], Validation Loss: 0.0382\n",
            "Epoch [645/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [645/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [645/1000], Validation Loss: 0.0383\n",
            "Epoch [646/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [646/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [646/1000], Validation Loss: 0.0382\n",
            "Epoch [647/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [647/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [647/1000], Validation Loss: 0.0382\n",
            "Epoch [648/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [648/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [648/1000], Validation Loss: 0.0383\n",
            "Epoch [649/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [649/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [649/1000], Validation Loss: 0.0382\n",
            "Epoch [650/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [650/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [650/1000], Validation Loss: 0.0381\n",
            "Epoch [651/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [651/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [651/1000], Validation Loss: 0.0382\n",
            "Epoch [652/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [652/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [652/1000], Validation Loss: 0.0381\n",
            "Epoch [653/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [653/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [653/1000], Validation Loss: 0.0382\n",
            "Epoch [654/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [654/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [654/1000], Validation Loss: 0.0381\n",
            "Epoch [655/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [655/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [655/1000], Validation Loss: 0.0382\n",
            "Epoch [656/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [656/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [656/1000], Validation Loss: 0.0383\n",
            "Epoch [657/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [657/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [657/1000], Validation Loss: 0.0382\n",
            "Epoch [658/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [658/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [658/1000], Validation Loss: 0.0382\n",
            "Epoch [659/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [659/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [659/1000], Validation Loss: 0.0383\n",
            "Epoch [660/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [660/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [660/1000], Validation Loss: 0.0382\n",
            "Epoch [661/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [661/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [661/1000], Validation Loss: 0.0383\n",
            "Epoch [662/1000], Batch [1/2], Train Loss: 0.0369\n",
            "Epoch [662/1000], Batch [2/2], Train Loss: 0.0388\n",
            "Epoch [662/1000], Validation Loss: 0.0382\n",
            "Epoch [663/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [663/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [663/1000], Validation Loss: 0.0383\n",
            "Epoch [664/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [664/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [664/1000], Validation Loss: 0.0382\n",
            "Epoch [665/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [665/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [665/1000], Validation Loss: 0.0382\n",
            "Epoch [666/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [666/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [666/1000], Validation Loss: 0.0382\n",
            "Epoch [667/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [667/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [667/1000], Validation Loss: 0.0382\n",
            "Epoch [668/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [668/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [668/1000], Validation Loss: 0.0382\n",
            "Epoch [669/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [669/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [669/1000], Validation Loss: 0.0382\n",
            "Epoch [670/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [670/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [670/1000], Validation Loss: 0.0382\n",
            "Epoch [671/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [671/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [671/1000], Validation Loss: 0.0382\n",
            "Epoch [672/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [672/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [672/1000], Validation Loss: 0.0382\n",
            "Epoch [673/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [673/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [673/1000], Validation Loss: 0.0383\n",
            "Epoch [674/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [674/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [674/1000], Validation Loss: 0.0382\n",
            "Epoch [675/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [675/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [675/1000], Validation Loss: 0.0382\n",
            "Epoch [676/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [676/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [676/1000], Validation Loss: 0.0382\n",
            "Epoch [677/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [677/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [677/1000], Validation Loss: 0.0382\n",
            "Epoch [678/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [678/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [678/1000], Validation Loss: 0.0382\n",
            "Epoch [679/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [679/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [679/1000], Validation Loss: 0.0382\n",
            "Epoch [680/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [680/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [680/1000], Validation Loss: 0.0382\n",
            "Epoch [681/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [681/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [681/1000], Validation Loss: 0.0382\n",
            "Epoch [682/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [682/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [682/1000], Validation Loss: 0.0383\n",
            "Epoch [683/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [683/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [683/1000], Validation Loss: 0.0383\n",
            "Epoch [684/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [684/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [684/1000], Validation Loss: 0.0382\n",
            "Epoch [685/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [685/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [685/1000], Validation Loss: 0.0382\n",
            "Epoch [686/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [686/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [686/1000], Validation Loss: 0.0382\n",
            "Epoch [687/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [687/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [687/1000], Validation Loss: 0.0382\n",
            "Epoch [688/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [688/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [688/1000], Validation Loss: 0.0381\n",
            "Epoch [689/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [689/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [689/1000], Validation Loss: 0.0383\n",
            "Epoch [690/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [690/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [690/1000], Validation Loss: 0.0382\n",
            "Epoch [691/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [691/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [691/1000], Validation Loss: 0.0381\n",
            "Epoch [692/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [692/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [692/1000], Validation Loss: 0.0382\n",
            "Epoch [693/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [693/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [693/1000], Validation Loss: 0.0382\n",
            "Epoch [694/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [694/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [694/1000], Validation Loss: 0.0382\n",
            "Epoch [695/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [695/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [695/1000], Validation Loss: 0.0382\n",
            "Epoch [696/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [696/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [696/1000], Validation Loss: 0.0383\n",
            "Epoch [697/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [697/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [697/1000], Validation Loss: 0.0383\n",
            "Epoch [698/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [698/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [698/1000], Validation Loss: 0.0383\n",
            "Epoch [699/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [699/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [699/1000], Validation Loss: 0.0382\n",
            "Epoch [700/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [700/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [700/1000], Validation Loss: 0.0382\n",
            "Epoch [701/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [701/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [701/1000], Validation Loss: 0.0382\n",
            "Epoch [702/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [702/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [702/1000], Validation Loss: 0.0383\n",
            "Epoch [703/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [703/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [703/1000], Validation Loss: 0.0382\n",
            "Epoch [704/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [704/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [704/1000], Validation Loss: 0.0382\n",
            "Epoch [705/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [705/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [705/1000], Validation Loss: 0.0383\n",
            "Epoch [706/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [706/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [706/1000], Validation Loss: 0.0382\n",
            "Epoch [707/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [707/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [707/1000], Validation Loss: 0.0382\n",
            "Epoch [708/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [708/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [708/1000], Validation Loss: 0.0381\n",
            "Epoch [709/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [709/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [709/1000], Validation Loss: 0.0383\n",
            "Epoch [710/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [710/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [710/1000], Validation Loss: 0.0383\n",
            "Epoch [711/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [711/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [711/1000], Validation Loss: 0.0382\n",
            "Epoch [712/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [712/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [712/1000], Validation Loss: 0.0383\n",
            "Epoch [713/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [713/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [713/1000], Validation Loss: 0.0382\n",
            "Epoch [714/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [714/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [714/1000], Validation Loss: 0.0381\n",
            "Epoch [715/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [715/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [715/1000], Validation Loss: 0.0383\n",
            "Epoch [716/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [716/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [716/1000], Validation Loss: 0.0382\n",
            "Epoch [717/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [717/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [717/1000], Validation Loss: 0.0382\n",
            "Epoch [718/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [718/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [718/1000], Validation Loss: 0.0383\n",
            "Epoch [719/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [719/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [719/1000], Validation Loss: 0.0383\n",
            "Epoch [720/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [720/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [720/1000], Validation Loss: 0.0383\n",
            "Epoch [721/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [721/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [721/1000], Validation Loss: 0.0382\n",
            "Epoch [722/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [722/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [722/1000], Validation Loss: 0.0382\n",
            "Epoch [723/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [723/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [723/1000], Validation Loss: 0.0382\n",
            "Epoch [724/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [724/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [724/1000], Validation Loss: 0.0382\n",
            "Epoch [725/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [725/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [725/1000], Validation Loss: 0.0383\n",
            "Epoch [726/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [726/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [726/1000], Validation Loss: 0.0382\n",
            "Epoch [727/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [727/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [727/1000], Validation Loss: 0.0383\n",
            "Epoch [728/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [728/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [728/1000], Validation Loss: 0.0382\n",
            "Epoch [729/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [729/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [729/1000], Validation Loss: 0.0382\n",
            "Epoch [730/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [730/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [730/1000], Validation Loss: 0.0383\n",
            "Epoch [731/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [731/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [731/1000], Validation Loss: 0.0382\n",
            "Epoch [732/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [732/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [732/1000], Validation Loss: 0.0382\n",
            "Epoch [733/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [733/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [733/1000], Validation Loss: 0.0382\n",
            "Epoch [734/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [734/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [734/1000], Validation Loss: 0.0383\n",
            "Epoch [735/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [735/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [735/1000], Validation Loss: 0.0382\n",
            "Epoch [736/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [736/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [736/1000], Validation Loss: 0.0382\n",
            "Epoch [737/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [737/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [737/1000], Validation Loss: 0.0382\n",
            "Epoch [738/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [738/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [738/1000], Validation Loss: 0.0383\n",
            "Epoch [739/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [739/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [739/1000], Validation Loss: 0.0382\n",
            "Epoch [740/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [740/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [740/1000], Validation Loss: 0.0382\n",
            "Epoch [741/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [741/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [741/1000], Validation Loss: 0.0383\n",
            "Epoch [742/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [742/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [742/1000], Validation Loss: 0.0383\n",
            "Epoch [743/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [743/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [743/1000], Validation Loss: 0.0383\n",
            "Epoch [744/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [744/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [744/1000], Validation Loss: 0.0383\n",
            "Epoch [745/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [745/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [745/1000], Validation Loss: 0.0383\n",
            "Epoch [746/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [746/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [746/1000], Validation Loss: 0.0383\n",
            "Epoch [747/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [747/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [747/1000], Validation Loss: 0.0382\n",
            "Epoch [748/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [748/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [748/1000], Validation Loss: 0.0383\n",
            "Epoch [749/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [749/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [749/1000], Validation Loss: 0.0383\n",
            "Epoch [750/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [750/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [750/1000], Validation Loss: 0.0381\n",
            "Epoch [751/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [751/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [751/1000], Validation Loss: 0.0381\n",
            "Epoch [752/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [752/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [752/1000], Validation Loss: 0.0382\n",
            "Epoch [753/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [753/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [753/1000], Validation Loss: 0.0382\n",
            "Epoch [754/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [754/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [754/1000], Validation Loss: 0.0382\n",
            "Epoch [755/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [755/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [755/1000], Validation Loss: 0.0382\n",
            "Epoch [756/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [756/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [756/1000], Validation Loss: 0.0382\n",
            "Epoch [757/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [757/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [757/1000], Validation Loss: 0.0382\n",
            "Epoch [758/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [758/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [758/1000], Validation Loss: 0.0383\n",
            "Epoch [759/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [759/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [759/1000], Validation Loss: 0.0382\n",
            "Epoch [760/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [760/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [760/1000], Validation Loss: 0.0382\n",
            "Epoch [761/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [761/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [761/1000], Validation Loss: 0.0382\n",
            "Epoch [762/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [762/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [762/1000], Validation Loss: 0.0383\n",
            "Epoch [763/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [763/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [763/1000], Validation Loss: 0.0382\n",
            "Epoch [764/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [764/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [764/1000], Validation Loss: 0.0382\n",
            "Epoch [765/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [765/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [765/1000], Validation Loss: 0.0382\n",
            "Epoch [766/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [766/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [766/1000], Validation Loss: 0.0382\n",
            "Epoch [767/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [767/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [767/1000], Validation Loss: 0.0382\n",
            "Epoch [768/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [768/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [768/1000], Validation Loss: 0.0382\n",
            "Epoch [769/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [769/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [769/1000], Validation Loss: 0.0382\n",
            "Epoch [770/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [770/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [770/1000], Validation Loss: 0.0383\n",
            "Epoch [771/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [771/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [771/1000], Validation Loss: 0.0382\n",
            "Epoch [772/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [772/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [772/1000], Validation Loss: 0.0382\n",
            "Epoch [773/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [773/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [773/1000], Validation Loss: 0.0382\n",
            "Epoch [774/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [774/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [774/1000], Validation Loss: 0.0383\n",
            "Epoch [775/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [775/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [775/1000], Validation Loss: 0.0382\n",
            "Epoch [776/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [776/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [776/1000], Validation Loss: 0.0382\n",
            "Epoch [777/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [777/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [777/1000], Validation Loss: 0.0383\n",
            "Epoch [778/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [778/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [778/1000], Validation Loss: 0.0383\n",
            "Epoch [779/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [779/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [779/1000], Validation Loss: 0.0383\n",
            "Epoch [780/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [780/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [780/1000], Validation Loss: 0.0383\n",
            "Epoch [781/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [781/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [781/1000], Validation Loss: 0.0382\n",
            "Epoch [782/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [782/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [782/1000], Validation Loss: 0.0382\n",
            "Epoch [783/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [783/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [783/1000], Validation Loss: 0.0382\n",
            "Epoch [784/1000], Batch [1/2], Train Loss: 0.0370\n",
            "Epoch [784/1000], Batch [2/2], Train Loss: 0.0386\n",
            "Epoch [784/1000], Validation Loss: 0.0383\n",
            "Epoch [785/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [785/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [785/1000], Validation Loss: 0.0383\n",
            "Epoch [786/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [786/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [786/1000], Validation Loss: 0.0382\n",
            "Epoch [787/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [787/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [787/1000], Validation Loss: 0.0382\n",
            "Epoch [788/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [788/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [788/1000], Validation Loss: 0.0381\n",
            "Epoch [789/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [789/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [789/1000], Validation Loss: 0.0382\n",
            "Epoch [790/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [790/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [790/1000], Validation Loss: 0.0383\n",
            "Epoch [791/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [791/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [791/1000], Validation Loss: 0.0381\n",
            "Epoch [792/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [792/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [792/1000], Validation Loss: 0.0382\n",
            "Epoch [793/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [793/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [793/1000], Validation Loss: 0.0382\n",
            "Epoch [794/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [794/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [794/1000], Validation Loss: 0.0383\n",
            "Epoch [795/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [795/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [795/1000], Validation Loss: 0.0383\n",
            "Epoch [796/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [796/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [796/1000], Validation Loss: 0.0381\n",
            "Epoch [797/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [797/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [797/1000], Validation Loss: 0.0381\n",
            "Epoch [798/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [798/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [798/1000], Validation Loss: 0.0381\n",
            "Epoch [799/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [799/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [799/1000], Validation Loss: 0.0383\n",
            "Epoch [800/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [800/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [800/1000], Validation Loss: 0.0382\n",
            "Epoch [801/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [801/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [801/1000], Validation Loss: 0.0382\n",
            "Epoch [802/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [802/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [802/1000], Validation Loss: 0.0382\n",
            "Epoch [803/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [803/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [803/1000], Validation Loss: 0.0381\n",
            "Epoch [804/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [804/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [804/1000], Validation Loss: 0.0383\n",
            "Epoch [805/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [805/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [805/1000], Validation Loss: 0.0383\n",
            "Epoch [806/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [806/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [806/1000], Validation Loss: 0.0381\n",
            "Epoch [807/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [807/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [807/1000], Validation Loss: 0.0382\n",
            "Epoch [808/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [808/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [808/1000], Validation Loss: 0.0383\n",
            "Epoch [809/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [809/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [809/1000], Validation Loss: 0.0382\n",
            "Epoch [810/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [810/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [810/1000], Validation Loss: 0.0383\n",
            "Epoch [811/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [811/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [811/1000], Validation Loss: 0.0383\n",
            "Epoch [812/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [812/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [812/1000], Validation Loss: 0.0382\n",
            "Epoch [813/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [813/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [813/1000], Validation Loss: 0.0382\n",
            "Epoch [814/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [814/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [814/1000], Validation Loss: 0.0382\n",
            "Epoch [815/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [815/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [815/1000], Validation Loss: 0.0382\n",
            "Epoch [816/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [816/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [816/1000], Validation Loss: 0.0381\n",
            "Epoch [817/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [817/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [817/1000], Validation Loss: 0.0382\n",
            "Epoch [818/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [818/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [818/1000], Validation Loss: 0.0382\n",
            "Epoch [819/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [819/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [819/1000], Validation Loss: 0.0382\n",
            "Epoch [820/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [820/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [820/1000], Validation Loss: 0.0382\n",
            "Epoch [821/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [821/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [821/1000], Validation Loss: 0.0382\n",
            "Epoch [822/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [822/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [822/1000], Validation Loss: 0.0383\n",
            "Epoch [823/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [823/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [823/1000], Validation Loss: 0.0382\n",
            "Epoch [824/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [824/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [824/1000], Validation Loss: 0.0383\n",
            "Epoch [825/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [825/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [825/1000], Validation Loss: 0.0383\n",
            "Epoch [826/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [826/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [826/1000], Validation Loss: 0.0382\n",
            "Epoch [827/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [827/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [827/1000], Validation Loss: 0.0382\n",
            "Epoch [828/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [828/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [828/1000], Validation Loss: 0.0382\n",
            "Epoch [829/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [829/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [829/1000], Validation Loss: 0.0382\n",
            "Epoch [830/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [830/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [830/1000], Validation Loss: 0.0383\n",
            "Epoch [831/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [831/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [831/1000], Validation Loss: 0.0382\n",
            "Epoch [832/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [832/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [832/1000], Validation Loss: 0.0382\n",
            "Epoch [833/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [833/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [833/1000], Validation Loss: 0.0382\n",
            "Epoch [834/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [834/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [834/1000], Validation Loss: 0.0383\n",
            "Epoch [835/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [835/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [835/1000], Validation Loss: 0.0382\n",
            "Epoch [836/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [836/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [836/1000], Validation Loss: 0.0381\n",
            "Epoch [837/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [837/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [837/1000], Validation Loss: 0.0382\n",
            "Epoch [838/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [838/1000], Batch [2/2], Train Loss: 0.0385\n",
            "Epoch [838/1000], Validation Loss: 0.0381\n",
            "Epoch [839/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [839/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [839/1000], Validation Loss: 0.0382\n",
            "Epoch [840/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [840/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [840/1000], Validation Loss: 0.0383\n",
            "Epoch [841/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [841/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [841/1000], Validation Loss: 0.0382\n",
            "Epoch [842/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [842/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [842/1000], Validation Loss: 0.0383\n",
            "Epoch [843/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [843/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [843/1000], Validation Loss: 0.0382\n",
            "Epoch [844/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [844/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [844/1000], Validation Loss: 0.0382\n",
            "Epoch [845/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [845/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [845/1000], Validation Loss: 0.0382\n",
            "Epoch [846/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [846/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [846/1000], Validation Loss: 0.0382\n",
            "Epoch [847/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [847/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [847/1000], Validation Loss: 0.0383\n",
            "Epoch [848/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [848/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [848/1000], Validation Loss: 0.0383\n",
            "Epoch [849/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [849/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [849/1000], Validation Loss: 0.0383\n",
            "Epoch [850/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [850/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [850/1000], Validation Loss: 0.0382\n",
            "Epoch [851/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [851/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [851/1000], Validation Loss: 0.0382\n",
            "Epoch [852/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [852/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [852/1000], Validation Loss: 0.0382\n",
            "Epoch [853/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [853/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [853/1000], Validation Loss: 0.0381\n",
            "Epoch [854/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [854/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [854/1000], Validation Loss: 0.0382\n",
            "Epoch [855/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [855/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [855/1000], Validation Loss: 0.0383\n",
            "Epoch [856/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [856/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [856/1000], Validation Loss: 0.0382\n",
            "Epoch [857/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [857/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [857/1000], Validation Loss: 0.0383\n",
            "Epoch [858/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [858/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [858/1000], Validation Loss: 0.0382\n",
            "Epoch [859/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [859/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [859/1000], Validation Loss: 0.0383\n",
            "Epoch [860/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [860/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [860/1000], Validation Loss: 0.0382\n",
            "Epoch [861/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [861/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [861/1000], Validation Loss: 0.0381\n",
            "Epoch [862/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [862/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [862/1000], Validation Loss: 0.0382\n",
            "Epoch [863/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [863/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [863/1000], Validation Loss: 0.0383\n",
            "Epoch [864/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [864/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [864/1000], Validation Loss: 0.0383\n",
            "Epoch [865/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [865/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [865/1000], Validation Loss: 0.0383\n",
            "Epoch [866/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [866/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [866/1000], Validation Loss: 0.0381\n",
            "Epoch [867/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [867/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [867/1000], Validation Loss: 0.0382\n",
            "Epoch [868/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [868/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [868/1000], Validation Loss: 0.0383\n",
            "Epoch [869/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [869/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [869/1000], Validation Loss: 0.0383\n",
            "Epoch [870/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [870/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [870/1000], Validation Loss: 0.0382\n",
            "Epoch [871/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [871/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [871/1000], Validation Loss: 0.0383\n",
            "Epoch [872/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [872/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [872/1000], Validation Loss: 0.0383\n",
            "Epoch [873/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [873/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [873/1000], Validation Loss: 0.0383\n",
            "Epoch [874/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [874/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [874/1000], Validation Loss: 0.0382\n",
            "Epoch [875/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [875/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [875/1000], Validation Loss: 0.0382\n",
            "Epoch [876/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [876/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [876/1000], Validation Loss: 0.0383\n",
            "Epoch [877/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [877/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [877/1000], Validation Loss: 0.0382\n",
            "Epoch [878/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [878/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [878/1000], Validation Loss: 0.0383\n",
            "Epoch [879/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [879/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [879/1000], Validation Loss: 0.0382\n",
            "Epoch [880/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [880/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [880/1000], Validation Loss: 0.0382\n",
            "Epoch [881/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [881/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [881/1000], Validation Loss: 0.0382\n",
            "Epoch [882/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [882/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [882/1000], Validation Loss: 0.0382\n",
            "Epoch [883/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [883/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [883/1000], Validation Loss: 0.0382\n",
            "Epoch [884/1000], Batch [1/2], Train Loss: 0.0381\n",
            "Epoch [884/1000], Batch [2/2], Train Loss: 0.0369\n",
            "Epoch [884/1000], Validation Loss: 0.0382\n",
            "Epoch [885/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [885/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [885/1000], Validation Loss: 0.0383\n",
            "Epoch [886/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [886/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [886/1000], Validation Loss: 0.0382\n",
            "Epoch [887/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [887/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [887/1000], Validation Loss: 0.0383\n",
            "Epoch [888/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [888/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [888/1000], Validation Loss: 0.0383\n",
            "Epoch [889/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [889/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [889/1000], Validation Loss: 0.0383\n",
            "Epoch [890/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [890/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [890/1000], Validation Loss: 0.0383\n",
            "Epoch [891/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [891/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [891/1000], Validation Loss: 0.0383\n",
            "Epoch [892/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [892/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [892/1000], Validation Loss: 0.0382\n",
            "Epoch [893/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [893/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [893/1000], Validation Loss: 0.0382\n",
            "Epoch [894/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [894/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [894/1000], Validation Loss: 0.0382\n",
            "Epoch [895/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [895/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [895/1000], Validation Loss: 0.0382\n",
            "Epoch [896/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [896/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [896/1000], Validation Loss: 0.0383\n",
            "Epoch [897/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [897/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [897/1000], Validation Loss: 0.0382\n",
            "Epoch [898/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [898/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [898/1000], Validation Loss: 0.0382\n",
            "Epoch [899/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [899/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [899/1000], Validation Loss: 0.0382\n",
            "Epoch [900/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [900/1000], Batch [2/2], Train Loss: 0.0367\n",
            "Epoch [900/1000], Validation Loss: 0.0382\n",
            "Epoch [901/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [901/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [901/1000], Validation Loss: 0.0382\n",
            "Epoch [902/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [902/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [902/1000], Validation Loss: 0.0383\n",
            "Epoch [903/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [903/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [903/1000], Validation Loss: 0.0383\n",
            "Epoch [904/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [904/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [904/1000], Validation Loss: 0.0383\n",
            "Epoch [905/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [905/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [905/1000], Validation Loss: 0.0382\n",
            "Epoch [906/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [906/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [906/1000], Validation Loss: 0.0382\n",
            "Epoch [907/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [907/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [907/1000], Validation Loss: 0.0383\n",
            "Epoch [908/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [908/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [908/1000], Validation Loss: 0.0382\n",
            "Epoch [909/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [909/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [909/1000], Validation Loss: 0.0382\n",
            "Epoch [910/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [910/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [910/1000], Validation Loss: 0.0382\n",
            "Epoch [911/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [911/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [911/1000], Validation Loss: 0.0381\n",
            "Epoch [912/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [912/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [912/1000], Validation Loss: 0.0383\n",
            "Epoch [913/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [913/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [913/1000], Validation Loss: 0.0382\n",
            "Epoch [914/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [914/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [914/1000], Validation Loss: 0.0382\n",
            "Epoch [915/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [915/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [915/1000], Validation Loss: 0.0383\n",
            "Epoch [916/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [916/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [916/1000], Validation Loss: 0.0383\n",
            "Epoch [917/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [917/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [917/1000], Validation Loss: 0.0383\n",
            "Epoch [918/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [918/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [918/1000], Validation Loss: 0.0382\n",
            "Epoch [919/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [919/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [919/1000], Validation Loss: 0.0382\n",
            "Epoch [920/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [920/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [920/1000], Validation Loss: 0.0383\n",
            "Epoch [921/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [921/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [921/1000], Validation Loss: 0.0382\n",
            "Epoch [922/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [922/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [922/1000], Validation Loss: 0.0382\n",
            "Epoch [923/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [923/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [923/1000], Validation Loss: 0.0382\n",
            "Epoch [924/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [924/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [924/1000], Validation Loss: 0.0383\n",
            "Epoch [925/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [925/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [925/1000], Validation Loss: 0.0382\n",
            "Epoch [926/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [926/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [926/1000], Validation Loss: 0.0382\n",
            "Epoch [927/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [927/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [927/1000], Validation Loss: 0.0382\n",
            "Epoch [928/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [928/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [928/1000], Validation Loss: 0.0382\n",
            "Epoch [929/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [929/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [929/1000], Validation Loss: 0.0382\n",
            "Epoch [930/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [930/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [930/1000], Validation Loss: 0.0382\n",
            "Epoch [931/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [931/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [931/1000], Validation Loss: 0.0382\n",
            "Epoch [932/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [932/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [932/1000], Validation Loss: 0.0382\n",
            "Epoch [933/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [933/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [933/1000], Validation Loss: 0.0382\n",
            "Epoch [934/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [934/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [934/1000], Validation Loss: 0.0382\n",
            "Epoch [935/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [935/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [935/1000], Validation Loss: 0.0382\n",
            "Epoch [936/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [936/1000], Batch [2/2], Train Loss: 0.0370\n",
            "Epoch [936/1000], Validation Loss: 0.0382\n",
            "Epoch [937/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [937/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [937/1000], Validation Loss: 0.0381\n",
            "Epoch [938/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [938/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [938/1000], Validation Loss: 0.0382\n",
            "Epoch [939/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [939/1000], Batch [2/2], Train Loss: 0.0383\n",
            "Epoch [939/1000], Validation Loss: 0.0382\n",
            "Epoch [940/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [940/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [940/1000], Validation Loss: 0.0383\n",
            "Epoch [941/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [941/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [941/1000], Validation Loss: 0.0382\n",
            "Epoch [942/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [942/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [942/1000], Validation Loss: 0.0383\n",
            "Epoch [943/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [943/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [943/1000], Validation Loss: 0.0382\n",
            "Epoch [944/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [944/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [944/1000], Validation Loss: 0.0382\n",
            "Epoch [945/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [945/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [945/1000], Validation Loss: 0.0382\n",
            "Epoch [946/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [946/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [946/1000], Validation Loss: 0.0382\n",
            "Epoch [947/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [947/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [947/1000], Validation Loss: 0.0382\n",
            "Epoch [948/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [948/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [948/1000], Validation Loss: 0.0382\n",
            "Epoch [949/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [949/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [949/1000], Validation Loss: 0.0382\n",
            "Epoch [950/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [950/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [950/1000], Validation Loss: 0.0382\n",
            "Epoch [951/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [951/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [951/1000], Validation Loss: 0.0382\n",
            "Epoch [952/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [952/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [952/1000], Validation Loss: 0.0383\n",
            "Epoch [953/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [953/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [953/1000], Validation Loss: 0.0382\n",
            "Epoch [954/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [954/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [954/1000], Validation Loss: 0.0382\n",
            "Epoch [955/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [955/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [955/1000], Validation Loss: 0.0383\n",
            "Epoch [956/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [956/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [956/1000], Validation Loss: 0.0382\n",
            "Epoch [957/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [957/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [957/1000], Validation Loss: 0.0382\n",
            "Epoch [958/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [958/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [958/1000], Validation Loss: 0.0383\n",
            "Epoch [959/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [959/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [959/1000], Validation Loss: 0.0382\n",
            "Epoch [960/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [960/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [960/1000], Validation Loss: 0.0383\n",
            "Epoch [961/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [961/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [961/1000], Validation Loss: 0.0383\n",
            "Epoch [962/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [962/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [962/1000], Validation Loss: 0.0382\n",
            "Epoch [963/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [963/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [963/1000], Validation Loss: 0.0383\n",
            "Epoch [964/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [964/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [964/1000], Validation Loss: 0.0383\n",
            "Epoch [965/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [965/1000], Batch [2/2], Train Loss: 0.0380\n",
            "Epoch [965/1000], Validation Loss: 0.0383\n",
            "Epoch [966/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [966/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [966/1000], Validation Loss: 0.0382\n",
            "Epoch [967/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [967/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [967/1000], Validation Loss: 0.0382\n",
            "Epoch [968/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [968/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [968/1000], Validation Loss: 0.0382\n",
            "Epoch [969/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [969/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [969/1000], Validation Loss: 0.0382\n",
            "Epoch [970/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [970/1000], Batch [2/2], Train Loss: 0.0379\n",
            "Epoch [970/1000], Validation Loss: 0.0383\n",
            "Epoch [971/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [971/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [971/1000], Validation Loss: 0.0382\n",
            "Epoch [972/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [972/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [972/1000], Validation Loss: 0.0382\n",
            "Epoch [973/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [973/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [973/1000], Validation Loss: 0.0381\n",
            "Epoch [974/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [974/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [974/1000], Validation Loss: 0.0383\n",
            "Epoch [975/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [975/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [975/1000], Validation Loss: 0.0382\n",
            "Epoch [976/1000], Batch [1/2], Train Loss: 0.0382\n",
            "Epoch [976/1000], Batch [2/2], Train Loss: 0.0368\n",
            "Epoch [976/1000], Validation Loss: 0.0381\n",
            "Epoch [977/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [977/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [977/1000], Validation Loss: 0.0382\n",
            "Epoch [978/1000], Batch [1/2], Train Loss: 0.0372\n",
            "Epoch [978/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [978/1000], Validation Loss: 0.0382\n",
            "Epoch [979/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [979/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [979/1000], Validation Loss: 0.0383\n",
            "Epoch [980/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [980/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [980/1000], Validation Loss: 0.0382\n",
            "Epoch [981/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [981/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [981/1000], Validation Loss: 0.0383\n",
            "Epoch [982/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [982/1000], Batch [2/2], Train Loss: 0.0371\n",
            "Epoch [982/1000], Validation Loss: 0.0383\n",
            "Epoch [983/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [983/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [983/1000], Validation Loss: 0.0382\n",
            "Epoch [984/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [984/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [984/1000], Validation Loss: 0.0382\n",
            "Epoch [985/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [985/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [985/1000], Validation Loss: 0.0383\n",
            "Epoch [986/1000], Batch [1/2], Train Loss: 0.0371\n",
            "Epoch [986/1000], Batch [2/2], Train Loss: 0.0384\n",
            "Epoch [986/1000], Validation Loss: 0.0382\n",
            "Epoch [987/1000], Batch [1/2], Train Loss: 0.0378\n",
            "Epoch [987/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [987/1000], Validation Loss: 0.0383\n",
            "Epoch [988/1000], Batch [1/2], Train Loss: 0.0373\n",
            "Epoch [988/1000], Batch [2/2], Train Loss: 0.0382\n",
            "Epoch [988/1000], Validation Loss: 0.0382\n",
            "Epoch [989/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [989/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [989/1000], Validation Loss: 0.0383\n",
            "Epoch [990/1000], Batch [1/2], Train Loss: 0.0375\n",
            "Epoch [990/1000], Batch [2/2], Train Loss: 0.0378\n",
            "Epoch [990/1000], Validation Loss: 0.0382\n",
            "Epoch [991/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [991/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [991/1000], Validation Loss: 0.0382\n",
            "Epoch [992/1000], Batch [1/2], Train Loss: 0.0380\n",
            "Epoch [992/1000], Batch [2/2], Train Loss: 0.0372\n",
            "Epoch [992/1000], Validation Loss: 0.0382\n",
            "Epoch [993/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [993/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [993/1000], Validation Loss: 0.0382\n",
            "Epoch [994/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [994/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [994/1000], Validation Loss: 0.0382\n",
            "Epoch [995/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [995/1000], Batch [2/2], Train Loss: 0.0374\n",
            "Epoch [995/1000], Validation Loss: 0.0382\n",
            "Epoch [996/1000], Batch [1/2], Train Loss: 0.0377\n",
            "Epoch [996/1000], Batch [2/2], Train Loss: 0.0375\n",
            "Epoch [996/1000], Validation Loss: 0.0382\n",
            "Epoch [997/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [997/1000], Batch [2/2], Train Loss: 0.0377\n",
            "Epoch [997/1000], Validation Loss: 0.0383\n",
            "Epoch [998/1000], Batch [1/2], Train Loss: 0.0379\n",
            "Epoch [998/1000], Batch [2/2], Train Loss: 0.0373\n",
            "Epoch [998/1000], Validation Loss: 0.0381\n",
            "Epoch [999/1000], Batch [1/2], Train Loss: 0.0376\n",
            "Epoch [999/1000], Batch [2/2], Train Loss: 0.0376\n",
            "Epoch [999/1000], Validation Loss: 0.0382\n",
            "Epoch [1000/1000], Batch [1/2], Train Loss: 0.0374\n",
            "Epoch [1000/1000], Batch [2/2], Train Loss: 0.0381\n",
            "Epoch [1000/1000], Validation Loss: 0.0382\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPFAW-kJL9dV",
        "outputId": "15967133-b68b-495c-c8c9-2cf6adb3e8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.037904392927885056,\n",
              " 0.037195563316345215,\n",
              " 0.03758431226015091,\n",
              " 0.03771628439426422,\n",
              " 0.03793232515454292,\n",
              " 0.03719206154346466,\n",
              " 0.037802327424287796,\n",
              " 0.03734620288014412,\n",
              " 0.03778769075870514,\n",
              " 0.037410397082567215,\n",
              " 0.03770967572927475,\n",
              " 0.03752969577908516,\n",
              " 0.03786255419254303,\n",
              " 0.03727363795042038,\n",
              " 0.03767665475606918,\n",
              " 0.0376417450606823,\n",
              " 0.03785935789346695,\n",
              " 0.03729652985930443,\n",
              " 0.03719864413142204,\n",
              " 0.0380912646651268,\n",
              " 0.03798770159482956,\n",
              " 0.03724668174982071,\n",
              " 0.03755659982562065,\n",
              " 0.03776998817920685,\n",
              " 0.0375327467918396,\n",
              " 0.037792056798934937,\n",
              " 0.03748596832156181,\n",
              " 0.03795449063181877,\n",
              " 0.03781898319721222,\n",
              " 0.0373639352619648,\n",
              " 0.03734074532985687,\n",
              " 0.03803573176264763,\n",
              " 0.037850067019462585,\n",
              " 0.037272557616233826,\n",
              " 0.03770868107676506,\n",
              " 0.0375395193696022,\n",
              " 0.037011295557022095,\n",
              " 0.03863564878702164,\n",
              " 0.03709288686513901,\n",
              " 0.03843695670366287,\n",
              " 0.037963394075632095,\n",
              " 0.03722498193383217,\n",
              " 0.03755880892276764,\n",
              " 0.03769954293966293,\n",
              " 0.03772813081741333,\n",
              " 0.03755708411335945,\n",
              " 0.03760956972837448,\n",
              " 0.03762303665280342,\n",
              " 0.03765060380101204,\n",
              " 0.03755282610654831,\n",
              " 0.03740273416042328,\n",
              " 0.038011584430933,\n",
              " 0.03766823932528496,\n",
              " 0.03742051497101784,\n",
              " 0.037915267050266266,\n",
              " 0.037161704152822495,\n",
              " 0.03764345869421959,\n",
              " 0.03753802180290222,\n",
              " 0.03753620386123657,\n",
              " 0.03777606785297394,\n",
              " 0.03771766647696495,\n",
              " 0.03731240704655647,\n",
              " 0.037656284868717194,\n",
              " 0.03758618235588074,\n",
              " 0.037402331829071045,\n",
              " 0.038016177713871,\n",
              " 0.03768832981586456,\n",
              " 0.037511225789785385,\n",
              " 0.03747820854187012,\n",
              " 0.03777703270316124,\n",
              " 0.03770747780799866,\n",
              " 0.037525177001953125,\n",
              " 0.03768777474761009,\n",
              " 0.03753969445824623,\n",
              " 0.038090433925390244,\n",
              " 0.03693054988980293,\n",
              " 0.03769424557685852,\n",
              " 0.03759271278977394,\n",
              " 0.03722045570611954,\n",
              " 0.0383058562874794,\n",
              " 0.03759842738509178,\n",
              " 0.03780968487262726,\n",
              " 0.03754114359617233,\n",
              " 0.037684280425310135,\n",
              " 0.037851374596357346,\n",
              " 0.03729468956589699,\n",
              " 0.038211286067962646,\n",
              " 0.036723095923662186,\n",
              " 0.03774191066622734,\n",
              " 0.03735692426562309,\n",
              " 0.03735368326306343,\n",
              " 0.0381055623292923,\n",
              " 0.03741328418254852,\n",
              " 0.037910763174295425,\n",
              " 0.036882348358631134,\n",
              " 0.03875010460615158,\n",
              " 0.03780025243759155,\n",
              " 0.03746131807565689,\n",
              " 0.037381429225206375,\n",
              " 0.037942446768283844,\n",
              " 0.037344302982091904,\n",
              " 0.038034189492464066,\n",
              " 0.037724532186985016,\n",
              " 0.037480223923921585,\n",
              " 0.037937361747026443,\n",
              " 0.03708522021770477,\n",
              " 0.03769679740071297,\n",
              " 0.03751630708575249,\n",
              " 0.03751230239868164,\n",
              " 0.037909820675849915,\n",
              " 0.03737097978591919,\n",
              " 0.03803499788045883,\n",
              " 0.037376902997493744,\n",
              " 0.038065649569034576,\n",
              " 0.03801684454083443,\n",
              " 0.037116751074790955,\n",
              " 0.037405770272016525,\n",
              " 0.038000959903001785,\n",
              " 0.037215668708086014,\n",
              " 0.03827577456831932,\n",
              " 0.03809899464249611,\n",
              " 0.03699593245983124,\n",
              " 0.03773021325469017,\n",
              " 0.03740520030260086,\n",
              " 0.03793872147798538,\n",
              " 0.03709324821829796,\n",
              " 0.03752371296286583,\n",
              " 0.037886135280132294,\n",
              " 0.03769815340638161,\n",
              " 0.0375201478600502,\n",
              " 0.03756813332438469,\n",
              " 0.03763763606548309,\n",
              " 0.03759470209479332,\n",
              " 0.037574950605630875,\n",
              " 0.03736724331974983,\n",
              " 0.0380733422935009,\n",
              " 0.03783133625984192,\n",
              " 0.03730729594826698,\n",
              " 0.03805193305015564,\n",
              " 0.03703521937131882,\n",
              " 0.03762310743331909,\n",
              " 0.03765656799077988,\n",
              " 0.03781744837760925,\n",
              " 0.037325575947761536,\n",
              " 0.03797318413853645,\n",
              " 0.03701115772128105,\n",
              " 0.03748495504260063,\n",
              " 0.03788638487458229,\n",
              " 0.03754574432969093,\n",
              " 0.037740930914878845,\n",
              " 0.03787226974964142,\n",
              " 0.0372408963739872,\n",
              " 0.037739742547273636,\n",
              " 0.037385351955890656,\n",
              " 0.03784732520580292,\n",
              " 0.037310972809791565,\n",
              " 0.03739144653081894,\n",
              " 0.037986576557159424,\n",
              " 0.03722769394516945,\n",
              " 0.03828496113419533,\n",
              " 0.03753090277314186,\n",
              " 0.03777339309453964,\n",
              " 0.037400223314762115,\n",
              " 0.03800049051642418,\n",
              " 0.038010336458683014,\n",
              " 0.03704051300883293,\n",
              " 0.03751254826784134,\n",
              " 0.03790725767612457,\n",
              " 0.03812795132398605,\n",
              " 0.0369560532271862,\n",
              " 0.03774178400635719,\n",
              " 0.03744189813733101,\n",
              " 0.037633225321769714,\n",
              " 0.03758976235985756,\n",
              " 0.03720178082585335,\n",
              " 0.03829988092184067,\n",
              " 0.037837572395801544,\n",
              " 0.03737550973892212,\n",
              " 0.03731232509016991,\n",
              " 0.03821192681789398,\n",
              " 0.037875112146139145,\n",
              " 0.037129029631614685,\n",
              " 0.03796787187457085,\n",
              " 0.037247899919748306,\n",
              " 0.03758363425731659,\n",
              " 0.03763749450445175,\n",
              " 0.0378846749663353,\n",
              " 0.03731613606214523,\n",
              " 0.03729037195444107,\n",
              " 0.03816170617938042,\n",
              " 0.03763184696435928,\n",
              " 0.03767160326242447,\n",
              " 0.03784298151731491,\n",
              " 0.03727483004331589,\n",
              " 0.037644512951374054,\n",
              " 0.037592556327581406,\n",
              " 0.03758244216442108,\n",
              " 0.037647996097803116,\n",
              " 0.03717551380395889,\n",
              " 0.038278140127658844,\n",
              " 0.03715813532471657,\n",
              " 0.03845914080739021,\n",
              " 0.037550076842308044,\n",
              " 0.03788469731807709,\n",
              " 0.037524621933698654,\n",
              " 0.03783510997891426,\n",
              " 0.037364277988672256,\n",
              " 0.03802766650915146,\n",
              " 0.037805814296007156,\n",
              " 0.03745291382074356,\n",
              " 0.037916965782642365,\n",
              " 0.03723287954926491,\n",
              " 0.03765163943171501,\n",
              " 0.03759611397981644,\n",
              " 0.03745773434638977,\n",
              " 0.03778970614075661,\n",
              " 0.037735339254140854,\n",
              " 0.03748799115419388,\n",
              " 0.03755062073469162,\n",
              " 0.03775455430150032,\n",
              " 0.0374419130384922,\n",
              " 0.037928659468889236,\n",
              " 0.03742784261703491,\n",
              " 0.03787560015916824,\n",
              " 0.037694044411182404,\n",
              " 0.037522949278354645,\n",
              " 0.03773244842886925,\n",
              " 0.03743862733244896,\n",
              " 0.03802989050745964,\n",
              " 0.03696113079786301,\n",
              " 0.037662338465452194,\n",
              " 0.03763822093605995,\n",
              " 0.03768393397331238,\n",
              " 0.03753599897027016,\n",
              " 0.03764231503009796,\n",
              " 0.03765714913606644,\n",
              " 0.03737948462367058,\n",
              " 0.03801703453063965,\n",
              " 0.037840958684682846,\n",
              " 0.03734859079122543,\n",
              " 0.037859559059143066,\n",
              " 0.03736790642142296,\n",
              " 0.03765874728560448,\n",
              " 0.03760072961449623,\n",
              " 0.03799058869481087,\n",
              " 0.0371461845934391,\n",
              " 0.037749797105789185,\n",
              " 0.03750895336270332,\n",
              " 0.037994544953107834,\n",
              " 0.03710244968533516,\n",
              " 0.0376264862716198,\n",
              " 0.0376175232231617,\n",
              " 0.037425681948661804,\n",
              " 0.03785640001296997,\n",
              " 0.03754037991166115,\n",
              " 0.037931889295578,\n",
              " 0.03712058439850807,\n",
              " 0.03831639140844345,\n",
              " 0.037583332508802414,\n",
              " 0.03773929178714752,\n",
              " 0.03761164844036102,\n",
              " 0.03768695518374443,\n",
              " 0.037667710334062576,\n",
              " 0.037617165595293045,\n",
              " 0.03750668093562126,\n",
              " 0.037797246128320694,\n",
              " 0.03788655996322632,\n",
              " 0.03722810372710228,\n",
              " 0.037569161504507065,\n",
              " 0.03773186355829239,\n",
              " 0.03767084702849388,\n",
              " 0.037672847509384155,\n",
              " 0.037809714674949646,\n",
              " 0.037284985184669495,\n",
              " 0.037782590836286545,\n",
              " 0.03748700022697449,\n",
              " 0.03799613192677498,\n",
              " 0.03712257742881775,\n",
              " 0.037957437336444855,\n",
              " 0.03706654533743858,\n",
              " 0.03807083144783974,\n",
              " 0.03702197223901749,\n",
              " 0.03745047003030777,\n",
              " 0.03785422816872597,\n",
              " 0.037509262561798096,\n",
              " 0.037742506712675095,\n",
              " 0.037653952836990356,\n",
              " 0.03756820783019066,\n",
              " 0.03750777617096901,\n",
              " 0.03786575794219971,\n",
              " 0.037673935294151306,\n",
              " 0.03766100853681564,\n",
              " 0.037634193897247314,\n",
              " 0.037517134100198746,\n",
              " 0.037729501724243164,\n",
              " 0.037577297538518906,\n",
              " 0.03749329596757889,\n",
              " 0.03780435025691986,\n",
              " 0.03749673813581467,\n",
              " 0.0379444882273674,\n",
              " 0.03793645277619362,\n",
              " 0.03712541237473488,\n",
              " 0.03724682331085205,\n",
              " 0.03819785267114639,\n",
              " 0.037730902433395386,\n",
              " 0.03754657134413719,\n",
              " 0.03791683539748192,\n",
              " 0.037158966064453125,\n",
              " 0.03770497813820839,\n",
              " 0.03757505491375923,\n",
              " 0.03792527690529823,\n",
              " 0.037254516035318375,\n",
              " 0.037473320960998535,\n",
              " 0.03781332075595856,\n",
              " 0.03735698014497757,\n",
              " 0.03808387368917465,\n",
              " 0.037753209471702576,\n",
              " 0.03744006156921387,\n",
              " 0.0377742275595665,\n",
              " 0.03743637353181839,\n",
              " 0.038061756640672684,\n",
              " 0.036971498280763626,\n",
              " 0.03761583939194679,\n",
              " 0.03774658590555191,\n",
              " 0.03760687634348869,\n",
              " 0.037728194147348404,\n",
              " 0.03730412945151329,\n",
              " 0.03808068484067917,\n",
              " 0.03754572197794914,\n",
              " 0.037700194865465164,\n",
              " 0.03769812360405922,\n",
              " 0.0374615378677845,\n",
              " 0.03810218721628189,\n",
              " 0.03701365366578102,\n",
              " 0.03776496648788452,\n",
              " 0.03740861266851425,\n",
              " 0.03801523521542549,\n",
              " 0.037044208496809006,\n",
              " 0.03751145303249359,\n",
              " 0.037868741899728775,\n",
              " 0.03760183975100517,\n",
              " 0.03779161721467972,\n",
              " 0.037353403866291046,\n",
              " 0.03815165162086487,\n",
              " 0.03748820722103119,\n",
              " 0.03788483515381813,\n",
              " 0.0374918095767498,\n",
              " 0.03775787726044655,\n",
              " 0.038057830184698105,\n",
              " 0.037011802196502686,\n",
              " 0.037418268620967865,\n",
              " 0.03799081966280937,\n",
              " 0.03769080713391304,\n",
              " 0.03758411109447479,\n",
              " 0.0376519151031971,\n",
              " 0.037636347115039825,\n",
              " 0.037685178220272064,\n",
              " 0.03763173520565033,\n",
              " 0.03801517188549042,\n",
              " 0.037216369062662125,\n",
              " 0.03740597143769264,\n",
              " 0.03787181153893471,\n",
              " 0.037465035915374756,\n",
              " 0.03788842633366585,\n",
              " 0.03787396103143692,\n",
              " 0.037187933921813965,\n",
              " 0.03775571659207344,\n",
              " 0.03749817982316017,\n",
              " 0.03788318112492561,\n",
              " 0.037315499037504196,\n",
              " 0.03773101791739464,\n",
              " 0.03745449334383011,\n",
              " 0.0374738834798336,\n",
              " 0.03788738325238228,\n",
              " 0.03696904331445694,\n",
              " 0.03865745663642883,\n",
              " 0.037688449025154114,\n",
              " 0.03755943849682808,\n",
              " 0.03745080530643463,\n",
              " 0.03789931908249855,\n",
              " 0.03771807625889778,\n",
              " 0.037474341690540314,\n",
              " 0.037847429513931274,\n",
              " 0.03735899180173874,\n",
              " 0.037545643746852875,\n",
              " 0.03779461979866028,\n",
              " 0.0377873033285141,\n",
              " 0.037395115941762924,\n",
              " 0.037257712334394455,\n",
              " 0.03812884911894798,\n",
              " 0.03785323351621628,\n",
              " 0.03742946311831474,\n",
              " 0.03788980096578598,\n",
              " 0.03716028481721878,\n",
              " 0.037109117954969406,\n",
              " 0.03850777819752693,\n",
              " 0.037203725427389145,\n",
              " 0.03826265409588814,\n",
              " 0.03761059418320656,\n",
              " 0.037657734006643295,\n",
              " 0.037976063787937164,\n",
              " 0.037254225462675095,\n",
              " 0.03751136362552643,\n",
              " 0.03777902573347092,\n",
              " 0.037719011306762695,\n",
              " 0.03755754977464676,\n",
              " 0.037797048687934875,\n",
              " 0.03734862059354782,\n",
              " 0.037541139870882034,\n",
              " 0.037776101380586624,\n",
              " 0.03782278671860695,\n",
              " 0.037235405296087265,\n",
              " 0.03755933791399002,\n",
              " 0.037727102637290955,\n",
              " 0.03790000453591347,\n",
              " 0.03722761943936348,\n",
              " 0.03775107488036156,\n",
              " 0.0375402458012104,\n",
              " 0.037590451538562775,\n",
              " 0.03773973882198334,\n",
              " 0.03784635663032532,\n",
              " 0.03732689470052719,\n",
              " 0.03740924596786499,\n",
              " 0.03803178668022156,\n",
              " 0.03772308677434921,\n",
              " 0.03743438795208931,\n",
              " 0.038252972066402435,\n",
              " 0.036785244941711426,\n",
              " 0.03805038705468178,\n",
              " 0.03702416270971298,\n",
              " 0.03757694736123085,\n",
              " 0.037753865122795105,\n",
              " 0.03769681975245476,\n",
              " 0.03754749521613121,\n",
              " 0.03782421350479126,\n",
              " 0.03736009821295738,\n",
              " 0.03758449852466583,\n",
              " 0.03763207048177719,\n",
              " 0.037624605000019073,\n",
              " 0.037680577486753464,\n",
              " 0.03733443096280098,\n",
              " 0.03805161267518997,\n",
              " 0.03758722171187401,\n",
              " 0.0376831516623497,\n",
              " 0.037810977548360825,\n",
              " 0.03742142766714096,\n",
              " 0.037638258188962936,\n",
              " 0.037651143968105316,\n",
              " 0.037859562784433365,\n",
              " 0.03719744086265564,\n",
              " 0.03787888586521149,\n",
              " 0.03722313046455383,\n",
              " 0.037956949323415756,\n",
              " 0.03714142367243767,\n",
              " 0.037360578775405884,\n",
              " 0.03812602534890175,\n",
              " 0.03742978721857071,\n",
              " 0.03793705627322197,\n",
              " 0.0377759113907814,\n",
              " 0.037325065582990646,\n",
              " 0.03745757415890694,\n",
              " 0.03790157288312912,\n",
              " 0.037756871432065964,\n",
              " 0.03758465498685837,\n",
              " 0.03798028454184532,\n",
              " 0.03715852275490761,\n",
              " 0.037762414664030075,\n",
              " 0.037454813718795776,\n",
              " 0.03776432201266289,\n",
              " 0.03735501319169998,\n",
              " 0.037428393959999084,\n",
              " 0.03787660971283913,\n",
              " 0.03718569874763489,\n",
              " 0.038441598415374756,\n",
              " 0.03793925791978836,\n",
              " 0.037123970687389374,\n",
              " 0.03753823786973953,\n",
              " 0.0376744419336319,\n",
              " 0.03781770169734955,\n",
              " 0.03732487931847572,\n",
              " 0.03771868720650673,\n",
              " 0.0375383086502552,\n",
              " 0.03826781362295151,\n",
              " 0.036687757819890976,\n",
              " 0.03734873607754707,\n",
              " 0.03795670345425606,\n",
              " 0.03747139498591423,\n",
              " 0.03788437694311142,\n",
              " 0.03803957253694534,\n",
              " 0.03695794194936752,\n",
              " 0.03803836181759834,\n",
              " 0.03704468905925751,\n",
              " 0.037488337606191635,\n",
              " 0.03785095736384392,\n",
              " 0.03807177022099495,\n",
              " 0.03707965090870857,\n",
              " 0.037809308618307114,\n",
              " 0.03732916712760925,\n",
              " 0.037454236298799515,\n",
              " 0.03794172406196594,\n",
              " 0.03751898184418678,\n",
              " 0.037751395255327225,\n",
              " 0.03721673786640167,\n",
              " 0.03824726119637489,\n",
              " 0.03763306140899658,\n",
              " 0.0376870259642601,\n",
              " 0.03772642835974693,\n",
              " 0.03756598010659218,\n",
              " 0.03781167045235634,\n",
              " 0.03733948618173599,\n",
              " 0.03783789649605751,\n",
              " 0.037497226148843765,\n",
              " 0.03790139779448509,\n",
              " 0.0371687225997448,\n",
              " 0.03717314079403877,\n",
              " 0.038352418690919876,\n",
              " 0.037477705627679825,\n",
              " 0.037816017866134644,\n",
              " 0.037397004663944244,\n",
              " 0.037958551198244095,\n",
              " 0.037757664918899536,\n",
              " 0.03735680878162384,\n",
              " 0.037683919072151184,\n",
              " 0.037462420761585236,\n",
              " 0.03745906427502632,\n",
              " 0.03790479525923729,\n",
              " 0.03806772455573082,\n",
              " 0.03711540624499321,\n",
              " 0.037845224142074585,\n",
              " 0.0372602753341198,\n",
              " 0.03778010979294777,\n",
              " 0.03734264150261879,\n",
              " 0.037451088428497314,\n",
              " 0.03796420991420746,\n",
              " 0.03762710094451904,\n",
              " 0.037717923521995544,\n",
              " 0.03791368007659912,\n",
              " 0.037227727472782135,\n",
              " 0.03769952058792114,\n",
              " 0.037566520273685455,\n",
              " 0.03760021552443504,\n",
              " 0.03773070499300957,\n",
              " 0.03695487603545189,\n",
              " 0.03862696886062622,\n",
              " 0.03816882148385048,\n",
              " 0.03676611930131912,\n",
              " 0.037751730531454086,\n",
              " 0.037458471953868866,\n",
              " 0.037245526909828186,\n",
              " 0.03810805082321167,\n",
              " 0.03737218305468559,\n",
              " 0.03795359656214714,\n",
              " 0.037542082369327545,\n",
              " 0.03776797279715538,\n",
              " 0.037270840257406235,\n",
              " 0.038137082010507584,\n",
              " 0.037272240966558456,\n",
              " 0.038209158927202225,\n",
              " 0.03711854666471481,\n",
              " 0.03841467946767807,\n",
              " 0.037449609488248825,\n",
              " 0.037920817732810974,\n",
              " 0.03753930702805519,\n",
              " 0.03772779181599617,\n",
              " 0.037440769374370575,\n",
              " 0.037877097725868225,\n",
              " 0.03761639446020126,\n",
              " 0.03763223811984062,\n",
              " 0.037310779094696045,\n",
              " 0.037977512925863266,\n",
              " 0.03780221939086914,\n",
              " 0.03728143498301506,\n",
              " 0.03751711919903755,\n",
              " 0.03784932568669319,\n",
              " 0.037939876317977905,\n",
              " 0.03719901666045189,\n",
              " 0.03785531222820282,\n",
              " 0.037213362753391266,\n",
              " 0.0375509113073349,\n",
              " 0.037779491394758224,\n",
              " 0.03784932196140289,\n",
              " 0.03726871684193611,\n",
              " 0.03740227594971657,\n",
              " 0.03794121369719505,\n",
              " 0.037696849554777145,\n",
              " 0.0375078022480011,\n",
              " 0.03705506771802902,\n",
              " 0.0384649857878685,\n",
              " 0.03754468634724617,\n",
              " 0.037688832730054855,\n",
              " 0.03794889897108078,\n",
              " 0.03707245737314224,\n",
              " 0.03744564577937126,\n",
              " 0.03787316754460335,\n",
              " 0.037898845970630646,\n",
              " 0.03730959817767143,\n",
              " 0.03801116719841957,\n",
              " 0.03717270493507385,\n",
              " 0.03743312507867813,\n",
              " 0.03788834065198898,\n",
              " 0.037558816373348236,\n",
              " 0.037759482860565186,\n",
              " 0.03744928166270256,\n",
              " 0.037843506783246994,\n",
              " 0.03709395229816437,\n",
              " 0.038458507508039474,\n",
              " 0.03758906200528145,\n",
              " 0.037568312138319016,\n",
              " 0.03779253363609314,\n",
              " 0.03738008067011833,\n",
              " 0.03784219175577164,\n",
              " 0.03741665557026863,\n",
              " 0.037583231925964355,\n",
              " 0.03767526149749756,\n",
              " 0.03758889064192772,\n",
              " 0.037712518125772476,\n",
              " 0.03725240379571915,\n",
              " 0.03813367709517479,\n",
              " 0.03777444735169411,\n",
              " 0.037386372685432434,\n",
              " 0.037908460944890976,\n",
              " 0.03710818663239479,\n",
              " 0.038055505603551865,\n",
              " 0.036986541002988815,\n",
              " 0.03775176778435707,\n",
              " 0.0374605692923069,\n",
              " 0.03712946176528931,\n",
              " 0.03836098313331604,\n",
              " 0.037452857941389084,\n",
              " 0.03790541738271713,\n",
              " 0.037963803857564926,\n",
              " 0.03715577721595764,\n",
              " 0.03731662780046463,\n",
              " 0.038048937916755676,\n",
              " 0.03798074647784233,\n",
              " 0.037069592624902725,\n",
              " 0.03814839571714401,\n",
              " 0.03684879094362259,\n",
              " 0.037748560309410095,\n",
              " 0.0374973826110363,\n",
              " 0.0374273844063282,\n",
              " 0.03792807459831238,\n",
              " 0.0377938449382782,\n",
              " 0.03736314922571182,\n",
              " 0.037922248244285583,\n",
              " 0.03727676719427109,\n",
              " 0.037340644747018814,\n",
              " 0.038094617426395416,\n",
              " 0.03754090145230293,\n",
              " 0.037689607590436935,\n",
              " 0.03805287554860115,\n",
              " 0.03704031929373741,\n",
              " 0.0373678058385849,\n",
              " 0.03809374198317528,\n",
              " 0.03732402250170708,\n",
              " 0.03813571110367775,\n",
              " 0.037483345717191696,\n",
              " 0.03786667436361313,\n",
              " 0.03754400834441185,\n",
              " 0.037611231207847595,\n",
              " 0.037831712514162064,\n",
              " 0.03725864365696907,\n",
              " 0.037514373660087585,\n",
              " 0.03774517774581909,\n",
              " 0.03722678869962692,\n",
              " 0.03821505233645439,\n",
              " 0.03709283843636513,\n",
              " 0.038435015827417374,\n",
              " 0.037701722234487534,\n",
              " 0.037587009370326996,\n",
              " 0.03724096715450287,\n",
              " 0.038148973137140274,\n",
              " 0.03787907958030701,\n",
              " 0.03720957785844803,\n",
              " 0.037673838436603546,\n",
              " 0.03758164867758751,\n",
              " 0.03758896887302399,\n",
              " 0.037690382450819016,\n",
              " 0.03772721812129021,\n",
              " 0.037580106407403946,\n",
              " 0.0376955009996891,\n",
              " 0.03754330053925514,\n",
              " 0.03737952560186386,\n",
              " 0.038010574877262115,\n",
              " 0.03766190633177757,\n",
              " 0.03763147071003914,\n",
              " 0.037625957280397415,\n",
              " 0.03766251355409622,\n",
              " 0.03730596601963043,\n",
              " 0.038086868822574615,\n",
              " 0.03782830014824867,\n",
              " 0.03728068619966507,\n",
              " 0.037817101925611496,\n",
              " 0.03730299323797226,\n",
              " 0.03766227886080742,\n",
              " 0.037620462477207184,\n",
              " 0.037877801805734634,\n",
              " 0.03724602237343788,\n",
              " 0.037983160465955734,\n",
              " 0.03715400770306587,\n",
              " 0.03762809559702873,\n",
              " 0.03766750171780586,\n",
              " 0.03721414506435394,\n",
              " 0.038197387009859085,\n",
              " 0.03751834109425545,\n",
              " 0.03779520094394684,\n",
              " 0.0374000184237957,\n",
              " 0.037986401468515396,\n",
              " 0.0374981164932251,\n",
              " 0.037800271064043045,\n",
              " 0.0374348945915699,\n",
              " 0.03794087842106819,\n",
              " 0.037757690995931625,\n",
              " 0.037370435893535614,\n",
              " 0.037710174918174744,\n",
              " 0.037591636180877686,\n",
              " 0.037212446331977844,\n",
              " 0.038316451013088226,\n",
              " 0.03710830211639404,\n",
              " 0.038406092673540115,\n",
              " 0.03754587098956108,\n",
              " 0.03780645877122879,\n",
              " 0.03789478540420532,\n",
              " 0.03726763278245926,\n",
              " 0.037729959934949875,\n",
              " 0.037422072142362595,\n",
              " 0.03766140714287758,\n",
              " 0.037660468369722366,\n",
              " 0.03811214119195938,\n",
              " 0.03690425679087639,\n",
              " 0.03764517232775688,\n",
              " 0.037578921765089035,\n",
              " 0.03780948370695114,\n",
              " 0.03738468885421753,\n",
              " 0.037895720452070236,\n",
              " 0.03722652420401573,\n",
              " 0.03757777810096741,\n",
              " 0.037718888372182846,\n",
              " 0.036998264491558075,\n",
              " 0.03847833350300789,\n",
              " 0.03766384720802307,\n",
              " 0.037612415850162506,\n",
              " 0.037522684782743454,\n",
              " 0.0378083698451519,\n",
              " 0.037515003234148026,\n",
              " 0.03778056055307388,\n",
              " 0.037407997995615005,\n",
              " 0.038015030324459076,\n",
              " 0.037540044635534286,\n",
              " 0.037820957601070404,\n",
              " 0.03768739849328995,\n",
              " 0.03765449672937393,\n",
              " 0.03813721239566803,\n",
              " 0.03684866800904274,\n",
              " 0.03775961324572563,\n",
              " 0.03740280494093895,\n",
              " 0.03784602880477905,\n",
              " 0.03738068416714668,\n",
              " 0.03783021867275238,\n",
              " 0.037349551916122437,\n",
              " 0.038044486194849014,\n",
              " 0.037113260477781296,\n",
              " 0.03803912177681923,\n",
              " 0.03703615069389343,\n",
              " 0.037476785480976105,\n",
              " 0.037884894758462906,\n",
              " 0.03741982579231262,\n",
              " 0.03796956688165665,\n",
              " 0.03748134896159172,\n",
              " 0.03779028356075287,\n",
              " 0.037981029599905014,\n",
              " 0.03713458776473999,\n",
              " 0.037915416061878204,\n",
              " 0.03725718334317207,\n",
              " 0.037353821098804474,\n",
              " 0.03812916949391365,\n",
              " 0.03765458986163139,\n",
              " 0.037605009973049164,\n",
              " 0.03749215230345726,\n",
              " 0.03789692372083664,\n",
              " 0.037509310990571976,\n",
              " 0.037759650498628616,\n",
              " 0.037474896758794785,\n",
              " 0.03784765303134918,\n",
              " 0.037574879825115204,\n",
              " 0.03770527243614197,\n",
              " 0.03759815916419029,\n",
              " 0.03770521655678749,\n",
              " 0.037711773067712784,\n",
              " 0.037578243762254715,\n",
              " 0.03762652724981308,\n",
              " 0.03759552165865898,\n",
              " 0.03766549006104469,\n",
              " 0.03761754184961319,\n",
              " 0.037403132766485214,\n",
              " 0.03798547759652138,\n",
              " 0.03784115985035896,\n",
              " 0.037226490676403046,\n",
              " 0.03784790262579918,\n",
              " 0.03730632737278938,\n",
              " 0.03769707679748535,\n",
              " 0.037603382021188736,\n",
              " 0.037701912224292755,\n",
              " 0.03747517243027687,\n",
              " 0.037751153111457825,\n",
              " 0.037420064210891724,\n",
              " 0.03781191632151604,\n",
              " 0.03740160912275314,\n",
              " 0.03773198276758194,\n",
              " 0.03730550780892372,\n",
              " 0.03757351636886597,\n",
              " 0.0377669632434845,\n",
              " 0.03726513311266899,\n",
              " 0.038272466510534286,\n",
              " 0.03793516382575035,\n",
              " 0.03732016310095787,\n",
              " 0.03736773878335953,\n",
              " 0.03804919123649597,\n",
              " 0.038128964602947235,\n",
              " 0.0368371307849884,\n",
              " 0.03780146315693855,\n",
              " 0.037529878318309784,\n",
              " 0.037861697375774384,\n",
              " 0.037223149091005325,\n",
              " 0.038052208721637726,\n",
              " 0.03714181110262871,\n",
              " 0.03752010315656662,\n",
              " 0.03772801533341408,\n",
              " 0.03768541291356087,\n",
              " 0.03750383108854294,\n",
              " 0.03791764751076698,\n",
              " 0.03723223879933357,\n",
              " 0.03799033537507057,\n",
              " 0.03707129880785942,\n",
              " 0.03790968656539917,\n",
              " 0.03733225166797638,\n",
              " 0.03760269284248352,\n",
              " 0.03774480149149895,\n",
              " 0.037670377641916275,\n",
              " 0.037546854466199875,\n",
              " 0.03765007480978966,\n",
              " 0.037570200860500336,\n",
              " 0.03750862926244736,\n",
              " 0.03781742975115776,\n",
              " 0.03764454647898674,\n",
              " 0.03765609860420227,\n",
              " 0.037621766328811646,\n",
              " 0.0377255342900753,\n",
              " 0.03751856088638306,\n",
              " 0.03775697946548462,\n",
              " 0.0378105603158474,\n",
              " 0.037413064390420914,\n",
              " 0.03765273466706276,\n",
              " 0.03771787881851196,\n",
              " 0.038131795823574066,\n",
              " 0.03690456598997116,\n",
              " 0.0380614697933197,\n",
              " 0.037101320922374725,\n",
              " 0.037703581154346466,\n",
              " 0.037527862936258316,\n",
              " 0.037745337933301926,\n",
              " 0.037471186369657516,\n",
              " 0.03780703991651535,\n",
              " 0.03736655041575432,\n",
              " 0.03791021183133125,\n",
              " 0.03717151656746864,\n",
              " 0.03787475451827049,\n",
              " 0.03724949061870575,\n",
              " 0.037797801196575165,\n",
              " 0.03731519356369972,\n",
              " 0.037628356367349625,\n",
              " 0.03761562332510948,\n",
              " 0.037689849734306335,\n",
              " 0.037592533975839615,\n",
              " 0.03767462074756622,\n",
              " 0.037577491253614426,\n",
              " 0.03747357800602913,\n",
              " 0.03793850168585777,\n",
              " 0.03777036815881729,\n",
              " 0.03743208572268486,\n",
              " 0.03772687539458275,\n",
              " 0.03743397071957588,\n",
              " 0.03739629313349724,\n",
              " 0.03787316754460335,\n",
              " 0.037944111973047256,\n",
              " 0.037152960896492004,\n",
              " 0.037909768521785736,\n",
              " 0.03723993897438049,\n",
              " 0.03774071857333183,\n",
              " 0.037434954196214676,\n",
              " 0.03755269944667816,\n",
              " 0.037806879729032516,\n",
              " 0.03788537532091141,\n",
              " 0.037251487374305725,\n",
              " 0.03753053396940231,\n",
              " 0.037717945873737335,\n",
              " 0.037630967795848846,\n",
              " 0.0376020148396492,\n",
              " 0.037315238267183304,\n",
              " 0.038011450320482254,\n",
              " 0.03786161541938782,\n",
              " 0.0372931994497776,\n",
              " 0.03741760179400444,\n",
              " 0.03787918761372566,\n",
              " 0.03738988935947418,\n",
              " 0.03794483840465546,\n",
              " 0.03729219734668732,\n",
              " 0.03808792680501938,\n",
              " 0.03747854009270668,\n",
              " 0.037811294198036194,\n",
              " 0.037305980920791626,\n",
              " 0.038060735911130905,\n",
              " 0.0373457632958889,\n",
              " 0.03797163814306259,\n",
              " 0.03697850927710533,\n",
              " 0.03845110535621643,\n",
              " 0.03743531182408333,\n",
              " 0.03804284706711769,\n",
              " 0.03783722594380379,\n",
              " 0.03736007213592529,\n",
              " 0.0371951200067997,\n",
              " 0.038210466504096985,\n",
              " 0.03738521412014961,\n",
              " 0.03788354992866516,\n",
              " 0.03759103640913963,\n",
              " 0.037774037569761276,\n",
              " 0.037408750504255295,\n",
              " 0.03801474720239639,\n",
              " 0.03778219223022461,\n",
              " 0.037476930767297745,\n",
              " 0.037340033799409866,\n",
              " 0.0380224883556366,\n",
              " 0.03731851279735565,\n",
              " 0.038028817623853683,\n",
              " 0.037586286664009094,\n",
              " 0.037650056183338165,\n",
              " 0.03728253021836281,\n",
              " 0.03814937174320221,\n",
              " 0.03794505447149277,\n",
              " 0.037173978984355927,\n",
              " 0.03783472627401352,\n",
              " 0.03738349303603172,\n",
              " 0.038061100989580154,\n",
              " 0.037003349512815475,\n",
              " 0.037156447768211365,\n",
              " 0.038409534841775894,\n",
              " 0.0378095880150795,\n",
              " 0.0374535396695137,\n",
              " 0.037871986627578735,\n",
              " 0.03722439706325531,\n",
              " 0.03756186366081238,\n",
              " 0.03774131089448929,\n",
              " 0.03812677040696144,\n",
              " 0.036866601556539536,\n",
              " 0.03750462830066681,\n",
              " 0.0378461591899395,\n",
              " 0.03756510093808174,\n",
              " 0.03767108917236328,\n",
              " 0.03745702654123306,\n",
              " 0.037911541759967804,\n",
              " 0.03765679895877838,\n",
              " 0.037542469799518585,\n",
              " 0.037574488669633865,\n",
              " 0.03789626806974411,\n",
              " 0.03766950964927673,\n",
              " 0.03760390728712082,\n",
              " 0.037876859307289124,\n",
              " 0.03727057948708534,\n",
              " 0.03729305788874626,\n",
              " 0.038133908063173294,\n",
              " 0.0376061275601387,\n",
              " 0.03769614174962044,\n",
              " 0.037799250334501266,\n",
              " 0.03751256689429283,\n",
              " 0.037823766469955444,\n",
              " 0.037351660430431366,\n",
              " 0.037500444799661636,\n",
              " 0.03784826770424843,\n",
              " 0.037187978625297546,\n",
              " 0.03838752210140228,\n",
              " 0.03769898787140846,\n",
              " 0.03744786977767944,\n",
              " 0.03761877119541168,\n",
              " 0.03766242787241936,\n",
              " 0.03765276074409485,\n",
              " 0.037535205483436584,\n",
              " 0.03740246221423149,\n",
              " 0.03789272904396057,\n",
              " 0.037935271859169006,\n",
              " 0.03724105656147003,\n",
              " 0.037870366126298904,\n",
              " 0.03722260892391205,\n",
              " 0.03710548207163811,\n",
              " 0.03843086212873459,\n",
              " 0.03751621022820473,\n",
              " 0.0377199724316597,\n",
              " 0.03778911381959915,\n",
              " 0.037418097257614136,\n",
              " 0.03804324194788933,\n",
              " 0.037042830139398575,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST 5"
      ],
      "metadata": {
        "id": "1rFGA6jp68mP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gVVKr6m2xRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCmvF6iP22JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model1.train()\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "        output = model1(real_features)\n",
        "        loss = criterion(output, deepfake_features)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model1.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model1(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # # Visualize some outputs\n",
        "            # if batch_idx == 0:  # Only visualize for the first batch of each epoch\n",
        "            #     visualize_output(real_features, output, deepfake_features)  # Implement visualize_output function\n",
        "\n",
        "        val_losses.append(loss.item())\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_losses[-1]:.4f}\")\n",
        "\n",
        "# Plot losses\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RNjbZgQK28lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RA5IWHFd2orR",
        "outputId": "bdd44f1d-d6c3-4e3c-8cf7-54fb83c7ac34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVTvuJJ3onsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(generated_features)"
      ],
      "metadata": {
        "id": "_v2NSflfy4ww",
        "outputId": "b7a67862-7b38-49d1-95b5-e6535e7f508b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_features"
      ],
      "metadata": {
        "id": "UqsEt9K34vkW",
        "outputId": "2fabe951-cd0f-46c9-b12d-ba22acb5cf05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[-0.1050486 ,  0.0592591 , -0.04588313, ...,  0.0681432 ,\n",
              "           0.05616908, -0.07822345],\n",
              "         [-0.09180458,  0.10368504, -0.02269186, ...,  0.080788  ,\n",
              "           0.09603249, -0.21644062],\n",
              "         [-0.10137026,  0.10495242, -0.0299967 , ...,  0.05484535,\n",
              "           0.10793833, -0.20948854],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10067847,  0.06771937, -0.04842731, ...,  0.06707394,\n",
              "           0.06730863, -0.09654537],\n",
              "         [-0.09655349,  0.09838504, -0.02307442, ...,  0.08135854,\n",
              "           0.08672763, -0.19937101],\n",
              "         [-0.10654895,  0.09703689, -0.01857823, ...,  0.06867893,\n",
              "           0.08792984, -0.19429311],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10461126,  0.06491963, -0.04714095, ...,  0.06867933,\n",
              "           0.05878128, -0.08669724],\n",
              "         [-0.09168521,  0.10055253, -0.02711318, ...,  0.07499073,\n",
              "           0.08861582, -0.20904362],\n",
              "         [-0.09862316,  0.10182767, -0.02230792, ...,  0.05916616,\n",
              "           0.09867103, -0.19508171],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10567412,  0.05970036, -0.0457128 , ...,  0.06949127,\n",
              "           0.05475235, -0.07977843],\n",
              "         [-0.09103884,  0.10447767, -0.02107649, ...,  0.0839594 ,\n",
              "           0.09703785, -0.2204105 ],\n",
              "         [-0.10220198,  0.10541014, -0.02933083, ...,  0.05980863,\n",
              "           0.11038655, -0.21552387],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10587838,  0.06364392, -0.04662772, ...,  0.06931551,\n",
              "           0.05758016, -0.08501776],\n",
              "         [-0.09029065,  0.10178299, -0.02609139, ...,  0.07634075,\n",
              "           0.09259861, -0.21383733],\n",
              "         [-0.09743474,  0.10364555, -0.02699101, ...,  0.05627059,\n",
              "           0.103205  , -0.20043904],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10188438,  0.06664818, -0.04957206, ...,  0.06674416,\n",
              "           0.06584059, -0.09433237],\n",
              "         [-0.09617442,  0.09826225, -0.02421855, ...,  0.08071016,\n",
              "           0.08580558, -0.20495132],\n",
              "         [-0.10612684,  0.09734742, -0.01805115, ...,  0.06859252,\n",
              "           0.08892216, -0.19750145],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10556963,  0.05969381, -0.04585102, ...,  0.06787232,\n",
              "           0.05477924, -0.07744896],\n",
              "         [-0.08869904,  0.1045911 , -0.02704651, ...,  0.07364191,\n",
              "           0.09365421, -0.21564516],\n",
              "         [-0.09705819,  0.10819812, -0.03152626, ...,  0.04942324,\n",
              "           0.1049196 , -0.20521861],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10582155,  0.05991479, -0.0458133 , ...,  0.06958824,\n",
              "           0.05552268, -0.08061987],\n",
              "         [-0.09252742,  0.10327734, -0.02175931, ...,  0.08419533,\n",
              "           0.09732684, -0.21971416],\n",
              "         [-0.10221012,  0.10384014, -0.02982329, ...,  0.06046731,\n",
              "           0.10918272, -0.21513468],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10498567,  0.06084574, -0.04646   , ...,  0.06743783,\n",
              "           0.05708665, -0.07927202],\n",
              "         [-0.09149438,  0.10337675, -0.02478732, ...,  0.07807736,\n",
              "           0.09423691, -0.2126596 ],\n",
              "         [-0.09883602,  0.10553637, -0.02922338, ...,  0.05268945,\n",
              "           0.10484164, -0.2027598 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10525143,  0.06419624, -0.04678965, ...,  0.06967433,\n",
              "           0.05895508, -0.08661169],\n",
              "         [-0.09203865,  0.09973094, -0.02616289, ...,  0.07775043,\n",
              "           0.09246886, -0.20965868],\n",
              "         [-0.09862547,  0.10100862, -0.02491973, ...,  0.05857493,\n",
              "           0.10214853, -0.19876865],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10578583,  0.05946093, -0.04552498, ...,  0.07047829,\n",
              "           0.05377477, -0.08051266],\n",
              "         [-0.09148811,  0.10638367, -0.01878802, ...,  0.08661988,\n",
              "           0.09852628, -0.22083333],\n",
              "         [-0.10219447,  0.10180168, -0.02874239, ...,  0.07195383,\n",
              "           0.10838732, -0.21930853],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10583545,  0.06362793, -0.04656396, ...,  0.06933975,\n",
              "           0.05758755, -0.08498275],\n",
              "         [-0.09086217,  0.10108474, -0.02632103, ...,  0.07696924,\n",
              "           0.09276228, -0.21251005],\n",
              "         [-0.09768687,  0.10289387, -0.02770893, ...,  0.05669699,\n",
              "           0.10248467, -0.2011539 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10539092,  0.06411511, -0.04699079, ...,  0.06876518,\n",
              "           0.05829835, -0.08558521],\n",
              "         [-0.09094317,  0.1000571 , -0.02704116, ...,  0.07571211,\n",
              "           0.09165069, -0.20984814],\n",
              "         [-0.09769921,  0.10245599, -0.02513464, ...,  0.05692976,\n",
              "           0.10189627, -0.1975829 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10517174,  0.06115534, -0.04620913, ...,  0.06804135,\n",
              "           0.05699155, -0.0799896 ],\n",
              "         [-0.09195904,  0.10299502, -0.02486687, ...,  0.0783838 ,\n",
              "           0.09471983, -0.21206379],\n",
              "         [-0.09890297,  0.10512158, -0.02940559, ...,  0.05275025,\n",
              "           0.10466412, -0.20251232],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.1050486 ,  0.0592591 , -0.04588313, ...,  0.0681432 ,\n",
              "           0.05616908, -0.07822345],\n",
              "         [-0.09180458,  0.10368504, -0.02269186, ...,  0.080788  ,\n",
              "           0.09603249, -0.21644062],\n",
              "         [-0.10137026,  0.10495242, -0.0299967 , ...,  0.05484535,\n",
              "           0.10793833, -0.20948854],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10067847,  0.06771937, -0.04842731, ...,  0.06707394,\n",
              "           0.06730863, -0.09654537],\n",
              "         [-0.09655349,  0.09838504, -0.02307442, ...,  0.08135854,\n",
              "           0.08672763, -0.19937101],\n",
              "         [-0.10654895,  0.09703689, -0.01857823, ...,  0.06867893,\n",
              "           0.08792984, -0.19429311],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10461126,  0.06491963, -0.04714095, ...,  0.06867933,\n",
              "           0.05878128, -0.08669724],\n",
              "         [-0.09168521,  0.10055253, -0.02711318, ...,  0.07499073,\n",
              "           0.08861582, -0.20904362],\n",
              "         [-0.09862316,  0.10182767, -0.02230792, ...,  0.05916616,\n",
              "           0.09867103, -0.19508171],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10567412,  0.05970036, -0.0457128 , ...,  0.06949127,\n",
              "           0.05475235, -0.07977843],\n",
              "         [-0.09103884,  0.10447767, -0.02107649, ...,  0.0839594 ,\n",
              "           0.09703785, -0.2204105 ],\n",
              "         [-0.10220198,  0.10541014, -0.02933083, ...,  0.05980863,\n",
              "           0.11038655, -0.21552387],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10587838,  0.06364392, -0.04662772, ...,  0.06931551,\n",
              "           0.05758016, -0.08501776],\n",
              "         [-0.09029065,  0.10178299, -0.02609139, ...,  0.07634075,\n",
              "           0.09259861, -0.21383733],\n",
              "         [-0.09743474,  0.10364555, -0.02699101, ...,  0.05627059,\n",
              "           0.103205  , -0.20043904],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10188438,  0.06664818, -0.04957206, ...,  0.06674416,\n",
              "           0.06584059, -0.09433237],\n",
              "         [-0.09617442,  0.09826225, -0.02421855, ...,  0.08071016,\n",
              "           0.08580558, -0.20495132],\n",
              "         [-0.10612684,  0.09734742, -0.01805115, ...,  0.06859252,\n",
              "           0.08892216, -0.19750145],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10556963,  0.05969381, -0.04585102, ...,  0.06787232,\n",
              "           0.05477924, -0.07744896],\n",
              "         [-0.08869904,  0.1045911 , -0.02704651, ...,  0.07364191,\n",
              "           0.09365421, -0.21564516],\n",
              "         [-0.09705819,  0.10819812, -0.03152626, ...,  0.04942324,\n",
              "           0.1049196 , -0.20521861],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10582155,  0.05991479, -0.0458133 , ...,  0.06958824,\n",
              "           0.05552268, -0.08061987],\n",
              "         [-0.09252742,  0.10327734, -0.02175931, ...,  0.08419533,\n",
              "           0.09732684, -0.21971416],\n",
              "         [-0.10221012,  0.10384014, -0.02982329, ...,  0.06046731,\n",
              "           0.10918272, -0.21513468],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10498567,  0.06084574, -0.04646   , ...,  0.06743783,\n",
              "           0.05708665, -0.07927202],\n",
              "         [-0.09149438,  0.10337675, -0.02478732, ...,  0.07807736,\n",
              "           0.09423691, -0.2126596 ],\n",
              "         [-0.09883602,  0.10553637, -0.02922338, ...,  0.05268945,\n",
              "           0.10484164, -0.2027598 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.10525143,  0.06419624, -0.04678965, ...,  0.06967433,\n",
              "           0.05895508, -0.08661169],\n",
              "         [-0.09203865,  0.09973094, -0.02616289, ...,  0.07775043,\n",
              "           0.09246886, -0.20965868],\n",
              "         [-0.09862547,  0.10100862, -0.02491973, ...,  0.05857493,\n",
              "           0.10214853, -0.19876865],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10578583,  0.05946093, -0.04552498, ...,  0.07047829,\n",
              "           0.05377477, -0.08051266],\n",
              "         [-0.09148811,  0.10638367, -0.01878802, ...,  0.08661988,\n",
              "           0.09852628, -0.22083333],\n",
              "         [-0.10219447,  0.10180168, -0.02874239, ...,  0.07195383,\n",
              "           0.10838732, -0.21930853],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10583545,  0.06362793, -0.04656396, ...,  0.06933975,\n",
              "           0.05758755, -0.08498275],\n",
              "         [-0.09086217,  0.10108474, -0.02632103, ...,  0.07696924,\n",
              "           0.09276228, -0.21251005],\n",
              "         [-0.09768687,  0.10289387, -0.02770893, ...,  0.05669699,\n",
              "           0.10248467, -0.2011539 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[-0.10539092,  0.06411511, -0.04699079, ...,  0.06876518,\n",
              "           0.05829835, -0.08558521],\n",
              "         [-0.09094317,  0.1000571 , -0.02704116, ...,  0.07571211,\n",
              "           0.09165069, -0.20984814],\n",
              "         [-0.09769921,  0.10245599, -0.02513464, ...,  0.05692976,\n",
              "           0.10189627, -0.1975829 ],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]],\n",
              " \n",
              "        [[-0.10517174,  0.06115534, -0.04620913, ...,  0.06804135,\n",
              "           0.05699155, -0.0799896 ],\n",
              "         [-0.09195904,  0.10299502, -0.02486687, ...,  0.0783838 ,\n",
              "           0.09471983, -0.21206379],\n",
              "         [-0.09890297,  0.10512158, -0.02940559, ...,  0.05275025,\n",
              "           0.10466412, -0.20251232],\n",
              "         ...,\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608],\n",
              "         [-0.01912401,  0.0277293 , -0.000632  , ...,  0.00333114,\n",
              "           0.02780168,  0.05257608]]], dtype=float32),\n",
              " array([[[ 0.14715578, -0.16542408,  0.18437177, ..., -0.06599808,\n",
              "          -0.194534  , -0.10618176],\n",
              "         [ 0.10362137, -0.14128314,  0.09954125, ..., -0.05560563,\n",
              "          -0.1580073 , -0.10774528],\n",
              "         [ 0.16606233, -0.15659708,  0.18928455, ..., -0.05213925,\n",
              "          -0.24475367, -0.05628156],\n",
              "         ...,\n",
              "         [ 0.13541538, -0.26515076,  0.13885772, ..., -0.04544246,\n",
              "          -0.16899347, -0.14278817],\n",
              "         [ 0.1359779 , -0.22044528, -0.00206409, ..., -0.10156794,\n",
              "          -0.19889742, -0.11590512],\n",
              "         [ 0.21420138, -0.21500239,  0.00319653, ..., -0.13956453,\n",
              "          -0.24934407, -0.05588746]],\n",
              " \n",
              "        [[ 0.16477555, -0.06135626,  0.09290937, ..., -0.05219459,\n",
              "          -0.1713922 ,  0.0260768 ],\n",
              "         [ 0.09882579, -0.16578633,  0.18301982, ..., -0.11404131,\n",
              "          -0.2243915 , -0.15205419],\n",
              "         [ 0.18069947, -0.08873253,  0.14884457, ..., -0.13759555,\n",
              "          -0.11434382, -0.08739879],\n",
              "         ...,\n",
              "         [ 0.08101115, -0.17590156,  0.14645568, ..., -0.07591494,\n",
              "          -0.14537112, -0.15541542],\n",
              "         [ 0.02297843, -0.16046882,  0.07823843, ...,  0.01271709,\n",
              "          -0.15709174, -0.09212461],\n",
              "         [ 0.15350382, -0.11757664,  0.11475099, ..., -0.08773544,\n",
              "          -0.15228795, -0.15729983]],\n",
              " \n",
              "        [[ 0.19625607, -0.10513404,  0.1720267 , ..., -0.14063212,\n",
              "          -0.10676042, -0.11211985],\n",
              "         [ 0.08202307, -0.15279388,  0.17499691, ..., -0.07344791,\n",
              "          -0.14854023, -0.17358261],\n",
              "         [ 0.13362864, -0.11295694,  0.04033468, ...,  0.0136869 ,\n",
              "          -0.15564333, -0.11587361],\n",
              "         ...,\n",
              "         [ 0.18760253, -0.14409575,  0.15215302, ...,  0.04425725,\n",
              "          -0.10952446, -0.07489967],\n",
              "         [ 0.22584888, -0.02724155,  0.09378228, ..., -0.12253709,\n",
              "          -0.12001681, -0.10705646],\n",
              "         [ 0.14477237, -0.1313594 ,  0.09489768, ..., -0.14119436,\n",
              "          -0.18217444, -0.05178448]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.09340491, -0.09403218,  0.21313003, ..., -0.12483843,\n",
              "          -0.04272227, -0.19625601],\n",
              "         [ 0.12872902, -0.13311672,  0.07659397, ..., -0.07318188,\n",
              "          -0.11709195, -0.15438503],\n",
              "         [ 0.09382847, -0.16081762,  0.05277772, ...,  0.01932165,\n",
              "          -0.11158763, -0.02525219],\n",
              "         ...,\n",
              "         [ 0.18025437, -0.16214299,  0.13609508, ...,  0.01245904,\n",
              "          -0.14663109,  0.01791615],\n",
              "         [ 0.14156541,  0.03468968,  0.12890586, ..., -0.05683227,\n",
              "          -0.06136257, -0.12050888],\n",
              "         [ 0.14283742, -0.21240726,  0.11469093, ..., -0.00893003,\n",
              "          -0.13280156, -0.09480312]],\n",
              " \n",
              "        [[ 0.16953275, -0.11783055,  0.14098072, ..., -0.0295395 ,\n",
              "          -0.13129282, -0.0034175 ],\n",
              "         [ 0.17784333, -0.13633081,  0.12348992, ..., -0.0726242 ,\n",
              "          -0.16142902,  0.14812173],\n",
              "         [ 0.14779486, -0.1364724 ,  0.19508633, ..., -0.20535518,\n",
              "          -0.1571775 ,  0.02822113],\n",
              "         ...,\n",
              "         [ 0.16721046, -0.1335326 ,  0.19241719, ..., -0.10516556,\n",
              "          -0.06357863, -0.07939464],\n",
              "         [ 0.11449449, -0.13916475,  0.26342067, ..., -0.13299777,\n",
              "          -0.10400392, -0.01540275],\n",
              "         [ 0.06741031, -0.10182379,  0.13750848, ..., -0.05598905,\n",
              "          -0.0533461 , -0.04988701]],\n",
              " \n",
              "        [[ 0.09741934, -0.09081461,  0.15483874, ...,  0.07099883,\n",
              "          -0.13650566, -0.09407285],\n",
              "         [ 0.09512539, -0.07514334,  0.13394026, ..., -0.02968398,\n",
              "          -0.11161713, -0.16142334],\n",
              "         [ 0.1698519 , -0.14753851,  0.12901248, ..., -0.07503626,\n",
              "          -0.26054138, -0.04621893],\n",
              "         ...,\n",
              "         [ 0.20279577, -0.1324355 ,  0.19178489, ..., -0.19024551,\n",
              "          -0.25114793, -0.00553855],\n",
              "         [ 0.07407718,  0.03096376,  0.11774819, ..., -0.17163305,\n",
              "           0.0090298 , -0.09045789],\n",
              "         [ 0.04222431, -0.16743204,  0.13460493, ..., -0.09836864,\n",
              "          -0.1803602 , -0.09732246]]], dtype=float32),\n",
              " array([[[ 0.09859009, -0.12221009,  0.10438082, ...,  0.05168626,\n",
              "          -0.11093855,  0.0316366 ],\n",
              "         [ 0.09690251, -0.15892488,  0.17384452, ..., -0.07588841,\n",
              "          -0.08055864, -0.04981975],\n",
              "         [ 0.05540636, -0.16284174,  0.17199364, ..., -0.0532384 ,\n",
              "          -0.1435321 , -0.07243399],\n",
              "         ...,\n",
              "         [ 0.16484535, -0.11541061,  0.07327206, ..., -0.07473288,\n",
              "          -0.15268669, -0.1597471 ],\n",
              "         [ 0.04455029, -0.16593178,  0.01671304, ...,  0.0784879 ,\n",
              "          -0.23621544, -0.06983378],\n",
              "         [ 0.12499263, -0.10027614,  0.23247331, ..., -0.0391896 ,\n",
              "          -0.05232021, -0.10222663]],\n",
              " \n",
              "        [[ 0.23625532, -0.26840812,  0.11314578, ..., -0.03401785,\n",
              "          -0.21604602, -0.1191306 ],\n",
              "         [ 0.14213544, -0.1648449 ,  0.11525565, ..., -0.10953651,\n",
              "          -0.07117928, -0.08638676],\n",
              "         [ 0.06117982, -0.1188499 ,  0.09721801, ..., -0.10393904,\n",
              "          -0.24736364, -0.03515124],\n",
              "         ...,\n",
              "         [ 0.08321212, -0.13384283,  0.23481178, ..., -0.07691306,\n",
              "          -0.03393253, -0.05554521],\n",
              "         [ 0.04809693, -0.12210578,  0.22281578, ...,  0.13761748,\n",
              "          -0.09077245, -0.14999679],\n",
              "         [ 0.13876693, -0.22333488,  0.1518335 , ..., -0.09222537,\n",
              "          -0.18308783, -0.17359829]],\n",
              " \n",
              "        [[ 0.21860178, -0.11732185,  0.1639662 , ..., -0.07501517,\n",
              "          -0.19077758, -0.02103924],\n",
              "         [ 0.20359543, -0.17416131,  0.2434921 , ...,  0.03530541,\n",
              "          -0.17072576, -0.12023363],\n",
              "         [ 0.11417441, -0.08362407,  0.023023  , ..., -0.05230832,\n",
              "          -0.16447605, -0.08625148],\n",
              "         ...,\n",
              "         [ 0.11105423, -0.24224234,  0.06367321, ..., -0.07651259,\n",
              "          -0.20676728,  0.07138773],\n",
              "         [ 0.12582484, -0.02890772,  0.17771897, ..., -0.08823619,\n",
              "          -0.05700698, -0.01358998],\n",
              "         [ 0.11530294, -0.1878736 ,  0.04136715, ..., -0.02722251,\n",
              "          -0.18016127, -0.09424595]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.12150389, -0.10948928,  0.1579941 , ..., -0.01886582,\n",
              "          -0.11819112, -0.10213214],\n",
              "         [ 0.14074248, -0.26773828,  0.22466078, ..., -0.05589716,\n",
              "          -0.22287123, -0.16726924],\n",
              "         [ 0.21268275, -0.15023687,  0.14524569, ..., -0.0579217 ,\n",
              "          -0.1155322 , -0.04548989],\n",
              "         ...,\n",
              "         [ 0.0845108 , -0.07205016,  0.10612622, ..., -0.02651654,\n",
              "          -0.18062365, -0.05875786],\n",
              "         [ 0.1488199 , -0.12312657,  0.16547874, ..., -0.06496854,\n",
              "          -0.11662549,  0.01651549],\n",
              "         [ 0.15713155, -0.178224  ,  0.13025862, ..., -0.02825943,\n",
              "          -0.17415348, -0.01818267]],\n",
              " \n",
              "        [[ 0.0579743 , -0.13146478,  0.20982063, ..., -0.02747923,\n",
              "          -0.14882183, -0.08131647],\n",
              "         [ 0.14483455, -0.12426993,  0.17519495, ..., -0.00328925,\n",
              "          -0.05499515,  0.06566026],\n",
              "         [ 0.1653795 , -0.11508633,  0.08758555, ..., -0.20125914,\n",
              "          -0.12312807, -0.1167995 ],\n",
              "         ...,\n",
              "         [ 0.09202421, -0.09167731,  0.15862745, ..., -0.06211166,\n",
              "          -0.05562861, -0.0888616 ],\n",
              "         [ 0.08484212, -0.07429229,  0.01402993, ..., -0.06260588,\n",
              "          -0.06882398,  0.01344069],\n",
              "         [ 0.01009945, -0.1126553 ,  0.06583668, ...,  0.03019221,\n",
              "          -0.08266883, -0.09070651]],\n",
              " \n",
              "        [[ 0.18001196, -0.14028913,  0.10361789, ..., -0.05694345,\n",
              "          -0.12395208, -0.16387458],\n",
              "         [ 0.099671  , -0.16487148,  0.09311263, ..., -0.19454059,\n",
              "          -0.11937958, -0.08517902],\n",
              "         [ 0.20242554, -0.15035892,  0.12220028, ..., -0.05459357,\n",
              "          -0.14679062, -0.13384148],\n",
              "         ...,\n",
              "         [ 0.03903284, -0.15435494,  0.16050708, ...,  0.00494498,\n",
              "          -0.08751711, -0.12477131],\n",
              "         [ 0.07555862, -0.09049684,  0.09123808, ..., -0.03423328,\n",
              "          -0.11625986, -0.06019301],\n",
              "         [ 0.26732945, -0.18132299,  0.22932678, ..., -0.11349286,\n",
              "          -0.12816544, -0.0749723 ]]], dtype=float32),\n",
              " array([[[ 0.17835227, -0.08346188, -0.03256889, ..., -0.03542718,\n",
              "          -0.13308851, -0.1185603 ],\n",
              "         [ 0.13203472, -0.16974166,  0.09284371, ..., -0.02423416,\n",
              "          -0.18465737, -0.09102242],\n",
              "         [ 0.03339614, -0.09404212,  0.177804  , ..., -0.01341219,\n",
              "          -0.11608868, -0.04646755],\n",
              "         ...,\n",
              "         [ 0.1296753 , -0.10580334,  0.08381587, ..., -0.07480372,\n",
              "          -0.14453068, -0.12506771],\n",
              "         [ 0.05660401, -0.13598913,  0.26875946, ..., -0.08263001,\n",
              "          -0.17877366, -0.0584752 ],\n",
              "         [ 0.25951666, -0.16769794,  0.10125215, ..., -0.14056993,\n",
              "          -0.23172234,  0.01593791]],\n",
              " \n",
              "        [[ 0.11258861, -0.02969231,  0.19633389, ..., -0.1661731 ,\n",
              "          -0.05118945,  0.01293334],\n",
              "         [ 0.09374955, -0.16301638,  0.13102797, ..., -0.0297424 ,\n",
              "          -0.11291413, -0.03768634],\n",
              "         [ 0.07236898, -0.13268651,  0.1048707 , ...,  0.02383941,\n",
              "          -0.24088015, -0.05180275],\n",
              "         ...,\n",
              "         [ 0.08997104, -0.11158589,  0.1869407 , ..., -0.02697894,\n",
              "          -0.10911778, -0.09567507],\n",
              "         [ 0.2010136 , -0.02228302,  0.17669356, ..., -0.10965112,\n",
              "          -0.08982457, -0.0670266 ],\n",
              "         [ 0.09230851, -0.24835476,  0.09801034, ...,  0.01556832,\n",
              "          -0.18170244, -0.09904482]]], dtype=float32),\n",
              " array([[[ 0.17182344, -0.10472631,  0.15874888, ..., -0.02016097,\n",
              "          -0.09651285, -0.06014703],\n",
              "         [ 0.14946869, -0.08265976,  0.04533787, ..., -0.13072701,\n",
              "          -0.10499927, -0.01437055],\n",
              "         [ 0.20935027, -0.11396149,  0.14526904, ..., -0.12531559,\n",
              "          -0.14707106, -0.00748096],\n",
              "         ...,\n",
              "         [ 0.03614266, -0.06195904,  0.07545969, ..., -0.06788902,\n",
              "          -0.07240257, -0.07878032],\n",
              "         [ 0.06778947, -0.17793491,  0.041425  , ..., -0.10014933,\n",
              "          -0.19330001, -0.06514876],\n",
              "         [ 0.11152744, -0.10890283,  0.08568069, ...,  0.04344854,\n",
              "          -0.15475321, -0.08883182]],\n",
              " \n",
              "        [[ 0.01213784, -0.09151769,  0.13004567, ..., -0.0574597 ,\n",
              "          -0.15106596, -0.06517816],\n",
              "         [ 0.1445654 , -0.11037904,  0.02668735, ...,  0.01977268,\n",
              "          -0.1495124 , -0.08659804],\n",
              "         [ 0.22781456, -0.15147367,  0.1523857 , ..., -0.05145472,\n",
              "          -0.25945514, -0.01980021],\n",
              "         ...,\n",
              "         [ 0.10677317, -0.13028926,  0.08802798, ..., -0.12198092,\n",
              "          -0.15922382, -0.13677545],\n",
              "         [ 0.17587592, -0.09712883,  0.13740863, ..., -0.19407296,\n",
              "          -0.12130795, -0.0969681 ],\n",
              "         [ 0.1290344 , -0.10371993,  0.07113956, ..., -0.1110704 ,\n",
              "          -0.13978171, -0.05078616]],\n",
              " \n",
              "        [[ 0.0698506 , -0.09013566,  0.09387176, ...,  0.043043  ,\n",
              "          -0.06869738, -0.19708818],\n",
              "         [ 0.17732151, -0.00455306,  0.18940744, ..., -0.08097533,\n",
              "          -0.07768755, -0.00924706],\n",
              "         [ 0.11482947, -0.07289544,  0.15419456, ..., -0.01826634,\n",
              "          -0.19479054, -0.17501934],\n",
              "         ...,\n",
              "         [ 0.19911611, -0.16262697,  0.18187408, ..., -0.03464466,\n",
              "          -0.1311762 , -0.08888538],\n",
              "         [ 0.13807999,  0.02485246,  0.1049337 , ..., -0.06393988,\n",
              "           0.05035236, -0.00030493],\n",
              "         [ 0.06356546, -0.07063062,  0.05671132, ...,  0.00242703,\n",
              "          -0.11095642,  0.0527093 ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.11342735, -0.0946094 ,  0.05695271, ..., -0.0027043 ,\n",
              "          -0.16674924, -0.05827061],\n",
              "         [ 0.08525057, -0.19867972,  0.1251979 , ..., -0.08924025,\n",
              "          -0.20702551, -0.03779582],\n",
              "         [ 0.12602009, -0.05075734,  0.1112495 , ..., -0.04048313,\n",
              "          -0.06139991, -0.05069529],\n",
              "         ...,\n",
              "         [ 0.16118076, -0.21940872,  0.17665395, ..., -0.08984384,\n",
              "          -0.07469676,  0.03886586],\n",
              "         [ 0.06427282, -0.11525099,  0.16793677, ..., -0.07812503,\n",
              "          -0.09745117, -0.08289573],\n",
              "         [ 0.02395882, -0.12653017,  0.10797857, ..., -0.12128692,\n",
              "          -0.13390137, -0.04323853]],\n",
              " \n",
              "        [[ 0.09642562, -0.11588772,  0.14489186, ..., -0.0179599 ,\n",
              "          -0.11108953, -0.02550048],\n",
              "         [ 0.12938392, -0.17905763,  0.10191969, ..., -0.01670669,\n",
              "          -0.17418   ,  0.00761053],\n",
              "         [ 0.16319832, -0.1396579 ,  0.14445007, ..., -0.05689876,\n",
              "          -0.09382012, -0.05942697],\n",
              "         ...,\n",
              "         [ 0.08647691, -0.04735997,  0.13708186, ..., -0.02488779,\n",
              "          -0.12004843, -0.0267514 ],\n",
              "         [ 0.1430286 , -0.09834951,  0.0796072 , ..., -0.05833963,\n",
              "          -0.1416513 , -0.07063184],\n",
              "         [ 0.09546408, -0.04677101,  0.0974915 , ..., -0.04684762,\n",
              "          -0.098603  , -0.03453708]],\n",
              " \n",
              "        [[ 0.15098517, -0.03184438,  0.22227597, ..., -0.08952178,\n",
              "          -0.01322219, -0.08001678],\n",
              "         [ 0.10745783, -0.14638449,  0.19524223, ..., -0.02689057,\n",
              "          -0.16289434,  0.02321913],\n",
              "         [ 0.10469677, -0.14057212,  0.15694618, ..., -0.11441819,\n",
              "          -0.1641827 , -0.08383467],\n",
              "         ...,\n",
              "         [-0.00282828, -0.10012202,  0.20510733, ..., -0.01689058,\n",
              "          -0.10235155,  0.04311837],\n",
              "         [ 0.2459613 , -0.13236359,  0.11051647, ..., -0.08554365,\n",
              "          -0.18860072, -0.10005952],\n",
              "         [ 0.17496127, -0.2607332 ,  0.19843951, ..., -0.15901092,\n",
              "          -0.20932546, -0.18640335]]], dtype=float32),\n",
              " array([[[ 0.23413976, -0.09397621,  0.21521291, ..., -0.01962303,\n",
              "          -0.09570497, -0.15967093],\n",
              "         [ 0.06479259, -0.19592059,  0.06345567, ..., -0.04483773,\n",
              "          -0.17927071, -0.10579144],\n",
              "         [ 0.15743008, -0.01892035,  0.07855554, ..., -0.08313142,\n",
              "          -0.09493808, -0.08945026],\n",
              "         ...,\n",
              "         [ 0.12588899, -0.09800266, -0.00303846, ..., -0.13116573,\n",
              "          -0.20837706, -0.19006719],\n",
              "         [ 0.07214468, -0.04481093,  0.14991246, ..., -0.14542508,\n",
              "          -0.01617915, -0.01035834],\n",
              "         [ 0.17212826, -0.24291253,  0.25922182, ..., -0.04312539,\n",
              "          -0.20084941, -0.09877289]],\n",
              " \n",
              "        [[ 0.14776477, -0.06429984,  0.2645673 , ...,  0.04025875,\n",
              "          -0.04691679, -0.03748563],\n",
              "         [ 0.21426123, -0.12616867,  0.17227486, ..., -0.08091119,\n",
              "          -0.14091419, -0.01834335],\n",
              "         [ 0.15646368, -0.12676133, -0.03090966, ..., -0.2034134 ,\n",
              "          -0.11094412, -0.06357023],\n",
              "         ...,\n",
              "         [ 0.20149659, -0.06215745,  0.13229744, ..., -0.11155528,\n",
              "          -0.01211721, -0.00874422],\n",
              "         [ 0.12833494, -0.1120006 ,  0.08084871, ..., -0.19283196,\n",
              "          -0.15835007, -0.06467672],\n",
              "         [ 0.20402706, -0.12926266,  0.14368434, ..., -0.04711966,\n",
              "          -0.16774571, -0.08283971]],\n",
              " \n",
              "        [[ 0.14978728, -0.13294676,  0.09633046, ...,  0.05549805,\n",
              "          -0.19051296, -0.06623498],\n",
              "         [ 0.1500722 , -0.11870874,  0.20834872, ..., -0.10817613,\n",
              "          -0.06147897,  0.02690414],\n",
              "         [ 0.16572827, -0.15809879,  0.18727654, ..., -0.1252226 ,\n",
              "          -0.15423849, -0.02753153],\n",
              "         ...,\n",
              "         [ 0.22504589, -0.24592876,  0.08160219, ..., -0.09885668,\n",
              "          -0.20837487, -0.0078943 ],\n",
              "         [-0.0309482 , -0.1786705 ,  0.1139391 , ...,  0.00758974,\n",
              "          -0.13212077,  0.03428467],\n",
              "         [ 0.09815492, -0.08677042,  0.07437263, ...,  0.00813185,\n",
              "          -0.17407665, -0.10015067]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.19023128, -0.09691342,  0.15567774, ..., -0.11052855,\n",
              "          -0.12590079, -0.0163616 ],\n",
              "         [ 0.05137437, -0.12249256,  0.12794988, ..., -0.05043689,\n",
              "          -0.10890789, -0.11437398],\n",
              "         [ 0.0906591 , -0.11646323,  0.04947168, ..., -0.01996741,\n",
              "          -0.08444505, -0.06291138],\n",
              "         ...,\n",
              "         [ 0.17842701, -0.19086182,  0.10482999, ..., -0.20855108,\n",
              "          -0.15805888, -0.12607867],\n",
              "         [ 0.06347732, -0.03257599,  0.09946884, ..., -0.00572381,\n",
              "          -0.07597449, -0.00660505],\n",
              "         [ 0.16626748, -0.1427186 ,  0.08187509, ..., -0.07914829,\n",
              "          -0.19089143, -0.12387828]],\n",
              " \n",
              "        [[ 0.14376779, -0.1623626 ,  0.05868319, ..., -0.05850179,\n",
              "          -0.15608993,  0.01501451],\n",
              "         [ 0.12482509, -0.10135555,  0.08180384, ..., -0.03385772,\n",
              "          -0.18709579, -0.05621662],\n",
              "         [ 0.19653365, -0.23903155,  0.18698819, ..., -0.03043757,\n",
              "          -0.0941631 , -0.09284016],\n",
              "         ...,\n",
              "         [ 0.153306  , -0.14609572,  0.12852658, ..., -0.10441029,\n",
              "          -0.15168966, -0.2026215 ],\n",
              "         [ 0.10944012, -0.20366392,  0.17919964, ..., -0.02466101,\n",
              "          -0.12972575, -0.10877305],\n",
              "         [ 0.26014364, -0.02032997,  0.18487643, ..., -0.06472355,\n",
              "          -0.132086  , -0.03730564]],\n",
              " \n",
              "        [[ 0.03902753, -0.13409778,  0.16751513, ..., -0.09863975,\n",
              "          -0.08659345, -0.1226683 ],\n",
              "         [ 0.02500464,  0.03390354,  0.13960543, ..., -0.02090924,\n",
              "          -0.0678618 , -0.13678421],\n",
              "         [ 0.18685244, -0.12976569,  0.13593946, ..., -0.14548415,\n",
              "          -0.12013298, -0.15940899],\n",
              "         ...,\n",
              "         [ 0.06635512, -0.11523379,  0.1509304 , ..., -0.05091722,\n",
              "          -0.01695318, -0.08135004],\n",
              "         [ 0.19969569, -0.1436018 ,  0.09810222, ..., -0.09655841,\n",
              "          -0.11856742, -0.05741444],\n",
              "         [ 0.1175875 , -0.06830283,  0.04793407, ..., -0.01640657,\n",
              "          -0.12554874, -0.10781009]]], dtype=float32),\n",
              " array([[[ 0.20608893, -0.25116912,  0.22925049, ..., -0.10066096,\n",
              "          -0.18375486, -0.08366905],\n",
              "         [ 0.06536619, -0.15623716,  0.16333228, ..., -0.0745257 ,\n",
              "          -0.15543246, -0.05161423],\n",
              "         [ 0.04304234, -0.00421196,  0.04644145, ...,  0.04611573,\n",
              "          -0.02298844, -0.16432598],\n",
              "         ...,\n",
              "         [ 0.11069582, -0.15486774,  0.21111193, ...,  0.0029071 ,\n",
              "          -0.12811255, -0.12044531],\n",
              "         [ 0.16789642, -0.14073642,  0.19700998, ..., -0.09486002,\n",
              "          -0.0838227 , -0.10618814],\n",
              "         [ 0.06156185, -0.09484993,  0.22884989, ..., -0.11341338,\n",
              "          -0.02193877, -0.09014407]],\n",
              " \n",
              "        [[ 0.17756048, -0.1087626 ,  0.14236873, ..., -0.06465074,\n",
              "          -0.05503491,  0.01848963],\n",
              "         [ 0.05905094, -0.16331407,  0.2237868 , ...,  0.0350264 ,\n",
              "          -0.20565417, -0.17643717],\n",
              "         [ 0.06645425, -0.10145439,  0.03438872, ...,  0.02043489,\n",
              "          -0.15575397, -0.07754795],\n",
              "         ...,\n",
              "         [ 0.19726817,  0.01838776,  0.06628577, ..., -0.03358784,\n",
              "          -0.09921418, -0.11673091],\n",
              "         [ 0.17675698, -0.18348426,  0.04967086, ..., -0.15177307,\n",
              "          -0.19784085, -0.23520054],\n",
              "         [ 0.01676503, -0.03706936,  0.116296  , ..., -0.0271126 ,\n",
              "          -0.09817945, -0.03757925]]], dtype=float32),\n",
              " array([[[ 0.07350589,  0.08540292, -0.11814226, ...,  0.07254045,\n",
              "           0.10022938,  0.12509671],\n",
              "         [ 0.06197687,  0.0440864 , -0.12928753, ...,  0.05345668,\n",
              "           0.10260555,  0.08218579],\n",
              "         [ 0.0617439 ,  0.02928242, -0.114475  , ...,  0.03918806,\n",
              "           0.11854063,  0.06712128],\n",
              "         ...,\n",
              "         [ 0.04968875,  0.07407567, -0.10933887, ...,  0.03510791,\n",
              "           0.11972811,  0.04435126],\n",
              "         [ 0.0494776 ,  0.07397258, -0.10940602, ...,  0.03513123,\n",
              "           0.11959815,  0.04437465],\n",
              "         [ 0.04923359,  0.07373656, -0.10966905, ...,  0.03528228,\n",
              "           0.11963189,  0.04407893]],\n",
              " \n",
              "        [[ 0.08110552,  0.08818956, -0.12014478, ...,  0.07110269,\n",
              "           0.10148961,  0.12481384],\n",
              "         [ 0.06622841,  0.04439364, -0.1290985 , ...,  0.05297282,\n",
              "           0.10818507,  0.08813566],\n",
              "         [ 0.06152562,  0.03142786, -0.11106625, ...,  0.04060686,\n",
              "           0.12266526,  0.06806123],\n",
              "         ...,\n",
              "         [ 0.0516622 ,  0.07252083, -0.11078314, ...,  0.03243639,\n",
              "           0.12366618,  0.0512844 ],\n",
              "         [ 0.05148285,  0.07257087, -0.11048897, ...,  0.03257896,\n",
              "           0.12322013,  0.05132347],\n",
              "         [ 0.05137869,  0.0726167 , -0.11019023, ...,  0.03288185,\n",
              "           0.12302458,  0.05142491]],\n",
              " \n",
              "        [[ 0.07295825,  0.0851263 , -0.11750502, ...,  0.07229646,\n",
              "           0.10103384,  0.12507787],\n",
              "         [ 0.06177049,  0.04417582, -0.1292926 , ...,  0.05297437,\n",
              "           0.10244097,  0.08185343],\n",
              "         [ 0.06188989,  0.02947162, -0.11486745, ...,  0.03868882,\n",
              "           0.11859605,  0.06668917],\n",
              "         ...,\n",
              "         [ 0.04946782,  0.07380189, -0.11048818, ...,  0.03539971,\n",
              "           0.1196399 ,  0.04317548],\n",
              "         [ 0.04916313,  0.0736221 , -0.110658  , ...,  0.03569021,\n",
              "           0.11962245,  0.04301934],\n",
              "         [ 0.04895076,  0.07355638, -0.11086187, ...,  0.0360806 ,\n",
              "           0.11970088,  0.04281446]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.07233965,  0.08486711, -0.11737864, ...,  0.07080016,\n",
              "           0.10197553,  0.12578629],\n",
              "         [ 0.06061181,  0.04308593, -0.12918828, ...,  0.05143397,\n",
              "           0.10102016,  0.08004651],\n",
              "         [ 0.06150599,  0.02713346, -0.11698038, ...,  0.03833746,\n",
              "           0.11697918,  0.06505089],\n",
              "         ...,\n",
              "         [ 0.05278318,  0.07565871, -0.10961752, ...,  0.03766758,\n",
              "           0.12235188,  0.04297913],\n",
              "         [ 0.05259652,  0.07562643, -0.10967648, ...,  0.03802252,\n",
              "           0.12251695,  0.04270146],\n",
              "         [ 0.05241788,  0.07555313, -0.10957758, ...,  0.03828842,\n",
              "           0.12247432,  0.0426279 ]],\n",
              " \n",
              "        [[ 0.06990384,  0.08634295, -0.11764519, ...,  0.07082616,\n",
              "           0.1056544 ,  0.12758787],\n",
              "         [ 0.06418891,  0.04725418, -0.13023831, ...,  0.05140411,\n",
              "           0.10283002,  0.07573909],\n",
              "         [ 0.06467666,  0.03327619, -0.12058782, ...,  0.03840179,\n",
              "           0.11833635,  0.05751907],\n",
              "         ...,\n",
              "         [ 0.06221844,  0.09086054, -0.10306732, ...,  0.04717466,\n",
              "           0.1198059 ,  0.0396966 ],\n",
              "         [ 0.06269441,  0.09110143, -0.10304302, ...,  0.04722216,\n",
              "           0.11983277,  0.03997777],\n",
              "         [ 0.06289172,  0.09130751, -0.10281429, ...,  0.04725643,\n",
              "           0.11980474,  0.03989404]],\n",
              " \n",
              "        [[ 0.08483134,  0.09061311, -0.1188971 , ...,  0.06909028,\n",
              "           0.10140397,  0.12531014],\n",
              "         [ 0.07370955,  0.04591142, -0.13369885, ...,  0.04970519,\n",
              "           0.10968024,  0.09530636],\n",
              "         [ 0.0604308 ,  0.03257699, -0.12132096, ...,  0.04244225,\n",
              "           0.11727296,  0.07656477],\n",
              "         ...,\n",
              "         [ 0.06285052,  0.08728807, -0.13838129, ...,  0.06245077,\n",
              "           0.09377725,  0.03822213],\n",
              "         [ 0.07003292,  0.08336292, -0.14801049, ...,  0.06256022,\n",
              "           0.0935294 ,  0.03964213],\n",
              "         [ 0.07235759,  0.07706353, -0.15249136, ...,  0.05959873,\n",
              "           0.0938057 ,  0.04304297]]], dtype=float32),\n",
              " array([[[ 0.0727218 ,  0.08480687, -0.11723716, ...,  0.07212423,\n",
              "           0.10114763,  0.12508804],\n",
              "         [ 0.06173581,  0.04399473, -0.12944925, ...,  0.05269828,\n",
              "           0.10220062,  0.08159378],\n",
              "         [ 0.0616764 ,  0.02895632, -0.11532217, ...,  0.0387369 ,\n",
              "           0.11829841,  0.06645567],\n",
              "         ...,\n",
              "         [ 0.04933172,  0.07358862, -0.11040686, ...,  0.03568832,\n",
              "           0.12000135,  0.04263116],\n",
              "         [ 0.04906313,  0.07328737, -0.11075093, ...,  0.03586263,\n",
              "           0.12000898,  0.04241762],\n",
              "         [ 0.04889193,  0.072974  , -0.11116786, ...,  0.03593157,\n",
              "           0.1200259 ,  0.04226675]],\n",
              " \n",
              "        [[ 0.08189404,  0.08942689, -0.12035061, ...,  0.07158051,\n",
              "           0.10237537,  0.1252409 ],\n",
              "         [ 0.06787037,  0.04474747, -0.1291291 , ...,  0.05305888,\n",
              "           0.10993835,  0.08959989],\n",
              "         [ 0.06055618,  0.03079783, -0.11110297, ...,  0.04178498,\n",
              "           0.12401915,  0.06759123],\n",
              "         ...,\n",
              "         [ 0.05243253,  0.07053378, -0.11069429, ...,  0.03482747,\n",
              "           0.12670857,  0.05174694],\n",
              "         [ 0.0524004 ,  0.07041875, -0.11060771, ...,  0.03506003,\n",
              "           0.12655371,  0.05171335],\n",
              "         [ 0.05204282,  0.07024039, -0.11026684, ...,  0.03532423,\n",
              "           0.12610714,  0.05154842]],\n",
              " \n",
              "        [[ 0.06603621,  0.08476046, -0.11649495, ...,  0.07170529,\n",
              "           0.11091743,  0.13073516],\n",
              "         [ 0.06995063,  0.05432592, -0.13010935, ...,  0.05052177,\n",
              "           0.10810201,  0.076179  ],\n",
              "         [ 0.07030486,  0.04105988, -0.12371233, ...,  0.04241265,\n",
              "           0.12175079,  0.05286368],\n",
              "         ...,\n",
              "         [ 0.07491899,  0.09603543, -0.10235459, ...,  0.05234284,\n",
              "           0.12692755,  0.04209303],\n",
              "         [ 0.07554228,  0.09624199, -0.10205707, ...,  0.05235577,\n",
              "           0.12738957,  0.04185977],\n",
              "         [ 0.07585385,  0.09631054, -0.10164355, ...,  0.05250722,\n",
              "           0.12762687,  0.04160228]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.08181033,  0.08973382, -0.1201372 , ...,  0.07145228,\n",
              "           0.10174948,  0.12506397],\n",
              "         [ 0.0694163 ,  0.0457495 , -0.12980883, ...,  0.05295496,\n",
              "           0.11028538,  0.09005424],\n",
              "         [ 0.06071762,  0.03142795, -0.11202428, ...,  0.04183044,\n",
              "           0.12364637,  0.06674632],\n",
              "         ...,\n",
              "         [ 0.05248371,  0.07143859, -0.10937146, ...,  0.03657286,\n",
              "           0.12668194,  0.05223943],\n",
              "         [ 0.05224296,  0.07131155, -0.10898827, ...,  0.03680187,\n",
              "           0.12577951,  0.05200994],\n",
              "         [ 0.05216816,  0.07125093, -0.10854112, ...,  0.03715418,\n",
              "           0.12519115,  0.05167744]],\n",
              " \n",
              "        [[ 0.07306269,  0.08535964, -0.11764509, ...,  0.0717776 ,\n",
              "           0.10091959,  0.12580535],\n",
              "         [ 0.06150617,  0.04337137, -0.12898318, ...,  0.05268841,\n",
              "           0.10241353,  0.08088554],\n",
              "         [ 0.06143083,  0.02832611, -0.11550541, ...,  0.0390805 ,\n",
              "           0.11800689,  0.06581895],\n",
              "         ...,\n",
              "         [ 0.05201986,  0.0753033 , -0.10934083, ...,  0.0357906 ,\n",
              "           0.12195551,  0.04401145],\n",
              "         [ 0.05190253,  0.07516053, -0.10926931, ...,  0.03565246,\n",
              "           0.12177624,  0.04420912],\n",
              "         [ 0.05178403,  0.07509346, -0.10922699, ...,  0.0356693 ,\n",
              "           0.12172776,  0.04434417]],\n",
              " \n",
              "        [[ 0.08182983,  0.0897546 , -0.11996727, ...,  0.07159978,\n",
              "           0.10132486,  0.125003  ],\n",
              "         [ 0.06994963,  0.04615651, -0.13035363, ...,  0.05303719,\n",
              "           0.11019199,  0.0904945 ],\n",
              "         [ 0.06047156,  0.03148489, -0.11285411, ...,  0.0420592 ,\n",
              "           0.12307081,  0.06683465],\n",
              "         ...,\n",
              "         [ 0.0523467 ,  0.0716006 , -0.10818477, ...,  0.03698853,\n",
              "           0.12510268,  0.05256998],\n",
              "         [ 0.05191868,  0.07150029, -0.10762212, ...,  0.03744889,\n",
              "           0.12466727,  0.05199569],\n",
              "         [ 0.05166977,  0.07150793, -0.10704714, ...,  0.03793942,\n",
              "           0.12427592,  0.05149204]]], dtype=float32),\n",
              " array([[[ 0.08268864,  0.0896084 , -0.12055501, ...,  0.07145537,\n",
              "           0.10249516,  0.12491141],\n",
              "         [ 0.06801009,  0.04488804, -0.12925248, ...,  0.05311379,\n",
              "           0.11016087,  0.08958603],\n",
              "         [ 0.06003444,  0.03121123, -0.11149111, ...,  0.04212456,\n",
              "           0.12381293,  0.066465  ],\n",
              "         ...,\n",
              "         [ 0.05231944,  0.07067563, -0.11015736, ...,  0.03552641,\n",
              "           0.1266408 ,  0.0513733 ],\n",
              "         [ 0.05219718,  0.0704812 , -0.11015511, ...,  0.03571337,\n",
              "           0.12611221,  0.05131946],\n",
              "         [ 0.05215535,  0.07016012, -0.11005185, ...,  0.03586804,\n",
              "           0.12545586,  0.05104086]],\n",
              " \n",
              "        [[ 0.07058845,  0.08538083, -0.1169364 , ...,  0.07016842,\n",
              "           0.10468835,  0.12656318],\n",
              "         [ 0.06263614,  0.04561147, -0.13040674, ...,  0.05119948,\n",
              "           0.10165679,  0.07830936],\n",
              "         [ 0.06471206,  0.03030997, -0.11969639, ...,  0.0375765 ,\n",
              "           0.117753  ,  0.06221066],\n",
              "         ...,\n",
              "         [ 0.06066427,  0.08580551, -0.10898127, ...,  0.04364588,\n",
              "           0.12275478,  0.04270075],\n",
              "         [ 0.06066652,  0.08590461, -0.1088026 , ...,  0.04383294,\n",
              "           0.1226497 ,  0.04263385],\n",
              "         [ 0.06059234,  0.08578143, -0.10876054, ...,  0.04412516,\n",
              "           0.12252538,  0.04254567]]], dtype=float32),\n",
              " array([[[-0.16506526,  0.20539798,  0.09006439, ..., -0.01518673,\n",
              "          -0.06237338, -0.1120986 ],\n",
              "         [-0.04242339,  0.18857169,  0.07289365, ...,  0.16407612,\n",
              "          -0.13501185, -0.03998402],\n",
              "         [-0.22376104,  0.14630446, -0.03631448, ...,  0.01733238,\n",
              "          -0.11798351, -0.00712513],\n",
              "         ...,\n",
              "         [-0.0013925 ,  0.23903154,  0.02676418, ...,  0.1518349 ,\n",
              "          -0.13168164, -0.05198951],\n",
              "         [-0.16954885,  0.10771735,  0.00625686, ...,  0.17380673,\n",
              "          -0.1089369 , -0.03524779],\n",
              "         [-0.05463796,  0.22484198,  0.04632217, ...,  0.10015103,\n",
              "          -0.07226235, -0.06173892]],\n",
              " \n",
              "        [[-0.13023496,  0.24692836,  0.12751439, ...,  0.05892333,\n",
              "          -0.04483313, -0.110017  ],\n",
              "         [ 0.02381375,  0.20175755,  0.03325775, ...,  0.18479395,\n",
              "          -0.04947454, -0.07114042],\n",
              "         [-0.06691057,  0.2024353 ,  0.01167967, ...,  0.17032915,\n",
              "          -0.05524456, -0.07242762],\n",
              "         ...,\n",
              "         [-0.09349818,  0.3180068 , -0.00886151, ...,  0.05821716,\n",
              "          -0.14485012, -0.11133884],\n",
              "         [-0.01067051,  0.24662976,  0.03530306, ...,  0.1839861 ,\n",
              "          -0.12257318, -0.03193236],\n",
              "         [-0.18435255,  0.32155776,  0.10004552, ...,  0.18058363,\n",
              "          -0.13589731, -0.0821469 ]],\n",
              " \n",
              "        [[-0.1551105 ,  0.22366416,  0.01991571, ...,  0.17691323,\n",
              "          -0.03867662, -0.09314706],\n",
              "         [-0.00849995,  0.2493576 ,  0.03878835, ...,  0.11372554,\n",
              "          -0.14491329,  0.03167394],\n",
              "         [-0.1600903 ,  0.2598812 , -0.0090397 , ...,  0.12859279,\n",
              "          -0.04887685, -0.04801562],\n",
              "         ...,\n",
              "         [-0.13944341,  0.16754504,  0.09757032, ...,  0.20030591,\n",
              "          -0.03350966, -0.16403148],\n",
              "         [-0.18908754,  0.09480138,  0.1311637 , ...,  0.10438014,\n",
              "          -0.1346974 , -0.12908064],\n",
              "         [-0.05762665,  0.2124691 , -0.01423747, ...,  0.10169112,\n",
              "          -0.10190539, -0.15804726]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-0.16108897,  0.27523562,  0.01253062, ...,  0.0620516 ,\n",
              "          -0.0684005 ,  0.07604842],\n",
              "         [-0.02193987,  0.14786132,  0.02365585, ...,  0.20999548,\n",
              "          -0.15677616, -0.0096595 ],\n",
              "         [-0.09815997,  0.20818253,  0.07823659, ...,  0.20199512,\n",
              "          -0.03793336,  0.02366715],\n",
              "         ...,\n",
              "         [-0.12554944,  0.16963896, -0.02431893, ...,  0.11810724,\n",
              "          -0.16470607, -0.02912222],\n",
              "         [-0.1141832 ,  0.33226317, -0.03655076, ..., -0.00169495,\n",
              "          -0.10212121, -0.03014355],\n",
              "         [-0.14218752,  0.09065378, -0.00673495, ...,  0.15375163,\n",
              "          -0.03060561, -0.03152971]],\n",
              " \n",
              "        [[-0.06933299,  0.29965132,  0.04888276, ...,  0.08633128,\n",
              "          -0.09005368,  0.03173055],\n",
              "         [-0.09824765,  0.15487015, -0.05250108, ...,  0.02894789,\n",
              "          -0.11409768, -0.0483125 ],\n",
              "         [-0.14299345,  0.15234178,  0.11807069, ...,  0.17602718,\n",
              "          -0.03525663,  0.07583968],\n",
              "         ...,\n",
              "         [-0.10871083,  0.16983977,  0.05172712, ...,  0.16053727,\n",
              "          -0.06201909, -0.0395555 ],\n",
              "         [-0.11186669,  0.18972707,  0.09067345, ...,  0.13806237,\n",
              "          -0.0868312 , -0.10789086],\n",
              "         [-0.13546236,  0.16688386,  0.10515251, ...,  0.06403796,\n",
              "          -0.11714996,  0.03220667]],\n",
              " \n",
              "        [[ 0.05266681,  0.21490574,  0.07020059, ...,  0.06364991,\n",
              "          -0.0581899 , -0.09547883],\n",
              "         [-0.14602098,  0.17291853,  0.01084864, ...,  0.17176741,\n",
              "          -0.10035472, -0.06332954],\n",
              "         [-0.10626693,  0.22793338,  0.05879866, ...,  0.15403855,\n",
              "          -0.11216967, -0.1679845 ],\n",
              "         ...,\n",
              "         [-0.06730375,  0.17621058,  0.11020979, ...,  0.19400375,\n",
              "          -0.19977951, -0.01643385],\n",
              "         [-0.20252603,  0.1284414 ,  0.06674216, ...,  0.17163879,\n",
              "          -0.08844489, -0.12170526],\n",
              "         [ 0.0084456 ,  0.29494846,  0.05896871, ...,  0.07355595,\n",
              "          -0.07656398, -0.0080778 ]]], dtype=float32),\n",
              " array([[[-1.00552216e-02,  2.44766712e-01,  7.14123845e-02, ...,\n",
              "           9.54396576e-02, -9.13544968e-02, -8.00447464e-02],\n",
              "         [-1.93945244e-02,  2.62669086e-01,  9.96799618e-02, ...,\n",
              "           1.62010789e-01, -1.05934925e-01, -7.18212426e-02],\n",
              "         [-1.10436842e-01,  1.13598667e-01,  1.63139496e-02, ...,\n",
              "           3.31799090e-02, -1.41079918e-01, -2.63464078e-02],\n",
              "         ...,\n",
              "         [-4.63873334e-02,  2.36228496e-01,  1.24679236e-02, ...,\n",
              "           9.48345363e-02, -1.04941525e-01, -1.30600393e-01],\n",
              "         [-6.17261454e-02,  1.99792147e-01,  3.93899120e-02, ...,\n",
              "           1.01013027e-01, -4.90884334e-02, -1.82538211e-01],\n",
              "         [-1.77431062e-01,  2.56680399e-01,  3.51257510e-02, ...,\n",
              "           9.31093842e-03, -9.74476337e-02, -8.68018046e-02]],\n",
              " \n",
              "        [[-8.42577145e-02,  2.10660875e-01,  1.83530226e-02, ...,\n",
              "           1.57758996e-01, -4.26387042e-02, -1.49473995e-01],\n",
              "         [-3.06269228e-02,  1.67767629e-01,  5.31523116e-02, ...,\n",
              "           1.16008535e-01, -1.80179864e-01, -1.00894824e-01],\n",
              "         [-1.53197423e-01,  1.33808896e-01,  7.43233636e-02, ...,\n",
              "           1.31095961e-01, -4.11070734e-02,  3.95690836e-02],\n",
              "         ...,\n",
              "         [-3.39869857e-02,  2.10949540e-01,  3.77599262e-02, ...,\n",
              "           9.42763984e-02, -1.15239099e-01, -1.45578086e-01],\n",
              "         [ 6.00309819e-02,  1.79349601e-01, -3.00052743e-02, ...,\n",
              "           1.49356037e-01, -1.32494003e-01, -1.42751023e-01],\n",
              "         [-1.06861927e-01,  1.80129781e-01, -4.52007353e-03, ...,\n",
              "           2.06041843e-01, -9.70836803e-02, -1.90606847e-01]],\n",
              " \n",
              "        [[-1.39247403e-01,  2.46429026e-01,  5.14721572e-02, ...,\n",
              "           1.35997623e-01, -1.28317699e-01, -4.29522991e-02],\n",
              "         [-3.37525085e-02,  2.70216584e-01, -6.43392801e-02, ...,\n",
              "           1.55541554e-01, -1.48128226e-01, -1.11298703e-01],\n",
              "         [-8.22464079e-02,  7.70917535e-02,  1.82376796e-04, ...,\n",
              "           1.99139431e-01, -1.88347518e-01, -9.91910845e-02],\n",
              "         ...,\n",
              "         [-9.46259424e-02,  1.05758242e-01, -1.23919053e-02, ...,\n",
              "           2.11932525e-01, -6.20118417e-02, -2.55262107e-03],\n",
              "         [-2.04924494e-01,  2.37124473e-01,  1.73767097e-03, ...,\n",
              "           1.52299583e-01, -2.20575958e-01, -8.96909684e-02],\n",
              "         [-8.91295746e-02,  1.66091397e-01, -3.16449441e-02, ...,\n",
              "           1.02736026e-01, -1.52306646e-01, -2.72391923e-02]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[-6.84290081e-02,  9.73446071e-02,  5.28997146e-02, ...,\n",
              "           1.80161223e-01, -5.99373356e-02, -2.55147256e-02],\n",
              "         [-1.20136112e-01,  2.95713127e-01,  7.56732747e-02, ...,\n",
              "           8.20279717e-02, -3.28140408e-02, -8.70313644e-02],\n",
              "         [-1.30956799e-01,  2.30204090e-01, -2.05946416e-02, ...,\n",
              "           1.39709473e-01, -1.16356254e-01, -1.19701773e-01],\n",
              "         ...,\n",
              "         [-1.42757311e-01,  2.12830424e-01, -2.78534275e-02, ...,\n",
              "           1.42460316e-01, -1.39020398e-01, -7.68853575e-02],\n",
              "         [-1.78898692e-01,  2.65978366e-01,  1.11033514e-01, ...,\n",
              "           8.33697915e-02, -1.82362050e-01, -8.35666955e-02],\n",
              "         [-1.43631324e-02,  2.53323793e-01,  3.45522016e-02, ...,\n",
              "           1.47399902e-01, -1.25309780e-01, -1.27955563e-02]],\n",
              " \n",
              "        [[-5.81567287e-02,  2.62430698e-01,  4.91079278e-02, ...,\n",
              "          -1.34258494e-02, -2.82362178e-02, -1.39148265e-01],\n",
              "         [-1.22467250e-01,  2.89830089e-01,  1.61025487e-02, ...,\n",
              "           2.25195840e-01, -7.44714960e-02, -9.55333263e-02],\n",
              "         [ 3.06332856e-03,  3.27725053e-01, -6.65829331e-02, ...,\n",
              "           5.54547310e-02, -8.15373957e-02, -4.74035256e-02],\n",
              "         ...,\n",
              "         [-1.01734936e-01,  2.78893590e-01,  4.76836897e-02, ...,\n",
              "           1.16022348e-01, -1.23044074e-01, -3.31377797e-02],\n",
              "         [-3.74753810e-02,  2.86735654e-01,  7.61380419e-02, ...,\n",
              "           1.71115041e-01, -1.30790174e-01, -1.37274429e-01],\n",
              "         [ 4.37450558e-02,  2.53863275e-01, -9.70986485e-03, ...,\n",
              "           1.90116078e-01, -5.63038252e-02, -2.08551139e-02]],\n",
              " \n",
              "        [[-1.60765946e-01,  2.61925429e-01,  1.14860870e-01, ...,\n",
              "           8.87803733e-04, -1.26908258e-01, -4.95050102e-02],\n",
              "         [-1.62229419e-01,  2.66925871e-01,  2.42935084e-02, ...,\n",
              "           9.73536074e-02, -1.33184969e-01, -7.48549998e-02],\n",
              "         [-6.72388822e-02,  2.54152626e-01, -3.40330116e-02, ...,\n",
              "           1.04065754e-01, -6.52506948e-03, -1.83004022e-01],\n",
              "         ...,\n",
              "         [-6.33759648e-02,  2.30234504e-01,  1.63366228e-01, ...,\n",
              "           1.61964655e-01, -7.03815371e-02, -4.05168235e-02],\n",
              "         [-1.45485982e-01,  2.43004963e-01, -4.39126603e-02, ...,\n",
              "           9.18498561e-02, -1.34548232e-01, -6.07015193e-03],\n",
              "         [-1.41090333e-01,  2.69794226e-01,  2.50102766e-02, ...,\n",
              "           1.95029825e-02,  1.48273110e-02, -6.61521330e-02]]],\n",
              "       dtype=float32),\n",
              " array([[[-0.06306498,  0.2357633 ,  0.144539  , ...,  0.1357031 ,\n",
              "          -0.09911857,  0.09618473],\n",
              "         [-0.14687234,  0.30779004,  0.00588021, ...,  0.16924319,\n",
              "          -0.06753041, -0.07706532],\n",
              "         [-0.16453269,  0.29638508,  0.08602589, ...,  0.15735018,\n",
              "          -0.05467541,  0.03099373],\n",
              "         ...,\n",
              "         [-0.19145605,  0.24275292,  0.04047006, ...,  0.21319613,\n",
              "          -0.02150712, -0.10966603],\n",
              "         [-0.04635255,  0.27446842,  0.02762482, ...,  0.00848101,\n",
              "          -0.15750366, -0.14887078],\n",
              "         [ 0.01567935,  0.23598482,  0.06742214, ...,  0.12729636,\n",
              "          -0.02759198, -0.06032167]],\n",
              " \n",
              "        [[-0.10864505,  0.27250472,  0.14442421, ...,  0.14416002,\n",
              "          -0.02521717,  0.04579343],\n",
              "         [-0.12852946,  0.177228  ,  0.05093628, ...,  0.04232198,\n",
              "          -0.10973053, -0.0735005 ],\n",
              "         [-0.07448094,  0.31467092,  0.09003263, ...,  0.08882602,\n",
              "          -0.11992939, -0.09374761],\n",
              "         ...,\n",
              "         [ 0.02111204,  0.271545  , -0.0316524 , ...,  0.06560164,\n",
              "          -0.21040925, -0.01104302],\n",
              "         [-0.13335523,  0.29249942,  0.08202957, ...,  0.16549507,\n",
              "          -0.07120378, -0.00369573],\n",
              "         [-0.17500308,  0.21583441,  0.02990662, ...,  0.08052534,\n",
              "          -0.01698747,  0.00153136]]], dtype=float32),\n",
              " array([[[ 0.07350589,  0.08540292, -0.11814226, ...,  0.07254045,\n",
              "           0.10022938,  0.12509671],\n",
              "         [ 0.06197687,  0.0440864 , -0.12928753, ...,  0.05345668,\n",
              "           0.10260555,  0.08218579],\n",
              "         [ 0.0617439 ,  0.02928242, -0.114475  , ...,  0.03918806,\n",
              "           0.11854063,  0.06712128],\n",
              "         ...,\n",
              "         [ 0.04968875,  0.07407567, -0.10933887, ...,  0.03510791,\n",
              "           0.11972811,  0.04435126],\n",
              "         [ 0.0494776 ,  0.07397258, -0.10940602, ...,  0.03513123,\n",
              "           0.11959815,  0.04437465],\n",
              "         [ 0.04923359,  0.07373656, -0.10966905, ...,  0.03528228,\n",
              "           0.11963189,  0.04407893]],\n",
              " \n",
              "        [[ 0.08110552,  0.08818956, -0.12014478, ...,  0.07110269,\n",
              "           0.10148961,  0.12481384],\n",
              "         [ 0.06622841,  0.04439364, -0.1290985 , ...,  0.05297282,\n",
              "           0.10818507,  0.08813566],\n",
              "         [ 0.06152562,  0.03142786, -0.11106625, ...,  0.04060686,\n",
              "           0.12266526,  0.06806123],\n",
              "         ...,\n",
              "         [ 0.0516622 ,  0.07252083, -0.11078314, ...,  0.03243639,\n",
              "           0.12366618,  0.0512844 ],\n",
              "         [ 0.05148285,  0.07257087, -0.11048897, ...,  0.03257896,\n",
              "           0.12322013,  0.05132347],\n",
              "         [ 0.05137869,  0.0726167 , -0.11019023, ...,  0.03288185,\n",
              "           0.12302458,  0.05142491]],\n",
              " \n",
              "        [[ 0.07295825,  0.0851263 , -0.11750502, ...,  0.07229646,\n",
              "           0.10103384,  0.12507787],\n",
              "         [ 0.06177049,  0.04417582, -0.1292926 , ...,  0.05297437,\n",
              "           0.10244097,  0.08185343],\n",
              "         [ 0.06188989,  0.02947162, -0.11486745, ...,  0.03868882,\n",
              "           0.11859605,  0.06668917],\n",
              "         ...,\n",
              "         [ 0.04946782,  0.07380189, -0.11048818, ...,  0.03539971,\n",
              "           0.1196399 ,  0.04317548],\n",
              "         [ 0.04916313,  0.0736221 , -0.110658  , ...,  0.03569021,\n",
              "           0.11962245,  0.04301934],\n",
              "         [ 0.04895076,  0.07355638, -0.11086187, ...,  0.0360806 ,\n",
              "           0.11970088,  0.04281446]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.07233965,  0.08486711, -0.11737864, ...,  0.07080016,\n",
              "           0.10197553,  0.12578629],\n",
              "         [ 0.06061181,  0.04308593, -0.12918828, ...,  0.05143397,\n",
              "           0.10102016,  0.08004651],\n",
              "         [ 0.06150599,  0.02713346, -0.11698038, ...,  0.03833746,\n",
              "           0.11697918,  0.06505089],\n",
              "         ...,\n",
              "         [ 0.05278318,  0.07565871, -0.10961752, ...,  0.03766758,\n",
              "           0.12235188,  0.04297913],\n",
              "         [ 0.05259652,  0.07562643, -0.10967648, ...,  0.03802252,\n",
              "           0.12251695,  0.04270146],\n",
              "         [ 0.05241788,  0.07555313, -0.10957758, ...,  0.03828842,\n",
              "           0.12247432,  0.0426279 ]],\n",
              " \n",
              "        [[ 0.06990384,  0.08634295, -0.11764519, ...,  0.07082616,\n",
              "           0.1056544 ,  0.12758787],\n",
              "         [ 0.06418891,  0.04725418, -0.13023831, ...,  0.05140411,\n",
              "           0.10283002,  0.07573909],\n",
              "         [ 0.06467666,  0.03327619, -0.12058782, ...,  0.03840179,\n",
              "           0.11833635,  0.05751907],\n",
              "         ...,\n",
              "         [ 0.06221844,  0.09086054, -0.10306732, ...,  0.04717466,\n",
              "           0.1198059 ,  0.0396966 ],\n",
              "         [ 0.06269441,  0.09110143, -0.10304302, ...,  0.04722216,\n",
              "           0.11983277,  0.03997777],\n",
              "         [ 0.06289172,  0.09130751, -0.10281429, ...,  0.04725643,\n",
              "           0.11980474,  0.03989404]],\n",
              " \n",
              "        [[ 0.08483134,  0.09061311, -0.1188971 , ...,  0.06909028,\n",
              "           0.10140397,  0.12531014],\n",
              "         [ 0.07370955,  0.04591142, -0.13369885, ...,  0.04970519,\n",
              "           0.10968024,  0.09530636],\n",
              "         [ 0.0604308 ,  0.03257699, -0.12132096, ...,  0.04244225,\n",
              "           0.11727296,  0.07656477],\n",
              "         ...,\n",
              "         [ 0.06285052,  0.08728807, -0.13838129, ...,  0.06245077,\n",
              "           0.09377725,  0.03822213],\n",
              "         [ 0.07003292,  0.08336292, -0.14801049, ...,  0.06256022,\n",
              "           0.0935294 ,  0.03964213],\n",
              "         [ 0.07235759,  0.07706353, -0.15249136, ...,  0.05959873,\n",
              "           0.0938057 ,  0.04304297]]], dtype=float32),\n",
              " array([[[ 0.0727218 ,  0.08480687, -0.11723716, ...,  0.07212423,\n",
              "           0.10114763,  0.12508804],\n",
              "         [ 0.06173581,  0.04399473, -0.12944925, ...,  0.05269828,\n",
              "           0.10220062,  0.08159378],\n",
              "         [ 0.0616764 ,  0.02895632, -0.11532217, ...,  0.0387369 ,\n",
              "           0.11829841,  0.06645567],\n",
              "         ...,\n",
              "         [ 0.04933172,  0.07358862, -0.11040686, ...,  0.03568832,\n",
              "           0.12000135,  0.04263116],\n",
              "         [ 0.04906313,  0.07328737, -0.11075093, ...,  0.03586263,\n",
              "           0.12000898,  0.04241762],\n",
              "         [ 0.04889193,  0.072974  , -0.11116786, ...,  0.03593157,\n",
              "           0.1200259 ,  0.04226675]],\n",
              " \n",
              "        [[ 0.08189404,  0.08942689, -0.12035061, ...,  0.07158051,\n",
              "           0.10237537,  0.1252409 ],\n",
              "         [ 0.06787037,  0.04474747, -0.1291291 , ...,  0.05305888,\n",
              "           0.10993835,  0.08959989],\n",
              "         [ 0.06055618,  0.03079783, -0.11110297, ...,  0.04178498,\n",
              "           0.12401915,  0.06759123],\n",
              "         ...,\n",
              "         [ 0.05243253,  0.07053378, -0.11069429, ...,  0.03482747,\n",
              "           0.12670857,  0.05174694],\n",
              "         [ 0.0524004 ,  0.07041875, -0.11060771, ...,  0.03506003,\n",
              "           0.12655371,  0.05171335],\n",
              "         [ 0.05204282,  0.07024039, -0.11026684, ...,  0.03532423,\n",
              "           0.12610714,  0.05154842]],\n",
              " \n",
              "        [[ 0.06603621,  0.08476046, -0.11649495, ...,  0.07170529,\n",
              "           0.11091743,  0.13073516],\n",
              "         [ 0.06995063,  0.05432592, -0.13010935, ...,  0.05052177,\n",
              "           0.10810201,  0.076179  ],\n",
              "         [ 0.07030486,  0.04105988, -0.12371233, ...,  0.04241265,\n",
              "           0.12175079,  0.05286368],\n",
              "         ...,\n",
              "         [ 0.07491899,  0.09603543, -0.10235459, ...,  0.05234284,\n",
              "           0.12692755,  0.04209303],\n",
              "         [ 0.07554228,  0.09624199, -0.10205707, ...,  0.05235577,\n",
              "           0.12738957,  0.04185977],\n",
              "         [ 0.07585385,  0.09631054, -0.10164355, ...,  0.05250722,\n",
              "           0.12762687,  0.04160228]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 0.08181033,  0.08973382, -0.1201372 , ...,  0.07145228,\n",
              "           0.10174948,  0.12506397],\n",
              "         [ 0.0694163 ,  0.0457495 , -0.12980883, ...,  0.05295496,\n",
              "           0.11028538,  0.09005424],\n",
              "         [ 0.06071762,  0.03142795, -0.11202428, ...,  0.04183044,\n",
              "           0.12364637,  0.06674632],\n",
              "         ...,\n",
              "         [ 0.05248371,  0.07143859, -0.10937146, ...,  0.03657286,\n",
              "           0.12668194,  0.05223943],\n",
              "         [ 0.05224296,  0.07131155, -0.10898827, ...,  0.03680187,\n",
              "           0.12577951,  0.05200994],\n",
              "         [ 0.05216816,  0.07125093, -0.10854112, ...,  0.03715418,\n",
              "           0.12519115,  0.05167744]],\n",
              " \n",
              "        [[ 0.07306269,  0.08535964, -0.11764509, ...,  0.0717776 ,\n",
              "           0.10091959,  0.12580535],\n",
              "         [ 0.06150617,  0.04337137, -0.12898318, ...,  0.05268841,\n",
              "           0.10241353,  0.08088554],\n",
              "         [ 0.06143083,  0.02832611, -0.11550541, ...,  0.0390805 ,\n",
              "           0.11800689,  0.06581895],\n",
              "         ...,\n",
              "         [ 0.05201986,  0.0753033 , -0.10934083, ...,  0.0357906 ,\n",
              "           0.12195551,  0.04401145],\n",
              "         [ 0.05190253,  0.07516053, -0.10926931, ...,  0.03565246,\n",
              "           0.12177624,  0.04420912],\n",
              "         [ 0.05178403,  0.07509346, -0.10922699, ...,  0.0356693 ,\n",
              "           0.12172776,  0.04434417]],\n",
              " \n",
              "        [[ 0.08182983,  0.0897546 , -0.11996727, ...,  0.07159978,\n",
              "           0.10132486,  0.125003  ],\n",
              "         [ 0.06994963,  0.04615651, -0.13035363, ...,  0.05303719,\n",
              "           0.11019199,  0.0904945 ],\n",
              "         [ 0.06047156,  0.03148489, -0.11285411, ...,  0.0420592 ,\n",
              "           0.12307081,  0.06683465],\n",
              "         ...,\n",
              "         [ 0.0523467 ,  0.0716006 , -0.10818477, ...,  0.03698853,\n",
              "           0.12510268,  0.05256998],\n",
              "         [ 0.05191868,  0.07150029, -0.10762212, ...,  0.03744889,\n",
              "           0.12466727,  0.05199569],\n",
              "         [ 0.05166977,  0.07150793, -0.10704714, ...,  0.03793942,\n",
              "           0.12427592,  0.05149204]]], dtype=float32),\n",
              " array([[[ 0.08268864,  0.0896084 , -0.12055501, ...,  0.07145537,\n",
              "           0.10249516,  0.12491141],\n",
              "         [ 0.06801009,  0.04488804, -0.12925248, ...,  0.05311379,\n",
              "           0.11016087,  0.08958603],\n",
              "         [ 0.06003444,  0.03121123, -0.11149111, ...,  0.04212456,\n",
              "           0.12381293,  0.066465  ],\n",
              "         ...,\n",
              "         [ 0.05231944,  0.07067563, -0.11015736, ...,  0.03552641,\n",
              "           0.1266408 ,  0.0513733 ],\n",
              "         [ 0.05219718,  0.0704812 , -0.11015511, ...,  0.03571337,\n",
              "           0.12611221,  0.05131946],\n",
              "         [ 0.05215535,  0.07016012, -0.11005185, ...,  0.03586804,\n",
              "           0.12545586,  0.05104086]],\n",
              " \n",
              "        [[ 0.07058845,  0.08538083, -0.1169364 , ...,  0.07016842,\n",
              "           0.10468835,  0.12656318],\n",
              "         [ 0.06263614,  0.04561147, -0.13040674, ...,  0.05119948,\n",
              "           0.10165679,  0.07830936],\n",
              "         [ 0.06471206,  0.03030997, -0.11969639, ...,  0.0375765 ,\n",
              "           0.117753  ,  0.06221066],\n",
              "         ...,\n",
              "         [ 0.06066427,  0.08580551, -0.10898127, ...,  0.04364588,\n",
              "           0.12275478,  0.04270075],\n",
              "         [ 0.06066652,  0.08590461, -0.1088026 , ...,  0.04383294,\n",
              "           0.1226497 ,  0.04263385],\n",
              "         [ 0.06059234,  0.08578143, -0.10876054, ...,  0.04412516,\n",
              "           0.12252538,  0.04254567]]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch):\n",
        "    \"\"\"Adjusts the learning rate of the optimizer.\"\"\"\n",
        "    lr = initial_lr * (0.1 ** (epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, initial_lr=0.001, lr_decay_epoch=3, device='cuda'):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    scheduler = StepLR(optimizer, step_size=lr_decay_epoch, gamma=0.1)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch)\n",
        "        for batch_idx, (real_features, deepfake_features) in enumerate(train_loader):\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(real_features)\n",
        "            loss = criterion(output, deepfake_features)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
        "\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (real_features, deepfake_features) in enumerate(val_loader):\n",
        "                real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "                output = model(real_features)\n",
        "                val_loss += criterion(output, deepfake_features).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "def evaluate_model(model, loader, device='cuda'):\n",
        "    model.eval()\n",
        "    criterion = nn.MSELoss()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for real_features, deepfake_features in loader:\n",
        "            real_features, deepfake_features = real_features.to(device), deepfake_features.to(device)\n",
        "            output = model(real_features)\n",
        "            total_loss += criterion(output, deepfake_features).item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "BllmtizSJkaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, 1000)\n",
        "evaluate_model(model, val_loader)"
      ],
      "metadata": {
        "id": "4P7JfXv4JpxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emotion Recognition"
      ],
      "metadata": {
        "id": "DyYz4-9352xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b7pskfUbEyvu",
        "outputId": "147534f8-3cce-43af-853b-c38a4f9f0af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/session1.zip\n",
        "!unzip /content/drive/MyDrive/session1_video.zip"
      ],
      "metadata": {
        "id": "_Ua795v4wDUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94470cb-4ea0-4c09-9a89-43fbe522eead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/session1.zip\n",
            "   creating: session1/\n",
            "   creating: session1/S01A/\n",
            "   creating: session1/S01A/P/\n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.wav  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.wav  \n",
            "   creating: session1/S01A/R/\n",
            "  inflating: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.wav  \n",
            "   creating: session1/S01A/S/\n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.wav  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.wav  \n",
            "   creating: session1/S01A/T/\n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.wav  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.wav  \n",
            "   creating: session1/S01H/\n",
            "   creating: session1/S01H/P/\n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav  \n",
            "   creating: session1/S01H/R/\n",
            "  inflating: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav  \n",
            "   creating: session1/S01H/S/\n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav  \n",
            "   creating: session1/S01H/T/\n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav  \n",
            "   creating: session1/S01N/\n",
            "   creating: session1/S01N/P/\n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.wav  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.wav  \n",
            "   creating: session1/S01N/R/\n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.wav  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.wav  \n",
            "   creating: session1/S01N/S/\n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.wav  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.wav  \n",
            "   creating: session1/S01N/T/\n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.wav  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.wav  \n",
            "   creating: session1/S01S/\n",
            "   creating: session1/S01S/P/\n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav  \n",
            "   creating: session1/S01S/R/\n",
            "  inflating: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav  \n",
            "   creating: session1/S01S/S/\n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav  \n",
            "   creating: session1/S01S/T/\n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav  \n",
            "   creating: session1/S02A/\n",
            "   creating: session1/S02A/P/\n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.wav  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.wav  \n",
            "   creating: session1/S02A/R/\n",
            "  inflating: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.wav  \n",
            "   creating: session1/S02A/S/\n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.wav  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.wav  \n",
            "   creating: session1/S02A/T/\n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.wav  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.wav  \n",
            "   creating: session1/S02H/\n",
            "   creating: session1/S02H/P/\n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.wav  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.wav  \n",
            "   creating: session1/S02H/R/\n",
            "  inflating: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.wav  \n",
            "   creating: session1/S02H/S/\n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.wav  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.wav  \n",
            "   creating: session1/S02H/T/\n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.wav  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.wav  \n",
            "   creating: session1/S02N/\n",
            "   creating: session1/S02N/P/\n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.wav  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.wav  \n",
            "   creating: session1/S02N/R/\n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.wav  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.wav  \n",
            "   creating: session1/S02N/S/\n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.wav  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.wav  \n",
            "   creating: session1/S02N/T/\n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.wav  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.wav  \n",
            "   creating: session1/S02S/\n",
            "   creating: session1/S02S/P/\n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav  \n",
            "   creating: session1/S02S/R/\n",
            "  inflating: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav  \n",
            "   creating: session1/S02S/S/\n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav  \n",
            "   creating: session1/S02S/T/\n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav  \n",
            "   creating: session1/S03A/\n",
            "   creating: session1/S03A/P/\n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav  \n",
            "   creating: session1/S03A/R/\n",
            "  inflating: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav  \n",
            "   creating: session1/S03A/S/\n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav  \n",
            "   creating: session1/S03A/T/\n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav  \n",
            "   creating: session1/S03H/\n",
            "   creating: session1/S03H/P/\n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.wav  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.wav  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.wav  \n",
            "   creating: session1/S03H/R/\n",
            "  inflating: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav  \n",
            "   creating: session1/S03H/S/\n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav  \n",
            "   creating: session1/S03H/T/\n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav  \n",
            "   creating: session1/S03N/\n",
            "   creating: session1/S03N/P/\n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.wav  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.wav  \n",
            "   creating: session1/S03N/R/\n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.wav  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.wav  \n",
            "   creating: session1/S03N/S/\n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.wav  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.wav  \n",
            "   creating: session1/S03N/T/\n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.wav  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.wav  \n",
            "   creating: session1/S03S/\n",
            "   creating: session1/S03S/P/\n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.wav  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.wav  \n",
            "   creating: session1/S03S/R/\n",
            "  inflating: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.wav  \n",
            "   creating: session1/S03S/S/\n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.wav  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.wav  \n",
            "   creating: session1/S03S/T/\n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.wav  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.wav  \n",
            "   creating: session1/S04A/\n",
            "   creating: session1/S04A/P/\n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.wav  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.wav  \n",
            "   creating: session1/S04A/R/\n",
            "  inflating: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.wav  \n",
            "   creating: session1/S04A/S/\n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.wav  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.wav  \n",
            "   creating: session1/S04A/T/\n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.wav  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.wav  \n",
            "   creating: session1/S04H/\n",
            "   creating: session1/S04H/P/\n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav  \n",
            "   creating: session1/S04H/R/\n",
            "  inflating: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav  \n",
            "   creating: session1/S04H/S/\n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav  \n",
            "   creating: session1/S04H/T/\n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav  \n",
            "   creating: session1/S04N/\n",
            "   creating: session1/S04N/P/\n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.wav  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.wav  \n",
            "   creating: session1/S04N/R/\n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.wav  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.wav  \n",
            "   creating: session1/S04N/S/\n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.wav  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.wav  \n",
            "   creating: session1/S04N/T/\n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.wav  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.wav  \n",
            "   creating: session1/S04S/\n",
            "   creating: session1/S04S/P/\n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav  \n",
            "   creating: session1/S04S/R/\n",
            "  inflating: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav  \n",
            "   creating: session1/S04S/S/\n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav  \n",
            "   creating: session1/S04S/T/\n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav  \n",
            "   creating: session1/S05A/\n",
            "   creating: session1/S05A/P/\n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.wav  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.wav  \n",
            "   creating: session1/S05A/R/\n",
            "  inflating: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.wav  \n",
            "   creating: session1/S05A/S/\n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.wav  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.wav  \n",
            "   creating: session1/S05A/T/\n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.wav  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.wav  \n",
            "   creating: session1/S05H/\n",
            "   creating: session1/S05H/P/\n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.wav  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.wav  \n",
            "   creating: session1/S05H/R/\n",
            "  inflating: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.wav  \n",
            "   creating: session1/S05H/S/\n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.wav  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.wav  \n",
            "   creating: session1/S05H/T/\n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.wav  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.wav  \n",
            "   creating: session1/S05N/\n",
            "   creating: session1/S05N/P/\n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav  \n",
            "   creating: session1/S05N/R/\n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav  \n",
            "   creating: session1/S05N/S/\n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav  \n",
            "   creating: session1/S05N/T/\n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav  \n",
            "   creating: session1/S05S/\n",
            "   creating: session1/S05S/P/\n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.wav  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.wav  \n",
            "   creating: session1/S05S/R/\n",
            "  inflating: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.wav  \n",
            "   creating: session1/S05S/S/\n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.wav  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.wav  \n",
            "   creating: session1/S05S/T/\n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.wav  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.wav  \n",
            "   creating: session1/S06A/\n",
            "   creating: session1/S06A/P/\n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.wav  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.wav  \n",
            "   creating: session1/S06A/R/\n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.wav  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.wav  \n",
            "   creating: session1/S06A/S/\n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.wav  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.wav  \n",
            "   creating: session1/S06A/T/\n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.wav  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.wav  \n",
            "   creating: session1/S06H/\n",
            "   creating: session1/S06H/P/\n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.wav  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.wav  \n",
            "   creating: session1/S06H/R/\n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.wav  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.wav  \n",
            "   creating: session1/S06H/S/\n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.wav  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.wav  \n",
            "   creating: session1/S06H/T/\n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.wav  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.wav  \n",
            "   creating: session1/S06N/\n",
            "   creating: session1/S06N/P/\n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.wav  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.wav  \n",
            "   creating: session1/S06N/R/\n",
            "  inflating: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.wav  \n",
            "   creating: session1/S06N/S/\n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.wav  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.wav  \n",
            "   creating: session1/S06N/T/\n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.wav  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.wav  \n",
            "   creating: session1/S06S/\n",
            "   creating: session1/S06S/P/\n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav  \n",
            "   creating: session1/S06S/R/\n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav  \n",
            "   creating: session1/S06S/S/\n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav  \n",
            "   creating: session1/S06S/T/\n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav  \n",
            "   creating: session1/S07A/\n",
            "   creating: session1/S07A/P/\n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav  \n",
            "   creating: session1/S07A/R/\n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav  \n",
            "   creating: session1/S07A/S/\n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav  \n",
            "   creating: session1/S07A/T/\n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav  \n",
            "   creating: session1/S07H/\n",
            "   creating: session1/S07H/P/\n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav  \n",
            "   creating: session1/S07H/R/\n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav  \n",
            "   creating: session1/S07H/S/\n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav  \n",
            "   creating: session1/S07H/T/\n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav  \n",
            "   creating: session1/S07N/\n",
            "   creating: session1/S07N/P/\n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.wav  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.wav  \n",
            "   creating: session1/S07N/R/\n",
            "  inflating: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.wav  \n",
            "   creating: session1/S07N/S/\n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.wav  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.wav  \n",
            "   creating: session1/S07N/T/\n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.wav  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.wav  \n",
            "   creating: session1/S07S/\n",
            "   creating: session1/S07S/P/\n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav  \n",
            "   creating: session1/S07S/R/\n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav  \n",
            "   creating: session1/S07S/S/\n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav  \n",
            "   creating: session1/S07S/T/\n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav  \n",
            "   creating: session1/S08A/\n",
            "   creating: session1/S08A/P/\n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav  \n",
            "   creating: session1/S08A/R/\n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav  \n",
            "   creating: session1/S08A/S/\n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav  \n",
            "   creating: session1/S08A/T/\n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav  \n",
            "   creating: session1/S08H/\n",
            "   creating: session1/S08H/P/\n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav  \n",
            "   creating: session1/S08H/R/\n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav  \n",
            "   creating: session1/S08H/S/\n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav  \n",
            "   creating: session1/S08H/T/\n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav  \n",
            "   creating: session1/S08N/\n",
            "   creating: session1/S08N/P/\n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.wav  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.wav  \n",
            "   creating: session1/S08N/R/\n",
            "  inflating: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.wav  \n",
            "   creating: session1/S08N/S/\n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.wav  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.wav  \n",
            "   creating: session1/S08N/T/\n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.wav  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.wav  \n",
            "   creating: session1/S08S/\n",
            "   creating: session1/S08S/P/\n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav  \n",
            "   creating: session1/S08S/R/\n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav  \n",
            "   creating: session1/S08S/S/\n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav  \n",
            "   creating: session1/S08S/T/\n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav  \n",
            "   creating: session1/S09A/\n",
            "   creating: session1/S09A/P/\n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.wav  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.wav  \n",
            "   creating: session1/S09A/R/\n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.wav  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.wav  \n",
            "   creating: session1/S09A/S/\n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.wav  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.wav  \n",
            "   creating: session1/S09A/T/\n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.wav  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.wav  \n",
            "   creating: session1/S09H/\n",
            "   creating: session1/S09H/P/\n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav  \n",
            "   creating: session1/S09H/R/\n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav  \n",
            "   creating: session1/S09H/S/\n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav  \n",
            "   creating: session1/S09H/T/\n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav  \n",
            "   creating: session1/S09N/\n",
            "   creating: session1/S09N/P/\n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav  \n",
            "   creating: session1/S09N/R/\n",
            "  inflating: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav  \n",
            "   creating: session1/S09N/S/\n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav  \n",
            "   creating: session1/S09N/T/\n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav  \n",
            "   creating: session1/S09S/\n",
            "   creating: session1/S09S/P/\n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.wav  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.wav  \n",
            "   creating: session1/S09S/R/\n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.wav  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.wav  \n",
            "   creating: session1/S09S/S/\n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.wav  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.wav  \n",
            "   creating: session1/S09S/T/\n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.wav  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.wav  \n",
            "   creating: session1/S10A/\n",
            "   creating: session1/S10A/P/\n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.wav  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.wav  \n",
            "   creating: session1/S10A/R/\n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.wav  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.wav  \n",
            "   creating: session1/S10A/S/\n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.wav  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.wav  \n",
            "   creating: session1/S10A/T/\n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.wav  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.wav  \n",
            "   creating: session1/S10H/\n",
            "   creating: session1/S10H/P/\n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav  \n",
            "   creating: session1/S10H/R/\n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav  \n",
            "   creating: session1/S10H/S/\n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav  \n",
            "   creating: session1/S10H/T/\n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav  \n",
            "   creating: session1/S10N/\n",
            "   creating: session1/S10N/P/\n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav  \n",
            "   creating: session1/S10N/R/\n",
            "  inflating: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav  \n",
            "   creating: session1/S10N/S/\n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav  \n",
            "   creating: session1/S10N/T/\n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav  \n",
            "   creating: session1/S10S/\n",
            "   creating: session1/S10S/P/\n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.wav  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.wav  \n",
            "   creating: session1/S10S/R/\n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.wav  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.wav  \n",
            "   creating: session1/S10S/S/\n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.wav  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.wav  \n",
            "   creating: session1/S10S/T/\n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.wav  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.wav  \n",
            "   creating: session1/S11A/\n",
            "   creating: session1/S11A/R/\n",
            "  inflating: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.wav  \n",
            "   creating: session1/S11H/\n",
            "   creating: session1/S11H/R/\n",
            "  inflating: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav  \n",
            "   creating: session1/S11N/\n",
            "   creating: session1/S11N/R/\n",
            "  inflating: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.wav  \n",
            "   creating: session1/S11S/\n",
            "   creating: session1/S11S/R/\n",
            "  inflating: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav  \n",
            "   creating: session1/S12A/\n",
            "   creating: session1/S12A/R/\n",
            "  inflating: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav  \n",
            "   creating: session1/S12H/\n",
            "   creating: session1/S12H/R/\n",
            "  inflating: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav  \n",
            "   creating: session1/S12N/\n",
            "   creating: session1/S12N/R/\n",
            "  inflating: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.wav  \n",
            "   creating: session1/S12S/\n",
            "   creating: session1/S12S/R/\n",
            "  inflating: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.wav  \n",
            "   creating: session1/S13A/\n",
            "   creating: session1/S13A/R/\n",
            "  inflating: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.wav  \n",
            "   creating: session1/S13H/\n",
            "   creating: session1/S13H/R/\n",
            "  inflating: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav  \n",
            "   creating: session1/S13N/\n",
            "   creating: session1/S13N/R/\n",
            "  inflating: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav  \n",
            "   creating: session1/S13S/\n",
            "   creating: session1/S13S/R/\n",
            "  inflating: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav  \n",
            "   creating: session1/S14A/\n",
            "   creating: session1/S14A/R/\n",
            "  inflating: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.wav  \n",
            "   creating: session1/S14H/\n",
            "   creating: session1/S14H/R/\n",
            "  inflating: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav  \n",
            "   creating: session1/S14N/\n",
            "   creating: session1/S14N/R/\n",
            "  inflating: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav  \n",
            "   creating: session1/S14S/\n",
            "   creating: session1/S14S/R/\n",
            "  inflating: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav  \n",
            "   creating: session1/S15A/\n",
            "   creating: session1/S15A/R/\n",
            "  inflating: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav  \n",
            "   creating: session1/S15H/\n",
            "   creating: session1/S15H/R/\n",
            "  inflating: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.wav  \n",
            "   creating: session1/S15N/\n",
            "   creating: session1/S15N/R/\n",
            "  inflating: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.wav  \n",
            "   creating: session1/S15S/\n",
            "   creating: session1/S15S/R/\n",
            "  inflating: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav  \n",
            "   creating: session1/S16A/\n",
            "   creating: session1/S16A/R/\n",
            "  inflating: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.wav  \n",
            "   creating: session1/S16H/\n",
            "   creating: session1/S16H/R/\n",
            "  inflating: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav  \n",
            "   creating: session1/S16N/\n",
            "   creating: session1/S16N/R/\n",
            "  inflating: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav  \n",
            "   creating: session1/S16S/\n",
            "   creating: session1/S16S/R/\n",
            "  inflating: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav  \n",
            "   creating: session1/S17A/\n",
            "   creating: session1/S17A/R/\n",
            "  inflating: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.wav  \n",
            "   creating: session1/S17H/\n",
            "   creating: session1/S17H/R/\n",
            "  inflating: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav  \n",
            "   creating: session1/S17N/\n",
            "   creating: session1/S17N/R/\n",
            "  inflating: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav  \n",
            "   creating: session1/S17S/\n",
            "   creating: session1/S17S/R/\n",
            "  inflating: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav  \n",
            "   creating: session1/S18A/\n",
            "   creating: session1/S18A/R/\n",
            "  inflating: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.wav  \n",
            "   creating: session1/S18H/\n",
            "   creating: session1/S18H/R/\n",
            "  inflating: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.wav  \n",
            "   creating: session1/S18N/\n",
            "   creating: session1/S18N/R/\n",
            "  inflating: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.wav  \n",
            "   creating: session1/S18S/\n",
            "   creating: session1/S18S/R/\n",
            "  inflating: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav  \n",
            "   creating: session1/S19A/\n",
            "   creating: session1/S19A/R/\n",
            "  inflating: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav  \n",
            "   creating: session1/S19H/\n",
            "   creating: session1/S19H/R/\n",
            "  inflating: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav  \n",
            "   creating: session1/S19N/\n",
            "   creating: session1/S19N/R/\n",
            "  inflating: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.wav  \n",
            "   creating: session1/S19S/\n",
            "   creating: session1/S19S/R/\n",
            "  inflating: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav  \n",
            "   creating: session1/S20A/\n",
            "   creating: session1/S20A/R/\n",
            "  inflating: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav  \n",
            "   creating: session1/S20H/\n",
            "   creating: session1/S20H/R/\n",
            "  inflating: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.wav  \n",
            "   creating: session1/S20N/\n",
            "   creating: session1/S20N/R/\n",
            "  inflating: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav  \n",
            "   creating: session1/S20S/\n",
            "   creating: session1/S20S/R/\n",
            "  inflating: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav  \n",
            "Archive:  /content/drive/MyDrive/session1_video.zip\n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-FM02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-F01-P-MF01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-FM02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF01.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF02.avi  \n",
            "  inflating: session1/S01A/P/MSP-IMPROV-S01A-M01-P-MF03.avi  \n",
            "  inflating: session1/S01A/R/MSP-IMPROV-S01A-M01-R-MM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-FM06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-F01-S-MF07.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM06.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-FM07.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF01.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF02.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF03.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF04.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF05.avi  \n",
            "  inflating: session1/S01A/S/MSP-IMPROV-S01A-M01-S-MF06.avi  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-F01-T-FM01.avi  \n",
            "  inflating: session1/S01A/T/MSP-IMPROV-S01A-M01-T-MF01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.avi  \n",
            "  inflating: session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.avi  \n",
            "  inflating: session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.avi  \n",
            "  inflating: session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.avi  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.avi  \n",
            "  inflating: session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM02.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-F01-P-FM03.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM01.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM02.avi  \n",
            "  inflating: session1/S01N/P/MSP-IMPROV-S01N-M01-P-FM03.avi  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM01.avi  \n",
            "  inflating: session1/S01N/R/MSP-IMPROV-S01N-M01-R-MM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-FM04.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-F01-S-MF03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM02.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM03.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM04.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM05.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-FM06.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF01.avi  \n",
            "  inflating: session1/S01N/S/MSP-IMPROV-S01N-M01-S-MF02.avi  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-F01-T-FM01.avi  \n",
            "  inflating: session1/S01N/T/MSP-IMPROV-S01N-M01-T-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.avi  \n",
            "  inflating: session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.avi  \n",
            "  inflating: session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.avi  \n",
            "  inflating: session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.avi  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.avi  \n",
            "  inflating: session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM03.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM04.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM05.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-FM06.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF03.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-F01-P-MF04.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-FM02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF01.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF02.avi  \n",
            "  inflating: session1/S02A/P/MSP-IMPROV-S02A-M01-P-MF03.avi  \n",
            "  inflating: session1/S02A/R/MSP-IMPROV-S02A-M01-R-MM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-FM05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF08.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF09.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF10.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-F01-S-MF11.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-FM07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF01.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF02.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF03.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF04.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF05.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF06.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF07.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF08.avi  \n",
            "  inflating: session1/S02A/S/MSP-IMPROV-S02A-M01-S-MF09.avi  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-F01-T-FM01.avi  \n",
            "  inflating: session1/S02A/T/MSP-IMPROV-S02A-M01-T-MF01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-F01-P-FM02.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-FM01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF01.avi  \n",
            "  inflating: session1/S02H/P/MSP-IMPROV-S02H-M01-P-MF02.avi  \n",
            "  inflating: session1/S02H/R/MSP-IMPROV-S02H-M01-R-MM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-FM03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-F01-S-MF04.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-FM02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF01.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF02.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF03.avi  \n",
            "  inflating: session1/S02H/S/MSP-IMPROV-S02H-M01-S-MF04.avi  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-F01-T-FM01.avi  \n",
            "  inflating: session1/S02H/T/MSP-IMPROV-S02H-M01-T-MF01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM02.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-F01-P-FM03.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-FM01.avi  \n",
            "  inflating: session1/S02N/P/MSP-IMPROV-S02N-M01-P-MF01.avi  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM01.avi  \n",
            "  inflating: session1/S02N/R/MSP-IMPROV-S02N-M01-R-MM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-FM03.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-F01-S-MF01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM02.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-FM03.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF01.avi  \n",
            "  inflating: session1/S02N/S/MSP-IMPROV-S02N-M01-S-MF02.avi  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-F01-T-FM01.avi  \n",
            "  inflating: session1/S02N/T/MSP-IMPROV-S02N-M01-T-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.avi  \n",
            "  inflating: session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.avi  \n",
            "  inflating: session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.avi  \n",
            "  inflating: session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.avi  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.avi  \n",
            "  inflating: session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.avi  \n",
            "  inflating: session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.avi  \n",
            "  inflating: session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.avi  \n",
            "  inflating: session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.avi  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.avi  \n",
            "  inflating: session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-F01-P-FM01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-FM01.avi  \n",
            "  inflating: session1/S03H/P/MSP-IMPROV-S03H-M01-P-MF01.avi  \n",
            "  inflating: session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.avi  \n",
            "  inflating: session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.avi  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.avi  \n",
            "  inflating: session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-FM01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-F01-P-MF01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-FM01.avi  \n",
            "  inflating: session1/S03N/P/MSP-IMPROV-S03N-M01-P-MF01.avi  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM01.avi  \n",
            "  inflating: session1/S03N/R/MSP-IMPROV-S03N-M01-R-MM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-FM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-F01-S-MF02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM02.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-FM03.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF01.avi  \n",
            "  inflating: session1/S03N/S/MSP-IMPROV-S03N-M01-S-MF02.avi  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-F01-T-FM01.avi  \n",
            "  inflating: session1/S03N/T/MSP-IMPROV-S03N-M01-T-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-FM02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-F01-P-MF03.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-FM02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF01.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF02.avi  \n",
            "  inflating: session1/S03S/P/MSP-IMPROV-S03S-M01-P-MF03.avi  \n",
            "  inflating: session1/S03S/R/MSP-IMPROV-S03S-M01-R-MM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-FM03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-F01-S-MF04.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-FM02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF01.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF02.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF03.avi  \n",
            "  inflating: session1/S03S/S/MSP-IMPROV-S03S-M01-S-MF04.avi  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-F01-T-FM01.avi  \n",
            "  inflating: session1/S03S/T/MSP-IMPROV-S03S-M01-T-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-FM02.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-F01-P-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-FM01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF01.avi  \n",
            "  inflating: session1/S04A/P/MSP-IMPROV-S04A-M01-P-MF02.avi  \n",
            "  inflating: session1/S04A/R/MSP-IMPROV-S04A-M01-R-MM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-FM03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-F01-S-MF04.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-FM03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF01.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF02.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF03.avi  \n",
            "  inflating: session1/S04A/S/MSP-IMPROV-S04A-M01-S-MF04.avi  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-F01-T-FM01.avi  \n",
            "  inflating: session1/S04A/T/MSP-IMPROV-S04A-M01-T-MF01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.avi  \n",
            "  inflating: session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.avi  \n",
            "  inflating: session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.avi  \n",
            "  inflating: session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.avi  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.avi  \n",
            "  inflating: session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-FM02.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-F01-P-MF01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM01.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-FM02.avi  \n",
            "  inflating: session1/S04N/P/MSP-IMPROV-S04N-M01-P-MF01.avi  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM01.avi  \n",
            "  inflating: session1/S04N/R/MSP-IMPROV-S04N-M01-R-MM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-FM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-F01-S-MF02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM01.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM02.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-FM03.avi  \n",
            "  inflating: session1/S04N/S/MSP-IMPROV-S04N-M01-S-MF01.avi  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-F01-T-FM01.avi  \n",
            "  inflating: session1/S04N/T/MSP-IMPROV-S04N-M01-T-MF01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.avi  \n",
            "  inflating: session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.avi  \n",
            "  inflating: session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.avi  \n",
            "  inflating: session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.avi  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.avi  \n",
            "  inflating: session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-FM01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-F01-P-MF02.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-FM01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF01.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF02.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF03.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF04.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF05.avi  \n",
            "  inflating: session1/S05A/P/MSP-IMPROV-S05A-M01-P-MF06.avi  \n",
            "  inflating: session1/S05A/R/MSP-IMPROV-S05A-M01-R-MM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-FM03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF04.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF05.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF06.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF07.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF08.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-F01-S-MF09.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-FM03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF01.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF02.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF03.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF04.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF05.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF06.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF07.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF08.avi  \n",
            "  inflating: session1/S05A/S/MSP-IMPROV-S05A-M01-S-MF09.avi  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-F01-T-FM01.avi  \n",
            "  inflating: session1/S05A/T/MSP-IMPROV-S05A-M01-T-MF01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM03.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-F01-P-FM04.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM03.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-FM04.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF01.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF02.avi  \n",
            "  inflating: session1/S05H/P/MSP-IMPROV-S05H-M01-P-MF03.avi  \n",
            "  inflating: session1/S05H/R/MSP-IMPROV-S05H-M01-R-MM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-FM02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF03.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-F01-S-MF04.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-FM02.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF01.avi  \n",
            "  inflating: session1/S05H/S/MSP-IMPROV-S05H-M01-S-MF02.avi  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-F01-T-FM01.avi  \n",
            "  inflating: session1/S05H/T/MSP-IMPROV-S05H-M01-T-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.avi  \n",
            "  inflating: session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.avi  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.avi  \n",
            "  inflating: session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.avi  \n",
            "  inflating: session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.avi  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.avi  \n",
            "  inflating: session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-FM01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF02.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-F01-P-MF03.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-FM01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF01.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF02.avi  \n",
            "  inflating: session1/S05S/P/MSP-IMPROV-S05S-M01-P-MF03.avi  \n",
            "  inflating: session1/S05S/R/MSP-IMPROV-S05S-M01-R-MM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-FM02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-F01-S-MF03.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-FM02.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF01.avi  \n",
            "  inflating: session1/S05S/S/MSP-IMPROV-S05S-M01-S-MF02.avi  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-F01-T-FM01.avi  \n",
            "  inflating: session1/S05S/T/MSP-IMPROV-S05S-M01-T-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-FM03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-F01-P-MF03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-FM02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF01.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF02.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF03.avi  \n",
            "  inflating: session1/S06A/P/MSP-IMPROV-S06A-M01-P-MF04.avi  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM01.avi  \n",
            "  inflating: session1/S06A/R/MSP-IMPROV-S06A-M01-R-MM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-FM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-F01-S-MF02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-FM02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF01.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF02.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF03.avi  \n",
            "  inflating: session1/S06A/S/MSP-IMPROV-S06A-M01-S-MF04.avi  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-F01-T-FM01.avi  \n",
            "  inflating: session1/S06A/T/MSP-IMPROV-S06A-M01-T-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-FM02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-F01-P-MF03.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-FM02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF01.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF02.avi  \n",
            "  inflating: session1/S06H/P/MSP-IMPROV-S06H-M01-P-MF03.avi  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM01.avi  \n",
            "  inflating: session1/S06H/R/MSP-IMPROV-S06H-M01-R-MM02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-FM01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-F01-S-MF02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM01.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM02.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-FM03.avi  \n",
            "  inflating: session1/S06H/S/MSP-IMPROV-S06H-M01-S-MF01.avi  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-F01-T-FM01.avi  \n",
            "  inflating: session1/S06H/T/MSP-IMPROV-S06H-M01-T-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-FM02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-F01-P-MF02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-FM03.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF01.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF02.avi  \n",
            "  inflating: session1/S06N/P/MSP-IMPROV-S06N-M01-P-MF03.avi  \n",
            "  inflating: session1/S06N/R/MSP-IMPROV-S06N-M01-R-MM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-FM02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-F01-S-MF02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM02.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-FM03.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF01.avi  \n",
            "  inflating: session1/S06N/S/MSP-IMPROV-S06N-M01-S-MF02.avi  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-F01-T-FM01.avi  \n",
            "  inflating: session1/S06N/T/MSP-IMPROV-S06N-M01-T-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.avi  \n",
            "  inflating: session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.avi  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.avi  \n",
            "  inflating: session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.avi  \n",
            "  inflating: session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.avi  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.avi  \n",
            "  inflating: session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.avi  \n",
            "  inflating: session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.avi  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.avi  \n",
            "  inflating: session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.avi  \n",
            "  inflating: session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.avi  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.avi  \n",
            "  inflating: session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.avi  \n",
            "  inflating: session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.avi  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.avi  \n",
            "  inflating: session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.avi  \n",
            "  inflating: session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.avi  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.avi  \n",
            "  inflating: session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-FM02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-F01-P-MF02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-FM02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF01.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF02.avi  \n",
            "  inflating: session1/S07N/P/MSP-IMPROV-S07N-M01-P-MF03.avi  \n",
            "  inflating: session1/S07N/R/MSP-IMPROV-S07N-M01-R-MM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-FM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-F01-S-MF02.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-FM02.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF01.avi  \n",
            "  inflating: session1/S07N/S/MSP-IMPROV-S07N-M01-S-MF02.avi  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-F01-T-FM01.avi  \n",
            "  inflating: session1/S07N/T/MSP-IMPROV-S07N-M01-T-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.avi  \n",
            "  inflating: session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.avi  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.avi  \n",
            "  inflating: session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.avi  \n",
            "  inflating: session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.avi  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.avi  \n",
            "  inflating: session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.avi  \n",
            "  inflating: session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.avi  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.avi  \n",
            "  inflating: session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.avi  \n",
            "  inflating: session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.avi  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.avi  \n",
            "  inflating: session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.avi  \n",
            "  inflating: session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.avi  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.avi  \n",
            "  inflating: session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.avi  \n",
            "  inflating: session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.avi  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.avi  \n",
            "  inflating: session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-FM03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-F01-P-MF02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM04.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM05.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM06.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-FM07.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF01.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF02.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF03.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF04.avi  \n",
            "  inflating: session1/S08N/P/MSP-IMPROV-S08N-M01-P-MF05.avi  \n",
            "  inflating: session1/S08N/R/MSP-IMPROV-S08N-M01-R-MM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-FM02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF03.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF04.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-F01-S-MF05.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-FM02.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF01.avi  \n",
            "  inflating: session1/S08N/S/MSP-IMPROV-S08N-M01-S-MF02.avi  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-F01-T-FM01.avi  \n",
            "  inflating: session1/S08N/T/MSP-IMPROV-S08N-M01-T-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.avi  \n",
            "  inflating: session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.avi  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.avi  \n",
            "  inflating: session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.avi  \n",
            "  inflating: session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.avi  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.avi  \n",
            "  inflating: session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-FM03.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-F01-P-MF02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-FM02.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF01.avi  \n",
            "  inflating: session1/S09A/P/MSP-IMPROV-S09A-M01-P-MF02.avi  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM01.avi  \n",
            "  inflating: session1/S09A/R/MSP-IMPROV-S09A-M01-R-MM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-FM03.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-F01-S-MF02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-FM02.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF01.avi  \n",
            "  inflating: session1/S09A/S/MSP-IMPROV-S09A-M01-S-MF02.avi  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-F01-T-FM01.avi  \n",
            "  inflating: session1/S09A/T/MSP-IMPROV-S09A-M01-T-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.avi  \n",
            "  inflating: session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.avi  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.avi  \n",
            "  inflating: session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.avi  \n",
            "  inflating: session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.avi  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.avi  \n",
            "  inflating: session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.avi  \n",
            "  inflating: session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.avi  \n",
            "  inflating: session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.avi  \n",
            "  inflating: session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.avi  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.avi  \n",
            "  inflating: session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-FM03.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-F01-P-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-FM03.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF01.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF02.avi  \n",
            "  inflating: session1/S09S/P/MSP-IMPROV-S09S-M01-P-MF03.avi  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM01.avi  \n",
            "  inflating: session1/S09S/R/MSP-IMPROV-S09S-M01-R-MM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM03.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM04.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM05.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-FM06.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-F01-S-MF01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM02.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM03.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-FM04.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF01.avi  \n",
            "  inflating: session1/S09S/S/MSP-IMPROV-S09S-M01-S-MF02.avi  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-F01-T-FM01.avi  \n",
            "  inflating: session1/S09S/T/MSP-IMPROV-S09S-M01-T-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM02.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-FM03.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-F01-P-MF02.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-FM01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF01.avi  \n",
            "  inflating: session1/S10A/P/MSP-IMPROV-S10A-M01-P-MF02.avi  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM01.avi  \n",
            "  inflating: session1/S10A/R/MSP-IMPROV-S10A-M01-R-MM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-FM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-F01-S-MF03.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-FM02.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF01.avi  \n",
            "  inflating: session1/S10A/S/MSP-IMPROV-S10A-M01-S-MF02.avi  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-F01-T-FM01.avi  \n",
            "  inflating: session1/S10A/T/MSP-IMPROV-S10A-M01-T-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.avi  \n",
            "  inflating: session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.avi  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.avi  \n",
            "  inflating: session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.avi  \n",
            "  inflating: session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.avi  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.avi  \n",
            "  inflating: session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.avi  \n",
            "  inflating: session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.avi  \n",
            "  inflating: session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.avi  \n",
            "  inflating: session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.avi  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.avi  \n",
            "  inflating: session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM03.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-FM04.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-F01-P-MF02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM02.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-FM03.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF01.avi  \n",
            "  inflating: session1/S10S/P/MSP-IMPROV-S10S-M01-P-MF02.avi  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM01.avi  \n",
            "  inflating: session1/S10S/R/MSP-IMPROV-S10S-M01-R-MM02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-FM01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-F01-S-MF02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM01.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-FM02.avi  \n",
            "  inflating: session1/S10S/S/MSP-IMPROV-S10S-M01-S-MF01.avi  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-F01-T-FM01.avi  \n",
            "  inflating: session1/S10S/T/MSP-IMPROV-S10S-M01-T-MF01.avi  \n",
            "  inflating: session1/S11A/R/MSP-IMPROV-S11A-M01-R-MM01.avi  \n",
            "  inflating: session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.avi  \n",
            "  inflating: session1/S11N/R/MSP-IMPROV-S11N-M01-R-MM01.avi  \n",
            "  inflating: session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.avi  \n",
            "  inflating: session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.avi  \n",
            "  inflating: session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.avi  \n",
            "  inflating: session1/S12N/R/MSP-IMPROV-S12N-M01-R-MM01.avi  \n",
            "  inflating: session1/S12S/R/MSP-IMPROV-S12S-M01-R-MM01.avi  \n",
            "  inflating: session1/S13A/R/MSP-IMPROV-S13A-M01-R-MM01.avi  \n",
            "  inflating: session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.avi  \n",
            "  inflating: session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.avi  \n",
            "  inflating: session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.avi  \n",
            "  inflating: session1/S14A/R/MSP-IMPROV-S14A-M01-R-MM01.avi  \n",
            "  inflating: session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.avi  \n",
            "  inflating: session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.avi  \n",
            "  inflating: session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.avi  \n",
            "  inflating: session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.avi  \n",
            "  inflating: session1/S15H/R/MSP-IMPROV-S15H-M01-R-MM01.avi  \n",
            "  inflating: session1/S15N/R/MSP-IMPROV-S15N-M01-R-MM01.avi  \n",
            "  inflating: session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.avi  \n",
            "  inflating: session1/S16A/R/MSP-IMPROV-S16A-M01-R-MM01.avi  \n",
            "  inflating: session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.avi  \n",
            "  inflating: session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.avi  \n",
            "  inflating: session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.avi  \n",
            "  inflating: session1/S17A/R/MSP-IMPROV-S17A-M01-R-MM01.avi  \n",
            "  inflating: session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.avi  \n",
            "  inflating: session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.avi  \n",
            "  inflating: session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.avi  \n",
            "  inflating: session1/S18A/R/MSP-IMPROV-S18A-M01-R-MM01.avi  \n",
            "  inflating: session1/S18H/R/MSP-IMPROV-S18H-M01-R-MM01.avi  \n",
            "  inflating: session1/S18N/R/MSP-IMPROV-S18N-M01-R-MM01.avi  \n",
            "  inflating: session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.avi  \n",
            "  inflating: session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.avi  \n",
            "  inflating: session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.avi  \n",
            "  inflating: session1/S19N/R/MSP-IMPROV-S19N-M01-R-MM01.avi  \n",
            "  inflating: session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.avi  \n",
            "  inflating: session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.avi  \n",
            "  inflating: session1/S20H/R/MSP-IMPROV-S20H-M01-R-MM01.avi  \n",
            "  inflating: session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.avi  \n",
            "  inflating: session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.avi  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RvsXPF5Y9ChI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_features = []"
      ],
      "metadata": {
        "id": "ajbUG-T8sFrq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory containing video and audio files\n",
        "directory = \"/content/drive/MyDrive/Extra_Data\"\n",
        "\n",
        "# Initialize an empty dictionary to store video-audio pairs\n",
        "video_audio_mapping = {}\n",
        "\n",
        "# Iterate through the directory and its subdirectories\n",
        "for root, dirs, files in os.walk(directory):\n",
        "    for file in files:\n",
        "        if file.endswith(\".avi\"):\n",
        "            video_path = os.path.join(root, file)\n",
        "            # Replace .avi with .wav to get corresponding audio path\n",
        "            audio_path = os.path.join(root, file[:-4] + \".wav\")\n",
        "            # Check if corresponding audio file exists\n",
        "            if os.path.exists(audio_path):\n",
        "                video_audio_mapping[video_path] = audio_path\n",
        "\n",
        "# Print the video-audio mapping\n",
        "for video_path, audio_path in video_audio_mapping.items():\n",
        "    print(f\"Video: {video_path}, Audio: {audio_path}\")"
      ],
      "metadata": {
        "id": "IPROVaNy5cxs",
        "outputId": "16bde542-e550-4e48-c5bc-1c4c9be3009c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF06.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF06.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF07.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF07.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-T-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM06.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM06.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM07.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM07.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM06.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM06.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-T-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-T-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-M03-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-M03-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-M03-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-M03-T-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-T-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM06.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM06.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-T-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-T-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-T-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-M02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-M02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM04.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM04.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM05.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM05.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM03.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM03.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-P-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-P-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-R-FF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-R-FF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-R-MM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-R-MM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-S-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-S-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-MF02.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-MF02.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-S-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-S-MF01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-T-FM01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-T-FM01.wav\n",
            "Video: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-T-MF01.avi, Audio: /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-T-MF01.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def resize_video(video_path, output_path, width=320, height=240):\n",
        "    # Open the video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        return\n",
        "\n",
        "    # Get original video properties\n",
        "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change this to match your video codec\n",
        "\n",
        "    # Create a VideoWriter object to write the resized video\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        # Resize the frame to the specified dimensions\n",
        "        resized_frame = cv2.resize(frame, (width, height))\n",
        "        out.write(resized_frame)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "ap1oGYNyBwGh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ckpt_path = \"/content/data/finetune-model.pt\"\n",
        "user_dir = \"/content/av_hubert/avhubert\"\n",
        "files = {}\n",
        "for video_path, audio_path in video_audio_mapping.items():\n",
        "  files[video_path] = audio_path\n",
        "  label = video_path.split(\"/\")\n",
        "  label = label[-1].split('-')[2][-1]\n",
        "  print(label)\n",
        "  if label == 'A':\n",
        "    label = 0\n",
        "  elif label == 'H':\n",
        "    label = 1\n",
        "  elif label == 'S':\n",
        "    label = 2\n",
        "  else:\n",
        "    label = 3\n",
        "  # Resize the video\n",
        "  output_path = \"resized_video.avi\"\n",
        "  resize_video(video_path, output_path, width=320, height=240)\n",
        "\n",
        "  # Extract visual features\n",
        "  layer_features, feature = extract_visual_feature(output_path, audio_path, ckpt_path, user_dir)\n",
        "\n",
        "  # Create a tensor for the label\n",
        "  label_tensor = torch.tensor([label] * feature.size(0), dtype=torch.float).unsqueeze(1)  # Repeat the label for each row in feature\n",
        "\n",
        "  # Concatenate the label tensor with the feature tensor along the second dimension (columns)\n",
        "  label_tensor = label_tensor.to(feature.device)\n",
        "  feature_with_label = torch.cat((feature, label_tensor), dim=1)\n",
        "  final_features.append(feature_with_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDLYlMN5gm5E",
        "outputId": "867e3e7a-dfab-4506-e80a-e9247673020c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (36, 240, 320)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM01.wav: shape (30, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 36, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM01.wav: shape torch.Size([1, 104, 36])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([36, 768])\n",
            "A\n",
            "Load video resized_video.avi: shape (64, 240, 320)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM03.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM03.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (141, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM02.wav: shape (119, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 141, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F03-P-FM02.wav: shape torch.Size([1, 104, 141])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([141, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (89, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM01.wav: shape (75, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 89, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM01.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (93, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF01.wav: shape (78, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 93, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF01.wav: shape torch.Size([1, 104, 93])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([93, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (74, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM05.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 74, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM05.wav: shape torch.Size([1, 104, 74])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([74, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM02.wav: shape (132, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM02.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (72, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF04.wav: shape (60, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 72, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF04.wav: shape torch.Size([1, 104, 72])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([72, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (328, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM04.wav: shape (274, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 328, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM04.wav: shape torch.Size([1, 104, 328])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([328, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (273, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM03.wav: shape (229, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 273, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-FM03.wav: shape torch.Size([1, 104, 273])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([273, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (169, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF03.wav: shape (141, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 169, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF03.wav: shape torch.Size([1, 104, 169])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([169, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (60, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF01.wav: shape (51, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 60, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF01.wav: shape torch.Size([1, 104, 60])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([60, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF06.wav: shape (91, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF06.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (156, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF05.wav: shape (131, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 156, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF05.wav: shape torch.Size([1, 104, 156])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([156, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF07.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF07.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (59, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF03.wav: shape (50, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 59, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF03.wav: shape torch.Size([1, 104, 59])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([59, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (92, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF02.wav: shape (77, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 92, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF02.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (208, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF02.wav: shape (174, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 208, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-P-MF02.wav: shape torch.Size([1, 104, 208])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([208, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-FM01.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-FM01.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF04.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M03-P-MF04.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n",
            "H\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (106, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-R-FF01.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 106, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F03-R-FF01.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (228, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM01.wav: shape (191, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 228, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM01.wav: shape torch.Size([1, 104, 228])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([228, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (114, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM02.wav: shape (96, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 114, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM02.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF01.wav: shape (91, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF01.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF02.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF02.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (46, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-P-FM01.wav: shape (39, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 46, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-P-FM01.wav: shape torch.Size([1, 104, 46])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([46, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (84, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF05.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 84, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF05.wav: shape torch.Size([1, 104, 84])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([84, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (98, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF04.wav: shape (82, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 98, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF04.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (277, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM03.wav: shape (231, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 277, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-FM03.wav: shape torch.Size([1, 104, 277])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([277, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (131, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-P-FM02.wav: shape (110, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 131, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-P-FM02.wav: shape torch.Size([1, 104, 131])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([131, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (147, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF03.wav: shape (124, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 147, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-P-MF03.wav: shape torch.Size([1, 104, 147])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([147, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-R-FF01.wav: shape (72, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-R-FF01.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (89, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-R-MM01.wav: shape (75, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 89, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-R-MM01.wav: shape torch.Size([1, 104, 89])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([89, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM01.wav: shape (52, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM01.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (77, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM02.wav: shape (65, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 77, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM02.wav: shape torch.Size([1, 104, 77])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([77, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (88, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM03.wav: shape (74, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 88, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-FM03.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (115, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-MF01.wav: shape (96, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 115, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-MF01.wav: shape torch.Size([1, 104, 115])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([115, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (51, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM03.wav: shape (43, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 51, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM03.wav: shape torch.Size([1, 104, 51])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([51, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (66, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM02.wav: shape (56, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 66, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM02.wav: shape torch.Size([1, 104, 66])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([66, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (56, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM01.wav: shape (47, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 56, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-FM01.wav: shape torch.Size([1, 104, 56])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([56, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-MF02.wav: shape (72, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-S-MF02.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (91, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-MF01.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 91, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-MF01.wav: shape torch.Size([1, 104, 91])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([91, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (139, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-MF02.wav: shape (116, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 139, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-S-MF02.wav: shape torch.Size([1, 104, 139])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([139, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (69, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-T-FM01.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 69, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-F03-T-FM01.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (58, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-T-MF01.wav: shape (49, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 58, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01N-M03-T-MF01.wav: shape torch.Size([1, 104, 58])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([58, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM02.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM02.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (110, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM01.wav: shape (92, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 110, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM01.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (56, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-P-FM01.wav: shape (47, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 56, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-P-FM01.wav: shape torch.Size([1, 104, 56])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([56, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (158, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM04.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 158, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM04.wav: shape torch.Size([1, 104, 158])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([158, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (202, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-P-MF01.wav: shape (169, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 202, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-P-MF01.wav: shape torch.Size([1, 104, 202])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([202, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (309, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-MF01.wav: shape (259, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 309, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-MF01.wav: shape torch.Size([1, 104, 309])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([309, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (425, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM03.wav: shape (355, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 425, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-P-FM03.wav: shape torch.Size([1, 104, 425])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([425, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-R-FF01.wav: shape (121, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-R-FF01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (182, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-R-MM01.wav: shape (153, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 182, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-R-MM01.wav: shape torch.Size([1, 104, 182])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([182, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM01.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (107, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM04.wav: shape (90, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 107, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM04.wav: shape torch.Size([1, 104, 107])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([107, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM03.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM03.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (61, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM06.wav: shape (52, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 61, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM06.wav: shape torch.Size([1, 104, 61])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([61, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (102, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM05.wav: shape (86, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 102, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM05.wav: shape torch.Size([1, 104, 102])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([102, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (139, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM02.wav: shape (117, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 139, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-FM02.wav: shape torch.Size([1, 104, 139])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([139, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM01.wav: shape (57, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM01.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (98, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF03.wav: shape (82, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 98, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF03.wav: shape torch.Size([1, 104, 98])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([98, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (72, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM05.wav: shape (61, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 72, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM05.wav: shape torch.Size([1, 104, 72])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([72, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM04.wav: shape (52, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM04.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (63, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM03.wav: shape (53, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 63, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM03.wav: shape torch.Size([1, 104, 63])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([63, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF01.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF01.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (211, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF02.wav: shape (176, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 211, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-S-MF02.wav: shape torch.Size([1, 104, 211])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([211, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (51, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM07.wav: shape (43, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 51, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM07.wav: shape torch.Size([1, 104, 51])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([51, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (80, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF01.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 80, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF01.wav: shape torch.Size([1, 104, 80])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([80, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (127, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM02.wav: shape (106, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 127, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM02.wav: shape torch.Size([1, 104, 127])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([127, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM06.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-FM06.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (79, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF03.wav: shape (67, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 79, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF03.wav: shape torch.Size([1, 104, 79])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([79, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (120, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF02.wav: shape (100, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 120, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-S-MF02.wav: shape torch.Size([1, 104, 120])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([120, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (103, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-T-MF01.wav: shape (87, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 103, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-M03-T-MF01.wav: shape torch.Size([1, 104, 103])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([103, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-T-FM01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02N-F03-T-FM01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (54, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF02.wav: shape (45, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 54, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF02.wav: shape torch.Size([1, 104, 54])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([54, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (157, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-FM01.wav: shape (132, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 157, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-FM01.wav: shape torch.Size([1, 104, 157])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([157, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (177, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF03.wav: shape (148, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 177, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF03.wav: shape torch.Size([1, 104, 177])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([177, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (169, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF01.wav: shape (141, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 169, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-MF01.wav: shape torch.Size([1, 104, 169])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([169, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (82, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-P-MF01.wav: shape (69, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 82, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-P-MF01.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (82, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-P-MF02.wav: shape (69, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 82, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-P-MF02.wav: shape torch.Size([1, 104, 82])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([82, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (140, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-FM02.wav: shape (117, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 140, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-P-FM02.wav: shape torch.Size([1, 104, 140])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([140, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-R-MM01.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-R-MM01.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (128, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-R-FF01.wav: shape (108, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 128, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-R-FF01.wav: shape torch.Size([1, 104, 128])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([128, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (97, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-FM01.wav: shape (81, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 97, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-FM01.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (45, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF02.wav: shape (38, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 45, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF02.wav: shape torch.Size([1, 104, 45])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([45, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (135, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF03.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 135, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF03.wav: shape torch.Size([1, 104, 135])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([135, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (41, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-FM01.wav: shape (34, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 41, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-FM01.wav: shape torch.Size([1, 104, 41])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([41, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-MF01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-MF01.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (70, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-FM02.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 70, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-FM02.wav: shape torch.Size([1, 104, 70])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([70, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (130, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-MF02.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 130, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-S-MF02.wav: shape torch.Size([1, 104, 130])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([130, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (175, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF01.wav: shape (147, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 175, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-S-MF01.wav: shape torch.Size([1, 104, 175])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([175, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (70, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-T-MF01.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 70, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-M03-T-MF01.wav: shape torch.Size([1, 104, 70])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([70, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (64, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-T-FM01.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03N-F03-T-FM01.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (95, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-P-FM01.wav: shape (80, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 95, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-P-FM01.wav: shape torch.Size([1, 104, 95])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([95, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (103, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-P-MF01.wav: shape (87, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 103, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-P-MF01.wav: shape torch.Size([1, 104, 103])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([103, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-M03-R-MM01.wav: shape (122, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-M03-R-MM01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (110, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-R-FF01.wav: shape (92, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 110, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-R-FF01.wav: shape torch.Size([1, 104, 110])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([110, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (87, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-T-FM01.wav: shape (73, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 87, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-F03-T-FM01.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n",
            "N\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (69, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-M03-T-MF01.wav: shape (58, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 69, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04N-M03-T-MF01.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (282, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-FM01.wav: shape (235, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 282, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-FM01.wav: shape torch.Size([1, 104, 282])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([282, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (662, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF01.wav: shape (553, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 662, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF01.wav: shape torch.Size([1, 104, 662])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([662, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (639, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF02.wav: shape (533, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 639, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF02.wav: shape torch.Size([1, 104, 639])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([639, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (78, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF03.wav: shape (66, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 78, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-P-MF03.wav: shape torch.Size([1, 104, 78])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([78, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (258, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-FM01.wav: shape (215, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 258, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-FM01.wav: shape torch.Size([1, 104, 258])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([258, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (205, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-FM02.wav: shape (172, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 205, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-FM02.wav: shape torch.Size([1, 104, 205])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([205, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (173, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-MF01.wav: shape (145, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 173, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-P-MF01.wav: shape torch.Size([1, 104, 173])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([173, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (153, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-R-FF01.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 153, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-R-FF01.wav: shape torch.Size([1, 104, 153])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([153, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (152, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-R-MM01.wav: shape (128, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 152, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-R-MM01.wav: shape torch.Size([1, 104, 152])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([152, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM02.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM02.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (168, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM01.wav: shape (140, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 168, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM01.wav: shape torch.Size([1, 104, 168])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([168, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (52, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM03.wav: shape (44, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 52, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-FM03.wav: shape torch.Size([1, 104, 52])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([52, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (141, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-MF02.wav: shape (118, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 141, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-MF02.wav: shape torch.Size([1, 104, 141])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([141, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-MF01.wav: shape (121, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-S-MF01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (186, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-FM01.wav: shape (155, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 186, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-FM01.wav: shape torch.Size([1, 104, 186])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([186, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (118, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF01.wav: shape (99, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 118, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF01.wav: shape torch.Size([1, 104, 118])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([118, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (31, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-FM02.wav: shape (26, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 31, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-FM02.wav: shape torch.Size([1, 104, 31])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([31, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF02.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF02.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (47, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF03.wav: shape (40, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 47, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-S-MF03.wav: shape torch.Size([1, 104, 47])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([47, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (59, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-T-FM01.wav: shape (50, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 59, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-F02-T-FM01.wav: shape torch.Size([1, 104, 59])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([59, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (62, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-T-MF01.wav: shape (52, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 62, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01A-M02-T-MF01.wav: shape torch.Size([1, 104, 62])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([62, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (70, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM01.wav: shape (59, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 70, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM01.wav: shape torch.Size([1, 104, 70])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([70, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (69, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM02.wav: shape (58, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 69, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM02.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (258, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM04.wav: shape (215, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 258, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM04.wav: shape torch.Size([1, 104, 258])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([258, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM03.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM03.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (528, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM05.wav: shape (441, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 528, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-FM05.wav: shape torch.Size([1, 104, 528])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([528, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (314, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF01.wav: shape (262, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 314, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF01.wav: shape torch.Size([1, 104, 314])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([314, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (81, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF04.wav: shape (68, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 81, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF04.wav: shape torch.Size([1, 104, 81])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([81, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (66, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF02.wav: shape (56, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 66, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF02.wav: shape torch.Size([1, 104, 66])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([66, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (44, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF03.wav: shape (37, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 44, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF03.wav: shape torch.Size([1, 104, 44])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([44, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (108, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-FM02.wav: shape (90, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 108, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-FM02.wav: shape torch.Size([1, 104, 108])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([108, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (85, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-FM01.wav: shape (71, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 85, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-FM01.wav: shape torch.Size([1, 104, 85])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([85, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (55, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF05.wav: shape (46, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 55, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-P-MF05.wav: shape torch.Size([1, 104, 55])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([55, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (143, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF01.wav: shape (120, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 143, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF01.wav: shape torch.Size([1, 104, 143])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([143, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF02.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF02.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (197, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF03.wav: shape (165, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 197, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF03.wav: shape torch.Size([1, 104, 197])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([197, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (197, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF04.wav: shape (165, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 197, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF04.wav: shape torch.Size([1, 104, 197])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([197, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (155, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF05.wav: shape (130, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 155, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-P-MF05.wav: shape torch.Size([1, 104, 155])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([155, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (268, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-R-FF01.wav: shape (224, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 268, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-R-FF01.wav: shape torch.Size([1, 104, 268])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([268, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (204, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-R-MM01.wav: shape (170, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 204, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-R-MM01.wav: shape torch.Size([1, 104, 204])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([204, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (105, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-FM02.wav: shape (88, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 105, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-FM02.wav: shape torch.Size([1, 104, 105])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([105, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (100, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-FM01.wav: shape (84, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 100, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-FM01.wav: shape torch.Size([1, 104, 100])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([100, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (71, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-MF02.wav: shape (60, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 71, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-MF02.wav: shape torch.Size([1, 104, 71])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([71, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (160, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-MF01.wav: shape (134, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 160, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-S-MF01.wav: shape torch.Size([1, 104, 160])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([160, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (198, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM01.wav: shape (165, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 198, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM01.wav: shape torch.Size([1, 104, 198])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([198, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (114, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM02.wav: shape (95, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 114, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM02.wav: shape torch.Size([1, 104, 114])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([114, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (207, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM04.wav: shape (173, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 207, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM04.wav: shape torch.Size([1, 104, 207])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([207, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (67, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM03.wav: shape (56, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 67, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM03.wav: shape torch.Size([1, 104, 67])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([67, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (193, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM05.wav: shape (162, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 193, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM05.wav: shape torch.Size([1, 104, 193])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([193, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (74, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM06.wav: shape (62, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 74, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-FM06.wav: shape torch.Size([1, 104, 74])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([74, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (96, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-MF01.wav: shape (81, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 96, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-S-MF01.wav: shape torch.Size([1, 104, 96])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([96, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (101, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-T-FM01.wav: shape (85, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 101, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-F02-T-FM01.wav: shape torch.Size([1, 104, 101])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([101, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (122, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-T-MF01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 122, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S02A-M02-T-MF01.wav: shape torch.Size([1, 104, 122])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([122, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (485, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-P-MF01.wav: shape (405, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 485, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-P-MF01.wav: shape torch.Size([1, 104, 485])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([485, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (231, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-R-FF01.wav: shape (193, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 231, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-R-FF01.wav: shape torch.Size([1, 104, 231])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([231, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (127, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-S-FM01.wav: shape (107, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 127, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-S-FM01.wav: shape torch.Size([1, 104, 127])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([127, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (169, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-R-MM01.wav: shape (141, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 169, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-R-MM01.wav: shape torch.Size([1, 104, 169])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([169, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (141, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-S-FM01.wav: shape (118, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 141, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-S-FM01.wav: shape torch.Size([1, 104, 141])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([141, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-S-MF01.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-S-MF01.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (83, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-T-FM01.wav: shape (70, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 83, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-F02-T-FM01.wav: shape torch.Size([1, 104, 83])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([83, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-T-MF01.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-T-MF01.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (76, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-S-FM02.wav: shape (64, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 76, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S03A-M02-S-FM02.wav: shape torch.Size([1, 104, 76])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([76, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (178, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-P-FM01.wav: shape (149, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 178, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-P-FM01.wav: shape torch.Size([1, 104, 178])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([178, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (281, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-P-MF01.wav: shape (235, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 281, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-P-MF01.wav: shape torch.Size([1, 104, 281])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([281, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (130, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-P-FM01.wav: shape (109, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 130, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-P-FM01.wav: shape torch.Size([1, 104, 130])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([130, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (196, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-R-FF01.wav: shape (164, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 196, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-R-FF01.wav: shape torch.Size([1, 104, 196])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([196, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (171, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-R-MM01.wav: shape (143, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 171, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-R-MM01.wav: shape torch.Size([1, 104, 171])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([171, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (231, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM01.wav: shape (193, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 231, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM01.wav: shape torch.Size([1, 104, 231])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([231, 768])\n",
            "A\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load video resized_video.avi: shape (99, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM02.wav: shape (83, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 99, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM02.wav: shape torch.Size([1, 104, 99])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([99, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (237, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM03.wav: shape (198, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 237, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM03.wav: shape torch.Size([1, 104, 237])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([237, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (69, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM04.wav: shape (58, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 69, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM04.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (33, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM05.wav: shape (28, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 33, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-FM05.wav: shape torch.Size([1, 104, 33])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([33, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (126, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-MF01.wav: shape (105, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 126, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-MF01.wav: shape torch.Size([1, 104, 126])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([126, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (171, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-MF02.wav: shape (143, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 171, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-S-MF02.wav: shape torch.Size([1, 104, 171])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([171, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (106, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM01.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 106, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM01.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (166, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM02.wav: shape (139, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 166, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM02.wav: shape torch.Size([1, 104, 166])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([166, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (258, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-MF01.wav: shape (215, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 258, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-MF01.wav: shape torch.Size([1, 104, 258])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([258, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (106, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM03.wav: shape (89, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 106, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-S-FM03.wav: shape torch.Size([1, 104, 106])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([106, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (97, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-T-FM01.wav: shape (81, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 97, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-F02-T-FM01.wav: shape torch.Size([1, 104, 97])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([97, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (64, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-T-MF01.wav: shape (54, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 64, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S04A-M02-T-MF01.wav: shape torch.Size([1, 104, 64])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([64, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (87, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-FM02.wav: shape (73, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 87, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-FM02.wav: shape torch.Size([1, 104, 87])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([87, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (169, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-FM01.wav: shape (142, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 169, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-FM01.wav: shape torch.Size([1, 104, 169])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([169, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (92, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-MF02.wav: shape (77, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 92, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-MF02.wav: shape torch.Size([1, 104, 92])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([92, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (219, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-MF01.wav: shape (183, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 219, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-F02-P-MF01.wav: shape torch.Size([1, 104, 219])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([219, 768])\n",
            "A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (349, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-M02-P-FM01.wav: shape (292, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 349, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S05A-M02-P-FM01.wav: shape torch.Size([1, 104, 349])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([349, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (159, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM01.wav: shape (133, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 159, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM01.wav: shape torch.Size([1, 104, 159])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([159, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (73, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM02.wav: shape (63, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 73, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM02.wav: shape torch.Size([1, 104, 73])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([73, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (135, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM04.wav: shape (113, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 135, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM04.wav: shape torch.Size([1, 104, 135])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([135, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (105, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM03.wav: shape (88, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 105, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM03.wav: shape torch.Size([1, 104, 105])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([105, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (69, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM05.wav: shape (58, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 69, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-FM05.wav: shape torch.Size([1, 104, 69])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([69, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (88, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF02.wav: shape (74, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 88, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF02.wav: shape torch.Size([1, 104, 88])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([88, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (123, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF01.wav: shape (103, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 123, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF01.wav: shape torch.Size([1, 104, 123])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([123, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF03.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-F02-S-MF03.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (121, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM01.wav: shape (102, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 121, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM01.wav: shape torch.Size([1, 104, 121])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([121, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (165, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM02.wav: shape (138, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 165, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM02.wav: shape torch.Size([1, 104, 165])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([165, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (112, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM03.wav: shape (94, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 112, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-FM03.wav: shape torch.Size([1, 104, 112])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([112, 768])\n",
            "H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (91, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-MF01.wav: shape (76, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 91, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01H-M02-S-MF01.wav: shape torch.Size([1, 104, 91])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([91, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (150, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-FM01.wav: shape (125, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 150, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-FM01.wav: shape torch.Size([1, 104, 150])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([150, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (290, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-MF01.wav: shape (242, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 290, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-MF01.wav: shape torch.Size([1, 104, 290])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([290, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (194, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-MF02.wav: shape (163, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 194, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-P-MF02.wav: shape torch.Size([1, 104, 194])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([194, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (145, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-P-FM01.wav: shape (122, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 145, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-P-FM01.wav: shape torch.Size([1, 104, 145])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([145, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (163, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-R-FF01.wav: shape (136, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 163, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-R-FF01.wav: shape torch.Size([1, 104, 163])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([163, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (94, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-R-MM01.wav: shape (79, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 94, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-R-MM01.wav: shape torch.Size([1, 104, 94])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([94, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (325, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-FM01.wav: shape (272, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 325, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-FM01.wav: shape torch.Size([1, 104, 325])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([325, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (305, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-MF01.wav: shape (255, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 305, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-MF01.wav: shape torch.Size([1, 104, 305])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([305, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (266, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-S-FM01.wav: shape (222, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 266, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-S-FM01.wav: shape torch.Size([1, 104, 266])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([266, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (68, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-MF02.wav: shape (58, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 68, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-S-MF02.wav: shape torch.Size([1, 104, 68])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([68, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (253, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-S-MF01.wav: shape (211, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 253, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-S-MF01.wav: shape torch.Size([1, 104, 253])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([253, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (65, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-T-FM01.wav: shape (55, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 65, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-F02-T-FM01.wav: shape torch.Size([1, 104, 65])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([65, 768])\n",
            "S\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load video resized_video.avi: shape (66, 240, 320)\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-T-MF01.wav: shape (56, 104)\n",
            "Load video resized_video.avi: shape torch.Size([1, 1, 66, 240, 320])\n",
            "Load audio /content/drive/MyDrive/Extra_Data/MSP-IMPROV-S01S-M02-T-MF01.wav: shape torch.Size([1, 104, 66])\n",
            "Checkpoint: fine-tuned\n",
            "AvHuBert Feature shape: torch.Size([66, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_features"
      ],
      "metadata": {
        "id": "JwmnXEf5w3ub",
        "outputId": "1ada1506-3528-4d65-e5b5-033b5553ada9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.0220, -0.1532, -0.0641,  ...,  0.0516,  0.1857,  0.0000],\n",
              "         [ 0.1117, -0.1285, -0.0622,  ...,  0.2440,  0.1520,  0.0000],\n",
              "         [ 0.0438, -0.1283, -0.0795,  ...,  0.3410,  0.0888,  0.0000],\n",
              "         ...,\n",
              "         [-0.2139,  0.0445,  0.1924,  ..., -0.0006, -0.0811,  0.0000],\n",
              "         [-0.2569,  0.0673,  0.2098,  ...,  0.0118, -0.0777,  0.0000],\n",
              "         [-0.2262,  0.0350,  0.2342,  ..., -0.0158, -0.0490,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0286, -0.1594, -0.0502,  ...,  0.0561,  0.2123,  0.0000],\n",
              "         [ 0.1501, -0.1051, -0.0691,  ...,  0.2958,  0.1523,  0.0000],\n",
              "         [ 0.1102, -0.1094, -0.0737,  ...,  0.3834,  0.0824,  0.0000],\n",
              "         ...,\n",
              "         [-0.1184,  0.0059,  0.1998,  ...,  0.1210,  0.0106,  0.0000],\n",
              "         [-0.2164,  0.0124,  0.2283,  ...,  0.0947, -0.0311,  0.0000],\n",
              "         [-0.2659,  0.0167,  0.2451,  ...,  0.0384, -0.0204,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0206, -0.1263, -0.0319,  ...,  0.0398,  0.2090,  0.0000],\n",
              "         [ 0.1170, -0.0450,  0.0004,  ...,  0.2351,  0.1158,  0.0000],\n",
              "         [ 0.1188,  0.0152,  0.0185,  ...,  0.3111, -0.0270,  0.0000],\n",
              "         ...,\n",
              "         [-0.0597,  0.1388,  0.2242,  ...,  0.0624,  0.0078,  0.0000],\n",
              "         [-0.2344,  0.1396,  0.3445,  ...,  0.0631, -0.0150,  0.0000],\n",
              "         [-0.2833,  0.1029,  0.2985,  ...,  0.0475, -0.0011,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0315, -0.1277, -0.0337,  ...,  0.0570,  0.2069,  1.0000],\n",
              "         [ 0.1344, -0.0656, -0.0385,  ...,  0.2671,  0.1332,  1.0000],\n",
              "         [ 0.1142, -0.0396, -0.0341,  ...,  0.3678,  0.0149,  1.0000],\n",
              "         ...,\n",
              "         [-0.1299,  0.0926,  0.2333,  ...,  0.1066, -0.0069,  1.0000],\n",
              "         [-0.2563,  0.0852,  0.3023,  ...,  0.0833, -0.0366,  1.0000],\n",
              "         [-0.2969,  0.0874,  0.2830,  ...,  0.0445, -0.0130,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0294, -0.1291, -0.0316,  ...,  0.0579,  0.2088,  1.0000],\n",
              "         [ 0.1421, -0.0607, -0.0344,  ...,  0.2670,  0.1368,  1.0000],\n",
              "         [ 0.1236, -0.0338, -0.0239,  ...,  0.3674,  0.0145,  1.0000],\n",
              "         ...,\n",
              "         [-0.1207,  0.0923,  0.2272,  ...,  0.0917, -0.0021,  1.0000],\n",
              "         [-0.2441,  0.0856,  0.2940,  ...,  0.0770, -0.0312,  1.0000],\n",
              "         [-0.2928,  0.0873,  0.2800,  ...,  0.0512, -0.0111,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0320, -0.1452, -0.0398,  ...,  0.0567,  0.2124,  1.0000],\n",
              "         [ 0.1486, -0.0783, -0.0600,  ...,  0.2911,  0.1453,  1.0000],\n",
              "         [ 0.1132, -0.0672, -0.0659,  ...,  0.3853,  0.0467,  1.0000],\n",
              "         ...,\n",
              "         [-0.1274,  0.0430,  0.2110,  ...,  0.1083,  0.0106,  1.0000],\n",
              "         [-0.2390,  0.0421,  0.2629,  ...,  0.0873, -0.0290,  1.0000],\n",
              "         [-0.2863,  0.0564,  0.2653,  ...,  0.0437, -0.0121,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0153, -0.1197, -0.0388,  ...,  0.0388,  0.2096,  1.0000],\n",
              "         [ 0.1165, -0.0374, -0.0107,  ...,  0.2324,  0.1130,  1.0000],\n",
              "         [ 0.1193,  0.0303,  0.0063,  ...,  0.3070, -0.0367,  1.0000],\n",
              "         ...,\n",
              "         [-0.0342,  0.1338,  0.1969,  ...,  0.0577,  0.0257,  1.0000],\n",
              "         [-0.2248,  0.1334,  0.3428,  ...,  0.0655, -0.0040,  1.0000],\n",
              "         [-0.2864,  0.0949,  0.3031,  ...,  0.0538,  0.0014,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0328, -0.1387, -0.0354,  ...,  0.0540,  0.2113,  1.0000],\n",
              "         [ 0.1412, -0.0754, -0.0434,  ...,  0.2726,  0.1517,  1.0000],\n",
              "         [ 0.1055, -0.0602, -0.0419,  ...,  0.3655,  0.0495,  1.0000],\n",
              "         ...,\n",
              "         [-0.1429,  0.0683,  0.2305,  ...,  0.0994,  0.0082,  1.0000],\n",
              "         [-0.2525,  0.0640,  0.2848,  ...,  0.0813, -0.0349,  1.0000],\n",
              "         [-0.3009,  0.0657,  0.2820,  ...,  0.0343, -0.0134,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0233, -0.1221, -0.0715,  ...,  0.0118,  0.1830,  1.0000],\n",
              "         [ 0.2042, -0.0311, -0.0590,  ...,  0.1991,  0.0279,  1.0000],\n",
              "         [ 0.2079,  0.0132, -0.0561,  ...,  0.2573, -0.1050,  1.0000],\n",
              "         ...,\n",
              "         [ 0.1214,  0.0075, -0.0371,  ...,  0.0509,  0.0615,  1.0000],\n",
              "         [-0.0932,  0.0872,  0.2705,  ...,  0.1153, -0.0271,  1.0000],\n",
              "         [-0.2596,  0.0678,  0.3077,  ...,  0.0767, -0.0106,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0166, -0.1103, -0.0701,  ...,  0.0293,  0.1928,  1.0000],\n",
              "         [ 0.1792, -0.0285, -0.0517,  ...,  0.2260,  0.0522,  1.0000],\n",
              "         [ 0.1863,  0.0234, -0.0535,  ...,  0.2971, -0.0942,  1.0000],\n",
              "         ...,\n",
              "         [ 0.1058,  0.0596,  0.0147,  ...,  0.0525,  0.0745,  1.0000],\n",
              "         [-0.1150,  0.1116,  0.2764,  ...,  0.1074, -0.0101,  1.0000],\n",
              "         [-0.2458,  0.0797,  0.2974,  ...,  0.0729, -0.0052,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0202, -0.1145, -0.0328,  ...,  0.0371,  0.2054,  1.0000],\n",
              "         [ 0.1173, -0.0295, -0.0088,  ...,  0.2323,  0.0988,  1.0000],\n",
              "         [ 0.1285,  0.0398,  0.0099,  ...,  0.3030, -0.0529,  1.0000],\n",
              "         ...,\n",
              "         [-0.0316,  0.1349,  0.1934,  ...,  0.0396,  0.0168,  1.0000],\n",
              "         [-0.2232,  0.1365,  0.3495,  ...,  0.0577, -0.0099,  1.0000],\n",
              "         [-0.2832,  0.1035,  0.3109,  ...,  0.0450,  0.0027,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.6840e-02, -1.6233e-01, -5.8441e-02,  ...,  6.0786e-02,\n",
              "           2.1045e-01,  1.0000e+00],\n",
              "         [ 1.4047e-01, -1.2278e-01, -8.2797e-02,  ...,  3.0439e-01,\n",
              "           1.4951e-01,  1.0000e+00],\n",
              "         [ 9.0918e-02, -1.2562e-01, -9.0734e-02,  ...,  4.0088e-01,\n",
              "           7.0582e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.2812e-01, -3.8633e-04,  1.8598e-01,  ...,  1.3122e-01,\n",
              "          -2.6631e-03,  1.0000e+00],\n",
              "         [-2.0359e-01,  4.3280e-03,  2.0243e-01,  ...,  1.0169e-01,\n",
              "          -3.4687e-02,  1.0000e+00],\n",
              "         [-2.5220e-01, -1.7232e-02,  2.3341e-01,  ...,  4.2291e-02,\n",
              "          -3.2394e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0240, -0.1307, -0.0267,  ...,  0.0444,  0.2083,  1.0000],\n",
              "         [ 0.1253, -0.0523, -0.0102,  ...,  0.2437,  0.1284,  1.0000],\n",
              "         [ 0.1139, -0.0050,  0.0119,  ...,  0.3328, -0.0092,  1.0000],\n",
              "         ...,\n",
              "         [-0.1148,  0.1302,  0.2392,  ...,  0.0766, -0.0045,  1.0000],\n",
              "         [-0.2579,  0.1273,  0.3400,  ...,  0.0593, -0.0361,  1.0000],\n",
              "         [-0.3017,  0.0895,  0.2984,  ...,  0.0479, -0.0134,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0162, -0.1226, -0.0330,  ...,  0.0382,  0.2063,  1.0000],\n",
              "         [ 0.1232, -0.0349, -0.0083,  ...,  0.2417,  0.1059,  1.0000],\n",
              "         [ 0.1265,  0.0334,  0.0128,  ...,  0.3204, -0.0410,  1.0000],\n",
              "         ...,\n",
              "         [-0.0351,  0.1306,  0.1905,  ...,  0.0624,  0.0151,  1.0000],\n",
              "         [-0.2236,  0.1336,  0.3363,  ...,  0.0669, -0.0080,  1.0000],\n",
              "         [-0.2784,  0.1004,  0.2974,  ...,  0.0499, -0.0026,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2799e-02, -1.3220e-01, -2.5185e-02,  ...,  4.3624e-02,\n",
              "           2.0894e-01,  1.0000e+00],\n",
              "         [ 1.2622e-01, -4.7799e-02, -5.2865e-04,  ...,  2.4541e-01,\n",
              "           1.2359e-01,  1.0000e+00],\n",
              "         [ 1.2234e-01,  4.3304e-03,  2.0621e-02,  ...,  3.2695e-01,\n",
              "          -1.1984e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.0094e-01,  1.3415e-01,  2.5064e-01,  ...,  6.9510e-02,\n",
              "          -6.8100e-03,  1.0000e+00],\n",
              "         [-2.5025e-01,  1.2976e-01,  3.5158e-01,  ...,  6.1501e-02,\n",
              "          -3.0152e-02,  1.0000e+00],\n",
              "         [-2.9404e-01,  9.7848e-02,  3.0344e-01,  ...,  4.6448e-02,\n",
              "          -7.5813e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.2034e-02, -1.5485e-01, -5.5437e-02,  ...,  5.7439e-02,\n",
              "           2.1314e-01,  1.0000e+00],\n",
              "         [ 1.3993e-01, -1.1019e-01, -8.0595e-02,  ...,  2.9884e-01,\n",
              "           1.5312e-01,  1.0000e+00],\n",
              "         [ 8.9673e-02, -1.1274e-01, -8.8908e-02,  ...,  3.9863e-01,\n",
              "           6.7963e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.3956e-01,  1.8962e-04,  1.9579e-01,  ...,  1.2873e-01,\n",
              "           4.0957e-05,  1.0000e+00],\n",
              "         [-2.2256e-01,  5.9710e-03,  2.2039e-01,  ...,  1.0017e-01,\n",
              "          -3.7413e-02,  1.0000e+00],\n",
              "         [-2.7020e-01,  2.0176e-03,  2.4466e-01,  ...,  3.7135e-02,\n",
              "          -2.8817e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0300, -0.1196, -0.0294,  ...,  0.0565,  0.2048,  1.0000],\n",
              "         [ 0.1300, -0.0634, -0.0292,  ...,  0.2593,  0.1400,  1.0000],\n",
              "         [ 0.1173, -0.0287, -0.0166,  ...,  0.3585,  0.0129,  1.0000],\n",
              "         ...,\n",
              "         [-0.1742,  0.1252,  0.2694,  ...,  0.1079, -0.0216,  1.0000],\n",
              "         [-0.2771,  0.1013,  0.3292,  ...,  0.0800, -0.0444,  1.0000],\n",
              "         [-0.3019,  0.0877,  0.2949,  ...,  0.0464, -0.0160,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0105, -0.1126, -0.0406,  ...,  0.0368,  0.2002,  1.0000],\n",
              "         [ 0.1425, -0.0180, -0.0237,  ...,  0.2315,  0.0715,  1.0000],\n",
              "         [ 0.1575,  0.0446, -0.0156,  ...,  0.2967, -0.0783,  1.0000],\n",
              "         ...,\n",
              "         [ 0.0156,  0.1152,  0.1307,  ...,  0.0328,  0.0251,  1.0000],\n",
              "         [-0.1924,  0.1321,  0.3299,  ...,  0.0704, -0.0139,  1.0000],\n",
              "         [-0.2679,  0.1030,  0.3069,  ...,  0.0516, -0.0033,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0216, -0.1218, -0.0269,  ...,  0.0357,  0.2017,  1.0000],\n",
              "         [ 0.1237, -0.0261,  0.0029,  ...,  0.2362,  0.0957,  1.0000],\n",
              "         [ 0.1285,  0.0397,  0.0245,  ...,  0.3079, -0.0496,  1.0000],\n",
              "         ...,\n",
              "         [-0.0227,  0.1377,  0.1938,  ...,  0.0417,  0.0152,  1.0000],\n",
              "         [-0.2175,  0.1343,  0.3476,  ...,  0.0478, -0.0113,  1.0000],\n",
              "         [-0.2838,  0.1056,  0.3085,  ...,  0.0387, -0.0053,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0215, -0.1290, -0.0242,  ...,  0.0398,  0.2071,  1.0000],\n",
              "         [ 0.1214, -0.0493,  0.0032,  ...,  0.2427,  0.1232,  1.0000],\n",
              "         [ 0.1227,  0.0086,  0.0209,  ...,  0.3258, -0.0091,  1.0000],\n",
              "         ...,\n",
              "         [-0.1154,  0.1400,  0.2702,  ...,  0.0790, -0.0153,  1.0000],\n",
              "         [-0.2536,  0.1290,  0.3622,  ...,  0.0633, -0.0327,  1.0000],\n",
              "         [-0.2978,  0.0956,  0.3128,  ...,  0.0501, -0.0154,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0221, -0.1326, -0.0281,  ...,  0.0488,  0.2142,  1.0000],\n",
              "         [ 0.1445, -0.0524, -0.0094,  ...,  0.2305,  0.1426,  1.0000],\n",
              "         [ 0.1289, -0.0060,  0.0136,  ...,  0.3150,  0.0065,  1.0000],\n",
              "         ...,\n",
              "         [-0.1467,  0.1536,  0.2621,  ...,  0.0557, -0.0109,  1.0000],\n",
              "         [-0.2559,  0.1292,  0.3254,  ...,  0.0536, -0.0333,  1.0000],\n",
              "         [-0.2856,  0.0981,  0.2924,  ...,  0.0546, -0.0111,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-5.7711e-03, -1.1343e-01, -4.9551e-02,  ...,  3.8722e-02,\n",
              "           1.9942e-01,  3.0000e+00],\n",
              "         [ 1.4084e-01, -2.4550e-02, -3.2740e-02,  ...,  2.4096e-01,\n",
              "           7.0428e-02,  3.0000e+00],\n",
              "         [ 1.5568e-01,  3.9102e-02, -2.7687e-02,  ...,  3.1078e-01,\n",
              "          -7.5825e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 5.4632e-02,  9.9652e-02,  8.9324e-02,  ...,  5.1279e-02,\n",
              "           4.5515e-02,  3.0000e+00],\n",
              "         [-1.7293e-01,  1.2256e-01,  3.0990e-01,  ...,  9.1493e-02,\n",
              "          -8.1856e-03,  3.0000e+00],\n",
              "         [-2.5763e-01,  9.9225e-02,  2.9580e-01,  ...,  6.1670e-02,\n",
              "           9.9905e-04,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.8464e-02, -1.3102e-01, -2.9414e-02,  ...,  4.4411e-02,\n",
              "           2.0643e-01,  3.0000e+00],\n",
              "         [ 1.3483e-01, -5.2449e-02, -7.8932e-03,  ...,  2.6433e-01,\n",
              "           1.2402e-01,  3.0000e+00],\n",
              "         [ 1.3069e-01,  1.6596e-03,  3.7709e-03,  ...,  3.5877e-01,\n",
              "          -1.6478e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-8.4125e-02,  1.1630e-01,  2.1775e-01,  ...,  9.5706e-02,\n",
              "          -9.4050e-03,  3.0000e+00],\n",
              "         [-2.3604e-01,  1.1482e-01,  3.2622e-01,  ...,  7.8835e-02,\n",
              "          -3.0939e-02,  3.0000e+00],\n",
              "         [-2.8532e-01,  9.5921e-02,  2.9382e-01,  ...,  5.1320e-02,\n",
              "          -1.0711e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.2798e-02, -1.3300e-01, -2.6981e-02,  ...,  4.5511e-02,\n",
              "           2.0942e-01,  3.0000e+00],\n",
              "         [ 1.3213e-01, -4.8767e-02, -9.1923e-03,  ...,  2.5634e-01,\n",
              "           1.2677e-01,  3.0000e+00],\n",
              "         [ 1.2301e-01, -2.2897e-03,  9.1022e-03,  ...,  3.4398e-01,\n",
              "          -5.2766e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0903e-01,  1.2480e-01,  2.4428e-01,  ...,  8.3601e-02,\n",
              "          -1.5052e-02,  3.0000e+00],\n",
              "         [-2.4604e-01,  1.1928e-01,  3.3420e-01,  ...,  7.0252e-02,\n",
              "          -3.4177e-02,  3.0000e+00],\n",
              "         [-2.9288e-01,  9.3226e-02,  2.9623e-01,  ...,  5.0548e-02,\n",
              "          -9.5643e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.9152e-02, -1.5609e-01, -5.1162e-02,  ...,  5.8132e-02,\n",
              "           2.1458e-01,  3.0000e+00],\n",
              "         [ 1.5146e-01, -9.9044e-02, -7.3873e-02,  ...,  2.9973e-01,\n",
              "           1.5275e-01,  3.0000e+00],\n",
              "         [ 1.0574e-01, -1.0206e-01, -7.9417e-02,  ...,  3.9565e-01,\n",
              "           6.9990e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.2805e-01,  6.2076e-03,  2.0761e-01,  ...,  1.1792e-01,\n",
              "           8.5470e-04,  3.0000e+00],\n",
              "         [-2.1818e-01,  1.1455e-02,  2.2953e-01,  ...,  9.3560e-02,\n",
              "          -3.3849e-02,  3.0000e+00],\n",
              "         [-2.6608e-01,  2.0241e-02,  2.4726e-01,  ...,  4.0469e-02,\n",
              "          -1.5792e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0338, -0.1508, -0.0574,  ...,  0.0641,  0.2040,  3.0000],\n",
              "         [ 0.1318, -0.1127, -0.0681,  ...,  0.3008,  0.1520,  3.0000],\n",
              "         [ 0.0688, -0.1118, -0.0751,  ...,  0.4040,  0.0810,  3.0000],\n",
              "         ...,\n",
              "         [-0.1998,  0.0389,  0.1965,  ...,  0.1035, -0.0625,  3.0000],\n",
              "         [-0.2557,  0.0469,  0.1971,  ...,  0.0854, -0.0762,  3.0000],\n",
              "         [-0.2605,  0.0305,  0.2348,  ...,  0.0260, -0.0409,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0298, -0.1280, -0.0370,  ...,  0.0553,  0.2096,  3.0000],\n",
              "         [ 0.1369, -0.0674, -0.0366,  ...,  0.2693,  0.1434,  3.0000],\n",
              "         [ 0.1159, -0.0474, -0.0377,  ...,  0.3705,  0.0252,  3.0000],\n",
              "         ...,\n",
              "         [-0.1315,  0.0785,  0.2345,  ...,  0.1007, -0.0040,  3.0000],\n",
              "         [-0.2485,  0.0681,  0.2932,  ...,  0.0827, -0.0355,  3.0000],\n",
              "         [-0.2941,  0.0792,  0.2778,  ...,  0.0438, -0.0146,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.0165e-02, -1.3352e-01, -2.8111e-02,  ...,  5.0775e-02,\n",
              "           2.1124e-01,  3.0000e+00],\n",
              "         [ 1.3638e-01, -5.4910e-02, -1.3881e-02,  ...,  2.6582e-01,\n",
              "           1.3393e-01,  3.0000e+00],\n",
              "         [ 1.2520e-01, -1.5988e-02,  8.5447e-04,  ...,  3.5817e-01,\n",
              "           4.2079e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.1983e-01,  1.1457e-01,  2.4579e-01,  ...,  9.6247e-02,\n",
              "          -2.3224e-02,  3.0000e+00],\n",
              "         [-2.4745e-01,  1.0689e-01,  3.2515e-01,  ...,  8.1849e-02,\n",
              "          -3.9642e-02,  3.0000e+00],\n",
              "         [-2.9283e-01,  8.9748e-02,  2.9204e-01,  ...,  5.3138e-02,\n",
              "          -1.0991e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0097, -0.1126, -0.0607,  ...,  0.0252,  0.1896,  3.0000],\n",
              "         [ 0.1771, -0.0252, -0.0474,  ...,  0.2308,  0.0391,  3.0000],\n",
              "         [ 0.1790,  0.0226, -0.0459,  ...,  0.2916, -0.0998,  3.0000],\n",
              "         ...,\n",
              "         [ 0.0896,  0.0544,  0.0352,  ...,  0.0455,  0.0493,  3.0000],\n",
              "         [-0.1295,  0.1137,  0.3008,  ...,  0.0993, -0.0201,  3.0000],\n",
              "         [-0.2553,  0.0848,  0.3027,  ...,  0.0652, -0.0101,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0263, -0.1260, -0.0243,  ...,  0.0364,  0.2037,  3.0000],\n",
              "         [ 0.1147, -0.0397,  0.0130,  ...,  0.2256,  0.1094,  3.0000],\n",
              "         [ 0.1148,  0.0170,  0.0345,  ...,  0.2989, -0.0294,  3.0000],\n",
              "         ...,\n",
              "         [-0.1011,  0.1447,  0.2633,  ...,  0.0505, -0.0111,  3.0000],\n",
              "         [-0.2507,  0.1328,  0.3687,  ...,  0.0426, -0.0277,  3.0000],\n",
              "         [-0.2986,  0.1007,  0.3162,  ...,  0.0338, -0.0074,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.9277e-02, -1.2583e-01, -3.2330e-02,  ...,  4.0216e-02,\n",
              "           2.0802e-01,  3.0000e+00],\n",
              "         [ 1.1897e-01, -3.5887e-02, -2.9852e-03,  ...,  2.3441e-01,\n",
              "           1.0875e-01,  3.0000e+00],\n",
              "         [ 1.3001e-01,  2.5348e-02,  1.2629e-02,  ...,  3.0291e-01,\n",
              "          -4.0388e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-7.1351e-02,  1.4345e-01,  2.2406e-01,  ...,  5.9769e-02,\n",
              "          -9.1386e-03,  3.0000e+00],\n",
              "         [-2.3687e-01,  1.3747e-01,  3.5146e-01,  ...,  5.5263e-02,\n",
              "          -2.5819e-02,  3.0000e+00],\n",
              "         [-2.8370e-01,  1.0294e-01,  3.0720e-01,  ...,  4.4378e-02,\n",
              "          -2.4583e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0338, -0.1349, -0.0313,  ...,  0.0599,  0.2116,  3.0000],\n",
              "         [ 0.1656, -0.0594, -0.0273,  ...,  0.2544,  0.1462,  3.0000],\n",
              "         [ 0.1287, -0.0323, -0.0099,  ...,  0.3418,  0.0384,  3.0000],\n",
              "         ...,\n",
              "         [-0.1445,  0.1068,  0.2501,  ...,  0.0668, -0.0075,  3.0000],\n",
              "         [-0.2501,  0.0876,  0.2893,  ...,  0.0608, -0.0407,  3.0000],\n",
              "         [-0.2806,  0.0808,  0.2765,  ...,  0.0480, -0.0182,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0319, -0.1208, -0.0287,  ...,  0.0530,  0.2056,  3.0000],\n",
              "         [ 0.1282, -0.0590, -0.0204,  ...,  0.2429,  0.1374,  3.0000],\n",
              "         [ 0.1116, -0.0272, -0.0052,  ...,  0.3351,  0.0184,  3.0000],\n",
              "         ...,\n",
              "         [-0.1720,  0.1196,  0.2703,  ...,  0.0828, -0.0244,  3.0000],\n",
              "         [-0.2818,  0.0995,  0.3268,  ...,  0.0684, -0.0463,  3.0000],\n",
              "         [-0.3015,  0.0966,  0.2920,  ...,  0.0342, -0.0148,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0367, -0.1498, -0.0434,  ...,  0.0548,  0.2134,  3.0000],\n",
              "         [ 0.1408, -0.0929, -0.0573,  ...,  0.2858,  0.1581,  3.0000],\n",
              "         [ 0.0976, -0.0920, -0.0650,  ...,  0.3785,  0.0796,  3.0000],\n",
              "         ...,\n",
              "         [-0.1498,  0.0334,  0.2225,  ...,  0.1107,  0.0102,  3.0000],\n",
              "         [-0.2541,  0.0382,  0.2575,  ...,  0.0864, -0.0390,  3.0000],\n",
              "         [-0.2904,  0.0377,  0.2659,  ...,  0.0305, -0.0171,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0337, -0.1405, -0.0361,  ...,  0.0517,  0.2089,  3.0000],\n",
              "         [ 0.1375, -0.0742, -0.0425,  ...,  0.2676,  0.1425,  3.0000],\n",
              "         [ 0.1062, -0.0567, -0.0433,  ...,  0.3573,  0.0402,  3.0000],\n",
              "         ...,\n",
              "         [-0.1426,  0.0653,  0.2284,  ...,  0.0883,  0.0088,  3.0000],\n",
              "         [-0.2502,  0.0624,  0.2820,  ...,  0.0729, -0.0338,  3.0000],\n",
              "         [-0.2937,  0.0657,  0.2806,  ...,  0.0341, -0.0146,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1223, -0.0310,  ...,  0.0522,  0.2044,  3.0000],\n",
              "         [ 0.1255, -0.0644, -0.0268,  ...,  0.2492,  0.1344,  3.0000],\n",
              "         [ 0.1092, -0.0342, -0.0165,  ...,  0.3432,  0.0158,  3.0000],\n",
              "         ...,\n",
              "         [-0.1613,  0.1151,  0.2606,  ...,  0.0909, -0.0190,  3.0000],\n",
              "         [-0.2741,  0.1013,  0.3199,  ...,  0.0730, -0.0442,  3.0000],\n",
              "         [-0.3026,  0.0919,  0.2913,  ...,  0.0327, -0.0178,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.5921e-02, -1.2875e-01, -2.5505e-02,  ...,  4.2645e-02,\n",
              "           2.0707e-01,  3.0000e+00],\n",
              "         [ 1.1706e-01, -5.0323e-02, -1.5141e-03,  ...,  2.4374e-01,\n",
              "           1.2467e-01,  3.0000e+00],\n",
              "         [ 1.1165e-01,  6.1516e-04,  1.6742e-02,  ...,  3.2749e-01,\n",
              "          -9.9288e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.2701e-01,  1.3850e-01,  2.7020e-01,  ...,  6.7053e-02,\n",
              "          -1.8424e-02,  3.0000e+00],\n",
              "         [-2.5691e-01,  1.3071e-01,  3.5641e-01,  ...,  5.9316e-02,\n",
              "          -3.5130e-02,  3.0000e+00],\n",
              "         [-3.0074e-01,  9.6371e-02,  3.0961e-01,  ...,  4.1354e-02,\n",
              "          -9.5864e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0358, -0.1528, -0.0517,  ...,  0.0591,  0.2113,  3.0000],\n",
              "         [ 0.1373, -0.1124, -0.0713,  ...,  0.2936,  0.1589,  3.0000],\n",
              "         [ 0.0789, -0.1127, -0.0759,  ...,  0.3941,  0.0819,  3.0000],\n",
              "         ...,\n",
              "         [-0.1617,  0.0192,  0.2043,  ...,  0.1171, -0.0159,  3.0000],\n",
              "         [-0.2476,  0.0327,  0.2148,  ...,  0.0935, -0.0531,  3.0000],\n",
              "         [-0.2753,  0.0153,  0.2439,  ...,  0.0318, -0.0367,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0333, -0.1462, -0.0380,  ...,  0.0521,  0.2122,  3.0000],\n",
              "         [ 0.1396, -0.0856, -0.0498,  ...,  0.2716,  0.1521,  3.0000],\n",
              "         [ 0.0999, -0.0735, -0.0516,  ...,  0.3630,  0.0560,  3.0000],\n",
              "         ...,\n",
              "         [-0.1501,  0.0380,  0.2256,  ...,  0.1039,  0.0164,  3.0000],\n",
              "         [-0.2506,  0.0419,  0.2744,  ...,  0.0812, -0.0348,  3.0000],\n",
              "         [-0.2929,  0.0500,  0.2755,  ...,  0.0312, -0.0225,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0376, -0.1465, -0.0465,  ...,  0.0563,  0.2140,  3.0000],\n",
              "         [ 0.1351, -0.0997, -0.0694,  ...,  0.2887,  0.1597,  3.0000],\n",
              "         [ 0.0854, -0.1016, -0.0737,  ...,  0.3854,  0.0830,  3.0000],\n",
              "         ...,\n",
              "         [-0.1537,  0.0171,  0.2148,  ...,  0.1234,  0.0062,  3.0000],\n",
              "         [-0.2549,  0.0255,  0.2431,  ...,  0.0948, -0.0407,  3.0000],\n",
              "         [-0.2900,  0.0248,  0.2596,  ...,  0.0311, -0.0283,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0337, -0.1221, -0.0320,  ...,  0.0523,  0.2071,  3.0000],\n",
              "         [ 0.1236, -0.0594, -0.0282,  ...,  0.2499,  0.1394,  3.0000],\n",
              "         [ 0.1050, -0.0309, -0.0161,  ...,  0.3429,  0.0194,  3.0000],\n",
              "         ...,\n",
              "         [-0.1660,  0.1124,  0.2696,  ...,  0.0949, -0.0182,  3.0000],\n",
              "         [-0.2778,  0.0976,  0.3247,  ...,  0.0722, -0.0462,  3.0000],\n",
              "         [-0.3062,  0.0888,  0.2933,  ...,  0.0322, -0.0205,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0294, -0.1191, -0.0298,  ...,  0.0539,  0.2049,  3.0000],\n",
              "         [ 0.1300, -0.0613, -0.0323,  ...,  0.2580,  0.1385,  3.0000],\n",
              "         [ 0.1152, -0.0300, -0.0213,  ...,  0.3557,  0.0131,  3.0000],\n",
              "         ...,\n",
              "         [-0.1612,  0.1212,  0.2608,  ...,  0.1145, -0.0178,  3.0000],\n",
              "         [-0.2731,  0.1097,  0.3240,  ...,  0.0836, -0.0403,  3.0000],\n",
              "         [-0.3068,  0.0842,  0.2928,  ...,  0.0445, -0.0268,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.1121e-02, -1.2455e-01, -2.7309e-02,  ...,  3.7395e-02,\n",
              "           2.0569e-01,  3.0000e+00],\n",
              "         [ 1.2404e-01, -3.4315e-02, -1.9139e-03,  ...,  2.3864e-01,\n",
              "           1.0914e-01,  3.0000e+00],\n",
              "         [ 1.2187e-01,  2.9034e-02,  1.6030e-02,  ...,  3.1912e-01,\n",
              "          -3.1405e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-5.0821e-02,  1.3146e-01,  2.1602e-01,  ...,  6.2318e-02,\n",
              "           4.4348e-03,  3.0000e+00],\n",
              "         [-2.3505e-01,  1.3007e-01,  3.5183e-01,  ...,  5.7464e-02,\n",
              "          -1.7809e-02,  3.0000e+00],\n",
              "         [-2.9218e-01,  9.4728e-02,  3.0781e-01,  ...,  4.5449e-02,\n",
              "          -1.1193e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0315, -0.1560, -0.0438,  ...,  0.0515,  0.2113,  3.0000],\n",
              "         [ 0.1440, -0.0930, -0.0583,  ...,  0.2726,  0.1479,  3.0000],\n",
              "         [ 0.1042, -0.0847, -0.0633,  ...,  0.3650,  0.0502,  3.0000],\n",
              "         ...,\n",
              "         [-0.1249,  0.0237,  0.2013,  ...,  0.0988,  0.0208,  3.0000],\n",
              "         [-0.2306,  0.0283,  0.2517,  ...,  0.0752, -0.0321,  3.0000],\n",
              "         [-0.2753,  0.0356,  0.2600,  ...,  0.0294, -0.0176,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.2102e-02, -1.5799e-01, -5.5257e-02,  ...,  5.7631e-02,\n",
              "           2.1224e-01,  3.0000e+00],\n",
              "         [ 1.3824e-01, -1.1672e-01, -8.0656e-02,  ...,  2.9672e-01,\n",
              "           1.5458e-01,  3.0000e+00],\n",
              "         [ 8.7847e-02, -1.1895e-01, -8.6674e-02,  ...,  3.9395e-01,\n",
              "           7.4410e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3982e-01,  1.0144e-03,  1.9227e-01,  ...,  1.2652e-01,\n",
              "           2.8816e-03,  3.0000e+00],\n",
              "         [-2.2257e-01,  1.0753e-02,  2.1302e-01,  ...,  9.8837e-02,\n",
              "          -3.6964e-02,  3.0000e+00],\n",
              "         [-2.6546e-01, -8.4913e-03,  2.4112e-01,  ...,  3.8830e-02,\n",
              "          -3.4382e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0181, -0.1226, -0.0338,  ...,  0.0376,  0.2052,  3.0000],\n",
              "         [ 0.1209, -0.0287, -0.0096,  ...,  0.2378,  0.0939,  3.0000],\n",
              "         [ 0.1322,  0.0386,  0.0081,  ...,  0.3100, -0.0570,  3.0000],\n",
              "         ...,\n",
              "         [-0.0272,  0.1290,  0.1824,  ...,  0.0465,  0.0107,  3.0000],\n",
              "         [-0.2190,  0.1280,  0.3388,  ...,  0.0585, -0.0149,  3.0000],\n",
              "         [-0.2786,  0.0976,  0.3020,  ...,  0.0483, -0.0030,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2709e-02, -1.3445e-01, -2.5579e-02,  ...,  4.4402e-02,\n",
              "           2.0605e-01,  3.0000e+00],\n",
              "         [ 1.3166e-01, -5.3110e-02, -4.8375e-03,  ...,  2.5862e-01,\n",
              "           1.2077e-01,  3.0000e+00],\n",
              "         [ 1.1802e-01, -9.7739e-03,  7.3562e-03,  ...,  3.4837e-01,\n",
              "          -2.1113e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-9.5759e-02,  1.2111e-01,  2.3664e-01,  ...,  9.0391e-02,\n",
              "          -9.6234e-03,  3.0000e+00],\n",
              "         [-2.4592e-01,  1.1916e-01,  3.3677e-01,  ...,  7.6587e-02,\n",
              "          -3.0676e-02,  3.0000e+00],\n",
              "         [-2.9300e-01,  9.6350e-02,  2.9744e-01,  ...,  5.1519e-02,\n",
              "          -9.1110e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.6583e-02, -1.5054e-01, -5.0866e-02,  ...,  5.6383e-02,\n",
              "           2.1415e-01,  3.0000e+00],\n",
              "         [ 1.3926e-01, -1.0589e-01, -7.3057e-02,  ...,  2.9447e-01,\n",
              "           1.5799e-01,  3.0000e+00],\n",
              "         [ 8.7918e-02, -1.0781e-01, -7.8288e-02,  ...,  3.9258e-01,\n",
              "           7.9312e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.4937e-01,  5.9950e-03,  2.0602e-01,  ...,  1.1870e-01,\n",
              "          -9.0155e-04,  3.0000e+00],\n",
              "         [-2.3896e-01,  1.3672e-02,  2.3111e-01,  ...,  9.3475e-02,\n",
              "          -4.0646e-02,  3.0000e+00],\n",
              "         [-2.8130e-01,  1.4242e-02,  2.5155e-01,  ...,  3.2345e-02,\n",
              "          -2.7183e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-1.9236e-02, -1.2392e-01, -3.3755e-02,  ...,  3.9688e-02,\n",
              "           2.0136e-01,  3.0000e+00],\n",
              "         [ 1.2628e-01, -3.1445e-02, -8.8881e-03,  ...,  2.4626e-01,\n",
              "           9.7790e-02,  3.0000e+00],\n",
              "         [ 1.2732e-01,  3.4206e-02,  7.4354e-03,  ...,  3.2631e-01,\n",
              "          -4.6426e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-2.1675e-02,  1.2682e-01,  1.7760e-01,  ...,  6.4751e-02,\n",
              "           1.5076e-02,  3.0000e+00],\n",
              "         [-2.1970e-01,  1.2699e-01,  3.3116e-01,  ...,  6.7629e-02,\n",
              "          -1.0642e-02,  3.0000e+00],\n",
              "         [-2.7545e-01,  1.0201e-01,  2.9189e-01,  ...,  4.6140e-02,\n",
              "          -9.4223e-04,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0099, -0.1148, -0.0432,  ...,  0.0305,  0.1944,  3.0000],\n",
              "         [ 0.1506, -0.0125, -0.0227,  ...,  0.2388,  0.0587,  3.0000],\n",
              "         [ 0.1529,  0.0518, -0.0150,  ...,  0.3073, -0.0806,  3.0000],\n",
              "         ...,\n",
              "         [ 0.0336,  0.1191,  0.1155,  ...,  0.0338,  0.0215,  3.0000],\n",
              "         [-0.1845,  0.1286,  0.3217,  ...,  0.0662, -0.0216,  3.0000],\n",
              "         [-0.2683,  0.0871,  0.3035,  ...,  0.0490, -0.0182,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 1.2643e-02, -1.1434e-01, -6.7141e-02,  ...,  2.1470e-02,\n",
              "           1.9243e-01,  3.0000e+00],\n",
              "         [ 1.8072e-01, -3.3428e-02, -6.0231e-02,  ...,  2.1710e-01,\n",
              "           3.1755e-02,  3.0000e+00],\n",
              "         [ 1.8672e-01,  1.0978e-02, -6.0725e-02,  ...,  2.7302e-01,\n",
              "          -1.0509e-01,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 1.0318e-01,  2.9918e-02, -1.6517e-03,  ...,  2.8035e-02,\n",
              "           5.6552e-02,  3.0000e+00],\n",
              "         [-1.1140e-01,  1.1659e-01,  2.9494e-01,  ...,  8.4865e-02,\n",
              "          -1.6552e-02,  3.0000e+00],\n",
              "         [-2.6347e-01,  8.5874e-02,  3.1266e-01,  ...,  6.1177e-02,\n",
              "          -4.0322e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 4.7659e-02, -1.7137e-01, -9.4477e-02,  ...,  1.0477e-03,\n",
              "           1.8588e-01,  3.0000e+00],\n",
              "         [ 2.7488e-01, -1.9405e-02, -9.1980e-02,  ...,  1.4317e-01,\n",
              "           2.0112e-02,  3.0000e+00],\n",
              "         [ 2.7559e-01,  2.9763e-02, -7.6277e-02,  ...,  1.8649e-01,\n",
              "          -9.7763e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [ 1.4230e-01,  3.5927e-03, -1.0454e-01,  ...,  8.8199e-02,\n",
              "           5.1224e-02,  3.0000e+00],\n",
              "         [-1.3384e-02,  7.6514e-02,  1.5843e-01,  ...,  1.2468e-01,\n",
              "          -2.8332e-02,  3.0000e+00],\n",
              "         [-2.3105e-01,  5.4947e-02,  2.9347e-01,  ...,  8.1466e-02,\n",
              "          -7.7838e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.1016e-02, -1.1710e-01, -2.8655e-02,  ...,  4.4124e-02,\n",
              "           2.1646e-01,  3.0000e+00],\n",
              "         [ 1.3031e-01, -3.2180e-02,  1.0548e-03,  ...,  2.0989e-01,\n",
              "           1.2711e-01,  3.0000e+00],\n",
              "         [ 1.2053e-01,  3.1098e-02,  2.4937e-02,  ...,  2.8846e-01,\n",
              "          -2.3374e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-8.8254e-02,  1.6521e-01,  2.4869e-01,  ...,  2.9038e-02,\n",
              "           2.7525e-03,  3.0000e+00],\n",
              "         [-2.4365e-01,  1.4775e-01,  3.5256e-01,  ...,  4.0939e-02,\n",
              "          -1.3952e-02,  3.0000e+00],\n",
              "         [-2.8005e-01,  1.1169e-01,  3.0801e-01,  ...,  5.9315e-02,\n",
              "           2.5814e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0202, -0.1156, -0.0319,  ...,  0.0396,  0.2037,  3.0000],\n",
              "         [ 0.1241, -0.0199, -0.0039,  ...,  0.2342,  0.0865,  3.0000],\n",
              "         [ 0.1377,  0.0494,  0.0100,  ...,  0.2988, -0.0633,  3.0000],\n",
              "         ...,\n",
              "         [-0.0119,  0.1359,  0.1692,  ...,  0.0325,  0.0234,  3.0000],\n",
              "         [-0.2109,  0.1325,  0.3433,  ...,  0.0574, -0.0071,  3.0000],\n",
              "         [-0.2731,  0.1072,  0.3041,  ...,  0.0440,  0.0064,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2440e-02, -1.3046e-01, -2.7212e-02,  ...,  4.1703e-02,\n",
              "           2.0749e-01,  3.0000e+00],\n",
              "         [ 1.2394e-01, -4.9363e-02, -3.2908e-03,  ...,  2.4989e-01,\n",
              "           1.1939e-01,  3.0000e+00],\n",
              "         [ 1.2008e-01,  4.4728e-03,  1.2806e-02,  ...,  3.3461e-01,\n",
              "          -1.6958e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-8.7069e-02,  1.3078e-01,  2.2775e-01,  ...,  7.2579e-02,\n",
              "          -1.0476e-03,  3.0000e+00],\n",
              "         [-2.4426e-01,  1.2993e-01,  3.4011e-01,  ...,  6.5726e-02,\n",
              "          -2.5606e-02,  3.0000e+00],\n",
              "         [-2.8876e-01,  9.7788e-02,  2.9863e-01,  ...,  4.6798e-02,\n",
              "          -5.6451e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0249, -0.1359, -0.0279,  ...,  0.0442,  0.2066,  3.0000],\n",
              "         [ 0.1278, -0.0538, -0.0102,  ...,  0.2583,  0.1229,  3.0000],\n",
              "         [ 0.1184, -0.0075,  0.0056,  ...,  0.3437, -0.0046,  3.0000],\n",
              "         ...,\n",
              "         [-0.1186,  0.1319,  0.2419,  ...,  0.0774, -0.0116,  3.0000],\n",
              "         [-0.2430,  0.1231,  0.3265,  ...,  0.0657, -0.0344,  3.0000],\n",
              "         [-0.2884,  0.0948,  0.3005,  ...,  0.0480, -0.0128,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3815e-02, -1.2975e-01, -2.6826e-02,  ...,  4.1691e-02,\n",
              "           2.0697e-01,  3.0000e+00],\n",
              "         [ 1.1959e-01, -4.9164e-02, -1.2335e-03,  ...,  2.4442e-01,\n",
              "           1.1915e-01,  3.0000e+00],\n",
              "         [ 1.1695e-01,  5.0675e-03,  1.6199e-02,  ...,  3.2601e-01,\n",
              "          -1.8500e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-9.8675e-02,  1.3779e-01,  2.5280e-01,  ...,  6.8796e-02,\n",
              "          -6.7540e-03,  3.0000e+00],\n",
              "         [-2.4861e-01,  1.3222e-01,  3.5510e-01,  ...,  6.1991e-02,\n",
              "          -2.8450e-02,  3.0000e+00],\n",
              "         [-2.9340e-01,  1.0042e-01,  3.0642e-01,  ...,  4.3607e-02,\n",
              "          -5.9007e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0326, -0.1601, -0.0538,  ...,  0.0543,  0.2099,  3.0000],\n",
              "         [ 0.1364, -0.1164, -0.0692,  ...,  0.2868,  0.1504,  3.0000],\n",
              "         [ 0.0897, -0.1191, -0.0756,  ...,  0.3768,  0.0778,  3.0000],\n",
              "         ...,\n",
              "         [-0.1493, -0.0036,  0.2050,  ...,  0.1047, -0.0095,  3.0000],\n",
              "         [-0.2274,  0.0217,  0.2149,  ...,  0.0864, -0.0443,  3.0000],\n",
              "         [-0.2610,  0.0101,  0.2413,  ...,  0.0306, -0.0228,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.5517e-02, -1.3500e-01, -2.7798e-02,  ...,  4.4497e-02,\n",
              "           2.0764e-01,  3.0000e+00],\n",
              "         [ 1.2848e-01, -5.5572e-02, -1.0409e-02,  ...,  2.6374e-01,\n",
              "           1.2350e-01,  3.0000e+00],\n",
              "         [ 1.1666e-01, -1.0460e-02,  4.7501e-03,  ...,  3.5095e-01,\n",
              "          -7.3165e-04,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.2579e-01,  1.2406e-01,  2.4714e-01,  ...,  7.1038e-02,\n",
              "          -1.3728e-02,  3.0000e+00],\n",
              "         [-2.4057e-01,  1.1929e-01,  3.2033e-01,  ...,  6.5503e-02,\n",
              "          -3.4787e-02,  3.0000e+00],\n",
              "         [-2.9157e-01,  9.1959e-02,  3.0089e-01,  ...,  4.6566e-02,\n",
              "          -1.2598e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0212, -0.1243, -0.0300,  ...,  0.0379,  0.2046,  3.0000],\n",
              "         [ 0.1220, -0.0382, -0.0045,  ...,  0.2412,  0.1079,  3.0000],\n",
              "         [ 0.1241,  0.0249,  0.0138,  ...,  0.3196, -0.0366,  3.0000],\n",
              "         ...,\n",
              "         [-0.0509,  0.1371,  0.2094,  ...,  0.0645,  0.0052,  3.0000],\n",
              "         [-0.2312,  0.1387,  0.3433,  ...,  0.0615, -0.0197,  3.0000],\n",
              "         [-0.2837,  0.1059,  0.3041,  ...,  0.0443, -0.0039,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0347, -0.1408, -0.0349,  ...,  0.0521,  0.2129,  3.0000],\n",
              "         [ 0.1371, -0.0777, -0.0495,  ...,  0.2720,  0.1559,  3.0000],\n",
              "         [ 0.0990, -0.0630, -0.0498,  ...,  0.3640,  0.0567,  3.0000],\n",
              "         ...,\n",
              "         [-0.1539,  0.0553,  0.2383,  ...,  0.1041,  0.0128,  3.0000],\n",
              "         [-0.2604,  0.0512,  0.2860,  ...,  0.0801, -0.0334,  3.0000],\n",
              "         [-0.3016,  0.0556,  0.2815,  ...,  0.0347, -0.0218,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.6350e-02, -1.3376e-01, -2.6219e-02,  ...,  4.6571e-02,\n",
              "           2.1001e-01,  3.0000e+00],\n",
              "         [ 1.2334e-01, -5.4782e-02, -4.0491e-03,  ...,  2.4475e-01,\n",
              "           1.3148e-01,  3.0000e+00],\n",
              "         [ 1.1156e-01, -1.3820e-02,  1.6282e-02,  ...,  3.2849e-01,\n",
              "           2.1198e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3819e-01,  1.2848e-01,  2.6603e-01,  ...,  7.0459e-02,\n",
              "          -2.2132e-02,  3.0000e+00],\n",
              "         [-2.5952e-01,  1.2027e-01,  3.4311e-01,  ...,  6.1262e-02,\n",
              "          -4.3857e-02,  3.0000e+00],\n",
              "         [-3.0221e-01,  9.0372e-02,  3.0386e-01,  ...,  4.3074e-02,\n",
              "          -1.4060e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0348, -0.1392, -0.0330,  ...,  0.0512,  0.2110,  3.0000],\n",
              "         [ 0.1333, -0.0739, -0.0460,  ...,  0.2723,  0.1490,  3.0000],\n",
              "         [ 0.0993, -0.0582, -0.0463,  ...,  0.3615,  0.0495,  3.0000],\n",
              "         ...,\n",
              "         [-0.1469,  0.0666,  0.2324,  ...,  0.1045,  0.0152,  3.0000],\n",
              "         [-0.2584,  0.0549,  0.2891,  ...,  0.0748, -0.0289,  3.0000],\n",
              "         [-0.3017,  0.0608,  0.2841,  ...,  0.0348, -0.0208,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0364, -0.1441, -0.0406,  ...,  0.0550,  0.2141,  3.0000],\n",
              "         [ 0.1375, -0.0872, -0.0570,  ...,  0.2868,  0.1580,  3.0000],\n",
              "         [ 0.0955, -0.0872, -0.0623,  ...,  0.3771,  0.0823,  3.0000],\n",
              "         ...,\n",
              "         [-0.1582,  0.0348,  0.2286,  ...,  0.1117,  0.0100,  3.0000],\n",
              "         [-0.2625,  0.0380,  0.2652,  ...,  0.0876, -0.0377,  3.0000],\n",
              "         [-0.2981,  0.0413,  0.2702,  ...,  0.0320, -0.0224,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0345, -0.1452, -0.0431,  ...,  0.0551,  0.2147,  3.0000],\n",
              "         [ 0.1363, -0.0908, -0.0623,  ...,  0.2934,  0.1558,  3.0000],\n",
              "         [ 0.0960, -0.0933, -0.0699,  ...,  0.3833,  0.0826,  3.0000],\n",
              "         ...,\n",
              "         [-0.1517,  0.0245,  0.2227,  ...,  0.1220,  0.0105,  3.0000],\n",
              "         [-0.2519,  0.0229,  0.2621,  ...,  0.0921, -0.0304,  3.0000],\n",
              "         [-0.2915,  0.0313,  0.2658,  ...,  0.0393, -0.0243,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0226, -0.1160, -0.0310,  ...,  0.0399,  0.2053,  3.0000],\n",
              "         [ 0.1142, -0.0306, -0.0071,  ...,  0.2341,  0.1003,  3.0000],\n",
              "         [ 0.1239,  0.0380,  0.0129,  ...,  0.3039, -0.0493,  3.0000],\n",
              "         ...,\n",
              "         [-0.0442,  0.1352,  0.2048,  ...,  0.0426,  0.0155,  3.0000],\n",
              "         [-0.2264,  0.1406,  0.3500,  ...,  0.0578, -0.0088,  3.0000],\n",
              "         [-0.2853,  0.1048,  0.3106,  ...,  0.0447,  0.0060,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0110, -0.1126, -0.0440,  ...,  0.0393,  0.2022,  3.0000],\n",
              "         [ 0.1338, -0.0224, -0.0260,  ...,  0.2365,  0.0789,  3.0000],\n",
              "         [ 0.1441,  0.0413, -0.0154,  ...,  0.3039, -0.0708,  3.0000],\n",
              "         ...,\n",
              "         [ 0.0328,  0.1051,  0.1013,  ...,  0.0386,  0.0550,  3.0000],\n",
              "         [-0.1841,  0.1314,  0.3150,  ...,  0.0844,  0.0030,  3.0000],\n",
              "         [-0.2684,  0.0980,  0.2981,  ...,  0.0565,  0.0036,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0364, -0.1527, -0.0531,  ...,  0.0579,  0.2114,  3.0000],\n",
              "         [ 0.1337, -0.1160, -0.0750,  ...,  0.2931,  0.1585,  3.0000],\n",
              "         [ 0.0764, -0.1164, -0.0798,  ...,  0.3943,  0.0798,  3.0000],\n",
              "         ...,\n",
              "         [-0.1590,  0.0093,  0.2007,  ...,  0.1146, -0.0159,  3.0000],\n",
              "         [-0.2424,  0.0238,  0.2117,  ...,  0.0904, -0.0534,  3.0000],\n",
              "         [-0.2737,  0.0102,  0.2430,  ...,  0.0295, -0.0335,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0324, -0.1380, -0.0379,  ...,  0.0532,  0.2098,  3.0000],\n",
              "         [ 0.1398, -0.0761, -0.0552,  ...,  0.2747,  0.1401,  3.0000],\n",
              "         [ 0.1128, -0.0573, -0.0595,  ...,  0.3674,  0.0293,  3.0000],\n",
              "         ...,\n",
              "         [-0.1356,  0.0533,  0.2124,  ...,  0.1082,  0.0160,  3.0000],\n",
              "         [-0.2435,  0.0518,  0.2731,  ...,  0.0772, -0.0258,  3.0000],\n",
              "         [-0.2914,  0.0528,  0.2744,  ...,  0.0413, -0.0228,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4067e-02, -1.2781e-01, -2.2107e-02,  ...,  4.1170e-02,\n",
              "           2.0494e-01,  3.0000e+00],\n",
              "         [ 1.2605e-01, -4.3284e-02,  3.9669e-04,  ...,  2.4760e-01,\n",
              "           1.1379e-01,  3.0000e+00],\n",
              "         [ 1.2716e-01,  2.1888e-02,  1.9522e-02,  ...,  3.3105e-01,\n",
              "          -2.3733e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-9.0492e-02,  1.4003e-01,  2.4978e-01,  ...,  6.7987e-02,\n",
              "          -4.2956e-03,  3.0000e+00],\n",
              "         [-2.4431e-01,  1.3513e-01,  3.5950e-01,  ...,  5.7729e-02,\n",
              "          -2.0924e-02,  3.0000e+00],\n",
              "         [-2.9605e-01,  1.0133e-01,  3.1225e-01,  ...,  4.7629e-02,\n",
              "          -1.1463e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.6624e-02, -1.3171e-01, -2.3197e-02,  ...,  4.2984e-02,\n",
              "           2.0678e-01,  3.0000e+00],\n",
              "         [ 1.2036e-01, -5.4892e-02,  2.9209e-05,  ...,  2.4718e-01,\n",
              "           1.2584e-01,  3.0000e+00],\n",
              "         [ 1.0838e-01, -9.0492e-03,  1.6820e-02,  ...,  3.3186e-01,\n",
              "           1.5783e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3583e-01,  1.3086e-01,  2.6774e-01,  ...,  8.2666e-02,\n",
              "          -1.7246e-02,  3.0000e+00],\n",
              "         [-2.6105e-01,  1.2212e-01,  3.5040e-01,  ...,  6.3691e-02,\n",
              "          -4.0376e-02,  3.0000e+00],\n",
              "         [-3.0393e-01,  9.0918e-02,  3.0948e-01,  ...,  4.5595e-02,\n",
              "          -2.1088e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0331, -0.1363, -0.0365,  ...,  0.0533,  0.2096,  3.0000],\n",
              "         [ 0.1395, -0.0738, -0.0529,  ...,  0.2742,  0.1395,  3.0000],\n",
              "         [ 0.1114, -0.0563, -0.0568,  ...,  0.3640,  0.0315,  3.0000],\n",
              "         ...,\n",
              "         [-0.1400,  0.0624,  0.2194,  ...,  0.1113,  0.0117,  3.0000],\n",
              "         [-0.2483,  0.0570,  0.2775,  ...,  0.0814, -0.0286,  3.0000],\n",
              "         [-0.2933,  0.0590,  0.2775,  ...,  0.0416, -0.0235,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0235, -0.1292, -0.0241,  ...,  0.0423,  0.2072,  3.0000],\n",
              "         [ 0.1237, -0.0473, -0.0033,  ...,  0.2532,  0.1200,  3.0000],\n",
              "         [ 0.1189,  0.0081,  0.0141,  ...,  0.3357, -0.0104,  3.0000],\n",
              "         ...,\n",
              "         [-0.0996,  0.1329,  0.2507,  ...,  0.0838, -0.0102,  3.0000],\n",
              "         [-0.2480,  0.1277,  0.3534,  ...,  0.0661, -0.0282,  3.0000],\n",
              "         [-0.3000,  0.0886,  0.3074,  ...,  0.0493, -0.0155,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0244, -0.1317, -0.0248,  ...,  0.0414,  0.2079,  3.0000],\n",
              "         [ 0.1228, -0.0519, -0.0045,  ...,  0.2443,  0.1281,  3.0000],\n",
              "         [ 0.1105, -0.0075,  0.0148,  ...,  0.3287,  0.0043,  3.0000],\n",
              "         ...,\n",
              "         [-0.1335,  0.1366,  0.2640,  ...,  0.0847, -0.0148,  3.0000],\n",
              "         [-0.2594,  0.1267,  0.3472,  ...,  0.0625, -0.0368,  3.0000],\n",
              "         [-0.3022,  0.0871,  0.3060,  ...,  0.0470, -0.0241,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.5940e-02, -1.2967e-01, -2.6534e-02,  ...,  4.1384e-02,\n",
              "           2.0723e-01,  3.0000e+00],\n",
              "         [ 1.1724e-01, -5.0658e-02, -1.1270e-03,  ...,  2.4257e-01,\n",
              "           1.2072e-01,  3.0000e+00],\n",
              "         [ 1.1646e-01,  4.4752e-03,  1.6384e-02,  ...,  3.2417e-01,\n",
              "          -1.6181e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.2444e-01,  1.4158e-01,  2.7152e-01,  ...,  6.2908e-02,\n",
              "          -1.7456e-02,  3.0000e+00],\n",
              "         [-2.5431e-01,  1.3391e-01,  3.5778e-01,  ...,  5.7755e-02,\n",
              "          -3.5178e-02,  3.0000e+00],\n",
              "         [-2.9603e-01,  9.9539e-02,  3.0957e-01,  ...,  4.1374e-02,\n",
              "          -8.8377e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0334, -0.1563, -0.0575,  ...,  0.0615,  0.2120,  3.0000],\n",
              "         [ 0.1422, -0.1143, -0.0792,  ...,  0.3060,  0.1549,  3.0000],\n",
              "         [ 0.0873, -0.1161, -0.0856,  ...,  0.4092,  0.0782,  3.0000],\n",
              "         ...,\n",
              "         [-0.1547,  0.0150,  0.1993,  ...,  0.1211, -0.0280,  3.0000],\n",
              "         [-0.2256,  0.0251,  0.2023,  ...,  0.0966, -0.0526,  3.0000],\n",
              "         [-0.2642,  0.0098,  0.2343,  ...,  0.0360, -0.0292,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0173, -0.1248, -0.0335,  ...,  0.0394,  0.2051,  3.0000],\n",
              "         [ 0.1259, -0.0303, -0.0095,  ...,  0.2415,  0.1024,  3.0000],\n",
              "         [ 0.1309,  0.0355,  0.0091,  ...,  0.3181, -0.0448,  3.0000],\n",
              "         ...,\n",
              "         [-0.0305,  0.1319,  0.1852,  ...,  0.0574,  0.0101,  3.0000],\n",
              "         [-0.2181,  0.1297,  0.3340,  ...,  0.0658, -0.0144,  3.0000],\n",
              "         [-0.2751,  0.0988,  0.2988,  ...,  0.0499, -0.0058,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0070, -0.1195, -0.0447,  ...,  0.0445,  0.2108,  3.0000],\n",
              "         [ 0.1241, -0.0374, -0.0256,  ...,  0.2375,  0.1095,  3.0000],\n",
              "         [ 0.1318,  0.0307, -0.0163,  ...,  0.3132, -0.0466,  3.0000],\n",
              "         ...,\n",
              "         [-0.0426,  0.1358,  0.1705,  ...,  0.0706,  0.0199,  3.0000],\n",
              "         [-0.2244,  0.1284,  0.3252,  ...,  0.0826, -0.0077,  3.0000],\n",
              "         [-0.2654,  0.0923,  0.2977,  ...,  0.0690,  0.0092,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.8900e-02, -1.1593e-01, -3.3722e-02,  ...,  3.8674e-02,\n",
              "           2.0398e-01,  3.0000e+00],\n",
              "         [ 1.2101e-01, -2.5973e-02, -8.7945e-03,  ...,  2.3388e-01,\n",
              "           9.9757e-02,  3.0000e+00],\n",
              "         [ 1.2843e-01,  4.2512e-02,  1.3251e-02,  ...,  3.0807e-01,\n",
              "          -4.9465e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-2.9447e-02,  1.3227e-01,  1.8275e-01,  ...,  4.4795e-02,\n",
              "           2.9142e-02,  3.0000e+00],\n",
              "         [-2.1575e-01,  1.3203e-01,  3.4158e-01,  ...,  5.9500e-02,\n",
              "          -1.1346e-03,  3.0000e+00],\n",
              "         [-2.7643e-01,  1.0547e-01,  3.0098e-01,  ...,  4.4647e-02,\n",
              "           4.2157e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-3.0710e-02, -1.3147e-01, -3.4214e-02,  ...,  5.1490e-02,\n",
              "           2.0855e-01,  3.0000e+00],\n",
              "         [ 1.3940e-01, -6.2156e-02, -4.0145e-02,  ...,  2.7038e-01,\n",
              "           1.4079e-01,  3.0000e+00],\n",
              "         [ 1.1788e-01, -3.9212e-02, -3.7540e-02,  ...,  3.5985e-01,\n",
              "           3.1624e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.4474e-01,  9.2137e-02,  2.3893e-01,  ...,  1.0664e-01,\n",
              "           3.3763e-05,  3.0000e+00],\n",
              "         [-2.5478e-01,  7.4982e-02,  2.9777e-01,  ...,  7.9227e-02,\n",
              "          -3.1370e-02,  3.0000e+00],\n",
              "         [-2.9698e-01,  6.9363e-02,  2.8607e-01,  ...,  4.3452e-02,\n",
              "          -2.6102e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0305, -0.1366, -0.0371,  ...,  0.0546,  0.2085,  3.0000],\n",
              "         [ 0.1462, -0.0756, -0.0520,  ...,  0.2833,  0.1378,  3.0000],\n",
              "         [ 0.1208, -0.0569, -0.0562,  ...,  0.3736,  0.0338,  3.0000],\n",
              "         ...,\n",
              "         [-0.1268,  0.0611,  0.2163,  ...,  0.1138,  0.0076,  3.0000],\n",
              "         [-0.2384,  0.0556,  0.2775,  ...,  0.0842, -0.0284,  3.0000],\n",
              "         [-0.2899,  0.0624,  0.2744,  ...,  0.0450, -0.0211,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0193, -0.1274, -0.0309,  ...,  0.0399,  0.2033,  3.0000],\n",
              "         [ 0.1276, -0.0390, -0.0083,  ...,  0.2494,  0.1075,  3.0000],\n",
              "         [ 0.1256,  0.0218,  0.0089,  ...,  0.3331, -0.0337,  3.0000],\n",
              "         ...,\n",
              "         [-0.0439,  0.1217,  0.2008,  ...,  0.0717,  0.0066,  3.0000],\n",
              "         [-0.2310,  0.1255,  0.3404,  ...,  0.0667, -0.0155,  3.0000],\n",
              "         [-0.2839,  0.0993,  0.2975,  ...,  0.0469, -0.0057,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0252, -0.1205, -0.0253,  ...,  0.0390,  0.2056,  3.0000],\n",
              "         [ 0.1163, -0.0280,  0.0067,  ...,  0.2304,  0.1056,  3.0000],\n",
              "         [ 0.1233,  0.0389,  0.0260,  ...,  0.2984, -0.0375,  3.0000],\n",
              "         ...,\n",
              "         [-0.0511,  0.1401,  0.2212,  ...,  0.0341,  0.0103,  3.0000],\n",
              "         [-0.2328,  0.1326,  0.3623,  ...,  0.0445, -0.0140,  3.0000],\n",
              "         [-0.2853,  0.1088,  0.3120,  ...,  0.0376,  0.0044,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.0450e-02, -1.2690e-01, -2.8222e-02,  ...,  4.4398e-02,\n",
              "           2.1522e-01,  3.0000e+00],\n",
              "         [ 1.3948e-01, -3.7686e-02,  2.2645e-03,  ...,  2.1393e-01,\n",
              "           1.3095e-01,  3.0000e+00],\n",
              "         [ 1.2443e-01,  1.9759e-02,  2.3167e-02,  ...,  2.9275e-01,\n",
              "          -1.2103e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.0558e-01,  1.7179e-01,  2.5143e-01,  ...,  3.8062e-02,\n",
              "           2.1945e-03,  3.0000e+00],\n",
              "         [-2.4670e-01,  1.4977e-01,  3.3919e-01,  ...,  4.1720e-02,\n",
              "          -2.0381e-02,  3.0000e+00],\n",
              "         [-2.7823e-01,  1.1068e-01,  2.9886e-01,  ...,  5.8029e-02,\n",
              "          -3.9690e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0256, -0.1326, -0.0274,  ...,  0.0473,  0.2073,  3.0000],\n",
              "         [ 0.1253, -0.0607, -0.0124,  ...,  0.2647,  0.1287,  3.0000],\n",
              "         [ 0.1088, -0.0266, -0.0037,  ...,  0.3554,  0.0103,  3.0000],\n",
              "         ...,\n",
              "         [-0.1217,  0.1211,  0.2459,  ...,  0.0915, -0.0116,  3.0000],\n",
              "         [-0.2515,  0.1146,  0.3298,  ...,  0.0737, -0.0372,  3.0000],\n",
              "         [-0.2981,  0.0913,  0.2968,  ...,  0.0447, -0.0139,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0336, -0.1538, -0.0564,  ...,  0.0591,  0.2045,  3.0000],\n",
              "         [ 0.1283, -0.1173, -0.0665,  ...,  0.2779,  0.1592,  3.0000],\n",
              "         [ 0.0657, -0.1154, -0.0687,  ...,  0.3794,  0.0853,  3.0000],\n",
              "         ...,\n",
              "         [-0.1940,  0.0276,  0.1998,  ...,  0.0895, -0.0450,  3.0000],\n",
              "         [-0.2640,  0.0484,  0.2048,  ...,  0.0778, -0.0730,  3.0000],\n",
              "         [-0.2660,  0.0303,  0.2380,  ...,  0.0194, -0.0382,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.4393e-02, -1.2508e-01, -2.5924e-02,  ...,  3.9791e-02,\n",
              "           2.0784e-01,  3.0000e+00],\n",
              "         [ 1.1387e-01, -4.1586e-02,  3.0874e-03,  ...,  2.3293e-01,\n",
              "           1.1651e-01,  3.0000e+00],\n",
              "         [ 1.1704e-01,  1.8336e-02,  2.3665e-02,  ...,  3.0825e-01,\n",
              "          -2.8995e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-7.7524e-02,  1.4126e-01,  2.4061e-01,  ...,  5.2111e-02,\n",
              "          -1.9820e-03,  3.0000e+00],\n",
              "         [-2.4403e-01,  1.3789e-01,  3.5879e-01,  ...,  5.2706e-02,\n",
              "          -2.2694e-02,  3.0000e+00],\n",
              "         [-2.9394e-01,  1.0249e-01,  3.1130e-01,  ...,  4.0662e-02,\n",
              "          -2.3230e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0285, -0.1542, -0.0588,  ...,  0.0584,  0.1992,  3.0000],\n",
              "         [ 0.1290, -0.1235, -0.0670,  ...,  0.2696,  0.1607,  3.0000],\n",
              "         [ 0.0666, -0.1207, -0.0714,  ...,  0.3698,  0.0928,  3.0000],\n",
              "         ...,\n",
              "         [-0.2033,  0.0306,  0.1865,  ...,  0.0742, -0.0629,  3.0000],\n",
              "         [-0.2614,  0.0445,  0.1994,  ...,  0.0678, -0.0760,  3.0000],\n",
              "         [-0.2543,  0.0263,  0.2330,  ...,  0.0101, -0.0456,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-3.0322e-02, -1.3031e-01, -3.5478e-02,  ...,  5.3315e-02,\n",
              "           2.0903e-01,  3.0000e+00],\n",
              "         [ 1.3837e-01, -6.6467e-02, -4.5572e-02,  ...,  2.7017e-01,\n",
              "           1.4073e-01,  3.0000e+00],\n",
              "         [ 1.1791e-01, -4.3036e-02, -4.4754e-02,  ...,  3.6467e-01,\n",
              "           2.4525e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.4065e-01,  7.7551e-02,  2.2470e-01,  ...,  1.1358e-01,\n",
              "           2.6747e-03,  3.0000e+00],\n",
              "         [-2.5269e-01,  7.0820e-02,  2.8798e-01,  ...,  8.1739e-02,\n",
              "          -3.2684e-02,  3.0000e+00],\n",
              "         [-2.9636e-01,  6.4292e-02,  2.8074e-01,  ...,  4.4892e-02,\n",
              "          -2.5873e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0330, -0.1412, -0.0377,  ...,  0.0542,  0.2132,  3.0000],\n",
              "         [ 0.1417, -0.0822, -0.0587,  ...,  0.2857,  0.1508,  3.0000],\n",
              "         [ 0.1048, -0.0698, -0.0640,  ...,  0.3805,  0.0510,  3.0000],\n",
              "         ...,\n",
              "         [-0.1346,  0.0409,  0.2174,  ...,  0.1144,  0.0192,  3.0000],\n",
              "         [-0.2445,  0.0390,  0.2743,  ...,  0.0863, -0.0269,  3.0000],\n",
              "         [-0.2942,  0.0498,  0.2732,  ...,  0.0400, -0.0191,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0225, -0.1272, -0.0273,  ...,  0.0386,  0.2062,  3.0000],\n",
              "         [ 0.1187, -0.0408, -0.0032,  ...,  0.2439,  0.1135,  3.0000],\n",
              "         [ 0.1186,  0.0211,  0.0134,  ...,  0.3233, -0.0243,  3.0000],\n",
              "         ...,\n",
              "         [-0.0715,  0.1337,  0.2286,  ...,  0.0757, -0.0053,  3.0000],\n",
              "         [-0.2413,  0.1321,  0.3579,  ...,  0.0602, -0.0262,  3.0000],\n",
              "         [-0.2964,  0.0932,  0.3103,  ...,  0.0456, -0.0165,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.8681e-02, -1.1690e-01, -3.3126e-02,  ...,  3.9418e-02,\n",
              "           2.0391e-01,  3.0000e+00],\n",
              "         [ 1.2300e-01, -2.8095e-02, -7.9890e-03,  ...,  2.3766e-01,\n",
              "           9.3033e-02,  3.0000e+00],\n",
              "         [ 1.3052e-01,  3.8600e-02,  9.8239e-03,  ...,  3.0653e-01,\n",
              "          -5.4359e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-6.7726e-03,  1.3253e-01,  1.6696e-01,  ...,  4.6570e-02,\n",
              "           2.9175e-02,  3.0000e+00],\n",
              "         [-2.1173e-01,  1.3424e-01,  3.3068e-01,  ...,  6.7436e-02,\n",
              "          -3.9693e-03,  3.0000e+00],\n",
              "         [-2.7349e-01,  1.0399e-01,  2.9796e-01,  ...,  4.3195e-02,\n",
              "           2.4692e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0329, -0.1405, -0.0355,  ...,  0.0488,  0.2110,  3.0000],\n",
              "         [ 0.1308, -0.0780, -0.0494,  ...,  0.2667,  0.1533,  3.0000],\n",
              "         [ 0.0955, -0.0657, -0.0547,  ...,  0.3581,  0.0554,  3.0000],\n",
              "         ...,\n",
              "         [-0.1475,  0.0589,  0.2268,  ...,  0.1187,  0.0196,  3.0000],\n",
              "         [-0.2605,  0.0519,  0.2881,  ...,  0.0856, -0.0295,  3.0000],\n",
              "         [-0.2998,  0.0516,  0.2829,  ...,  0.0390, -0.0266,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0343, -0.1453, -0.0418,  ...,  0.0530,  0.2112,  3.0000],\n",
              "         [ 0.1384, -0.0879, -0.0519,  ...,  0.2809,  0.1549,  3.0000],\n",
              "         [ 0.1008, -0.0889, -0.0582,  ...,  0.3688,  0.0829,  3.0000],\n",
              "         ...,\n",
              "         [-0.1572,  0.0392,  0.2301,  ...,  0.1077,  0.0073,  3.0000],\n",
              "         [-0.2592,  0.0387,  0.2688,  ...,  0.0842, -0.0382,  3.0000],\n",
              "         [-0.2944,  0.0458,  0.2727,  ...,  0.0288, -0.0174,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.9736e-02, -1.2636e-01, -2.8383e-02,  ...,  4.9749e-02,\n",
              "           2.0504e-01,  3.0000e+00],\n",
              "         [ 1.2728e-01, -5.8054e-02, -1.8573e-02,  ...,  2.4937e-01,\n",
              "           1.3403e-01,  3.0000e+00],\n",
              "         [ 1.1393e-01, -2.2796e-02, -2.4177e-03,  ...,  3.4188e-01,\n",
              "           9.1066e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.5485e-01,  1.3074e-01,  2.6606e-01,  ...,  8.1114e-02,\n",
              "          -1.8045e-02,  3.0000e+00],\n",
              "         [-2.6603e-01,  1.1943e-01,  3.2811e-01,  ...,  7.1169e-02,\n",
              "          -4.0097e-02,  3.0000e+00],\n",
              "         [-3.0388e-01,  9.3908e-02,  2.9870e-01,  ...,  4.3576e-02,\n",
              "          -1.6059e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.2153e-02, -1.3621e-01, -3.0032e-02,  ...,  5.0957e-02,\n",
              "           2.1198e-01,  3.0000e+00],\n",
              "         [ 1.3759e-01, -5.0630e-02, -1.2462e-02,  ...,  2.6280e-01,\n",
              "           1.3262e-01,  3.0000e+00],\n",
              "         [ 1.2527e-01, -1.1560e-02,  7.5824e-03,  ...,  3.4904e-01,\n",
              "           2.8961e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.1463e-01,  1.1994e-01,  2.3578e-01,  ...,  8.4176e-02,\n",
              "          -1.5109e-02,  3.0000e+00],\n",
              "         [-2.4159e-01,  1.1024e-01,  3.1554e-01,  ...,  7.0506e-02,\n",
              "          -3.4910e-02,  3.0000e+00],\n",
              "         [-2.8947e-01,  9.1371e-02,  2.8726e-01,  ...,  5.2136e-02,\n",
              "          -1.1692e-02,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.6758e-02, -1.2144e-01, -2.4976e-02,  ...,  3.9315e-02,\n",
              "           2.0475e-01,  3.0000e+00],\n",
              "         [ 1.1501e-01, -3.0666e-02,  6.7479e-03,  ...,  2.3188e-01,\n",
              "           1.0535e-01,  3.0000e+00],\n",
              "         [ 1.2411e-01,  3.5175e-02,  2.5351e-02,  ...,  2.9919e-01,\n",
              "          -3.8933e-02,  3.0000e+00],\n",
              "         ...,\n",
              "         [-7.1413e-02,  1.4317e-01,  2.3524e-01,  ...,  4.0792e-02,\n",
              "          -9.6720e-03,  3.0000e+00],\n",
              "         [-2.4094e-01,  1.3704e-01,  3.6336e-01,  ...,  4.2063e-02,\n",
              "          -2.5009e-02,  3.0000e+00],\n",
              "         [-2.8918e-01,  1.1136e-01,  3.1448e-01,  ...,  3.8137e-02,\n",
              "           2.5600e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-2.3554e-02, -1.3198e-01, -2.4685e-02,  ...,  4.7738e-02,\n",
              "           2.1523e-01,  3.0000e+00],\n",
              "         [ 1.4169e-01, -4.8132e-02,  6.3132e-04,  ...,  2.2586e-01,\n",
              "           1.3958e-01,  3.0000e+00],\n",
              "         [ 1.2606e-01,  2.7452e-03,  2.6765e-02,  ...,  3.0451e-01,\n",
              "           3.2626e-03,  3.0000e+00],\n",
              "         ...,\n",
              "         [-1.3868e-01,  1.5677e-01,  2.7553e-01,  ...,  4.3875e-02,\n",
              "          -7.5639e-03,  3.0000e+00],\n",
              "         [-2.5316e-01,  1.3603e-01,  3.4077e-01,  ...,  4.8525e-02,\n",
              "          -2.9440e-02,  3.0000e+00],\n",
              "         [-2.8656e-01,  1.0023e-01,  3.0120e-01,  ...,  5.5361e-02,\n",
              "          -7.3919e-03,  3.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0332, -0.1243, -0.0329,  ...,  0.0547,  0.2059,  3.0000],\n",
              "         [ 0.1255, -0.0661, -0.0317,  ...,  0.2574,  0.1359,  3.0000],\n",
              "         [ 0.1075, -0.0376, -0.0267,  ...,  0.3535,  0.0186,  3.0000],\n",
              "         ...,\n",
              "         [-0.1526,  0.1091,  0.2542,  ...,  0.0977, -0.0163,  3.0000],\n",
              "         [-0.2691,  0.0968,  0.3136,  ...,  0.0776, -0.0420,  3.0000],\n",
              "         [-0.3038,  0.0893,  0.2889,  ...,  0.0350, -0.0186,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0343, -0.1418, -0.0374,  ...,  0.0531,  0.2131,  3.0000],\n",
              "         [ 0.1368, -0.0814, -0.0608,  ...,  0.2795,  0.1542,  3.0000],\n",
              "         [ 0.0984, -0.0695, -0.0670,  ...,  0.3728,  0.0555,  3.0000],\n",
              "         ...,\n",
              "         [-0.1564,  0.0539,  0.2309,  ...,  0.1064,  0.0137,  3.0000],\n",
              "         [-0.2547,  0.0447,  0.2793,  ...,  0.0807, -0.0272,  3.0000],\n",
              "         [-0.2961,  0.0425,  0.2785,  ...,  0.0418, -0.0248,  3.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0070, -0.1212, -0.0587,  ...,  0.0336,  0.2134,  0.0000],\n",
              "         [ 0.1857, -0.0412, -0.0447,  ...,  0.2211,  0.0542,  0.0000],\n",
              "         [ 0.1800, -0.0013, -0.0413,  ...,  0.2971, -0.0870,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0778,  0.0691,  0.0914,  ...,  0.0353,  0.0287,  0.0000],\n",
              "         [-0.1390,  0.1152,  0.2906,  ...,  0.0874, -0.0190,  0.0000],\n",
              "         [-0.2610,  0.0781,  0.2947,  ...,  0.0613, -0.0049,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0860, -0.2331, -0.1449,  ..., -0.0684,  0.1818,  0.0000],\n",
              "         [ 0.2863, -0.0401, -0.0284,  ..., -0.0793,  0.0730,  0.0000],\n",
              "         [ 0.3092, -0.0282, -0.0348,  ..., -0.0257,  0.0683,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1963, -0.0592, -0.0743,  ..., -0.0244,  0.1273,  0.0000],\n",
              "         [ 0.1136, -0.0257,  0.0637,  ...,  0.0121,  0.0825,  0.0000],\n",
              "         [-0.0595, -0.0461,  0.2554,  ..., -0.0704,  0.0859,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0729, -0.2285, -0.1411,  ..., -0.0474,  0.1851,  0.0000],\n",
              "         [ 0.2842, -0.0298, -0.0298,  ..., -0.0564,  0.0526,  0.0000],\n",
              "         [ 0.3068, -0.0111, -0.0347,  ...,  0.0069,  0.0417,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1785, -0.0296, -0.0665,  ...,  0.0204,  0.0978,  0.0000],\n",
              "         [ 0.0836, -0.0036,  0.0770,  ...,  0.0496,  0.0515,  0.0000],\n",
              "         [-0.0801, -0.0268,  0.2663,  ..., -0.0369,  0.0664,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0311, -0.1388, -0.0334,  ...,  0.0575,  0.2158,  0.0000],\n",
              "         [ 0.1615, -0.0696, -0.0353,  ...,  0.2866,  0.1465,  0.0000],\n",
              "         [ 0.1298, -0.0506, -0.0289,  ...,  0.3718,  0.0433,  0.0000],\n",
              "         ...,\n",
              "         [-0.1628,  0.0655,  0.2592,  ...,  0.0887, -0.0175,  0.0000],\n",
              "         [-0.2451,  0.0615,  0.2787,  ...,  0.0805, -0.0453,  0.0000],\n",
              "         [-0.2779,  0.0667,  0.2786,  ...,  0.0489, -0.0158,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0142, -0.1259, -0.0554,  ...,  0.0449,  0.2063,  0.0000],\n",
              "         [ 0.1856, -0.0223, -0.0541,  ...,  0.2445,  0.0539,  0.0000],\n",
              "         [ 0.2005,  0.0297, -0.0458,  ...,  0.3137, -0.0855,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0837,  0.0732,  0.0564,  ...,  0.0599,  0.0623,  0.0000],\n",
              "         [-0.1204,  0.1072,  0.2545,  ...,  0.0845,  0.0043,  0.0000],\n",
              "         [-0.2302,  0.0863,  0.2631,  ...,  0.0676, -0.0018,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0024, -0.1112, -0.0440,  ...,  0.0357,  0.2098,  0.0000],\n",
              "         [ 0.1403, -0.0133, -0.0120,  ...,  0.2223,  0.0963,  0.0000],\n",
              "         [ 0.1493,  0.0504,  0.0026,  ...,  0.2967, -0.0594,  0.0000],\n",
              "         ...,\n",
              "         [-0.0184,  0.1459,  0.1745,  ...,  0.0481,  0.0194,  0.0000],\n",
              "         [-0.2059,  0.1391,  0.3252,  ...,  0.0682, -0.0053,  0.0000],\n",
              "         [-0.2702,  0.0977,  0.2983,  ...,  0.0505, -0.0039,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0130, -0.1172, -0.0346,  ...,  0.0328,  0.2104,  0.0000],\n",
              "         [ 0.1266, -0.0231, -0.0045,  ...,  0.2169,  0.1112,  0.0000],\n",
              "         [ 0.1348,  0.0464,  0.0172,  ...,  0.2894, -0.0403,  0.0000],\n",
              "         ...,\n",
              "         [-0.0585,  0.1432,  0.2123,  ...,  0.0397,  0.0141,  0.0000],\n",
              "         [-0.2229,  0.1401,  0.3378,  ...,  0.0478, -0.0051,  0.0000],\n",
              "         [-0.2773,  0.1006,  0.3020,  ...,  0.0398,  0.0026,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0185, -0.1223, -0.0275,  ...,  0.0413,  0.2088,  0.0000],\n",
              "         [ 0.1388, -0.0204,  0.0011,  ...,  0.2464,  0.1112,  0.0000],\n",
              "         [ 0.1435,  0.0453,  0.0205,  ...,  0.3169, -0.0318,  0.0000],\n",
              "         ...,\n",
              "         [-0.0272,  0.1266,  0.2000,  ...,  0.0523,  0.0187,  0.0000],\n",
              "         [-0.2197,  0.1248,  0.3503,  ...,  0.0594, -0.0091,  0.0000],\n",
              "         [-0.2756,  0.1046,  0.3057,  ...,  0.0482,  0.0018,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0190, -0.1190, -0.0312,  ...,  0.0334,  0.2132,  0.0000],\n",
              "         [ 0.1203, -0.0295,  0.0074,  ...,  0.2210,  0.1230,  0.0000],\n",
              "         [ 0.1260,  0.0373,  0.0239,  ...,  0.2904, -0.0168,  0.0000],\n",
              "         ...,\n",
              "         [-0.1090,  0.1610,  0.2645,  ...,  0.0464,  0.0096,  0.0000],\n",
              "         [-0.2363,  0.1446,  0.3456,  ...,  0.0490, -0.0113,  0.0000],\n",
              "         [-0.2840,  0.1017,  0.3026,  ...,  0.0403,  0.0042,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0265, -0.1332, -0.0252,  ...,  0.0484,  0.2152,  0.0000],\n",
              "         [ 0.1414, -0.0517,  0.0005,  ...,  0.2533,  0.1348,  0.0000],\n",
              "         [ 0.1313, -0.0163,  0.0258,  ...,  0.3307,  0.0134,  0.0000],\n",
              "         ...,\n",
              "         [-0.1661,  0.1385,  0.2946,  ...,  0.0683, -0.0316,  0.0000],\n",
              "         [-0.2526,  0.1185,  0.3346,  ...,  0.0662, -0.0414,  0.0000],\n",
              "         [-0.2883,  0.0936,  0.3010,  ...,  0.0522, -0.0156,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0180, -0.1200, -0.0315,  ...,  0.0446,  0.2178,  0.0000],\n",
              "         [ 0.1313, -0.0394,  0.0035,  ...,  0.2358,  0.1220,  0.0000],\n",
              "         [ 0.1309,  0.0132,  0.0229,  ...,  0.3055, -0.0286,  0.0000],\n",
              "         ...,\n",
              "         [-0.0618,  0.1626,  0.2270,  ...,  0.0489,  0.0039,  0.0000],\n",
              "         [-0.2224,  0.1446,  0.3384,  ...,  0.0642, -0.0117,  0.0000],\n",
              "         [-0.2739,  0.1047,  0.3019,  ...,  0.0617,  0.0006,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0352, -0.1494, -0.0464,  ...,  0.0620,  0.2135,  0.0000],\n",
              "         [ 0.1421, -0.1079, -0.0583,  ...,  0.2900,  0.1613,  0.0000],\n",
              "         [ 0.0858, -0.0994, -0.0596,  ...,  0.3964,  0.0750,  0.0000],\n",
              "         ...,\n",
              "         [-0.1880,  0.0212,  0.2248,  ...,  0.0901, -0.0388,  0.0000],\n",
              "         [-0.2575,  0.0419,  0.2258,  ...,  0.0792, -0.0620,  0.0000],\n",
              "         [-0.2676,  0.0285,  0.2503,  ...,  0.0304, -0.0304,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0218, -0.1235, -0.0282,  ...,  0.0439,  0.2167,  0.0000],\n",
              "         [ 0.1289, -0.0400,  0.0112,  ...,  0.2408,  0.1281,  0.0000],\n",
              "         [ 0.1302,  0.0120,  0.0324,  ...,  0.3112, -0.0135,  0.0000],\n",
              "         ...,\n",
              "         [-0.1115,  0.1589,  0.2701,  ...,  0.0610, -0.0089,  0.0000],\n",
              "         [-0.2382,  0.1441,  0.3524,  ...,  0.0599, -0.0222,  0.0000],\n",
              "         [-0.2849,  0.1009,  0.3091,  ...,  0.0552, -0.0040,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0199, -0.1218, -0.0271,  ...,  0.0433,  0.2165,  0.0000],\n",
              "         [ 0.1315, -0.0397,  0.0105,  ...,  0.2377,  0.1273,  0.0000],\n",
              "         [ 0.1316,  0.0144,  0.0327,  ...,  0.3080, -0.0158,  0.0000],\n",
              "         ...,\n",
              "         [-0.0995,  0.1606,  0.2622,  ...,  0.0577, -0.0036,  0.0000],\n",
              "         [-0.2334,  0.1448,  0.3497,  ...,  0.0600, -0.0176,  0.0000],\n",
              "         [-0.2824,  0.1023,  0.3086,  ...,  0.0568, -0.0033,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0128, -0.1158, -0.0370,  ...,  0.0331,  0.2132,  0.0000],\n",
              "         [ 0.1270, -0.0208, -0.0060,  ...,  0.2153,  0.1100,  0.0000],\n",
              "         [ 0.1408,  0.0482,  0.0127,  ...,  0.2849, -0.0441,  0.0000],\n",
              "         ...,\n",
              "         [-0.0673,  0.1395,  0.2173,  ...,  0.0391,  0.0190,  0.0000],\n",
              "         [-0.2251,  0.1358,  0.3402,  ...,  0.0532, -0.0007,  0.0000],\n",
              "         [-0.2781,  0.1006,  0.3049,  ...,  0.0441,  0.0062,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2443e-02, -1.2904e-01, -2.6325e-02,  ...,  4.0578e-02,\n",
              "           2.1095e-01,  0.0000e+00],\n",
              "         [ 1.2964e-01, -4.6845e-02,  4.3934e-03,  ...,  2.4597e-01,\n",
              "           1.2799e-01,  0.0000e+00],\n",
              "         [ 1.2302e-01,  2.4515e-03,  2.2316e-02,  ...,  3.2389e-01,\n",
              "           1.0386e-04,  0.0000e+00],\n",
              "         ...,\n",
              "         [-1.5631e-01,  1.3721e-01,  2.9257e-01,  ...,  6.4346e-02,\n",
              "          -2.0816e-02,  0.0000e+00],\n",
              "         [-2.4935e-01,  1.2404e-01,  3.4923e-01,  ...,  5.8915e-02,\n",
              "          -3.3644e-02,  0.0000e+00],\n",
              "         [-2.9302e-01,  9.3219e-02,  3.0493e-01,  ...,  4.4513e-02,\n",
              "          -9.1419e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0156, -0.1490, -0.0620,  ...,  0.0443,  0.1765,  0.0000],\n",
              "         [ 0.1071, -0.1259, -0.0469,  ...,  0.2185,  0.1517,  0.0000],\n",
              "         [ 0.0432, -0.1278, -0.0671,  ...,  0.3040,  0.1045,  0.0000],\n",
              "         ...,\n",
              "         [-0.2133,  0.0437,  0.2437,  ..., -0.0539, -0.0919,  0.0000],\n",
              "         [-0.2505,  0.0694,  0.2446,  ..., -0.0466, -0.0877,  0.0000],\n",
              "         [-0.1949,  0.0683,  0.2496,  ..., -0.0488, -0.0685,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0212, -0.1354, -0.0300,  ...,  0.0440,  0.2147,  0.0000],\n",
              "         [ 0.1409, -0.0524, -0.0105,  ...,  0.2589,  0.1381,  0.0000],\n",
              "         [ 0.1258, -0.0103,  0.0064,  ...,  0.3464,  0.0143,  0.0000],\n",
              "         ...,\n",
              "         [-0.1517,  0.1143,  0.2716,  ...,  0.0686, -0.0154,  0.0000],\n",
              "         [-0.2380,  0.0975,  0.3148,  ...,  0.0640, -0.0304,  0.0000],\n",
              "         [-0.2883,  0.0803,  0.2925,  ...,  0.0519, -0.0152,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0327, -0.1523, -0.0534,  ...,  0.0573,  0.1984,  0.0000],\n",
              "         [ 0.1234, -0.1188, -0.0562,  ...,  0.2702,  0.1541,  0.0000],\n",
              "         [ 0.0613, -0.1152, -0.0627,  ...,  0.3646,  0.0882,  0.0000],\n",
              "         ...,\n",
              "         [-0.2282,  0.0314,  0.2060,  ...,  0.0702, -0.0707,  0.0000],\n",
              "         [-0.2730,  0.0445,  0.2052,  ...,  0.0590, -0.0727,  0.0000],\n",
              "         [-0.2578,  0.0281,  0.2375,  ...,  0.0101, -0.0432,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0340, -0.1484, -0.0440,  ...,  0.0600,  0.2164,  0.0000],\n",
              "         [ 0.1503, -0.1008, -0.0569,  ...,  0.2928,  0.1602,  0.0000],\n",
              "         [ 0.0979, -0.0953, -0.0570,  ...,  0.3954,  0.0696,  0.0000],\n",
              "         ...,\n",
              "         [-0.1696,  0.0176,  0.2332,  ...,  0.0930, -0.0244,  0.0000],\n",
              "         [-0.2468,  0.0319,  0.2376,  ...,  0.0807, -0.0483,  0.0000],\n",
              "         [-0.2695,  0.0302,  0.2576,  ...,  0.0353, -0.0203,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0318, -0.1498, -0.0454,  ...,  0.0535,  0.2148,  0.0000],\n",
              "         [ 0.1476, -0.0943, -0.0545,  ...,  0.2816,  0.1638,  0.0000],\n",
              "         [ 0.1011, -0.0965, -0.0555,  ...,  0.3726,  0.0918,  0.0000],\n",
              "         ...,\n",
              "         [-0.1716,  0.0099,  0.2352,  ...,  0.0912, -0.0141,  0.0000],\n",
              "         [-0.2464,  0.0164,  0.2423,  ...,  0.0749, -0.0391,  0.0000],\n",
              "         [-0.2736,  0.0247,  0.2579,  ...,  0.0303, -0.0197,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0320, -0.1442, -0.0346,  ...,  0.0568,  0.2167,  0.0000],\n",
              "         [ 0.1605, -0.0807, -0.0425,  ...,  0.2887,  0.1548,  0.0000],\n",
              "         [ 0.1199, -0.0671, -0.0362,  ...,  0.3763,  0.0576,  0.0000],\n",
              "         ...,\n",
              "         [-0.1650,  0.0472,  0.2567,  ...,  0.0941, -0.0108,  0.0000],\n",
              "         [-0.2454,  0.0480,  0.2714,  ...,  0.0824, -0.0419,  0.0000],\n",
              "         [-0.2778,  0.0537,  0.2752,  ...,  0.0444, -0.0147,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0300, -0.1472, -0.0367,  ...,  0.0569,  0.2176,  0.0000],\n",
              "         [ 0.1633, -0.0842, -0.0462,  ...,  0.2885,  0.1565,  0.0000],\n",
              "         [ 0.1234, -0.0707, -0.0415,  ...,  0.3769,  0.0590,  0.0000],\n",
              "         ...,\n",
              "         [-0.1546,  0.0411,  0.2457,  ...,  0.0954, -0.0071,  0.0000],\n",
              "         [-0.2393,  0.0453,  0.2647,  ...,  0.0829, -0.0423,  0.0000],\n",
              "         [-0.2737,  0.0489,  0.2702,  ...,  0.0441, -0.0174,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0029, -0.1163, -0.0549,  ...,  0.0362,  0.2137,  0.0000],\n",
              "         [ 0.1721, -0.0303, -0.0383,  ...,  0.2215,  0.0660,  0.0000],\n",
              "         [ 0.1686,  0.0094, -0.0310,  ...,  0.2988, -0.0793,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0576,  0.0950,  0.1043,  ...,  0.0301,  0.0319,  0.0000],\n",
              "         [-0.1553,  0.1285,  0.2982,  ...,  0.0810, -0.0123,  0.0000],\n",
              "         [-0.2603,  0.0858,  0.2936,  ...,  0.0611, -0.0053,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0261, -0.1347, -0.0256,  ...,  0.0495,  0.2159,  0.0000],\n",
              "         [ 0.1429, -0.0538, -0.0021,  ...,  0.2601,  0.1348,  0.0000],\n",
              "         [ 0.1316, -0.0188,  0.0222,  ...,  0.3385,  0.0130,  0.0000],\n",
              "         ...,\n",
              "         [-0.1613,  0.1361,  0.2869,  ...,  0.0739, -0.0324,  0.0000],\n",
              "         [-0.2491,  0.1157,  0.3278,  ...,  0.0713, -0.0423,  0.0000],\n",
              "         [-0.2833,  0.0936,  0.2956,  ...,  0.0554, -0.0134,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0471, -0.2242, -0.0995,  ..., -0.0021,  0.2204,  0.0000],\n",
              "         [ 0.2897, -0.0005, -0.0589,  ...,  0.0299,  0.0139,  0.0000],\n",
              "         [ 0.3130,  0.0359, -0.0452,  ...,  0.1269, -0.0471,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1641, -0.0121, -0.0348,  ...,  0.0854,  0.0155,  0.0000],\n",
              "         [ 0.0018,  0.0326,  0.1686,  ...,  0.1045, -0.0333,  0.0000],\n",
              "         [-0.1386, -0.0028,  0.3073,  ...,  0.0252,  0.0003,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0158, -0.1266, -0.0654,  ...,  0.0262,  0.2073,  0.0000],\n",
              "         [ 0.2007, -0.0535, -0.0502,  ...,  0.2060,  0.0423,  0.0000],\n",
              "         [ 0.1942, -0.0181, -0.0549,  ...,  0.2751, -0.0974,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1097,  0.0353,  0.0495,  ...,  0.0301,  0.0336,  0.0000],\n",
              "         [-0.1191,  0.1023,  0.2789,  ...,  0.0893, -0.0265,  0.0000],\n",
              "         [-0.2685,  0.0603,  0.2994,  ...,  0.0660, -0.0092,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0322, -0.1297, -0.0314,  ...,  0.0572,  0.2142,  0.0000],\n",
              "         [ 0.1529, -0.0623, -0.0290,  ...,  0.2771,  0.1470,  0.0000],\n",
              "         [ 0.1254, -0.0397, -0.0166,  ...,  0.3634,  0.0418,  0.0000],\n",
              "         ...,\n",
              "         [-0.1834,  0.0965,  0.2798,  ...,  0.0894, -0.0272,  0.0000],\n",
              "         [-0.2620,  0.0820,  0.2996,  ...,  0.0819, -0.0479,  0.0000],\n",
              "         [-0.2899,  0.0793,  0.2852,  ...,  0.0458, -0.0163,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0325, -0.1465, -0.0391,  ...,  0.0569,  0.2181,  0.0000],\n",
              "         [ 0.1563, -0.0880, -0.0486,  ...,  0.2872,  0.1598,  0.0000],\n",
              "         [ 0.1139, -0.0768, -0.0446,  ...,  0.3800,  0.0624,  0.0000],\n",
              "         ...,\n",
              "         [-0.1651,  0.0348,  0.2482,  ...,  0.0950, -0.0082,  0.0000],\n",
              "         [-0.2459,  0.0422,  0.2602,  ...,  0.0838, -0.0420,  0.0000],\n",
              "         [-0.2769,  0.0387,  0.2710,  ...,  0.0406, -0.0191,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0323, -0.1519, -0.0528,  ...,  0.0615,  0.2047,  0.0000],\n",
              "         [ 0.1334, -0.1210, -0.0613,  ...,  0.2738,  0.1606,  0.0000],\n",
              "         [ 0.0685, -0.1087, -0.0615,  ...,  0.3865,  0.0768,  0.0000],\n",
              "         ...,\n",
              "         [-0.2126,  0.0305,  0.1997,  ...,  0.0711, -0.0641,  0.0000],\n",
              "         [-0.2659,  0.0551,  0.2097,  ...,  0.0661, -0.0746,  0.0000],\n",
              "         [-0.2552,  0.0261,  0.2425,  ...,  0.0207, -0.0429,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0237, -0.1320, -0.0260,  ...,  0.0427,  0.2122,  0.0000],\n",
              "         [ 0.1280, -0.0516,  0.0053,  ...,  0.2487,  0.1339,  0.0000],\n",
              "         [ 0.1177, -0.0099,  0.0180,  ...,  0.3265,  0.0136,  0.0000],\n",
              "         ...,\n",
              "         [-0.1640,  0.1300,  0.2986,  ...,  0.0719, -0.0245,  0.0000],\n",
              "         [-0.2558,  0.1177,  0.3474,  ...,  0.0644, -0.0363,  0.0000],\n",
              "         [-0.2977,  0.0885,  0.3042,  ...,  0.0460, -0.0110,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0291, -0.1282, -0.0327,  ...,  0.0564,  0.2115,  0.0000],\n",
              "         [ 0.1499, -0.0610, -0.0282,  ...,  0.2706,  0.1436,  0.0000],\n",
              "         [ 0.1269, -0.0317, -0.0191,  ...,  0.3629,  0.0331,  0.0000],\n",
              "         ...,\n",
              "         [-0.1686,  0.0915,  0.2748,  ...,  0.0831, -0.0197,  0.0000],\n",
              "         [-0.2553,  0.0743,  0.3049,  ...,  0.0767, -0.0365,  0.0000],\n",
              "         [-0.2921,  0.0865,  0.2838,  ...,  0.0478, -0.0125,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0340, -0.1505, -0.0472,  ...,  0.0623,  0.2164,  0.0000],\n",
              "         [ 0.1519, -0.1077, -0.0620,  ...,  0.2989,  0.1618,  0.0000],\n",
              "         [ 0.0985, -0.1010, -0.0628,  ...,  0.4047,  0.0737,  0.0000],\n",
              "         ...,\n",
              "         [-0.1643,  0.0127,  0.2202,  ...,  0.1003, -0.0284,  0.0000],\n",
              "         [-0.2421,  0.0323,  0.2244,  ...,  0.0856, -0.0526,  0.0000],\n",
              "         [-0.2656,  0.0245,  0.2493,  ...,  0.0350, -0.0233,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0161, -0.1265, -0.0321,  ...,  0.0443,  0.2148,  0.0000],\n",
              "         [ 0.1293, -0.0463, -0.0121,  ...,  0.2458,  0.1292,  0.0000],\n",
              "         [ 0.1298,  0.0199,  0.0012,  ...,  0.3283, -0.0198,  0.0000],\n",
              "         ...,\n",
              "         [-0.0689,  0.1414,  0.2073,  ...,  0.0781,  0.0216,  0.0000],\n",
              "         [-0.2371,  0.1363,  0.3338,  ...,  0.0700, -0.0113,  0.0000],\n",
              "         [-0.2779,  0.0947,  0.3002,  ...,  0.0661,  0.0037,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0323, -0.1258, -0.0326,  ...,  0.0518,  0.2095,  0.0000],\n",
              "         [ 0.1354, -0.0624, -0.0287,  ...,  0.2598,  0.1424,  0.0000],\n",
              "         [ 0.1115, -0.0339, -0.0206,  ...,  0.3471,  0.0360,  0.0000],\n",
              "         ...,\n",
              "         [-0.1733,  0.0928,  0.2687,  ...,  0.0844, -0.0146,  0.0000],\n",
              "         [-0.2722,  0.0743,  0.3096,  ...,  0.0728, -0.0428,  0.0000],\n",
              "         [-0.2970,  0.0830,  0.2879,  ...,  0.0356, -0.0131,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0120, -0.1146, -0.0367,  ...,  0.0285,  0.2066,  0.0000],\n",
              "         [ 0.1304, -0.0145, -0.0051,  ...,  0.2247,  0.0934,  0.0000],\n",
              "         [ 0.1482,  0.0577,  0.0149,  ...,  0.2930, -0.0599,  0.0000],\n",
              "         ...,\n",
              "         [-0.0355,  0.1278,  0.1879,  ...,  0.0436,  0.0211,  0.0000],\n",
              "         [-0.2013,  0.1344,  0.3376,  ...,  0.0547, -0.0067,  0.0000],\n",
              "         [-0.2727,  0.0968,  0.3090,  ...,  0.0413, -0.0030,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0038, -0.1292, -0.0392,  ...,  0.0434,  0.2089,  0.0000],\n",
              "         [ 0.1550, -0.0275, -0.0294,  ...,  0.2532,  0.0856,  0.0000],\n",
              "         [ 0.1699,  0.0442, -0.0132,  ...,  0.3265, -0.0636,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0172,  0.1191,  0.1127,  ...,  0.0499,  0.0560,  0.0000],\n",
              "         [-0.1648,  0.1239,  0.2753,  ...,  0.0699,  0.0055,  0.0000],\n",
              "         [-0.2408,  0.0939,  0.2655,  ...,  0.0715,  0.0027,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0170, -0.1201, -0.0313,  ...,  0.0310,  0.2108,  0.0000],\n",
              "         [ 0.1172, -0.0328,  0.0045,  ...,  0.2254,  0.1146,  0.0000],\n",
              "         [ 0.1257,  0.0343,  0.0248,  ...,  0.2993, -0.0276,  0.0000],\n",
              "         ...,\n",
              "         [-0.1036,  0.1485,  0.2656,  ...,  0.0529, -0.0019,  0.0000],\n",
              "         [-0.2370,  0.1400,  0.3575,  ...,  0.0464, -0.0174,  0.0000],\n",
              "         [-0.2869,  0.0989,  0.3101,  ...,  0.0417, -0.0015,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0008, -0.1081, -0.0600,  ...,  0.0318,  0.1995,  0.0000],\n",
              "         [ 0.1673, -0.0035, -0.0379,  ...,  0.2420,  0.0506,  0.0000],\n",
              "         [ 0.1734,  0.0477, -0.0325,  ...,  0.3045, -0.0870,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0794,  0.0720,  0.0365,  ...,  0.0404,  0.0540,  0.0000],\n",
              "         [-0.1421,  0.1197,  0.3075,  ...,  0.0872, -0.0133,  0.0000],\n",
              "         [-0.2616,  0.0905,  0.2995,  ...,  0.0600, -0.0004,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0115, -0.1112, -0.0407,  ...,  0.0306,  0.2125,  0.0000],\n",
              "         [ 0.1268, -0.0174, -0.0118,  ...,  0.2126,  0.1075,  0.0000],\n",
              "         [ 0.1409,  0.0558,  0.0043,  ...,  0.2781, -0.0418,  0.0000],\n",
              "         ...,\n",
              "         [-0.0530,  0.1387,  0.1954,  ...,  0.0499,  0.0397,  0.0000],\n",
              "         [-0.2110,  0.1396,  0.3302,  ...,  0.0672,  0.0102,  0.0000],\n",
              "         [-0.2771,  0.0955,  0.2999,  ...,  0.0471,  0.0110,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0255, -0.1319, -0.0243,  ...,  0.0468,  0.2157,  0.0000],\n",
              "         [ 0.1397, -0.0502,  0.0068,  ...,  0.2499,  0.1332,  0.0000],\n",
              "         [ 0.1322, -0.0107,  0.0330,  ...,  0.3250,  0.0100,  0.0000],\n",
              "         ...,\n",
              "         [-0.1605,  0.1453,  0.2964,  ...,  0.0672, -0.0284,  0.0000],\n",
              "         [-0.2516,  0.1264,  0.3423,  ...,  0.0644, -0.0395,  0.0000],\n",
              "         [-0.2883,  0.0947,  0.3040,  ...,  0.0529, -0.0145,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0270, -0.1339, -0.0251,  ...,  0.0491,  0.2164,  0.0000],\n",
              "         [ 0.1407, -0.0528, -0.0018,  ...,  0.2535,  0.1347,  0.0000],\n",
              "         [ 0.1304, -0.0182,  0.0236,  ...,  0.3340,  0.0132,  0.0000],\n",
              "         ...,\n",
              "         [-0.1625,  0.1401,  0.2906,  ...,  0.0685, -0.0290,  0.0000],\n",
              "         [-0.2511,  0.1195,  0.3317,  ...,  0.0666, -0.0403,  0.0000],\n",
              "         [-0.2875,  0.0917,  0.2995,  ...,  0.0528, -0.0161,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0311, -0.1445, -0.0377,  ...,  0.0578,  0.2185,  0.0000],\n",
              "         [ 0.1602, -0.0814, -0.0464,  ...,  0.2918,  0.1542,  0.0000],\n",
              "         [ 0.1216, -0.0691, -0.0423,  ...,  0.3815,  0.0551,  0.0000],\n",
              "         ...,\n",
              "         [-0.1569,  0.0430,  0.2469,  ...,  0.0944, -0.0065,  0.0000],\n",
              "         [-0.2381,  0.0453,  0.2654,  ...,  0.0829, -0.0395,  0.0000],\n",
              "         [-0.2750,  0.0492,  0.2725,  ...,  0.0449, -0.0145,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0181, -0.1187, -0.0301,  ...,  0.0421,  0.2173,  0.0000],\n",
              "         [ 0.1270, -0.0331,  0.0096,  ...,  0.2325,  0.1189,  0.0000],\n",
              "         [ 0.1298,  0.0230,  0.0301,  ...,  0.2984, -0.0295,  0.0000],\n",
              "         ...,\n",
              "         [-0.0687,  0.1618,  0.2373,  ...,  0.0446, -0.0035,  0.0000],\n",
              "         [-0.2269,  0.1482,  0.3461,  ...,  0.0559, -0.0160,  0.0000],\n",
              "         [-0.2781,  0.1045,  0.3071,  ...,  0.0555, -0.0025,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0118, -0.1145, -0.0395,  ...,  0.0314,  0.2113,  0.0000],\n",
              "         [ 0.1269, -0.0181, -0.0098,  ...,  0.2180,  0.0972,  0.0000],\n",
              "         [ 0.1446,  0.0531,  0.0074,  ...,  0.2841, -0.0566,  0.0000],\n",
              "         ...,\n",
              "         [-0.0430,  0.1284,  0.1839,  ...,  0.0413,  0.0284,  0.0000],\n",
              "         [-0.2149,  0.1357,  0.3362,  ...,  0.0587,  0.0027,  0.0000],\n",
              "         [-0.2759,  0.0986,  0.3040,  ...,  0.0449,  0.0066,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0221, -0.1317, -0.0273,  ...,  0.0425,  0.2135,  0.0000],\n",
              "         [ 0.1332, -0.0507,  0.0059,  ...,  0.2483,  0.1339,  0.0000],\n",
              "         [ 0.1272, -0.0032,  0.0231,  ...,  0.3233,  0.0089,  0.0000],\n",
              "         ...,\n",
              "         [-0.1588,  0.1364,  0.2928,  ...,  0.0657, -0.0161,  0.0000],\n",
              "         [-0.2499,  0.1208,  0.3426,  ...,  0.0625, -0.0297,  0.0000],\n",
              "         [-0.2918,  0.0921,  0.3015,  ...,  0.0493, -0.0070,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0077, -0.1132, -0.0412,  ...,  0.0297,  0.2109,  0.0000],\n",
              "         [ 0.1334, -0.0124, -0.0132,  ...,  0.2132,  0.0957,  0.0000],\n",
              "         [ 0.1522,  0.0560,  0.0013,  ...,  0.2805, -0.0592,  0.0000],\n",
              "         ...,\n",
              "         [-0.0346,  0.1285,  0.1740,  ...,  0.0383,  0.0338,  0.0000],\n",
              "         [-0.2065,  0.1372,  0.3324,  ...,  0.0559,  0.0048,  0.0000],\n",
              "         [-0.2709,  0.0977,  0.3025,  ...,  0.0435,  0.0053,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0296, -0.1506, -0.0433,  ...,  0.0544,  0.2175,  0.0000],\n",
              "         [ 0.1557, -0.0881, -0.0570,  ...,  0.2822,  0.1638,  0.0000],\n",
              "         [ 0.1099, -0.0810, -0.0573,  ...,  0.3764,  0.0706,  0.0000],\n",
              "         ...,\n",
              "         [-0.1588,  0.0187,  0.2333,  ...,  0.0847, -0.0045,  0.0000],\n",
              "         [-0.2365,  0.0196,  0.2489,  ...,  0.0731, -0.0318,  0.0000],\n",
              "         [-0.2727,  0.0307,  0.2607,  ...,  0.0349, -0.0163,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0102, -0.1148, -0.0359,  ...,  0.0323,  0.2110,  0.0000],\n",
              "         [ 0.1311, -0.0174, -0.0036,  ...,  0.2157,  0.1040,  0.0000],\n",
              "         [ 0.1444,  0.0498,  0.0144,  ...,  0.2841, -0.0491,  0.0000],\n",
              "         ...,\n",
              "         [-0.0582,  0.1439,  0.2081,  ...,  0.0364,  0.0186,  0.0000],\n",
              "         [-0.2207,  0.1391,  0.3377,  ...,  0.0482, -0.0013,  0.0000],\n",
              "         [-0.2769,  0.1006,  0.3028,  ...,  0.0402,  0.0016,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0304, -0.1439, -0.0383,  ...,  0.0526,  0.2158,  0.0000],\n",
              "         [ 0.1517, -0.0740, -0.0464,  ...,  0.2745,  0.1572,  0.0000],\n",
              "         [ 0.1137, -0.0616, -0.0448,  ...,  0.3637,  0.0590,  0.0000],\n",
              "         ...,\n",
              "         [-0.1631,  0.0382,  0.2446,  ...,  0.0753,  0.0015,  0.0000],\n",
              "         [-0.2433,  0.0343,  0.2681,  ...,  0.0683, -0.0307,  0.0000],\n",
              "         [-0.2818,  0.0462,  0.2714,  ...,  0.0365, -0.0146,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0242, -0.1323, -0.0320,  ...,  0.0474,  0.2119,  0.0000],\n",
              "         [ 0.1402, -0.0569, -0.0133,  ...,  0.2603,  0.1353,  0.0000],\n",
              "         [ 0.1230, -0.0239, -0.0009,  ...,  0.3449,  0.0210,  0.0000],\n",
              "         ...,\n",
              "         [-0.1647,  0.0986,  0.2750,  ...,  0.0646, -0.0218,  0.0000],\n",
              "         [-0.2437,  0.0816,  0.3055,  ...,  0.0639, -0.0349,  0.0000],\n",
              "         [-0.2870,  0.0837,  0.2896,  ...,  0.0458, -0.0135,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0252, -0.1317, -0.0257,  ...,  0.0471,  0.2148,  0.0000],\n",
              "         [ 0.1388, -0.0504,  0.0020,  ...,  0.2506,  0.1334,  0.0000],\n",
              "         [ 0.1299, -0.0142,  0.0272,  ...,  0.3274,  0.0111,  0.0000],\n",
              "         ...,\n",
              "         [-0.1651,  0.1414,  0.2925,  ...,  0.0694, -0.0320,  0.0000],\n",
              "         [-0.2542,  0.1214,  0.3362,  ...,  0.0658, -0.0426,  0.0000],\n",
              "         [-0.2886,  0.0941,  0.3022,  ...,  0.0516, -0.0177,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0234, -0.1274, -0.0270,  ...,  0.0384,  0.2115,  0.0000],\n",
              "         [ 0.1237, -0.0460,  0.0073,  ...,  0.2381,  0.1266,  0.0000],\n",
              "         [ 0.1241,  0.0092,  0.0230,  ...,  0.3134, -0.0071,  0.0000],\n",
              "         ...,\n",
              "         [-0.1561,  0.1403,  0.2940,  ...,  0.0571, -0.0177,  0.0000],\n",
              "         [-0.2520,  0.1266,  0.3536,  ...,  0.0554, -0.0321,  0.0000],\n",
              "         [-0.2949,  0.0961,  0.3071,  ...,  0.0429, -0.0055,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0416, -0.1962, -0.0885,  ...,  0.0134,  0.2166,  0.0000],\n",
              "         [ 0.2843,  0.0099, -0.0729,  ...,  0.0917,  0.0210,  0.0000],\n",
              "         [ 0.2966,  0.0393, -0.0512,  ...,  0.1659, -0.0813,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1430,  0.0207, -0.0136,  ...,  0.0875,  0.0128,  0.0000],\n",
              "         [-0.0137,  0.0670,  0.1964,  ...,  0.1227, -0.0354,  0.0000],\n",
              "         [-0.1792,  0.0259,  0.3087,  ...,  0.0506, -0.0161,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0070, -0.1082, -0.0464,  ...,  0.0366,  0.2033,  0.0000],\n",
              "         [ 0.1547, -0.0043, -0.0234,  ...,  0.2383,  0.0711,  0.0000],\n",
              "         [ 0.1666,  0.0565, -0.0146,  ...,  0.3022, -0.0775,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0559,  0.0932,  0.0748,  ...,  0.0259,  0.0561,  0.0000],\n",
              "         [-0.1672,  0.1252,  0.3179,  ...,  0.0766, -0.0036,  0.0000],\n",
              "         [-0.2630,  0.1016,  0.3002,  ...,  0.0533,  0.0023,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3877e-02, -1.2936e-01, -2.5908e-02,  ...,  4.5318e-02,\n",
              "           2.1520e-01,  0.0000e+00],\n",
              "         [ 1.3609e-01, -4.5665e-02,  9.5860e-03,  ...,  2.4321e-01,\n",
              "           1.2770e-01,  0.0000e+00],\n",
              "         [ 1.3426e-01,  1.1981e-04,  3.3423e-02,  ...,  3.1413e-01,\n",
              "          -6.1569e-03,  0.0000e+00],\n",
              "         ...,\n",
              "         [-1.1984e-01,  1.6361e-01,  2.6914e-01,  ...,  5.8960e-02,\n",
              "          -1.6411e-02,  0.0000e+00],\n",
              "         [-2.4297e-01,  1.4390e-01,  3.4321e-01,  ...,  5.7781e-02,\n",
              "          -3.1281e-02,  0.0000e+00],\n",
              "         [-2.8302e-01,  1.0338e-01,  3.0117e-01,  ...,  5.6304e-02,\n",
              "          -8.9613e-03,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0185, -0.1159, -0.0331,  ...,  0.0320,  0.2142,  0.0000],\n",
              "         [ 0.1160, -0.0261,  0.0019,  ...,  0.2167,  0.1184,  0.0000],\n",
              "         [ 0.1251,  0.0469,  0.0189,  ...,  0.2830, -0.0244,  0.0000],\n",
              "         ...,\n",
              "         [-0.0944,  0.1539,  0.2493,  ...,  0.0466,  0.0227,  0.0000],\n",
              "         [-0.2331,  0.1430,  0.3475,  ...,  0.0545,  0.0004,  0.0000],\n",
              "         [-0.2878,  0.0961,  0.3060,  ...,  0.0436,  0.0098,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0183, -0.1228, -0.0275,  ...,  0.0343,  0.2128,  0.0000],\n",
              "         [ 0.1245, -0.0342,  0.0081,  ...,  0.2200,  0.1256,  0.0000],\n",
              "         [ 0.1286,  0.0281,  0.0277,  ...,  0.2920, -0.0202,  0.0000],\n",
              "         ...,\n",
              "         [-0.1206,  0.1514,  0.2764,  ...,  0.0432,  0.0022,  0.0000],\n",
              "         [-0.2477,  0.1382,  0.3599,  ...,  0.0421, -0.0171,  0.0000],\n",
              "         [-0.2921,  0.0980,  0.3106,  ...,  0.0387, -0.0024,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.5933e-02, -1.1543e-01, -3.3203e-02,  ...,  4.1880e-02,\n",
              "           2.1723e-01,  0.0000e+00],\n",
              "         [ 1.2921e-01, -2.9636e-02,  5.2083e-03,  ...,  2.2918e-01,\n",
              "           1.1470e-01,  0.0000e+00],\n",
              "         [ 1.3280e-01,  2.6277e-02,  2.3205e-02,  ...,  2.9487e-01,\n",
              "          -3.5421e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [-5.7919e-02,  1.5855e-01,  2.2149e-01,  ...,  4.7535e-02,\n",
              "           1.1860e-03,  0.0000e+00],\n",
              "         [-2.2054e-01,  1.4583e-01,  3.4085e-01,  ...,  6.3732e-02,\n",
              "          -1.1490e-02,  0.0000e+00],\n",
              "         [-2.7598e-01,  1.0293e-01,  3.0605e-01,  ...,  5.7322e-02,\n",
              "           1.5950e-04,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0316, -0.1265, -0.0303,  ...,  0.0560,  0.2129,  0.0000],\n",
              "         [ 0.1465, -0.0624, -0.0275,  ...,  0.2664,  0.1446,  0.0000],\n",
              "         [ 0.1215, -0.0364, -0.0139,  ...,  0.3546,  0.0349,  0.0000],\n",
              "         ...,\n",
              "         [-0.1844,  0.1023,  0.2842,  ...,  0.0894, -0.0265,  0.0000],\n",
              "         [-0.2680,  0.0860,  0.3081,  ...,  0.0801, -0.0486,  0.0000],\n",
              "         [-0.2926,  0.0824,  0.2882,  ...,  0.0442, -0.0198,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0244, -0.1347, -0.0297,  ...,  0.0454,  0.2147,  0.0000],\n",
              "         [ 0.1372, -0.0532, -0.0044,  ...,  0.2572,  0.1375,  0.0000],\n",
              "         [ 0.1241, -0.0143,  0.0084,  ...,  0.3377,  0.0210,  0.0000],\n",
              "         ...,\n",
              "         [-0.1742,  0.1146,  0.2894,  ...,  0.0661, -0.0247,  0.0000],\n",
              "         [-0.2484,  0.0960,  0.3192,  ...,  0.0664, -0.0340,  0.0000],\n",
              "         [-0.2898,  0.0860,  0.2933,  ...,  0.0487, -0.0094,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0309, -0.1442, -0.0387,  ...,  0.0503,  0.2151,  0.0000],\n",
              "         [ 0.1475, -0.0753, -0.0457,  ...,  0.2679,  0.1538,  0.0000],\n",
              "         [ 0.1102, -0.0613, -0.0448,  ...,  0.3550,  0.0548,  0.0000],\n",
              "         ...,\n",
              "         [-0.1674,  0.0348,  0.2468,  ...,  0.0697,  0.0010,  0.0000],\n",
              "         [-0.2435,  0.0313,  0.2689,  ...,  0.0641, -0.0292,  0.0000],\n",
              "         [-0.2820,  0.0450,  0.2715,  ...,  0.0359, -0.0160,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7796e-02, -1.1801e-01, -3.4636e-02,  ...,  4.3705e-02,\n",
              "           2.1694e-01,  0.0000e+00],\n",
              "         [ 1.2769e-01, -3.6095e-02,  2.6758e-04,  ...,  2.2911e-01,\n",
              "           1.1842e-01,  0.0000e+00],\n",
              "         [ 1.2527e-01,  1.6361e-02,  1.8323e-02,  ...,  2.9955e-01,\n",
              "          -3.3903e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [-6.2178e-02,  1.6652e-01,  2.2506e-01,  ...,  4.8545e-02,\n",
              "           1.1151e-04,  0.0000e+00],\n",
              "         [-2.2581e-01,  1.4883e-01,  3.3740e-01,  ...,  6.5349e-02,\n",
              "          -1.3918e-02,  0.0000e+00],\n",
              "         [-2.7567e-01,  1.0631e-01,  3.0082e-01,  ...,  5.9361e-02,\n",
              "          -8.4193e-04,  0.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0103, -0.1203, -0.0591,  ...,  0.0357,  0.2111,  0.0000],\n",
              "         [ 0.1895, -0.0406, -0.0417,  ...,  0.2210,  0.0535,  0.0000],\n",
              "         [ 0.1856, -0.0037, -0.0426,  ...,  0.2946, -0.0895,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0793,  0.0697,  0.0938,  ...,  0.0335,  0.0282,  0.0000],\n",
              "         [-0.1360,  0.1144,  0.2949,  ...,  0.0861, -0.0200,  0.0000],\n",
              "         [-0.2582,  0.0721,  0.2979,  ...,  0.0651, -0.0057,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0217, -0.1281, -0.0268,  ...,  0.0368,  0.2138,  0.0000],\n",
              "         [ 0.1260, -0.0426,  0.0079,  ...,  0.2393,  0.1268,  0.0000],\n",
              "         [ 0.1297,  0.0216,  0.0272,  ...,  0.3146, -0.0129,  0.0000],\n",
              "         ...,\n",
              "         [-0.1367,  0.1482,  0.2799,  ...,  0.0498, -0.0059,  0.0000],\n",
              "         [-0.2421,  0.1319,  0.3467,  ...,  0.0489, -0.0247,  0.0000],\n",
              "         [-0.2882,  0.0954,  0.3033,  ...,  0.0467, -0.0047,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0169, -0.1106, -0.0373,  ...,  0.0394,  0.2082,  0.0000],\n",
              "         [ 0.1347, -0.0082, -0.0108,  ...,  0.2341,  0.0915,  0.0000],\n",
              "         [ 0.1458,  0.0602,  0.0050,  ...,  0.2968, -0.0570,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0097,  0.1211,  0.1327,  ...,  0.0281,  0.0441,  0.0000],\n",
              "         [-0.2021,  0.1294,  0.3377,  ...,  0.0622, -0.0033,  0.0000],\n",
              "         [-0.2731,  0.1031,  0.3036,  ...,  0.0488,  0.0072,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0169, -0.1151, -0.0336,  ...,  0.0332,  0.2128,  0.0000],\n",
              "         [ 0.1204, -0.0238,  0.0004,  ...,  0.2203,  0.1165,  0.0000],\n",
              "         [ 0.1296,  0.0484,  0.0168,  ...,  0.2870, -0.0270,  0.0000],\n",
              "         ...,\n",
              "         [-0.0848,  0.1503,  0.2409,  ...,  0.0493,  0.0187,  0.0000],\n",
              "         [-0.2295,  0.1406,  0.3443,  ...,  0.0570, -0.0025,  0.0000],\n",
              "         [-0.2836,  0.0971,  0.3039,  ...,  0.0425,  0.0083,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0066, -0.1131, -0.0488,  ...,  0.0410,  0.2158,  0.0000],\n",
              "         [ 0.1489, -0.0268, -0.0292,  ...,  0.2291,  0.0861,  0.0000],\n",
              "         [ 0.1454,  0.0189, -0.0159,  ...,  0.3070, -0.0628,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0223,  0.1231,  0.1313,  ...,  0.0388,  0.0299,  0.0000],\n",
              "         [-0.1756,  0.1399,  0.3064,  ...,  0.0780, -0.0051,  0.0000],\n",
              "         [-0.2647,  0.0957,  0.2902,  ...,  0.0621,  0.0007,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0263, -0.1322, -0.0246,  ...,  0.0470,  0.2155,  0.0000],\n",
              "         [ 0.1405, -0.0515,  0.0019,  ...,  0.2492,  0.1361,  0.0000],\n",
              "         [ 0.1284, -0.0139,  0.0282,  ...,  0.3257,  0.0149,  0.0000],\n",
              "         ...,\n",
              "         [-0.1761,  0.1423,  0.3014,  ...,  0.0655, -0.0305,  0.0000],\n",
              "         [-0.2565,  0.1188,  0.3382,  ...,  0.0627, -0.0405,  0.0000],\n",
              "         [-0.2898,  0.0924,  0.3017,  ...,  0.0517, -0.0188,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0061, -0.1077, -0.0509,  ...,  0.0378,  0.2176,  0.0000],\n",
              "         [ 0.1528, -0.0266, -0.0297,  ...,  0.2201,  0.0877,  0.0000],\n",
              "         [ 0.1462,  0.0200, -0.0218,  ...,  0.2987, -0.0592,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0227,  0.1283,  0.1384,  ...,  0.0352,  0.0300,  0.0000],\n",
              "         [-0.1747,  0.1445,  0.3087,  ...,  0.0759, -0.0068,  0.0000],\n",
              "         [-0.2664,  0.0952,  0.2953,  ...,  0.0619, -0.0010,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0297, -0.1480, -0.0385,  ...,  0.0557,  0.2181,  0.0000],\n",
              "         [ 0.1596, -0.0882, -0.0458,  ...,  0.2834,  0.1585,  0.0000],\n",
              "         [ 0.1179, -0.0744, -0.0420,  ...,  0.3713,  0.0587,  0.0000],\n",
              "         ...,\n",
              "         [-0.1547,  0.0381,  0.2449,  ...,  0.0905, -0.0059,  0.0000],\n",
              "         [-0.2349,  0.0426,  0.2636,  ...,  0.0793, -0.0401,  0.0000],\n",
              "         [-0.2718,  0.0443,  0.2691,  ...,  0.0422, -0.0182,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0201, -0.1521, -0.0580,  ...,  0.0496,  0.1834,  0.0000],\n",
              "         [ 0.1219, -0.1334, -0.0498,  ...,  0.2341,  0.1522,  0.0000],\n",
              "         [ 0.0482, -0.1308, -0.0639,  ...,  0.3448,  0.0835,  0.0000],\n",
              "         ...,\n",
              "         [-0.2041,  0.0489,  0.2217,  ..., -0.0428, -0.0912,  0.0000],\n",
              "         [-0.2445,  0.0726,  0.2342,  ..., -0.0356, -0.0811,  0.0000],\n",
              "         [-0.2020,  0.0495,  0.2477,  ..., -0.0355, -0.0599,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0246, -0.1287, -0.0258,  ...,  0.0474,  0.2161,  0.0000],\n",
              "         [ 0.1363, -0.0484,  0.0091,  ...,  0.2493,  0.1300,  0.0000],\n",
              "         [ 0.1346, -0.0014,  0.0324,  ...,  0.3212, -0.0027,  0.0000],\n",
              "         ...,\n",
              "         [-0.1328,  0.1563,  0.2829,  ...,  0.0664, -0.0163,  0.0000],\n",
              "         [-0.2423,  0.1387,  0.3457,  ...,  0.0655, -0.0284,  0.0000],\n",
              "         [-0.2834,  0.1006,  0.3029,  ...,  0.0591, -0.0045,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0161, -0.1192, -0.0325,  ...,  0.0430,  0.2172,  0.0000],\n",
              "         [ 0.1289, -0.0328,  0.0059,  ...,  0.2369,  0.1179,  0.0000],\n",
              "         [ 0.1317,  0.0222,  0.0255,  ...,  0.3036, -0.0333,  0.0000],\n",
              "         ...,\n",
              "         [-0.0548,  0.1542,  0.2225,  ...,  0.0519, -0.0005,  0.0000],\n",
              "         [-0.2202,  0.1448,  0.3418,  ...,  0.0641, -0.0124,  0.0000],\n",
              "         [-0.2743,  0.1007,  0.3049,  ...,  0.0603, -0.0013,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0226, -0.1324, -0.0268,  ...,  0.0428,  0.2129,  0.0000],\n",
              "         [ 0.1339, -0.0496,  0.0038,  ...,  0.2476,  0.1337,  0.0000],\n",
              "         [ 0.1244, -0.0041,  0.0244,  ...,  0.3269,  0.0077,  0.0000],\n",
              "         ...,\n",
              "         [-0.1625,  0.1321,  0.2889,  ...,  0.0623, -0.0204,  0.0000],\n",
              "         [-0.2520,  0.1161,  0.3360,  ...,  0.0606, -0.0350,  0.0000],\n",
              "         [-0.2936,  0.0899,  0.3005,  ...,  0.0474, -0.0104,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0181, -0.1192, -0.0316,  ...,  0.0329,  0.2116,  0.0000],\n",
              "         [ 0.1216, -0.0258,  0.0057,  ...,  0.2209,  0.1099,  0.0000],\n",
              "         [ 0.1328,  0.0418,  0.0260,  ...,  0.2872, -0.0385,  0.0000],\n",
              "         ...,\n",
              "         [-0.0809,  0.1439,  0.2424,  ...,  0.0402,  0.0076,  0.0000],\n",
              "         [-0.2331,  0.1384,  0.3520,  ...,  0.0475, -0.0085,  0.0000],\n",
              "         [-0.2861,  0.0988,  0.3106,  ...,  0.0399,  0.0039,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0008, -0.1083, -0.0562,  ...,  0.0239,  0.2043,  0.0000],\n",
              "         [ 0.1461, -0.0156, -0.0280,  ...,  0.2179,  0.0688,  0.0000],\n",
              "         [ 0.1668,  0.0427, -0.0281,  ...,  0.2881, -0.0794,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0260,  0.0917,  0.1097,  ...,  0.0412,  0.0521,  0.0000],\n",
              "         [-0.1661,  0.1282,  0.3051,  ...,  0.0703,  0.0057,  0.0000],\n",
              "         [-0.2617,  0.0858,  0.2976,  ...,  0.0479,  0.0048,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0226, -0.1323, -0.0275,  ...,  0.0424,  0.2140,  0.0000],\n",
              "         [ 0.1339, -0.0479,  0.0018,  ...,  0.2450,  0.1381,  0.0000],\n",
              "         [ 0.1245, -0.0023,  0.0202,  ...,  0.3240,  0.0090,  0.0000],\n",
              "         ...,\n",
              "         [-0.1625,  0.1338,  0.2883,  ...,  0.0624, -0.0197,  0.0000],\n",
              "         [-0.2531,  0.1168,  0.3379,  ...,  0.0586, -0.0357,  0.0000],\n",
              "         [-0.2950,  0.0874,  0.3015,  ...,  0.0463, -0.0140,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0271, -0.1318, -0.0256,  ...,  0.0490,  0.2156,  0.0000],\n",
              "         [ 0.1422, -0.0549, -0.0015,  ...,  0.2539,  0.1396,  0.0000],\n",
              "         [ 0.1303, -0.0205,  0.0234,  ...,  0.3318,  0.0183,  0.0000],\n",
              "         ...,\n",
              "         [-0.1786,  0.1378,  0.3006,  ...,  0.0722, -0.0315,  0.0000],\n",
              "         [-0.2567,  0.1171,  0.3331,  ...,  0.0702, -0.0396,  0.0000],\n",
              "         [-0.2901,  0.0912,  0.3003,  ...,  0.0529, -0.0176,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0291, -0.1531, -0.0488,  ...,  0.0524,  0.2129,  0.0000],\n",
              "         [ 0.1477, -0.1016, -0.0580,  ...,  0.2857,  0.1578,  0.0000],\n",
              "         [ 0.1103, -0.1046, -0.0582,  ...,  0.3681,  0.0949,  0.0000],\n",
              "         ...,\n",
              "         [-0.1532,  0.0029,  0.2273,  ...,  0.1026, -0.0090,  0.0000],\n",
              "         [-0.2304,  0.0102,  0.2367,  ...,  0.0822, -0.0367,  0.0000],\n",
              "         [-0.2643,  0.0211,  0.2524,  ...,  0.0336, -0.0215,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0320, -0.1261, -0.0300,  ...,  0.0574,  0.2117,  0.0000],\n",
              "         [ 0.1515, -0.0601, -0.0216,  ...,  0.2642,  0.1434,  0.0000],\n",
              "         [ 0.1281, -0.0326, -0.0053,  ...,  0.3482,  0.0342,  0.0000],\n",
              "         ...,\n",
              "         [-0.1796,  0.1139,  0.2801,  ...,  0.0819, -0.0326,  0.0000],\n",
              "         [-0.2656,  0.0980,  0.3060,  ...,  0.0774, -0.0517,  0.0000],\n",
              "         [-0.2889,  0.0884,  0.2862,  ...,  0.0460, -0.0187,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0163, -0.1180, -0.0319,  ...,  0.0415,  0.2164,  0.0000],\n",
              "         [ 0.1301, -0.0334,  0.0064,  ...,  0.2307,  0.1202,  0.0000],\n",
              "         [ 0.1292,  0.0191,  0.0265,  ...,  0.2979, -0.0308,  0.0000],\n",
              "         ...,\n",
              "         [-0.0542,  0.1645,  0.2199,  ...,  0.0464,  0.0023,  0.0000],\n",
              "         [-0.2221,  0.1529,  0.3379,  ...,  0.0594, -0.0121,  0.0000],\n",
              "         [-0.2773,  0.1040,  0.3039,  ...,  0.0576, -0.0046,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0307, -0.1249, -0.0278,  ...,  0.0588,  0.2120,  0.0000],\n",
              "         [ 0.1516, -0.0584, -0.0166,  ...,  0.2671,  0.1425,  0.0000],\n",
              "         [ 0.1328, -0.0308,  0.0023,  ...,  0.3543,  0.0294,  0.0000],\n",
              "         ...,\n",
              "         [-0.1773,  0.1263,  0.2869,  ...,  0.0847, -0.0325,  0.0000],\n",
              "         [-0.2613,  0.1078,  0.3137,  ...,  0.0809, -0.0453,  0.0000],\n",
              "         [-0.2896,  0.0898,  0.2905,  ...,  0.0516, -0.0181,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0094, -0.1135, -0.0464,  ...,  0.0403,  0.2150,  0.0000],\n",
              "         [ 0.1453, -0.0268, -0.0182,  ...,  0.2273,  0.0905,  0.0000],\n",
              "         [ 0.1464,  0.0202, -0.0064,  ...,  0.3005, -0.0619,  0.0000],\n",
              "         ...,\n",
              "         [ 0.0039,  0.1304,  0.1484,  ...,  0.0412,  0.0194,  0.0000],\n",
              "         [-0.1875,  0.1380,  0.3176,  ...,  0.0743, -0.0109,  0.0000],\n",
              "         [-0.2697,  0.0934,  0.2976,  ...,  0.0623, -0.0022,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0228, -0.1271, -0.0809,  ...,  0.0141,  0.2024,  0.0000],\n",
              "         [ 0.1948, -0.0246, -0.0644,  ...,  0.1956,  0.0385,  0.0000],\n",
              "         [ 0.2058,  0.0234, -0.0645,  ...,  0.2614, -0.0949,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1061,  0.0264, -0.0011,  ...,  0.0407,  0.0785,  0.0000],\n",
              "         [-0.1020,  0.1138,  0.2550,  ...,  0.0778,  0.0082,  0.0000],\n",
              "         [-0.2599,  0.0710,  0.2891,  ...,  0.0567,  0.0040,  0.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.8154e-02, -1.1890e-01, -3.0240e-02,  ...,  4.2188e-02,\n",
              "           2.1736e-01,  1.0000e+00],\n",
              "         [ 1.2764e-01, -3.5321e-02,  9.8356e-03,  ...,  2.3094e-01,\n",
              "           1.2231e-01,  1.0000e+00],\n",
              "         [ 1.3146e-01,  2.0838e-02,  2.9656e-02,  ...,  2.9709e-01,\n",
              "          -2.4336e-02,  1.0000e+00],\n",
              "         ...,\n",
              "         [-7.9784e-02,  1.6316e-01,  2.4469e-01,  ...,  5.0552e-02,\n",
              "          -4.0612e-04,  1.0000e+00],\n",
              "         [-2.2853e-01,  1.4579e-01,  3.4627e-01,  ...,  5.8916e-02,\n",
              "          -1.4118e-02,  1.0000e+00],\n",
              "         [-2.7818e-01,  1.0614e-01,  3.0595e-01,  ...,  5.4759e-02,\n",
              "           5.7757e-04,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0277, -0.1547, -0.0410,  ...,  0.0556,  0.2152,  1.0000],\n",
              "         [ 0.1618, -0.0965, -0.0467,  ...,  0.2850,  0.1475,  1.0000],\n",
              "         [ 0.1188, -0.0824, -0.0459,  ...,  0.3705,  0.0508,  1.0000],\n",
              "         ...,\n",
              "         [-0.1353,  0.0196,  0.2266,  ...,  0.0880, -0.0055,  1.0000],\n",
              "         [-0.2121,  0.0303,  0.2424,  ...,  0.0771, -0.0383,  1.0000],\n",
              "         [-0.2530,  0.0316,  0.2559,  ...,  0.0445, -0.0175,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0220, -0.1247, -0.0267,  ...,  0.0424,  0.2163,  1.0000],\n",
              "         [ 0.1298, -0.0424,  0.0126,  ...,  0.2357,  0.1276,  1.0000],\n",
              "         [ 0.1308,  0.0102,  0.0357,  ...,  0.3040, -0.0122,  1.0000],\n",
              "         ...,\n",
              "         [-0.1148,  0.1631,  0.2729,  ...,  0.0528, -0.0127,  1.0000],\n",
              "         [-0.2402,  0.1439,  0.3527,  ...,  0.0530, -0.0265,  1.0000],\n",
              "         [-0.2840,  0.1038,  0.3072,  ...,  0.0514, -0.0061,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0251, -0.1314, -0.0248,  ...,  0.0487,  0.2152,  1.0000],\n",
              "         [ 0.1415, -0.0520,  0.0011,  ...,  0.2546,  0.1340,  1.0000],\n",
              "         [ 0.1326, -0.0133,  0.0267,  ...,  0.3302,  0.0102,  1.0000],\n",
              "         ...,\n",
              "         [-0.1571,  0.1433,  0.2883,  ...,  0.0720, -0.0291,  1.0000],\n",
              "         [-0.2479,  0.1230,  0.3348,  ...,  0.0688, -0.0398,  1.0000],\n",
              "         [-0.2846,  0.0944,  0.2995,  ...,  0.0561, -0.0139,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0307, -0.1440, -0.0374,  ...,  0.0559,  0.2171,  1.0000],\n",
              "         [ 0.1569, -0.0831, -0.0456,  ...,  0.2830,  0.1565,  1.0000],\n",
              "         [ 0.1171, -0.0688, -0.0407,  ...,  0.3712,  0.0571,  1.0000],\n",
              "         ...,\n",
              "         [-0.1656,  0.0439,  0.2549,  ...,  0.0941, -0.0097,  1.0000],\n",
              "         [-0.2476,  0.0477,  0.2716,  ...,  0.0816, -0.0433,  1.0000],\n",
              "         [-0.2776,  0.0526,  0.2737,  ...,  0.0420, -0.0165,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0309, -0.1239, -0.0310,  ...,  0.0596,  0.2122,  1.0000],\n",
              "         [ 0.1516, -0.0586, -0.0229,  ...,  0.2718,  0.1409,  1.0000],\n",
              "         [ 0.1315, -0.0329, -0.0084,  ...,  0.3602,  0.0301,  1.0000],\n",
              "         ...,\n",
              "         [-0.1826,  0.1132,  0.2868,  ...,  0.0888, -0.0336,  1.0000],\n",
              "         [-0.2644,  0.0954,  0.3103,  ...,  0.0818, -0.0489,  1.0000],\n",
              "         [-0.2891,  0.0873,  0.2888,  ...,  0.0473, -0.0189,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.3947e-02, -1.2945e-01, -2.5191e-02,  ...,  4.5748e-02,\n",
              "           2.1604e-01,  1.0000e+00],\n",
              "         [ 1.3775e-01, -4.8272e-02,  9.0470e-03,  ...,  2.4752e-01,\n",
              "           1.2882e-01,  1.0000e+00],\n",
              "         [ 1.3601e-01,  3.7002e-04,  3.3707e-02,  ...,  3.1828e-01,\n",
              "          -3.9656e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.2619e-01,  1.5681e-01,  2.7794e-01,  ...,  6.1112e-02,\n",
              "          -1.7915e-02,  1.0000e+00],\n",
              "         [-2.4108e-01,  1.3734e-01,  3.4774e-01,  ...,  6.0167e-02,\n",
              "          -3.1407e-02,  1.0000e+00],\n",
              "         [-2.8510e-01,  9.8590e-02,  3.0514e-01,  ...,  5.5642e-02,\n",
              "          -9.6417e-03,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0340, -0.1469, -0.0410,  ...,  0.0588,  0.2179,  1.0000],\n",
              "         [ 0.1560, -0.0894, -0.0548,  ...,  0.2910,  0.1588,  1.0000],\n",
              "         [ 0.1122, -0.0817, -0.0525,  ...,  0.3857,  0.0656,  1.0000],\n",
              "         ...,\n",
              "         [-0.1652,  0.0284,  0.2461,  ...,  0.0966, -0.0145,  1.0000],\n",
              "         [-0.2476,  0.0367,  0.2542,  ...,  0.0831, -0.0441,  1.0000],\n",
              "         [-0.2758,  0.0384,  0.2676,  ...,  0.0403, -0.0178,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0224, -0.1279, -0.0265,  ...,  0.0369,  0.2109,  1.0000],\n",
              "         [ 0.1241, -0.0432,  0.0095,  ...,  0.2371,  0.1249,  1.0000],\n",
              "         [ 0.1237,  0.0113,  0.0284,  ...,  0.3111, -0.0080,  1.0000],\n",
              "         ...,\n",
              "         [-0.1606,  0.1435,  0.2953,  ...,  0.0550, -0.0226,  1.0000],\n",
              "         [-0.2510,  0.1284,  0.3527,  ...,  0.0493, -0.0352,  1.0000],\n",
              "         [-0.2925,  0.0935,  0.3065,  ...,  0.0408, -0.0108,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0073, -0.1278, -0.0386,  ...,  0.0488,  0.2159,  1.0000],\n",
              "         [ 0.1421, -0.0363, -0.0223,  ...,  0.2467,  0.1219,  1.0000],\n",
              "         [ 0.1489,  0.0337, -0.0047,  ...,  0.3284, -0.0290,  1.0000],\n",
              "         ...,\n",
              "         [-0.0431,  0.1396,  0.1766,  ...,  0.0918,  0.0429,  1.0000],\n",
              "         [-0.2083,  0.1303,  0.3068,  ...,  0.0931,  0.0051,  1.0000],\n",
              "         [-0.2574,  0.0977,  0.2841,  ...,  0.0793,  0.0104,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.2745e-02, -1.3046e-01, -2.6387e-02,  ...,  3.9883e-02,\n",
              "           2.1314e-01,  1.0000e+00],\n",
              "         [ 1.2970e-01, -4.8096e-02,  6.1133e-03,  ...,  2.4242e-01,\n",
              "           1.3427e-01,  1.0000e+00],\n",
              "         [ 1.2374e-01,  2.8452e-04,  2.5793e-02,  ...,  3.1896e-01,\n",
              "           5.4023e-03,  1.0000e+00],\n",
              "         ...,\n",
              "         [-1.6517e-01,  1.3702e-01,  2.9848e-01,  ...,  5.9782e-02,\n",
              "          -2.1833e-02,  1.0000e+00],\n",
              "         [-2.5572e-01,  1.1969e-01,  3.4957e-01,  ...,  5.4364e-02,\n",
              "          -3.5257e-02,  1.0000e+00],\n",
              "         [-2.9596e-01,  9.0229e-02,  3.0507e-01,  ...,  4.4173e-02,\n",
              "          -1.2868e-02,  1.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0306, -0.1262, -0.0325,  ...,  0.0551,  0.2102,  1.0000],\n",
              "         [ 0.1423, -0.0608, -0.0241,  ...,  0.2607,  0.1419,  1.0000],\n",
              "         [ 0.1216, -0.0293, -0.0132,  ...,  0.3509,  0.0307,  1.0000],\n",
              "         ...,\n",
              "         [-0.1817,  0.0931,  0.2853,  ...,  0.0689, -0.0244,  1.0000],\n",
              "         [-0.2578,  0.0768,  0.3030,  ...,  0.0692, -0.0374,  1.0000],\n",
              "         [-0.2875,  0.0848,  0.2846,  ...,  0.0402, -0.0118,  1.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.1652e-02, -1.2438e-01, -2.8300e-02,  ...,  4.4996e-02,\n",
              "           2.1768e-01,  2.0000e+00],\n",
              "         [ 1.2894e-01, -4.2952e-02,  7.4145e-03,  ...,  2.3884e-01,\n",
              "           1.2842e-01,  2.0000e+00],\n",
              "         [ 1.2762e-01,  8.7847e-03,  2.8929e-02,  ...,  3.0764e-01,\n",
              "          -1.4697e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-8.4850e-02,  1.6533e-01,  2.4531e-01,  ...,  4.9639e-02,\n",
              "           1.4681e-03,  2.0000e+00],\n",
              "         [-2.3023e-01,  1.4623e-01,  3.3877e-01,  ...,  6.0345e-02,\n",
              "          -1.4728e-02,  2.0000e+00],\n",
              "         [-2.7656e-01,  1.0646e-01,  3.0033e-01,  ...,  6.0272e-02,\n",
              "           1.6964e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0177, -0.1232, -0.0602,  ...,  0.0316,  0.2050,  2.0000],\n",
              "         [ 0.1966, -0.0373, -0.0440,  ...,  0.2154,  0.0436,  2.0000],\n",
              "         [ 0.1923, -0.0034, -0.0421,  ...,  0.2881, -0.0988,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0945,  0.0596,  0.0642,  ...,  0.0357,  0.0398,  2.0000],\n",
              "         [-0.1310,  0.1166,  0.2917,  ...,  0.0924, -0.0204,  2.0000],\n",
              "         [-0.2562,  0.0706,  0.2970,  ...,  0.0638, -0.0110,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0094, -0.1181, -0.0385,  ...,  0.0415,  0.2148,  2.0000],\n",
              "         [ 0.1481, -0.0335, -0.0088,  ...,  0.2341,  0.0990,  2.0000],\n",
              "         [ 0.1519,  0.0199,  0.0054,  ...,  0.3041, -0.0543,  2.0000],\n",
              "         ...,\n",
              "         [-0.0148,  0.1417,  0.1780,  ...,  0.0559,  0.0184,  2.0000],\n",
              "         [-0.1994,  0.1423,  0.3269,  ...,  0.0763, -0.0053,  2.0000],\n",
              "         [-0.2689,  0.1002,  0.2964,  ...,  0.0630, -0.0022,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-1.7440e-02, -1.2577e-01, -3.2379e-02,  ...,  4.0128e-02,\n",
              "           2.1103e-01,  2.0000e+00],\n",
              "         [ 1.3356e-01, -3.3417e-02, -1.0803e-03,  ...,  2.4027e-01,\n",
              "           1.1625e-01,  2.0000e+00],\n",
              "         [ 1.3925e-01,  2.3985e-02,  1.5978e-02,  ...,  3.1106e-01,\n",
              "          -2.3938e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-6.6369e-02,  1.4241e-01,  2.2864e-01,  ...,  7.0994e-02,\n",
              "          -1.0777e-03,  2.0000e+00],\n",
              "         [-2.2607e-01,  1.3679e-01,  3.4740e-01,  ...,  6.7970e-02,\n",
              "          -2.1490e-02,  2.0000e+00],\n",
              "         [-2.8120e-01,  1.0519e-01,  3.0481e-01,  ...,  5.0926e-02,\n",
              "          -6.3045e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0182, -0.1194, -0.0318,  ...,  0.0437,  0.2120,  2.0000],\n",
              "         [ 0.1339, -0.0202, -0.0051,  ...,  0.2347,  0.1140,  2.0000],\n",
              "         [ 0.1375,  0.0460,  0.0161,  ...,  0.3032, -0.0336,  2.0000],\n",
              "         ...,\n",
              "         [-0.0249,  0.1289,  0.1845,  ...,  0.0387,  0.0302,  2.0000],\n",
              "         [-0.2199,  0.1252,  0.3433,  ...,  0.0567, -0.0043,  2.0000],\n",
              "         [-0.2756,  0.1024,  0.3036,  ...,  0.0497,  0.0072,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-2.9808e-02, -1.1812e-01, -3.0976e-02,  ...,  4.6258e-02,\n",
              "           2.0757e-01,  2.0000e+00],\n",
              "         [ 1.2554e-01, -5.7124e-02, -1.3603e-02,  ...,  2.3752e-01,\n",
              "           1.4562e-01,  2.0000e+00],\n",
              "         [ 1.0603e-01, -2.8482e-02, -1.9861e-03,  ...,  3.2363e-01,\n",
              "           3.0400e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [-1.9993e-01,  1.2040e-01,  3.1001e-01,  ...,  7.1407e-02,\n",
              "          -2.6007e-02,  2.0000e+00],\n",
              "         [-2.7566e-01,  1.0328e-01,  3.3659e-01,  ...,  6.5047e-02,\n",
              "          -3.9390e-02,  2.0000e+00],\n",
              "         [-3.0385e-01,  8.8114e-02,  2.9841e-01,  ...,  3.6453e-02,\n",
              "          -1.7704e-02,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[ 0.0235, -0.1300, -0.0681,  ...,  0.0223,  0.2049,  2.0000],\n",
              "         [ 0.2120, -0.0565, -0.0517,  ...,  0.1955,  0.0393,  2.0000],\n",
              "         [ 0.2037, -0.0190, -0.0570,  ...,  0.2648, -0.1001,  2.0000],\n",
              "         ...,\n",
              "         [ 0.1041,  0.0295,  0.0565,  ...,  0.0376,  0.0294,  2.0000],\n",
              "         [-0.1146,  0.0895,  0.2741,  ...,  0.0938, -0.0292,  2.0000],\n",
              "         [-0.2670,  0.0543,  0.3000,  ...,  0.0684, -0.0091,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 0.0204, -0.1259, -0.0627,  ...,  0.0293,  0.2048,  2.0000],\n",
              "         [ 0.2085, -0.0506, -0.0441,  ...,  0.2101,  0.0415,  2.0000],\n",
              "         [ 0.2024, -0.0165, -0.0473,  ...,  0.2792, -0.0996,  2.0000],\n",
              "         ...,\n",
              "         [ 0.0973,  0.0453,  0.0707,  ...,  0.0404,  0.0309,  2.0000],\n",
              "         [-0.1200,  0.1015,  0.2818,  ...,  0.0948, -0.0240,  2.0000],\n",
              "         [-0.2619,  0.0606,  0.3000,  ...,  0.0685, -0.0083,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 8.8080e-03, -1.1037e-01, -5.7706e-02,  ...,  2.6457e-02,\n",
              "           2.0534e-01,  2.0000e+00],\n",
              "         [ 1.6633e-01, -8.0629e-03, -3.6634e-02,  ...,  2.1620e-01,\n",
              "           6.4027e-02,  2.0000e+00],\n",
              "         [ 1.8535e-01,  4.4250e-02, -3.7914e-02,  ...,  2.8137e-01,\n",
              "          -8.1634e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 5.0509e-02,  9.0618e-02,  8.8342e-02,  ...,  2.7549e-02,\n",
              "           6.1514e-02,  2.0000e+00],\n",
              "         [-1.5167e-01,  1.3188e-01,  3.0347e-01,  ...,  6.7020e-02,\n",
              "           7.9188e-03,  2.0000e+00],\n",
              "         [-2.5054e-01,  8.8717e-02,  2.9750e-01,  ...,  4.8398e-02,\n",
              "           1.7598e-03,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0299, -0.1509, -0.0413,  ...,  0.0579,  0.2178,  2.0000],\n",
              "         [ 0.1621, -0.0927, -0.0499,  ...,  0.2908,  0.1544,  2.0000],\n",
              "         [ 0.1198, -0.0810, -0.0473,  ...,  0.3816,  0.0574,  2.0000],\n",
              "         ...,\n",
              "         [-0.1491,  0.0274,  0.2353,  ...,  0.0976, -0.0054,  2.0000],\n",
              "         [-0.2293,  0.0354,  0.2514,  ...,  0.0846, -0.0401,  2.0000],\n",
              "         [-0.2657,  0.0361,  0.2641,  ...,  0.0431, -0.0175,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[ 1.1721e-03, -1.1036e-01, -5.4335e-02,  ...,  2.4224e-02,\n",
              "           2.0265e-01,  2.0000e+00],\n",
              "         [ 1.4893e-01, -1.1676e-02, -2.5376e-02,  ...,  2.1571e-01,\n",
              "           6.8167e-02,  2.0000e+00],\n",
              "         [ 1.6981e-01,  4.6952e-02, -2.3690e-02,  ...,  2.8314e-01,\n",
              "          -7.8552e-02,  2.0000e+00],\n",
              "         ...,\n",
              "         [ 1.2748e-02,  9.8542e-02,  1.2402e-01,  ...,  3.8270e-02,\n",
              "           4.4430e-02,  2.0000e+00],\n",
              "         [-1.7089e-01,  1.2913e-01,  3.0919e-01,  ...,  6.5967e-02,\n",
              "           2.1187e-03,  2.0000e+00],\n",
              "         [-2.6153e-01,  8.5803e-02,  2.9994e-01,  ...,  4.3303e-02,\n",
              "           5.6556e-04,  2.0000e+00]], device='cuda:0'),\n",
              " tensor([[-0.0319, -0.1443, -0.0398,  ...,  0.0553,  0.2166,  2.0000],\n",
              "         [ 0.1525, -0.0863, -0.0459,  ...,  0.2808,  0.1583,  2.0000],\n",
              "         [ 0.1085, -0.0778, -0.0429,  ...,  0.3720,  0.0647,  2.0000],\n",
              "         ...,\n",
              "         [-0.1744,  0.0339,  0.2545,  ...,  0.0945, -0.0151,  2.0000],\n",
              "         [-0.2549,  0.0403,  0.2646,  ...,  0.0809, -0.0462,  2.0000],\n",
              "         [-0.2785,  0.0455,  0.2725,  ...,  0.0372, -0.0184,  2.0000]],\n",
              "        device='cuda:0'),\n",
              " tensor([[-0.0303, -0.1538, -0.0449,  ...,  0.0513,  0.2144,  2.0000],\n",
              "         [ 0.1502, -0.0953, -0.0573,  ...,  0.2756,  0.1585,  2.0000],\n",
              "         [ 0.1031, -0.0893, -0.0589,  ...,  0.3671,  0.0681,  2.0000],\n",
              "         ...,\n",
              "         [-0.1543,  0.0094,  0.2310,  ...,  0.0885, -0.0046,  2.0000],\n",
              "         [-0.2319,  0.0160,  0.2450,  ...,  0.0738, -0.0347,  2.0000],\n",
              "         [-0.2665,  0.0256,  0.2579,  ...,  0.0325, -0.0210,  2.0000]],\n",
              "        device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert the list of tensors to a list of NumPy arrays\n",
        "final_features_numpy = [tensor.cpu().numpy() for tensor in final_features]\n",
        "\n",
        "# Save the list of NumPy arrays using NumPy's save function\n",
        "np.save('/content/extra_data.npy', final_features_numpy)"
      ],
      "metadata": {
        "id": "jSWYc1yLxVA4",
        "outputId": "8eeb16ef-4513-440d-96fc-e6ec90af713a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "id": "zDSXtjMm_bEz",
        "outputId": "63be7153-6875-4085-fc14-f76bb8d09529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM02.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM03.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF03.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM02.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-FM01.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM03.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-FM01.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF01.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF02.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF01.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.avi': 'session1/S07A/S/MSP-IMPROV-S07A-F01-S-MF03.wav',\n",
              " 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.avi': 'session1/S07A/S/MSP-IMPROV-S07A-M01-S-MF02.wav',\n",
              " 'session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.avi': 'session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM02.wav',\n",
              " 'session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.avi': 'session1/S07A/R/MSP-IMPROV-S07A-M01-R-MM01.wav',\n",
              " 'session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.avi': 'session1/S07A/T/MSP-IMPROV-S07A-F01-T-FM01.wav',\n",
              " 'session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.avi': 'session1/S07A/T/MSP-IMPROV-S07A-M01-T-MF01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM04.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF03.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-MF02.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM02.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM02.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-MF02.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM01.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.avi': 'session1/S07A/P/MSP-IMPROV-S07A-F01-P-FM03.wav',\n",
              " 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.avi': 'session1/S07A/P/MSP-IMPROV-S07A-M01-P-FM03.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.avi': 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF01.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.avi': 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM02.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.avi': 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF02.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.avi': 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM02.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.avi': 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-FM01.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.avi': 'session1/S08H/S/MSP-IMPROV-S08H-M01-S-MF02.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.avi': 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-FM01.wav',\n",
              " 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.avi': 'session1/S08H/S/MSP-IMPROV-S08H-F01-S-MF01.wav',\n",
              " 'session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.avi': 'session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM01.wav',\n",
              " 'session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.avi': 'session1/S08H/R/MSP-IMPROV-S08H-M01-R-MM02.wav',\n",
              " 'session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.avi': 'session1/S08H/T/MSP-IMPROV-S08H-F01-T-FM01.wav',\n",
              " 'session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.avi': 'session1/S08H/T/MSP-IMPROV-S08H-M01-T-MF01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.avi': 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF02.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.avi': 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF03.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.avi': 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.avi': 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.avi': 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-FM02.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.avi': 'session1/S08H/P/MSP-IMPROV-S08H-F01-P-MF01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.avi': 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-FM01.wav',\n",
              " 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.avi': 'session1/S08H/P/MSP-IMPROV-S08H-M01-P-MF02.wav',\n",
              " 'session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.avi': 'session1/S12A/R/MSP-IMPROV-S12A-M01-R-MM01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF02.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-MF01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM02.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-MF03.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM02.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM03.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM01.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.avi': 'session1/S08S/S/MSP-IMPROV-S08S-F01-S-FM04.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM04.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM03.wav',\n",
              " 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.avi': 'session1/S08S/S/MSP-IMPROV-S08S-M01-S-FM05.wav',\n",
              " 'session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.avi': 'session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM01.wav',\n",
              " 'session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.avi': 'session1/S08S/R/MSP-IMPROV-S08S-M01-R-MM02.wav',\n",
              " 'session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.avi': 'session1/S08S/T/MSP-IMPROV-S08S-M01-T-MF01.wav',\n",
              " 'session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.avi': 'session1/S08S/T/MSP-IMPROV-S08S-F01-T-FM01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF02.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM04.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-MF01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM03.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM04.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM05.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM02.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF03.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF02.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM02.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-MF01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.avi': 'session1/S08S/P/MSP-IMPROV-S08S-M01-P-FM01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM01.wav',\n",
              " 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.avi': 'session1/S08S/P/MSP-IMPROV-S08S-F01-P-FM03.wav',\n",
              " 'session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.avi': 'session1/S20N/R/MSP-IMPROV-S20N-M01-R-MM01.wav',\n",
              " 'session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.avi': 'session1/S20S/R/MSP-IMPROV-S20S-M01-R-MM01.wav',\n",
              " 'session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.avi': 'session1/S14S/R/MSP-IMPROV-S14S-M01-R-MM01.wav',\n",
              " 'session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.avi': 'session1/S16H/R/MSP-IMPROV-S16H-M01-R-MM01.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.avi': 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF02.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM02.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF02.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.avi': 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-MF01.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-FM01.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.avi': 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM01.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF03.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.avi': 'session1/S10H/S/MSP-IMPROV-S10H-M01-S-FM02.wav',\n",
              " 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.avi': 'session1/S10H/S/MSP-IMPROV-S10H-F01-S-MF01.wav',\n",
              " 'session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.avi': 'session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM01.wav',\n",
              " 'session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.avi': 'session1/S10H/R/MSP-IMPROV-S10H-M01-R-MM02.wav',\n",
              " 'session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.avi': 'session1/S10H/T/MSP-IMPROV-S10H-M01-T-MF01.wav',\n",
              " 'session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.avi': 'session1/S10H/T/MSP-IMPROV-S10H-F01-T-FM01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.avi': 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF03.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.avi': 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF02.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.avi': 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-MF01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM03.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.avi': 'session1/S10H/P/MSP-IMPROV-S10H-M01-P-FM01.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-MF02.wav',\n",
              " 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.avi': 'session1/S10H/P/MSP-IMPROV-S10H-F01-P-FM02.wav',\n",
              " 'session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.avi': 'session1/S18S/R/MSP-IMPROV-S18S-M01-R-MM01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF05.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF02.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-FM01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.avi': 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.avi': 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM01.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF03.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.avi': 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-FM02.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.avi': 'session1/S10N/S/MSP-IMPROV-S10N-F01-S-MF04.wav',\n",
              " 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.avi': 'session1/S10N/S/MSP-IMPROV-S10N-M01-S-MF02.wav',\n",
              " 'session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.avi': 'session1/S10N/R/MSP-IMPROV-S10N-M01-R-MM01.wav',\n",
              " 'session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.avi': 'session1/S10N/T/MSP-IMPROV-S10N-M01-T-MF01.wav',\n",
              " 'session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.avi': 'session1/S10N/T/MSP-IMPROV-S10N-F01-T-FM01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF02.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM02.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-FM01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF04.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM02.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF02.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.avi': 'session1/S10N/P/MSP-IMPROV-S10N-F01-P-MF03.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-FM01.wav',\n",
              " 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.avi': 'session1/S10N/P/MSP-IMPROV-S10N-M01-P-MF03.wav',\n",
              " 'session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.avi': 'session1/S13H/R/MSP-IMPROV-S13H-M01-R-MM01.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF02.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF03.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF01.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM02.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM02.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM01.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-FM03.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM03.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-FM01.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.avi': 'session1/S04S/S/MSP-IMPROV-S04S-M01-S-MF03.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF02.wav',\n",
              " 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.avi': 'session1/S04S/S/MSP-IMPROV-S04S-F01-S-MF01.wav',\n",
              " 'session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.avi': 'session1/S04S/R/MSP-IMPROV-S04S-M01-R-MM01.wav',\n",
              " 'session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.avi': 'session1/S04S/T/MSP-IMPROV-S04S-M01-T-MF01.wav',\n",
              " 'session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.avi': 'session1/S04S/T/MSP-IMPROV-S04S-F01-T-FM01.wav',\n",
              " 'session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.avi': 'session1/S04S/P/MSP-IMPROV-S04S-F01-P-FM01.wav',\n",
              " 'session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.avi': 'session1/S04S/P/MSP-IMPROV-S04S-M01-P-MF01.wav',\n",
              " 'session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.avi': 'session1/S04S/P/MSP-IMPROV-S04S-F01-P-MF01.wav',\n",
              " 'session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.avi': 'session1/S12H/R/MSP-IMPROV-S12H-M01-R-MM01.wav',\n",
              " 'session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.avi': 'session1/S19A/R/MSP-IMPROV-S19A-M01-R-MM01.wav',\n",
              " 'session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.avi': 'session1/S16S/R/MSP-IMPROV-S16S-M01-R-MM01.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF02.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF01.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF04.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF03.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-MF03.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF02.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM02.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-MF01.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM01.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.avi': 'session1/S07H/S/MSP-IMPROV-S07H-F01-S-FM02.wav',\n",
              " 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.avi': 'session1/S07H/S/MSP-IMPROV-S07H-M01-S-FM01.wav',\n",
              " 'session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.avi': 'session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM02.wav',\n",
              " 'session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.avi': 'session1/S07H/R/MSP-IMPROV-S07H-M01-R-MM01.wav',\n",
              " 'session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.avi': 'session1/S07H/T/MSP-IMPROV-S07H-F01-T-FM01.wav',\n",
              " 'session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.avi': 'session1/S07H/T/MSP-IMPROV-S07H-M01-T-MF01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF04.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF03.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM02.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM04.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM02.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF03.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-MF02.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.avi': 'session1/S07H/P/MSP-IMPROV-S07H-F01-P-FM03.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM01.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-MF02.wav',\n",
              " 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.avi': 'session1/S07H/P/MSP-IMPROV-S07H-M01-P-FM03.wav',\n",
              " 'session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.avi': 'session1/S15S/R/MSP-IMPROV-S15S-M01-R-MM01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.avi': 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.avi': 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM02.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.avi': 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-FM01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.avi': 'session1/S07S/S/MSP-IMPROV-S07S-M01-S-MF02.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM01.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM02.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-FM03.wav',\n",
              " 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.avi': 'session1/S07S/S/MSP-IMPROV-S07S-F01-S-MF02.wav',\n",
              " 'session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.avi': 'session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM01.wav',\n",
              " 'session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.avi': 'session1/S07S/R/MSP-IMPROV-S07S-M01-R-MM02.wav',\n",
              " 'session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.avi': 'session1/S07S/T/MSP-IMPROV-S07S-M01-T-MF01.wav',\n",
              " 'session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.avi': 'session1/S07S/T/MSP-IMPROV-S07S-F01-T-FM01.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.avi': 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF01.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.avi': 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-FM01.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF02.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM02.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM03.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-FM01.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.avi': 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF03.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.avi': 'session1/S07S/P/MSP-IMPROV-S07S-M01-P-MF02.wav',\n",
              " 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.avi': 'session1/S07S/P/MSP-IMPROV-S07S-F01-P-MF01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF03.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF02.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM02.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF02.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-FM02.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF03.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-MF04.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.avi': 'session1/S03A/S/MSP-IMPROV-S03A-F01-S-FM01.wav',\n",
              " 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.avi': 'session1/S03A/S/MSP-IMPROV-S03A-M01-S-MF04.wav',\n",
              " 'session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.avi': 'session1/S03A/R/MSP-IMPROV-S03A-M01-R-MM01.wav',\n",
              " 'session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.avi': 'session1/S03A/T/MSP-IMPROV-S03A-F01-T-FM01.wav',\n",
              " 'session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.avi': 'session1/S03A/T/MSP-IMPROV-S03A-M01-T-MF01.wav',\n",
              " 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.avi': 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF02.wav',\n",
              " 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.avi': 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-FM01.wav',\n",
              " 'session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.avi': 'session1/S03A/P/MSP-IMPROV-S03A-F01-P-FM01.wav',\n",
              " 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.avi': 'session1/S03A/P/MSP-IMPROV-S03A-M01-P-MF01.wav',\n",
              " 'session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.avi': 'session1/S17H/R/MSP-IMPROV-S17H-M01-R-MM01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF03.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.avi': 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.avi': 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM02.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.avi': 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-FM02.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-MF02.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.avi': 'session1/S04H/S/MSP-IMPROV-S04H-M01-S-FM01.wav',\n",
              " 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.avi': 'session1/S04H/S/MSP-IMPROV-S04H-F01-S-MF02.wav',\n",
              " 'session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.avi': 'session1/S04H/R/MSP-IMPROV-S04H-M01-R-MM01.wav',\n",
              " 'session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.avi': 'session1/S04H/T/MSP-IMPROV-S04H-M01-T-MF01.wav',\n",
              " 'session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.avi': 'session1/S04H/T/MSP-IMPROV-S04H-F01-T-FM01.wav',\n",
              " 'session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.avi': 'session1/S04H/P/MSP-IMPROV-S04H-M01-P-MF01.wav',\n",
              " 'session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.avi': 'session1/S04H/P/MSP-IMPROV-S04H-M01-P-FM01.wav',\n",
              " 'session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.avi': 'session1/S04H/P/MSP-IMPROV-S04H-F01-P-FM01.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF03.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF01.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF03.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM01.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM02.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF05.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF01.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF04.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-MF02.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF02.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-FM02.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.avi': 'session1/S01H/S/MSP-IMPROV-S01H-M01-S-MF04.wav',\n",
              " 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.avi': 'session1/S01H/S/MSP-IMPROV-S01H-F01-S-FM01.wav',\n",
              " 'session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.avi': 'session1/S01H/R/MSP-IMPROV-S01H-M01-R-MM01.wav',\n",
              " 'session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.avi': 'session1/S01H/T/MSP-IMPROV-S01H-M01-T-MF01.wav',\n",
              " 'session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.avi': 'session1/S01H/T/MSP-IMPROV-S01H-F01-T-FM01.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.avi': 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM03.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.avi': 'session1/S01H/P/MSP-IMPROV-S01H-M01-P-FM01.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.avi': 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-MF01.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.avi': 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM01.wav',\n",
              " 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.avi': 'session1/S01H/P/MSP-IMPROV-S01H-F01-P-FM02.wav',\n",
              " 'session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.avi': 'session1/S13S/R/MSP-IMPROV-S13S-M01-R-MM01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.avi': 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM02.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.avi': 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF02.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.avi': 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-MF01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.avi': 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.avi': 'session1/S06S/S/MSP-IMPROV-S06S-M01-S-FM01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.avi': 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-MF01.wav',\n",
              " 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.avi': 'session1/S06S/S/MSP-IMPROV-S06S-F01-S-FM02.wav',\n",
              " 'session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.avi': 'session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM01.wav',\n",
              " 'session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.avi': 'session1/S06S/R/MSP-IMPROV-S06S-M01-R-MM02.wav',\n",
              " 'session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.avi': 'session1/S06S/T/MSP-IMPROV-S06S-F01-T-FM01.wav',\n",
              " 'session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.avi': 'session1/S06S/T/MSP-IMPROV-S06S-M01-T-MF01.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.avi': 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-MF01.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.avi': 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-FM01.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.avi': 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF02.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.avi': 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF01.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.avi': 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM02.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.avi': 'session1/S06S/P/MSP-IMPROV-S06S-M01-P-MF03.wav',\n",
              " 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.avi': 'session1/S06S/P/MSP-IMPROV-S06S-F01-P-FM01.wav',\n",
              " 'session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.avi': 'session1/S17S/R/MSP-IMPROV-S17S-M01-R-MM01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM02.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM03.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF02.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-FM03.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM04.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.avi': 'session1/S02S/S/MSP-IMPROV-S02S-M01-S-MF03.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF03.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM01.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-MF02.wav',\n",
              " 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.avi': 'session1/S02S/S/MSP-IMPROV-S02S-F01-S-FM02.wav',\n",
              " 'session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.avi': 'session1/S02S/R/MSP-IMPROV-S02S-M01-R-MM01.wav',\n",
              " 'session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.avi': 'session1/S02S/T/MSP-IMPROV-S02S-M01-T-MF01.wav',\n",
              " 'session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.avi': 'session1/S02S/T/MSP-IMPROV-S02S-F01-T-FM01.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.avi': 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF03.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.avi': 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF01.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.avi': 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-MF02.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.avi': 'session1/S02S/P/MSP-IMPROV-S02S-M01-P-FM01.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.avi': 'session1/S02S/P/MSP-IMPROV-S02S-F01-P-MF01.wav',\n",
              " 'session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.avi': 'session1/S02S/P/MSP-IMPROV-S02S-F01-P-FM01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF03.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM03.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF05.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF02.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM02.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF05.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-FM03.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF04.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF02.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF06.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF04.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF01.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-FM02.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.avi': 'session1/S01S/S/MSP-IMPROV-S01S-M01-S-MF03.wav',\n",
              " 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.avi': 'session1/S01S/S/MSP-IMPROV-S01S-F01-S-MF06.wav',\n",
              " 'session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.avi': 'session1/S01S/R/MSP-IMPROV-S01S-M01-R-MM01.wav',\n",
              " 'session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.avi': 'session1/S01S/T/MSP-IMPROV-S01S-M01-T-MF01.wav',\n",
              " 'session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.avi': 'session1/S01S/T/MSP-IMPROV-S01S-F01-T-FM01.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM02.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.avi': 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF04.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF02.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.avi': 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF01.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF03.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.avi': 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF03.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF01.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-MF04.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.avi': 'session1/S01S/P/MSP-IMPROV-S01S-M01-P-MF02.wav',\n",
              " 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.avi': 'session1/S01S/P/MSP-IMPROV-S01S-F01-P-FM01.wav',\n",
              " 'session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.avi': 'session1/S16N/R/MSP-IMPROV-S16N-M01-R-MM01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM03.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM03.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF02.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM02.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM04.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM04.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-MF01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-FM05.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.avi': 'session1/S08A/S/MSP-IMPROV-S08A-M01-S-MF01.wav',\n",
              " 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.avi': 'session1/S08A/S/MSP-IMPROV-S08A-F01-S-FM02.wav',\n",
              " 'session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.avi': 'session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM02.wav',\n",
              " 'session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.avi': 'session1/S08A/R/MSP-IMPROV-S08A-M01-R-MM01.wav',\n",
              " 'session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.avi': 'session1/S08A/T/MSP-IMPROV-S08A-F01-T-FM01.wav',\n",
              " 'session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.avi': 'session1/S08A/T/MSP-IMPROV-S08A-M01-T-MF01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM02.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-MF01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM04.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM03.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM03.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF02.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM05.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-FM01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM02.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.avi': 'session1/S08A/P/MSP-IMPROV-S08A-M01-P-MF01.wav',\n",
              " 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.avi': 'session1/S08A/P/MSP-IMPROV-S08A-F01-P-FM06.wav',\n",
              " 'session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.avi': 'session1/S20A/R/MSP-IMPROV-S20A-M01-R-MM01.wav',\n",
              " 'session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.avi': 'session1/S13N/R/MSP-IMPROV-S13N-M01-R-MM01.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM01.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF03.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF01.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM01.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF02.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-FM02.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-FM02.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF03.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.avi': 'session1/S09H/S/MSP-IMPROV-S09H-F01-S-MF02.wav',\n",
              " 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.avi': 'session1/S09H/S/MSP-IMPROV-S09H-M01-S-MF01.wav',\n",
              " 'session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.avi': 'session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM02.wav',\n",
              " 'session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.avi': 'session1/S09H/R/MSP-IMPROV-S09H-M01-R-MM01.wav',\n",
              " 'session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.avi': 'session1/S09H/T/MSP-IMPROV-S09H-F01-T-FM01.wav',\n",
              " 'session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.avi': 'session1/S09H/T/MSP-IMPROV-S09H-M01-T-MF01.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM02.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF04.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF02.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM01.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM01.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF02.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF03.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-MF01.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF03.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.avi': 'session1/S09H/P/MSP-IMPROV-S09H-M01-P-FM03.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-FM02.wav',\n",
              " 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.avi': 'session1/S09H/P/MSP-IMPROV-S09H-F01-P-MF01.wav',\n",
              " 'session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.avi': 'session1/S19H/R/MSP-IMPROV-S19H-M01-R-MM01.wav',\n",
              " 'session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.avi': 'session1/S11H/R/MSP-IMPROV-S11H-M01-R-MM01.wav',\n",
              " 'session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.avi': 'session1/S15A/R/MSP-IMPROV-S15A-M01-R-MM01.wav',\n",
              " 'session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.avi': 'session1/S17N/R/MSP-IMPROV-S17N-M01-R-MM01.wav',\n",
              " 'session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.avi': 'session1/S14N/R/MSP-IMPROV-S14N-M01-R-MM01.wav',\n",
              " 'session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.avi': 'session1/S11S/R/MSP-IMPROV-S11S-M01-R-MM01.wav',\n",
              " 'session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.avi': 'session1/S19S/R/MSP-IMPROV-S19S-M01-R-MM01.wav',\n",
              " 'session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.avi': 'session1/S14H/R/MSP-IMPROV-S14H-M01-R-MM01.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.avi': 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-MF01.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.avi': 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM02.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.avi': 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF01.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.avi': 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-MF02.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.avi': 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM01.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.avi': 'session1/S05N/S/MSP-IMPROV-S05N-M01-S-FM02.wav',\n",
              " 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.avi': 'session1/S05N/S/MSP-IMPROV-S05N-F01-S-FM01.wav',\n",
              " 'session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.avi': 'session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM01.wav',\n",
              " 'session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.avi': 'session1/S05N/R/MSP-IMPROV-S05N-M01-R-MM02.wav',\n",
              " 'session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.avi': 'session1/S05N/T/MSP-IMPROV-S05N-M01-T-MF01.wav',\n",
              " 'session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.avi': 'session1/S05N/T/MSP-IMPROV-S05N-F01-T-FM01.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.avi': 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF02.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.avi': 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF02.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.avi': 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM02.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.avi': 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-MF01.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.avi': 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-MF01.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.avi': 'session1/S05N/P/MSP-IMPROV-S05N-M01-P-FM01.wav',\n",
              " 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.avi': 'session1/S05N/P/MSP-IMPROV-S05N-F01-P-FM01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.avi': 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-MF01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.avi': 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.avi': 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.avi': 'session1/S09N/S/MSP-IMPROV-S09N-F01-S-FM02.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.avi': 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-MF01.wav',\n",
              " 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.avi': 'session1/S09N/S/MSP-IMPROV-S09N-M01-S-FM02.wav',\n",
              " 'session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.avi': 'session1/S09N/R/MSP-IMPROV-S09N-M01-R-MM01.wav',\n",
              " 'session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.avi': 'session1/S09N/T/MSP-IMPROV-S09N-M01-T-MF01.wav',\n",
              " 'session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.avi': 'session1/S09N/T/MSP-IMPROV-S09N-F01-T-FM01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-FM01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF04.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.avi': 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-MF01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.avi': 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM01.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF03.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.avi': 'session1/S09N/P/MSP-IMPROV-S09N-M01-P-MF02.wav',\n",
              " 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.avi': 'session1/S09N/P/MSP-IMPROV-S09N-F01-P-FM02.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM03.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM02.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM04.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF02.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.avi': 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF01.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.avi': 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-MF02.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.avi': 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM01.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-FM01.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.avi': 'session1/S03H/S/MSP-IMPROV-S03H-M01-S-MF01.wav',\n",
              " 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.avi': 'session1/S03H/S/MSP-IMPROV-S03H-F01-S-FM02.wav',\n",
              " 'session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.avi': 'session1/S03H/R/MSP-IMPROV-S03H-M01-R-MM01.wav',\n",
              " 'session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.avi': 'session1/S03H/T/MSP-IMPROV-S03H-F01-T-FM01.wav',\n",
              " 'session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.avi': 'session1/S03H/T/MSP-IMPROV-S03H-M01-T-MF01.wav'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(files.items(), columns=['Video File', 'Audio File'])\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "df.to_csv(\"/content/files.csv\", index=False)"
      ],
      "metadata": {
        "id": "ixa-aVSH_Emx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load('/content/session1.npy', allow_pickle=True)\n",
        "data_extra = np.load('/content/extra_data.npy', allow_pickle=True)\n",
        "\n",
        "# Combine both datasets horizontally if they have the same number of samples\n",
        "combined_data = np.hstack((data, data_extra))\n",
        "\n",
        "# Alternatively, if you want to combine them vertically (assuming they have the same number of features)\n",
        "# combined_data = np.vstack((data, data_extra))\n",
        "\n",
        "# Now you can use the combined data\n",
        "print(combined_data)"
      ],
      "metadata": {
        "id": "yy2NdF1ZzuJ5",
        "outputId": "cb52b7e9-8baf-4737-cda1-b7d290e8a2f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[-0.02370743, -0.13372436, -0.02600399, ...,  0.04763608,\n",
            "          0.2146651 ,  0.        ],\n",
            "        [ 0.13718703, -0.04317781, -0.0023525 , ...,  0.24006915,\n",
            "          0.13413857,  0.        ],\n",
            "        [ 0.13125321,  0.0069481 ,  0.02102276, ...,  0.31726515,\n",
            "          0.00163406,  0.        ],\n",
            "        ...,\n",
            "        [-0.11683967,  0.14273715,  0.24456276, ...,  0.0557744 ,\n",
            "         -0.01042632,  0.        ],\n",
            "        [-0.25608966,  0.13328592,  0.33725896, ...,  0.05293535,\n",
            "         -0.03525682,  0.        ],\n",
            "        [-0.2928651 ,  0.10035783,  0.30199414, ...,  0.05435017,\n",
            "         -0.00631261,  0.        ]], dtype=float32)\n",
            " array([[-0.03537891, -0.15370318, -0.05731953, ...,  0.05926085,\n",
            "          0.20858468,  0.        ],\n",
            "        [ 0.1362604 , -0.11624897, -0.07601633, ...,  0.2856895 ,\n",
            "          0.16155516,  0.        ],\n",
            "        [ 0.08013933, -0.1172556 , -0.08037224, ...,  0.38533303,\n",
            "          0.089897  ,  0.        ],\n",
            "        ...,\n",
            "        [-0.18725322,  0.02207345,  0.20027992, ...,  0.10902755,\n",
            "         -0.03959378,  0.        ],\n",
            "        [-0.26085004,  0.03997039,  0.20246252, ...,  0.08697025,\n",
            "         -0.06886151,  0.        ],\n",
            "        [-0.27534908,  0.01665409,  0.23802942, ...,  0.02345487,\n",
            "         -0.03786651,  0.        ]], dtype=float32)\n",
            " array([[-0.03607857, -0.15551116, -0.05748026, ...,  0.06323748,\n",
            "          0.20388332,  0.        ],\n",
            "        [ 0.1257649 , -0.12229984, -0.07067903, ...,  0.28593433,\n",
            "          0.1541902 ,  0.        ],\n",
            "        [ 0.06149955, -0.11712244, -0.0765297 , ...,  0.38928068,\n",
            "          0.08003119,  0.        ],\n",
            "        ...,\n",
            "        [-0.20857674,  0.03517333,  0.19763818, ...,  0.09065197,\n",
            "         -0.06127654,  0.        ],\n",
            "        [-0.26356274,  0.05463022,  0.19619335, ...,  0.07742973,\n",
            "         -0.07909571,  0.        ],\n",
            "        [-0.26289034,  0.02500576,  0.2315907 , ...,  0.02149431,\n",
            "         -0.04270244,  0.        ]], dtype=float32)\n",
            " array([[-0.02500229, -0.12419444, -0.0230597 , ...,  0.03925381,\n",
            "          0.20727544,  0.        ],\n",
            "        [ 0.11965357, -0.03784336,  0.00580956, ...,  0.2303323 ,\n",
            "          0.12200487,  0.        ],\n",
            "        [ 0.11399645,  0.02013571,  0.0284889 , ...,  0.30917853,\n",
            "         -0.01423023,  0.        ],\n",
            "        ...,\n",
            "        [-0.08538663,  0.1339196 ,  0.24221587, ...,  0.05124141,\n",
            "          0.00042278,  0.        ],\n",
            "        [-0.25249273,  0.13092214,  0.36210743, ...,  0.04511794,\n",
            "         -0.02770517,  0.        ],\n",
            "        [-0.3028342 ,  0.09778896,  0.3151183 , ...,  0.04178696,\n",
            "         -0.00610329,  0.        ]], dtype=float32)\n",
            " array([[-0.02486484, -0.12405111, -0.02459172, ...,  0.03837623,\n",
            "          0.20661631,  0.        ],\n",
            "        [ 0.11837108, -0.03533713,  0.00842633, ...,  0.22825694,\n",
            "          0.11790617,  0.        ],\n",
            "        [ 0.11600338,  0.02506382,  0.03001561, ...,  0.30349258,\n",
            "         -0.01837688,  0.        ],\n",
            "        ...,\n",
            "        [-0.0724698 ,  0.1359897 ,  0.23710434, ...,  0.04595288,\n",
            "          0.00697935,  0.        ],\n",
            "        [-0.2477171 ,  0.12963073,  0.3639451 , ...,  0.04053193,\n",
            "         -0.02335457,  0.        ],\n",
            "        [-0.30145678,  0.10072804,  0.31437138, ...,  0.03635113,\n",
            "         -0.00419059,  0.        ]], dtype=float32)\n",
            " array([[-0.0342677 , -0.1485397 , -0.05283961, ...,  0.06347413,\n",
            "          0.20657684,  0.        ],\n",
            "        [ 0.13573994, -0.10990519, -0.06330301, ...,  0.2779925 ,\n",
            "          0.16426933,  0.        ],\n",
            "        [ 0.0722834 , -0.10031857, -0.06333723, ...,  0.39043885,\n",
            "          0.07845128,  0.        ],\n",
            "        ...,\n",
            "        [-0.20912988,  0.02982185,  0.20524819, ...,  0.08181554,\n",
            "         -0.0495782 ,  0.        ],\n",
            "        [-0.27874568,  0.06711469,  0.21264425, ...,  0.07579659,\n",
            "         -0.07448984,  0.        ],\n",
            "        [-0.26983225,  0.03973367,  0.24098092, ...,  0.02459843,\n",
            "         -0.04093658,  0.        ]], dtype=float32)\n",
            " array([[-0.01936195, -0.12854984, -0.03222039, ...,  0.04819154,\n",
            "          0.21759753,  0.        ],\n",
            "        [ 0.13602416, -0.03251903, -0.00822826, ...,  0.2332479 ,\n",
            "          0.13016538,  0.        ],\n",
            "        [ 0.13545136,  0.02948571,  0.01420182, ...,  0.31105047,\n",
            "         -0.01524676,  0.        ],\n",
            "        ...,\n",
            "        [-0.05159966,  0.1437097 ,  0.19490585, ...,  0.0447405 ,\n",
            "          0.02013177,  0.        ],\n",
            "        [-0.23339048,  0.14536934,  0.32798404, ...,  0.05195722,\n",
            "         -0.01632947,  0.        ],\n",
            "        [-0.28302354,  0.1018369 ,  0.2985532 , ...,  0.06248601,\n",
            "          0.00189226,  0.        ]], dtype=float32)\n",
            " array([[-0.02909078, -0.12892984, -0.02832657, ...,  0.05164484,\n",
            "          0.21284892,  0.        ],\n",
            "        [ 0.1365296 , -0.04014882, -0.00611087, ...,  0.260288  ,\n",
            "          0.12425833,  0.        ],\n",
            "        [ 0.13472797,  0.01895142,  0.01258548, ...,  0.3393554 ,\n",
            "         -0.01728581,  0.        ],\n",
            "        ...,\n",
            "        [-0.10186689,  0.13771106,  0.24757463, ...,  0.07211117,\n",
            "         -0.02016887,  0.        ],\n",
            "        [-0.2522118 ,  0.13787414,  0.34365144, ...,  0.06368116,\n",
            "         -0.03979816,  0.        ],\n",
            "        [-0.29183123,  0.10136858,  0.3074484 , ...,  0.05786747,\n",
            "         -0.0039948 ,  0.        ]], dtype=float32)\n",
            " array([[-0.01998688, -0.12230202, -0.03606343, ...,  0.04901915,\n",
            "          0.21473281,  0.        ],\n",
            "        [ 0.13497585, -0.02692945, -0.01392958, ...,  0.25147384,\n",
            "          0.11381592,  0.        ],\n",
            "        [ 0.1419937 ,  0.0441057 ,  0.00546781, ...,  0.3255146 ,\n",
            "         -0.04000742,  0.        ],\n",
            "        ...,\n",
            "        [-0.04174446,  0.13415432,  0.19239491, ...,  0.06249314,\n",
            "          0.00891298,  0.        ],\n",
            "        [-0.22972718,  0.14158139,  0.33223408, ...,  0.07012685,\n",
            "         -0.01444812,  0.        ],\n",
            "        [-0.27693197,  0.1062154 ,  0.3001439 , ...,  0.06919002,\n",
            "          0.00900207,  0.        ]], dtype=float32)\n",
            " array([[-0.03275993, -0.13240142, -0.03244612, ...,  0.05441014,\n",
            "          0.20866147,  0.        ],\n",
            "        [ 0.14567772, -0.06152733, -0.03950933, ...,  0.26471788,\n",
            "          0.14231324,  0.        ],\n",
            "        [ 0.11611474, -0.03909332, -0.03413397, ...,  0.35461205,\n",
            "          0.03736826,  0.        ],\n",
            "        ...,\n",
            "        [-0.12995338,  0.07159282,  0.22283736, ...,  0.0877764 ,\n",
            "          0.01435248,  0.        ],\n",
            "        [-0.24987508,  0.06813926,  0.28487584, ...,  0.06579093,\n",
            "         -0.03164354,  0.        ],\n",
            "        [-0.298417  ,  0.07246787,  0.28003508, ...,  0.03900819,\n",
            "         -0.01789999,  0.        ]], dtype=float32)\n",
            " array([[-0.02471368, -0.1302498 , -0.03211069, ...,  0.05541969,\n",
            "          0.21430624,  0.        ],\n",
            "        [ 0.148229  , -0.03773041, -0.01432231, ...,  0.25957337,\n",
            "          0.12618388,  0.        ],\n",
            "        [ 0.14025053,  0.02197483,  0.00197893, ...,  0.34665796,\n",
            "         -0.0186038 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.08897519,  0.14852779,  0.22235043, ...,  0.07964244,\n",
            "         -0.00155162,  0.        ],\n",
            "        [-0.24862608,  0.13729   ,  0.32170087, ...,  0.07415981,\n",
            "         -0.02730865,  0.        ],\n",
            "        [-0.28536677,  0.1008326 ,  0.2906255 , ...,  0.07192295,\n",
            "          0.00300379,  0.        ]], dtype=float32)\n",
            " array([[-0.03285519, -0.15512265, -0.04500385, ...,  0.05413013,\n",
            "          0.21437165,  0.        ],\n",
            "        [ 0.14824706, -0.09511232, -0.06691869, ...,  0.28242385,\n",
            "          0.15723236,  0.        ],\n",
            "        [ 0.10253986, -0.08699975, -0.07040938, ...,  0.37652814,\n",
            "          0.06184779,  0.        ],\n",
            "        ...,\n",
            "        [-0.13924277,  0.01712721,  0.20593965, ...,  0.09839779,\n",
            "          0.01589254,  0.        ],\n",
            "        [-0.23127711,  0.02602274,  0.23852283, ...,  0.07872743,\n",
            "         -0.03075213,  0.        ],\n",
            "        [-0.27879626,  0.02288869,  0.2528794 , ...,  0.03487115,\n",
            "         -0.02079538,  0.        ]], dtype=float32)\n",
            " array([[-0.01906602, -0.13009223, -0.02706281, ...,  0.04767675,\n",
            "          0.2118906 ,  0.        ],\n",
            "        [ 0.14580615, -0.04203974, -0.00449666, ...,  0.26565394,\n",
            "          0.12750556,  0.        ],\n",
            "        [ 0.14338781,  0.01242558,  0.00790131, ...,  0.34543064,\n",
            "         -0.00039325,  0.        ],\n",
            "        ...,\n",
            "        [-0.07034433,  0.12376413,  0.23174264, ...,  0.08885309,\n",
            "          0.00628269,  0.        ],\n",
            "        [-0.23333563,  0.12473761,  0.33598572, ...,  0.07942343,\n",
            "         -0.02165802,  0.        ],\n",
            "        [-0.2801178 ,  0.1019144 ,  0.29603818, ...,  0.05673892,\n",
            "          0.00153079,  0.        ]], dtype=float32)\n",
            " array([[-0.01235101, -0.12472367, -0.02979217, ...,  0.04745331,\n",
            "          0.21162471,  0.        ],\n",
            "        [ 0.15782714, -0.02590524, -0.01027661, ...,  0.26554808,\n",
            "          0.12168368,  0.        ],\n",
            "        [ 0.1607626 ,  0.03902584,  0.00435659, ...,  0.3408557 ,\n",
            "         -0.01924145,  0.        ],\n",
            "        ...,\n",
            "        [-0.00816077,  0.120345  ,  0.18047245, ...,  0.08070648,\n",
            "          0.03370621,  0.        ],\n",
            "        [-0.20994759,  0.12471105,  0.32758752, ...,  0.08345386,\n",
            "         -0.00404729,  0.        ],\n",
            "        [-0.26326737,  0.10769101,  0.29305622, ...,  0.06205046,\n",
            "          0.00784934,  0.        ]], dtype=float32)\n",
            " array([[-0.03608925, -0.14732003, -0.04858997, ...,  0.06263082,\n",
            "          0.21594658,  0.        ],\n",
            "        [ 0.14929947, -0.09621798, -0.06741466, ...,  0.2875161 ,\n",
            "          0.16454837,  0.        ],\n",
            "        [ 0.09676495, -0.09175082, -0.06904788, ...,  0.3928773 ,\n",
            "          0.07440975,  0.        ],\n",
            "        ...,\n",
            "        [-0.16195181,  0.02162874,  0.21331428, ...,  0.1031585 ,\n",
            "         -0.00631178,  0.        ],\n",
            "        [-0.2668666 ,  0.04269142,  0.23056808, ...,  0.08069089,\n",
            "         -0.05009116,  0.        ],\n",
            "        [-0.2841324 ,  0.03422393,  0.25098827, ...,  0.02836863,\n",
            "         -0.02252825,  0.        ]], dtype=float32)\n",
            " array([[-0.03205482, -0.15306607, -0.05826423, ...,  0.05848508,\n",
            "          0.19614592,  0.        ],\n",
            "        [ 0.11661559, -0.12450714, -0.06531183, ...,  0.26613545,\n",
            "          0.15084761,  0.        ],\n",
            "        [ 0.05322564, -0.12378543, -0.0739498 , ...,  0.3622404 ,\n",
            "          0.08909672,  0.        ],\n",
            "        ...,\n",
            "        [-0.2312307 ,  0.04837891,  0.20153731, ...,  0.05571168,\n",
            "         -0.08012091,  0.        ],\n",
            "        [-0.27201587,  0.06263883,  0.20690666, ...,  0.05159755,\n",
            "         -0.080521  ,  0.        ],\n",
            "        [-0.2532705 ,  0.03527553,  0.23813115, ...,  0.00377882,\n",
            "         -0.04639186,  0.        ]], dtype=float32)\n",
            " array([[-0.03089309, -0.15287411, -0.04528369, ...,  0.05617236,\n",
            "          0.21448341,  0.        ],\n",
            "        [ 0.15069826, -0.09315318, -0.07344322, ...,  0.29175413,\n",
            "          0.15483315,  0.        ],\n",
            "        [ 0.10744145, -0.08745669, -0.08037245, ...,  0.38679308,\n",
            "          0.05938616,  0.        ],\n",
            "        ...,\n",
            "        [-0.12635961,  0.01646423,  0.1950022 , ...,  0.10841226,\n",
            "          0.01871312,  0.        ],\n",
            "        [-0.22632542,  0.01638   ,  0.24219747, ...,  0.08266745,\n",
            "         -0.02394507,  0.        ],\n",
            "        [-0.27956867,  0.02582838,  0.25590143, ...,  0.03796278,\n",
            "         -0.01765267,  0.        ]], dtype=float32)\n",
            " array([[-0.01533999, -0.12756176, -0.0361326 , ...,  0.05343474,\n",
            "          0.21554868,  0.        ],\n",
            "        [ 0.14199942, -0.0323571 , -0.01124815, ...,  0.24973369,\n",
            "          0.1275599 ,  0.        ],\n",
            "        [ 0.14367168,  0.03442477,  0.00839356, ...,  0.32762545,\n",
            "         -0.02130736,  0.        ],\n",
            "        ...,\n",
            "        [-0.03964872,  0.14618976,  0.19309682, ...,  0.05660079,\n",
            "          0.02516399,  0.        ],\n",
            "        [-0.21667892,  0.13380995,  0.31521046, ...,  0.06667425,\n",
            "         -0.00678349,  0.        ],\n",
            "        [-0.26600325,  0.10756316,  0.2880768 , ...,  0.06822252,\n",
            "          0.00873954,  0.        ]], dtype=float32)\n",
            " array([[-0.02022413, -0.16317727, -0.05079167, ...,  0.06557695,\n",
            "          0.21120057,  0.        ],\n",
            "        [ 0.15726665, -0.10057273, -0.07805031, ...,  0.29972228,\n",
            "          0.14128405,  0.        ],\n",
            "        [ 0.1198226 , -0.09464654, -0.08947318, ...,  0.39067245,\n",
            "          0.04756651,  0.        ],\n",
            "        ...,\n",
            "        [-0.09118692, -0.00099511,  0.16144465, ...,  0.10929286,\n",
            "          0.02777003,  0.        ],\n",
            "        [-0.18896282,  0.00612904,  0.20760213, ...,  0.08557413,\n",
            "         -0.01123665,  0.        ],\n",
            "        [-0.24439022,  0.00646162,  0.22743171, ...,  0.05313763,\n",
            "         -0.01866156,  0.        ]], dtype=float32)\n",
            " array([[-0.01980905, -0.12069994, -0.02922124, ...,  0.03633877,\n",
            "          0.20762584,  0.        ],\n",
            "        [ 0.12483246, -0.02440695,  0.00181858, ...,  0.23111223,\n",
            "          0.11270539,  0.        ],\n",
            "        [ 0.12405167,  0.03994989,  0.02272075, ...,  0.3063343 ,\n",
            "         -0.03058712,  0.        ],\n",
            "        ...,\n",
            "        [-0.03274182,  0.13735652,  0.19981267, ...,  0.04438953,\n",
            "          0.02102565,  0.        ],\n",
            "        [-0.22966462,  0.1315441 ,  0.3481256 , ...,  0.04707307,\n",
            "         -0.01564007,  0.        ],\n",
            "        [-0.29106396,  0.09983777,  0.30688432, ...,  0.04347785,\n",
            "         -0.00547949,  0.        ]], dtype=float32)\n",
            " array([[-0.03055925, -0.12257066, -0.03068476, ...,  0.05546754,\n",
            "          0.20693664,  0.        ],\n",
            "        [ 0.13982363, -0.05508897, -0.02907486, ...,  0.2579341 ,\n",
            "          0.14098464,  0.        ],\n",
            "        [ 0.12156689, -0.02404101, -0.01475641, ...,  0.35280538,\n",
            "          0.0223201 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.14191394,  0.11778945,  0.24383704, ...,  0.09086558,\n",
            "         -0.00445726,  0.        ],\n",
            "        [-0.26368392,  0.10513282,  0.31284246, ...,  0.07088094,\n",
            "         -0.0347844 ,  0.        ],\n",
            "        [-0.30569008,  0.08776717,  0.28935313, ...,  0.04238304,\n",
            "         -0.01938193,  0.        ]], dtype=float32)\n",
            " array([[-2.0541552e-02, -1.3063507e-01, -3.2893647e-02, ...,\n",
            "          4.9485222e-02,  2.1786214e-01,  0.0000000e+00],\n",
            "        [ 1.3816391e-01, -3.8975421e-02, -7.9147415e-03, ...,\n",
            "          2.3706266e-01,  1.4166018e-01,  0.0000000e+00],\n",
            "        [ 1.3442741e-01,  1.7652432e-02,  1.5983636e-02, ...,\n",
            "          3.1942508e-01, -6.5524742e-05,  0.0000000e+00],\n",
            "        ...,\n",
            "        [-6.3778631e-02,  1.4532018e-01,  2.0911670e-01, ...,\n",
            "          6.0058605e-02,  2.2321848e-02,  0.0000000e+00],\n",
            "        [-2.3852110e-01,  1.3917221e-01,  3.2560501e-01, ...,\n",
            "          5.8596328e-02, -1.8167062e-02,  0.0000000e+00],\n",
            "        [-2.8478220e-01,  9.6209012e-02,  2.9192749e-01, ...,\n",
            "          6.1185848e-02, -2.5306167e-03,  0.0000000e+00]], dtype=float32)\n",
            " array([[-0.01943466, -0.1263244 , -0.03288626, ...,  0.04937792,\n",
            "          0.21540219,  0.        ],\n",
            "        [ 0.13133927, -0.03121322, -0.006899  , ...,  0.23541635,\n",
            "          0.12841716,  0.        ],\n",
            "        [ 0.13329442,  0.02906696,  0.01641291, ...,  0.31086278,\n",
            "         -0.02123962,  0.        ],\n",
            "        ...,\n",
            "        [-0.04178609,  0.13814554,  0.20053902, ...,  0.04476111,\n",
            "          0.01479603,  0.        ],\n",
            "        [-0.23047175,  0.14309408,  0.33537298, ...,  0.05594037,\n",
            "         -0.01419399,  0.        ],\n",
            "        [-0.27899733,  0.10523123,  0.30244032, ...,  0.0632423 ,\n",
            "          0.00588398,  0.        ]], dtype=float32)\n",
            " array([[-0.00369971, -0.11021082, -0.05207145, ...,  0.03411904,\n",
            "          0.19520046,  0.        ],\n",
            "        [ 0.16688249, -0.00273511, -0.03745453, ...,  0.2379519 ,\n",
            "          0.04242001,  0.        ],\n",
            "        [ 0.17234983,  0.05097849, -0.03435622, ...,  0.30104324,\n",
            "         -0.09331148,  0.        ],\n",
            "        ...,\n",
            "        [ 0.06415537,  0.08696893,  0.06047089, ...,  0.02446827,\n",
            "          0.04336442,  0.        ],\n",
            "        [-0.161503  ,  0.1197079 ,  0.30840528, ...,  0.07842164,\n",
            "         -0.01984229,  0.        ],\n",
            "        [-0.26126558,  0.08850439,  0.2943265 , ...,  0.05340436,\n",
            "         -0.00702881,  0.        ]], dtype=float32)\n",
            " array([[-0.00204518, -0.11129654, -0.05481978, ...,  0.03746331,\n",
            "          0.20879734,  0.        ],\n",
            "        [ 0.14869294, -0.00124637, -0.03406644, ...,  0.22390091,\n",
            "          0.08899555,  0.        ],\n",
            "        [ 0.16369486,  0.05853512, -0.02176691, ...,  0.29793814,\n",
            "         -0.07114974,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05018977,  0.09873749,  0.0709693 , ...,  0.0267044 ,\n",
            "          0.05589729,  0.        ],\n",
            "        [-0.16487712,  0.13689528,  0.30173153, ...,  0.07114115,\n",
            "         -0.00645578,  0.        ],\n",
            "        [-0.25744703,  0.09659939,  0.2936369 , ...,  0.06043224,\n",
            "          0.00230177,  0.        ]], dtype=float32)\n",
            " array([[-0.02465201, -0.13539445, -0.02928443, ...,  0.04968604,\n",
            "          0.2111155 ,  0.        ],\n",
            "        [ 0.1430243 , -0.04739876, -0.01889353, ...,  0.27511445,\n",
            "          0.13270545,  0.        ],\n",
            "        [ 0.12699683, -0.00650876, -0.00142878, ...,  0.363395  ,\n",
            "          0.01277842,  0.        ],\n",
            "        ...,\n",
            "        [-0.10536697,  0.11120117,  0.22587137, ...,  0.08821487,\n",
            "          0.00430284,  0.        ],\n",
            "        [-0.23635817,  0.10365931,  0.30956146, ...,  0.07489333,\n",
            "         -0.03041141,  0.        ],\n",
            "        [-0.2921463 ,  0.08100174,  0.29055023, ...,  0.05781195,\n",
            "         -0.01351557,  0.        ]], dtype=float32)\n",
            " array([[-0.02321586, -0.13654824, -0.02862808, ...,  0.05094765,\n",
            "          0.21710886,  0.        ],\n",
            "        [ 0.1434229 , -0.04493428, -0.01097775, ...,  0.24705996,\n",
            "          0.14202821,  0.        ],\n",
            "        [ 0.13388509,  0.00323357,  0.01418124, ...,  0.3308989 ,\n",
            "          0.00555493,  0.        ],\n",
            "        ...,\n",
            "        [-0.10041725,  0.14327902,  0.22528362, ...,  0.05862287,\n",
            "          0.00343368,  0.        ],\n",
            "        [-0.2468183 ,  0.13283043,  0.32118195, ...,  0.05958578,\n",
            "         -0.02893167,  0.        ],\n",
            "        [-0.2892124 ,  0.09324145,  0.2926407 , ...,  0.06023557,\n",
            "         -0.00454462,  0.        ]], dtype=float32)\n",
            " array([[-0.00883939, -0.11259034, -0.04633435, ...,  0.03447646,\n",
            "          0.19829471,  0.        ],\n",
            "        [ 0.15152343, -0.00552464, -0.02866693, ...,  0.23500021,\n",
            "          0.0598394 ,  0.        ],\n",
            "        [ 0.15799075,  0.05407001, -0.02145906, ...,  0.30316103,\n",
            "         -0.08021063,  0.        ],\n",
            "        ...,\n",
            "        [ 0.04805652,  0.09507069,  0.08137623, ...,  0.02738977,\n",
            "          0.04401999,  0.        ],\n",
            "        [-0.17506193,  0.11932431,  0.31600946, ...,  0.07256276,\n",
            "         -0.01485125,  0.        ],\n",
            "        [-0.2659031 ,  0.0889871 ,  0.29866785, ...,  0.05549423,\n",
            "         -0.0052994 ,  0.        ]], dtype=float32)\n",
            " array([[-0.03256929, -0.15820567, -0.0612855 , ...,  0.06223148,\n",
            "          0.19946757,  1.        ],\n",
            "        [ 0.12019391, -0.1302704 , -0.07092186, ...,  0.27907884,\n",
            "          0.15390116,  1.        ],\n",
            "        [ 0.05723717, -0.12839945, -0.07765271, ...,  0.3760536 ,\n",
            "          0.08959586,  1.        ],\n",
            "        ...,\n",
            "        [-0.2128933 ,  0.04011046,  0.1905818 , ...,  0.07679793,\n",
            "         -0.07670555,  1.        ],\n",
            "        [-0.26015922,  0.04834473,  0.19087018, ...,  0.06547613,\n",
            "         -0.08045114,  1.        ],\n",
            "        [-0.25357175,  0.01822538,  0.22883815, ...,  0.01210507,\n",
            "         -0.04766449,  1.        ]], dtype=float32)\n",
            " array([[-0.03236446, -0.12219382, -0.03092641, ...,  0.05571645,\n",
            "          0.20657617,  1.        ],\n",
            "        [ 0.13665263, -0.05756362, -0.0350645 , ...,  0.2658944 ,\n",
            "          0.14066723,  1.        ],\n",
            "        [ 0.1179251 , -0.02614623, -0.02307468, ...,  0.35858145,\n",
            "          0.0273482 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.14460213,  0.10664532,  0.24571252, ...,  0.09400675,\n",
            "         -0.00475643,  1.        ],\n",
            "        [-0.26232868,  0.09145541,  0.30932903, ...,  0.07444217,\n",
            "         -0.03482142,  1.        ],\n",
            "        [-0.30552152,  0.08507799,  0.28858387, ...,  0.03898925,\n",
            "         -0.01751306,  1.        ]], dtype=float32)\n",
            " array([[-0.01770027, -0.12748179, -0.03273603, ...,  0.05304772,\n",
            "          0.21712306,  1.        ],\n",
            "        [ 0.15582527, -0.03085431, -0.00945008, ...,  0.26535472,\n",
            "          0.1264248 ,  1.        ],\n",
            "        [ 0.15326071,  0.03739365,  0.01221053, ...,  0.34095287,\n",
            "         -0.01983763,  1.        ],\n",
            "        ...,\n",
            "        [-0.03458933,  0.13756752,  0.19403382, ...,  0.06455448,\n",
            "          0.01635252,  1.        ],\n",
            "        [-0.21649349,  0.1373541 ,  0.31421885, ...,  0.06909942,\n",
            "         -0.0111075 ,  1.        ],\n",
            "        [-0.26768413,  0.10622293,  0.29171696, ...,  0.07324444,\n",
            "          0.00907299,  1.        ]], dtype=float32)\n",
            " array([[-0.01370875, -0.12192954, -0.03364512, ...,  0.04889206,\n",
            "          0.21577331,  1.        ],\n",
            "        [ 0.1460636 , -0.03013031, -0.01407268, ...,  0.24731469,\n",
            "          0.12066004,  1.        ],\n",
            "        [ 0.1419367 ,  0.04439886,  0.0055397 , ...,  0.32002297,\n",
            "         -0.03181976,  1.        ],\n",
            "        ...,\n",
            "        [-0.02175164,  0.1426235 ,  0.18305549, ...,  0.05222317,\n",
            "          0.02534888,  1.        ],\n",
            "        [-0.2147738 ,  0.13919045,  0.32108474, ...,  0.06528853,\n",
            "         -0.00527688,  1.        ],\n",
            "        [-0.26378644,  0.10971331,  0.2938689 , ...,  0.07197709,\n",
            "          0.00805707,  1.        ]], dtype=float32)\n",
            " array([[-0.02282106, -0.12673539, -0.02595658, ...,  0.03980867,\n",
            "          0.20738333,  1.        ],\n",
            "        [ 0.12405933, -0.03346802,  0.00317804, ...,  0.23829278,\n",
            "          0.11848407,  1.        ],\n",
            "        [ 0.12129702,  0.02489953,  0.02446512, ...,  0.3152366 ,\n",
            "         -0.01554486,  1.        ],\n",
            "        ...,\n",
            "        [-0.07355876,  0.13283579,  0.2294856 , ...,  0.05731845,\n",
            "          0.00497226,  1.        ],\n",
            "        [-0.24587828,  0.12662503,  0.3548033 , ...,  0.05000265,\n",
            "         -0.02544097,  1.        ],\n",
            "        [-0.2975959 ,  0.09724771,  0.30939522, ...,  0.04254349,\n",
            "         -0.00829947,  1.        ]], dtype=float32)\n",
            " array([[-0.035275  , -0.1379718 , -0.03540283, ...,  0.050854  ,\n",
            "          0.21265317,  1.        ],\n",
            "        [ 0.13876995, -0.07340647, -0.04973961, ...,  0.26328057,\n",
            "          0.158806  ,  1.        ],\n",
            "        [ 0.09751339, -0.05949805, -0.04644564, ...,  0.35544884,\n",
            "          0.06018497,  1.        ],\n",
            "        ...,\n",
            "        [-0.1503469 ,  0.0607052 ,  0.23219891, ...,  0.09622222,\n",
            "          0.0242537 ,  1.        ],\n",
            "        [-0.26759213,  0.05659498,  0.28843802, ...,  0.07141783,\n",
            "         -0.03294798,  1.        ],\n",
            "        [-0.30804923,  0.05771742,  0.28369054, ...,  0.03085872,\n",
            "         -0.02139077,  1.        ]], dtype=float32)\n",
            " array([[-0.03574226, -0.13123575, -0.03253333, ...,  0.06157572,\n",
            "          0.21137416,  1.        ],\n",
            "        [ 0.14982127, -0.05629941, -0.03616502, ...,  0.26414132,\n",
            "          0.14463751,  1.        ],\n",
            "        [ 0.11917179, -0.0308212 , -0.01939768, ...,  0.354995  ,\n",
            "          0.03850562,  1.        ],\n",
            "        ...,\n",
            "        [-0.1629272 ,  0.10133585,  0.2585905 , ...,  0.08005543,\n",
            "         -0.01978228,  1.        ],\n",
            "        [-0.27212366,  0.0826789 ,  0.2997555 , ...,  0.07099776,\n",
            "         -0.04731137,  1.        ],\n",
            "        [-0.29565272,  0.0840311 ,  0.2810392 , ...,  0.04326354,\n",
            "         -0.01407775,  1.        ]], dtype=float32)\n",
            " array([[-0.0331554 , -0.14083083, -0.03834435, ...,  0.06303481,\n",
            "          0.21536614,  1.        ],\n",
            "        [ 0.1719152 , -0.06279514, -0.04241801, ...,  0.2851371 ,\n",
            "          0.15313518,  1.        ],\n",
            "        [ 0.13191886, -0.04507287, -0.03541976, ...,  0.3762362 ,\n",
            "          0.04768552,  1.        ],\n",
            "        ...,\n",
            "        [-0.13037908,  0.06095685,  0.21517071, ...,  0.09052511,\n",
            "          0.00106975,  1.        ],\n",
            "        [-0.24352665,  0.06109525,  0.2590143 , ...,  0.07685386,\n",
            "         -0.03850311,  1.        ],\n",
            "        [-0.28064036,  0.06544383,  0.26485246, ...,  0.04599423,\n",
            "         -0.01142908,  1.        ]], dtype=float32)\n",
            " array([[-0.00109148, -0.10924863, -0.04530831, ...,  0.042402  ,\n",
            "          0.20542696,  1.        ],\n",
            "        [ 0.17612067, -0.00565848, -0.03615543, ...,  0.25394398,\n",
            "          0.07120927,  1.        ],\n",
            "        [ 0.18697524,  0.0582815 , -0.03305858, ...,  0.31240276,\n",
            "         -0.06769708,  1.        ],\n",
            "        ...,\n",
            "        [ 0.08945104,  0.09012741,  0.05442204, ...,  0.05357203,\n",
            "          0.06592051,  1.        ],\n",
            "        [-0.1453478 ,  0.1244963 ,  0.30258206, ...,  0.11127009,\n",
            "          0.00163126,  1.        ],\n",
            "        [-0.24379602,  0.10661662,  0.29090348, ...,  0.06773752,\n",
            "          0.00888429,  1.        ]], dtype=float32)\n",
            " array([[-1.32616814e-02, -1.18153974e-01, -3.38514335e-02, ...,\n",
            "          4.48126793e-02,  2.08225965e-01,  1.00000000e+00],\n",
            "        [ 1.44245386e-01, -2.03875788e-02, -1.59726664e-02, ...,\n",
            "          2.56903172e-01,  1.00926176e-01,  1.00000000e+00],\n",
            "        [ 1.54383749e-01,  5.03118001e-02, -2.85359379e-03, ...,\n",
            "          3.26064557e-01, -4.41174582e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.42848117e-02,  1.18815832e-01,  1.42652631e-01, ...,\n",
            "          6.01354539e-02,  4.14428897e-02,  1.00000000e+00],\n",
            "        [-1.92898765e-01,  1.25550807e-01,  3.25224578e-01, ...,\n",
            "          8.66288915e-02,  7.07103231e-04,  1.00000000e+00],\n",
            "        [-2.59841383e-01,  1.09304510e-01,  2.94583529e-01, ...,\n",
            "          5.83743416e-02,  1.00196917e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.0224173 , -0.1318904 , -0.03004837, ...,  0.05190208,\n",
            "          0.21530253,  1.        ],\n",
            "        [ 0.14209704, -0.03980266, -0.00997689, ...,  0.25211552,\n",
            "          0.12907416,  1.        ],\n",
            "        [ 0.13794446,  0.02046023,  0.01160993, ...,  0.33288017,\n",
            "         -0.01565028,  1.        ],\n",
            "        ...,\n",
            "        [-0.08489337,  0.13885608,  0.22823022, ...,  0.06045651,\n",
            "         -0.00419193,  1.        ],\n",
            "        [-0.23961757,  0.13391002,  0.3316041 , ...,  0.06017998,\n",
            "         -0.0274884 ,  1.        ],\n",
            "        [-0.28140518,  0.10074469,  0.29761168, ...,  0.0654041 ,\n",
            "          0.00191413,  1.        ]], dtype=float32)\n",
            " array([[-0.02366355, -0.13216807, -0.02672127, ...,  0.04556489,\n",
            "          0.20886861,  1.        ],\n",
            "        [ 0.13333797, -0.04947613, -0.00994191, ...,  0.25772312,\n",
            "          0.13240115,  1.        ],\n",
            "        [ 0.11717682, -0.00832037,  0.00809623, ...,  0.34444502,\n",
            "          0.01102483,  1.        ],\n",
            "        ...,\n",
            "        [-0.11632805,  0.12788714,  0.24062133, ...,  0.08603922,\n",
            "         -0.00515226,  1.        ],\n",
            "        [-0.25389904,  0.11757035,  0.33179155, ...,  0.06739145,\n",
            "         -0.03616372,  1.        ],\n",
            "        [-0.30167586,  0.08854829,  0.29807973, ...,  0.04787791,\n",
            "         -0.01808902,  1.        ]], dtype=float32)\n",
            " array([[-0.00333244, -0.12105025, -0.04771851, ...,  0.05637505,\n",
            "          0.21519208,  1.        ],\n",
            "        [ 0.17691584, -0.01010354, -0.03543095, ...,  0.26321727,\n",
            "          0.1105582 ,  1.        ],\n",
            "        [ 0.17472422,  0.05062088, -0.02084493, ...,  0.34219876,\n",
            "         -0.04521212,  1.        ],\n",
            "        ...,\n",
            "        [ 0.07458708,  0.12573077,  0.09486032, ...,  0.04439074,\n",
            "          0.04135908,  1.        ],\n",
            "        [-0.14684889,  0.13903436,  0.27337646, ...,  0.07469717,\n",
            "         -0.0014567 ,  1.        ],\n",
            "        [-0.24363534,  0.10821497,  0.27008438, ...,  0.07650939,\n",
            "          0.00457307,  1.        ]], dtype=float32)\n",
            " array([[-0.03054285, -0.15443324, -0.06021101, ...,  0.0580647 ,\n",
            "          0.19292657,  1.        ],\n",
            "        [ 0.11549101, -0.12701768, -0.06748361, ...,  0.25797316,\n",
            "          0.15046225,  1.        ],\n",
            "        [ 0.049212  , -0.1227864 , -0.07704497, ...,  0.35766128,\n",
            "          0.08593395,  1.        ],\n",
            "        ...,\n",
            "        [-0.23157193,  0.04932523,  0.19831753, ...,  0.03738715,\n",
            "         -0.08040414,  1.        ],\n",
            "        [-0.27252495,  0.06716032,  0.2104562 , ...,  0.03822418,\n",
            "         -0.07867909,  1.        ],\n",
            "        [-0.24636945,  0.02822414,  0.2371208 , ..., -0.0014689 ,\n",
            "         -0.04958471,  1.        ]], dtype=float32)\n",
            " array([[-0.02174572, -0.13104524, -0.02787025, ...,  0.04376018,\n",
            "          0.20950074,  1.        ],\n",
            "        [ 0.13800374, -0.03962254, -0.00330898, ...,  0.25553432,\n",
            "          0.12766446,  1.        ],\n",
            "        [ 0.13145235,  0.0104357 ,  0.01909938, ...,  0.33646104,\n",
            "         -0.00180807,  1.        ],\n",
            "        ...,\n",
            "        [-0.08280612,  0.13015264,  0.22534221, ...,  0.07670389,\n",
            "          0.00230004,  1.        ],\n",
            "        [-0.2397473 ,  0.12421504,  0.33261272, ...,  0.0627922 ,\n",
            "         -0.0267709 ,  1.        ],\n",
            "        [-0.29308957,  0.09444033,  0.29701045, ...,  0.04964802,\n",
            "         -0.01041957,  1.        ]], dtype=float32)\n",
            " array([[ 0.01219954, -0.10603727, -0.06992296, ...,  0.03920858,\n",
            "          0.20699082,  1.        ],\n",
            "        [ 0.1632791 , -0.00813134, -0.05242465, ...,  0.20228979,\n",
            "          0.0946877 ,  1.        ],\n",
            "        [ 0.1564506 ,  0.03924131, -0.04299161, ...,  0.2897468 ,\n",
            "         -0.06807008,  1.        ],\n",
            "        ...,\n",
            "        [ 0.07840449,  0.09197326,  0.0506904 , ...,  0.02719782,\n",
            "          0.06043504,  1.        ],\n",
            "        [-0.14635469,  0.1350927 ,  0.26996922, ...,  0.08251295,\n",
            "         -0.00404423,  1.        ],\n",
            "        [-0.2538219 ,  0.08646705,  0.2818717 , ...,  0.06927587,\n",
            "         -0.00407785,  1.        ]], dtype=float32)\n",
            " array([[-2.2087580e-02, -1.3960610e-01, -2.9675173e-02, ...,\n",
            "          5.2897844e-02,  2.1754767e-01,  1.0000000e+00],\n",
            "        [ 1.4420655e-01, -4.5334451e-02, -1.3990562e-02, ...,\n",
            "          2.4915190e-01,  1.3810712e-01,  1.0000000e+00],\n",
            "        [ 1.3869715e-01,  2.8500990e-03,  1.0093464e-02, ...,\n",
            "          3.2876763e-01, -3.6414363e-04,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0914441e-01,  1.5644117e-01,  2.3228431e-01, ...,\n",
            "          5.3607877e-02,  5.5485964e-04,  1.0000000e+00],\n",
            "        [-2.4651736e-01,  1.3035631e-01,  3.2303822e-01, ...,\n",
            "          5.5969097e-02, -3.0123591e-02,  1.0000000e+00],\n",
            "        [-2.7764836e-01,  9.5360965e-02,  2.8860053e-01, ...,\n",
            "          6.7538448e-02, -1.3504790e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-8.4661003e-03, -1.2919293e-01, -3.9027054e-02, ...,\n",
            "          5.8416937e-02,  2.2067195e-01,  1.0000000e+00],\n",
            "        [ 1.7879725e-01, -1.8391808e-02, -2.3510477e-02, ...,\n",
            "          2.7242476e-01,  1.3005345e-01,  1.0000000e+00],\n",
            "        [ 1.7471427e-01,  4.3337140e-02, -2.9711437e-04, ...,\n",
            "          3.5223135e-01, -1.5200656e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [ 2.4183437e-02,  1.3208733e-01,  1.4221331e-01, ...,\n",
            "          4.9197480e-02,  1.8376151e-02,  1.0000000e+00],\n",
            "        [-1.6783790e-01,  1.3414928e-01,  2.7451944e-01, ...,\n",
            "          6.2236544e-02, -8.1488248e-03,  1.0000000e+00],\n",
            "        [-2.4097465e-01,  1.0653738e-01,  2.7320719e-01, ...,\n",
            "          8.1629820e-02,  1.0256815e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[ 4.30854931e-02, -1.39285862e-01, -6.99747652e-02, ...,\n",
            "          1.53903784e-02,  1.68772057e-01,  1.00000000e+00],\n",
            "        [ 2.52713978e-01, -2.78254747e-02, -6.32065311e-02, ...,\n",
            "          1.90229729e-01,  9.17415455e-05,  1.00000000e+00],\n",
            "        [ 2.58350492e-01,  4.16915305e-03, -5.71621992e-02, ...,\n",
            "          2.37708852e-01, -1.18115537e-01,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.44198477e-01, -1.14997942e-03, -4.66095582e-02, ...,\n",
            "          5.57937846e-02,  5.42583279e-02,  1.00000000e+00],\n",
            "        [-7.25303218e-02,  8.00884292e-02,  2.55938411e-01, ...,\n",
            "          1.18248545e-01, -4.31812406e-02,  1.00000000e+00],\n",
            "        [-2.43581116e-01,  5.41764200e-02,  3.03849638e-01, ...,\n",
            "          7.59140998e-02, -2.70987786e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.01729516, -0.12047933, -0.03267742, ...,  0.0367816 ,\n",
            "          0.206478  ,  1.        ],\n",
            "        [ 0.12845252, -0.01845613, -0.00481399, ...,  0.23752125,\n",
            "          0.1041547 ,  1.        ],\n",
            "        [ 0.13251896,  0.04934881,  0.01473251, ...,  0.31075746,\n",
            "         -0.04141886,  1.        ],\n",
            "        ...,\n",
            "        [-0.00584199,  0.12815677,  0.16274002, ...,  0.04468771,\n",
            "          0.03199115,  1.        ],\n",
            "        [-0.21239628,  0.12860303,  0.33349144, ...,  0.05812951,\n",
            "         -0.00920152,  1.        ],\n",
            "        [-0.27966052,  0.09655063,  0.3025141 , ...,  0.0477794 ,\n",
            "         -0.00356048,  1.        ]], dtype=float32)\n",
            " array([[-0.01805556, -0.13180317, -0.02767235, ...,  0.04662737,\n",
            "          0.21098614,  0.        ],\n",
            "        [ 0.14849284, -0.04492218, -0.00431378, ...,  0.2636215 ,\n",
            "          0.12811968,  0.        ],\n",
            "        [ 0.14371268,  0.00517778,  0.00830098, ...,  0.34479228,\n",
            "          0.00280453,  0.        ],\n",
            "        ...,\n",
            "        [-0.07616472,  0.12568815,  0.22658919, ...,  0.08662517,\n",
            "          0.00693537,  0.        ],\n",
            "        [-0.23511018,  0.12539564,  0.32912344, ...,  0.07706248,\n",
            "         -0.02347055,  0.        ],\n",
            "        [-0.28135496,  0.10286187,  0.29403374, ...,  0.05627281,\n",
            "         -0.00062166,  0.        ]], dtype=float32)\n",
            " array([[-2.50864010e-02, -1.34490550e-01, -3.02595049e-02, ...,\n",
            "          5.36964759e-02,  2.15073124e-01,  2.00000000e+00],\n",
            "        [ 1.52894735e-01, -4.26782668e-02, -1.22344196e-02, ...,\n",
            "          2.72626013e-01,  1.35314554e-01,  2.00000000e+00],\n",
            "        [ 1.40372559e-01,  1.71836908e-03,  1.07444394e-02, ...,\n",
            "          3.57202947e-01,  6.93452917e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.22400858e-01,  1.30455643e-01,  2.46471539e-01, ...,\n",
            "          7.65014887e-02, -1.79604646e-02,  2.00000000e+00],\n",
            "        [-2.45506510e-01,  1.20283715e-01,  3.15221339e-01, ...,\n",
            "          6.96687400e-02, -3.86336260e-02,  2.00000000e+00],\n",
            "        [-2.89738089e-01,  9.33017209e-02,  2.93834388e-01, ...,\n",
            "          5.98864183e-02, -8.83322954e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.5635142e-02, -1.3162953e-01, -2.3490729e-02, ...,\n",
            "          4.3844935e-02,  2.0826945e-01,  2.0000000e+00],\n",
            "        [ 1.3165966e-01, -4.6822943e-02, -1.6898044e-03, ...,\n",
            "          2.4101956e-01,  1.3344932e-01,  2.0000000e+00],\n",
            "        [ 1.1691132e-01, -1.6295427e-03,  2.2123661e-02, ...,\n",
            "          3.2463104e-01,  8.7878155e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1909135e-01,  1.3493340e-01,  2.5349087e-01, ...,\n",
            "          6.4304255e-02,  1.1643018e-03,  2.0000000e+00],\n",
            "        [-2.5897941e-01,  1.2533781e-01,  3.4155196e-01, ...,\n",
            "          5.5189595e-02, -3.1562634e-02,  2.0000000e+00],\n",
            "        [-3.0504683e-01,  9.3072385e-02,  3.0301306e-01, ...,\n",
            "          4.3979786e-02, -1.3878147e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02086981, -0.12280907, -0.02687786, ...,  0.03693625,\n",
            "          0.20655414,  2.        ],\n",
            "        [ 0.12580493, -0.02453395,  0.00527673, ...,  0.23096825,\n",
            "          0.11038472,  2.        ],\n",
            "        [ 0.12466186,  0.03859653,  0.0244095 , ...,  0.3051074 ,\n",
            "         -0.02840097,  2.        ],\n",
            "        ...,\n",
            "        [-0.04615949,  0.1364701 ,  0.2057706 , ...,  0.04453343,\n",
            "          0.01511209,  2.        ],\n",
            "        [-0.23603866,  0.13003397,  0.34751773, ...,  0.04474196,\n",
            "         -0.01895364,  2.        ],\n",
            "        [-0.29245317,  0.1008094 ,  0.30895823, ...,  0.04099694,\n",
            "         -0.00408008,  2.        ]], dtype=float32)\n",
            " array([[-0.02468475, -0.13115384, -0.02996864, ...,  0.05092499,\n",
            "          0.21630093,  2.        ],\n",
            "        [ 0.13919991, -0.04251653, -0.00602561, ...,  0.23812099,\n",
            "          0.13446908,  2.        ],\n",
            "        [ 0.1279412 ,  0.01476029,  0.01525749, ...,  0.3139736 ,\n",
            "         -0.00952514,  2.        ],\n",
            "        ...,\n",
            "        [-0.06719918,  0.16163442,  0.20744783, ...,  0.03979082,\n",
            "          0.01437937,  2.        ],\n",
            "        [-0.24087983,  0.14592662,  0.31934744, ...,  0.04822349,\n",
            "         -0.01742687,  2.        ],\n",
            "        [-0.27949527,  0.10793316,  0.2907317 , ...,  0.0633151 ,\n",
            "          0.00238078,  2.        ]], dtype=float32)\n",
            " array([[-0.02046243, -0.12449647, -0.02906084, ...,  0.04651995,\n",
            "          0.21406344,  2.        ],\n",
            "        [ 0.1501483 , -0.02653096, -0.00322749, ...,  0.25469598,\n",
            "          0.12148345,  2.        ],\n",
            "        [ 0.14810379,  0.03671091,  0.02063923, ...,  0.3267985 ,\n",
            "         -0.02149163,  2.        ],\n",
            "        ...,\n",
            "        [-0.03687198,  0.1382799 ,  0.19674854, ...,  0.05220207,\n",
            "          0.01275885,  2.        ],\n",
            "        [-0.22200245,  0.1440537 ,  0.32250032, ...,  0.05454477,\n",
            "         -0.01996895,  2.        ],\n",
            "        [-0.27630898,  0.10581391,  0.29814157, ...,  0.05902356,\n",
            "          0.0022763 ,  2.        ]], dtype=float32)\n",
            " array([[-1.37971705e-02, -1.20156288e-01, -3.54160517e-02, ...,\n",
            "          4.82626446e-02,  2.13107169e-01,  2.00000000e+00],\n",
            "        [ 1.58676401e-01, -1.69154406e-02, -1.50690423e-02, ...,\n",
            "          2.60667980e-01,  1.14728123e-01,  2.00000000e+00],\n",
            "        [ 1.62558898e-01,  5.09799272e-02,  7.57797807e-03, ...,\n",
            "          3.31146449e-01, -3.66201028e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 6.09534036e-04,  1.30945921e-01,  1.62277058e-01, ...,\n",
            "          5.99837378e-02,  2.55806204e-02,  2.00000000e+00],\n",
            "        [-2.02638835e-01,  1.39789730e-01,  3.12963396e-01, ...,\n",
            "          7.03806132e-02, -9.03363712e-03,  2.00000000e+00],\n",
            "        [-2.62864411e-01,  1.08437739e-01,  2.92446107e-01, ...,\n",
            "          6.84446245e-02,  7.99853634e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-7.9734558e-03, -1.1284901e-01, -4.4578090e-02, ...,\n",
            "          4.2524081e-02,  2.1324708e-01,  2.0000000e+00],\n",
            "        [ 1.4161509e-01, -1.9694855e-02, -2.1904245e-02, ...,\n",
            "          2.1681407e-01,  1.1503702e-01,  2.0000000e+00],\n",
            "        [ 1.3836928e-01,  4.0215183e-02, -6.2585478e-03, ...,\n",
            "          2.8974828e-01, -4.4445664e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.4958998e-02,  1.3839643e-01,  1.3266411e-01, ...,\n",
            "          2.0344654e-02,  4.3888845e-02,  2.0000000e+00],\n",
            "        [-1.9478239e-01,  1.4935242e-01,  3.1308183e-01, ...,\n",
            "          5.5811513e-02,  4.4131242e-03,  2.0000000e+00],\n",
            "        [-2.6968914e-01,  1.0017134e-01,  2.9794759e-01, ...,\n",
            "          6.3833602e-02, -3.6354782e-04,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01665699, -0.11992195, -0.03359434, ...,  0.05052188,\n",
            "          0.21526395,  2.        ],\n",
            "        [ 0.14333464, -0.026392  , -0.00961243, ...,  0.23983629,\n",
            "          0.11964289,  2.        ],\n",
            "        [ 0.14244546,  0.04027577,  0.00677012, ...,  0.3093094 ,\n",
            "         -0.03139746,  2.        ],\n",
            "        ...,\n",
            "        [-0.01282837,  0.14676856,  0.17553098, ...,  0.04621662,\n",
            "          0.02450425,  2.        ],\n",
            "        [-0.21975982,  0.14794268,  0.3214675 , ...,  0.06215248,\n",
            "         -0.00900002,  2.        ],\n",
            "        [-0.2720755 ,  0.11362316,  0.2988915 , ...,  0.06789498,\n",
            "          0.0091171 ,  2.        ]], dtype=float32)\n",
            " array([[-0.01693177, -0.12298851, -0.03264012, ...,  0.03776136,\n",
            "          0.20647584,  2.        ],\n",
            "        [ 0.13295913, -0.01765162, -0.00639265, ...,  0.23821014,\n",
            "          0.10209513,  2.        ],\n",
            "        [ 0.1347587 ,  0.04664403,  0.01029339, ...,  0.31426382,\n",
            "         -0.03922923,  2.        ],\n",
            "        ...,\n",
            "        [-0.01144176,  0.12706776,  0.16730855, ...,  0.04712791,\n",
            "          0.02646602,  2.        ],\n",
            "        [-0.2152699 ,  0.12142418,  0.33415818, ...,  0.05836013,\n",
            "         -0.01059105,  2.        ],\n",
            "        [-0.27691814,  0.09654248,  0.30012065, ...,  0.04753436,\n",
            "         -0.00429729,  2.        ]], dtype=float32)\n",
            " array([[-2.0930087e-02, -1.2843703e-01, -2.9157585e-02, ...,\n",
            "          4.8413888e-02,  2.1772239e-01,  2.0000000e+00],\n",
            "        [ 1.3872221e-01, -3.9546657e-02, -1.3349822e-03, ...,\n",
            "          2.2751375e-01,  1.3535909e-01,  2.0000000e+00],\n",
            "        [ 1.3082895e-01,  1.9625127e-02,  2.4294993e-02, ...,\n",
            "          3.0812326e-01, -1.1760524e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-8.1378996e-02,  1.5531430e-01,  2.3377210e-01, ...,\n",
            "          3.6298618e-02,  1.1028898e-02,  2.0000000e+00],\n",
            "        [-2.4063453e-01,  1.3734835e-01,  3.3701974e-01, ...,\n",
            "          4.5994382e-02, -1.7061725e-02,  2.0000000e+00],\n",
            "        [-2.8299385e-01,  1.0348574e-01,  2.9872778e-01, ...,\n",
            "          6.1494090e-02,  2.3444588e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.42230725e-02, -1.31158054e-01, -2.45580859e-02, ...,\n",
            "          4.35336195e-02,  2.08572567e-01,  2.00000000e+00],\n",
            "        [ 1.29406035e-01, -4.33485955e-02, -1.27622695e-03, ...,\n",
            "          2.48368904e-01,  1.29520386e-01,  2.00000000e+00],\n",
            "        [ 1.18618622e-01,  5.22542745e-03,  2.16852836e-02, ...,\n",
            "          3.30137551e-01,  5.70440153e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.15473144e-01,  1.34050071e-01,  2.53471285e-01, ...,\n",
            "          7.16527253e-02, -5.76462084e-03,  2.00000000e+00],\n",
            "        [-2.56663859e-01,  1.21043332e-01,  3.44930083e-01, ...,\n",
            "          6.07462041e-02, -3.23588178e-02,  2.00000000e+00],\n",
            "        [-3.01587731e-01,  9.34205428e-02,  3.05216223e-01, ...,\n",
            "          4.71445769e-02, -1.23515725e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-1.9652234e-02, -1.2333426e-01, -3.0580688e-02, ...,\n",
            "          3.8116828e-02,  2.0610482e-01,  2.0000000e+00],\n",
            "        [ 1.2735710e-01, -2.1686142e-02, -1.0797760e-03, ...,\n",
            "          2.3913208e-01,  1.0617135e-01,  2.0000000e+00],\n",
            "        [ 1.2626356e-01,  4.2886142e-02,  1.6069544e-02, ...,\n",
            "          3.1456286e-01, -3.4864098e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-2.4095327e-02,  1.3235490e-01,  1.8087599e-01, ...,\n",
            "          5.1248476e-02,  1.9495418e-02,  2.0000000e+00],\n",
            "        [-2.2351287e-01,  1.2639754e-01,  3.3717272e-01, ...,\n",
            "          5.2280877e-02, -1.5423256e-02,  2.0000000e+00],\n",
            "        [-2.8423861e-01,  9.7859085e-02,  3.0398709e-01, ...,\n",
            "          4.1581359e-02, -4.8548430e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02763581, -0.15398824, -0.0451188 , ...,  0.05764119,\n",
            "          0.20990318,  2.        ],\n",
            "        [ 0.15088442, -0.09097124, -0.06790076, ...,  0.28515697,\n",
            "          0.14117745,  2.        ],\n",
            "        [ 0.11511979, -0.0803418 , -0.07807099, ...,  0.37182647,\n",
            "          0.04613618,  2.        ],\n",
            "        ...,\n",
            "        [-0.1129981 ,  0.01570019,  0.17728136, ...,  0.09585126,\n",
            "          0.02558456,  2.        ],\n",
            "        [-0.21273832,  0.0161102 ,  0.23156938, ...,  0.07264727,\n",
            "         -0.01623908,  2.        ],\n",
            "        [-0.2676216 ,  0.02649579,  0.24627675, ...,  0.04162537,\n",
            "         -0.01894404,  2.        ]], dtype=float32)\n",
            " array([[-9.42623243e-03, -1.15128055e-01, -3.61380056e-02, ...,\n",
            "          4.20458876e-02,  2.06711099e-01,  2.00000000e+00],\n",
            "        [ 1.55675590e-01, -8.01625941e-03, -1.84418876e-02, ...,\n",
            "          2.49682307e-01,  8.69377404e-02,  2.00000000e+00],\n",
            "        [ 1.70829073e-01,  6.09938428e-02, -1.14551429e-02, ...,\n",
            "          3.11261356e-01, -6.08130805e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 4.84836921e-02,  1.14774957e-01,  1.08833306e-01, ...,\n",
            "          4.59053554e-02,  5.14277332e-02,  2.00000000e+00],\n",
            "        [-1.74599513e-01,  1.29050538e-01,  3.19879472e-01, ...,\n",
            "          8.82911608e-02, -9.32994240e-04,  2.00000000e+00],\n",
            "        [-2.53727466e-01,  1.08628258e-01,  2.94986337e-01, ...,\n",
            "          5.62504455e-02,  6.40603295e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-1.61941871e-02, -1.17012888e-01, -3.30289602e-02, ...,\n",
            "          4.27233391e-02,  2.09487945e-01,  2.00000000e+00],\n",
            "        [ 1.36760011e-01, -1.87996943e-02, -1.29423840e-02, ...,\n",
            "          2.52434790e-01,  1.01767555e-01,  2.00000000e+00],\n",
            "        [ 1.48547083e-01,  5.19850031e-02, -1.61121774e-04, ...,\n",
            "          3.21492732e-01, -4.46910709e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 3.91989388e-03,  1.20740667e-01,  1.59525111e-01, ...,\n",
            "          5.75873926e-02,  3.41088809e-02,  2.00000000e+00],\n",
            "        [-2.04379797e-01,  1.25258222e-01,  3.34379971e-01, ...,\n",
            "          7.82368034e-02, -7.87740108e-04,  2.00000000e+00],\n",
            "        [-2.66284972e-01,  1.06358021e-01,  2.97267616e-01, ...,\n",
            "          5.63602559e-02,  1.09415073e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.53083240e-02, -1.29753679e-01, -2.30115093e-02, ...,\n",
            "          4.20795716e-02,  2.07779929e-01,  2.00000000e+00],\n",
            "        [ 1.25907391e-01, -4.53990549e-02,  2.62056617e-03, ...,\n",
            "          2.40239203e-01,  1.27534524e-01,  2.00000000e+00],\n",
            "        [ 1.16560452e-01,  5.55304624e-03,  2.46354174e-02, ...,\n",
            "          3.21551770e-01, -4.00711811e-04,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.03451416e-01,  1.35992095e-01,  2.51560688e-01, ...,\n",
            "          6.50692508e-02,  5.88775554e-04,  2.00000000e+00],\n",
            "        [-2.55636692e-01,  1.27471983e-01,  3.54119211e-01, ...,\n",
            "          5.59246056e-02, -2.64029186e-02,  2.00000000e+00],\n",
            "        [-3.03588480e-01,  9.82060358e-02,  3.08305532e-01, ...,\n",
            "          4.36040424e-02, -9.31193400e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02131033, -0.12406615, -0.03295069, ...,  0.0446629 ,\n",
            "          0.21479304,  2.        ],\n",
            "        [ 0.13059443, -0.03488443, -0.01166665, ...,  0.22922175,\n",
            "          0.12454776,  2.        ],\n",
            "        [ 0.12980789,  0.02889035,  0.00894474, ...,  0.30599982,\n",
            "         -0.03125336,  2.        ],\n",
            "        ...,\n",
            "        [-0.04045993,  0.14589581,  0.19290972, ...,  0.03512472,\n",
            "          0.01877798,  2.        ],\n",
            "        [-0.23130439,  0.14536838,  0.32980883, ...,  0.04827288,\n",
            "         -0.01222753,  2.        ],\n",
            "        [-0.2839001 ,  0.10830455,  0.30038732, ...,  0.05819999,\n",
            "          0.00366432,  2.        ]], dtype=float32)\n",
            " array([[-2.4271313e-02, -1.3403510e-01, -3.0652337e-02, ...,\n",
            "          5.5746272e-02,  2.1674697e-01,  2.0000000e+00],\n",
            "        [ 1.5485431e-01, -3.7665363e-02, -1.1798745e-02, ...,\n",
            "          2.6708078e-01,  1.3584089e-01,  2.0000000e+00],\n",
            "        [ 1.4794986e-01,  1.6902443e-02,  1.1779260e-02, ...,\n",
            "          3.5179842e-01, -1.1204479e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-7.7883206e-02,  1.3645807e-01,  2.2014776e-01, ...,\n",
            "          6.6412225e-02,  3.9791237e-03,  2.0000000e+00],\n",
            "        [-2.3109302e-01,  1.2978294e-01,  3.1051776e-01, ...,\n",
            "          6.8364486e-02, -2.4345074e-02,  2.0000000e+00],\n",
            "        [-2.7796218e-01,  9.7976558e-02,  2.8787762e-01, ...,\n",
            "          6.8831652e-02,  3.2927974e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02512041, -0.13351387, -0.02615994, ...,  0.04783177,\n",
            "          0.20951653,  2.        ],\n",
            "        [ 0.13731539, -0.04614734, -0.0128152 , ...,  0.26271752,\n",
            "          0.1344693 ,  2.        ],\n",
            "        [ 0.12169291, -0.00606884,  0.0053694 , ...,  0.34839475,\n",
            "          0.01491237,  2.        ],\n",
            "        ...,\n",
            "        [-0.12933049,  0.12439492,  0.24676783, ...,  0.08303677,\n",
            "         -0.00729987,  2.        ],\n",
            "        [-0.25525856,  0.10873847,  0.32472032, ...,  0.06790123,\n",
            "         -0.03483557,  2.        ],\n",
            "        [-0.30217507,  0.08816396,  0.29828736, ...,  0.05081998,\n",
            "         -0.0150269 ,  2.        ]], dtype=float32)\n",
            " array([[ 1.04372762e-03, -1.12547383e-01, -5.12751378e-02, ...,\n",
            "          4.95891385e-02,  2.14868471e-01,  2.00000000e+00],\n",
            "        [ 1.69748902e-01,  4.81536612e-03, -3.61608900e-02, ...,\n",
            "          2.44628102e-01,  1.09654255e-01,  2.00000000e+00],\n",
            "        [ 1.74295112e-01,  6.45870343e-02, -1.55306244e-02, ...,\n",
            "          3.24716508e-01, -4.88598682e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 8.71881545e-02,  1.14550866e-01,  7.83571824e-02, ...,\n",
            "          4.11484689e-02,  5.22697829e-02,  2.00000000e+00],\n",
            "        [-1.34124145e-01,  1.42463773e-01,  2.72425205e-01, ...,\n",
            "          7.10542575e-02,  9.91474371e-05,  2.00000000e+00],\n",
            "        [-2.36060202e-01,  1.10119663e-01,  2.75174201e-01, ...,\n",
            "          7.38117024e-02,  4.38408367e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.03669862, -0.15852164, -0.058846  , ...,  0.06162629,\n",
            "          0.20680659,  2.        ],\n",
            "        [ 0.1312291 , -0.12515533, -0.07678162, ...,  0.29770318,\n",
            "          0.15316664,  2.        ],\n",
            "        [ 0.07199196, -0.12304239, -0.08352604, ...,  0.3940562 ,\n",
            "          0.08153979,  2.        ],\n",
            "        ...,\n",
            "        [-0.18317159,  0.01786101,  0.19014853, ...,  0.10348181,\n",
            "         -0.0443863 ,  2.        ],\n",
            "        [-0.23873025,  0.03438309,  0.19204307, ...,  0.08925876,\n",
            "         -0.06951445,  2.        ],\n",
            "        [-0.2626666 ,  0.00431823,  0.2283926 , ...,  0.02948718,\n",
            "         -0.03806711,  2.        ]], dtype=float32)\n",
            " array([[-0.02260692, -0.12720795, -0.02647803, ...,  0.04412415,\n",
            "          0.21207511,  2.        ],\n",
            "        [ 0.12804738, -0.03307533,  0.00494758, ...,  0.23051837,\n",
            "          0.1219826 ,  2.        ],\n",
            "        [ 0.12927808,  0.02078667,  0.03111829, ...,  0.30155972,\n",
            "         -0.01700123,  2.        ],\n",
            "        ...,\n",
            "        [-0.06170247,  0.1437489 ,  0.22482319, ...,  0.03785556,\n",
            "          0.00719871,  2.        ],\n",
            "        [-0.23947856,  0.14048782,  0.35158285, ...,  0.04213904,\n",
            "         -0.02207141,  2.        ],\n",
            "        [-0.2927518 ,  0.1034609 ,  0.30875963, ...,  0.04498076,\n",
            "         -0.00312805,  2.        ]], dtype=float32)\n",
            " array([[ 0.02338808, -0.10524032, -0.08079462, ...,  0.03928481,\n",
            "          0.20425937,  2.        ],\n",
            "        [ 0.17017317, -0.01840903, -0.06566247, ...,  0.2050972 ,\n",
            "          0.0915125 ,  2.        ],\n",
            "        [ 0.16038924,  0.0336015 , -0.05438394, ...,  0.2927948 ,\n",
            "         -0.07500141,  2.        ],\n",
            "        ...,\n",
            "        [ 0.09100785,  0.09107246,  0.04316654, ...,  0.03934649,\n",
            "          0.07048123,  2.        ],\n",
            "        [-0.1313572 ,  0.13543306,  0.25369057, ...,  0.09604625,\n",
            "         -0.00447163,  2.        ],\n",
            "        [-0.24219453,  0.07521635,  0.27897683, ...,  0.08043882,\n",
            "         -0.00608707,  2.        ]], dtype=float32)\n",
            " array([[-0.0152119 , -0.11893003, -0.0375594 , ...,  0.03679402,\n",
            "          0.20173202,  2.        ],\n",
            "        [ 0.1374733 , -0.01068984, -0.0149699 , ...,  0.23853044,\n",
            "          0.08518166,  2.        ],\n",
            "        [ 0.13905926,  0.05362006, -0.00242417, ...,  0.31175423,\n",
            "         -0.05592344,  2.        ],\n",
            "        ...,\n",
            "        [ 0.0127448 ,  0.12795027,  0.13946977, ...,  0.03827258,\n",
            "          0.02582478,  2.        ],\n",
            "        [-0.20310599,  0.12141425,  0.32638252, ...,  0.06044389,\n",
            "         -0.01587839,  2.        ],\n",
            "        [-0.2706014 ,  0.09208967,  0.2989186 , ...,  0.04698558,\n",
            "         -0.0078114 ,  2.        ]], dtype=float32)\n",
            " array([[ 0.00702813, -0.10856512, -0.06486207, ...,  0.02162768,\n",
            "          0.19582273,  2.        ],\n",
            "        [ 0.17165232, -0.00755903, -0.04188068, ...,  0.2159736 ,\n",
            "          0.04094072,  2.        ],\n",
            "        [ 0.17483114,  0.04516235, -0.04143349, ...,  0.28061107,\n",
            "         -0.09989839,  2.        ],\n",
            "        ...,\n",
            "        [ 0.07428564,  0.0568922 ,  0.03370536, ...,  0.0190456 ,\n",
            "          0.07723999,  2.        ],\n",
            "        [-0.14045383,  0.11948565,  0.30783576, ...,  0.07114816,\n",
            "         -0.00745088,  2.        ],\n",
            "        [-0.26316887,  0.08470055,  0.29787266, ...,  0.05876254,\n",
            "         -0.00799214,  2.        ]], dtype=float32)\n",
            " array([[-0.02422165, -0.13328017, -0.02577398, ...,  0.04600368,\n",
            "          0.21143998,  2.        ],\n",
            "        [ 0.13703065, -0.04564312, -0.00927179, ...,  0.25598794,\n",
            "          0.13554086,  2.        ],\n",
            "        [ 0.12105448, -0.0026872 ,  0.01173084, ...,  0.33987287,\n",
            "          0.0156267 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.11013504,  0.12786727,  0.2356542 , ...,  0.06956733,\n",
            "          0.00307905,  2.        ],\n",
            "        [-0.25061855,  0.11463943,  0.32398078, ...,  0.05879617,\n",
            "         -0.02722378,  2.        ],\n",
            "        [-0.30019638,  0.08841022,  0.2953595 , ...,  0.04956393,\n",
            "         -0.01333781,  2.        ]], dtype=float32)\n",
            " array([[-0.01709444, -0.12273375, -0.03693597, ...,  0.04977351,\n",
            "          0.21478276,  2.        ],\n",
            "        [ 0.14484724, -0.02509551, -0.01438776, ...,  0.23513296,\n",
            "          0.12476983,  2.        ],\n",
            "        [ 0.1351293 ,  0.03381056,  0.00788582, ...,  0.31121832,\n",
            "         -0.0243702 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.00396502,  0.14448938,  0.15841147, ...,  0.03598492,\n",
            "          0.03568929,  2.        ],\n",
            "        [-0.20374571,  0.1438931 ,  0.312422  , ...,  0.05827576,\n",
            "         -0.00258008,  2.        ],\n",
            "        [-0.26284054,  0.1109863 ,  0.28707924, ...,  0.06653699,\n",
            "          0.00564763,  2.        ]], dtype=float32)\n",
            " array([[-0.01905987, -0.1322606 , -0.03169744, ...,  0.04443121,\n",
            "          0.20998108,  2.        ],\n",
            "        [ 0.14651914, -0.03180103, -0.0097834 , ...,  0.26388523,\n",
            "          0.12365079,  2.        ],\n",
            "        [ 0.1435397 ,  0.0217723 ,  0.01012547, ...,  0.34423026,\n",
            "         -0.01018186,  2.        ],\n",
            "        ...,\n",
            "        [-0.04772997,  0.12646335,  0.19077477, ...,  0.08290893,\n",
            "          0.01633483,  2.        ],\n",
            "        [-0.22193299,  0.11895523,  0.31594557, ...,  0.07169359,\n",
            "         -0.01859859,  2.        ],\n",
            "        [-0.27984676,  0.09211747,  0.2893298 , ...,  0.05711078,\n",
            "         -0.009237  ,  2.        ]], dtype=float32)\n",
            " array([[-0.03003889, -0.1562291 , -0.047996  , ...,  0.05551167,\n",
            "          0.21281686,  2.        ],\n",
            "        [ 0.14820088, -0.0973398 , -0.07481848, ...,  0.28588676,\n",
            "          0.15255453,  2.        ],\n",
            "        [ 0.10608859, -0.09116563, -0.08268693, ...,  0.37950835,\n",
            "          0.05708081,  2.        ],\n",
            "        ...,\n",
            "        [-0.12363902,  0.00952206,  0.18472067, ...,  0.10679843,\n",
            "          0.0234344 ,  2.        ],\n",
            "        [-0.22369619,  0.01233073,  0.23461904, ...,  0.07894748,\n",
            "         -0.02235563,  2.        ],\n",
            "        [-0.27581233,  0.02134772,  0.24989647, ...,  0.0368858 ,\n",
            "         -0.01852244,  2.        ]], dtype=float32)\n",
            " array([[-0.00224074, -0.12332524, -0.04982079, ...,  0.05579647,\n",
            "          0.21532133,  2.        ],\n",
            "        [ 0.1601976 , -0.02529858, -0.03469783, ...,  0.23269132,\n",
            "          0.12121435,  2.        ],\n",
            "        [ 0.1521907 ,  0.03135341, -0.01324716, ...,  0.31935555,\n",
            "         -0.03624523,  2.        ],\n",
            "        ...,\n",
            "        [ 0.04832794,  0.11095212,  0.08897997, ...,  0.04306475,\n",
            "          0.06473542,  2.        ],\n",
            "        [-0.15757765,  0.12779838,  0.2667733 , ...,  0.07006112,\n",
            "          0.01068022,  2.        ],\n",
            "        [-0.24804555,  0.10051101,  0.26616785, ...,  0.07384451,\n",
            "          0.00627365,  2.        ]], dtype=float32)\n",
            " array([[ 0.04142078, -0.15193965, -0.08751757, ...,  0.02746982,\n",
            "          0.19781461,  2.        ],\n",
            "        [ 0.25372627, -0.05203114, -0.0896331 , ...,  0.19343358,\n",
            "          0.03159722,  2.        ],\n",
            "        [ 0.24162772, -0.01052091, -0.08179509, ...,  0.25347835,\n",
            "         -0.10262647,  2.        ],\n",
            "        ...,\n",
            "        [ 0.19536394, -0.02075027, -0.03936331, ...,  0.04999527,\n",
            "          0.03277873,  2.        ],\n",
            "        [-0.02987688,  0.0462041 ,  0.20901152, ...,  0.10331404,\n",
            "         -0.04308047,  2.        ],\n",
            "        [-0.23175722,  0.03665546,  0.28370064, ...,  0.07979424,\n",
            "         -0.02043138,  2.        ]], dtype=float32)\n",
            " array([[-3.0927367e-03, -1.1004008e-01, -4.6651494e-02, ...,\n",
            "          4.0331006e-02,  2.0486437e-01,  3.0000000e+00],\n",
            "        [ 1.6820645e-01, -4.9000336e-03, -3.3102844e-02, ...,\n",
            "          2.5185162e-01,  6.7321330e-02,  3.0000000e+00],\n",
            "        [ 1.8028413e-01,  5.5705320e-02, -2.8894583e-02, ...,\n",
            "          3.0978999e-01, -7.1984932e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 8.9480780e-02,  8.1970289e-02,  4.6946980e-02, ...,\n",
            "          4.3502580e-02,  6.5126628e-02,  3.0000000e+00],\n",
            "        [-1.4431259e-01,  1.2616141e-01,  3.0579096e-01, ...,\n",
            "          9.7263120e-02,  7.3645770e-04,  3.0000000e+00],\n",
            "        [-2.4928729e-01,  1.0778715e-01,  2.9012561e-01, ...,\n",
            "          6.3018128e-02,  8.1485063e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-8.1503568e-03, -1.1438914e-01, -3.8759302e-02, ...,\n",
            "          4.1601844e-02,  2.0822543e-01,  2.0000000e+00],\n",
            "        [ 1.5361516e-01, -1.0182058e-02, -2.1243544e-02, ...,\n",
            "          2.4510348e-01,  8.9431584e-02,  2.0000000e+00],\n",
            "        [ 1.6761993e-01,  5.7939477e-02, -1.3736790e-02, ...,\n",
            "          3.1199431e-01, -5.9535321e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 4.5512319e-02,  1.1013599e-01,  1.0621537e-01, ...,\n",
            "          4.2231072e-02,  5.4060478e-02,  2.0000000e+00],\n",
            "        [-1.7895909e-01,  1.2461413e-01,  3.1834993e-01, ...,\n",
            "          8.5544080e-02,  1.8732557e-03,  2.0000000e+00],\n",
            "        [-2.5500646e-01,  1.0917042e-01,  2.9148656e-01, ...,\n",
            "          5.7722233e-02,  7.8117172e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01305525, -0.12435271, -0.02971946, ...,  0.04435587,\n",
            "          0.21044332,  2.        ],\n",
            "        [ 0.15270017, -0.02516587, -0.00598561, ...,  0.2631949 ,\n",
            "          0.11729775,  2.        ],\n",
            "        [ 0.15756384,  0.03882395,  0.00763096, ...,  0.33457258,\n",
            "         -0.0207791 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.0080116 ,  0.1249527 ,  0.1791784 , ...,  0.07883907,\n",
            "          0.02861202,  2.        ],\n",
            "        [-0.21098693,  0.130857  ,  0.32964635, ...,  0.07921249,\n",
            "         -0.00759211,  2.        ],\n",
            "        [-0.26763278,  0.10798343,  0.29768646, ...,  0.05769183,\n",
            "          0.004237  ,  2.        ]], dtype=float32)\n",
            " array([[-1.19571257e-02, -1.21290095e-01, -3.01586855e-02, ...,\n",
            "          4.27377410e-02,  2.11235911e-01,  1.00000000e+00],\n",
            "        [ 1.52028874e-01, -2.16840412e-02, -8.51775240e-03, ...,\n",
            "          2.58287698e-01,  1.14656225e-01,  1.00000000e+00],\n",
            "        [ 1.59349531e-01,  5.02402224e-02,  8.09776224e-03, ...,\n",
            "          3.27742368e-01, -2.97025777e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.69618614e-02,  1.20650105e-01,  1.58066779e-01, ...,\n",
            "          6.21847659e-02,  3.95003296e-02,  1.00000000e+00],\n",
            "        [-1.97683260e-01,  1.25398830e-01,  3.27753961e-01, ...,\n",
            "          7.93002918e-02, -2.30805541e-04,  1.00000000e+00],\n",
            "        [-2.61016101e-01,  1.09250143e-01,  2.96959996e-01, ...,\n",
            "          5.86566180e-02,  8.61420576e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.02416598, -0.12911825, -0.02487905, ...,  0.04336393,\n",
            "          0.2080091 ,  1.        ],\n",
            "        [ 0.12546511, -0.04529824,  0.00140067, ...,  0.23941629,\n",
            "          0.12854043,  1.        ],\n",
            "        [ 0.1167114 ,  0.0052656 ,  0.02280047, ...,  0.32210305,\n",
            "         -0.00296201,  1.        ],\n",
            "        ...,\n",
            "        [-0.10342336,  0.13637449,  0.2516349 , ...,  0.06868761,\n",
            "          0.00108876,  1.        ],\n",
            "        [-0.25581142,  0.12782367,  0.35433102, ...,  0.05635743,\n",
            "         -0.02804439,  1.        ],\n",
            "        [-0.30360568,  0.09721232,  0.30789027, ...,  0.0429152 ,\n",
            "         -0.01096999,  1.        ]], dtype=float32)\n",
            " array([[-0.03051816, -0.15660876, -0.03935686, ...,  0.05994259,\n",
            "          0.2149591 ,  1.        ],\n",
            "        [ 0.16726989, -0.08597576, -0.04935258, ...,  0.29189485,\n",
            "          0.15485162,  1.        ],\n",
            "        [ 0.12540376, -0.07358199, -0.0471856 , ...,  0.38350317,\n",
            "          0.05715147,  1.        ],\n",
            "        ...,\n",
            "        [-0.1273582 ,  0.03178256,  0.21370625, ...,  0.08993953,\n",
            "          0.00571987,  1.        ],\n",
            "        [-0.22942093,  0.03499299,  0.24666576, ...,  0.07645225,\n",
            "         -0.03197614,  1.        ],\n",
            "        [-0.27209508,  0.04511841,  0.25732973, ...,  0.04388255,\n",
            "         -0.01383497,  1.        ]], dtype=float32)\n",
            " array([[-0.01866108, -0.13152252, -0.03219882, ...,  0.05454345,\n",
            "          0.21689297,  1.        ],\n",
            "        [ 0.1621814 , -0.03643352, -0.01625473, ...,  0.27502367,\n",
            "          0.13248576,  1.        ],\n",
            "        [ 0.1558313 ,  0.02444806,  0.00462748, ...,  0.36256444,\n",
            "         -0.01169695,  1.        ],\n",
            "        ...,\n",
            "        [-0.06148899,  0.13244551,  0.20682274, ...,  0.07694167,\n",
            "          0.00362982,  1.        ],\n",
            "        [-0.2201643 ,  0.13018435,  0.30615917, ...,  0.07552738,\n",
            "         -0.02323143,  1.        ],\n",
            "        [-0.2705931 ,  0.09999356,  0.28746477, ...,  0.07268578,\n",
            "          0.00225335,  1.        ]], dtype=float32)\n",
            " array([[-0.02414909, -0.1321085 , -0.02677361, ...,  0.04491766,\n",
            "          0.20967817,  1.        ],\n",
            "        [ 0.1336752 , -0.04759007, -0.00889424, ...,  0.25626853,\n",
            "          0.13250092,  1.        ],\n",
            "        [ 0.11836221, -0.00697925,  0.00924803, ...,  0.34203392,\n",
            "          0.0112126 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.1168997 ,  0.12762216,  0.2406664 , ...,  0.08390073,\n",
            "         -0.00290993,  1.        ],\n",
            "        [-0.25294015,  0.11639191,  0.33019978, ...,  0.06493179,\n",
            "         -0.03316807,  1.        ],\n",
            "        [-0.30116528,  0.08862236,  0.2985599 , ...,  0.04773366,\n",
            "         -0.01667356,  1.        ]], dtype=float32)\n",
            " array([[-0.02367824, -0.13804924, -0.02845543, ...,  0.05396927,\n",
            "          0.21569538,  1.        ],\n",
            "        [ 0.15157725, -0.04653776, -0.00986444, ...,  0.25759044,\n",
            "          0.13874675,  1.        ],\n",
            "        [ 0.1364292 , -0.00121112,  0.01349516, ...,  0.33917946,\n",
            "          0.01017716,  1.        ],\n",
            "        ...,\n",
            "        [-0.11901772,  0.14198998,  0.22966813, ...,  0.06080105,\n",
            "         -0.01103975,  1.        ],\n",
            "        [-0.2500491 ,  0.1215023 ,  0.3103714 , ...,  0.05894112,\n",
            "         -0.03628786,  1.        ],\n",
            "        [-0.2840155 ,  0.09694939,  0.28732195, ...,  0.06202201,\n",
            "         -0.00751969,  1.        ]], dtype=float32)\n",
            " array([[-0.02012238, -0.12753478, -0.02789691, ...,  0.03965099,\n",
            "          0.20636547,  1.        ],\n",
            "        [ 0.13224067, -0.0333072 , -0.00127328, ...,  0.24407019,\n",
            "          0.1173875 ,  1.        ],\n",
            "        [ 0.12659328,  0.02535858,  0.01854509, ...,  0.3249506 ,\n",
            "         -0.01710826,  1.        ],\n",
            "        ...,\n",
            "        [-0.05673496,  0.13154136,  0.20831251, ...,  0.07046223,\n",
            "          0.01237669,  1.        ],\n",
            "        [-0.23513289,  0.12513545,  0.34051055, ...,  0.06169111,\n",
            "         -0.01982948,  1.        ],\n",
            "        [-0.28938875,  0.09757119,  0.30295324, ...,  0.04510697,\n",
            "         -0.00898875,  1.        ]], dtype=float32)\n",
            " array([[-0.03174462, -0.15431237, -0.06185065, ...,  0.06832104,\n",
            "          0.20475599,  1.        ],\n",
            "        [ 0.15374526, -0.1161072 , -0.06192034, ...,  0.2951189 ,\n",
            "          0.16771473,  1.        ],\n",
            "        [ 0.08812717, -0.10599048, -0.06194177, ...,  0.41137084,\n",
            "          0.0835444 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.19131608,  0.04005385,  0.18628483, ...,  0.08983284,\n",
            "         -0.0564911 ,  1.        ],\n",
            "        [-0.2518498 ,  0.06415554,  0.19465578, ...,  0.07788895,\n",
            "         -0.06650759,  1.        ],\n",
            "        [-0.24532227,  0.03613104,  0.22598052, ...,  0.0243051 ,\n",
            "         -0.03556717,  1.        ]], dtype=float32)\n",
            " array([[-0.02476581, -0.1576591 , -0.06347252, ...,  0.05352031,\n",
            "          0.18508328,  1.        ],\n",
            "        [ 0.10820181, -0.13387318, -0.06285698, ...,  0.24330968,\n",
            "          0.15040264,  1.        ],\n",
            "        [ 0.04127723, -0.1344095 , -0.08022538, ...,  0.33794358,\n",
            "          0.09159502,  1.        ],\n",
            "        ...,\n",
            "        [-0.22444254,  0.04823797,  0.2031676 , ..., -0.00805797,\n",
            "         -0.08918613,  1.        ],\n",
            "        [-0.2622058 ,  0.06317966,  0.20834865, ...,  0.00313435,\n",
            "         -0.08402448,  1.        ],\n",
            "        [-0.22490153,  0.03722733,  0.23466903, ..., -0.02623339,\n",
            "         -0.05442889,  1.        ]], dtype=float32)\n",
            " array([[-0.01528339, -0.11841486, -0.03912491, ...,  0.05005169,\n",
            "          0.21262115,  1.        ],\n",
            "        [ 0.15251438, -0.00734508, -0.01531304, ...,  0.25612876,\n",
            "          0.10642391,  1.        ],\n",
            "        [ 0.15820166,  0.06130895,  0.00375342, ...,  0.3272113 ,\n",
            "         -0.04855673,  1.        ],\n",
            "        ...,\n",
            "        [ 0.00144701,  0.13001625,  0.1625887 , ...,  0.05073735,\n",
            "          0.01725862,  1.        ],\n",
            "        [-0.19817184,  0.13905153,  0.3183781 , ...,  0.06604449,\n",
            "         -0.01072684,  1.        ],\n",
            "        [-0.26096758,  0.10860897,  0.29493225, ...,  0.06976932,\n",
            "          0.00731085,  1.        ]], dtype=float32)\n",
            " array([[-5.64333168e-04, -1.10412911e-01, -4.33995128e-02, ...,\n",
            "          4.14584689e-02,  2.06039399e-01,  1.00000000e+00],\n",
            "        [ 1.73416510e-01, -3.78929055e-03, -3.12961675e-02, ...,\n",
            "          2.51132786e-01,  7.81988278e-02,  1.00000000e+00],\n",
            "        [ 1.84345812e-01,  6.03665449e-02, -2.62519419e-02, ...,\n",
            "          3.11967313e-01, -6.52652234e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 8.76961350e-02,  8.94517228e-02,  5.64185306e-02, ...,\n",
            "          4.62557785e-02,  6.69383109e-02,  1.00000000e+00],\n",
            "        [-1.49477512e-01,  1.24624871e-01,  3.04935753e-01, ...,\n",
            "          1.00820281e-01,  3.07201082e-03,  1.00000000e+00],\n",
            "        [-2.44749531e-01,  1.08993754e-01,  2.89151758e-01, ...,\n",
            "          6.31746575e-02,  7.30123604e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.00858529, -0.11776134, -0.03679939, ...,  0.04571396,\n",
            "          0.20850837,  1.        ],\n",
            "        [ 0.15705512, -0.01406227, -0.02168532, ...,  0.25722986,\n",
            "          0.10169929,  1.        ],\n",
            "        [ 0.16538487,  0.0552858 , -0.01094056, ...,  0.33067772,\n",
            "         -0.04330911,  1.        ],\n",
            "        ...,\n",
            "        [ 0.03197657,  0.11962496,  0.13387002, ...,  0.06623937,\n",
            "          0.04325181,  1.        ],\n",
            "        [-0.18955973,  0.12084106,  0.31888992, ...,  0.09031302,\n",
            "         -0.00198644,  1.        ],\n",
            "        [-0.2547895 ,  0.10786854,  0.28789473, ...,  0.06134979,\n",
            "          0.00606501,  1.        ]], dtype=float32)\n",
            " array([[-0.01675859, -0.13813756, -0.02503882, ...,  0.05464143,\n",
            "          0.21378806,  1.        ],\n",
            "        [ 0.15492247, -0.05970743, -0.01545044, ...,  0.24980387,\n",
            "          0.15785418,  1.        ],\n",
            "        [ 0.12253129, -0.03471868,  0.00230279, ...,  0.34076655,\n",
            "          0.05242174,  1.        ],\n",
            "        ...,\n",
            "        [-0.07843053,  0.10623561,  0.22140299, ...,  0.09678608,\n",
            "          0.03969907,  1.        ],\n",
            "        [-0.23600331,  0.10406063,  0.3243211 , ...,  0.10533653,\n",
            "          0.00432019,  1.        ],\n",
            "        [-0.31040618,  0.08309225,  0.29478785, ...,  0.07434549,\n",
            "         -0.0032923 ,  1.        ]], dtype=float32)\n",
            " array([[-0.03206005, -0.14677344, -0.04004591, ...,  0.06221212,\n",
            "          0.21722351,  1.        ],\n",
            "        [ 0.17391762, -0.07346112, -0.05812815, ...,  0.295465  ,\n",
            "          0.15481664,  1.        ],\n",
            "        [ 0.1320788 , -0.06298253, -0.05375155, ...,  0.39174953,\n",
            "          0.05384953,  1.        ],\n",
            "        ...,\n",
            "        [-0.11101098,  0.04365036,  0.19433297, ...,  0.09759468,\n",
            "          0.01413182,  1.        ],\n",
            "        [-0.23438162,  0.04702431,  0.2527165 , ...,  0.07903895,\n",
            "         -0.03253826,  1.        ],\n",
            "        [-0.282568  ,  0.05640779,  0.26291797, ...,  0.04493512,\n",
            "         -0.01222551,  1.        ]], dtype=float32)\n",
            " array([[-1.9687355e-02, -1.2634249e-01, -2.7776903e-02, ...,\n",
            "          3.9949924e-02,  2.0779589e-01,  1.0000000e+00],\n",
            "        [ 1.3208485e-01, -3.1068129e-02,  4.3082226e-04, ...,\n",
            "          2.4518682e-01,  1.1897461e-01,  1.0000000e+00],\n",
            "        [ 1.2775154e-01,  2.9659530e-02,  2.2496674e-02, ...,\n",
            "          3.2357243e-01, -1.9003114e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-4.0919445e-02,  1.3257942e-01,  1.9830537e-01, ...,\n",
            "          6.3558199e-02,  1.8096456e-02,  1.0000000e+00],\n",
            "        [-2.3189616e-01,  1.3066179e-01,  3.3887893e-01, ...,\n",
            "          5.7592347e-02, -1.5127225e-02,  1.0000000e+00],\n",
            "        [-2.8986037e-01,  9.9406779e-02,  3.0165106e-01, ...,\n",
            "          4.7016181e-02, -8.3320886e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02298584, -0.12828435, -0.02507497, ...,  0.04095198,\n",
            "          0.2073586 ,  1.        ],\n",
            "        [ 0.12887941, -0.04166729,  0.0045481 , ...,  0.23654665,\n",
            "          0.12341388,  1.        ],\n",
            "        [ 0.11959025,  0.01056473,  0.02718493, ...,  0.31622452,\n",
            "         -0.00582336,  1.        ],\n",
            "        ...,\n",
            "        [-0.09783309,  0.13999082,  0.2422871 , ...,  0.06313398,\n",
            "          0.00450251,  1.        ],\n",
            "        [-0.25182515,  0.1344238 ,  0.34761226, ...,  0.05362139,\n",
            "         -0.02844182,  1.        ],\n",
            "        [-0.30058128,  0.10008375,  0.30615425, ...,  0.04344015,\n",
            "         -0.01017036,  1.        ]], dtype=float32)\n",
            " array([[-0.01795064, -0.14075959, -0.03395282, ...,  0.0517626 ,\n",
            "          0.21607739,  1.        ],\n",
            "        [ 0.14968476, -0.04428928, -0.01242012, ...,  0.25187758,\n",
            "          0.13869418,  1.        ],\n",
            "        [ 0.13976002,  0.00299863,  0.01101487, ...,  0.33291963,\n",
            "          0.00375311,  1.        ],\n",
            "        ...,\n",
            "        [-0.0489788 ,  0.14186013,  0.17867564, ...,  0.04734629,\n",
            "          0.03146386,  1.        ],\n",
            "        [-0.21359682,  0.12706052,  0.2910571 , ...,  0.05717053,\n",
            "         -0.00903075,  1.        ],\n",
            "        [-0.27313206,  0.09737287,  0.27381787, ...,  0.06569937,\n",
            "         -0.00342167,  1.        ]], dtype=float32)\n",
            " array([[-0.01966288, -0.13024297, -0.02753676, ...,  0.04402677,\n",
            "          0.21006441,  1.        ],\n",
            "        [ 0.13847862, -0.03512032, -0.00422271, ...,  0.2533619 ,\n",
            "          0.1273382 ,  1.        ],\n",
            "        [ 0.13554803,  0.0203068 ,  0.0172416 , ...,  0.3332417 ,\n",
            "         -0.00581053,  1.        ],\n",
            "        ...,\n",
            "        [-0.06289487,  0.13233541,  0.22000149, ...,  0.07666437,\n",
            "          0.0123643 ,  1.        ],\n",
            "        [-0.23465098,  0.12265653,  0.3384678 , ...,  0.06809931,\n",
            "         -0.01757036,  1.        ],\n",
            "        [-0.28812918,  0.09388144,  0.29941463, ...,  0.05457367,\n",
            "         -0.00817961,  1.        ]], dtype=float32)\n",
            " array([[ 3.1197526e-02, -1.2628478e-01, -8.5835859e-02, ...,\n",
            "          3.7205558e-02,  2.0670295e-01,  1.0000000e+00],\n",
            "        [ 2.2861758e-01,  3.3384487e-03, -7.0828885e-02, ...,\n",
            "          2.4482438e-01,  6.0516980e-02,  1.0000000e+00],\n",
            "        [ 2.1549965e-01,  3.5637792e-02, -6.1864704e-02, ...,\n",
            "          3.2316998e-01, -7.5344644e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [ 2.0032175e-01,  1.7644973e-02, -4.9614217e-02, ...,\n",
            "          5.8435790e-02,  8.6401157e-02,  1.0000000e+00],\n",
            "        [-4.1354142e-02,  9.2401423e-02,  2.2400321e-01, ...,\n",
            "          1.0432030e-01,  5.9990291e-03,  1.0000000e+00],\n",
            "        [-2.2761627e-01,  7.8339599e-02,  2.7111864e-01, ...,\n",
            "          7.9205148e-02, -7.9715101e-05,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.013965  , -0.12120335, -0.0353304 , ...,  0.04799291,\n",
            "          0.21845204,  1.        ],\n",
            "        [ 0.14754789, -0.02398829, -0.01336467, ...,  0.24592853,\n",
            "          0.12032609,  1.        ],\n",
            "        [ 0.14767046,  0.04135533,  0.00748582, ...,  0.32054353,\n",
            "         -0.03282656,  1.        ],\n",
            "        ...,\n",
            "        [-0.00123308,  0.13895792,  0.16263558, ...,  0.05078538,\n",
            "          0.03088121,  1.        ],\n",
            "        [-0.20880876,  0.14549166,  0.31535614, ...,  0.06771115,\n",
            "         -0.00928316,  1.        ],\n",
            "        [-0.26623234,  0.10864531,  0.29492807, ...,  0.07117241,\n",
            "          0.00483996,  1.        ]], dtype=float32)\n",
            " array([[-0.01975279, -0.12207877, -0.03127986, ...,  0.03804402,\n",
            "          0.20666   ,  1.        ],\n",
            "        [ 0.12596981, -0.01819715, -0.00300354, ...,  0.23607065,\n",
            "          0.10474312,  1.        ],\n",
            "        [ 0.12866262,  0.04876288,  0.0163925 , ...,  0.30948034,\n",
            "         -0.03741411,  1.        ],\n",
            "        ...,\n",
            "        [-0.01657265,  0.12737077,  0.1743518 , ...,  0.04010146,\n",
            "          0.02502643,  1.        ],\n",
            "        [-0.22096133,  0.12320973,  0.33913985, ...,  0.04922864,\n",
            "         -0.01261027,  1.        ],\n",
            "        [-0.28158817,  0.09598426,  0.30454674, ...,  0.04363429,\n",
            "         -0.00226917,  1.        ]], dtype=float32)\n",
            " array([[-0.02536638, -0.14765482, -0.04391514, ...,  0.06742646,\n",
            "          0.21337278,  1.        ],\n",
            "        [ 0.18948571, -0.07086933, -0.05589253, ...,  0.29788664,\n",
            "          0.14556645,  1.        ],\n",
            "        [ 0.15355237, -0.05713689, -0.05078499, ...,  0.38991022,\n",
            "          0.04237614,  1.        ],\n",
            "        ...,\n",
            "        [-0.09083825,  0.03445011,  0.18490118, ...,  0.08525338,\n",
            "          0.00485741,  1.        ],\n",
            "        [-0.20469499,  0.04772687,  0.22557299, ...,  0.07924498,\n",
            "         -0.03064762,  1.        ],\n",
            "        [-0.2515598 ,  0.05130232,  0.24395779, ...,  0.05412001,\n",
            "         -0.01274569,  1.        ]], dtype=float32)\n",
            " array([[ 0.00659721, -0.11940145, -0.06088507, ...,  0.05279312,\n",
            "          0.20904602,  1.        ],\n",
            "        [ 0.16949534, -0.0107664 , -0.05153409, ...,  0.23945424,\n",
            "          0.10404121,  1.        ],\n",
            "        [ 0.16286547,  0.04194534, -0.03414015, ...,  0.32641804,\n",
            "         -0.05719742,  1.        ],\n",
            "        ...,\n",
            "        [ 0.06847383,  0.10034128,  0.08370105, ...,  0.04924395,\n",
            "          0.03851741,  1.        ],\n",
            "        [-0.13808215,  0.13421024,  0.2607332 , ...,  0.07180519,\n",
            "         -0.00544702,  1.        ],\n",
            "        [-0.2400117 ,  0.09830663,  0.26132244, ...,  0.07456896,\n",
            "          0.00215271,  1.        ]], dtype=float32)\n",
            " array([[-1.76828913e-02, -1.26763672e-01, -2.72378903e-02, ...,\n",
            "          4.35591713e-02,  2.08871499e-01,  2.00000000e+00],\n",
            "        [ 1.44647554e-01, -3.20360102e-02, -9.98761505e-04, ...,\n",
            "          2.58893877e-01,  1.15868963e-01,  2.00000000e+00],\n",
            "        [ 1.47808954e-01,  2.72527877e-02,  1.24799656e-02, ...,\n",
            "          3.31263304e-01, -1.92849226e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-2.97582336e-02,  1.23714246e-01,  1.98341653e-01, ...,\n",
            "          7.47883469e-02,  1.68781690e-02,  2.00000000e+00],\n",
            "        [-2.24421680e-01,  1.30492792e-01,  3.39064956e-01, ...,\n",
            "          7.27665126e-02, -1.43395225e-02,  2.00000000e+00],\n",
            "        [-2.74237514e-01,  1.08672604e-01,  2.98560500e-01, ...,\n",
            "          5.10324575e-02,  3.85916210e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-3.4253232e-02, -1.6100785e-01, -4.5420174e-02, ...,\n",
            "          6.5142393e-02,  2.1401022e-01,  3.0000000e+00],\n",
            "        [ 1.7437236e-01, -9.7165518e-02, -5.5297751e-02, ...,\n",
            "          2.9872647e-01,  1.6299874e-01,  3.0000000e+00],\n",
            "        [ 1.2658887e-01, -9.1386944e-02, -5.1716223e-02, ...,\n",
            "          3.9249408e-01,  7.0780188e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.3550209e-01,  2.8409937e-02,  2.0112504e-01, ...,\n",
            "          9.5090322e-02, -2.3946585e-03,  3.0000000e+00],\n",
            "        [-2.3596127e-01,  4.2225990e-02,  2.2068664e-01, ...,\n",
            "          7.8525469e-02, -3.9154500e-02,  3.0000000e+00],\n",
            "        [-2.6465440e-01,  3.1057507e-02,  2.4166986e-01, ...,\n",
            "          3.9928276e-02, -1.9196108e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.9015409e-02, -1.2915105e-01, -3.1290133e-02, ...,\n",
            "          6.3854218e-02,  2.1242559e-01,  3.0000000e+00],\n",
            "        [ 1.6759254e-01, -5.0361086e-02, -2.3400009e-02, ...,\n",
            "          2.6734862e-01,  1.4465976e-01,  3.0000000e+00],\n",
            "        [ 1.4374729e-01, -1.6144490e-02, -2.3081002e-03, ...,\n",
            "          3.6118814e-01,  2.5044216e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1283331e-01,  1.2244813e-01,  2.2499749e-01, ...,\n",
            "          7.7161096e-02, -7.8131761e-03,  3.0000000e+00],\n",
            "        [-2.4993926e-01,  1.0479943e-01,  2.9515275e-01, ...,\n",
            "          7.0925973e-02, -3.6025498e-02,  3.0000000e+00],\n",
            "        [-2.8506598e-01,  9.4286129e-02,  2.7776885e-01, ...,\n",
            "          5.9933558e-02, -7.6208157e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02124049, -0.12450365, -0.03609015, ...,  0.05065326,\n",
            "          0.21195182,  3.        ],\n",
            "        [ 0.1341717 , -0.0206976 , -0.01072489, ...,  0.24858177,\n",
            "          0.1085953 ,  3.        ],\n",
            "        [ 0.14186315,  0.04691086,  0.00590875, ...,  0.31767198,\n",
            "         -0.04373518,  3.        ],\n",
            "        ...,\n",
            "        [-0.02860326,  0.13976415,  0.18760253, ...,  0.04799777,\n",
            "          0.00578769,  3.        ],\n",
            "        [-0.22574307,  0.14411452,  0.33390683, ...,  0.06043467,\n",
            "         -0.01967489,  3.        ],\n",
            "        [-0.27645227,  0.10692069,  0.30296382, ...,  0.06748039,\n",
            "          0.00535919,  3.        ]], dtype=float32)\n",
            " array([[-5.0476496e-03, -1.0948212e-01, -5.3097840e-02, ...,\n",
            "          2.9424397e-02,  1.9742690e-01,  3.0000000e+00],\n",
            "        [ 1.5029009e-01, -8.5247094e-03, -2.4855912e-02, ...,\n",
            "          2.2546217e-01,  5.3960372e-02,  3.0000000e+00],\n",
            "        [ 1.5994467e-01,  5.3957339e-02, -2.1105714e-02, ...,\n",
            "          2.9125324e-01, -8.7838963e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.2135158e-02,  8.2199857e-02,  6.7081429e-02, ...,\n",
            "          1.9493189e-02,  7.2070837e-02,  3.0000000e+00],\n",
            "        [-1.6496165e-01,  1.2414506e-01,  3.1512219e-01, ...,\n",
            "          6.9023527e-02, -4.4334694e-04,  3.0000000e+00],\n",
            "        [-2.6856771e-01,  8.9168906e-02,  3.0038649e-01, ...,\n",
            "          5.3648774e-02, -2.2872665e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.4524918e-02, -1.3999285e-01, -3.2226358e-02, ...,\n",
            "          5.3931233e-02,  2.1626320e-01,  3.0000000e+00],\n",
            "        [ 1.6062124e-01, -4.3790523e-02, -1.4467308e-02, ...,\n",
            "          2.7206188e-01,  1.2965816e-01,  3.0000000e+00],\n",
            "        [ 1.4947441e-01,  1.0852516e-02,  4.1109915e-03, ...,\n",
            "          3.5141486e-01, -9.2601118e-04,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-6.9716349e-02,  1.3529798e-01,  1.9298369e-01, ...,\n",
            "          6.0752802e-02,  7.7014104e-03,  3.0000000e+00],\n",
            "        [-2.2845152e-01,  1.2738194e-01,  2.9196939e-01, ...,\n",
            "          6.3429534e-02, -2.1260783e-02,  3.0000000e+00],\n",
            "        [-2.7466404e-01,  9.7821929e-02,  2.7994794e-01, ...,\n",
            "          6.7880228e-02,  2.0903971e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03201182, -0.12166312, -0.02970908, ...,  0.05599002,\n",
            "          0.20613495,  3.        ],\n",
            "        [ 0.13633339, -0.05419631, -0.02923264, ...,  0.25774118,\n",
            "          0.14131598,  3.        ],\n",
            "        [ 0.11708938, -0.02341691, -0.01499587, ...,  0.35086071,\n",
            "          0.02568009,  3.        ],\n",
            "        ...,\n",
            "        [-0.14828514,  0.11177809,  0.24883097, ...,  0.08839899,\n",
            "         -0.00734728,  3.        ],\n",
            "        [-0.26598626,  0.09900486,  0.313785  , ...,  0.06911823,\n",
            "         -0.03754996,  3.        ],\n",
            "        [-0.30748665,  0.0874343 ,  0.29105967, ...,  0.03921661,\n",
            "         -0.01775062,  3.        ]], dtype=float32)\n",
            " array([[-0.03464951, -0.13955346, -0.03609059, ...,  0.06102585,\n",
            "          0.21224295,  3.        ],\n",
            "        [ 0.16293135, -0.05985417, -0.03759754, ...,  0.2712158 ,\n",
            "          0.14771023,  3.        ],\n",
            "        [ 0.12657331, -0.03711152, -0.02787862, ...,  0.35694152,\n",
            "          0.04276998,  3.        ],\n",
            "        ...,\n",
            "        [-0.13601044,  0.07567976,  0.22315133, ...,  0.07624772,\n",
            "         -0.00461201,  3.        ],\n",
            "        [-0.25758958,  0.0660684 ,  0.2677926 , ...,  0.06320165,\n",
            "         -0.04309697,  3.        ],\n",
            "        [-0.2853657 ,  0.07037856,  0.26797464, ...,  0.04408112,\n",
            "         -0.0160709 ,  3.        ]], dtype=float32)\n",
            " array([[-0.02180982, -0.13878372, -0.02942616, ...,  0.04827115,\n",
            "          0.21063913,  3.        ],\n",
            "        [ 0.14808908, -0.04976252, -0.01820525, ...,  0.27303478,\n",
            "          0.1335582 ,  3.        ],\n",
            "        [ 0.13083622, -0.01323024, -0.00638919, ...,  0.36011523,\n",
            "          0.01915225,  3.        ],\n",
            "        ...,\n",
            "        [-0.09927853,  0.09942615,  0.2135229 , ...,  0.08773331,\n",
            "          0.00697557,  3.        ],\n",
            "        [-0.23315157,  0.08729264,  0.2991198 , ...,  0.06921618,\n",
            "         -0.02622155,  3.        ],\n",
            "        [-0.28994763,  0.08102592,  0.2889322 , ...,  0.05529799,\n",
            "         -0.01385292,  3.        ]], dtype=float32)\n",
            " array([[-2.52608117e-02, -1.39732614e-01, -2.83513665e-02, ...,\n",
            "          5.62291779e-02,  2.17208222e-01,  3.00000000e+00],\n",
            "        [ 1.55058622e-01, -4.87343632e-02, -1.16838086e-02, ...,\n",
            "          2.57707119e-01,  1.42620817e-01,  3.00000000e+00],\n",
            "        [ 1.40420556e-01,  3.44233704e-05,  1.03590442e-02, ...,\n",
            "          3.41899842e-01,  1.05419289e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.03711806e-01,  1.42297328e-01,  2.22408429e-01, ...,\n",
            "          6.32366538e-02, -1.17298739e-03,  3.00000000e+00],\n",
            "        [-2.49583676e-01,  1.24518409e-01,  3.08948666e-01, ...,\n",
            "          6.17308021e-02, -2.91057937e-02,  3.00000000e+00],\n",
            "        [-2.83431262e-01,  9.55256298e-02,  2.85085917e-01, ...,\n",
            "          6.35089278e-02, -1.96295767e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.16335561e-02, -1.23122990e-01, -2.84031928e-02, ...,\n",
            "          3.76658626e-02,  2.05369756e-01,  3.00000000e+00],\n",
            "        [ 1.24285221e-01, -3.01352162e-02,  2.55292072e-03, ...,\n",
            "          2.30961055e-01,  1.13111876e-01,  3.00000000e+00],\n",
            "        [ 1.19543687e-01,  3.05279717e-02,  2.09789407e-02, ...,\n",
            "          3.08500648e-01, -2.43309103e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-5.03611416e-02,  1.37391791e-01,  2.08017975e-01, ...,\n",
            "          4.84546162e-02,  1.72263514e-02,  3.00000000e+00],\n",
            "        [-2.36594900e-01,  1.37749106e-01,  3.43556136e-01, ...,\n",
            "          4.59029526e-02, -1.61564574e-02,  3.00000000e+00],\n",
            "        [-2.92756855e-01,  1.03559516e-01,  3.05527627e-01, ...,\n",
            "          3.95272262e-02, -4.73741861e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.00746779e-02, -1.17684513e-01, -3.39480191e-02, ...,\n",
            "          4.35776673e-02,  2.08902165e-01,  3.00000000e+00],\n",
            "        [ 1.54248804e-01, -1.14541929e-02, -1.32614700e-02, ...,\n",
            "          2.50301391e-01,  1.01454355e-01,  3.00000000e+00],\n",
            "        [ 1.63407519e-01,  5.89878559e-02, -2.46681483e-03, ...,\n",
            "          3.17951560e-01, -4.52255905e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.60583293e-02,  1.17503241e-01,  1.37326896e-01, ...,\n",
            "          4.95459437e-02,  4.30863723e-02,  3.00000000e+00],\n",
            "        [-1.91217020e-01,  1.23667903e-01,  3.24174643e-01, ...,\n",
            "          7.94674158e-02, -4.33198802e-05,  3.00000000e+00],\n",
            "        [-2.56009489e-01,  1.11170672e-01,  2.92050809e-01, ...,\n",
            "          5.59518784e-02,  8.17464478e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.8699107e-02, -1.2608169e-01, -2.7833357e-02, ...,\n",
            "          4.7079619e-02,  2.0544475e-01,  3.0000000e+00],\n",
            "        [ 1.3463299e-01, -5.3443074e-02, -1.7754082e-02, ...,\n",
            "          2.3905513e-01,  1.3422452e-01,  3.0000000e+00],\n",
            "        [ 1.1402842e-01, -2.2545673e-02,  1.2556590e-03, ...,\n",
            "          3.3100551e-01,  1.7095335e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.3377033e-01,  1.2383160e-01,  2.3966423e-01, ...,\n",
            "          6.8746954e-02,  1.1916382e-03,  3.0000000e+00],\n",
            "        [-2.6077124e-01,  1.1318078e-01,  3.1839755e-01, ...,\n",
            "          5.4679479e-02, -3.5781506e-02,  3.0000000e+00],\n",
            "        [-3.0484137e-01,  9.5075265e-02,  2.9406315e-01, ...,\n",
            "          3.8458936e-02, -1.7722458e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03625703, -0.15152033, -0.05083894, ...,  0.06614945,\n",
            "          0.2127518 ,  3.        ],\n",
            "        [ 0.16028257, -0.09833042, -0.06909859, ...,  0.30761543,\n",
            "          0.15788044,  3.        ],\n",
            "        [ 0.1118403 , -0.09633303, -0.06955121, ...,  0.4122246 ,\n",
            "          0.0693917 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.14645115,  0.01687439,  0.20551595, ...,  0.11712254,\n",
            "         -0.01035408,  3.        ],\n",
            "        [-0.24664377,  0.02867796,  0.21893524, ...,  0.08929678,\n",
            "         -0.04387379,  3.        ],\n",
            "        [-0.27051264,  0.03815155,  0.243725  , ...,  0.03774983,\n",
            "         -0.0182225 ,  3.        ]], dtype=float32)\n",
            " array([[-2.42132153e-02, -1.39642313e-01, -3.11008468e-02, ...,\n",
            "          5.62209412e-02,  2.16984048e-01,  3.00000000e+00],\n",
            "        [ 1.59434423e-01, -4.43637259e-02, -1.90418977e-02, ...,\n",
            "          2.71506518e-01,  1.37471557e-01,  3.00000000e+00],\n",
            "        [ 1.45331100e-01,  3.07905546e-04,  4.52463981e-03, ...,\n",
            "          3.56381804e-01,  9.00775567e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-8.43119621e-02,  1.17379807e-01,  2.09142536e-01, ...,\n",
            "          6.34668544e-02, -1.60290708e-03,  3.00000000e+00],\n",
            "        [-2.28016570e-01,  1.11911304e-01,  2.95490026e-01, ...,\n",
            "          6.50519505e-02, -2.98303608e-02,  3.00000000e+00],\n",
            "        [-2.78439790e-01,  9.01414528e-02,  2.82562345e-01, ...,\n",
            "          6.41142875e-02, -3.74458078e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.12675985e-02, -1.24909192e-01, -3.84846032e-02, ...,\n",
            "          5.31715974e-02,  2.14005351e-01,  3.00000000e+00],\n",
            "        [ 1.41953975e-01, -1.55514646e-02, -1.41628115e-02, ...,\n",
            "          2.52412558e-01,  1.15505196e-01,  3.00000000e+00],\n",
            "        [ 1.46465659e-01,  4.81731929e-02,  2.63184868e-03, ...,\n",
            "          3.26828927e-01, -3.12300678e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.77056175e-02,  1.34126782e-01,  1.71707749e-01, ...,\n",
            "          5.73997460e-02,  1.84016787e-02,  3.00000000e+00],\n",
            "        [-2.19611242e-01,  1.37988999e-01,  3.24407220e-01, ...,\n",
            "          7.07260519e-02, -1.61853060e-02,  3.00000000e+00],\n",
            "        [-2.77985305e-01,  1.02668174e-01,  2.98001021e-01, ...,\n",
            "          6.92316666e-02,  4.85879090e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.01934863, -0.13034862, -0.03575426, ...,  0.05209428,\n",
            "          0.21503146,  3.        ],\n",
            "        [ 0.14391403, -0.02873984, -0.01374783, ...,  0.2509328 ,\n",
            "          0.12600327,  3.        ],\n",
            "        [ 0.14199746,  0.03489854,  0.00759754, ...,  0.32708248,\n",
            "         -0.02100768,  3.        ],\n",
            "        ...,\n",
            "        [-0.04238029,  0.14638297,  0.1865297 , ...,  0.04836432,\n",
            "          0.01842791,  3.        ],\n",
            "        [-0.22173074,  0.14494006,  0.30756065, ...,  0.05781666,\n",
            "         -0.01414434,  3.        ],\n",
            "        [-0.27344733,  0.10474078,  0.2891405 , ...,  0.06715902,\n",
            "          0.00370719,  3.        ]], dtype=float32)\n",
            " array([[-0.03292932, -0.15919405, -0.05608523, ...,  0.06497405,\n",
            "          0.21252722,  3.        ],\n",
            "        [ 0.15203114, -0.10857985, -0.06966903, ...,  0.29757407,\n",
            "          0.15690675,  3.        ],\n",
            "        [ 0.10143917, -0.10272883, -0.07172598, ...,  0.39630947,\n",
            "          0.06538022,  3.        ],\n",
            "        ...,\n",
            "        [-0.15157343,  0.00793051,  0.19808795, ...,  0.09100258,\n",
            "         -0.02118216,  3.        ],\n",
            "        [-0.22687227,  0.03471028,  0.19753781, ...,  0.08034531,\n",
            "         -0.04743684,  3.        ],\n",
            "        [-0.25194904,  0.01472085,  0.22715855, ...,  0.04068865,\n",
            "         -0.02626838,  3.        ]], dtype=float32)\n",
            " array([[-0.02675763, -0.15940662, -0.0475746 , ...,  0.05704852,\n",
            "          0.21247658,  3.        ],\n",
            "        [ 0.15158136, -0.09928057, -0.07590517, ...,  0.28887418,\n",
            "          0.15006353,  3.        ],\n",
            "        [ 0.11003683, -0.09401229, -0.08337735, ...,  0.38189676,\n",
            "          0.05677528,  3.        ],\n",
            "        ...,\n",
            "        [-0.10812002,  0.01215437,  0.17887877, ...,  0.10612138,\n",
            "          0.0279573 ,  3.        ],\n",
            "        [-0.21014397,  0.01489135,  0.22709313, ...,  0.07900816,\n",
            "         -0.01591542,  3.        ],\n",
            "        [-0.26531795,  0.01462107,  0.24335569, ...,  0.04336945,\n",
            "         -0.02258555,  3.        ]], dtype=float32)\n",
            " array([[-0.01904949, -0.1544731 , -0.06369968, ...,  0.04887078,\n",
            "          0.17825001,  3.        ],\n",
            "        [ 0.1046309 , -0.13109083, -0.05556778, ...,  0.22939625,\n",
            "          0.14572155,  3.        ],\n",
            "        [ 0.03808829, -0.13363136, -0.07581625, ...,  0.32327995,\n",
            "          0.0924965 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.21367365,  0.04939011,  0.2325007 , ..., -0.04354977,\n",
            "         -0.09483258,  3.        ],\n",
            "        [-0.24768077,  0.0743373 ,  0.23562276, ..., -0.03171566,\n",
            "         -0.09209391,  3.        ],\n",
            "        [-0.20242648,  0.05641251,  0.24355353, ..., -0.04355041,\n",
            "         -0.06468046,  3.        ]], dtype=float32)\n",
            " array([[-0.03161503, -0.1262314 , -0.03102248, ...,  0.05784568,\n",
            "          0.20769872,  3.        ],\n",
            "        [ 0.14560153, -0.05722874, -0.03510547, ...,  0.2732268 ,\n",
            "          0.1401015 ,  3.        ],\n",
            "        [ 0.12547901, -0.02824308, -0.02640948, ...,  0.36789912,\n",
            "          0.02860104,  3.        ],\n",
            "        ...,\n",
            "        [-0.12239194,  0.0918585 ,  0.22699179, ...,  0.09466986,\n",
            "          0.00477882,  3.        ],\n",
            "        [-0.24911633,  0.07993858,  0.29570758, ...,  0.07301796,\n",
            "         -0.03034311,  3.        ],\n",
            "        [-0.29943252,  0.0809981 ,  0.28543973, ...,  0.04673995,\n",
            "         -0.01696096,  3.        ]], dtype=float32)\n",
            " array([[ 0.03085224, -0.13232635, -0.07475076, ...,  0.0094952 ,\n",
            "          0.17809486,  3.        ],\n",
            "        [ 0.22500956, -0.01832211, -0.06055803, ...,  0.1860754 ,\n",
            "          0.01203757,  3.        ],\n",
            "        [ 0.22699091,  0.02315541, -0.0530851 , ...,  0.24153762,\n",
            "         -0.10810972,  3.        ],\n",
            "        ...,\n",
            "        [ 0.12460442,  0.00364568, -0.03731531, ...,  0.04153555,\n",
            "          0.07323473,  3.        ],\n",
            "        [-0.08339435,  0.09276606,  0.26055112, ...,  0.10614704,\n",
            "         -0.02913628,  3.        ],\n",
            "        [-0.26109204,  0.06379906,  0.30330843, ...,  0.07428612,\n",
            "         -0.02109112,  3.        ]], dtype=float32)\n",
            " array([[-0.03368687, -0.14450713, -0.03668427, ...,  0.06231222,\n",
            "          0.21580045,  3.        ],\n",
            "        [ 0.1719187 , -0.06657369, -0.0442768 , ...,  0.28441137,\n",
            "          0.15184627,  3.        ],\n",
            "        [ 0.13253237, -0.04800586, -0.03935768, ...,  0.37168902,\n",
            "          0.05060734,  3.        ],\n",
            "        ...,\n",
            "        [-0.11190724,  0.07059671,  0.20149015, ...,  0.08676619,\n",
            "          0.01287691,  3.        ],\n",
            "        [-0.23995784,  0.07223263,  0.2573099 , ...,  0.07428747,\n",
            "         -0.03281214,  3.        ],\n",
            "        [-0.28251103,  0.06222625,  0.26107362, ...,  0.04945118,\n",
            "         -0.01716415,  3.        ]], dtype=float32)\n",
            " array([[-2.27952041e-02, -1.30235776e-01, -2.71862615e-02, ...,\n",
            "          4.34051007e-02,  2.08091095e-01,  3.00000000e+00],\n",
            "        [ 1.33645609e-01, -3.71719711e-02, -3.46434535e-03, ...,\n",
            "          2.52784342e-01,  1.24260485e-01,  3.00000000e+00],\n",
            "        [ 1.26732692e-01,  1.56267211e-02,  1.66850388e-02, ...,\n",
            "          3.32799673e-01, -4.54040663e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-8.64253491e-02,  1.34084418e-01,  2.27055416e-01, ...,\n",
            "          7.86311105e-02,  2.33059516e-03,  3.00000000e+00],\n",
            "        [-2.44025856e-01,  1.22918002e-01,  3.39691460e-01, ...,\n",
            "          6.44837096e-02, -2.71481276e-02,  3.00000000e+00],\n",
            "        [-2.94220299e-01,  9.55822393e-02,  3.01443785e-01, ...,\n",
            "          4.85988930e-02, -1.21112140e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.2827249e-02, -1.3163245e-01, -2.5024865e-02, ...,\n",
            "          4.4900890e-02,  2.0992507e-01,  3.0000000e+00],\n",
            "        [ 1.3657361e-01, -4.2841926e-02, -5.2257944e-03, ...,\n",
            "          2.5539574e-01,  1.3248616e-01,  3.0000000e+00],\n",
            "        [ 1.2524675e-01,  4.1192491e-03,  1.6684098e-02, ...,\n",
            "          3.3788893e-01,  7.8761857e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0420532e-01,  1.3221157e-01,  2.4399598e-01, ...,\n",
            "          7.9787567e-02, -6.2423392e-04,  3.0000000e+00],\n",
            "        [-2.5006592e-01,  1.2316789e-01,  3.3827144e-01, ...,\n",
            "          6.5228276e-02, -2.9375827e-02,  3.0000000e+00],\n",
            "        [-2.9921851e-01,  9.0741634e-02,  3.0064392e-01, ...,\n",
            "          5.1765807e-02, -1.4719901e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-1.7650733e-02, -1.2787610e-01, -2.6912784e-02, ...,\n",
            "          4.5297928e-02,  2.1065466e-01,  1.0000000e+00],\n",
            "        [ 1.4599180e-01, -3.4738574e-02, -6.1564118e-04, ...,\n",
            "          2.5832766e-01,  1.2184256e-01,  1.0000000e+00],\n",
            "        [ 1.4626083e-01,  2.1844923e-02,  1.3054026e-02, ...,\n",
            "          3.3289480e-01, -9.6567757e-03,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-4.4198457e-02,  1.2669332e-01,  2.1341521e-01, ...,\n",
            "          7.7863947e-02,  1.5560330e-02,  1.0000000e+00],\n",
            "        [-2.2788124e-01,  1.3059393e-01,  3.4087947e-01, ...,\n",
            "          7.4922368e-02, -1.6448209e-02,  1.0000000e+00],\n",
            "        [-2.7630380e-01,  1.0688209e-01,  2.9990616e-01, ...,\n",
            "          5.3462863e-02,  3.6642386e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.0163116 , -0.120873  , -0.03641046, ...,  0.03713342,\n",
            "          0.20421048,  2.        ],\n",
            "        [ 0.13372654, -0.01623204, -0.00949946, ...,  0.23867367,\n",
            "          0.0955365 ,  2.        ],\n",
            "        [ 0.1345786 ,  0.04884605,  0.00595469, ...,  0.31223464,\n",
            "         -0.04947124,  2.        ],\n",
            "        ...,\n",
            "        [ 0.00552623,  0.12535924,  0.14836705, ...,  0.04395315,\n",
            "          0.02594198,  2.        ],\n",
            "        [-0.20735005,  0.1232936 ,  0.3240161 , ...,  0.05834119,\n",
            "         -0.01395124,  2.        ],\n",
            "        [-0.27612188,  0.0934137 ,  0.29712898, ...,  0.04636434,\n",
            "         -0.00573417,  2.        ]], dtype=float32)\n",
            " array([[ 0.03618673, -0.13331738, -0.09003406, ...,  0.03854427,\n",
            "          0.20579757,  2.        ],\n",
            "        [ 0.23201267, -0.04563585, -0.0890477 , ...,  0.2308043 ,\n",
            "          0.04848106,  2.        ],\n",
            "        [ 0.2043234 , -0.00742076, -0.08249351, ...,  0.31133866,\n",
            "         -0.0919041 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.19874726, -0.00289035, -0.00209471, ...,  0.07165728,\n",
            "          0.04880456,  2.        ],\n",
            "        [-0.0360458 ,  0.05534249,  0.21469446, ...,  0.12128417,\n",
            "         -0.02035928,  2.        ],\n",
            "        [-0.22904208,  0.053097  ,  0.26775628, ...,  0.09553064,\n",
            "         -0.00752706,  2.        ]], dtype=float32)\n",
            " array([[-2.25603655e-02, -1.31659657e-01, -2.68965419e-02, ...,\n",
            "          4.30188440e-02,  2.08546668e-01,  2.00000000e+00],\n",
            "        [ 1.37783542e-01, -4.13436666e-02, -5.80612151e-03, ...,\n",
            "          2.49895319e-01,  1.28916427e-01,  2.00000000e+00],\n",
            "        [ 1.23899244e-01,  3.55131296e-03,  1.54362451e-02, ...,\n",
            "          3.32112253e-01,  4.86704893e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.07932590e-01,  1.31831393e-01,  2.31642917e-01, ...,\n",
            "          7.12711215e-02, -1.95370032e-03,  2.00000000e+00],\n",
            "        [-2.50750482e-01,  1.18463188e-01,  3.27359676e-01, ...,\n",
            "          5.70744760e-02, -3.09756342e-02,  2.00000000e+00],\n",
            "        [-2.96982616e-01,  9.24646035e-02,  2.96728492e-01, ...,\n",
            "          4.67781648e-02, -1.58749837e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.27658860e-02, -1.34133026e-01, -2.45213602e-02, ...,\n",
            "          4.57474589e-02,  2.09300503e-01,  2.00000000e+00],\n",
            "        [ 1.37202203e-01, -4.58938628e-02, -4.76385700e-03, ...,\n",
            "          2.57615566e-01,  1.31516501e-01,  2.00000000e+00],\n",
            "        [ 1.23884305e-01,  1.25867038e-04,  1.51059199e-02, ...,\n",
            "          3.41836095e-01,  1.09787676e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.06121831e-01,  1.27257034e-01,  2.39174575e-01, ...,\n",
            "          7.85214081e-02,  1.80380302e-03,  2.00000000e+00],\n",
            "        [-2.49770284e-01,  1.16616644e-01,  3.30259502e-01, ...,\n",
            "          6.53640777e-02, -2.94465609e-02,  2.00000000e+00],\n",
            "        [-2.97904253e-01,  8.91167521e-02,  2.98672229e-01, ...,\n",
            "          5.00046648e-02, -1.39569212e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02110778, -0.12878668, -0.03208622, ...,  0.04895047,\n",
            "          0.21603024,  2.        ],\n",
            "        [ 0.14056082, -0.03251731, -0.01055853, ...,  0.24278192,\n",
            "          0.12451281,  2.        ],\n",
            "        [ 0.13750648,  0.03166188,  0.00972135, ...,  0.3182082 ,\n",
            "         -0.02262949,  2.        ],\n",
            "        ...,\n",
            "        [-0.04813776,  0.14385866,  0.20104223, ...,  0.04682961,\n",
            "          0.01238929,  2.        ],\n",
            "        [-0.23327933,  0.13968042,  0.33070648, ...,  0.05602377,\n",
            "         -0.01758208,  2.        ],\n",
            "        [-0.27793068,  0.10590541,  0.29781303, ...,  0.06687072,\n",
            "          0.00456118,  2.        ]], dtype=float32)\n",
            " array([[-0.03237474, -0.12667489, -0.03101867, ...,  0.05458902,\n",
            "          0.20792747,  2.        ],\n",
            "        [ 0.14167142, -0.054529  , -0.03359394, ...,  0.26173216,\n",
            "          0.13964662,  2.        ],\n",
            "        [ 0.1199313 , -0.02709318, -0.02298842, ...,  0.35538226,\n",
            "          0.02612228,  2.        ],\n",
            "        ...,\n",
            "        [-0.13108963,  0.0942489 ,  0.2297157 , ...,  0.08399789,\n",
            "          0.00548005,  2.        ],\n",
            "        [-0.25405797,  0.08298113,  0.29714313, ...,  0.06414315,\n",
            "         -0.03265071,  2.        ],\n",
            "        [-0.3023427 ,  0.08113781,  0.28609776, ...,  0.04216471,\n",
            "         -0.01902958,  2.        ]], dtype=float32)\n",
            " array([[-1.9021211e-02, -1.2923376e-01, -2.7758436e-02, ...,\n",
            "          3.7908509e-02,  2.0823276e-01,  2.0000000e+00],\n",
            "        [ 1.3137007e-01, -2.6107261e-02, -3.2612131e-04, ...,\n",
            "          2.4896051e-01,  1.1185056e-01,  2.0000000e+00],\n",
            "        [ 1.3286164e-01,  3.9283082e-02,  2.0127535e-02, ...,\n",
            "          3.2355437e-01, -2.1107072e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-2.6037592e-02,  1.2898578e-01,  1.8876943e-01, ...,\n",
            "          6.1093256e-02,  2.5849866e-02,  2.0000000e+00],\n",
            "        [-2.2116481e-01,  1.2435863e-01,  3.3564767e-01, ...,\n",
            "          6.0196634e-02, -1.1307572e-02,  2.0000000e+00],\n",
            "        [-2.8065720e-01,  9.7209774e-02,  3.0026135e-01, ...,\n",
            "          5.0230898e-02, -7.4003427e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01709747, -0.12321088, -0.03531668, ...,  0.05020972,\n",
            "          0.2166379 ,  2.        ],\n",
            "        [ 0.14157511, -0.03226892, -0.01321817, ...,  0.24065152,\n",
            "          0.127208  ,  2.        ],\n",
            "        [ 0.13503394,  0.03365349,  0.01062424, ...,  0.3174746 ,\n",
            "         -0.02553911,  2.        ],\n",
            "        ...,\n",
            "        [-0.02960104,  0.14540261,  0.18799663, ...,  0.04518314,\n",
            "          0.02973875,  2.        ],\n",
            "        [-0.21977462,  0.14279357,  0.32258222, ...,  0.06029118,\n",
            "         -0.00621358,  2.        ],\n",
            "        [-0.27169028,  0.110273  ,  0.29398516, ...,  0.06938094,\n",
            "          0.00703427,  2.        ]], dtype=float32)\n",
            " array([[ 0.02896943, -0.12500235, -0.08587939, ...,  0.0250567 ,\n",
            "          0.20242688,  2.        ],\n",
            "        [ 0.21744224, -0.01447252, -0.07496443, ...,  0.2076353 ,\n",
            "          0.05325966,  2.        ],\n",
            "        [ 0.20755492,  0.02168025, -0.07093003, ...,  0.2858959 ,\n",
            "         -0.08817372,  2.        ],\n",
            "        ...,\n",
            "        [ 0.15810056,  0.01058365, -0.0391488 , ...,  0.04508584,\n",
            "          0.06877274,  2.        ],\n",
            "        [-0.07502406,  0.09102655,  0.23551469, ...,  0.09650861,\n",
            "         -0.01643426,  2.        ],\n",
            "        [-0.2501294 ,  0.07398054,  0.2822261 , ...,  0.08212439,\n",
            "         -0.00659996,  2.        ]], dtype=float32)\n",
            " array([[-0.01893533, -0.12321585, -0.03163066, ...,  0.03864685,\n",
            "          0.20698449,  2.        ],\n",
            "        [ 0.13077922, -0.02381088, -0.0054551 , ...,  0.24256335,\n",
            "          0.11008137,  2.        ],\n",
            "        [ 0.12834637,  0.04028173,  0.01314178, ...,  0.31824934,\n",
            "         -0.03053631,  2.        ],\n",
            "        ...,\n",
            "        [-0.02259835,  0.12990756,  0.18336596, ...,  0.05379957,\n",
            "          0.01936286,  2.        ],\n",
            "        [-0.2243165 ,  0.12508507,  0.3377074 , ...,  0.05689589,\n",
            "         -0.0147417 ,  2.        ],\n",
            "        [-0.28356284,  0.09453934,  0.30172464, ...,  0.04601872,\n",
            "         -0.00507573,  2.        ]], dtype=float32)\n",
            " array([[ 0.01316554, -0.12497742, -0.06388889, ...,  0.05864139,\n",
            "          0.2123518 ,  2.        ],\n",
            "        [ 0.19927303, -0.05211253, -0.07444704, ...,  0.23638028,\n",
            "          0.06475019,  2.        ],\n",
            "        [ 0.16620086, -0.01765813, -0.06638783, ...,  0.33006808,\n",
            "         -0.0789287 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.15727632,  0.03523066,  0.07013406, ...,  0.05462203,\n",
            "          0.01068464,  2.        ],\n",
            "        [-0.07504775,  0.07662337,  0.26285452, ...,  0.09818465,\n",
            "         -0.04310559,  2.        ],\n",
            "        [-0.22653584,  0.07441754,  0.2791244 , ...,  0.08516076,\n",
            "         -0.00552511,  2.        ]], dtype=float32)\n",
            " array([[-1.13181779e-02, -1.18677855e-01, -4.02372926e-02, ...,\n",
            "          5.34548685e-02,  2.19679877e-01,  2.00000000e+00],\n",
            "        [ 1.31097808e-01, -3.07193771e-02, -1.40107116e-02, ...,\n",
            "          2.11089954e-01,  1.35365739e-01,  2.00000000e+00],\n",
            "        [ 1.18369944e-01,  3.02461740e-02,  3.56259709e-03, ...,\n",
            "          2.96847761e-01, -2.88651288e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-2.87482347e-02,  1.61326736e-01,  1.85302719e-01, ...,\n",
            "          2.96225194e-02,  3.33471373e-02,  2.00000000e+00],\n",
            "        [-2.17122212e-01,  1.54885143e-01,  3.26846272e-01, ...,\n",
            "          5.16045950e-02,  1.27559516e-03,  2.00000000e+00],\n",
            "        [-2.66416728e-01,  1.07714310e-01,  2.96875477e-01, ...,\n",
            "          7.02023134e-02,  4.89980541e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01271082, -0.12156627, -0.0310789 , ...,  0.04379483,\n",
            "          0.20889315,  2.        ],\n",
            "        [ 0.15441768, -0.02103423, -0.009148  , ...,  0.2594796 ,\n",
            "          0.11218333,  2.        ],\n",
            "        [ 0.15891449,  0.04656251,  0.00464775, ...,  0.3298042 ,\n",
            "         -0.03256104,  2.        ],\n",
            "        ...,\n",
            "        [ 0.00729821,  0.12420505,  0.16605292, ...,  0.0684146 ,\n",
            "          0.03360057,  2.        ],\n",
            "        [-0.20208971,  0.12771018,  0.3278173 , ...,  0.07769917,\n",
            "         -0.00380297,  2.        ],\n",
            "        [-0.2620186 ,  0.10963   ,  0.29451087, ...,  0.05639404,\n",
            "          0.00656078,  2.        ]], dtype=float32)\n",
            " array([[-0.03322762, -0.13662688, -0.03760391, ...,  0.05783623,\n",
            "          0.21104024,  2.        ],\n",
            "        [ 0.14550538, -0.06808735, -0.05585315, ...,  0.2839864 ,\n",
            "          0.14449778,  2.        ],\n",
            "        [ 0.1158264 , -0.0514258 , -0.05867286, ...,  0.37618715,\n",
            "          0.0388146 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.12475187,  0.05448135,  0.20639586, ...,  0.10376165,\n",
            "          0.015029  ,  2.        ],\n",
            "        [-0.24123886,  0.05361287,  0.26819834, ...,  0.07924215,\n",
            "         -0.02966674,  2.        ],\n",
            "        [-0.29359153,  0.05848968,  0.27114657, ...,  0.04450746,\n",
            "         -0.01799116,  2.        ]], dtype=float32)\n",
            " array([[-0.02995788, -0.1512596 , -0.03716065, ...,  0.06100526,\n",
            "          0.21277727,  2.        ],\n",
            "        [ 0.17793585, -0.08073269, -0.04902349, ...,  0.28668946,\n",
            "          0.15203112,  2.        ],\n",
            "        [ 0.13628407, -0.06301911, -0.04315894, ...,  0.37961015,\n",
            "          0.0520674 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.11425708,  0.05277742,  0.20062523, ...,  0.09602853,\n",
            "          0.01049791,  2.        ],\n",
            "        [-0.23288526,  0.05345034,  0.25197083, ...,  0.07943644,\n",
            "         -0.03516779,  2.        ],\n",
            "        [-0.27584946,  0.05680097,  0.2587431 , ...,  0.04725881,\n",
            "         -0.01593215,  2.        ]], dtype=float32)\n",
            " array([[-1.9413531e-02, -1.4072677e-01, -3.5082396e-02, ...,\n",
            "          5.9848044e-02,  2.1916296e-01,  2.0000000e+00],\n",
            "        [ 1.5785328e-01, -4.3787200e-02, -1.6448192e-02, ...,\n",
            "          2.6331231e-01,  1.4113355e-01,  2.0000000e+00],\n",
            "        [ 1.5154551e-01,  1.1738909e-03,  6.7312238e-03, ...,\n",
            "          3.4524211e-01,  6.0516135e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-5.0785292e-02,  1.3751391e-01,  1.8168916e-01, ...,\n",
            "          4.9754400e-02,  1.8640816e-02,  2.0000000e+00],\n",
            "        [-2.1172805e-01,  1.2432895e-01,  2.8826836e-01, ...,\n",
            "          5.7693731e-02, -1.6036324e-02,  2.0000000e+00],\n",
            "        [-2.6769114e-01,  1.0080070e-01,  2.7464548e-01, ...,\n",
            "          7.1708247e-02,  1.0295863e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02060344, -0.13269417, -0.02865467, ...,  0.04396624,\n",
            "          0.2095229 ,  2.        ],\n",
            "        [ 0.1411847 , -0.0410035 , -0.00639481, ...,  0.2558081 ,\n",
            "          0.12755622,  2.        ],\n",
            "        [ 0.13540816,  0.00972812,  0.01339244, ...,  0.33674714,\n",
            "         -0.00285519,  2.        ],\n",
            "        ...,\n",
            "        [-0.07806261,  0.12977038,  0.22334108, ...,  0.08348747,\n",
            "          0.00352092,  2.        ],\n",
            "        [-0.24118596,  0.12237612,  0.33461556, ...,  0.06968496,\n",
            "         -0.02519758,  2.        ],\n",
            "        [-0.28950784,  0.09381961,  0.2960283 , ...,  0.05430537,\n",
            "         -0.01012367,  2.        ]], dtype=float32)\n",
            " array([[-3.4145094e-03, -1.2167451e-01, -4.7680233e-02, ...,\n",
            "          6.0639251e-02,  2.1816355e-01,  2.0000000e+00],\n",
            "        [ 1.5121377e-01, -2.3072910e-02, -2.3101661e-02, ...,\n",
            "          2.3383975e-01,  1.2365659e-01,  2.0000000e+00],\n",
            "        [ 1.4249232e-01,  3.9091751e-02, -7.7622682e-03, ...,\n",
            "          3.1642833e-01, -3.7366200e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 3.3381330e-03,  1.5159859e-01,  1.5183248e-01, ...,\n",
            "          4.5813721e-02,  3.2057762e-02,  2.0000000e+00],\n",
            "        [-1.9351174e-01,  1.4528498e-01,  3.0570859e-01, ...,\n",
            "          6.9020562e-02, -7.8032208e-03,  2.0000000e+00],\n",
            "        [-2.5202301e-01,  1.0122797e-01,  2.8371859e-01, ...,\n",
            "          7.6615117e-02,  1.3153922e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01689079, -0.13055812, -0.02648594, ...,  0.04628431,\n",
            "          0.21164498,  1.        ],\n",
            "        [ 0.14870636, -0.03934436, -0.00264476, ...,  0.26376608,\n",
            "          0.12621132,  1.        ],\n",
            "        [ 0.147545  ,  0.01518007,  0.01099353, ...,  0.34310046,\n",
            "         -0.0021672 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.06603411,  0.12515259,  0.22747234, ...,  0.08866294,\n",
            "          0.01038133,  1.        ],\n",
            "        [-0.23352712,  0.1250636 ,  0.33718243, ...,  0.08122372,\n",
            "         -0.0204341 ,  1.        ],\n",
            "        [-0.27883548,  0.10305358,  0.2974715 , ...,  0.05843033,\n",
            "          0.00146889,  1.        ]], dtype=float32)\n",
            " array([[-5.21307345e-03, -1.10098734e-01, -4.56507616e-02, ...,\n",
            "          4.03970741e-02,  2.04835892e-01,  0.00000000e+00],\n",
            "        [ 1.64797828e-01, -5.83928637e-03, -3.32686678e-02, ...,\n",
            "          2.53112048e-01,  7.06502944e-02,  0.00000000e+00],\n",
            "        [ 1.76939145e-01,  5.87203950e-02, -2.81351246e-02, ...,\n",
            "          3.12870622e-01, -7.06075281e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 8.20564851e-02,  8.81267264e-02,  5.35647012e-02, ...,\n",
            "          5.02421819e-02,  6.45162687e-02,  0.00000000e+00],\n",
            "        [-1.52295992e-01,  1.24163456e-01,  3.06767970e-01, ...,\n",
            "          1.03379861e-01, -1.09056782e-04,  0.00000000e+00],\n",
            "        [-2.50943005e-01,  1.04804918e-01,  2.92224020e-01, ...,\n",
            "          6.69917017e-02,  7.42367050e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.0165593 , -0.12993333, -0.02748554, ...,  0.04689191,\n",
            "          0.2114909 ,  2.        ],\n",
            "        [ 0.15160744, -0.03532492, -0.00497742, ...,  0.27008113,\n",
            "          0.12422502,  2.        ],\n",
            "        [ 0.15239275,  0.02252328,  0.00890682, ...,  0.34805092,\n",
            "         -0.00538094,  2.        ],\n",
            "        ...,\n",
            "        [-0.04556847,  0.11979751,  0.20983373, ...,  0.0913634 ,\n",
            "          0.01795984,  2.        ],\n",
            "        [-0.22480734,  0.12363733,  0.33103034, ...,  0.08389971,\n",
            "         -0.01491796,  2.        ],\n",
            "        [-0.2750353 ,  0.10239039,  0.29548004, ...,  0.06084546,\n",
            "          0.00305242,  2.        ]], dtype=float32)\n",
            " array([[-0.02785093, -0.13047689, -0.03140447, ...,  0.06253967,\n",
            "          0.21095368,  1.        ],\n",
            "        [ 0.16767001, -0.05115669, -0.02559949, ...,  0.28101107,\n",
            "          0.14118844,  1.        ],\n",
            "        [ 0.14788005, -0.01268458, -0.00435756, ...,  0.37595758,\n",
            "          0.01613838,  1.        ],\n",
            "        ...,\n",
            "        [-0.11834661,  0.11235137,  0.23219799, ...,  0.08921637,\n",
            "         -0.01007378,  1.        ],\n",
            "        [-0.24534364,  0.10157084,  0.2894478 , ...,  0.0798998 ,\n",
            "         -0.03517734,  1.        ],\n",
            "        [-0.28517613,  0.09082858,  0.27841   , ...,  0.06058622,\n",
            "         -0.00928741,  1.        ]], dtype=float32)\n",
            " array([[-0.03369351, -0.12997185, -0.03193486, ...,  0.06614373,\n",
            "          0.21209721,  1.        ],\n",
            "        [ 0.16423677, -0.05057324, -0.03024264, ...,  0.27483174,\n",
            "          0.14303657,  1.        ],\n",
            "        [ 0.13742463, -0.01939011, -0.0096274 , ...,  0.36681104,\n",
            "          0.032707  ,  1.        ],\n",
            "        ...,\n",
            "        [-0.14253527,  0.10846308,  0.24675296, ...,  0.07867935,\n",
            "         -0.01596371,  1.        ],\n",
            "        [-0.25802657,  0.09334178,  0.2913377 , ...,  0.07306611,\n",
            "         -0.04012088,  1.        ],\n",
            "        [-0.286614  ,  0.08862281,  0.27768475, ...,  0.05144254,\n",
            "         -0.01044509,  1.        ]], dtype=float32)\n",
            " array([[-0.03425734, -0.1550526 , -0.05182698, ...,  0.06683262,\n",
            "          0.2111723 ,  1.        ],\n",
            "        [ 0.16351433, -0.10831609, -0.06094582, ...,  0.30584767,\n",
            "          0.16566141,  1.        ],\n",
            "        [ 0.10888485, -0.10118258, -0.06026407, ...,  0.41152522,\n",
            "          0.07650483,  1.        ],\n",
            "        ...,\n",
            "        [-0.1695212 ,  0.03253163,  0.20910366, ...,  0.10721986,\n",
            "         -0.01974117,  1.        ],\n",
            "        [-0.25126046,  0.05331756,  0.2123532 , ...,  0.0891807 ,\n",
            "         -0.05014442,  1.        ],\n",
            "        [-0.2629712 ,  0.03390362,  0.23757066, ...,  0.03634107,\n",
            "         -0.02489718,  1.        ]], dtype=float32)\n",
            " array([[-0.02919985, -0.15321347, -0.05857433, ...,  0.05332206,\n",
            "          0.188496  ,  1.        ],\n",
            "        [ 0.09906989, -0.12728615, -0.06258538, ...,  0.2390439 ,\n",
            "          0.14539786,  1.        ],\n",
            "        [ 0.03125427, -0.12708643, -0.0772137 , ...,  0.33586988,\n",
            "          0.08444639,  1.        ],\n",
            "        ...,\n",
            "        [-0.23863687,  0.0591001 ,  0.21851812, ..., -0.00566128,\n",
            "         -0.08775006,  1.        ],\n",
            "        [-0.26985607,  0.07518084,  0.22466342, ...,  0.00176017,\n",
            "         -0.08128721,  1.        ],\n",
            "        [-0.2310284 ,  0.0389572 ,  0.24504519, ..., -0.01892592,\n",
            "         -0.05549843,  1.        ]], dtype=float32)\n",
            " array([[-0.03311662, -0.15671016, -0.05303816, ...,  0.06779441,\n",
            "          0.21191941,  1.        ],\n",
            "        [ 0.17174272, -0.10658637, -0.06286813, ...,  0.3148384 ,\n",
            "          0.16502215,  1.        ],\n",
            "        [ 0.11591683, -0.10169826, -0.06181872, ...,  0.42241487,\n",
            "          0.07927448,  1.        ],\n",
            "        ...,\n",
            "        [-0.15702184,  0.01674745,  0.20008567, ...,  0.10623779,\n",
            "         -0.02432294,  1.        ],\n",
            "        [-0.23228037,  0.03978052,  0.20111103, ...,  0.08787309,\n",
            "         -0.04766469,  1.        ],\n",
            "        [-0.25338995,  0.02436798,  0.23063289, ...,  0.03592379,\n",
            "         -0.02175262,  1.        ]], dtype=float32)\n",
            " array([[-0.02742982, -0.12977888, -0.0244744 , ...,  0.04163108,\n",
            "          0.20780471,  1.        ],\n",
            "        [ 0.12351288, -0.05055071, -0.00315868, ...,  0.23773757,\n",
            "          0.13278636,  1.        ],\n",
            "        [ 0.1069781 , -0.00969852,  0.0175971 , ...,  0.32142165,\n",
            "          0.01204104,  1.        ],\n",
            "        ...,\n",
            "        [-0.14126813,  0.13638589,  0.26333442, ...,  0.06639637,\n",
            "         -0.00381441,  1.        ],\n",
            "        [-0.26456526,  0.12559687,  0.3408127 , ...,  0.05306748,\n",
            "         -0.03718717,  1.        ],\n",
            "        [-0.3062458 ,  0.09234308,  0.30448806, ...,  0.03947905,\n",
            "         -0.01970178,  1.        ]], dtype=float32)\n",
            " array([[-0.02985744, -0.1538935 , -0.04480312, ...,  0.05190295,\n",
            "          0.21122557,  1.        ],\n",
            "        [ 0.14621778, -0.09360787, -0.06656948, ...,  0.27801776,\n",
            "          0.14917453,  1.        ],\n",
            "        [ 0.1049056 , -0.08455042, -0.07468644, ...,  0.36891428,\n",
            "          0.05268739,  1.        ],\n",
            "        ...,\n",
            "        [-0.12115301,  0.02112741,  0.18954204, ...,  0.10178988,\n",
            "          0.0291271 ,  1.        ],\n",
            "        [-0.22233778,  0.01956934,  0.24529985, ...,  0.07509661,\n",
            "         -0.0181682 ,  1.        ],\n",
            "        [-0.27716166,  0.02495602,  0.2560341 , ...,  0.03523659,\n",
            "         -0.01919959,  1.        ]], dtype=float32)\n",
            " array([[-0.03356726, -0.14359558, -0.03829879, ...,  0.05268684,\n",
            "          0.213615  ,  1.        ],\n",
            "        [ 0.14435694, -0.08055844, -0.05514506, ...,  0.27113858,\n",
            "          0.15781954,  1.        ],\n",
            "        [ 0.10188622, -0.0693067 , -0.05730677, ...,  0.36592323,\n",
            "          0.0634212 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.14731349,  0.05432905,  0.22179101, ...,  0.09881724,\n",
            "          0.02273854,  1.        ],\n",
            "        [-0.25481376,  0.04870837,  0.27650297, ...,  0.07563756,\n",
            "         -0.02956372,  1.        ],\n",
            "        [-0.30164728,  0.04804948,  0.27744576, ...,  0.03220261,\n",
            "         -0.02013901,  1.        ]], dtype=float32)\n",
            " array([[-0.02307515, -0.12807971, -0.0283715 , ...,  0.0538373 ,\n",
            "          0.21671395,  1.        ],\n",
            "        [ 0.14557791, -0.03862249, -0.0062051 , ...,  0.25744757,\n",
            "          0.13316375,  1.        ],\n",
            "        [ 0.14228643,  0.01945553,  0.01414398, ...,  0.335906  ,\n",
            "         -0.00715526,  1.        ],\n",
            "        ...,\n",
            "        [-0.0870638 ,  0.14182016,  0.23894213, ...,  0.06548604,\n",
            "          0.00213928,  1.        ],\n",
            "        [-0.24396263,  0.13633564,  0.33480215, ...,  0.06265268,\n",
            "         -0.02561638,  1.        ],\n",
            "        [-0.28476977,  0.10351855,  0.2991355 , ...,  0.06343844,\n",
            "          0.00282451,  1.        ]], dtype=float32)\n",
            " array([[-0.01944209, -0.11911654, -0.03249545, ...,  0.04748818,\n",
            "          0.2147467 ,  1.        ],\n",
            "        [ 0.12862176, -0.02906787, -0.00810636, ...,  0.23290479,\n",
            "          0.12244047,  1.        ],\n",
            "        [ 0.13086896,  0.03608425,  0.01409116, ...,  0.30596095,\n",
            "         -0.02737612,  1.        ],\n",
            "        ...,\n",
            "        [-0.05426065,  0.13854226,  0.21372505, ...,  0.04396769,\n",
            "          0.01462879,  1.        ],\n",
            "        [-0.2345111 ,  0.13718335,  0.34628963, ...,  0.05221232,\n",
            "         -0.00880241,  1.        ],\n",
            "        [-0.28080666,  0.10467912,  0.30783105, ...,  0.05626001,\n",
            "          0.01004902,  1.        ]], dtype=float32)\n",
            " array([[-2.66961046e-02, -1.65405691e-01, -5.11311293e-02, ...,\n",
            "          5.76186478e-02,  2.11493552e-01,  1.00000000e+00],\n",
            "        [ 1.43816605e-01, -1.13640763e-01, -7.62761086e-02, ...,\n",
            "          2.90333390e-01,  1.52532637e-01,  1.00000000e+00],\n",
            "        [ 9.77578014e-02, -1.10110804e-01, -8.57281312e-02, ...,\n",
            "          3.80917996e-01,  6.63004592e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.13879450e-01,  2.29654764e-03,  1.82448551e-01, ...,\n",
            "          1.07552633e-01,  1.75555795e-02,  1.00000000e+00],\n",
            "        [-2.04398617e-01,  4.81802598e-03,  2.15980396e-01, ...,\n",
            "          7.99287260e-02, -2.18128543e-02,  1.00000000e+00],\n",
            "        [-2.56302208e-01, -3.13288154e-04,  2.37274155e-01, ...,\n",
            "          3.94131914e-02, -2.38836147e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.01905062, -0.13826454, -0.0306271 , ...,  0.05413401,\n",
            "          0.2136279 ,  1.        ],\n",
            "        [ 0.15917967, -0.05160293, -0.02036033, ...,  0.28668895,\n",
            "          0.13608642,  1.        ],\n",
            "        [ 0.146336  , -0.01627452, -0.01490327, ...,  0.3738004 ,\n",
            "          0.0250689 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.09062319,  0.10034191,  0.21263523, ...,  0.10297871,\n",
            "          0.00572071,  1.        ],\n",
            "        [-0.22744338,  0.09450189,  0.29365632, ...,  0.0870024 ,\n",
            "         -0.02379191,  1.        ],\n",
            "        [-0.27771726,  0.08880963,  0.2813746 , ...,  0.06199351,\n",
            "         -0.00327096,  1.        ]], dtype=float32)\n",
            " array([[-1.65232625e-02, -1.32216305e-01, -2.73948107e-02, ...,\n",
            "          4.79815900e-02,  2.11172223e-01,  1.00000000e+00],\n",
            "        [ 1.53474867e-01, -3.99287529e-02, -4.41118563e-03, ...,\n",
            "          2.71434069e-01,  1.27386615e-01,  1.00000000e+00],\n",
            "        [ 1.51784852e-01,  1.17389141e-02,  8.49295128e-03, ...,\n",
            "          3.50862652e-01,  2.53528869e-03,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-6.76500201e-02,  1.23567402e-01,  2.23214284e-01, ...,\n",
            "          9.49734598e-02,  8.30406789e-03,  1.00000000e+00],\n",
            "        [-2.29891270e-01,  1.22572571e-01,  3.29089195e-01, ...,\n",
            "          8.31373110e-02, -2.26782560e-02,  1.00000000e+00],\n",
            "        [-2.76870728e-01,  1.01969056e-01,  2.94929504e-01, ...,\n",
            "          5.93762733e-02, -8.48595009e-05,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.0349558 , -0.13994732, -0.03701025, ...,  0.056892  ,\n",
            "          0.21296811,  1.        ],\n",
            "        [ 0.15240969, -0.06549003, -0.04085524, ...,  0.26745206,\n",
            "          0.14803913,  1.        ],\n",
            "        [ 0.1202508 , -0.04404005, -0.03248837, ...,  0.3541755 ,\n",
            "          0.04017897,  1.        ],\n",
            "        ...,\n",
            "        [-0.13977066,  0.07594635,  0.22811751, ...,  0.08043326,\n",
            "          0.00750606,  1.        ],\n",
            "        [-0.25786415,  0.06441204,  0.2804307 , ...,  0.06611612,\n",
            "         -0.03683887,  1.        ],\n",
            "        [-0.29200298,  0.07144496,  0.2743815 , ...,  0.04269158,\n",
            "         -0.01370497,  1.        ]], dtype=float32)\n",
            " array([[-3.3328377e-02, -1.5625581e-01, -5.9977535e-02, ...,\n",
            "          5.7159089e-02,  1.9439226e-01,  1.0000000e+00],\n",
            "        [ 1.0895038e-01, -1.2956758e-01, -6.8534620e-02, ...,\n",
            "          2.5934067e-01,  1.4804503e-01,  1.0000000e+00],\n",
            "        [ 4.3155748e-02, -1.2529996e-01, -7.9347402e-02, ...,\n",
            "          3.5849354e-01,  7.8262836e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-2.2391993e-01,  4.4601303e-02,  1.9500031e-01, ...,\n",
            "          3.5660520e-02, -7.9434812e-02,  1.0000000e+00],\n",
            "        [-2.6788437e-01,  6.4106911e-02,  2.0859616e-01, ...,\n",
            "          4.1395575e-02, -7.9674847e-02,  1.0000000e+00],\n",
            "        [-2.4928942e-01,  2.5005130e-02,  2.3824285e-01, ...,\n",
            "          9.5190881e-05, -5.0960965e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.00950694, -0.12748598, -0.0427044 , ...,  0.05597021,\n",
            "          0.21690679,  1.        ],\n",
            "        [ 0.152788  , -0.02275597, -0.01981901, ...,  0.24877718,\n",
            "          0.1197883 ,  1.        ],\n",
            "        [ 0.1564152 ,  0.04385666, -0.00735243, ...,  0.32623222,\n",
            "         -0.0351724 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.01054921,  0.1456196 ,  0.16743936, ...,  0.05145525,\n",
            "          0.01987988,  1.        ],\n",
            "        [-0.19856839,  0.14938611,  0.30889714, ...,  0.06384915,\n",
            "         -0.01215676,  1.        ],\n",
            "        [-0.26005787,  0.10809923,  0.2896407 , ...,  0.07289027,\n",
            "          0.00488184,  1.        ]], dtype=float32)\n",
            " array([[-0.03461648, -0.15468098, -0.05850868, ...,  0.061679  ,\n",
            "          0.20431195,  1.        ],\n",
            "        [ 0.12478136, -0.12000906, -0.07034819, ...,  0.278869  ,\n",
            "          0.1564056 ,  1.        ],\n",
            "        [ 0.06122292, -0.11649093, -0.0757074 , ...,  0.38417935,\n",
            "          0.08149802,  1.        ],\n",
            "        ...,\n",
            "        [-0.20912036,  0.03833066,  0.19805667, ...,  0.08979018,\n",
            "         -0.06073476,  1.        ],\n",
            "        [-0.26513463,  0.05177025,  0.19934645, ...,  0.07620249,\n",
            "         -0.07828113,  1.        ],\n",
            "        [-0.2651734 ,  0.02040601,  0.23486745, ...,  0.02140173,\n",
            "         -0.04558249,  1.        ]], dtype=float32)\n",
            " array([[-0.03135217, -0.15538514, -0.04787717, ...,  0.06286512,\n",
            "          0.21421197,  1.        ],\n",
            "        [ 0.17138708, -0.09281985, -0.06037733, ...,  0.2918374 ,\n",
            "          0.16021536,  1.        ],\n",
            "        [ 0.12310872, -0.09025231, -0.05826582, ...,  0.39270452,\n",
            "          0.0658422 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.14222066,  0.01745741,  0.20957784, ...,  0.09026897,\n",
            "         -0.00947594,  1.        ],\n",
            "        [-0.23508148,  0.03487102,  0.22233568, ...,  0.07778122,\n",
            "         -0.04125847,  1.        ],\n",
            "        [-0.2623621 ,  0.03361533,  0.24334785, ...,  0.03958853,\n",
            "         -0.01768341,  1.        ]], dtype=float32)\n",
            " array([[-0.01461086, -0.12219807, -0.04546318, ...,  0.05200389,\n",
            "          0.21176495,  1.        ],\n",
            "        [ 0.15175961, -0.00200064, -0.02232659, ...,  0.25010663,\n",
            "          0.10411764,  1.        ],\n",
            "        [ 0.16088912,  0.05809002, -0.00909252, ...,  0.3219822 ,\n",
            "         -0.04854963,  1.        ],\n",
            "        ...,\n",
            "        [ 0.01361189,  0.13290101,  0.13702403, ...,  0.05117431,\n",
            "          0.01059952,  1.        ],\n",
            "        [-0.19386445,  0.13947088,  0.30587804, ...,  0.06807405,\n",
            "         -0.01747612,  1.        ],\n",
            "        [-0.2591867 ,  0.10696064,  0.28773028, ...,  0.07110409,\n",
            "          0.00962614,  1.        ]], dtype=float32)\n",
            " array([[-2.1026121e-02, -1.3103032e-01, -2.8166601e-02, ...,\n",
            "          5.0616976e-02,  2.1747720e-01,  1.0000000e+00],\n",
            "        [ 1.4528707e-01, -4.0043242e-02, -9.2391996e-03, ...,\n",
            "          2.5472960e-01,  1.3721049e-01,  1.0000000e+00],\n",
            "        [ 1.3975371e-01,  1.2278179e-02,  1.6939554e-02, ...,\n",
            "          3.3400062e-01, -2.6381145e-05,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-7.6459855e-02,  1.3615617e-01,  2.2697221e-01, ...,\n",
            "          6.3196704e-02,  3.0260698e-03,  1.0000000e+00],\n",
            "        [-2.3608245e-01,  1.3349456e-01,  3.2722998e-01, ...,\n",
            "          6.2307507e-02, -2.5806053e-02,  1.0000000e+00],\n",
            "        [-2.8561041e-01,  9.8338380e-02,  2.9817167e-01, ...,\n",
            "          6.0455471e-02, -3.0897681e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.03590215, -0.15209131, -0.04616095, ...,  0.05551583,\n",
            "          0.21343012,  1.        ],\n",
            "        [ 0.14442067, -0.09469505, -0.06962399, ...,  0.29052433,\n",
            "          0.15638843,  1.        ],\n",
            "        [ 0.10103837, -0.09826997, -0.07563081, ...,  0.3786867 ,\n",
            "          0.08274521,  1.        ],\n",
            "        ...,\n",
            "        [-0.15384841,  0.02278051,  0.21277197, ...,  0.10364793,\n",
            "          0.0071427 ,  1.        ],\n",
            "        [-0.24387975,  0.02073051,  0.24173568, ...,  0.08095131,\n",
            "         -0.03246641,  1.        ],\n",
            "        [-0.28597152,  0.02196159,  0.25743264, ...,  0.03394723,\n",
            "         -0.02410006,  1.        ]], dtype=float32)\n",
            " array([[-3.33852135e-03, -1.15778483e-01, -4.74837609e-02, ...,\n",
            "          4.45071608e-02,  2.14429632e-01,  1.00000000e+00],\n",
            "        [ 1.44624740e-01, -1.42310765e-02, -2.58588158e-02, ...,\n",
            "          2.20551863e-01,  1.17450334e-01,  1.00000000e+00],\n",
            "        [ 1.50341377e-01,  4.70620207e-02, -8.88065249e-03, ...,\n",
            "          3.01016718e-01, -4.47448865e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.09520571e-02,  1.26374215e-01,  1.19132727e-01, ...,\n",
            "          3.69905978e-02,  4.14547436e-02,  1.00000000e+00],\n",
            "        [-1.84044898e-01,  1.43377990e-01,  3.01854312e-01, ...,\n",
            "          6.26306161e-02,  7.54818728e-04,  1.00000000e+00],\n",
            "        [-2.58963346e-01,  9.98300016e-02,  2.90714443e-01, ...,\n",
            "          6.62344322e-02,  2.72021163e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.02419298, -0.13035142, -0.02585465, ...,  0.04476782,\n",
            "          0.20999461,  1.        ],\n",
            "        [ 0.13286705, -0.04271316, -0.00513376, ...,  0.2548666 ,\n",
            "          0.1314402 ,  1.        ],\n",
            "        [ 0.12181895,  0.00652129,  0.01732065, ...,  0.33756092,\n",
            "          0.00562041,  1.        ],\n",
            "        ...,\n",
            "        [-0.10658393,  0.13298899,  0.24261715, ...,  0.07869069,\n",
            "         -0.00139316,  1.        ],\n",
            "        [-0.2518026 ,  0.12462718,  0.337341  , ...,  0.06418112,\n",
            "         -0.02969423,  1.        ],\n",
            "        [-0.3009743 ,  0.09218032,  0.30070874, ...,  0.05079202,\n",
            "         -0.01282852,  1.        ]], dtype=float32)\n",
            " array([[-0.03238541, -0.12967198, -0.03202756, ...,  0.06022902,\n",
            "          0.21270457,  1.        ],\n",
            "        [ 0.1504074 , -0.05382968, -0.02854712, ...,  0.25335756,\n",
            "          0.15380271,  1.        ],\n",
            "        [ 0.12193592, -0.02748324, -0.00926746, ...,  0.34636548,\n",
            "          0.04355088,  1.        ],\n",
            "        ...,\n",
            "        [-0.14492576,  0.11174309,  0.2424358 , ...,  0.06404389,\n",
            "         -0.00452153,  1.        ],\n",
            "        [-0.26396927,  0.08959006,  0.29985487, ...,  0.05773275,\n",
            "         -0.03827542,  1.        ],\n",
            "        [-0.2941182 ,  0.08096813,  0.27998146, ...,  0.04711724,\n",
            "         -0.01331865,  1.        ]], dtype=float32)\n",
            " array([[-1.50706768e-02, -1.22816958e-01, -4.01682295e-02, ...,\n",
            "          5.27929589e-02,  2.12520763e-01,  1.00000000e+00],\n",
            "        [ 1.54995874e-01, -7.51417596e-03, -1.46032618e-02, ...,\n",
            "          2.53675014e-01,  1.07213534e-01,  1.00000000e+00],\n",
            "        [ 1.62144318e-01,  6.00107238e-02, -3.10240983e-04, ...,\n",
            "          3.22599232e-01, -4.62166965e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-9.36184544e-03,  1.36988655e-01,  1.66254133e-01, ...,\n",
            "          5.11060879e-02,  1.31606357e-02,  1.00000000e+00],\n",
            "        [-2.05085635e-01,  1.40083686e-01,  3.13279957e-01, ...,\n",
            "          6.52530491e-02, -1.73724331e-02,  1.00000000e+00],\n",
            "        [-2.64551997e-01,  1.10289201e-01,  2.87976027e-01, ...,\n",
            "          7.25780204e-02,  1.06733516e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.03647119, -0.15691712, -0.05882998, ...,  0.06501878,\n",
            "          0.20149983,  1.        ],\n",
            "        [ 0.11903236, -0.12458274, -0.07019067, ...,  0.292892  ,\n",
            "          0.14885715,  1.        ],\n",
            "        [ 0.05362314, -0.1198422 , -0.07853846, ...,  0.3925827 ,\n",
            "          0.07929996,  1.        ],\n",
            "        ...,\n",
            "        [-0.21109787,  0.03992487,  0.1958616 , ...,  0.08657615,\n",
            "         -0.07547925,  1.        ],\n",
            "        [-0.2577429 ,  0.0522963 ,  0.19299836, ...,  0.07408333,\n",
            "         -0.08198024,  1.        ],\n",
            "        [-0.25591996,  0.02385133,  0.22902034, ...,  0.01996258,\n",
            "         -0.04479473,  1.        ]], dtype=float32)\n",
            " array([[-1.6255951e-02, -1.2160563e-01, -3.7983719e-02, ...,\n",
            "          3.8553838e-02,  2.0469695e-01,  1.0000000e+00],\n",
            "        [ 1.3729034e-01, -1.2841692e-02, -1.4170356e-02, ...,\n",
            "          2.4339692e-01,  9.4996192e-02,  1.0000000e+00],\n",
            "        [ 1.3982239e-01,  4.9073111e-02, -3.8791410e-04, ...,\n",
            "          3.1733158e-01, -4.5886494e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [ 7.3175519e-03,  1.2900834e-01,  1.4277178e-01, ...,\n",
            "          4.8720263e-02,  2.6580568e-02,  1.0000000e+00],\n",
            "        [-2.0645496e-01,  1.2010124e-01,  3.2378989e-01, ...,\n",
            "          6.4576782e-02, -1.5528712e-02,  1.0000000e+00],\n",
            "        [-2.7199820e-01,  9.5134474e-02,  2.9534593e-01, ...,\n",
            "          4.9894940e-02, -6.5186508e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.03515649, -0.15644094, -0.05465568, ...,  0.05846566,\n",
            "          0.21255217,  1.        ],\n",
            "        [ 0.13795327, -0.11073717, -0.0788487 , ...,  0.2972974 ,\n",
            "          0.15552251,  1.        ],\n",
            "        [ 0.08708223, -0.11305615, -0.0859467 , ...,  0.39449123,\n",
            "          0.07863779,  1.        ],\n",
            "        ...,\n",
            "        [-0.1422642 ,  0.0100184 ,  0.19686419, ...,  0.11287689,\n",
            "         -0.00395526,  1.        ],\n",
            "        [-0.22813411,  0.01861142,  0.21102928, ...,  0.09049167,\n",
            "         -0.04222427,  1.        ],\n",
            "        [-0.27104488,  0.00249507,  0.2397967 , ...,  0.03507655,\n",
            "         -0.03128054,  1.        ]], dtype=float32)\n",
            " array([[-0.02080481, -0.133375  , -0.02685499, ...,  0.0443515 ,\n",
            "          0.20907648,  1.        ],\n",
            "        [ 0.14128524, -0.04206533, -0.00612873, ...,  0.25828546,\n",
            "          0.1286722 ,  1.        ],\n",
            "        [ 0.12973303,  0.00778695,  0.01423045, ...,  0.34102675,\n",
            "          0.00454876,  1.        ],\n",
            "        ...,\n",
            "        [-0.09462931,  0.12715912,  0.22368777, ...,  0.07913209,\n",
            "          0.0035164 ,  1.        ],\n",
            "        [-0.24342352,  0.1157564 ,  0.32463682, ...,  0.06471501,\n",
            "         -0.02766356,  1.        ],\n",
            "        [-0.29328114,  0.091351  ,  0.29747292, ...,  0.05123254,\n",
            "         -0.01309738,  1.        ]], dtype=float32)\n",
            " array([[-1.01330923e-02, -1.19206548e-01, -3.34387273e-02, ...,\n",
            "          4.39279601e-02,  2.08608523e-01,  2.00000000e+00],\n",
            "        [ 1.52766511e-01, -1.42204082e-02, -1.27124032e-02, ...,\n",
            "          2.55864739e-01,  1.02696598e-01,  2.00000000e+00],\n",
            "        [ 1.62491232e-01,  5.53175919e-02, -2.40521552e-03, ...,\n",
            "          3.25239033e-01, -4.13950644e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.93332227e-02,  1.18870899e-01,  1.38798296e-01, ...,\n",
            "          5.40671535e-02,  4.14683372e-02,  2.00000000e+00],\n",
            "        [-1.90896630e-01,  1.24268554e-01,  3.24277252e-01, ...,\n",
            "          8.13734233e-02, -1.61194021e-03,  2.00000000e+00],\n",
            "        [-2.55787462e-01,  1.09874293e-01,  2.92672396e-01, ...,\n",
            "          5.63935079e-02,  7.30156945e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.01819520e-02, -1.19057618e-01, -3.08743697e-02, ...,\n",
            "          3.64007503e-02,  2.05101848e-01,  2.00000000e+00],\n",
            "        [ 1.24876410e-01, -2.07620077e-02,  3.05392430e-04, ...,\n",
            "          2.32191056e-01,  1.01715624e-01,  2.00000000e+00],\n",
            "        [ 1.25437841e-01,  4.68202382e-02,  2.03331746e-02, ...,\n",
            "          3.04798305e-01, -4.11274545e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.19535699e-02,  1.31546080e-01,  1.76029503e-01, ...,\n",
            "          3.55233103e-02,  3.21403742e-02,  2.00000000e+00],\n",
            "        [-2.20445231e-01,  1.30582884e-01,  3.42367411e-01, ...,\n",
            "          4.71301712e-02, -9.67218354e-03,  2.00000000e+00],\n",
            "        [-2.86299497e-01,  9.96802747e-02,  3.06852162e-01, ...,\n",
            "          4.24952768e-02, -1.73473323e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.03306458, -0.15574174, -0.05816447, ...,  0.05888721,\n",
            "          0.19233826,  2.        ],\n",
            "        [ 0.11204366, -0.1288932 , -0.0648201 , ...,  0.26006535,\n",
            "          0.14772734,  2.        ],\n",
            "        [ 0.04492518, -0.12457335, -0.07602876, ...,  0.35770586,\n",
            "          0.08329084,  2.        ],\n",
            "        ...,\n",
            "        [-0.24087891,  0.05319867,  0.20402943, ...,  0.03507139,\n",
            "         -0.08647879,  2.        ],\n",
            "        [-0.2758414 ,  0.06819569,  0.21127053, ...,  0.03437596,\n",
            "         -0.08204602,  2.        ],\n",
            "        [-0.24642605,  0.03388897,  0.23867439, ..., -0.00571033,\n",
            "         -0.05050536,  2.        ]], dtype=float32)\n",
            " array([[-0.02043065, -0.12152696, -0.02747405, ...,  0.03647267,\n",
            "          0.20608093,  2.        ],\n",
            "        [ 0.12706777, -0.02204737,  0.00618507, ...,  0.23299779,\n",
            "          0.10781125,  2.        ],\n",
            "        [ 0.12773433,  0.04257592,  0.02777779, ...,  0.30607083,\n",
            "         -0.03123893,  2.        ],\n",
            "        ...,\n",
            "        [-0.03284603,  0.13296194,  0.19456033, ...,  0.03974679,\n",
            "          0.02188246,  2.        ],\n",
            "        [-0.22662376,  0.12847139,  0.34624818, ...,  0.0421505 ,\n",
            "         -0.0140104 ,  2.        ],\n",
            "        [-0.28867123,  0.10222249,  0.30757234, ...,  0.03818193,\n",
            "         -0.00246797,  2.        ]], dtype=float32)\n",
            " array([[-0.03143179, -0.15689702, -0.05943136, ...,  0.05680875,\n",
            "          0.19155842,  2.        ],\n",
            "        [ 0.11371826, -0.13091886, -0.06445052, ...,  0.25783315,\n",
            "          0.14873494,  2.        ],\n",
            "        [ 0.04563731, -0.12559842, -0.07446805, ...,  0.35748336,\n",
            "          0.08327466,  2.        ],\n",
            "        ...,\n",
            "        [-0.22200164,  0.04716107,  0.1923016 , ...,  0.02577645,\n",
            "         -0.08338036,  2.        ],\n",
            "        [-0.2672748 ,  0.07083949,  0.20982502, ...,  0.03105986,\n",
            "         -0.07913751,  2.        ],\n",
            "        [-0.2435223 ,  0.03166194,  0.23598203, ..., -0.00653042,\n",
            "         -0.05150508,  2.        ]], dtype=float32)\n",
            " array([[-0.03538483, -0.13534008, -0.03330295, ...,  0.06224126,\n",
            "          0.21278442,  2.        ],\n",
            "        [ 0.16231096, -0.06030845, -0.0298604 , ...,  0.27530345,\n",
            "          0.15372066,  2.        ],\n",
            "        [ 0.12539838, -0.03321083, -0.01824571, ...,  0.367265  ,\n",
            "          0.04427567,  2.        ],\n",
            "        ...,\n",
            "        [-0.16472508,  0.09929305,  0.2530941 , ...,  0.08633608,\n",
            "         -0.01849134,  2.        ],\n",
            "        [-0.26727706,  0.08418173,  0.28580242, ...,  0.07618856,\n",
            "         -0.04185491,  2.        ],\n",
            "        [-0.2931111 ,  0.07842994,  0.27621984, ...,  0.04850299,\n",
            "         -0.01229779,  2.        ]], dtype=float32)\n",
            " array([[ 0.02112283, -0.12886925, -0.07947879, ...,  0.03271211,\n",
            "          0.18958512,  2.        ],\n",
            "        [ 0.21573502,  0.00912457, -0.0632293 , ...,  0.23252647,\n",
            "          0.04552215,  2.        ],\n",
            "        [ 0.19872226,  0.04221422, -0.05912919, ...,  0.3092748 ,\n",
            "         -0.09148222,  2.        ],\n",
            "        ...,\n",
            "        [ 0.16308843,  0.01089377, -0.00268424, ...,  0.0726378 ,\n",
            "          0.03570727,  2.        ],\n",
            "        [-0.07311214,  0.08130191,  0.25947005, ...,  0.11909104,\n",
            "         -0.02485208,  2.        ],\n",
            "        [-0.24809751,  0.07642537,  0.2872306 , ...,  0.08306855,\n",
            "         -0.02248034,  2.        ]], dtype=float32)\n",
            " array([[-0.0323956 , -0.13460648, -0.03229933, ...,  0.06862719,\n",
            "          0.21154958,  2.        ],\n",
            "        [ 0.17432453, -0.05256716, -0.03038313, ...,  0.2800701 ,\n",
            "          0.14392273,  2.        ],\n",
            "        [ 0.1466516 , -0.02130787, -0.01123064, ...,  0.37229076,\n",
            "          0.03042771,  2.        ],\n",
            "        ...,\n",
            "        [-0.1321702 ,  0.11852911,  0.23547941, ...,  0.08686   ,\n",
            "         -0.01527452,  2.        ],\n",
            "        [-0.2601657 ,  0.0962219 ,  0.28902936, ...,  0.07646408,\n",
            "         -0.0381878 ,  2.        ],\n",
            "        [-0.2837705 ,  0.09335311,  0.273643  , ...,  0.06364533,\n",
            "         -0.00782438,  2.        ]], dtype=float32)\n",
            " array([[-0.02759452, -0.14860521, -0.0604827 , ...,  0.05858247,\n",
            "          0.19738258,  2.        ],\n",
            "        [ 0.131629  , -0.12092443, -0.06156378, ...,  0.25214943,\n",
            "          0.16483687,  2.        ],\n",
            "        [ 0.06357726, -0.10880154, -0.06622373, ...,  0.363137  ,\n",
            "          0.08239521,  2.        ],\n",
            "        ...,\n",
            "        [-0.2266034 ,  0.05279104,  0.18761437, ...,  0.03269643,\n",
            "         -0.07481442,  2.        ],\n",
            "        [-0.27595314,  0.07189136,  0.21206303, ...,  0.04412488,\n",
            "         -0.07623972,  2.        ],\n",
            "        [-0.24853079,  0.03872584,  0.23651126, ...,  0.00595416,\n",
            "         -0.05201726,  2.        ]], dtype=float32)\n",
            " array([[-0.01725925, -0.11798313, -0.03836179, ...,  0.04614706,\n",
            "          0.21174358,  2.        ],\n",
            "        [ 0.1405575 , -0.0104807 , -0.01168748, ...,  0.24574542,\n",
            "          0.10579658,  2.        ],\n",
            "        [ 0.15171286,  0.05850211,  0.00774089, ...,  0.31455302,\n",
            "         -0.04919594,  2.        ],\n",
            "        ...,\n",
            "        [-0.00567039,  0.13452305,  0.16209444, ...,  0.0389418 ,\n",
            "          0.02513897,  2.        ],\n",
            "        [-0.20453379,  0.14244114,  0.3281292 , ...,  0.06042393,\n",
            "         -0.01086017,  2.        ],\n",
            "        [-0.2697053 ,  0.10616504,  0.29952174, ...,  0.06293584,\n",
            "          0.00443129,  2.        ]], dtype=float32)\n",
            " array([[-9.5237019e-03, -1.2093341e-01, -3.2613985e-02, ...,\n",
            "          4.7069725e-02,  2.1186240e-01,  2.0000000e+00],\n",
            "        [ 1.5747687e-01, -1.8730251e-02, -1.4562910e-02, ...,\n",
            "          2.6255575e-01,  1.1625521e-01,  2.0000000e+00],\n",
            "        [ 1.6440329e-01,  5.0777331e-02, -1.1762223e-03, ...,\n",
            "          3.3539075e-01, -2.6076233e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.5188373e-02,  1.1900038e-01,  1.5542893e-01, ...,\n",
            "          7.3396020e-02,  4.0777076e-02,  2.0000000e+00],\n",
            "        [-1.9608445e-01,  1.2173134e-01,  3.2399002e-01, ...,\n",
            "          8.8040181e-02,  8.6426700e-04,  2.0000000e+00],\n",
            "        [-2.5671008e-01,  1.0759356e-01,  2.9277408e-01, ...,\n",
            "          6.3280188e-02,  8.8380231e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.3606368e-02, -1.2205434e-01, -3.0466704e-02, ...,\n",
            "          4.6560496e-02,  2.1191640e-01,  2.0000000e+00],\n",
            "        [ 1.5123074e-01, -2.2259444e-02, -9.8322118e-03, ...,\n",
            "          2.6270688e-01,  1.1838171e-01,  2.0000000e+00],\n",
            "        [ 1.5652245e-01,  4.4931728e-02,  4.2714784e-03, ...,\n",
            "          3.3490252e-01, -2.3295276e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.7383802e-03,  1.2185714e-01,  1.7576434e-01, ...,\n",
            "          7.3139094e-02,  3.2754134e-02,  2.0000000e+00],\n",
            "        [-2.0784517e-01,  1.2519079e-01,  3.3086607e-01, ...,\n",
            "          8.0411434e-02, -2.4656039e-03,  2.0000000e+00],\n",
            "        [-2.6273936e-01,  1.0843594e-01,  2.9495674e-01, ...,\n",
            "          5.9402935e-02,  9.9569783e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.03205339, -0.13022694, -0.02962795, ...,  0.05299262,\n",
            "          0.2055159 ,  2.        ],\n",
            "        [ 0.14450994, -0.05621052, -0.02570199, ...,  0.2550283 ,\n",
            "          0.13879842,  2.        ],\n",
            "        [ 0.1225049 , -0.02709138, -0.0116666 , ...,  0.34503016,\n",
            "          0.02819583,  2.        ],\n",
            "        ...,\n",
            "        [-0.11999017,  0.09968148,  0.22005932, ...,  0.07228039,\n",
            "          0.01195458,  2.        ],\n",
            "        [-0.25138992,  0.09281776,  0.29483297, ...,  0.05866607,\n",
            "         -0.03091889,  2.        ],\n",
            "        [-0.2974618 ,  0.08762788,  0.2844663 , ...,  0.03941306,\n",
            "         -0.01768752,  2.        ]], dtype=float32)\n",
            " array([[-0.02784317, -0.1421136 , -0.03714063, ...,  0.06753361,\n",
            "          0.21632181,  2.        ],\n",
            "        [ 0.1843655 , -0.07037898, -0.04409961, ...,  0.28237346,\n",
            "          0.16306107,  2.        ],\n",
            "        [ 0.1428142 , -0.04721626, -0.03597663, ...,  0.38115382,\n",
            "          0.05573868,  2.        ],\n",
            "        ...,\n",
            "        [-0.09803611,  0.0833248 ,  0.20385195, ...,  0.1138429 ,\n",
            "          0.00789814,  2.        ],\n",
            "        [-0.2389242 ,  0.08062635,  0.27359658, ...,  0.09405863,\n",
            "         -0.02551282,  2.        ],\n",
            "        [-0.2832437 ,  0.07766346,  0.26292244, ...,  0.06995108,\n",
            "         -0.00886972,  2.        ]], dtype=float32)\n",
            " array([[-0.02938236, -0.14746566, -0.04263393, ...,  0.06232549,\n",
            "          0.21249469,  2.        ],\n",
            "        [ 0.15694349, -0.07694878, -0.06475262, ...,  0.29855412,\n",
            "          0.1436501 ,  2.        ],\n",
            "        [ 0.12555559, -0.06527878, -0.07103374, ...,  0.3890455 ,\n",
            "          0.04288363,  2.        ],\n",
            "        ...,\n",
            "        [-0.1092216 ,  0.03005066,  0.18553028, ...,  0.09978931,\n",
            "          0.0231484 ,  2.        ],\n",
            "        [-0.21550037,  0.03113534,  0.24186832, ...,  0.08299693,\n",
            "         -0.01901484,  2.        ],\n",
            "        [-0.2740315 ,  0.03948638,  0.2534646 , ...,  0.05346477,\n",
            "         -0.01717308,  2.        ]], dtype=float32)\n",
            " array([[-0.01875746, -0.11888348, -0.03308633, ...,  0.03600862,\n",
            "          0.2037521 ,  2.        ],\n",
            "        [ 0.12710924, -0.01135107, -0.00305333, ...,  0.23202817,\n",
            "          0.09040141,  2.        ],\n",
            "        [ 0.13461144,  0.05659389,  0.0124614 , ...,  0.303043  ,\n",
            "         -0.0532678 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.00269384,  0.12594478,  0.14870429, ...,  0.02730866,\n",
            "          0.03359742,  2.        ],\n",
            "        [-0.2095438 ,  0.12275729,  0.33692762, ...,  0.04881941,\n",
            "         -0.01340185,  2.        ],\n",
            "        [-0.27776378,  0.09643058,  0.3046144 , ...,  0.042345  ,\n",
            "         -0.00355528,  2.        ]], dtype=float32)\n",
            " array([[-0.01829606, -0.12294189, -0.03840005, ...,  0.04975357,\n",
            "          0.2139627 ,  2.        ],\n",
            "        [ 0.13864745, -0.02397471, -0.01094704, ...,  0.23167172,\n",
            "          0.1220087 ,  2.        ],\n",
            "        [ 0.13568035,  0.04336124,  0.00826598, ...,  0.31003258,\n",
            "         -0.0291345 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.03547104,  0.14975043,  0.18856427, ...,  0.04456607,\n",
            "          0.01961631,  2.        ],\n",
            "        [-0.22756219,  0.14125916,  0.3251553 , ...,  0.05857896,\n",
            "         -0.01090041,  2.        ],\n",
            "        [-0.27139008,  0.10689285,  0.29253516, ...,  0.06999806,\n",
            "          0.00884096,  2.        ]], dtype=float32)\n",
            " array([[-1.77658023e-03, -1.08281605e-01, -5.73967099e-02, ...,\n",
            "          4.38827090e-02,  2.11501524e-01,  2.00000000e+00],\n",
            "        [ 1.43937513e-01, -1.56032713e-03, -2.97743622e-02, ...,\n",
            "          2.22037897e-01,  9.85356197e-02,  2.00000000e+00],\n",
            "        [ 1.53497711e-01,  5.48077263e-02, -1.94172151e-02, ...,\n",
            "          2.97368139e-01, -6.34220988e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 3.67968455e-02,  1.27068833e-01,  1.15752049e-01, ...,\n",
            "          2.26422250e-02,  4.04400006e-02,  2.00000000e+00],\n",
            "        [-1.75093174e-01,  1.44731253e-01,  3.11121881e-01, ...,\n",
            "          6.16752729e-02, -9.96939931e-03,  2.00000000e+00],\n",
            "        [-2.59225219e-01,  9.94335189e-02,  2.94385821e-01, ...,\n",
            "          6.54006302e-02, -2.72723148e-04,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.04798114e-02, -1.32061899e-01, -3.38501222e-02, ...,\n",
            "          5.34272566e-02,  2.14915857e-01,  2.00000000e+00],\n",
            "        [ 1.40947118e-01, -3.41035724e-02, -1.26362415e-02, ...,\n",
            "          2.52002031e-01,  1.27354547e-01,  2.00000000e+00],\n",
            "        [ 1.40762404e-01,  3.01574580e-02,  7.11721554e-03, ...,\n",
            "          3.34439486e-01, -2.05930043e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-6.09584413e-02,  1.40408128e-01,  2.08083853e-01, ...,\n",
            "          6.74283355e-02,  8.93498491e-03,  2.00000000e+00],\n",
            "        [-2.32380345e-01,  1.41555473e-01,  3.24798077e-01, ...,\n",
            "          6.87708035e-02, -2.07784325e-02,  2.00000000e+00],\n",
            "        [-2.81881720e-01,  1.01704463e-01,  2.96430081e-01, ...,\n",
            "          6.83730245e-02,  1.32869207e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01890459, -0.14940593, -0.03438168, ...,  0.06279458,\n",
            "          0.22117157,  2.        ],\n",
            "        [ 0.17792715, -0.04960196, -0.03073816, ...,  0.2823832 ,\n",
            "          0.14309905,  2.        ],\n",
            "        [ 0.15979366, -0.012491  , -0.00861482, ...,  0.3689299 ,\n",
            "          0.02160777,  2.        ],\n",
            "        ...,\n",
            "        [-0.06602719,  0.09610913,  0.18379283, ...,  0.07480772,\n",
            "          0.00840722,  2.        ],\n",
            "        [-0.20667426,  0.08869311,  0.2663854 , ...,  0.07448124,\n",
            "         -0.02597818,  2.        ],\n",
            "        [-0.26700178,  0.08078192,  0.2661218 , ...,  0.07319619,\n",
            "         -0.00536735,  2.        ]], dtype=float32)\n",
            " array([[-1.76412761e-02, -1.16894886e-01, -3.03948540e-02, ...,\n",
            "          3.31853405e-02,  2.04246089e-01,  2.00000000e+00],\n",
            "        [ 1.26755342e-01, -1.51692694e-02, -8.88812472e-04, ...,\n",
            "          2.24320978e-01,  9.79019105e-02,  2.00000000e+00],\n",
            "        [ 1.30221561e-01,  5.18648401e-02,  1.91304684e-02, ...,\n",
            "          2.96005905e-01, -5.00808023e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.10413078e-02,  1.32174596e-01,  1.72393262e-01, ...,\n",
            "          1.97804980e-02,  3.29072550e-02,  2.00000000e+00],\n",
            "        [-2.16494262e-01,  1.36108801e-01,  3.42048645e-01, ...,\n",
            "          3.85403372e-02, -1.02454927e-02,  2.00000000e+00],\n",
            "        [-2.83346266e-01,  9.96036455e-02,  3.09140056e-01, ...,\n",
            "          4.19743024e-02, -6.28487207e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-9.8419785e-03, -1.0930533e-01, -4.7014207e-02, ...,\n",
            "          2.9070016e-02,  1.9949770e-01,  2.0000000e+00],\n",
            "        [ 1.3873512e-01, -5.3799949e-03, -1.6613152e-02, ...,\n",
            "          2.2244668e-01,  6.8133749e-02,  2.0000000e+00],\n",
            "        [ 1.5082011e-01,  5.6004290e-02, -7.8898259e-03, ...,\n",
            "          2.9095888e-01, -7.7944398e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 3.7560791e-02,  9.2703938e-02,  8.6145923e-02, ...,\n",
            "          1.1380427e-02,  6.2928103e-02,  2.0000000e+00],\n",
            "        [-1.7833893e-01,  1.3125795e-01,  3.2465440e-01, ...,\n",
            "          5.3703051e-02, -1.1416533e-03,  2.0000000e+00],\n",
            "        [-2.7345228e-01,  9.6320875e-02,  3.0470246e-01, ...,\n",
            "          4.7670972e-02, -4.4984184e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02331862, -0.13224742, -0.02901731, ...,  0.04744578,\n",
            "          0.21660478,  2.        ],\n",
            "        [ 0.1419894 , -0.03875061, -0.0056514 , ...,  0.2509805 ,\n",
            "          0.13149595,  2.        ],\n",
            "        [ 0.14223988,  0.02165684,  0.01937579, ...,  0.32417697,\n",
            "         -0.00564374,  2.        ],\n",
            "        ...,\n",
            "        [-0.08917492,  0.14835735,  0.2343129 , ...,  0.05347985,\n",
            "         -0.00994713,  2.        ],\n",
            "        [-0.2390165 ,  0.13748316,  0.33299148, ...,  0.05314212,\n",
            "         -0.03101346,  2.        ],\n",
            "        [-0.28520277,  0.09991997,  0.30140862, ...,  0.05741284,\n",
            "         -0.00618191,  2.        ]], dtype=float32)\n",
            " array([[-1.38793895e-02, -1.21513918e-01, -3.77990864e-02, ...,\n",
            "          4.96140532e-02,  2.19510719e-01,  0.00000000e+00],\n",
            "        [ 1.31722435e-01, -3.85234617e-02, -1.36117209e-02, ...,\n",
            "          2.28422344e-01,  1.41044676e-01,  0.00000000e+00],\n",
            "        [ 1.31995425e-01,  2.50065867e-02,  5.81687642e-03, ...,\n",
            "          3.09628755e-01, -1.63144488e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-5.88845313e-02,  1.48511708e-01,  2.08844364e-01, ...,\n",
            "          5.79196252e-02,  1.17694233e-02,  0.00000000e+00],\n",
            "        [-2.33649731e-01,  1.39857098e-01,  3.35885465e-01, ...,\n",
            "          6.13626577e-02, -1.64351854e-02,  0.00000000e+00],\n",
            "        [-2.80826509e-01,  1.00708663e-01,  3.02845329e-01, ...,\n",
            "          6.00713938e-02, -1.56176451e-04,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.02753714, -0.14807007, -0.05883229, ...,  0.06176234,\n",
            "          0.2019842 ,  0.        ],\n",
            "        [ 0.13694298, -0.11744019, -0.06242619, ...,  0.26240313,\n",
            "          0.16601506,  0.        ],\n",
            "        [ 0.07051834, -0.10753734, -0.06486657, ...,  0.37494898,\n",
            "          0.08837821,  0.        ],\n",
            "        ...,\n",
            "        [-0.21165685,  0.04964204,  0.19043419, ...,  0.05128235,\n",
            "         -0.06490473,  0.        ],\n",
            "        [-0.27189225,  0.05965149,  0.21044649, ...,  0.06247024,\n",
            "         -0.06953947,  0.        ],\n",
            "        [-0.25684586,  0.04226247,  0.24037005, ...,  0.01314814,\n",
            "         -0.04300357,  0.        ]], dtype=float32)\n",
            " array([[-0.01724049, -0.12853572, -0.03168064, ...,  0.03948403,\n",
            "          0.20589356,  0.        ],\n",
            "        [ 0.13360448, -0.03288339, -0.00711851, ...,  0.24856317,\n",
            "          0.11197498,  0.        ],\n",
            "        [ 0.13016775,  0.02774235,  0.01295034, ...,  0.32848775,\n",
            "         -0.02804065,  0.        ],\n",
            "        ...,\n",
            "        [-0.02941119,  0.12890759,  0.18507832, ...,  0.07269811,\n",
            "          0.01796409,  0.        ],\n",
            "        [-0.22225349,  0.12733963,  0.33029357, ...,  0.06259649,\n",
            "         -0.01405546,  0.        ],\n",
            "        [-0.2788665 ,  0.09645831,  0.2944133 , ...,  0.04626785,\n",
            "         -0.00767879,  0.        ]], dtype=float32)\n",
            " array([[-0.03620535, -0.15451264, -0.05660684, ...,  0.06076425,\n",
            "          0.20814033,  0.        ],\n",
            "        [ 0.13747689, -0.11800624, -0.07851393, ...,  0.28877366,\n",
            "          0.16109993,  0.        ],\n",
            "        [ 0.07578454, -0.11531438, -0.08314251, ...,  0.3956179 ,\n",
            "          0.0825597 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.1858128 ,  0.02232457,  0.19728398, ...,  0.10949606,\n",
            "         -0.03851924,  0.        ],\n",
            "        [-0.25982058,  0.0437252 ,  0.19870989, ...,  0.08716325,\n",
            "         -0.06905561,  0.        ],\n",
            "        [-0.27213433,  0.01951444,  0.23636726, ...,  0.023494  ,\n",
            "         -0.03796861,  0.        ]], dtype=float32)\n",
            " array([[-0.01936723, -0.13621877, -0.02886553, ...,  0.04947962,\n",
            "          0.21628413,  0.        ],\n",
            "        [ 0.15061088, -0.0484153 , -0.01072501, ...,  0.24879768,\n",
            "          0.13736038,  0.        ],\n",
            "        [ 0.13826375,  0.00455488,  0.01239951, ...,  0.33104423,\n",
            "         -0.00512545,  0.        ],\n",
            "        ...,\n",
            "        [-0.08952311,  0.15199856,  0.21589315, ...,  0.04876805,\n",
            "          0.00227822,  0.        ],\n",
            "        [-0.23536302,  0.13274285,  0.3085586 , ...,  0.05369464,\n",
            "         -0.02743929,  0.        ],\n",
            "        [-0.275805  ,  0.09793203,  0.2857594 , ...,  0.06478274,\n",
            "         -0.00546833,  0.        ]], dtype=float32)\n",
            " array([[-3.08834016e-04, -1.17166631e-01, -4.61579673e-02, ...,\n",
            "          5.75839058e-02,  2.18646437e-01,  0.00000000e+00],\n",
            "        [ 1.46776378e-01, -2.82294601e-02, -2.88003590e-02, ...,\n",
            "          2.25436553e-01,  1.26475528e-01,  0.00000000e+00],\n",
            "        [ 1.35769233e-01,  3.27276289e-02, -1.18631171e-02, ...,\n",
            "          3.12466919e-01, -3.84422392e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.25340242e-02,  1.47653639e-01,  1.30620211e-01, ...,\n",
            "          4.53451164e-02,  4.01573814e-02,  0.00000000e+00],\n",
            "        [-1.89869821e-01,  1.48540527e-01,  2.96514422e-01, ...,\n",
            "          7.14563802e-02,  2.89592217e-03,  0.00000000e+00],\n",
            "        [-2.48146340e-01,  1.07115224e-01,  2.81370580e-01, ...,\n",
            "          7.58918971e-02,  5.32218441e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.03199393, -0.13619512, -0.03906126, ...,  0.05468629,\n",
            "          0.20971248,  0.        ],\n",
            "        [ 0.1442832 , -0.072451  , -0.05300092, ...,  0.27039868,\n",
            "          0.13950686,  0.        ],\n",
            "        [ 0.1180485 , -0.05344436, -0.05538661, ...,  0.3643999 ,\n",
            "          0.02786182,  0.        ],\n",
            "        ...,\n",
            "        [-0.1233651 ,  0.0584075 ,  0.2015379 , ...,  0.09951323,\n",
            "          0.01716466,  0.        ],\n",
            "        [-0.24157815,  0.0536807 ,  0.27103594, ...,  0.07194363,\n",
            "         -0.02742266,  0.        ],\n",
            "        [-0.29100594,  0.0593278 ,  0.2698555 , ...,  0.03811486,\n",
            "         -0.01961621,  0.        ]], dtype=float32)\n",
            " array([[-0.03378477, -0.16060136, -0.05179932, ...,  0.05769264,\n",
            "          0.21215838,  0.        ],\n",
            "        [ 0.14189208, -0.10973261, -0.073591  , ...,  0.2910828 ,\n",
            "          0.15276358,  0.        ],\n",
            "        [ 0.09324002, -0.11339973, -0.08011403, ...,  0.380345  ,\n",
            "          0.0774243 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.13928464,  0.00563961,  0.19706044, ...,  0.10831141,\n",
            "          0.00554749,  0.        ],\n",
            "        [-0.23295684,  0.02087802,  0.21350475, ...,  0.08694743,\n",
            "         -0.04180528,  0.        ],\n",
            "        [-0.27079028,  0.0079864 ,  0.24093243, ...,  0.03428492,\n",
            "         -0.02811515,  0.        ]], dtype=float32)\n",
            " array([[-0.02823017, -0.12393438, -0.03161198, ...,  0.05164116,\n",
            "          0.2072014 ,  0.        ],\n",
            "        [ 0.13706507, -0.06182395, -0.03427041, ...,  0.26242906,\n",
            "          0.1374925 ,  0.        ],\n",
            "        [ 0.1196413 , -0.0295089 , -0.02375328, ...,  0.36198628,\n",
            "          0.01473058,  0.        ],\n",
            "        ...,\n",
            "        [-0.12826742,  0.1029757 ,  0.23544867, ...,  0.0937777 ,\n",
            "         -0.00282949,  0.        ],\n",
            "        [-0.25271556,  0.09442167,  0.30679208, ...,  0.0704852 ,\n",
            "         -0.03159675,  0.        ],\n",
            "        [-0.29966408,  0.08277538,  0.28857747, ...,  0.04494632,\n",
            "         -0.01845813,  0.        ]], dtype=float32)\n",
            " array([[ 0.01388634, -0.11026864, -0.06144489, ...,  0.05376919,\n",
            "          0.20722954,  0.        ],\n",
            "        [ 0.16737956, -0.01433512, -0.05442454, ...,  0.21749276,\n",
            "          0.09983942,  0.        ],\n",
            "        [ 0.15648678,  0.0394453 , -0.04368256, ...,  0.2999679 ,\n",
            "         -0.0629897 ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.07180007,  0.11392347,  0.07449375, ...,  0.04585604,\n",
            "          0.04871606,  0.        ],\n",
            "        [-0.15032218,  0.13257723,  0.2698867 , ...,  0.086236  ,\n",
            "         -0.00226844,  0.        ],\n",
            "        [-0.2419447 ,  0.09655008,  0.27145582, ...,  0.06956609,\n",
            "          0.00059861,  0.        ]], dtype=float32)\n",
            " array([[-0.03421102, -0.147076  , -0.0381652 , ...,  0.06113831,\n",
            "          0.21546327,  0.        ],\n",
            "        [ 0.16527455, -0.0831129 , -0.04908946, ...,  0.28767812,\n",
            "          0.16092122,  0.        ],\n",
            "        [ 0.11699872, -0.07924662, -0.04485791, ...,  0.3840177 ,\n",
            "          0.07121903,  0.        ],\n",
            "        ...,\n",
            "        [-0.15118505,  0.05494932,  0.22420785, ...,  0.10005048,\n",
            "          0.00263071,  0.        ],\n",
            "        [-0.263578  ,  0.05328072,  0.2578207 , ...,  0.0804942 ,\n",
            "         -0.04397631,  0.        ],\n",
            "        [-0.28969663,  0.05423373,  0.26423803, ...,  0.03838131,\n",
            "         -0.02131736,  0.        ]], dtype=float32)\n",
            " array([[-0.0333078 , -0.13998927, -0.03657612, ...,  0.05492349,\n",
            "          0.21127862,  0.        ],\n",
            "        [ 0.14827724, -0.07130702, -0.0499519 , ...,  0.2788612 ,\n",
            "          0.14751434,  0.        ],\n",
            "        [ 0.11443538, -0.05653666, -0.05216073, ...,  0.3697386 ,\n",
            "          0.04685856,  0.        ],\n",
            "        ...,\n",
            "        [-0.14160772,  0.05711604,  0.2241804 , ...,  0.08676621,\n",
            "          0.00995239,  0.        ],\n",
            "        [-0.24518189,  0.05584786,  0.2705739 , ...,  0.06983051,\n",
            "         -0.025954  ,  0.        ],\n",
            "        [-0.29352474,  0.05611045,  0.2750723 , ...,  0.03939183,\n",
            "         -0.01806896,  0.        ]], dtype=float32)\n",
            " array([[-0.0083478 , -0.11450306, -0.03470621, ...,  0.04325089,\n",
            "          0.20786326,  0.        ],\n",
            "        [ 0.16059946, -0.01098205, -0.01630138, ...,  0.2575245 ,\n",
            "          0.09645046,  0.        ],\n",
            "        [ 0.17225477,  0.0599304 , -0.00569723, ...,  0.32120705,\n",
            "         -0.05091513,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05224777,  0.11334234,  0.10838744, ...,  0.05301099,\n",
            "          0.05494562,  0.        ],\n",
            "        [-0.17324854,  0.12493108,  0.31366706, ...,  0.09096227,\n",
            "          0.00301993,  0.        ],\n",
            "        [-0.2529582 ,  0.11190556,  0.29264876, ...,  0.06016074,\n",
            "          0.00946447,  0.        ]], dtype=float32)\n",
            " array([[-0.03262887, -0.14375871, -0.03532254, ...,  0.06289613,\n",
            "          0.21466282,  0.        ],\n",
            "        [ 0.16686454, -0.0709767 , -0.03834858, ...,  0.2782775 ,\n",
            "          0.1526577 ,  0.        ],\n",
            "        [ 0.12338641, -0.05163218, -0.0291585 , ...,  0.370734  ,\n",
            "          0.0508346 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.14078757,  0.07539637,  0.23360467, ...,  0.09464204,\n",
            "         -0.00086047,  0.        ],\n",
            "        [-0.25556123,  0.062233  ,  0.27680856, ...,  0.07669771,\n",
            "         -0.04175996,  0.        ],\n",
            "        [-0.28229368,  0.07084479,  0.2690969 , ...,  0.04849378,\n",
            "         -0.01696519,  0.        ]], dtype=float32)\n",
            " array([[-0.03391745, -0.13540003, -0.0362187 , ...,  0.05257385,\n",
            "          0.2099488 ,  0.        ],\n",
            "        [ 0.13711722, -0.06742352, -0.04212019, ...,  0.26845405,\n",
            "          0.1467051 ,  0.        ],\n",
            "        [ 0.10808577, -0.047665  , -0.04103614, ...,  0.35934964,\n",
            "          0.04111985,  0.        ],\n",
            "        ...,\n",
            "        [-0.16042937,  0.06994257,  0.24740745, ...,  0.08888259,\n",
            "          0.00227256,  0.        ],\n",
            "        [-0.26049545,  0.06598742,  0.28810665, ...,  0.07017851,\n",
            "         -0.03323639,  0.        ],\n",
            "        [-0.3012768 ,  0.06601983,  0.28305233, ...,  0.03458909,\n",
            "         -0.01939631,  0.        ]], dtype=float32)\n",
            " array([[ 0.06250786, -0.22717749, -0.14560533, ..., -0.033278  ,\n",
            "          0.1874667 ,  0.        ],\n",
            "        [ 0.29687044,  0.00710882, -0.09368446, ..., -0.03633432,\n",
            "          0.03443502,  0.        ],\n",
            "        [ 0.3229723 ,  0.02231958, -0.07661767, ...,  0.01256877,\n",
            "         -0.00260136,  0.        ],\n",
            "        ...,\n",
            "        [ 0.18502247, -0.01933676, -0.14807758, ...,  0.02530233,\n",
            "          0.09274411,  0.        ],\n",
            "        [ 0.0838681 ,  0.03303347,  0.04377017, ...,  0.09600921,\n",
            "          0.01836698,  0.        ],\n",
            "        [-0.09867921, -0.0139999 ,  0.25860894, ...,  0.02004092,\n",
            "          0.03813343,  0.        ]], dtype=float32)\n",
            " array([[-0.00770989, -0.10988152, -0.05122291, ...,  0.02998647,\n",
            "          0.19736803,  0.        ],\n",
            "        [ 0.14725764, -0.00448409, -0.02493238, ...,  0.22941284,\n",
            "          0.05296984,  0.        ],\n",
            "        [ 0.15918882,  0.05549708, -0.02052126, ...,  0.2981895 ,\n",
            "         -0.09116606,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05126381,  0.0867865 ,  0.07023534, ...,  0.01703203,\n",
            "          0.0557189 ,  0.        ],\n",
            "        [-0.16808295,  0.12389506,  0.32086888, ...,  0.06387942,\n",
            "         -0.00872416,  0.        ],\n",
            "        [-0.26756698,  0.09312035,  0.29983068, ...,  0.05029715,\n",
            "         -0.00399821,  0.        ]], dtype=float32)\n",
            " array([[-0.01888611, -0.12349731, -0.03221035, ...,  0.04733855,\n",
            "          0.21726169,  0.        ],\n",
            "        [ 0.12879165, -0.03465383, -0.00711485, ...,  0.23842798,\n",
            "          0.13415001,  0.        ],\n",
            "        [ 0.12651469,  0.02624798,  0.01472754, ...,  0.31357193,\n",
            "         -0.01596351,  0.        ],\n",
            "        ...,\n",
            "        [-0.03477661,  0.14004524,  0.19496208, ...,  0.04704157,\n",
            "          0.02825261,  0.        ],\n",
            "        [-0.2229103 ,  0.14479682,  0.33094102, ...,  0.05614726,\n",
            "         -0.00611516,  0.        ],\n",
            "        [-0.28442264,  0.10038105,  0.3011533 , ...,  0.05664498,\n",
            "          0.00033527,  0.        ]], dtype=float32)\n",
            " array([[-2.42431350e-02, -1.31684482e-01, -2.58897021e-02, ...,\n",
            "          4.31920551e-02,  2.08820552e-01,  0.00000000e+00],\n",
            "        [ 1.30327970e-01, -4.57127169e-02, -2.29754500e-04, ...,\n",
            "          2.46086985e-01,  1.31864950e-01,  0.00000000e+00],\n",
            "        [ 1.19842134e-01,  1.71420979e-04,  1.98684279e-02, ...,\n",
            "          3.28587979e-01,  5.50611457e-03,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-1.09177597e-01,  1.33483022e-01,  2.53756046e-01, ...,\n",
            "          8.08317438e-02, -4.09068447e-03,  0.00000000e+00],\n",
            "        [-2.54411280e-01,  1.24907516e-01,  3.47878993e-01, ...,\n",
            "          6.21813498e-02, -3.25649157e-02,  0.00000000e+00],\n",
            "        [-3.02278638e-01,  9.15069431e-02,  3.03375125e-01, ...,\n",
            "          4.74313870e-02, -1.57350525e-02,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.00863604, -0.11535039, -0.03578259, ...,  0.04336778,\n",
            "          0.20925888,  1.        ],\n",
            "        [ 0.15857641, -0.01044429, -0.0188087 , ...,  0.2569353 ,\n",
            "          0.09658028,  1.        ],\n",
            "        [ 0.17053974,  0.06082953, -0.00754978, ...,  0.32055932,\n",
            "         -0.05129989,  1.        ],\n",
            "        ...,\n",
            "        [ 0.0549601 ,  0.11197611,  0.10715854, ...,  0.05189146,\n",
            "          0.05308717,  1.        ],\n",
            "        [-0.17326036,  0.12459357,  0.3170766 , ...,  0.09096101,\n",
            "          0.00200807,  1.        ],\n",
            "        [-0.25248352,  0.10922682,  0.29346633, ...,  0.06242468,\n",
            "          0.00921797,  1.        ]], dtype=float32)\n",
            " array([[-0.03049671, -0.1552062 , -0.06070391, ...,  0.05802335,\n",
            "          0.19119604,  1.        ],\n",
            "        [ 0.10908446, -0.12939218, -0.06851939, ...,  0.26162568,\n",
            "          0.145399  ,  1.        ],\n",
            "        [ 0.0406464 , -0.12769417, -0.08276057, ...,  0.36024415,\n",
            "          0.08183516,  1.        ],\n",
            "        ...,\n",
            "        [-0.23216084,  0.05243248,  0.19814876, ...,  0.03351101,\n",
            "         -0.08549556,  1.        ],\n",
            "        [-0.2680985 ,  0.06130483,  0.20405506, ...,  0.03364165,\n",
            "         -0.08210108,  1.        ],\n",
            "        [-0.24246411,  0.03061224,  0.23652533, ..., -0.00612585,\n",
            "         -0.05065754,  1.        ]], dtype=float32)\n",
            " array([[-0.03142974, -0.13249287, -0.0360553 , ...,  0.05477992,\n",
            "          0.21585546,  1.        ],\n",
            "        [ 0.14433765, -0.06661236, -0.04182461, ...,  0.26187983,\n",
            "          0.1601327 ,  1.        ],\n",
            "        [ 0.10830755, -0.04562644, -0.03342244, ...,  0.3583326 ,\n",
            "          0.04856908,  1.        ],\n",
            "        ...,\n",
            "        [-0.17232442,  0.08219409,  0.25384936, ...,  0.08205292,\n",
            "         -0.01211485,  1.        ],\n",
            "        [-0.27326512,  0.07090143,  0.29083884, ...,  0.06977752,\n",
            "         -0.04466575,  1.        ],\n",
            "        [-0.30155346,  0.07237522,  0.28159538, ...,  0.04011964,\n",
            "         -0.01756639,  1.        ]], dtype=float32)\n",
            " array([[-0.01935295, -0.13994281, -0.04357653, ...,  0.07454462,\n",
            "          0.21111614,  1.        ],\n",
            "        [ 0.19134106, -0.08260582, -0.07238938, ...,  0.3103904 ,\n",
            "          0.1602467 ,  1.        ],\n",
            "        [ 0.16063951, -0.07005225, -0.07946588, ...,  0.4164876 ,\n",
            "          0.06203399,  1.        ],\n",
            "        ...,\n",
            "        [-0.06102317,  0.03103221,  0.14919998, ...,  0.17004651,\n",
            "          0.02933378,  1.        ],\n",
            "        [-0.20968524,  0.05061518,  0.25743532, ...,  0.13931003,\n",
            "         -0.00529729,  1.        ],\n",
            "        [-0.28298542,  0.05690791,  0.25000924, ...,  0.07302113,\n",
            "         -0.00858889,  1.        ]], dtype=float32)\n",
            " array([[-0.0328275 , -0.13501327, -0.03099092, ...,  0.06456453,\n",
            "          0.21395871,  1.        ],\n",
            "        [ 0.16868521, -0.06022608, -0.02778458, ...,  0.26842085,\n",
            "          0.15014115,  1.        ],\n",
            "        [ 0.13720666, -0.03089164, -0.01538443, ...,  0.3634766 ,\n",
            "          0.04174133,  1.        ],\n",
            "        ...,\n",
            "        [-0.12600517,  0.11200277,  0.22904441, ...,  0.0818699 ,\n",
            "         -0.00189119,  1.        ],\n",
            "        [-0.25455585,  0.09200066,  0.28614825, ...,  0.06838141,\n",
            "         -0.03440831,  1.        ],\n",
            "        [-0.2847185 ,  0.08746713,  0.2727526 , ...,  0.0533959 ,\n",
            "         -0.01080056,  1.        ]], dtype=float32)\n",
            " array([[-0.03145939, -0.16085407, -0.04965286, ...,  0.05651963,\n",
            "          0.21146949,  1.        ],\n",
            "        [ 0.14584738, -0.10757039, -0.07179609, ...,  0.2929549 ,\n",
            "          0.15524235,  1.        ],\n",
            "        [ 0.10971302, -0.11246884, -0.07653057, ...,  0.37170273,\n",
            "          0.09428091,  1.        ],\n",
            "        ...,\n",
            "        [-0.13885824,  0.00570882,  0.19878095, ...,  0.10876229,\n",
            "          0.00536679,  1.        ],\n",
            "        [-0.22412212,  0.00822943,  0.22267668, ...,  0.08534726,\n",
            "         -0.03029137,  1.        ],\n",
            "        [-0.27117574,  0.00805163,  0.24480547, ...,  0.03691016,\n",
            "         -0.0218458 ,  1.        ]], dtype=float32)\n",
            " array([[-0.02268122, -0.1368224 , -0.03042446, ...,  0.05790232,\n",
            "          0.21727245,  1.        ],\n",
            "        [ 0.15270302, -0.0452668 , -0.01433461, ...,  0.26152533,\n",
            "          0.13648741,  1.        ],\n",
            "        [ 0.14112751,  0.00697511,  0.0037528 , ...,  0.3461324 ,\n",
            "         -0.00641594,  1.        ],\n",
            "        ...,\n",
            "        [-0.09666932,  0.1532691 ,  0.22608325, ...,  0.07187917,\n",
            "         -0.00450987,  1.        ],\n",
            "        [-0.2437151 ,  0.13414581,  0.31545866, ...,  0.06723938,\n",
            "         -0.03145377,  1.        ],\n",
            "        [-0.2791093 ,  0.10258302,  0.28865886, ...,  0.07243279,\n",
            "         -0.00132172,  1.        ]], dtype=float32)\n",
            " array([[-0.00239548, -0.18217301, -0.08319092, ...,  0.08676971,\n",
            "          0.2113053 ,  1.        ],\n",
            "        [ 0.21838231, -0.14993334, -0.13970387, ...,  0.3404688 ,\n",
            "          0.15779813,  1.        ],\n",
            "        [ 0.18831268, -0.14814065, -0.15628007, ...,  0.44547814,\n",
            "          0.08639205,  1.        ],\n",
            "        ...,\n",
            "        [ 0.00281352, -0.06926995,  0.05366249, ...,  0.20120528,\n",
            "          0.02196268,  1.        ],\n",
            "        [-0.1267778 , -0.03523651,  0.13905291, ...,  0.16715957,\n",
            "         -0.01119935,  1.        ],\n",
            "        [-0.2258127 , -0.03573944,  0.18056743, ...,  0.0807282 ,\n",
            "         -0.01994375,  1.        ]], dtype=float32)\n",
            " array([[-0.02225601, -0.13914259, -0.02998795, ...,  0.0485435 ,\n",
            "          0.21014105,  1.        ],\n",
            "        [ 0.14720309, -0.0494111 , -0.02058093, ...,  0.27506235,\n",
            "          0.13050264,  1.        ],\n",
            "        [ 0.13044369, -0.00943302, -0.00602507, ...,  0.36299247,\n",
            "          0.01199605,  1.        ],\n",
            "        ...,\n",
            "        [-0.08658994,  0.09570027,  0.20336004, ...,  0.08981007,\n",
            "          0.00714623,  1.        ],\n",
            "        [-0.22608894,  0.08842222,  0.29856336, ...,  0.0714362 ,\n",
            "         -0.02691715,  1.        ],\n",
            "        [-0.28804725,  0.08114675,  0.2898293 , ...,  0.05617496,\n",
            "         -0.0146734 ,  1.        ]], dtype=float32)\n",
            " array([[-0.02296563, -0.12910253, -0.02950166, ...,  0.04921945,\n",
            "          0.21635582,  1.        ],\n",
            "        [ 0.12699868, -0.04749877, -0.0078197 , ...,  0.23056066,\n",
            "          0.13819571,  1.        ],\n",
            "        [ 0.12289878,  0.00833472,  0.01510055, ...,  0.3107667 ,\n",
            "         -0.0090776 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.11998826,  0.1551555 ,  0.25838605, ...,  0.0523615 ,\n",
            "         -0.00624647,  1.        ],\n",
            "        [-0.25305003,  0.13882597,  0.34678417, ...,  0.05293529,\n",
            "         -0.03089179,  1.        ],\n",
            "        [-0.29208377,  0.10073031,  0.3055996 , ...,  0.05504682,\n",
            "         -0.00315082,  1.        ]], dtype=float32)\n",
            " array([[-0.01778642, -0.12645619, -0.02664015, ...,  0.04445148,\n",
            "          0.21146654,  1.        ],\n",
            "        [ 0.14549221, -0.0351176 , -0.00194769, ...,  0.2597273 ,\n",
            "          0.12223681,  1.        ],\n",
            "        [ 0.14805844,  0.02588911,  0.01300113, ...,  0.3341831 ,\n",
            "         -0.0134396 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.04084318,  0.12257966,  0.21101542, ...,  0.07796495,\n",
            "          0.01543138,  1.        ],\n",
            "        [-0.22689348,  0.12816413,  0.3409348 , ...,  0.07696061,\n",
            "         -0.01322433,  1.        ],\n",
            "        [-0.27581313,  0.10759062,  0.29965135, ...,  0.05597256,\n",
            "          0.00550278,  1.        ]], dtype=float32)\n",
            " array([[-0.02438894, -0.15482524, -0.06067955, ...,  0.04907952,\n",
            "          0.18095066,  1.        ],\n",
            "        [ 0.10042287, -0.13305989, -0.05455398, ...,  0.23494384,\n",
            "          0.14475147,  1.        ],\n",
            "        [ 0.03110962, -0.13487145, -0.07663831, ...,  0.32909495,\n",
            "          0.08843786,  1.        ],\n",
            "        ...,\n",
            "        [-0.21635379,  0.05466101,  0.22331384, ..., -0.03537429,\n",
            "         -0.09125253,  1.        ],\n",
            "        [-0.24815965,  0.07437647,  0.22853085, ..., -0.02755118,\n",
            "         -0.08771004,  1.        ],\n",
            "        [-0.20980735,  0.05580416,  0.24600387, ..., -0.04061862,\n",
            "         -0.0598426 ,  1.        ]], dtype=float32)\n",
            " array([[-0.03285024, -0.15013637, -0.05291598, ...,  0.06152605,\n",
            "          0.20646782,  1.        ],\n",
            "        [ 0.1365485 , -0.11106397, -0.06173865, ...,  0.27902853,\n",
            "          0.16371755,  1.        ],\n",
            "        [ 0.07510109, -0.10815027, -0.05901173, ...,  0.38389227,\n",
            "          0.08780156,  1.        ],\n",
            "        ...,\n",
            "        [-0.19432588,  0.03029116,  0.20490864, ...,  0.09385598,\n",
            "         -0.03927898,  1.        ],\n",
            "        [-0.27089503,  0.05171657,  0.21162668, ...,  0.08040889,\n",
            "         -0.06611237,  1.        ],\n",
            "        [-0.27158344,  0.04329588,  0.2422961 , ...,  0.0249258 ,\n",
            "         -0.03466797,  1.        ]], dtype=float32)\n",
            " array([[-0.0089506 , -0.10888892, -0.04913377, ...,  0.0295855 ,\n",
            "          0.1975909 ,  1.        ],\n",
            "        [ 0.1476206 , -0.00133797, -0.02420055, ...,  0.23115084,\n",
            "          0.05481748,  1.        ],\n",
            "        [ 0.16072719,  0.05844066, -0.02054308, ...,  0.29546162,\n",
            "         -0.08687877,  1.        ],\n",
            "        ...,\n",
            "        [ 0.04845535,  0.09332981,  0.07169899, ...,  0.01997325,\n",
            "          0.04491793,  1.        ],\n",
            "        [-0.1706241 ,  0.12845434,  0.32414383, ...,  0.06332026,\n",
            "         -0.01672988,  1.        ],\n",
            "        [-0.2690262 ,  0.09226496,  0.3049321 , ...,  0.05097986,\n",
            "         -0.00696227,  1.        ]], dtype=float32)\n",
            " array([[-0.03666857, -0.15830943, -0.06183608, ...,  0.06359263,\n",
            "          0.20666258,  1.        ],\n",
            "        [ 0.12612437, -0.12878586, -0.08050807, ...,  0.29770055,\n",
            "          0.15139322,  1.        ],\n",
            "        [ 0.06639121, -0.12627152, -0.08986894, ...,  0.39858833,\n",
            "          0.07715318,  1.        ],\n",
            "        ...,\n",
            "        [-0.18231104,  0.01812561,  0.1852739 , ...,  0.1065155 ,\n",
            "         -0.04862437,  1.        ],\n",
            "        [-0.23705582,  0.03226755,  0.18561907, ...,  0.0898207 ,\n",
            "         -0.07044501,  1.        ],\n",
            "        [-0.2600498 ,  0.00480263,  0.22524232, ...,  0.02741477,\n",
            "         -0.0372179 ,  1.        ]], dtype=float32)\n",
            " array([[-0.00446843, -0.11814194, -0.05279792, ...,  0.04874803,\n",
            "          0.2133169 ,  1.        ],\n",
            "        [ 0.14818391, -0.00782208, -0.03349764, ...,  0.22573239,\n",
            "          0.10948468,  1.        ],\n",
            "        [ 0.15226261,  0.04797788, -0.01923409, ...,  0.308622  ,\n",
            "         -0.05312546,  1.        ],\n",
            "        ...,\n",
            "        [ 0.04817954,  0.12207913,  0.09517533, ...,  0.0287824 ,\n",
            "          0.0464813 ,  1.        ],\n",
            "        [-0.17459199,  0.1429648 ,  0.2962546 , ...,  0.066497  ,\n",
            "         -0.00374374,  1.        ],\n",
            "        [-0.2580334 ,  0.10454911,  0.2845838 , ...,  0.06690774,\n",
            "          0.00253146,  1.        ]], dtype=float32)\n",
            " array([[-3.2556355e-02, -1.2572412e-01, -2.8697072e-02, ...,\n",
            "          6.1144259e-02,  2.1114340e-01,  1.0000000e+00],\n",
            "        [ 1.4668386e-01, -5.2171364e-02, -2.2656430e-02, ...,\n",
            "          2.5333345e-01,  1.4532247e-01,  1.0000000e+00],\n",
            "        [ 1.2512656e-01, -2.1004315e-02, -1.7908681e-04, ...,\n",
            "          3.4523636e-01,  3.1611606e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.5077704e-01,  1.2665276e-01,  2.5810343e-01, ...,\n",
            "          6.8862975e-02, -1.7656459e-02,  1.0000000e+00],\n",
            "        [-2.6116559e-01,  1.0680261e-01,  3.1329787e-01, ...,\n",
            "          6.5198183e-02, -4.1195169e-02,  1.0000000e+00],\n",
            "        [-2.9525530e-01,  9.1231830e-02,  2.8734869e-01, ...,\n",
            "          4.3075752e-02, -1.3016892e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.0333879 , -0.14646636, -0.04114733, ...,  0.05500285,\n",
            "          0.2144808 ,  1.        ],\n",
            "        [ 0.14852841, -0.08307905, -0.06550734, ...,  0.2836156 ,\n",
            "          0.15631229,  1.        ],\n",
            "        [ 0.10645127, -0.07504368, -0.07081989, ...,  0.3785138 ,\n",
            "          0.05924631,  1.        ],\n",
            "        ...,\n",
            "        [-0.13422295,  0.03699474,  0.20576482, ...,  0.10691633,\n",
            "          0.024183  ,  1.        ],\n",
            "        [-0.24470983,  0.03562671,  0.26049727, ...,  0.08040851,\n",
            "         -0.02755664,  1.        ],\n",
            "        [-0.29448876,  0.04008947,  0.26690212, ...,  0.03724464,\n",
            "         -0.01971132,  1.        ]], dtype=float32)\n",
            " array([[-0.03717034, -0.15487479, -0.05429149, ...,  0.05998304,\n",
            "          0.2100968 ,  1.        ],\n",
            "        [ 0.14085196, -0.11585267, -0.07477669, ...,  0.2889399 ,\n",
            "          0.1629395 ,  1.        ],\n",
            "        [ 0.0826325 , -0.11465187, -0.07865882, ...,  0.39125404,\n",
            "          0.08738364,  1.        ],\n",
            "        ...,\n",
            "        [-0.17734234,  0.01842542,  0.2040422 , ...,  0.11326569,\n",
            "         -0.02530393,  1.        ],\n",
            "        [-0.25842777,  0.04154824,  0.20859168, ...,  0.08893543,\n",
            "         -0.06387255,  1.        ],\n",
            "        [-0.2762257 ,  0.01978214,  0.24222554, ...,  0.02581203,\n",
            "         -0.0344581 ,  1.        ]], dtype=float32)\n",
            " array([[-0.0336393 , -0.12539811, -0.03146144, ...,  0.05483415,\n",
            "          0.20751233,  1.        ],\n",
            "        [ 0.1356755 , -0.0614607 , -0.03728278, ...,  0.27076572,\n",
            "          0.14000796,  1.        ],\n",
            "        [ 0.10867351, -0.03773299, -0.03293828, ...,  0.36652443,\n",
            "          0.03326073,  1.        ],\n",
            "        ...,\n",
            "        [-0.14535618,  0.08727865,  0.23987915, ...,  0.09648173,\n",
            "         -0.00218932,  1.        ],\n",
            "        [-0.26086792,  0.07715517,  0.29857573, ...,  0.07471856,\n",
            "         -0.03596871,  1.        ],\n",
            "        [-0.3053042 ,  0.07950476,  0.28499228, ...,  0.03663596,\n",
            "         -0.01729793,  1.        ]], dtype=float32)\n",
            " array([[-0.03101509, -0.1498019 , -0.05729734, ...,  0.05671167,\n",
            "          0.19794136,  1.        ],\n",
            "        [ 0.11975449, -0.11994053, -0.06375244, ...,  0.24640249,\n",
            "          0.15868361,  1.        ],\n",
            "        [ 0.05387842, -0.11025222, -0.06727825, ...,  0.35581395,\n",
            "          0.08158293,  1.        ],\n",
            "        ...,\n",
            "        [-0.22605786,  0.0460932 ,  0.19379157, ...,  0.03789191,\n",
            "         -0.07259159,  1.        ],\n",
            "        [-0.2788449 ,  0.06465357,  0.21287726, ...,  0.04722018,\n",
            "         -0.07383545,  1.        ],\n",
            "        [-0.25693664,  0.04430884,  0.24236798, ...,  0.00389493,\n",
            "         -0.04734744,  1.        ]], dtype=float32)\n",
            " array([[-0.02084407, -0.13299084, -0.02814703, ...,  0.0509769 ,\n",
            "          0.21343417,  1.        ],\n",
            "        [ 0.13985944, -0.04385815, -0.00739694, ...,  0.24602982,\n",
            "          0.13042426,  1.        ],\n",
            "        [ 0.13809504,  0.01750345,  0.01255802, ...,  0.32490534,\n",
            "         -0.01531106,  1.        ],\n",
            "        ...,\n",
            "        [-0.07681226,  0.14845322,  0.22027017, ...,  0.05717247,\n",
            "          0.01091978,  1.        ],\n",
            "        [-0.24104057,  0.13808449,  0.3310934 , ...,  0.05992776,\n",
            "         -0.01638676,  1.        ],\n",
            "        [-0.28152603,  0.1035581 ,  0.2963377 , ...,  0.06333285,\n",
            "          0.00397496,  1.        ]], dtype=float32)\n",
            " array([[-2.1871775e-02, -1.3559297e-01, -2.8791467e-02, ...,\n",
            "          5.0658505e-02,  2.1625368e-01,  1.0000000e+00],\n",
            "        [ 1.3819921e-01, -3.6318917e-02, -3.9881266e-05, ...,\n",
            "          2.3540293e-01,  1.2788874e-01,  1.0000000e+00],\n",
            "        [ 1.3593541e-01,  2.2482596e-02,  2.3177011e-02, ...,\n",
            "          3.0770975e-01, -9.7789727e-03,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-6.3690953e-02,  1.5104571e-01,  2.1280241e-01, ...,\n",
            "          4.6791829e-02,  8.4836483e-03,  1.0000000e+00],\n",
            "        [-2.3571357e-01,  1.4274159e-01,  3.2910940e-01, ...,\n",
            "          5.1271260e-02, -2.3928257e-02,  1.0000000e+00],\n",
            "        [-2.7759281e-01,  1.0503897e-01,  2.9767990e-01, ...,\n",
            "          5.9458897e-02, -6.6378753e-04,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02750656, -0.13902315, -0.02766697, ...,  0.05354372,\n",
            "          0.21586345,  1.        ],\n",
            "        [ 0.1460187 , -0.04903478, -0.01141072, ...,  0.24945396,\n",
            "          0.14326991,  1.        ],\n",
            "        [ 0.13350022, -0.00462159,  0.01365329, ...,  0.33017448,\n",
            "          0.01351366,  1.        ],\n",
            "        ...,\n",
            "        [-0.12638694,  0.14504416,  0.24056558, ...,  0.05152893,\n",
            "         -0.00676483,  1.        ],\n",
            "        [-0.2507546 ,  0.12212608,  0.3149006 , ...,  0.05308526,\n",
            "         -0.03305648,  1.        ],\n",
            "        [-0.28851384,  0.0950767 ,  0.29059955, ...,  0.05567019,\n",
            "         -0.00739002,  1.        ]], dtype=float32)\n",
            " array([[-0.03818538, -0.14898574, -0.04481905, ...,  0.0611383 ,\n",
            "          0.21631691,  1.        ],\n",
            "        [ 0.15086734, -0.09781709, -0.05822209, ...,  0.28166297,\n",
            "          0.16930492,  1.        ],\n",
            "        [ 0.09784087, -0.08789875, -0.05717806, ...,  0.3811175 ,\n",
            "          0.08004008,  1.        ],\n",
            "        ...,\n",
            "        [-0.16812094,  0.02844981,  0.22647983, ...,  0.09386489,\n",
            "         -0.00291579,  1.        ],\n",
            "        [-0.26855242,  0.04154604,  0.24121183, ...,  0.07390713,\n",
            "         -0.04533592,  1.        ],\n",
            "        [-0.28653762,  0.04335836,  0.25795653, ...,  0.02904651,\n",
            "         -0.02236015,  1.        ]], dtype=float32)\n",
            " array([[-2.76312493e-02, -1.63131177e-01, -5.43858334e-02, ...,\n",
            "          5.91125078e-02,  2.11066097e-01,  1.00000000e+00],\n",
            "        [ 1.48447990e-01, -1.13568835e-01, -7.97445029e-02, ...,\n",
            "          2.95876235e-01,  1.53014332e-01,  1.00000000e+00],\n",
            "        [ 1.04347616e-01, -1.17433265e-01, -8.55437890e-02, ...,\n",
            "          3.87663782e-01,  7.90476874e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.17408693e-01, -2.55971472e-03,  1.85246795e-01, ...,\n",
            "          1.20077118e-01,  1.05352728e-02,  1.00000000e+00],\n",
            "        [-2.12437063e-01,  6.51258416e-03,  2.07204208e-01, ...,\n",
            "          9.17508379e-02, -3.24712768e-02,  1.00000000e+00],\n",
            "        [-2.59960473e-01,  8.85982357e-04,  2.34579027e-01, ...,\n",
            "          3.95771898e-02, -2.57599652e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.03412068, -0.13850042, -0.03505816, ...,  0.05116812,\n",
            "          0.2097725 ,  1.        ],\n",
            "        [ 0.14255813, -0.07409268, -0.05209228, ...,  0.27028537,\n",
            "          0.14892045,  1.        ],\n",
            "        [ 0.10400998, -0.06067442, -0.05461182, ...,  0.3603555 ,\n",
            "          0.05399377,  1.        ],\n",
            "        ...,\n",
            "        [-0.14482504,  0.06029013,  0.22464886, ...,  0.09311247,\n",
            "          0.01762944,  1.        ],\n",
            "        [-0.2528159 ,  0.04777799,  0.27840412, ...,  0.06805088,\n",
            "         -0.02741494,  1.        ],\n",
            "        [-0.3012873 ,  0.05683375,  0.2779629 , ...,  0.03494003,\n",
            "         -0.01946898,  1.        ]], dtype=float32)\n",
            " array([[-0.02886548, -0.12449797, -0.03036177, ...,  0.05629142,\n",
            "          0.20674373,  1.        ],\n",
            "        [ 0.14118113, -0.06020146, -0.03244468, ...,  0.2699048 ,\n",
            "          0.13714361,  1.        ],\n",
            "        [ 0.12132673, -0.03020318, -0.02170702, ...,  0.36947125,\n",
            "          0.01912845,  1.        ],\n",
            "        ...,\n",
            "        [-0.11765094,  0.09910337,  0.22180077, ...,  0.09992595,\n",
            "          0.00520168,  1.        ],\n",
            "        [-0.25070718,  0.09379808,  0.30131352, ...,  0.07742674,\n",
            "         -0.03064987,  1.        ],\n",
            "        [-0.30030936,  0.08563938,  0.28550544, ...,  0.04727111,\n",
            "         -0.01662379,  1.        ]], dtype=float32)\n",
            " array([[-0.02221464, -0.14394395, -0.02767006, ...,  0.05423588,\n",
            "          0.21872294,  1.        ],\n",
            "        [ 0.15990902, -0.05164197, -0.01347519, ...,  0.2564385 ,\n",
            "          0.14355691,  1.        ],\n",
            "        [ 0.13958666, -0.00898025,  0.01122297, ...,  0.33993158,\n",
            "          0.01652662,  1.        ],\n",
            "        ...,\n",
            "        [-0.09064334,  0.131477  ,  0.21016957, ...,  0.05373463,\n",
            "          0.00778559,  1.        ],\n",
            "        [-0.23041108,  0.11469637,  0.29503095, ...,  0.05496695,\n",
            "         -0.02792651,  1.        ],\n",
            "        [-0.27722627,  0.09217588,  0.2805818 , ...,  0.06469619,\n",
            "         -0.00709259,  1.        ]], dtype=float32)\n",
            " array([[-1.62547100e-02, -1.31162897e-01, -2.76014414e-02, ...,\n",
            "          4.93635163e-02,  2.12308109e-01,  1.00000000e+00],\n",
            "        [ 1.54924601e-01, -3.99009734e-02, -8.47013481e-03, ...,\n",
            "          2.73337394e-01,  1.29686207e-01,  1.00000000e+00],\n",
            "        [ 1.53393403e-01,  1.47189535e-02,  4.68068197e-03, ...,\n",
            "          3.56161654e-01,  4.87617217e-04,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-6.11137077e-02,  1.20918371e-01,  2.17081830e-01, ...,\n",
            "          9.60127562e-02,  1.51938153e-02,  1.00000000e+00],\n",
            "        [-2.26123169e-01,  1.19559214e-01,  3.25694621e-01, ...,\n",
            "          8.70376602e-02, -1.81722827e-02,  1.00000000e+00],\n",
            "        [-2.75623590e-01,  1.00747071e-01,  2.92828739e-01, ...,\n",
            "          6.30187541e-02,  2.09458033e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.00203614, -0.14430082, -0.07249292, ...,  0.03645103,\n",
            "          0.1673165 ,  1.        ],\n",
            "        [ 0.09609808, -0.12222248, -0.07003035, ...,  0.195878  ,\n",
            "          0.13859472,  1.        ],\n",
            "        [ 0.035801  , -0.1201084 , -0.09612063, ...,  0.27369064,\n",
            "          0.09515563,  1.        ],\n",
            "        ...,\n",
            "        [-0.12933055,  0.02802032,  0.28814837, ..., -0.0490549 ,\n",
            "         -0.10840733,  1.        ],\n",
            "        [-0.22313534,  0.09176616,  0.25234067, ..., -0.04568714,\n",
            "         -0.09880371,  1.        ],\n",
            "        [-0.17063633,  0.11416283,  0.25786182, ..., -0.07237053,\n",
            "         -0.07836438,  1.        ]], dtype=float32)\n",
            " array([[-0.01702367, -0.14696154, -0.06850561, ...,  0.04637748,\n",
            "          0.18078078,  1.        ],\n",
            "        [ 0.10440655, -0.12604195, -0.06266817, ...,  0.2151966 ,\n",
            "          0.14980498,  1.        ],\n",
            "        [ 0.03595306, -0.12478966, -0.07724659, ...,  0.32291615,\n",
            "          0.0882856 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.20562996,  0.04679383,  0.2362845 , ..., -0.04836201,\n",
            "         -0.09270799,  1.        ],\n",
            "        [-0.24787742,  0.07429554,  0.24161267, ..., -0.03931066,\n",
            "         -0.08914664,  1.        ],\n",
            "        [-0.19759843,  0.07815223,  0.25264156, ..., -0.04039843,\n",
            "         -0.06498374,  1.        ]], dtype=float32)\n",
            " array([[-0.03254446, -0.14841296, -0.03520915, ...,  0.06004139,\n",
            "          0.21676832,  1.        ],\n",
            "        [ 0.16530757, -0.0729377 , -0.04100109, ...,  0.2721064 ,\n",
            "          0.1663907 ,  1.        ],\n",
            "        [ 0.11943004, -0.05315332, -0.03067736, ...,  0.36183134,\n",
            "          0.06746417,  1.        ],\n",
            "        ...,\n",
            "        [-0.13186213,  0.07827557,  0.22226751, ...,  0.08227494,\n",
            "          0.01399958,  1.        ],\n",
            "        [-0.25733176,  0.06486786,  0.2715733 , ...,  0.06557511,\n",
            "         -0.03822632,  1.        ],\n",
            "        [-0.2906703 ,  0.05751087,  0.26931667, ...,  0.04269058,\n",
            "         -0.0213002 ,  1.        ]], dtype=float32)\n",
            " array([[-0.02358875, -0.1295714 , -0.02442043, ...,  0.04340508,\n",
            "          0.20874974,  1.        ],\n",
            "        [ 0.13293986, -0.04106189, -0.00289147, ...,  0.252484  ,\n",
            "          0.1281447 ,  1.        ],\n",
            "        [ 0.12223987,  0.00937365,  0.02038899, ...,  0.3344926 ,\n",
            "          0.00343188,  1.        ],\n",
            "        ...,\n",
            "        [-0.10729261,  0.13057432,  0.2460707 , ...,  0.0740962 ,\n",
            "         -0.00504111,  1.        ],\n",
            "        [-0.25425154,  0.12029061,  0.3426299 , ...,  0.06126398,\n",
            "         -0.03238735,  1.        ],\n",
            "        [-0.3014602 ,  0.09284016,  0.30512366, ...,  0.04801406,\n",
            "         -0.01356607,  1.        ]], dtype=float32)\n",
            " array([[-0.01477761, -0.12275053, -0.03565429, ...,  0.04553136,\n",
            "          0.21547523,  1.        ],\n",
            "        [ 0.1362724 , -0.02108545, -0.01439015, ...,  0.23300436,\n",
            "          0.12471341,  1.        ],\n",
            "        [ 0.14109854,  0.04058022,  0.00807565, ...,  0.31284797,\n",
            "         -0.03001533,  1.        ],\n",
            "        ...,\n",
            "        [-0.01371499,  0.1321714 ,  0.16546471, ...,  0.04285989,\n",
            "          0.02328623,  1.        ],\n",
            "        [-0.20797646,  0.13772494,  0.3219982 , ...,  0.05258898,\n",
            "         -0.0105988 ,  1.        ],\n",
            "        [-0.26914018,  0.09968583,  0.29527497, ...,  0.0606435 ,\n",
            "         -0.00373883,  1.        ]], dtype=float32)\n",
            " array([[-0.01880161, -0.14755398, -0.03450478, ...,  0.05681061,\n",
            "          0.22038174,  1.        ],\n",
            "        [ 0.16727418, -0.0487203 , -0.02929938, ...,  0.27228254,\n",
            "          0.14221407,  1.        ],\n",
            "        [ 0.14685504, -0.01380308, -0.00916707, ...,  0.3558128 ,\n",
            "          0.01704977,  1.        ],\n",
            "        ...,\n",
            "        [-0.05135368,  0.10115176,  0.15885057, ...,  0.06109716,\n",
            "          0.02274592,  1.        ],\n",
            "        [-0.20687954,  0.09703857,  0.26557007, ...,  0.05985159,\n",
            "         -0.02921306,  1.        ],\n",
            "        [-0.2666497 ,  0.07472734,  0.26889417, ...,  0.06719336,\n",
            "         -0.01412373,  1.        ]], dtype=float32)\n",
            " array([[-3.2078370e-02, -1.5021740e-01, -4.0992688e-02, ...,\n",
            "          6.1970983e-02,  2.1797320e-01,  1.0000000e+00],\n",
            "        [ 1.6833924e-01, -7.9374626e-02, -5.4502975e-02, ...,\n",
            "          2.8696930e-01,  1.6513966e-01,  1.0000000e+00],\n",
            "        [ 1.2339974e-01, -6.6018119e-02, -4.8858214e-02, ...,\n",
            "          3.8119048e-01,  6.7405172e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.4040321e-01,  4.8622198e-02,  2.1850057e-01, ...,\n",
            "          8.2022242e-02,  2.5784236e-04,  1.0000000e+00],\n",
            "        [-2.4322325e-01,  5.2371264e-02,  2.5002986e-01, ...,\n",
            "          7.3669344e-02, -3.8192261e-02,  1.0000000e+00],\n",
            "        [-2.8261223e-01,  4.0713195e-02,  2.5855127e-01, ...,\n",
            "          3.8047910e-02, -2.0551918e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-1.17255533e-02, -1.22827418e-01, -3.09224948e-02, ...,\n",
            "          4.55951132e-02,  2.11059213e-01,  2.00000000e+00],\n",
            "        [ 1.55884922e-01, -2.33472697e-02, -1.15256859e-02, ...,\n",
            "          2.62945831e-01,  1.17339373e-01,  2.00000000e+00],\n",
            "        [ 1.61541626e-01,  4.30358164e-02,  2.15177028e-03, ...,\n",
            "          3.36109191e-01, -2.40114368e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.75578683e-03,  1.20297931e-01,  1.71115667e-01, ...,\n",
            "          7.55768195e-02,  3.32774445e-02,  2.00000000e+00],\n",
            "        [-2.04998478e-01,  1.24247685e-01,  3.28625530e-01, ...,\n",
            "          8.29735845e-02, -2.31205323e-03,  2.00000000e+00],\n",
            "        [-2.62021065e-01,  1.07166938e-01,  2.93840945e-01, ...,\n",
            "          6.09917194e-02,  7.03007542e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02452481, -0.1580924 , -0.06325781, ...,  0.05348477,\n",
            "          0.18438265,  2.        ],\n",
            "        [ 0.11129352, -0.13333535, -0.06279344, ...,  0.24354734,\n",
            "          0.14951049,  2.        ],\n",
            "        [ 0.0435982 , -0.13366832, -0.07917896, ...,  0.3410806 ,\n",
            "          0.08978602,  2.        ],\n",
            "        ...,\n",
            "        [-0.22415729,  0.04971977,  0.20273036, ..., -0.00737837,\n",
            "         -0.08866555,  2.        ],\n",
            "        [-0.26265922,  0.06759165,  0.20953698, ...,  0.00410016,\n",
            "         -0.08328262,  2.        ],\n",
            "        [-0.22577104,  0.03741316,  0.2346817 , ..., -0.02523686,\n",
            "         -0.0555364 ,  2.        ]], dtype=float32)\n",
            " array([[-0.03627414, -0.15161663, -0.04899341, ...,  0.06530434,\n",
            "          0.21155344,  2.        ],\n",
            "        [ 0.15872571, -0.10268603, -0.05855017, ...,  0.29826385,\n",
            "          0.16594444,  2.        ],\n",
            "        [ 0.10501091, -0.09552787, -0.05671069, ...,  0.4015281 ,\n",
            "          0.0778999 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.16473278,  0.03435559,  0.21576667, ...,  0.10745205,\n",
            "         -0.01116336,  2.        ],\n",
            "        [-0.26095748,  0.05643121,  0.22251926, ...,  0.0864609 ,\n",
            "         -0.05223651,  2.        ],\n",
            "        [-0.27087423,  0.04032133,  0.24408753, ...,  0.03381633,\n",
            "         -0.02545036,  2.        ]], dtype=float32)\n",
            " array([[-2.4939422e-02, -1.3292848e-01, -2.4406973e-02, ...,\n",
            "          4.4255268e-02,  2.0841897e-01,  2.0000000e+00],\n",
            "        [ 1.3504113e-01, -4.5279048e-02, -2.4268590e-03, ...,\n",
            "          2.4951661e-01,  1.3070716e-01,  2.0000000e+00],\n",
            "        [ 1.2007419e-01, -8.3314267e-04,  2.0617727e-02, ...,\n",
            "          3.3244476e-01,  9.1180373e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1247543e-01,  1.2968808e-01,  2.4567109e-01, ...,\n",
            "          7.3087044e-02, -2.1623403e-03,  2.0000000e+00],\n",
            "        [-2.5571692e-01,  1.2216800e-01,  3.3720601e-01, ...,\n",
            "          5.9609678e-02, -3.2654107e-02,  2.0000000e+00],\n",
            "        [-3.0304223e-01,  9.3342759e-02,  3.0124202e-01, ...,\n",
            "          4.5531545e-02, -1.4059771e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.57124212e-02, -1.37678728e-01, -2.75823697e-02, ...,\n",
            "          5.28977364e-02,  2.15140745e-01,  2.00000000e+00],\n",
            "        [ 1.51528448e-01, -4.70893681e-02, -8.12419783e-03, ...,\n",
            "          2.58076727e-01,  1.35931417e-01,  2.00000000e+00],\n",
            "        [ 1.35759234e-01,  5.87299350e-04,  1.70746502e-02, ...,\n",
            "          3.39030534e-01,  9.95391607e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.24688581e-01,  1.42474458e-01,  2.46376306e-01, ...,\n",
            "          6.17584214e-02, -1.15233101e-02,  2.00000000e+00],\n",
            "        [-2.50203907e-01,  1.25489488e-01,  3.20384085e-01, ...,\n",
            "          5.99763878e-02, -3.71855311e-02,  2.00000000e+00],\n",
            "        [-2.90288389e-01,  9.37921926e-02,  2.95369714e-01, ...,\n",
            "          5.79355918e-02, -1.10051995e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02076443, -0.12445816, -0.02650813, ...,  0.03748032,\n",
            "          0.2076035 ,  2.        ],\n",
            "        [ 0.12356376, -0.02424166,  0.00640942, ...,  0.22847977,\n",
            "          0.11285189,  2.        ],\n",
            "        [ 0.1225436 ,  0.0363031 ,  0.02718842, ...,  0.30279246,\n",
            "         -0.02254261,  2.        ],\n",
            "        ...,\n",
            "        [-0.04383318,  0.13592292,  0.20867425, ...,  0.0391182 ,\n",
            "          0.02335222,  2.        ],\n",
            "        [-0.23185806,  0.12688823,  0.35179836, ...,  0.04387961,\n",
            "         -0.01291472,  2.        ],\n",
            "        [-0.29118806,  0.09903164,  0.30936676, ...,  0.04061497,\n",
            "         -0.00389168,  2.        ]], dtype=float32)\n",
            " array([[-0.01652215, -0.11608578, -0.03778841, ...,  0.04734511,\n",
            "          0.21286939,  2.        ],\n",
            "        [ 0.13548103, -0.02044505, -0.01561737, ...,  0.2428149 ,\n",
            "          0.11232271,  2.        ],\n",
            "        [ 0.14351231,  0.04840067,  0.00518003, ...,  0.31243047,\n",
            "         -0.04535107,  2.        ],\n",
            "        ...,\n",
            "        [-0.02169414,  0.13638294,  0.18179055, ...,  0.04813622,\n",
            "          0.0100375 ,  2.        ],\n",
            "        [-0.21895885,  0.13756584,  0.33572578, ...,  0.06580136,\n",
            "         -0.01500245,  2.        ],\n",
            "        [-0.2717496 ,  0.10782441,  0.30496997, ...,  0.06798729,\n",
            "          0.0067237 ,  2.        ]], dtype=float32)\n",
            " array([[-0.03395514, -0.14447132, -0.03324958, ...,  0.05882109,\n",
            "          0.2117377 ,  2.        ],\n",
            "        [ 0.16430365, -0.06914343, -0.03584979, ...,  0.26845998,\n",
            "          0.15222892,  2.        ],\n",
            "        [ 0.12239945, -0.04812844, -0.0233942 , ...,  0.35400167,\n",
            "          0.0518944 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.14779297,  0.08557077,  0.23910731, ...,  0.07323747,\n",
            "         -0.00362661,  2.        ],\n",
            "        [-0.26188895,  0.06800286,  0.27909443, ...,  0.06386506,\n",
            "         -0.04171513,  2.        ],\n",
            "        [-0.2876687 ,  0.07144515,  0.27100027, ...,  0.04565222,\n",
            "         -0.01911933,  2.        ]], dtype=float32)\n",
            " array([[ 0.00657338, -0.10934892, -0.05444293, ...,  0.03964962,\n",
            "          0.20510148,  2.        ],\n",
            "        [ 0.18573178, -0.00241047, -0.04625988, ...,  0.2551872 ,\n",
            "          0.05645086,  2.        ],\n",
            "        [ 0.198127  ,  0.0562714 , -0.0450359 , ...,  0.31480742,\n",
            "         -0.07841921,  2.        ],\n",
            "        ...,\n",
            "        [ 0.11308608,  0.0679331 ,  0.01568196, ...,  0.06408984,\n",
            "          0.07244489,  2.        ],\n",
            "        [-0.1240731 ,  0.12109364,  0.28819096, ...,  0.11278326,\n",
            "         -0.00497006,  2.        ],\n",
            "        [-0.23702429,  0.10291395,  0.28212672, ...,  0.06844807,\n",
            "          0.00495235,  2.        ]], dtype=float32)\n",
            " array([[-1.19837904e-02, -1.21344559e-01, -3.20382304e-02, ...,\n",
            "          4.63971682e-02,  2.09740534e-01,  2.00000000e+00],\n",
            "        [ 1.49851426e-01, -2.23231744e-02, -1.33220702e-02, ...,\n",
            "          2.59419918e-01,  1.12829894e-01,  2.00000000e+00],\n",
            "        [ 1.57352686e-01,  4.61911596e-02, -8.27614567e-04, ...,\n",
            "          3.32041740e-01, -3.09966225e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 5.14029618e-03,  1.22721620e-01,  1.66899607e-01, ...,\n",
            "          6.94432855e-02,  3.33689228e-02,  2.00000000e+00],\n",
            "        [-2.06252992e-01,  1.25126079e-01,  3.29328179e-01, ...,\n",
            "          8.26353133e-02, -1.04629924e-03,  2.00000000e+00],\n",
            "        [-2.61112362e-01,  1.07754119e-01,  2.93283284e-01, ...,\n",
            "          6.00712337e-02,  8.65787268e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-3.4596302e-02, -1.3074453e-01, -2.8557148e-02, ...,\n",
            "          5.7996705e-02,  2.1014571e-01,  2.0000000e+00],\n",
            "        [ 1.5636081e-01, -5.4877631e-02, -2.4235526e-02, ...,\n",
            "          2.5508374e-01,  1.4573231e-01,  2.0000000e+00],\n",
            "        [ 1.2734124e-01, -2.3957791e-02, -9.5521042e-04, ...,\n",
            "          3.4167239e-01,  3.8847979e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.6026354e-01,  1.2411282e-01,  2.5882834e-01, ...,\n",
            "          6.5361321e-02, -9.2375418e-03,  2.0000000e+00],\n",
            "        [-2.6895553e-01,  1.0609480e-01,  3.0502355e-01, ...,\n",
            "          6.3293800e-02, -3.9318427e-02,  2.0000000e+00],\n",
            "        [-2.9956961e-01,  8.8912658e-02,  2.8473508e-01, ...,\n",
            "          4.2923652e-02, -1.6786836e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-3.08292620e-02, -1.23229355e-01, -2.86257956e-02, ...,\n",
            "          5.47434427e-02,  2.06777111e-01,  2.00000000e+00],\n",
            "        [ 1.38850167e-01, -5.52961417e-02, -2.82574743e-02, ...,\n",
            "          2.55264819e-01,  1.42011464e-01,  2.00000000e+00],\n",
            "        [ 1.18607797e-01, -2.55587902e-02, -1.32345352e-02, ...,\n",
            "          3.50603729e-01,  2.43637599e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.31162927e-01,  1.10822208e-01,  2.37128466e-01, ...,\n",
            "          8.36235806e-02,  1.74818200e-03,  2.00000000e+00],\n",
            "        [-2.60227501e-01,  1.00169308e-01,  3.10377151e-01, ...,\n",
            "          6.70051351e-02, -3.26590128e-02,  2.00000000e+00],\n",
            "        [-3.04867774e-01,  8.87634456e-02,  2.88562566e-01, ...,\n",
            "          4.41723689e-02, -1.76462345e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-5.0604274e-03, -1.1046249e-01, -5.2190464e-02, ...,\n",
            "          4.6180844e-02,  2.1384330e-01,  2.0000000e+00],\n",
            "        [ 1.5505765e-01, -2.1548562e-03, -3.6107231e-02, ...,\n",
            "          2.3563389e-01,  1.0780812e-01,  2.0000000e+00],\n",
            "        [ 1.6189930e-01,  5.4963782e-02, -1.7825378e-02, ...,\n",
            "          3.1287622e-01, -5.5065520e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.7091344e-02,  1.1605086e-01,  9.1365717e-02, ...,\n",
            "          3.2839194e-02,  4.4907540e-02,  2.0000000e+00],\n",
            "        [-1.6713937e-01,  1.4378312e-01,  2.9216138e-01, ...,\n",
            "          6.8425372e-02, -1.2239830e-03,  2.0000000e+00],\n",
            "        [-2.5569117e-01,  1.0733314e-01,  2.8324395e-01, ...,\n",
            "          7.0208959e-02,  8.0638826e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01881506, -0.12348311, -0.03160955, ...,  0.03867479,\n",
            "          0.20526557,  2.        ],\n",
            "        [ 0.13348669, -0.01774411, -0.0032661 , ...,  0.24006407,\n",
            "          0.10347437,  2.        ],\n",
            "        [ 0.13389052,  0.04470397,  0.01371646, ...,  0.31258443,\n",
            "         -0.03750933,  2.        ],\n",
            "        ...,\n",
            "        [-0.01084498,  0.13068606,  0.16865276, ...,  0.04604613,\n",
            "          0.02677535,  2.        ],\n",
            "        [-0.21725225,  0.12429554,  0.33336052, ...,  0.05380963,\n",
            "         -0.01344587,  2.        ],\n",
            "        [-0.2806811 ,  0.0978268 ,  0.30186728, ...,  0.04348883,\n",
            "         -0.0040317 ,  2.        ]], dtype=float32)\n",
            " array([[-2.32305713e-02, -1.29817262e-01, -2.48768814e-02, ...,\n",
            "          4.25917916e-02,  2.08857432e-01,  2.00000000e+00],\n",
            "        [ 1.33111328e-01, -3.90970893e-02,  6.74937735e-04, ...,\n",
            "          2.45802626e-01,  1.27214581e-01,  2.00000000e+00],\n",
            "        [ 1.25480637e-01,  1.40291825e-02,  2.40235478e-02, ...,\n",
            "          3.24861079e-01, -1.46323943e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-8.80111307e-02,  1.34226039e-01,  2.34887213e-01, ...,\n",
            "          6.74576908e-02,  3.47331259e-03,  2.00000000e+00],\n",
            "        [-2.49679655e-01,  1.26613915e-01,  3.44497651e-01, ...,\n",
            "          5.53678125e-02, -2.52898261e-02,  2.00000000e+00],\n",
            "        [-2.98288703e-01,  9.57650095e-02,  3.02645594e-01, ...,\n",
            "          4.57200892e-02, -9.85622872e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02516603, -0.14478306, -0.04454501, ...,  0.06732181,\n",
            "          0.21172825,  2.        ],\n",
            "        [ 0.15980521, -0.07893296, -0.06871942, ...,  0.3029888 ,\n",
            "          0.13846412,  2.        ],\n",
            "        [ 0.13565306, -0.06546146, -0.07597163, ...,  0.39569122,\n",
            "          0.03393065,  2.        ],\n",
            "        ...,\n",
            "        [-0.08977001,  0.02059223,  0.1698114 , ...,  0.10849401,\n",
            "          0.03128558,  2.        ],\n",
            "        [-0.20085818,  0.02670127,  0.23920345, ...,  0.09089978,\n",
            "         -0.01465718,  2.        ],\n",
            "        [-0.2648852 ,  0.0369721 ,  0.24905232, ...,  0.0599275 ,\n",
            "         -0.01579564,  2.        ]], dtype=float32)\n",
            " array([[-2.49218550e-02, -1.30810365e-01, -2.63516475e-02, ...,\n",
            "          4.62548174e-02,  2.15833157e-01,  2.00000000e+00],\n",
            "        [ 1.30697429e-01, -3.86050045e-02,  1.33059116e-03, ...,\n",
            "          2.24481195e-01,  1.35631129e-01,  2.00000000e+00],\n",
            "        [ 1.24524578e-01,  1.49323428e-02,  2.50468962e-02, ...,\n",
            "          3.01162183e-01, -3.67852999e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-7.21338168e-02,  1.49186492e-01,  2.20023677e-01, ...,\n",
            "          2.79017817e-02,  1.63179636e-02,  2.00000000e+00],\n",
            "        [-2.42132902e-01,  1.41294152e-01,  3.35723758e-01, ...,\n",
            "          3.97580788e-02, -1.51498523e-02,  2.00000000e+00],\n",
            "        [-2.92989492e-01,  1.00346588e-01,  2.99632818e-01, ...,\n",
            "          5.08317463e-02,  1.05099054e-04,  2.00000000e+00]], dtype=float32)\n",
            " array([[-3.2962184e-02, -1.2390009e-01, -3.0649470e-02, ...,\n",
            "          5.5099986e-02,  2.0647901e-01,  2.0000000e+00],\n",
            "        [ 1.3820404e-01, -5.5824146e-02, -2.8857283e-02, ...,\n",
            "          2.6068461e-01,  1.3869713e-01,  2.0000000e+00],\n",
            "        [ 1.1663206e-01, -2.5452558e-02, -1.4354622e-02, ...,\n",
            "          3.5408944e-01,  2.5178244e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.3712700e-01,  1.0336951e-01,  2.3864737e-01, ...,\n",
            "          8.7545373e-02, -1.2754719e-03,  2.0000000e+00],\n",
            "        [-2.5956970e-01,  9.2517287e-02,  3.0815434e-01, ...,\n",
            "          6.7634188e-02, -3.6932334e-02,  2.0000000e+00],\n",
            "        [-3.0457088e-01,  8.7667853e-02,  2.8941387e-01, ...,\n",
            "          3.7360560e-02, -1.6184710e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.7306155e-02, -1.2979585e-01, -3.8082547e-02, ...,\n",
            "          5.0144423e-02,  2.1947455e-01,  2.0000000e+00],\n",
            "        [ 1.4094961e-01, -3.1096123e-02, -1.2578886e-02, ...,\n",
            "          2.4793471e-01,  1.3041405e-01,  2.0000000e+00],\n",
            "        [ 1.4302719e-01,  3.1507056e-02,  7.9716723e-03, ...,\n",
            "          3.2390609e-01, -1.7212566e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-3.3925667e-02,  1.4426959e-01,  1.7870738e-01, ...,\n",
            "          5.6713074e-02,  2.7998723e-02,  2.0000000e+00],\n",
            "        [-2.1521388e-01,  1.4332306e-01,  3.1769359e-01, ...,\n",
            "          6.6155434e-02, -1.3733521e-02,  2.0000000e+00],\n",
            "        [-2.7182284e-01,  1.0166121e-01,  2.9328132e-01, ...,\n",
            "          7.1439102e-02, -8.7511784e-05,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.3148237e-02, -1.2475367e-01, -3.1022767e-02, ...,\n",
            "          4.4497781e-02,  2.0977940e-01,  2.0000000e+00],\n",
            "        [ 1.5401822e-01, -2.2238828e-02, -9.3844878e-03, ...,\n",
            "          2.6601252e-01,  1.1310957e-01,  2.0000000e+00],\n",
            "        [ 1.5963955e-01,  4.1096888e-02,  3.5403848e-03, ...,\n",
            "          3.3764350e-01, -2.4568589e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-8.5521629e-04,  1.2108675e-01,  1.6884623e-01, ...,\n",
            "          7.9212956e-02,  3.0083746e-02,  2.0000000e+00],\n",
            "        [-2.0465374e-01,  1.2580752e-01,  3.2465303e-01, ...,\n",
            "          8.1333153e-02, -5.2719563e-03,  2.0000000e+00],\n",
            "        [-2.6283294e-01,  1.0672572e-01,  2.9270330e-01, ...,\n",
            "          5.8747970e-02,  5.9541198e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02224377, -0.12836474, -0.02550164, ...,  0.0410096 ,\n",
            "          0.20730962,  2.        ],\n",
            "        [ 0.13599949, -0.03467594,  0.00283985, ...,  0.24863409,\n",
            "          0.1203284 ,  2.        ],\n",
            "        [ 0.12937605,  0.01963042,  0.02408848, ...,  0.32728136,\n",
            "         -0.00863014,  2.        ],\n",
            "        ...,\n",
            "        [-0.07457536,  0.13075694,  0.22406784, ...,  0.06820614,\n",
            "          0.00601674,  2.        ],\n",
            "        [-0.24408574,  0.12820028,  0.34105483, ...,  0.05649285,\n",
            "         -0.02467367,  2.        ],\n",
            "        [-0.29559502,  0.0998183 ,  0.30220404, ...,  0.0444949 ,\n",
            "         -0.00783281,  2.        ]], dtype=float32)\n",
            " array([[-2.23385431e-02, -1.31097749e-01, -2.53374651e-02, ...,\n",
            "          4.16971631e-02,  2.07570076e-01,  2.00000000e+00],\n",
            "        [ 1.32328972e-01, -4.44836393e-02,  2.10602582e-03, ...,\n",
            "          2.46231362e-01,  1.25475019e-01,  2.00000000e+00],\n",
            "        [ 1.18243925e-01,  2.64030386e-04,  2.24442221e-02, ...,\n",
            "          3.27915907e-01,  3.68924323e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.09913751e-01,  1.29907593e-01,  2.40356311e-01, ...,\n",
            "          6.79700077e-02, -3.80022754e-03,  2.00000000e+00],\n",
            "        [-2.52574772e-01,  1.27242252e-01,  3.36759984e-01, ...,\n",
            "          5.54371066e-02, -3.39922272e-02,  2.00000000e+00],\n",
            "        [-2.98510998e-01,  9.66253579e-02,  3.03379208e-01, ...,\n",
            "          4.31055464e-02, -1.21820820e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-1.34129375e-02, -1.24897219e-01, -4.07704338e-02, ...,\n",
            "          4.99238037e-02,  2.14064270e-01,  2.00000000e+00],\n",
            "        [ 1.48059398e-01, -2.76196506e-02, -1.91138703e-02, ...,\n",
            "          2.46981233e-01,  1.18498333e-01,  2.00000000e+00],\n",
            "        [ 1.50024459e-01,  4.12560664e-02,  6.61621278e-04, ...,\n",
            "          3.27255338e-01, -3.96292210e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.61985382e-02,  1.32643551e-01,  1.65899113e-01, ...,\n",
            "          5.75355738e-02,  2.64424775e-02,  2.00000000e+00],\n",
            "        [-2.08695754e-01,  1.34737134e-01,  3.09558600e-01, ...,\n",
            "          7.08854347e-02, -6.99107116e-03,  2.00000000e+00],\n",
            "        [-2.67086506e-01,  1.06613830e-01,  2.87256151e-01, ...,\n",
            "          7.57454783e-02,  9.09514073e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.07222197e-02, -1.37465760e-01, -3.17428224e-02, ...,\n",
            "          5.76602630e-02,  2.17638463e-01,  2.00000000e+00],\n",
            "        [ 1.48352802e-01, -4.68592346e-02, -9.98358708e-03, ...,\n",
            "          2.45579422e-01,  1.41183659e-01,  2.00000000e+00],\n",
            "        [ 1.38662994e-01,  4.41700220e-04,  1.01931663e-02, ...,\n",
            "          3.28848451e-01,  3.83896893e-03,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.13264322e-01,  1.55425295e-01,  2.39181116e-01, ...,\n",
            "          6.76155537e-02, -5.32507244e-03,  2.00000000e+00],\n",
            "        [-2.48194292e-01,  1.32772475e-01,  3.23454320e-01, ...,\n",
            "          6.39059842e-02, -3.24430838e-02,  2.00000000e+00],\n",
            "        [-2.77297676e-01,  1.04316734e-01,  2.87861735e-01, ...,\n",
            "          6.91366345e-02, -2.53769592e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02031211, -0.12915096, -0.02845856, ...,  0.04276435,\n",
            "          0.20801662,  2.        ],\n",
            "        [ 0.13764757, -0.03560758, -0.00645812, ...,  0.2514546 ,\n",
            "          0.12265014,  2.        ],\n",
            "        [ 0.13185413,  0.02082645,  0.01455482, ...,  0.33419973,\n",
            "         -0.01484672,  2.        ],\n",
            "        ...,\n",
            "        [-0.05257419,  0.1271087 ,  0.20342343, ...,  0.07521813,\n",
            "          0.01449399,  2.        ],\n",
            "        [-0.23323841,  0.1246163 ,  0.33372548, ...,  0.06589407,\n",
            "         -0.01749287,  2.        ],\n",
            "        [-0.28863367,  0.09449816,  0.29768506, ...,  0.05164852,\n",
            "         -0.00850087,  2.        ]], dtype=float32)\n",
            " array([[-2.0037655e-02, -1.1978098e-01, -3.0170292e-02, ...,\n",
            "          3.5418410e-02,  2.0429365e-01,  2.0000000e+00],\n",
            "        [ 1.2173709e-01, -2.5461858e-02,  2.1716987e-03, ...,\n",
            "          2.2961934e-01,  1.0186598e-01,  2.0000000e+00],\n",
            "        [ 1.2629871e-01,  4.3784294e-02,  2.3068804e-02, ...,\n",
            "          3.0228165e-01, -4.4055905e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-2.9574756e-02,  1.3173069e-01,  1.9335042e-01, ...,\n",
            "          3.7330076e-02,  2.3410317e-02,  2.0000000e+00],\n",
            "        [-2.2569555e-01,  1.3060229e-01,  3.4722281e-01, ...,\n",
            "          4.5026131e-02, -1.2065740e-02,  2.0000000e+00],\n",
            "        [-2.8837860e-01,  9.9008590e-02,  3.0708870e-01, ...,\n",
            "          3.9304323e-02, -1.5556209e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.5139801e-02, -1.2950367e-01, -2.3249447e-02, ...,\n",
            "          4.0600158e-02,  2.0807411e-01,  2.0000000e+00],\n",
            "        [ 1.2812372e-01, -4.5036256e-02, -1.5361825e-04, ...,\n",
            "          2.3949033e-01,  1.3001101e-01,  2.0000000e+00],\n",
            "        [ 1.1218317e-01, -1.1441960e-03,  2.2887692e-02, ...,\n",
            "          3.2011425e-01,  9.2830937e-03,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2808272e-01,  1.3240941e-01,  2.5896722e-01, ...,\n",
            "          6.0271211e-02, -7.9105226e-03,  2.0000000e+00],\n",
            "        [-2.6024410e-01,  1.2853186e-01,  3.4524852e-01, ...,\n",
            "          5.0656628e-02, -3.7894186e-02,  2.0000000e+00],\n",
            "        [-3.0402216e-01,  9.4690926e-02,  3.0927253e-01, ...,\n",
            "          4.1006982e-02, -1.6147817e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-3.1330071e-02, -1.3249075e-01, -3.6486987e-02, ...,\n",
            "          6.9723345e-02,  2.1431573e-01,  2.0000000e+00],\n",
            "        [ 1.7166644e-01, -5.2386861e-02, -3.9597120e-02, ...,\n",
            "          2.9092634e-01,  1.4307548e-01,  2.0000000e+00],\n",
            "        [ 1.4459223e-01, -2.7026486e-02, -2.7210077e-02, ...,\n",
            "          3.8596356e-01,  3.4624096e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1478408e-01,  9.5964342e-02,  2.2171518e-01, ...,\n",
            "          9.5824867e-02, -1.1567790e-03,  2.0000000e+00],\n",
            "        [-2.5147003e-01,  8.2127117e-02,  2.8214130e-01, ...,\n",
            "          7.9910159e-02, -3.8356688e-02,  2.0000000e+00],\n",
            "        [-2.8392622e-01,  8.6257935e-02,  2.7468219e-01, ...,\n",
            "          5.6677688e-02, -1.4903331e-02,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.37155557e-02, -1.36514366e-01, -2.73607653e-02, ...,\n",
            "          4.77112569e-02,  2.09797099e-01,  2.00000000e+00],\n",
            "        [ 1.41396374e-01, -4.79958877e-02, -1.25873294e-02, ...,\n",
            "          2.64617145e-01,  1.35055840e-01,  2.00000000e+00],\n",
            "        [ 1.24493368e-01, -8.82514101e-03,  4.88124462e-03, ...,\n",
            "          3.51857483e-01,  1.39213791e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.09077603e-01,  1.18689284e-01,  2.31373638e-01, ...,\n",
            "          8.65580663e-02, -1.84657122e-03,  2.00000000e+00],\n",
            "        [-2.45546311e-01,  1.07601732e-01,  3.17167580e-01, ...,\n",
            "          6.81548044e-02, -3.15974206e-02,  2.00000000e+00],\n",
            "        [-2.97040403e-01,  8.56229290e-02,  2.92292833e-01, ...,\n",
            "          5.14542162e-02, -1.61537994e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01675459, -0.13241827, -0.032689  , ...,  0.05262958,\n",
            "          0.21887803,  2.        ],\n",
            "        [ 0.14886928, -0.04207616, -0.00785744, ...,  0.22803621,\n",
            "          0.13622868,  2.        ],\n",
            "        [ 0.13419579,  0.0153581 ,  0.01425529, ...,  0.30776426,\n",
            "         -0.01679922,  2.        ],\n",
            "        ...,\n",
            "        [-0.03175871,  0.1653944 ,  0.18082586, ...,  0.03037728,\n",
            "          0.02639674,  2.        ],\n",
            "        [-0.2139191 ,  0.14355816,  0.30802855, ...,  0.04322098,\n",
            "         -0.0078003 ,  2.        ],\n",
            "        [-0.26284212,  0.10780862,  0.28411594, ...,  0.06946221,\n",
            "          0.00325738,  2.        ]], dtype=float32)\n",
            " array([[-0.02315804, -0.13105212, -0.02957999, ...,  0.05058012,\n",
            "          0.21779229,  2.        ],\n",
            "        [ 0.13500243, -0.04281001, -0.00599558, ...,  0.24147137,\n",
            "          0.13343133,  2.        ],\n",
            "        [ 0.1327176 ,  0.01514635,  0.0151702 , ...,  0.32055983,\n",
            "         -0.00913312,  2.        ],\n",
            "        ...,\n",
            "        [-0.08486824,  0.14371964,  0.22855704, ...,  0.05478474,\n",
            "          0.0047828 ,  2.        ],\n",
            "        [-0.24718095,  0.13743573,  0.34020722, ...,  0.05599689,\n",
            "         -0.02291211,  2.        ],\n",
            "        [-0.287544  ,  0.10259891,  0.30054224, ...,  0.0632908 ,\n",
            "          0.00343905,  2.        ]], dtype=float32)\n",
            " array([[-7.7940100e-03, -1.1643796e-01, -4.3582514e-02, ...,\n",
            "          5.3988211e-02,  2.1529178e-01,  2.0000000e+00],\n",
            "        [ 1.4509822e-01, -2.8723530e-02, -2.1687731e-02, ...,\n",
            "          2.2319825e-01,  1.2777384e-01,  2.0000000e+00],\n",
            "        [ 1.3413145e-01,  3.0275291e-02, -3.5851449e-03, ...,\n",
            "          3.0367231e-01, -3.3799212e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.8159100e-03,  1.5032670e-01,  1.5748312e-01, ...,\n",
            "          4.3063663e-02,  3.6915720e-02,  2.0000000e+00],\n",
            "        [-1.9865984e-01,  1.4176518e-01,  3.1283826e-01, ...,\n",
            "          7.0267342e-02,  2.0794226e-03,  2.0000000e+00],\n",
            "        [-2.6058626e-01,  1.0730313e-01,  2.8934407e-01, ...,\n",
            "          7.2475672e-02,  6.2499903e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.03322813, -0.15457344, -0.05493136, ...,  0.06758822,\n",
            "          0.21175443,  2.        ],\n",
            "        [ 0.15497558, -0.10882518, -0.0715786 , ...,  0.30076215,\n",
            "          0.1533947 ,  2.        ],\n",
            "        [ 0.09975222, -0.10446794, -0.07174235, ...,  0.4085411 ,\n",
            "          0.06590702,  2.        ],\n",
            "        ...,\n",
            "        [-0.15233186,  0.02202589,  0.2003221 , ...,  0.11222131,\n",
            "         -0.01189366,  2.        ],\n",
            "        [-0.24517098,  0.04727799,  0.209348  , ...,  0.09459784,\n",
            "         -0.05323811,  2.        ],\n",
            "        [-0.26455003,  0.02958842,  0.23689415, ...,  0.03572473,\n",
            "         -0.02923426,  2.        ]], dtype=float32)\n",
            " array([[-1.0961010e-02, -1.1829240e-01, -3.2807030e-02, ...,\n",
            "          4.4310626e-02,  2.0977457e-01,  2.0000000e+00],\n",
            "        [ 1.4979300e-01, -1.9967010e-02, -1.3981996e-02, ...,\n",
            "          2.5452507e-01,  1.0565123e-01,  2.0000000e+00],\n",
            "        [ 1.6012771e-01,  5.0605919e-02, -1.6475912e-03, ...,\n",
            "          3.2395917e-01, -4.1054353e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.7676342e-02,  1.2082475e-01,  1.5174958e-01, ...,\n",
            "          6.2006809e-02,  3.9839938e-02,  2.0000000e+00],\n",
            "        [-1.9551668e-01,  1.2543394e-01,  3.2776549e-01, ...,\n",
            "          8.4084079e-02,  9.3515473e-04,  2.0000000e+00],\n",
            "        [-2.5973991e-01,  1.0983435e-01,  2.9542759e-01, ...,\n",
            "          5.8481328e-02,  8.4540630e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.03322137, -0.12316255, -0.03054539, ...,  0.05296833,\n",
            "          0.20517229,  2.        ],\n",
            "        [ 0.13133703, -0.05924057, -0.0300845 , ...,  0.25436956,\n",
            "          0.13921441,  2.        ],\n",
            "        [ 0.1099442 , -0.03054403, -0.01865598, ...,  0.34721407,\n",
            "          0.02516576,  2.        ],\n",
            "        ...,\n",
            "        [-0.15380192,  0.1073621 ,  0.2494774 , ...,  0.09623293,\n",
            "         -0.00823448,  2.        ],\n",
            "        [-0.2704158 ,  0.10084862,  0.31273112, ...,  0.07327332,\n",
            "         -0.04007948,  2.        ],\n",
            "        [-0.3086493 ,  0.08841884,  0.29066724, ...,  0.03428244,\n",
            "         -0.01951296,  2.        ]], dtype=float32)\n",
            " array([[-0.02187085, -0.14144163, -0.03497723, ...,  0.05989187,\n",
            "          0.21809019,  2.        ],\n",
            "        [ 0.16172406, -0.04766096, -0.02459321, ...,  0.28047094,\n",
            "          0.13849066,  2.        ],\n",
            "        [ 0.1474279 , -0.00588987, -0.00424209, ...,  0.37283528,\n",
            "          0.00856693,  2.        ],\n",
            "        ...,\n",
            "        [-0.08760419,  0.11801953,  0.20351505, ...,  0.08374158,\n",
            "          0.00379005,  2.        ],\n",
            "        [-0.22711855,  0.10989151,  0.2866756 , ...,  0.07852519,\n",
            "         -0.02958065,  2.        ],\n",
            "        [-0.27831247,  0.09368971,  0.27814898, ...,  0.07179451,\n",
            "         -0.00573455,  2.        ]], dtype=float32)\n",
            " array([[-1.7028078e-02, -1.1830984e-01, -3.5714906e-02, ...,\n",
            "          3.4029666e-02,  2.0591214e-01,  2.0000000e+00],\n",
            "        [ 1.2871473e-01, -1.4642207e-02, -6.8185786e-03, ...,\n",
            "          2.3100697e-01,  9.6916802e-02,  2.0000000e+00],\n",
            "        [ 1.3246781e-01,  5.2233037e-02,  8.5223122e-03, ...,\n",
            "          3.0199942e-01, -4.9010858e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.4098979e-03,  1.2597333e-01,  1.5043999e-01, ...,\n",
            "          3.3085946e-02,  3.1826518e-02,  2.0000000e+00],\n",
            "        [-2.1058205e-01,  1.2718761e-01,  3.3521158e-01, ...,\n",
            "          4.9593158e-02, -9.6607991e-03,  2.0000000e+00],\n",
            "        [-2.7848619e-01,  9.3981452e-02,  3.0178079e-01, ...,\n",
            "          4.5627788e-02, -5.0128014e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.10309289e-02, -1.33248433e-01, -2.77417079e-02, ...,\n",
            "          4.57186773e-02,  2.09592909e-01,  2.00000000e+00],\n",
            "        [ 1.41219020e-01, -3.85709070e-02, -5.74472174e-03, ...,\n",
            "          2.62154192e-01,  1.27441317e-01,  2.00000000e+00],\n",
            "        [ 1.36417374e-01,  1.20665822e-02,  1.43704601e-02, ...,\n",
            "          3.41081232e-01,  2.00933602e-04,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-8.81486386e-02,  1.28228068e-01,  2.34270036e-01, ...,\n",
            "          9.06424522e-02,  9.29939852e-04,  2.00000000e+00],\n",
            "        [-2.43011370e-01,  1.16230965e-01,  3.37999314e-01, ...,\n",
            "          7.59178475e-02, -2.78798249e-02,  2.00000000e+00],\n",
            "        [-2.90560275e-01,  9.23018679e-02,  2.98359692e-01, ...,\n",
            "          5.47569916e-02, -1.00065693e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 4.54281345e-02, -1.69927537e-01, -9.36583728e-02, ...,\n",
            "         -7.86879857e-04,  1.80927902e-01,  2.00000000e+00],\n",
            "        [ 2.74101526e-01, -2.72780610e-03, -8.57678577e-02, ...,\n",
            "          1.36205748e-01,  1.34541672e-02,  2.00000000e+00],\n",
            "        [ 2.72595286e-01,  4.08695005e-02, -6.96934387e-02, ...,\n",
            "          1.82836562e-01, -1.01418190e-01,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.38040870e-01,  5.91460662e-03, -1.13706104e-01, ...,\n",
            "          5.23598902e-02,  7.07255304e-02,  2.00000000e+00],\n",
            "        [-3.34937423e-02,  8.67825001e-02,  1.83643699e-01, ...,\n",
            "          1.11021444e-01, -3.56771760e-02,  2.00000000e+00],\n",
            "        [-2.29201183e-01,  4.27726842e-02,  2.97078788e-01, ...,\n",
            "          6.88884407e-02, -1.89769808e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 0.00778995, -0.10986402, -0.05826611, ...,  0.03027965,\n",
            "          0.1914196 ,  2.        ],\n",
            "        [ 0.18471704, -0.00221542, -0.04390402, ...,  0.23196772,\n",
            "          0.03447714,  2.        ],\n",
            "        [ 0.18669721,  0.04523101, -0.04206067, ...,  0.29448643,\n",
            "         -0.10024928,  2.        ],\n",
            "        ...,\n",
            "        [ 0.0857142 ,  0.06429377,  0.0410293 , ...,  0.03332373,\n",
            "          0.05891776,  2.        ],\n",
            "        [-0.13443463,  0.11889943,  0.3021004 , ...,  0.08877781,\n",
            "         -0.01664882,  2.        ],\n",
            "        [-0.2507574 ,  0.08836926,  0.29147747, ...,  0.05764017,\n",
            "         -0.01137916,  2.        ]], dtype=float32)\n",
            " array([[-1.1571941e-02, -1.2246791e-01, -4.0037483e-02, ...,\n",
            "          4.9951650e-02,  2.1377541e-01,  2.0000000e+00],\n",
            "        [ 1.3534370e-01, -2.5062960e-02, -1.7212780e-02, ...,\n",
            "          2.3468375e-01,  1.2515250e-01,  2.0000000e+00],\n",
            "        [ 1.3788909e-01,  3.6888421e-02,  1.7329277e-03, ...,\n",
            "          3.1210712e-01, -3.0578062e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1463593e-02,  1.4188309e-01,  1.5880249e-01, ...,\n",
            "          4.3698460e-02,  3.8517226e-02,  2.0000000e+00],\n",
            "        [-2.0998618e-01,  1.4381169e-01,  3.1988710e-01, ...,\n",
            "          6.1799441e-02, -4.4497740e-03,  2.0000000e+00],\n",
            "        [-2.6768240e-01,  1.0274305e-01,  2.9668134e-01, ...,\n",
            "          6.4013831e-02, -1.6516473e-04,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.01730401, -0.13005471, -0.03781258, ...,  0.05362581,\n",
            "          0.21648854,  2.        ],\n",
            "        [ 0.15264978, -0.02362985, -0.0165387 , ...,  0.25787812,\n",
            "          0.12450594,  2.        ],\n",
            "        [ 0.15624557,  0.0424277 ,  0.0041446 , ...,  0.33687413,\n",
            "         -0.02532775,  2.        ],\n",
            "        ...,\n",
            "        [-0.04285945,  0.14702666,  0.18310761, ...,  0.05360767,\n",
            "          0.01333815,  2.        ],\n",
            "        [-0.21102132,  0.1375921 ,  0.29972097, ...,  0.05811973,\n",
            "         -0.01633329,  2.        ],\n",
            "        [-0.26426622,  0.10409798,  0.28345305, ...,  0.07078888,\n",
            "          0.0053425 ,  2.        ]], dtype=float32)\n",
            " array([[ 2.54899939e-03, -1.09652646e-01, -5.52405827e-02, ...,\n",
            "          5.19923493e-02,  2.13443249e-01,  2.00000000e+00],\n",
            "        [ 1.56913444e-01, -1.59126073e-02, -4.49434593e-02, ...,\n",
            "          2.14703619e-01,  1.09831959e-01,  2.00000000e+00],\n",
            "        [ 1.41939953e-01,  3.49166244e-02, -2.89712511e-02, ...,\n",
            "          3.05965334e-01, -5.51293269e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 4.60273735e-02,  1.28641501e-01,  1.00772642e-01, ...,\n",
            "          3.58888321e-02,  4.51405682e-02,  2.00000000e+00],\n",
            "        [-1.70294970e-01,  1.39450252e-01,  2.84638137e-01, ...,\n",
            "          8.39329138e-02,  1.46042876e-04,  2.00000000e+00],\n",
            "        [-2.51752973e-01,  1.04650967e-01,  2.80155003e-01, ...,\n",
            "          6.98230267e-02,  1.04122679e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-2.4289597e-02, -1.2287104e-01, -2.3046458e-02, ...,\n",
            "          3.6888953e-02,  2.0694841e-01,  2.0000000e+00],\n",
            "        [ 1.2149683e-01, -3.4252357e-02,  7.6022265e-03, ...,\n",
            "          2.2979742e-01,  1.1759377e-01,  2.0000000e+00],\n",
            "        [ 1.1702818e-01,  2.6898934e-02,  3.1513724e-02, ...,\n",
            "          3.0478093e-01, -1.7810201e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-8.0578797e-02,  1.3729580e-01,  2.4166983e-01, ...,\n",
            "          4.5756102e-02,  7.9500017e-04,  2.0000000e+00],\n",
            "        [-2.4895805e-01,  1.3532746e-01,  3.6338383e-01, ...,\n",
            "          3.8713634e-02, -2.7156508e-02,  2.0000000e+00],\n",
            "        [-3.0220044e-01,  1.0099348e-01,  3.1705186e-01, ...,\n",
            "          4.0997811e-02, -7.5017959e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.38104018e-02, -1.18889563e-01, -3.90977710e-02, ...,\n",
            "          4.85478416e-02,  2.11448908e-01,  2.00000000e+00],\n",
            "        [ 1.45567164e-01, -1.88126285e-02, -1.35144209e-02, ...,\n",
            "          2.27781698e-01,  1.14368275e-01,  2.00000000e+00],\n",
            "        [ 1.41742632e-01,  4.41622175e-02,  5.55221457e-04, ...,\n",
            "          2.98537612e-01, -3.79935615e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.24427835e-02,  1.52308822e-01,  1.48139536e-01, ...,\n",
            "          3.33900452e-02,  2.98915543e-02,  2.00000000e+00],\n",
            "        [-2.06924126e-01,  1.56615630e-01,  3.16626787e-01, ...,\n",
            "          6.29990920e-02, -7.51671009e-03,  2.00000000e+00],\n",
            "        [-2.69426793e-01,  1.11672908e-01,  2.95078129e-01, ...,\n",
            "          7.21920803e-02,  4.04846715e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.00874824, -0.11686739, -0.04247124, ...,  0.05585648,\n",
            "          0.21796142,  2.        ],\n",
            "        [ 0.1378477 , -0.03377773, -0.02328989, ...,  0.2228045 ,\n",
            "          0.13293597,  2.        ],\n",
            "        [ 0.12129262,  0.02652098, -0.00429241, ...,  0.307154  ,\n",
            "         -0.03152786,  2.        ],\n",
            "        ...,\n",
            "        [-0.00681017,  0.1492847 ,  0.16481239, ...,  0.03714512,\n",
            "          0.03584674,  2.        ],\n",
            "        [-0.19741645,  0.14639784,  0.31211153, ...,  0.06345107,\n",
            "          0.00439985,  2.        ],\n",
            "        [-0.26048085,  0.10581239,  0.2906339 , ...,  0.07824882,\n",
            "          0.00903645,  2.        ]], dtype=float32)\n",
            " array([[-0.01847531, -0.13760833, -0.03600984, ...,  0.06046814,\n",
            "          0.22175336,  2.        ],\n",
            "        [ 0.14943054, -0.04785894, -0.01397943, ...,  0.24162976,\n",
            "          0.14036451,  2.        ],\n",
            "        [ 0.13017157,  0.00389523,  0.00395607, ...,  0.32475457,\n",
            "         -0.01269249,  2.        ],\n",
            "        ...,\n",
            "        [-0.02620394,  0.16663954,  0.17273666, ...,  0.0355254 ,\n",
            "          0.03228004,  2.        ],\n",
            "        [-0.20231193,  0.1422798 ,  0.296119  , ...,  0.04623486,\n",
            "         -0.00593846,  2.        ],\n",
            "        [-0.2556912 ,  0.1038922 ,  0.27272946, ...,  0.0766525 ,\n",
            "          0.00387247,  2.        ]], dtype=float32)\n",
            " array([[-0.00348694, -0.10800996, -0.05251719, ...,  0.02500424,\n",
            "          0.19346553,  2.        ],\n",
            "        [ 0.1601824 , -0.00367526, -0.02754253, ...,  0.22202879,\n",
            "          0.04555078,  2.        ],\n",
            "        [ 0.1665884 ,  0.05190904, -0.02441525, ...,  0.28747687,\n",
            "         -0.0950271 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.05255336,  0.08369501,  0.07511098, ...,  0.01426861,\n",
            "          0.05709151,  2.        ],\n",
            "        [-0.16157742,  0.12525648,  0.32246315, ...,  0.05968031,\n",
            "         -0.00868774,  2.        ],\n",
            "        [-0.2651575 ,  0.09062364,  0.30362296, ...,  0.04719282,\n",
            "         -0.00750563,  2.        ]], dtype=float32)\n",
            " array([[-0.01634261, -0.11955868, -0.03727517, ...,  0.04681911,\n",
            "          0.2147831 ,  2.        ],\n",
            "        [ 0.13559309, -0.01918885, -0.01162453, ...,  0.23462908,\n",
            "          0.11535981,  2.        ],\n",
            "        [ 0.14165857,  0.04768632,  0.00653068, ...,  0.30691177,\n",
            "         -0.03879829,  2.        ],\n",
            "        ...,\n",
            "        [-0.03745681,  0.1368402 ,  0.1810616 , ...,  0.04836932,\n",
            "          0.01668401,  2.        ],\n",
            "        [-0.2236871 ,  0.14473777,  0.32766917, ...,  0.05859102,\n",
            "         -0.01314702,  2.        ],\n",
            "        [-0.27566   ,  0.10657671,  0.30089292, ...,  0.0625396 ,\n",
            "          0.00795852,  2.        ]], dtype=float32)\n",
            " array([[-1.7690100e-02, -1.2180847e-01, -3.2545198e-02, ...,\n",
            "          3.5468157e-02,  2.0617051e-01,  2.0000000e+00],\n",
            "        [ 1.2636510e-01, -1.9488886e-02,  1.0286877e-03, ...,\n",
            "          2.2450434e-01,  9.9125825e-02,  2.0000000e+00],\n",
            "        [ 1.3061443e-01,  4.5676790e-02,  1.9238913e-02, ...,\n",
            "          2.9434010e-01, -4.7298342e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-9.9646328e-03,  1.3372651e-01,  1.7010547e-01, ...,\n",
            "          2.6887832e-02,  3.7022341e-02,  2.0000000e+00],\n",
            "        [-2.1453594e-01,  1.3412985e-01,  3.3879870e-01, ...,\n",
            "          4.1747585e-02, -4.6949438e-03,  2.0000000e+00],\n",
            "        [-2.8084701e-01,  9.9306352e-02,  3.0356506e-01, ...,\n",
            "          3.9220870e-02,  7.7686983e-04,  2.0000000e+00]], dtype=float32)\n",
            " array([[-2.1204803e-02, -1.3971631e-01, -3.0337710e-02, ...,\n",
            "          5.3431801e-02,  2.1526954e-01,  2.0000000e+00],\n",
            "        [ 1.5428367e-01, -5.0313029e-02, -1.3503700e-02, ...,\n",
            "          2.6826695e-01,  1.3206601e-01,  2.0000000e+00],\n",
            "        [ 1.4423381e-01,  2.8956567e-03,  7.1141310e-03, ...,\n",
            "          3.5667488e-01, -9.1216038e-04,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-9.0625122e-02,  1.3788237e-01,  2.1999010e-01, ...,\n",
            "          7.2306804e-02, -3.6512255e-03,  2.0000000e+00],\n",
            "        [-2.3622832e-01,  1.2527516e-01,  3.0820855e-01, ...,\n",
            "          7.1653903e-02, -3.0163646e-02,  2.0000000e+00],\n",
            "        [-2.7840474e-01,  9.8382033e-02,  2.8577289e-01, ...,\n",
            "          7.0395082e-02, -3.6510269e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.84639692e-02, -1.25140473e-01, -2.91215107e-02, ...,\n",
            "          3.74332592e-02,  2.07849845e-01,  2.00000000e+00],\n",
            "        [ 1.27854645e-01, -2.40012724e-02,  1.98119460e-03, ...,\n",
            "          2.27851897e-01,  1.09795436e-01,  2.00000000e+00],\n",
            "        [ 1.29877493e-01,  3.87488231e-02,  2.20958851e-02, ...,\n",
            "          2.99826980e-01, -3.16541009e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-3.16135101e-02,  1.32885024e-01,  1.95684776e-01, ...,\n",
            "          4.10079733e-02,  2.82325763e-02,  2.00000000e+00],\n",
            "        [-2.25354180e-01,  1.28867626e-01,  3.46644163e-01, ...,\n",
            "          4.67829816e-02, -7.70824496e-03,  2.00000000e+00],\n",
            "        [-2.84466892e-01,  9.80417356e-02,  3.04317623e-01, ...,\n",
            "          4.20534499e-02, -9.70606692e-04,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01793253, -0.1229065 , -0.03727143, ...,  0.05596315,\n",
            "          0.21973467,  2.        ],\n",
            "        [ 0.13944715, -0.03717544, -0.01628651, ...,  0.21901004,\n",
            "          0.13698715,  2.        ],\n",
            "        [ 0.12145903,  0.0181559 ,  0.00449823, ...,  0.3052825 ,\n",
            "         -0.02122079,  2.        ],\n",
            "        ...,\n",
            "        [-0.01775227,  0.15623365,  0.16427599, ...,  0.0364672 ,\n",
            "          0.04042167,  2.        ],\n",
            "        [-0.20960748,  0.14838998,  0.3086936 , ...,  0.05687371,\n",
            "          0.00269213,  2.        ],\n",
            "        [-0.26589093,  0.10886653,  0.28428224, ...,  0.07618819,\n",
            "          0.00787243,  2.        ]], dtype=float32)\n",
            " array([[-0.03368976, -0.13488644, -0.03296263, ...,  0.05180957,\n",
            "          0.20882824,  2.        ],\n",
            "        [ 0.14175557, -0.06733368, -0.04062228, ...,  0.26704296,\n",
            "          0.14526561,  2.        ],\n",
            "        [ 0.10706498, -0.04713593, -0.03750598, ...,  0.35563588,\n",
            "          0.04434026,  2.        ],\n",
            "        ...,\n",
            "        [-0.13890788,  0.07237085,  0.22936827, ...,  0.09364565,\n",
            "          0.01338142,  2.        ],\n",
            "        [-0.2558885 ,  0.06289073,  0.2891215 , ...,  0.07042227,\n",
            "         -0.03442606,  2.        ],\n",
            "        [-0.3032323 ,  0.07043716,  0.2856523 , ...,  0.03486334,\n",
            "         -0.01716067,  2.        ]], dtype=float32)\n",
            " array([[-6.7492533e-03, -1.1480323e-01, -4.2911049e-02, ...,\n",
            "          3.9043721e-02,  2.0292631e-01,  2.0000000e+00],\n",
            "        [ 1.5184614e-01, -9.5941350e-03, -2.3677917e-02, ...,\n",
            "          2.2729959e-01,  8.0149792e-02,  2.0000000e+00],\n",
            "        [ 1.5488456e-01,  5.1055674e-02, -1.3970991e-02, ...,\n",
            "          3.0234262e-01, -6.7801744e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 4.3428268e-02,  1.0974554e-01,  1.0018587e-01, ...,\n",
            "          2.2118768e-02,  5.9476409e-02,  2.0000000e+00],\n",
            "        [-1.8133059e-01,  1.2128055e-01,  3.1275323e-01, ...,\n",
            "          6.3962817e-02,  2.2174695e-03,  2.0000000e+00],\n",
            "        [-2.6029220e-01,  9.4993882e-02,  2.8863531e-01, ...,\n",
            "          4.9347192e-02, -1.5888257e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-1.21049341e-02, -1.18831724e-01, -3.98111679e-02, ...,\n",
            "          5.50591499e-02,  2.17863902e-01,  2.00000000e+00],\n",
            "        [ 1.37769163e-01, -3.32535915e-02, -1.84411854e-02, ...,\n",
            "          2.10375085e-01,  1.31940395e-01,  2.00000000e+00],\n",
            "        [ 1.17745981e-01,  2.35484298e-02, -1.90765760e-03, ...,\n",
            "          2.98111618e-01, -2.87139416e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-3.69124510e-03,  1.54321462e-01,  1.59199640e-01, ...,\n",
            "          2.71449611e-02,  4.24759686e-02,  2.00000000e+00],\n",
            "        [-1.96716174e-01,  1.52448937e-01,  3.14545155e-01, ...,\n",
            "          5.59401773e-02,  5.41450176e-03,  2.00000000e+00],\n",
            "        [-2.59360760e-01,  1.09148055e-01,  2.89440870e-01, ...,\n",
            "          7.32594058e-02,  5.21720154e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01747171, -0.11298119, -0.03627186, ...,  0.02883613,\n",
            "          0.20004757,  2.        ],\n",
            "        [ 0.12908563, -0.0073276 , -0.00449342, ...,  0.22276494,\n",
            "          0.07688253,  2.        ],\n",
            "        [ 0.14315479,  0.06076347,  0.01012726, ...,  0.28814504,\n",
            "         -0.0720024 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.00502208,  0.11799572,  0.14198212, ...,  0.01259906,\n",
            "          0.03604037,  2.        ],\n",
            "        [-0.20186229,  0.13192618,  0.34706154, ...,  0.04025278,\n",
            "         -0.01123837,  2.        ],\n",
            "        [-0.27858195,  0.09573471,  0.31521913, ...,  0.03848377,\n",
            "         -0.00457751,  2.        ]], dtype=float32)\n",
            " array([[-0.02430294, -0.12333473, -0.02408767, ...,  0.03768035,\n",
            "          0.2075672 ,  2.        ],\n",
            "        [ 0.12043267, -0.0353735 ,  0.00401036, ...,  0.22996634,\n",
            "          0.11784622,  2.        ],\n",
            "        [ 0.11657033,  0.02418208,  0.02728388, ...,  0.30954465,\n",
            "         -0.02008249,  2.        ],\n",
            "        ...,\n",
            "        [-0.07469839,  0.13302572,  0.23537374, ...,  0.0470724 ,\n",
            "          0.00504803,  2.        ],\n",
            "        [-0.24745455,  0.13451049,  0.36158562, ...,  0.04128824,\n",
            "         -0.02310033,  2.        ],\n",
            "        [-0.30060872,  0.10042753,  0.314721  , ...,  0.03986115,\n",
            "         -0.00439297,  2.        ]], dtype=float32)\n",
            " array([[-0.02383904, -0.12965418, -0.02458566, ...,  0.04001015,\n",
            "          0.20825982,  2.        ],\n",
            "        [ 0.12761806, -0.03696444,  0.00670167, ...,  0.23356327,\n",
            "          0.12374615,  2.        ],\n",
            "        [ 0.12371228,  0.01799067,  0.02961966, ...,  0.3094534 ,\n",
            "         -0.0110709 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.08717255,  0.14012793,  0.24550197, ...,  0.0560042 ,\n",
            "          0.00348415,  2.        ],\n",
            "        [-0.24920069,  0.13037583,  0.35751116, ...,  0.04817497,\n",
            "         -0.02466202,  2.        ],\n",
            "        [-0.29687876,  0.09742802,  0.30747113, ...,  0.04143293,\n",
            "         -0.00718639,  2.        ]], dtype=float32)\n",
            " array([[ 0.00867058, -0.11601037, -0.0580594 , ...,  0.04590271,\n",
            "          0.21018623,  2.        ],\n",
            "        [ 0.18575552, -0.01800278, -0.04775624, ...,  0.22812831,\n",
            "          0.07886266,  2.        ],\n",
            "        [ 0.1705447 ,  0.03319638, -0.03990139, ...,  0.30899668,\n",
            "         -0.06725545,  2.        ],\n",
            "        ...,\n",
            "        [ 0.09364977,  0.08289639,  0.08053694, ...,  0.02892976,\n",
            "          0.04295725,  2.        ],\n",
            "        [-0.13463995,  0.11979156,  0.29074815, ...,  0.083671  ,\n",
            "         -0.01308422,  2.        ],\n",
            "        [-0.24189198,  0.10526612,  0.28128463, ...,  0.05998348,\n",
            "         -0.0038451 ,  2.        ]], dtype=float32)\n",
            " array([[-0.01649973, -0.12951855, -0.02718094, ...,  0.04717202,\n",
            "          0.21139564,  2.        ],\n",
            "        [ 0.15327452, -0.03555502, -0.00556271, ...,  0.2680717 ,\n",
            "          0.12642746,  2.        ],\n",
            "        [ 0.15252395,  0.02147505,  0.00877771, ...,  0.34726208,\n",
            "         -0.00233532,  2.        ],\n",
            "        ...,\n",
            "        [-0.0480383 ,  0.12249365,  0.21005568, ...,  0.08723339,\n",
            "          0.02010909,  2.        ],\n",
            "        [-0.2258082 ,  0.12289451,  0.33098954, ...,  0.08163191,\n",
            "         -0.01431391,  2.        ],\n",
            "        [-0.27508825,  0.10211354,  0.29534855, ...,  0.06035616,\n",
            "          0.00331995,  2.        ]], dtype=float32)\n",
            " array([[-0.03076708, -0.15191388, -0.05843464, ...,  0.05692876,\n",
            "          0.19354418,  2.        ],\n",
            "        [ 0.12033758, -0.12027757, -0.06107125, ...,  0.26006308,\n",
            "          0.15414916,  2.        ],\n",
            "        [ 0.0536495 , -0.11695078, -0.0693789 , ...,  0.36231515,\n",
            "          0.08788099,  2.        ],\n",
            "        ...,\n",
            "        [-0.23228878,  0.04865343,  0.19882174, ...,  0.0367942 ,\n",
            "         -0.07747597,  2.        ],\n",
            "        [-0.27519006,  0.06498305,  0.21128051, ...,  0.0377805 ,\n",
            "         -0.07697756,  2.        ],\n",
            "        [-0.24600554,  0.04131319,  0.23887305, ..., -0.00541983,\n",
            "         -0.04715889,  2.        ]], dtype=float32)\n",
            " array([[-2.92799473e-02, -1.51216060e-01, -5.93715422e-02, ...,\n",
            "          6.20769784e-02,  1.94987550e-01,  2.00000000e+00],\n",
            "        [ 1.29254833e-01, -1.22453570e-01, -6.36853799e-02, ...,\n",
            "          2.71552056e-01,  1.57429859e-01,  2.00000000e+00],\n",
            "        [ 5.97847104e-02, -1.16260745e-01, -6.77718446e-02, ...,\n",
            "          3.78405273e-01,  8.83190632e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-2.14331403e-01,  5.33599220e-02,  1.82250962e-01, ...,\n",
            "          3.03290989e-02, -7.53905922e-02,  2.00000000e+00],\n",
            "        [-2.65263230e-01,  6.87379315e-02,  2.04513550e-01, ...,\n",
            "          4.06261943e-02, -6.94511086e-02,  2.00000000e+00],\n",
            "        [-2.42122442e-01,  4.54094410e-02,  2.33200669e-01, ...,\n",
            "         -2.54302227e-04, -4.28718477e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 0.02592978, -0.1326232 , -0.07961189, ...,  0.05596863,\n",
            "          0.20637383,  2.        ],\n",
            "        [ 0.21014342, -0.0068955 , -0.07053353, ...,  0.24094509,\n",
            "          0.06082471,  2.        ],\n",
            "        [ 0.1806632 ,  0.0251996 , -0.06644922, ...,  0.33482185,\n",
            "         -0.09376422,  2.        ],\n",
            "        ...,\n",
            "        [ 0.16433279,  0.04667316,  0.04105252, ...,  0.0580323 ,\n",
            "          0.04245109,  2.        ],\n",
            "        [-0.08040489,  0.11569528,  0.25044635, ...,  0.09958172,\n",
            "         -0.0085832 ,  2.        ],\n",
            "        [-0.21052949,  0.07483868,  0.26468652, ...,  0.07874145,\n",
            "         -0.01025286,  2.        ]], dtype=float32)\n",
            " array([[-1.5702039e-03, -1.0780942e-01, -5.6409631e-02, ...,\n",
            "          2.4482258e-02,  1.9899438e-01,  2.0000000e+00],\n",
            "        [ 1.5230379e-01, -6.6180816e-03, -2.8903238e-02, ...,\n",
            "          2.1732223e-01,  6.0890283e-02,  2.0000000e+00],\n",
            "        [ 1.6241680e-01,  5.0100490e-02, -2.5908558e-02, ...,\n",
            "          2.8654638e-01, -8.7927923e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.6396686e-02,  8.5167661e-02,  6.7811556e-02, ...,\n",
            "          1.5955605e-02,  6.6210538e-02,  2.0000000e+00],\n",
            "        [-1.6055493e-01,  1.2701751e-01,  3.0842143e-01, ...,\n",
            "          6.2837563e-02, -2.1741153e-03,  2.0000000e+00],\n",
            "        [-2.6350069e-01,  8.7668598e-02,  3.0035982e-01, ...,\n",
            "          5.3289771e-02, -4.6337876e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.03058418, -0.16082561, -0.0559805 , ...,  0.06539982,\n",
            "          0.2161643 ,  2.        ],\n",
            "        [ 0.15551051, -0.10602922, -0.07627898, ...,  0.30454612,\n",
            "          0.15745208,  2.        ],\n",
            "        [ 0.10616075, -0.10531559, -0.08296652, ...,  0.4059495 ,\n",
            "          0.06904098,  2.        ],\n",
            "        ...,\n",
            "        [-0.12423263,  0.00211582,  0.19173262, ...,  0.0993957 ,\n",
            "         -0.00847089,  2.        ],\n",
            "        [-0.2160071 ,  0.0239162 ,  0.20072073, ...,  0.08656564,\n",
            "         -0.04093348,  2.        ],\n",
            "        [-0.25570178,  0.01003918,  0.22974817, ...,  0.04128231,\n",
            "         -0.02225566,  2.        ]], dtype=float32)\n",
            " array([[ 5.17729074e-02, -2.19369695e-01, -1.17399156e-01, ...,\n",
            "         -1.66878253e-02,  1.98648214e-01,  2.00000000e+00],\n",
            "        [ 3.10936123e-01,  2.58923527e-02, -9.55180079e-02, ...,\n",
            "          2.84913331e-02,  1.00180451e-02,  2.00000000e+00],\n",
            "        [ 3.21848661e-01,  5.93319274e-02, -7.92049021e-02, ...,\n",
            "          8.75126645e-02, -6.49503618e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.70968980e-01, -7.25491066e-03, -1.35978609e-01, ...,\n",
            "          5.09137549e-02,  5.96464910e-02,  2.00000000e+00],\n",
            "        [ 3.30771655e-02,  5.89126535e-02,  1.01152264e-01, ...,\n",
            "          1.10715002e-01, -9.12269950e-03,  2.00000000e+00],\n",
            "        [-1.43789366e-01,  1.62790120e-02,  2.84120321e-01, ...,\n",
            "          4.67642285e-02,  1.61156373e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 0.01186576, -0.11134393, -0.0601698 , ...,  0.05406455,\n",
            "          0.20991398,  2.        ],\n",
            "        [ 0.16796778, -0.01614368, -0.05501695, ...,  0.2268102 ,\n",
            "          0.09440993,  2.        ],\n",
            "        [ 0.15976608,  0.03328632, -0.04268743, ...,  0.30741888,\n",
            "         -0.06619439,  2.        ],\n",
            "        ...,\n",
            "        [ 0.0911177 ,  0.10390371,  0.05591189, ...,  0.03205312,\n",
            "          0.05758102,  2.        ],\n",
            "        [-0.1420398 ,  0.1343779 ,  0.2699548 , ...,  0.08813463,\n",
            "         -0.00442374,  2.        ],\n",
            "        [-0.24249068,  0.0958266 ,  0.27927187, ...,  0.06823157,\n",
            "         -0.00403144,  2.        ]], dtype=float32)\n",
            " array([[-1.74365137e-02, -1.19775884e-01, -3.36936787e-02, ...,\n",
            "          3.72975357e-02,  2.06463039e-01,  2.00000000e+00],\n",
            "        [ 1.33016020e-01, -1.71044879e-02, -2.10805191e-03, ...,\n",
            "          2.28055120e-01,  1.02163725e-01,  2.00000000e+00],\n",
            "        [ 1.31059080e-01,  4.66331914e-02,  1.56238070e-02, ...,\n",
            "          3.01663280e-01, -4.16454822e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.36975013e-02,  1.32258475e-01,  1.71642721e-01, ...,\n",
            "          3.59254293e-02,  3.48837934e-02,  2.00000000e+00],\n",
            "        [-2.19783932e-01,  1.26912221e-01,  3.37808877e-01, ...,\n",
            "          4.95257080e-02, -5.33087645e-03,  2.00000000e+00],\n",
            "        [-2.79244214e-01,  9.80862379e-02,  2.98085600e-01, ...,\n",
            "          4.19885367e-02,  1.74474169e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.02983232, -0.14659917, -0.03566116, ...,  0.06035346,\n",
            "          0.2158043 ,  2.        ],\n",
            "        [ 0.16453004, -0.07600013, -0.04240802, ...,  0.27383992,\n",
            "          0.15834017,  2.        ],\n",
            "        [ 0.12074443, -0.05880851, -0.03517045, ...,  0.36845112,\n",
            "          0.05626207,  2.        ],\n",
            "        ...,\n",
            "        [-0.11721491,  0.05350009,  0.21673356, ...,  0.08536812,\n",
            "          0.00872264,  2.        ],\n",
            "        [-0.23567922,  0.04986363,  0.2645867 , ...,  0.0695653 ,\n",
            "         -0.0346719 ,  2.        ],\n",
            "        [-0.27727816,  0.06095142,  0.26310274, ...,  0.04411001,\n",
            "         -0.01205712,  2.        ]], dtype=float32)\n",
            " array([[ 0.03611891, -0.12666522, -0.08665457, ...,  0.02848442,\n",
            "          0.19340439,  2.        ],\n",
            "        [ 0.21188071, -0.03314567, -0.07926604, ...,  0.20883228,\n",
            "          0.06193379,  2.        ],\n",
            "        [ 0.19990154,  0.00714263, -0.0645055 , ...,  0.29083028,\n",
            "         -0.08719877,  2.        ],\n",
            "        ...,\n",
            "        [ 0.1620112 ,  0.02510812,  0.00312538, ...,  0.06354415,\n",
            "          0.06524449,  2.        ],\n",
            "        [-0.06319188,  0.07950925,  0.23452695, ...,  0.11591317,\n",
            "         -0.01788844,  2.        ],\n",
            "        [-0.22901967,  0.06243887,  0.2816109 , ...,  0.08743662,\n",
            "         -0.01504868,  2.        ]], dtype=float32)\n",
            " array([[ 0.01754181, -0.11630016, -0.06281462, ...,  0.02273544,\n",
            "          0.18931058,  2.        ],\n",
            "        [ 0.19560894, -0.01384257, -0.04615188, ...,  0.22156006,\n",
            "          0.02796651,  2.        ],\n",
            "        [ 0.1913634 ,  0.0314828 , -0.04373498, ...,  0.28016046,\n",
            "         -0.10216887,  2.        ],\n",
            "        ...,\n",
            "        [ 0.09434528,  0.03785443,  0.03574145, ...,  0.04151082,\n",
            "          0.07260939,  2.        ],\n",
            "        [-0.12191379,  0.10615824,  0.30424228, ...,  0.09194328,\n",
            "         -0.01042496,  2.        ],\n",
            "        [-0.25033888,  0.07719075,  0.301972  , ...,  0.057828  ,\n",
            "         -0.01297911,  2.        ]], dtype=float32)\n",
            " array([[-0.03295666, -0.13019381, -0.03267292, ...,  0.05572275,\n",
            "          0.21046405,  2.        ],\n",
            "        [ 0.14573221, -0.05493668, -0.02974645, ...,  0.25579748,\n",
            "          0.14877038,  2.        ],\n",
            "        [ 0.11409359, -0.03256965, -0.0117433 , ...,  0.34428534,\n",
            "          0.04563309,  2.        ],\n",
            "        ...,\n",
            "        [-0.15857704,  0.09135657,  0.26127622, ...,  0.07831275,\n",
            "         -0.01162989,  2.        ],\n",
            "        [-0.26879606,  0.07700376,  0.30448675, ...,  0.06753937,\n",
            "         -0.0477221 ,  2.        ],\n",
            "        [-0.30008456,  0.08502801,  0.28444794, ...,  0.03785806,\n",
            "         -0.0185583 ,  2.        ]], dtype=float32)\n",
            " array([[-0.01637167, -0.1288519 , -0.02728851, ...,  0.0465681 ,\n",
            "          0.21114227,  3.        ],\n",
            "        [ 0.14970583, -0.03769656, -0.00590002, ...,  0.26253805,\n",
            "          0.12575346,  3.        ],\n",
            "        [ 0.14947744,  0.02082173,  0.0102956 , ...,  0.3421139 ,\n",
            "         -0.01125154,  3.        ],\n",
            "        ...,\n",
            "        [-0.04038913,  0.12055006,  0.20441075, ...,  0.08161098,\n",
            "          0.01975922,  3.        ],\n",
            "        [-0.2248375 ,  0.12595537,  0.33333123, ...,  0.07731747,\n",
            "         -0.01435323,  3.        ],\n",
            "        [-0.27460414,  0.10538875,  0.29561898, ...,  0.05601711,\n",
            "          0.00347381,  3.        ]], dtype=float32)\n",
            " array([[-0.02237599, -0.13794209, -0.02849396, ...,  0.0545837 ,\n",
            "          0.21695396,  0.        ],\n",
            "        [ 0.1472648 , -0.04886949, -0.01070032, ...,  0.25292358,\n",
            "          0.13949284,  0.        ],\n",
            "        [ 0.13595644,  0.0012    ,  0.01098617, ...,  0.33817923,\n",
            "          0.00708071,  0.        ],\n",
            "        ...,\n",
            "        [-0.09056563,  0.14234915,  0.2211558 , ...,  0.06590389,\n",
            "          0.00173809,  0.        ],\n",
            "        [-0.2468245 ,  0.13254449,  0.3203731 , ...,  0.06539837,\n",
            "         -0.028892  ,  0.        ],\n",
            "        [-0.2872361 ,  0.09743987,  0.292311  , ...,  0.06523556,\n",
            "         -0.00294644,  0.        ]], dtype=float32)\n",
            " array([[-2.42558420e-02, -1.33070305e-01, -2.52358932e-02, ...,\n",
            "          4.68528122e-02,  2.09280178e-01,  0.00000000e+00],\n",
            "        [ 1.35332480e-01, -4.81409691e-02, -1.06527805e-02, ...,\n",
            "          2.57648170e-01,  1.31897673e-01,  0.00000000e+00],\n",
            "        [ 1.21124707e-01, -2.68997089e-03,  8.18575919e-03, ...,\n",
            "          3.44128191e-01,  9.89921112e-03,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-1.16736397e-01,  1.26858488e-01,  2.42055893e-01, ...,\n",
            "          8.18403289e-02, -3.14121833e-04,  0.00000000e+00],\n",
            "        [-2.54189491e-01,  1.13990277e-01,  3.29869926e-01, ...,\n",
            "          6.78133368e-02, -2.99450103e-02,  0.00000000e+00],\n",
            "        [-2.99777687e-01,  9.09529924e-02,  2.98318952e-01, ...,\n",
            "          4.84187864e-02, -1.16631445e-02,  0.00000000e+00]], dtype=float32)\n",
            " array([[-1.86443180e-02, -1.14403613e-01, -3.66871282e-02, ...,\n",
            "          3.44535522e-02,  2.02536866e-01,  0.00000000e+00],\n",
            "        [ 1.28941491e-01, -1.34679005e-02, -7.26275425e-03, ...,\n",
            "          2.32615247e-01,  7.87707418e-02,  0.00000000e+00],\n",
            "        [ 1.38211876e-01,  5.72253950e-02,  7.17473403e-03, ...,\n",
            "          3.01659256e-01, -6.71571270e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.46273915e-02,  1.18760914e-01,  1.27757072e-01, ...,\n",
            "          2.63439063e-02,  5.17172180e-02,  0.00000000e+00],\n",
            "        [-2.02498034e-01,  1.28486186e-01,  3.33142579e-01, ...,\n",
            "          5.42437509e-02, -4.66221943e-03,  0.00000000e+00],\n",
            "        [-2.80517250e-01,  9.72236097e-02,  3.03642035e-01, ...,\n",
            "          4.70051803e-02,  2.85063521e-04,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.03520603, -0.15269056, -0.05638042, ...,  0.05950005,\n",
            "          0.2096184 ,  0.        ],\n",
            "        [ 0.13771114, -0.11372418, -0.07597794, ...,  0.2843338 ,\n",
            "          0.16246186,  0.        ],\n",
            "        [ 0.07982775, -0.11375597, -0.08034786, ...,  0.3898306 ,\n",
            "          0.08527289,  0.        ],\n",
            "        ...,\n",
            "        [-0.18515281,  0.02249629,  0.2020171 , ...,  0.10690989,\n",
            "         -0.03759996,  0.        ],\n",
            "        [-0.26020315,  0.03722868,  0.20510858, ...,  0.08578946,\n",
            "         -0.06747767,  0.        ],\n",
            "        [-0.2766243 ,  0.01963335,  0.24109223, ...,  0.02242417,\n",
            "         -0.03625875,  0.        ]], dtype=float32)\n",
            " array([[-0.02202629, -0.13436879, -0.02889259, ...,  0.05068167,\n",
            "          0.21745206,  0.        ],\n",
            "        [ 0.14232685, -0.04635741, -0.00772201, ...,  0.24418433,\n",
            "          0.1361179 ,  0.        ],\n",
            "        [ 0.13293922,  0.00962984,  0.0164728 , ...,  0.32424733,\n",
            "         -0.00218674,  0.        ],\n",
            "        ...,\n",
            "        [-0.07771487,  0.14870672,  0.21504687, ...,  0.05266661,\n",
            "          0.01104627,  0.        ],\n",
            "        [-0.2379851 ,  0.14174719,  0.31742185, ...,  0.05898244,\n",
            "         -0.0223893 ,  0.        ],\n",
            "        [-0.28365573,  0.10113052,  0.2916664 , ...,  0.06497268,\n",
            "         -0.00194701,  0.        ]], dtype=float32)\n",
            " array([[-0.02498045, -0.12927376, -0.02357622, ...,  0.04350647,\n",
            "          0.2070475 ,  0.        ],\n",
            "        [ 0.12868738, -0.04182516,  0.0007332 , ...,  0.24692357,\n",
            "          0.12649925,  0.        ],\n",
            "        [ 0.11650721,  0.0049977 ,  0.02166218, ...,  0.3276018 ,\n",
            "          0.00350045,  0.        ],\n",
            "        ...,\n",
            "        [-0.11177039,  0.13366191,  0.25230017, ...,  0.07015545,\n",
            "         -0.00320341,  0.        ],\n",
            "        [-0.2561651 ,  0.12229806,  0.34907886, ...,  0.05825484,\n",
            "         -0.03223031,  0.        ],\n",
            "        [-0.3023876 ,  0.09488626,  0.30717382, ...,  0.04276699,\n",
            "         -0.01185198,  0.        ]], dtype=float32)\n",
            " array([[-0.02912681, -0.12344509, -0.0261516 , ...,  0.0490243 ,\n",
            "          0.20478661,  0.        ],\n",
            "        [ 0.1327806 , -0.05389144, -0.01614528, ...,  0.24706823,\n",
            "          0.13660993,  0.        ],\n",
            "        [ 0.11406272, -0.01961334,  0.00319512, ...,  0.3403934 ,\n",
            "          0.0138936 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.14641969,  0.12369169,  0.255305  , ...,  0.08261113,\n",
            "         -0.00920618,  0.        ],\n",
            "        [-0.26673347,  0.11029909,  0.3267629 , ...,  0.06538752,\n",
            "         -0.03944035,  0.        ],\n",
            "        [-0.30820256,  0.0937884 ,  0.29711363, ...,  0.03974879,\n",
            "         -0.01746876,  0.        ]], dtype=float32)\n",
            " array([[-0.02331657, -0.12999949, -0.02980142, ...,  0.04924263,\n",
            "          0.21334775,  0.        ],\n",
            "        [ 0.13829991, -0.04144775, -0.00632616, ...,  0.24773748,\n",
            "          0.1277436 ,  0.        ],\n",
            "        [ 0.1348685 ,  0.01702049,  0.01772079, ...,  0.32621062,\n",
            "         -0.01438168,  0.        ],\n",
            "        ...,\n",
            "        [-0.09448799,  0.14652334,  0.23677878, ...,  0.06393766,\n",
            "         -0.00155833,  0.        ],\n",
            "        [-0.2505008 ,  0.13837217,  0.33957246, ...,  0.05818041,\n",
            "         -0.03186399,  0.        ],\n",
            "        [-0.28937504,  0.10306723,  0.30107793, ...,  0.0587499 ,\n",
            "         -0.00393274,  0.        ]], dtype=float32)\n",
            " array([[ 0.00314237, -0.10345753, -0.06425022, ...,  0.03365968,\n",
            "          0.20227502,  0.        ],\n",
            "        [ 0.16405986,  0.00820009, -0.03701883, ...,  0.22435915,\n",
            "          0.07566608,  0.        ],\n",
            "        [ 0.16860142,  0.06254929, -0.02757354, ...,  0.3052232 ,\n",
            "         -0.0809003 ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.07833051,  0.0856446 ,  0.04953894, ...,  0.04335492,\n",
            "          0.05621871,  0.        ],\n",
            "        [-0.1463221 ,  0.13708052,  0.3006408 , ...,  0.08128867,\n",
            "         -0.00704555,  0.        ],\n",
            "        [-0.25395906,  0.098526  ,  0.29274333, ...,  0.06304353,\n",
            "         -0.0026616 ,  0.        ]], dtype=float32)\n",
            " array([[-0.03413427, -0.12462689, -0.03117526, ...,  0.05197352,\n",
            "          0.20739534,  0.        ],\n",
            "        [ 0.13395461, -0.05592593, -0.03250667, ...,  0.25526106,\n",
            "          0.14703372,  0.        ],\n",
            "        [ 0.10559446, -0.0313003 , -0.02168581, ...,  0.34648967,\n",
            "          0.03913869,  0.        ],\n",
            "        ...,\n",
            "        [-0.15795322,  0.09697188,  0.25007498, ...,  0.08759096,\n",
            "          0.00051561,  0.        ],\n",
            "        [-0.27152717,  0.08249653,  0.3074991 , ...,  0.06613325,\n",
            "         -0.03793184,  0.        ],\n",
            "        [-0.31129405,  0.08297896,  0.29005346, ...,  0.03109119,\n",
            "         -0.01930606,  0.        ]], dtype=float32)\n",
            " array([[-0.02324015, -0.12834632, -0.02483963, ...,  0.04037478,\n",
            "          0.20833743,  0.        ],\n",
            "        [ 0.12641087, -0.03826324,  0.00336283, ...,  0.2399566 ,\n",
            "          0.12272856,  0.        ],\n",
            "        [ 0.12148178,  0.01825456,  0.02613478, ...,  0.31698805,\n",
            "         -0.0108926 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.08127248,  0.13668323,  0.2388177 , ...,  0.06151449,\n",
            "          0.00779734,  0.        ],\n",
            "        [-0.24687795,  0.13052373,  0.35308495, ...,  0.05310778,\n",
            "         -0.02461996,  0.        ],\n",
            "        [-0.29901123,  0.09712976,  0.30767545, ...,  0.04448463,\n",
            "         -0.0086096 ,  0.        ]], dtype=float32)\n",
            " array([[-0.02191956, -0.16947204, -0.04666083, ...,  0.06804747,\n",
            "          0.21122286,  0.        ],\n",
            "        [ 0.19010037, -0.09707025, -0.05902236, ...,  0.31030995,\n",
            "          0.14689533,  0.        ],\n",
            "        [ 0.14861673, -0.09184304, -0.06049786, ...,  0.39847288,\n",
            "          0.06156828,  0.        ],\n",
            "        ...,\n",
            "        [-0.08050936,  0.00666223,  0.16119303, ...,  0.09916874,\n",
            "          0.01489405,  0.        ],\n",
            "        [-0.19062643,  0.02274868,  0.19891344, ...,  0.08591622,\n",
            "         -0.02045695,  0.        ],\n",
            "        [-0.240873  ,  0.02195768,  0.22737187, ...,  0.05699196,\n",
            "         -0.01445276,  0.        ]], dtype=float32)\n",
            " array([[-1.4399991e-02, -1.1611620e-01, -3.4175631e-02, ...,\n",
            "          4.3111969e-02,  2.0754968e-01,  0.0000000e+00],\n",
            "        [ 1.3994357e-01, -2.0907745e-02, -1.4895519e-02, ...,\n",
            "          2.4935885e-01,  9.8450713e-02,  0.0000000e+00],\n",
            "        [ 1.5063439e-01,  4.8895083e-02, -2.9921078e-03, ...,\n",
            "          3.1882977e-01, -4.9629584e-02,  0.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.2369733e-02,  1.2092329e-01,  1.5318510e-01, ...,\n",
            "          5.5114411e-02,  3.8252894e-02,  0.0000000e+00],\n",
            "        [-1.9987206e-01,  1.2628531e-01,  3.3233190e-01, ...,\n",
            "          8.0706403e-02,  2.2220312e-04,  0.0000000e+00],\n",
            "        [-2.6456979e-01,  1.0794211e-01,  2.9637685e-01, ...,\n",
            "          5.5213694e-02,  9.5783425e-03,  0.0000000e+00]], dtype=float32)\n",
            " array([[ 2.41555063e-05, -1.09340362e-01, -5.06579280e-02, ...,\n",
            "          4.11569811e-02,  2.03350440e-01,  0.00000000e+00],\n",
            "        [ 1.80355743e-01, -3.93523648e-03, -4.20061797e-02, ...,\n",
            "          2.55870432e-01,  5.73865511e-02,  0.00000000e+00],\n",
            "        [ 1.90443814e-01,  5.69635369e-02, -3.95333320e-02, ...,\n",
            "          3.13446760e-01, -7.72397742e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 9.62907746e-02,  7.98243806e-02,  3.81246209e-02, ...,\n",
            "          5.77899925e-02,  6.13779463e-02,  0.00000000e+00],\n",
            "        [-1.37794763e-01,  1.23467304e-01,  3.00123334e-01, ...,\n",
            "          1.13006644e-01, -6.55732071e-03,  0.00000000e+00],\n",
            "        [-2.44163126e-01,  1.03626445e-01,  2.89366066e-01, ...,\n",
            "          6.78095594e-02,  5.92817366e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.02348512, -0.13035853, -0.02980401, ...,  0.04711983,\n",
            "          0.21473412,  0.        ],\n",
            "        [ 0.1260452 , -0.03821783, -0.00837306, ...,  0.24236621,\n",
            "          0.12395158,  0.        ],\n",
            "        [ 0.13071689,  0.02528022,  0.01496376, ...,  0.3206218 ,\n",
            "         -0.020647  ,  0.        ],\n",
            "        ...,\n",
            "        [-0.06717963,  0.1401748 ,  0.21846785, ...,  0.051353  ,\n",
            "          0.00383256,  0.        ],\n",
            "        [-0.24169195,  0.14132321,  0.34078777, ...,  0.05338374,\n",
            "         -0.02264558,  0.        ],\n",
            "        [-0.28718206,  0.10064969,  0.30389717, ...,  0.05898089,\n",
            "          0.00114197,  0.        ]], dtype=float32)\n",
            " array([[-0.02133249, -0.1220579 , -0.02948798, ...,  0.03886698,\n",
            "          0.20653169,  0.        ],\n",
            "        [ 0.12251801, -0.02438235, -0.00221275, ...,  0.23411056,\n",
            "          0.10763633,  0.        ],\n",
            "        [ 0.12253804,  0.0401642 ,  0.0158961 , ...,  0.30832183,\n",
            "         -0.03271574,  0.        ],\n",
            "        ...,\n",
            "        [-0.02833656,  0.1319901 ,  0.19092004, ...,  0.03881343,\n",
            "          0.02801788,  0.        ],\n",
            "        [-0.2297713 ,  0.12981924,  0.3466661 , ...,  0.04682697,\n",
            "         -0.00937745,  0.        ],\n",
            "        [-0.28895962,  0.10025246,  0.30626532, ...,  0.04376646,\n",
            "         -0.00085595,  0.        ]], dtype=float32)\n",
            " array([[ 0.05354775, -0.20470047, -0.10656381, ..., -0.01139846,\n",
            "          0.18814053,  0.        ],\n",
            "        [ 0.31474578,  0.01916454, -0.09842851, ...,  0.07402953,\n",
            "          0.00989604,  0.        ],\n",
            "        [ 0.31240755,  0.05506718, -0.07978693, ...,  0.12204283,\n",
            "         -0.09469166,  0.        ],\n",
            "        ...,\n",
            "        [ 0.16424008, -0.01194559, -0.1623185 , ...,  0.03517276,\n",
            "          0.07698955,  0.        ],\n",
            "        [ 0.01811628,  0.05308146,  0.12953319, ...,  0.10955985,\n",
            "         -0.02127033,  0.        ],\n",
            "        [-0.17442049,  0.02574887,  0.2821743 , ...,  0.05390009,\n",
            "         -0.01381258,  0.        ]], dtype=float32)\n",
            " array([[-0.00746522, -0.11792487, -0.04569609, ...,  0.04964843,\n",
            "          0.21355842,  0.        ],\n",
            "        [ 0.14567359, -0.01528369, -0.02625343, ...,  0.23894136,\n",
            "          0.11684205,  0.        ],\n",
            "        [ 0.15040809,  0.0503085 , -0.00976779, ...,  0.3195206 ,\n",
            "         -0.04657724,  0.        ],\n",
            "        ...,\n",
            "        [-0.00151524,  0.14000621,  0.14292163, ...,  0.04892357,\n",
            "          0.02311725,  0.        ],\n",
            "        [-0.199215  ,  0.1496082 ,  0.306432  , ...,  0.06817286,\n",
            "         -0.00961818,  0.        ],\n",
            "        [-0.2611384 ,  0.1046599 ,  0.289491  , ...,  0.07094705,\n",
            "          0.00325524,  0.        ]], dtype=float32)\n",
            " array([[-0.01667459, -0.11866918, -0.03530796, ...,  0.04408614,\n",
            "          0.21548028,  0.        ],\n",
            "        [ 0.12708516, -0.02275225, -0.00814675, ...,  0.22758338,\n",
            "          0.12531208,  0.        ],\n",
            "        [ 0.13159803,  0.03999691,  0.01641461, ...,  0.29961327,\n",
            "         -0.02670292,  0.        ],\n",
            "        ...,\n",
            "        [-0.03681563,  0.14253345,  0.19735669, ...,  0.04619598,\n",
            "          0.01926314,  0.        ],\n",
            "        [-0.22229438,  0.13939932,  0.34009072, ...,  0.05607871,\n",
            "         -0.0108941 ,  0.        ],\n",
            "        [-0.2814787 ,  0.09870503,  0.3086569 , ...,  0.05591563,\n",
            "         -0.00127252,  0.        ]], dtype=float32)\n",
            " array([[-0.00116715, -0.12458944, -0.04707282, ...,  0.05515541,\n",
            "          0.2145739 ,  0.        ],\n",
            "        [ 0.16360264, -0.011059  , -0.02611814, ...,  0.23877774,\n",
            "          0.11756982,  0.        ],\n",
            "        [ 0.16470131,  0.05197058, -0.00741936, ...,  0.3214787 ,\n",
            "         -0.04036128,  0.        ],\n",
            "        ...,\n",
            "        [ 0.04171571,  0.12739924,  0.11194377, ...,  0.03662002,\n",
            "          0.03801142,  0.        ],\n",
            "        [-0.16612257,  0.13724576,  0.27920854, ...,  0.05670184,\n",
            "         -0.00652385,  0.        ],\n",
            "        [-0.24541552,  0.10863123,  0.27377024, ...,  0.07093716,\n",
            "          0.00240788,  0.        ]], dtype=float32)\n",
            " array([[-0.02138951, -0.12121896, -0.02804859, ...,  0.03832725,\n",
            "          0.2061501 ,  0.        ],\n",
            "        [ 0.12227751, -0.02901548,  0.00065084, ...,  0.233636  ,\n",
            "          0.11118168,  0.        ],\n",
            "        [ 0.12202297,  0.03580398,  0.02136949, ...,  0.30945757,\n",
            "         -0.03127633,  0.        ],\n",
            "        ...,\n",
            "        [-0.03622976,  0.12984183,  0.20354973, ...,  0.04511   ,\n",
            "          0.0156477 ,  0.        ],\n",
            "        [-0.2274242 ,  0.12834181,  0.34840184, ...,  0.05191514,\n",
            "         -0.01845326,  0.        ],\n",
            "        [-0.29116413,  0.1006157 ,  0.31360507, ...,  0.04501297,\n",
            "         -0.00209571,  0.        ]], dtype=float32)\n",
            " array([[ 0.0292323 , -0.13026458, -0.07392593, ...,  0.01161531,\n",
            "          0.18071058,  0.        ],\n",
            "        [ 0.22255997, -0.01906616, -0.0643228 , ...,  0.1909676 ,\n",
            "          0.01456259,  0.        ],\n",
            "        [ 0.22585048,  0.02201726, -0.05601162, ...,  0.24293919,\n",
            "         -0.10981473,  0.        ],\n",
            "        ...,\n",
            "        [ 0.13094366, -0.00153994, -0.05486963, ...,  0.03950429,\n",
            "          0.07099599,  0.        ],\n",
            "        [-0.07871556,  0.0952933 ,  0.26070413, ...,  0.10442971,\n",
            "         -0.03195761,  0.        ],\n",
            "        [-0.26027396,  0.06465278,  0.30386263, ...,  0.07199034,\n",
            "         -0.01824013,  0.        ]], dtype=float32)\n",
            " array([[-0.01502221, -0.12648578, -0.03635695, ...,  0.04745623,\n",
            "          0.21722467,  0.        ],\n",
            "        [ 0.13515028, -0.02770747, -0.01555942, ...,  0.23563454,\n",
            "          0.1274689 ,  0.        ],\n",
            "        [ 0.13488182,  0.0368774 ,  0.00563874, ...,  0.3131228 ,\n",
            "         -0.02639894,  0.        ],\n",
            "        ...,\n",
            "        [-0.01975349,  0.13996498,  0.15909879, ...,  0.04661169,\n",
            "          0.03765636,  0.        ],\n",
            "        [-0.21459916,  0.14373335,  0.31355396, ...,  0.05757703,\n",
            "         -0.00509691,  0.        ],\n",
            "        [-0.27182132,  0.10447467,  0.29051587, ...,  0.06269245,\n",
            "          0.00432717,  0.        ]], dtype=float32)\n",
            " array([[-0.00510096, -0.11692548, -0.04833753, ...,  0.05297056,\n",
            "          0.21689172,  0.        ],\n",
            "        [ 0.14650212, -0.01346086, -0.03239004, ...,  0.23529619,\n",
            "          0.11900122,  0.        ],\n",
            "        [ 0.15362792,  0.04674752, -0.01565224, ...,  0.31561533,\n",
            "         -0.04062163,  0.        ],\n",
            "        ...,\n",
            "        [ 0.04089506,  0.12033158,  0.09682029, ...,  0.04598722,\n",
            "          0.04601602,  0.        ],\n",
            "        [-0.17375886,  0.13551196,  0.28672343, ...,  0.0761872 ,\n",
            "          0.00053146,  0.        ],\n",
            "        [-0.25489768,  0.10845909,  0.2848868 , ...,  0.07535421,\n",
            "          0.01047088,  0.        ]], dtype=float32)\n",
            " array([[-0.03316279, -0.12820487, -0.0324354 , ...,  0.05492957,\n",
            "          0.20910455,  0.        ],\n",
            "        [ 0.13864556, -0.05967386, -0.03882203, ...,  0.27029085,\n",
            "          0.14702472,  0.        ],\n",
            "        [ 0.10975651, -0.03678428, -0.03077625, ...,  0.36207497,\n",
            "          0.04188975,  0.        ],\n",
            "        ...,\n",
            "        [-0.14341213,  0.08856437,  0.23882711, ...,  0.09355155,\n",
            "         -0.0021646 ,  0.        ],\n",
            "        [-0.26176953,  0.0742125 ,  0.2981877 , ...,  0.07100499,\n",
            "         -0.0370827 ,  0.        ],\n",
            "        [-0.30743945,  0.07988156,  0.28690654, ...,  0.03674104,\n",
            "         -0.01758117,  0.        ]], dtype=float32)\n",
            " array([[ 0.01544338, -0.11191582, -0.06711379, ...,  0.0387624 ,\n",
            "          0.20880277,  0.        ],\n",
            "        [ 0.17980108, -0.00509691, -0.05532445, ...,  0.21865751,\n",
            "          0.07654244,  0.        ],\n",
            "        [ 0.18213606,  0.04107853, -0.04459095, ...,  0.29895964,\n",
            "         -0.07809997,  0.        ],\n",
            "        ...,\n",
            "        [ 0.10755177,  0.06874344,  0.02253051, ...,  0.03950789,\n",
            "          0.07318252,  0.        ],\n",
            "        [-0.12796514,  0.12764364,  0.27037644, ...,  0.08316243,\n",
            "          0.00076525,  0.        ],\n",
            "        [-0.24121305,  0.09661821,  0.2792873 , ...,  0.06378949,\n",
            "         -0.00031788,  0.        ]], dtype=float32)\n",
            " array([[-0.01774156, -0.12600154, -0.02946129, ...,  0.03835232,\n",
            "          0.207582  ,  0.        ],\n",
            "        [ 0.1330399 , -0.02379643, -0.00247252, ...,  0.24293779,\n",
            "          0.1106225 ,  0.        ],\n",
            "        [ 0.13175584,  0.04026794,  0.01832011, ...,  0.32153043,\n",
            "         -0.02509818,  0.        ],\n",
            "        ...,\n",
            "        [-0.01852494,  0.1263586 ,  0.17921685, ...,  0.05430831,\n",
            "          0.03001333,  0.        ],\n",
            "        [-0.2192231 ,  0.12507224,  0.33495733, ...,  0.05876937,\n",
            "         -0.00729459,  0.        ],\n",
            "        [-0.28083536,  0.09817064,  0.29941887, ...,  0.05023274,\n",
            "         -0.00504927,  0.        ]], dtype=float32)\n",
            " array([[-0.01614952, -0.13188967, -0.03547577, ...,  0.05436365,\n",
            "          0.21994983,  0.        ],\n",
            "        [ 0.14762847, -0.04598985, -0.02924673, ...,  0.2617495 ,\n",
            "          0.14277379,  0.        ],\n",
            "        [ 0.1401661 ,  0.00927051, -0.00971096, ...,  0.35632282,\n",
            "         -0.0063797 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.04744829,  0.12966968,  0.17316075, ...,  0.06525526,\n",
            "          0.01877537,  0.        ],\n",
            "        [-0.21268572,  0.1275731 ,  0.2877683 , ...,  0.06961942,\n",
            "         -0.01281438,  0.        ],\n",
            "        [-0.26992685,  0.09392954,  0.27699193, ...,  0.07412635,\n",
            "         -0.00167656,  0.        ]], dtype=float32)\n",
            " array([[-5.41121373e-03, -1.09437518e-01, -4.54782508e-02, ...,\n",
            "          4.09112200e-02,  2.03524277e-01,  0.00000000e+00],\n",
            "        [ 1.62683561e-01, -4.28041676e-03, -2.84687728e-02, ...,\n",
            "          2.50744581e-01,  7.08327517e-02,  0.00000000e+00],\n",
            "        [ 1.75611347e-01,  6.24141246e-02, -2.28141472e-02, ...,\n",
            "          3.11904609e-01, -7.23971352e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [ 7.81936795e-02,  9.00893584e-02,  5.81045784e-02, ...,\n",
            "          4.02088463e-02,  6.17703199e-02,  0.00000000e+00],\n",
            "        [-1.55216396e-01,  1.26081705e-01,  3.08573246e-01, ...,\n",
            "          9.50367972e-02,  2.96896265e-04,  0.00000000e+00],\n",
            "        [-2.52029330e-01,  1.10479504e-01,  2.90031314e-01, ...,\n",
            "          5.83111756e-02,  6.41053682e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.01483055, -0.12404978, -0.02907629, ...,  0.04485377,\n",
            "          0.21203521,  3.        ],\n",
            "        [ 0.15147495, -0.02539426, -0.0060473 , ...,  0.26071265,\n",
            "          0.12166853,  3.        ],\n",
            "        [ 0.15451987,  0.03823886,  0.00864688, ...,  0.33150798,\n",
            "         -0.0161427 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.01267376,  0.1239945 ,  0.18634842, ...,  0.07411047,\n",
            "          0.02721305,  3.        ],\n",
            "        [-0.21270739,  0.12594137,  0.33383954, ...,  0.07659243,\n",
            "         -0.00646719,  3.        ],\n",
            "        [-0.26683548,  0.10633241,  0.29681826, ...,  0.05612719,\n",
            "          0.00706185,  3.        ]], dtype=float32)\n",
            " array([[-1.9664383e-02, -1.3145210e-01, -3.2571442e-02, ...,\n",
            "          5.1460601e-02,  2.1638456e-01,  1.0000000e+00],\n",
            "        [ 1.4736992e-01, -3.7810158e-02, -1.9345757e-02, ...,\n",
            "          2.5275642e-01,  1.3344666e-01,  1.0000000e+00],\n",
            "        [ 1.4332171e-01,  2.0878928e-02,  2.5516134e-03, ...,\n",
            "          3.3810568e-01, -1.4501036e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-6.5361470e-02,  1.4596152e-01,  1.9768460e-01, ...,\n",
            "          5.5706482e-02,  7.6979063e-03,  1.0000000e+00],\n",
            "        [-2.3335655e-01,  1.3565049e-01,  3.1646645e-01, ...,\n",
            "          5.9482262e-02, -2.3942312e-02,  1.0000000e+00],\n",
            "        [-2.7526352e-01,  9.9643722e-02,  2.8983465e-01, ...,\n",
            "          6.7294002e-02,  5.3236645e-04,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.03336255, -0.15952244, -0.05200159, ...,  0.06538031,\n",
            "          0.2106759 ,  1.        ],\n",
            "        [ 0.17317288, -0.11706089, -0.06572358, ...,  0.31778705,\n",
            "          0.16960695,  1.        ],\n",
            "        [ 0.12067405, -0.10989899, -0.06555831, ...,  0.42198217,\n",
            "          0.0854109 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.1525042 ,  0.02250678,  0.1975867 , ...,  0.11639389,\n",
            "         -0.01327245,  1.        ],\n",
            "        [-0.23907055,  0.03874758,  0.20440514, ...,  0.0912487 ,\n",
            "         -0.04091028,  1.        ],\n",
            "        [-0.2611722 ,  0.02617697,  0.23406261, ...,  0.03640728,\n",
            "         -0.02054228,  1.        ]], dtype=float32)\n",
            " array([[-0.02264646, -0.13338909, -0.03001359, ...,  0.0552885 ,\n",
            "          0.2168349 ,  1.        ],\n",
            "        [ 0.15312776, -0.04587824, -0.01392792, ...,  0.26523095,\n",
            "          0.1403255 ,  1.        ],\n",
            "        [ 0.14211722,  0.00386729,  0.00902171, ...,  0.354598  ,\n",
            "          0.0016262 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.12188178,  0.13225666,  0.25074634, ...,  0.08226662,\n",
            "         -0.02064609,  1.        ],\n",
            "        [-0.24840531,  0.12173783,  0.32328105, ...,  0.0740667 ,\n",
            "         -0.03851113,  1.        ],\n",
            "        [-0.2853853 ,  0.09538835,  0.29468468, ...,  0.06437643,\n",
            "         -0.00526218,  1.        ]], dtype=float32)\n",
            " array([[-0.02370227, -0.13224758, -0.02523117, ...,  0.04588544,\n",
            "          0.20899968,  1.        ],\n",
            "        [ 0.13366564, -0.04899461, -0.00533331, ...,  0.25737756,\n",
            "          0.13377944,  1.        ],\n",
            "        [ 0.11718984, -0.00796367,  0.01465603, ...,  0.3397888 ,\n",
            "          0.01754362,  1.        ],\n",
            "        ...,\n",
            "        [-0.12655433,  0.12947105,  0.25505027, ...,  0.07818237,\n",
            "         -0.00592632,  1.        ],\n",
            "        [-0.25624263,  0.11456487,  0.33708367, ...,  0.06528661,\n",
            "         -0.03251409,  1.        ],\n",
            "        [-0.30377385,  0.08944135,  0.30215925, ...,  0.04715906,\n",
            "         -0.0141461 ,  1.        ]], dtype=float32)\n",
            " array([[-2.78904457e-02, -1.24062918e-01, -3.12797539e-02, ...,\n",
            "          5.37903905e-02,  2.05610096e-01,  1.00000000e+00],\n",
            "        [ 1.40148610e-01, -5.53118065e-02, -2.57421639e-02, ...,\n",
            "          2.61023760e-01,  1.37999669e-01,  1.00000000e+00],\n",
            "        [ 1.22189313e-01, -2.45672222e-02, -1.36317154e-02, ...,\n",
            "          3.57155263e-01,  1.91219002e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.24628715e-01,  1.03917763e-01,  2.24111959e-01, ...,\n",
            "          9.72265601e-02, -2.35226005e-04,  1.00000000e+00],\n",
            "        [-2.52894431e-01,  1.00607783e-01,  3.05962592e-01, ...,\n",
            "          7.20267892e-02, -3.50594446e-02,  1.00000000e+00],\n",
            "        [-3.01327318e-01,  8.79905820e-02,  2.87715733e-01, ...,\n",
            "          4.43134196e-02, -1.85735729e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.01749524, -0.1239253 , -0.03427749, ...,  0.05090967,\n",
            "          0.21397223,  1.        ],\n",
            "        [ 0.14834076, -0.02194314, -0.01346144, ...,  0.25423834,\n",
            "          0.11690494,  1.        ],\n",
            "        [ 0.15216361,  0.04426229,  0.00616973, ...,  0.3268365 ,\n",
            "         -0.03475524,  1.        ],\n",
            "        ...,\n",
            "        [-0.0388938 ,  0.13798706,  0.19590525, ...,  0.05785534,\n",
            "          0.00222138,  1.        ],\n",
            "        [-0.22352073,  0.13879754,  0.32362768, ...,  0.06404681,\n",
            "         -0.02015423,  1.        ],\n",
            "        [-0.26974154,  0.10936551,  0.29587188, ...,  0.07062072,\n",
            "          0.00876498,  1.        ]], dtype=float32)\n",
            " array([[-2.45665163e-02, -1.34312496e-01, -2.75526866e-02, ...,\n",
            "          4.68450971e-02,  2.08608836e-01,  1.00000000e+00],\n",
            "        [ 1.36866882e-01, -4.74484563e-02, -1.19380457e-02, ...,\n",
            "          2.66723394e-01,  1.31052971e-01,  1.00000000e+00],\n",
            "        [ 1.17855869e-01, -8.14324245e-03,  4.64201998e-03, ...,\n",
            "          3.51357371e-01,  1.77231897e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.17316395e-01,  1.19747661e-01,  2.35990450e-01, ...,\n",
            "          8.45808163e-02, -7.60230701e-04,  1.00000000e+00],\n",
            "        [-2.49458432e-01,  1.05175570e-01,  3.21674079e-01, ...,\n",
            "          6.84904605e-02, -3.17641906e-02,  1.00000000e+00],\n",
            "        [-2.99105525e-01,  8.65547359e-02,  2.96258956e-01, ...,\n",
            "          4.89501730e-02, -1.50077827e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.03380454, -0.15741938, -0.0584895 , ...,  0.06213852,\n",
            "          0.21094014,  1.        ],\n",
            "        [ 0.13910751, -0.11913418, -0.08158167, ...,  0.30501398,\n",
            "          0.15522668,  1.        ],\n",
            "        [ 0.08516707, -0.11939061, -0.08924095, ...,  0.407235  ,\n",
            "          0.08010318,  1.        ],\n",
            "        ...,\n",
            "        [-0.1575073 ,  0.00935247,  0.19161813, ...,  0.11336827,\n",
            "         -0.02766697,  1.        ],\n",
            "        [-0.2279045 ,  0.02249978,  0.1927189 , ...,  0.09231174,\n",
            "         -0.05436935,  1.        ],\n",
            "        [-0.26373145,  0.00415025,  0.22885454, ...,  0.03192943,\n",
            "         -0.03265665,  1.        ]], dtype=float32)\n",
            " array([[-0.02049593, -0.13257314, -0.03407004, ...,  0.05660817,\n",
            "          0.21761474,  1.        ],\n",
            "        [ 0.159542  , -0.03424236, -0.0144226 , ...,  0.26799417,\n",
            "          0.12887345,  1.        ],\n",
            "        [ 0.15168414,  0.02457297,  0.00474343, ...,  0.34788233,\n",
            "         -0.01307442,  1.        ],\n",
            "        ...,\n",
            "        [-0.04854366,  0.14668669,  0.2051006 , ...,  0.07333324,\n",
            "          0.0094137 ,  1.        ],\n",
            "        [-0.22564429,  0.13667904,  0.31348994, ...,  0.07235198,\n",
            "         -0.01796333,  1.        ],\n",
            "        [-0.27078265,  0.1042214 ,  0.28862777, ...,  0.07422666,\n",
            "          0.00404603,  1.        ]], dtype=float32)\n",
            " array([[-0.0244292 , -0.13176064, -0.02626042, ...,  0.04327898,\n",
            "          0.21004514,  1.        ],\n",
            "        [ 0.13073008, -0.04800883, -0.0039393 , ...,  0.24726053,\n",
            "          0.13292055,  1.        ],\n",
            "        [ 0.11567546, -0.00404234,  0.01797117, ...,  0.33176   ,\n",
            "          0.00821906,  1.        ],\n",
            "        ...,\n",
            "        [-0.12115783,  0.13153686,  0.24734282, ...,  0.07088745,\n",
            "         -0.00350703,  1.        ],\n",
            "        [-0.2560426 ,  0.12156787,  0.33586764, ...,  0.05657971,\n",
            "         -0.03423894,  1.        ],\n",
            "        [-0.30243674,  0.09213585,  0.3010503 , ...,  0.04409275,\n",
            "         -0.01590163,  1.        ]], dtype=float32)\n",
            " array([[-1.64711885e-02, -1.29008234e-01, -3.04759517e-02, ...,\n",
            "          4.95640524e-02,  2.10281745e-01,  1.00000000e+00],\n",
            "        [ 1.51258275e-01, -3.82613763e-02, -1.32064596e-02, ...,\n",
            "          2.75980294e-01,  1.24914058e-01,  1.00000000e+00],\n",
            "        [ 1.50279000e-01,  1.46878641e-02, -8.83131521e-04, ...,\n",
            "          3.59793633e-01, -7.45686749e-03,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-4.78518158e-02,  1.18684724e-01,  1.97856754e-01, ...,\n",
            "          1.00346074e-01,  1.61595959e-02,  1.00000000e+00],\n",
            "        [-2.23673001e-01,  1.19339734e-01,  3.21650565e-01, ...,\n",
            "          8.73823464e-02, -1.77335478e-02,  1.00000000e+00],\n",
            "        [-2.72497922e-01,  1.02216475e-01,  2.89108157e-01, ...,\n",
            "          5.90588488e-02,  1.98428007e-03,  1.00000000e+00]], dtype=float32)\n",
            " array([[-9.2304451e-03, -1.1846925e-01, -3.3539265e-02, ...,\n",
            "          4.3783642e-02,  2.0902130e-01,  1.0000000e+00],\n",
            "        [ 1.5776487e-01, -1.7369822e-02, -1.4773730e-02, ...,\n",
            "          2.5961486e-01,  1.0695558e-01,  1.0000000e+00],\n",
            "        [ 1.6547239e-01,  5.2686650e-02, -2.1851732e-04, ...,\n",
            "          3.2864183e-01, -3.9926890e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [ 3.1178327e-02,  1.2141363e-01,  1.4081101e-01, ...,\n",
            "          6.3977428e-02,  4.2776048e-02,  1.0000000e+00],\n",
            "        [-1.8793458e-01,  1.2622254e-01,  3.1939080e-01, ...,\n",
            "          8.4126286e-02, -8.8948582e-08,  1.0000000e+00],\n",
            "        [-2.5644174e-01,  1.1000537e-01,  2.9263857e-01, ...,\n",
            "          5.9298042e-02,  7.1333032e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.0322363 , -0.15823288, -0.04381682, ...,  0.06023479,\n",
            "          0.21169837,  1.        ],\n",
            "        [ 0.16591048, -0.09612425, -0.05398342, ...,  0.3026771 ,\n",
            "          0.15704627,  1.        ],\n",
            "        [ 0.11900704, -0.09456845, -0.05397129, ...,  0.38775668,\n",
            "          0.08525305,  1.        ],\n",
            "        ...,\n",
            "        [-0.1319621 ,  0.01970115,  0.20867203, ...,  0.1140107 ,\n",
            "          0.0100354 ,  1.        ],\n",
            "        [-0.23455724,  0.03319609,  0.23352216, ...,  0.0939602 ,\n",
            "         -0.03806137,  1.        ],\n",
            "        [-0.27426037,  0.03326831,  0.2526274 , ...,  0.03904299,\n",
            "         -0.01821063,  1.        ]], dtype=float32)\n",
            " array([[-0.0378045 , -0.15285866, -0.05741339, ...,  0.06115913,\n",
            "          0.20402932,  1.        ],\n",
            "        [ 0.11943454, -0.12139756, -0.07385018, ...,  0.28325528,\n",
            "          0.15133336,  1.        ],\n",
            "        [ 0.05414636, -0.11784264, -0.08132719, ...,  0.3870265 ,\n",
            "          0.07832758,  1.        ],\n",
            "        ...,\n",
            "        [-0.20849553,  0.03451633,  0.1996971 , ...,  0.09235831,\n",
            "         -0.05796757,  1.        ],\n",
            "        [-0.26309443,  0.05088788,  0.19875664, ...,  0.07833716,\n",
            "         -0.07878377,  1.        ],\n",
            "        [-0.26773664,  0.0227823 ,  0.23444891, ...,  0.02102865,\n",
            "         -0.04289364,  1.        ]], dtype=float32)\n",
            " array([[-2.3037661e-02, -1.3275211e-01, -2.4409924e-02, ...,\n",
            "          4.5870740e-02,  2.0882769e-01,  1.0000000e+00],\n",
            "        [ 1.3580495e-01, -4.5902200e-02, -3.2553058e-03, ...,\n",
            "          2.5412515e-01,  1.3301715e-01,  1.0000000e+00],\n",
            "        [ 1.2123727e-01, -2.9262288e-03,  1.6433522e-02, ...,\n",
            "          3.3625072e-01,  1.6170820e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1660930e-01,  1.3043401e-01,  2.5291446e-01, ...,\n",
            "          7.8278445e-02, -7.7681069e-04,  1.0000000e+00],\n",
            "        [-2.5581652e-01,  1.1684508e-01,  3.3968160e-01, ...,\n",
            "          6.5750510e-02, -2.9008454e-02,  1.0000000e+00],\n",
            "        [-3.0165249e-01,  9.1062844e-02,  3.0189541e-01, ...,\n",
            "          4.8656274e-02, -1.2670942e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02460298, -0.13020667, -0.02479949, ...,  0.04437539,\n",
            "          0.20773336,  1.        ],\n",
            "        [ 0.12706341, -0.05075973, -0.00337186, ...,  0.24664956,\n",
            "          0.13281755,  1.        ],\n",
            "        [ 0.11080398, -0.00871872,  0.01633468, ...,  0.33341128,\n",
            "          0.00796976,  1.        ],\n",
            "        ...,\n",
            "        [-0.1276158 ,  0.1340761 ,  0.2629553 , ...,  0.07944738,\n",
            "         -0.00705965,  1.        ],\n",
            "        [-0.26330543,  0.12430702,  0.34776893, ...,  0.06218985,\n",
            "         -0.03556756,  1.        ],\n",
            "        [-0.30796283,  0.09288449,  0.30591455, ...,  0.04505692,\n",
            "         -0.01777129,  1.        ]], dtype=float32)\n",
            " array([[-0.01620841, -0.11773072, -0.03516945, ...,  0.04362996,\n",
            "          0.2141623 ,  1.        ],\n",
            "        [ 0.14078018, -0.02220813, -0.01490067, ...,  0.2424094 ,\n",
            "          0.1210461 ,  1.        ],\n",
            "        [ 0.14557967,  0.04830053,  0.01100862, ...,  0.31725368,\n",
            "         -0.03361328,  1.        ],\n",
            "        ...,\n",
            "        [-0.01741089,  0.12930603,  0.17857507, ...,  0.0489898 ,\n",
            "          0.02075768,  1.        ],\n",
            "        [-0.20842344,  0.13970393,  0.32807228, ...,  0.06285021,\n",
            "         -0.00764915,  1.        ],\n",
            "        [-0.26904917,  0.10445111,  0.3028323 , ...,  0.06321496,\n",
            "          0.0072558 ,  1.        ]], dtype=float32)\n",
            " array([[-0.01418314, -0.12019573, -0.03814282, ...,  0.04645696,\n",
            "          0.21531636,  1.        ],\n",
            "        [ 0.13174894, -0.019515  , -0.01128546, ...,  0.22620018,\n",
            "          0.12257495,  1.        ],\n",
            "        [ 0.13476354,  0.04570853,  0.00437545, ...,  0.30188993,\n",
            "         -0.03457795,  1.        ],\n",
            "        ...,\n",
            "        [-0.02320079,  0.14353374,  0.1623102 , ...,  0.03084776,\n",
            "          0.03192446,  1.        ],\n",
            "        [-0.21669225,  0.14942133,  0.32556406, ...,  0.04771538,\n",
            "         -0.00456815,  1.        ],\n",
            "        [-0.2713474 ,  0.10159727,  0.29738098, ...,  0.06286889,\n",
            "          0.00328986,  1.        ]], dtype=float32)\n",
            " array([[-0.01255337, -0.11673891, -0.04070864, ...,  0.03707341,\n",
            "          0.20039546,  1.        ],\n",
            "        [ 0.1472193 , -0.00927668, -0.01923006, ...,  0.23944497,\n",
            "          0.07263502,  1.        ],\n",
            "        [ 0.15036267,  0.05548036, -0.00938066, ...,  0.31006548,\n",
            "         -0.06876746,  1.        ],\n",
            "        ...,\n",
            "        [ 0.03779997,  0.11574401,  0.10532504, ...,  0.03302018,\n",
            "          0.04011523,  1.        ],\n",
            "        [-0.19146043,  0.11958548,  0.31669173, ...,  0.06617972,\n",
            "         -0.01339722,  1.        ],\n",
            "        [-0.26819155,  0.09167331,  0.29600394, ...,  0.04660028,\n",
            "         -0.0060981 ,  1.        ]], dtype=float32)\n",
            " array([[-3.4119174e-02, -1.2609503e-01, -3.2121886e-02, ...,\n",
            "          5.3747442e-02,  2.0741294e-01,  1.0000000e+00],\n",
            "        [ 1.3606580e-01, -5.7571292e-02, -3.5891037e-02, ...,\n",
            "          2.5656876e-01,  1.4182188e-01,  1.0000000e+00],\n",
            "        [ 1.1186314e-01, -3.0388186e-02, -2.5419068e-02, ...,\n",
            "          3.5008436e-01,  3.0079493e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.4986108e-01,  9.2533864e-02,  2.4263185e-01, ...,\n",
            "          9.1341436e-02,  9.5851917e-04,  1.0000000e+00],\n",
            "        [-2.6687372e-01,  8.6918660e-02,  3.0241480e-01, ...,\n",
            "          7.0061743e-02, -3.9379880e-02,  1.0000000e+00],\n",
            "        [-3.0663216e-01,  8.3335027e-02,  2.8768888e-01, ...,\n",
            "          3.4783069e-02, -1.9950319e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-2.2607822e-02, -1.3059178e-01, -2.5754562e-02, ...,\n",
            "          4.3271460e-02,  2.0920937e-01,  1.0000000e+00],\n",
            "        [ 1.3324611e-01, -4.5269825e-02, -4.3163975e-03, ...,\n",
            "          2.5232968e-01,  1.2839189e-01,  1.0000000e+00],\n",
            "        [ 1.2332881e-01,  6.4068460e-03,  1.5882131e-02, ...,\n",
            "          3.3774880e-01, -9.0039166e-04,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-9.7444423e-02,  1.3515939e-01,  2.3557778e-01, ...,\n",
            "          7.8423887e-02,  6.2723234e-03,  1.0000000e+00],\n",
            "        [-2.4838863e-01,  1.2595436e-01,  3.3848542e-01, ...,\n",
            "          6.5060414e-02, -2.6763149e-02,  1.0000000e+00],\n",
            "        [-2.9805568e-01,  9.4081685e-02,  3.0058500e-01, ...,\n",
            "          4.9112435e-02, -1.1457022e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02939509, -0.15052249, -0.0435121 , ...,  0.05776186,\n",
            "          0.21362925,  1.        ],\n",
            "        [ 0.15401527, -0.08289156, -0.06814846, ...,  0.29493776,\n",
            "          0.14829867,  1.        ],\n",
            "        [ 0.119144  , -0.0732405 , -0.07406658, ...,  0.38771212,\n",
            "          0.04877469,  1.        ],\n",
            "        ...,\n",
            "        [-0.11935864,  0.0269765 ,  0.19199298, ...,  0.0999032 ,\n",
            "          0.02337913,  1.        ],\n",
            "        [-0.2193294 ,  0.02635626,  0.24202067, ...,  0.07933273,\n",
            "         -0.01793019,  1.        ],\n",
            "        [-0.27621874,  0.03396474,  0.2537206 , ...,  0.04598169,\n",
            "         -0.01728746,  1.        ]], dtype=float32)\n",
            " array([[-0.0155017 , -0.1164477 , -0.03738982, ...,  0.0441276 ,\n",
            "          0.21700682,  1.        ],\n",
            "        [ 0.13892342, -0.02250945, -0.01677296, ...,  0.24084191,\n",
            "          0.12254092,  1.        ],\n",
            "        [ 0.1453566 ,  0.04588739,  0.00709062, ...,  0.31505302,\n",
            "         -0.03336922,  1.        ],\n",
            "        ...,\n",
            "        [-0.01768866,  0.13042194,  0.16877909, ...,  0.04970678,\n",
            "          0.02881481,  1.        ],\n",
            "        [-0.20745632,  0.1445704 ,  0.31804076, ...,  0.06116961,\n",
            "         -0.00462589,  1.        ],\n",
            "        [-0.27287656,  0.10671308,  0.29804462, ...,  0.06321174,\n",
            "          0.00859632,  1.        ]], dtype=float32)\n",
            " array([[-0.03674658, -0.15518832, -0.0555952 , ...,  0.06155408,\n",
            "          0.21135478,  1.        ],\n",
            "        [ 0.13988611, -0.11181495, -0.07855086, ...,  0.3021231 ,\n",
            "          0.15748572,  1.        ],\n",
            "        [ 0.086004  , -0.11208406, -0.08586544, ...,  0.4009268 ,\n",
            "          0.08149134,  1.        ],\n",
            "        ...,\n",
            "        [-0.1688612 ,  0.01622963,  0.20079197, ...,  0.10555796,\n",
            "         -0.03149424,  1.        ],\n",
            "        [-0.2366675 ,  0.02304958,  0.20445564, ...,  0.08749329,\n",
            "         -0.05338522,  1.        ],\n",
            "        [-0.2712694 ,  0.00962042,  0.23740368, ...,  0.02975094,\n",
            "         -0.03293324,  1.        ]], dtype=float32)\n",
            " array([[-1.6869638e-02, -1.2340236e-01, -3.6242716e-02, ...,\n",
            "          4.5904037e-02,  2.1689023e-01,  1.0000000e+00],\n",
            "        [ 1.3710696e-01, -2.3871765e-02, -1.5155001e-02, ...,\n",
            "          2.4205661e-01,  1.2592006e-01,  1.0000000e+00],\n",
            "        [ 1.3922358e-01,  3.9824352e-02,  5.6118807e-03, ...,\n",
            "          3.1895638e-01, -2.1927902e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-3.0807488e-02,  1.3592713e-01,  1.7691751e-01, ...,\n",
            "          5.0100658e-02,  2.4297427e-02,  1.0000000e+00],\n",
            "        [-2.1536100e-01,  1.3658194e-01,  3.1884757e-01, ...,\n",
            "          5.6070875e-02, -9.8005310e-03,  1.0000000e+00],\n",
            "        [-2.7424774e-01,  9.7144842e-02,  2.9467931e-01, ...,\n",
            "          5.9895374e-02, -5.4129562e-04,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02217198, -0.14914873, -0.04404445, ...,  0.07346633,\n",
            "          0.21567486,  1.        ],\n",
            "        [ 0.19506057, -0.06830287, -0.05820715, ...,  0.3007375 ,\n",
            "          0.1508604 ,  1.        ],\n",
            "        [ 0.16017114, -0.05618699, -0.05092775, ...,  0.39667732,\n",
            "          0.04858255,  1.        ],\n",
            "        ...,\n",
            "        [-0.08093791,  0.03568661,  0.1769267 , ...,  0.08544556,\n",
            "          0.01099601,  1.        ],\n",
            "        [-0.19349319,  0.04985096,  0.22445948, ...,  0.08350211,\n",
            "         -0.02406853,  1.        ],\n",
            "        [-0.2466875 ,  0.05235057,  0.23948814, ...,  0.06380884,\n",
            "         -0.01042477,  1.        ]], dtype=float32)\n",
            " array([[-0.01327848, -0.12250534, -0.03055838, ...,  0.04405614,\n",
            "          0.21024957,  1.        ],\n",
            "        [ 0.14698268, -0.0244194 , -0.0106489 , ...,  0.2613021 ,\n",
            "          0.11209685,  1.        ],\n",
            "        [ 0.15544634,  0.04334809,  0.00350242, ...,  0.3329562 ,\n",
            "         -0.03080771,  1.        ],\n",
            "        ...,\n",
            "        [-0.00274834,  0.12260263,  0.17440921, ...,  0.07372025,\n",
            "          0.02769721,  1.        ],\n",
            "        [-0.20785686,  0.12690032,  0.33362854, ...,  0.0811473 ,\n",
            "         -0.00488417,  1.        ],\n",
            "        [-0.26560944,  0.10709003,  0.29780298, ...,  0.05935733,\n",
            "          0.00626357,  1.        ]], dtype=float32)\n",
            " array([[-0.01523639, -0.12740256, -0.02798125, ...,  0.04626468,\n",
            "          0.21076052,  1.        ],\n",
            "        [ 0.14983755, -0.03176328, -0.00376947, ...,  0.26311105,\n",
            "          0.12118605,  1.        ],\n",
            "        [ 0.15208764,  0.0273828 ,  0.00937176, ...,  0.3385799 ,\n",
            "         -0.01344517,  1.        ],\n",
            "        ...,\n",
            "        [-0.03301089,  0.12414891,  0.20183736, ...,  0.08243634,\n",
            "          0.02152513,  1.        ],\n",
            "        [-0.22145227,  0.1276973 ,  0.33587486, ...,  0.08124578,\n",
            "         -0.01176192,  1.        ],\n",
            "        [-0.27115738,  0.10742261,  0.29754934, ...,  0.05799746,\n",
            "          0.00524192,  1.        ]], dtype=float32)\n",
            " array([[-0.00394507, -0.11304309, -0.0417644 , ...,  0.04137134,\n",
            "          0.2050478 ,  0.        ],\n",
            "        [ 0.16195841, -0.0053108 , -0.02572901, ...,  0.24394487,\n",
            "          0.08493565,  0.        ],\n",
            "        [ 0.17260201,  0.06082173, -0.01823127, ...,  0.311647  ,\n",
            "         -0.06232702,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05867664,  0.10721779,  0.09002659, ...,  0.03945896,\n",
            "          0.05802524,  0.        ],\n",
            "        [-0.17345306,  0.12355632,  0.31002244, ...,  0.08415824,\n",
            "         -0.0016944 ,  0.        ],\n",
            "        [-0.25124767,  0.10869855,  0.28654882, ...,  0.05380462,\n",
            "          0.00145502,  0.        ]], dtype=float32)\n",
            " array([[-1.42191704e-02, -1.21749952e-01, -2.91807577e-02, ...,\n",
            "          4.33440320e-02,  2.10779414e-01,  3.00000000e+00],\n",
            "        [ 1.48342550e-01, -2.54682600e-02, -5.51636005e-03, ...,\n",
            "          2.54553467e-01,  1.15070276e-01,  3.00000000e+00],\n",
            "        [ 1.54797614e-01,  4.32595834e-02,  9.99491941e-03, ...,\n",
            "          3.25119019e-01, -2.96794437e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.03454595e-03,  1.22992247e-01,  1.75663963e-01, ...,\n",
            "          6.10467233e-02,  3.43217105e-02,  3.00000000e+00],\n",
            "        [-2.08152011e-01,  1.28415808e-01,  3.34005892e-01, ...,\n",
            "          7.37982541e-02, -2.10620672e-03,  3.00000000e+00],\n",
            "        [-2.66187251e-01,  1.09809183e-01,  2.97495931e-01, ...,\n",
            "          5.49639203e-02,  8.85419920e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.01626579, -0.12921573, -0.02740039, ...,  0.0470802 ,\n",
            "          0.21232162,  3.        ],\n",
            "        [ 0.15282391, -0.03487961, -0.00492918, ...,  0.26723668,\n",
            "          0.12605324,  3.        ],\n",
            "        [ 0.15346721,  0.02429049,  0.00970464, ...,  0.3445449 ,\n",
            "         -0.00602763,  3.        ],\n",
            "        ...,\n",
            "        [-0.03980157,  0.12074697,  0.20521459, ...,  0.0878748 ,\n",
            "          0.01954398,  3.        ],\n",
            "        [-0.22294079,  0.12399863,  0.33191493, ...,  0.08203062,\n",
            "         -0.01370182,  3.        ],\n",
            "        [-0.27270314,  0.10441282,  0.2952879 , ...,  0.05917932,\n",
            "          0.00383013,  3.        ]], dtype=float32)\n",
            " array([[-1.12440940e-02, -1.23878345e-01, -3.15896794e-02, ...,\n",
            "          4.64421995e-02,  2.11777151e-01,  2.00000000e+00],\n",
            "        [ 1.60041332e-01, -2.51826290e-02, -1.32871447e-02, ...,\n",
            "          2.68625289e-01,  1.20678082e-01,  2.00000000e+00],\n",
            "        [ 1.63767934e-01,  3.98649424e-02,  1.07669213e-03, ...,\n",
            "          3.43894124e-01, -2.07280833e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-3.88204353e-05,  1.17788635e-01,  1.64725706e-01, ...,\n",
            "          8.44372585e-02,  3.46698873e-02,  2.00000000e+00],\n",
            "        [-2.02794522e-01,  1.22463018e-01,  3.18190455e-01, ...,\n",
            "          8.50330517e-02, -2.84069055e-03,  2.00000000e+00],\n",
            "        [-2.61612058e-01,  1.06876746e-01,  2.89862782e-01, ...,\n",
            "          6.20902888e-02,  7.83887412e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-3.69484606e-03, -1.11819416e-01, -4.37767915e-02, ...,\n",
            "          4.20171618e-02,  2.06159711e-01,  2.00000000e+00],\n",
            "        [ 1.66917562e-01, -5.27932728e-03, -3.20441686e-02, ...,\n",
            "          2.51613498e-01,  7.54520819e-02,  2.00000000e+00],\n",
            "        [ 1.80990547e-01,  6.13278672e-02, -2.72135735e-02, ...,\n",
            "          3.15719873e-01, -6.69883266e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [ 7.47874603e-02,  9.80172753e-02,  7.07319304e-02, ...,\n",
            "          5.31582609e-02,  6.04294948e-02,  2.00000000e+00],\n",
            "        [-1.59396470e-01,  1.24466285e-01,  3.05934668e-01, ...,\n",
            "          1.01617910e-01, -5.59009553e-04,  2.00000000e+00],\n",
            "        [-2.47582763e-01,  1.06982410e-01,  2.89038271e-01, ...,\n",
            "          6.42084181e-02,  6.41275337e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[-0.01573599, -0.12534836, -0.02889393, ...,  0.04590463,\n",
            "          0.21126783,  1.        ],\n",
            "        [ 0.14969361, -0.02950898, -0.00651639, ...,  0.26259917,\n",
            "          0.12134559,  1.        ],\n",
            "        [ 0.15243982,  0.03221598,  0.00824964, ...,  0.33773816,\n",
            "         -0.0173633 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.02921724,  0.12307289,  0.19809087, ...,  0.08278764,\n",
            "          0.0203053 ,  1.        ],\n",
            "        [-0.22277676,  0.12676406,  0.3370428 , ...,  0.07989442,\n",
            "         -0.01157213,  1.        ],\n",
            "        [-0.27130273,  0.10735155,  0.29748166, ...,  0.05721361,\n",
            "          0.00533486,  1.        ]], dtype=float32)\n",
            " array([[ 2.23713629e-02, -1.19910218e-01, -7.37381130e-02, ...,\n",
            "          5.94319291e-02,  2.13191062e-01,  3.00000000e+00],\n",
            "        [ 1.89956129e-01, -6.04336616e-03, -6.35773391e-02, ...,\n",
            "          2.37670138e-01,  8.01294446e-02,  3.00000000e+00],\n",
            "        [ 1.86401069e-01,  4.56673503e-02, -5.46421595e-02, ...,\n",
            "          3.25590640e-01, -8.12445879e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.26823172e-01,  8.67818594e-02,  3.11833061e-02, ...,\n",
            "          4.75516282e-02,  5.81776462e-02,  3.00000000e+00],\n",
            "        [-1.11257076e-01,  1.32269204e-01,  2.41128251e-01, ...,\n",
            "          8.69496688e-02, -1.92473026e-03,  3.00000000e+00],\n",
            "        [-2.19657928e-01,  9.29528475e-02,  2.60228097e-01, ...,\n",
            "          7.70629123e-02,  2.01061065e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.0358177 , -0.14835478, -0.04467376, ...,  0.06341485,\n",
            "          0.21239613,  3.        ],\n",
            "        [ 0.15116788, -0.10162023, -0.05306782, ...,  0.28254128,\n",
            "          0.17458743,  3.        ],\n",
            "        [ 0.09624863, -0.08861382, -0.05203802, ...,  0.3856488 ,\n",
            "          0.08304416,  3.        ],\n",
            "        ...,\n",
            "        [-0.17999978,  0.04180461,  0.22773854, ...,  0.08818824,\n",
            "         -0.01610329,  3.        ],\n",
            "        [-0.27723104,  0.06801715,  0.23517072, ...,  0.07118528,\n",
            "         -0.05517603,  3.        ],\n",
            "        [-0.27975857,  0.04872304,  0.2534869 , ...,  0.02755263,\n",
            "         -0.03044967,  3.        ]], dtype=float32)\n",
            " array([[-0.03042706, -0.14562948, -0.0419724 , ...,  0.05365938,\n",
            "          0.21184492,  3.        ],\n",
            "        [ 0.14998205, -0.07932954, -0.06259006, ...,  0.28113928,\n",
            "          0.14587365,  3.        ],\n",
            "        [ 0.11548831, -0.06747676, -0.06792514, ...,  0.37436888,\n",
            "          0.04325574,  3.        ],\n",
            "        ...,\n",
            "        [-0.117492  ,  0.04141832,  0.1887943 , ...,  0.1012419 ,\n",
            "          0.02411709,  3.        ],\n",
            "        [-0.23048982,  0.03815247,  0.25317514, ...,  0.07432229,\n",
            "         -0.02379187,  3.        ],\n",
            "        [-0.28535503,  0.04345846,  0.26123822, ...,  0.03975853,\n",
            "         -0.02064956,  3.        ]], dtype=float32)\n",
            " array([[-2.16265190e-02, -1.31717265e-01, -2.62883212e-02, ...,\n",
            "          4.39692214e-02,  2.08980948e-01,  3.00000000e+00],\n",
            "        [ 1.33002639e-01, -4.39932346e-02, -2.94610392e-03, ...,\n",
            "          2.51598835e-01,  1.29833117e-01,  3.00000000e+00],\n",
            "        [ 1.23257264e-01,  5.03899762e-03,  1.67597122e-02, ...,\n",
            "          3.33162874e-01,  1.37576682e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-9.13782343e-02,  1.30802646e-01,  2.33851045e-01, ...,\n",
            "          7.97718465e-02,  3.17742303e-03,  3.00000000e+00],\n",
            "        [-2.47688591e-01,  1.24367625e-01,  3.39769602e-01, ...,\n",
            "          6.60577789e-02, -2.80379690e-02,  3.00000000e+00],\n",
            "        [-2.95321435e-01,  9.29125473e-02,  2.99951613e-01, ...,\n",
            "          4.93020266e-02, -1.11773666e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.79939996e-02, -1.18247651e-01, -3.34849544e-02, ...,\n",
            "          3.60572152e-02,  2.02909335e-01,  3.00000000e+00],\n",
            "        [ 1.27415165e-01, -1.48700681e-02, -5.19880792e-03, ...,\n",
            "          2.35814676e-01,  9.31387022e-02,  3.00000000e+00],\n",
            "        [ 1.28970966e-01,  5.20354882e-02,  1.02084605e-02, ...,\n",
            "          3.10117364e-01, -4.77794297e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 8.49581193e-05,  1.28213897e-01,  1.57036185e-01, ...,\n",
            "          3.42650414e-02,  3.04493662e-02,  3.00000000e+00],\n",
            "        [-2.13364020e-01,  1.23168506e-01,  3.36904377e-01, ...,\n",
            "          5.19778877e-02, -1.24132540e-02,  3.00000000e+00],\n",
            "        [-2.79509723e-01,  9.54631120e-02,  3.04808795e-01, ...,\n",
            "          4.24712263e-02, -4.21518786e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.5128378e-02, -1.3240051e-01, -2.5378371e-02, ...,\n",
            "          4.5785658e-02,  2.0890997e-01,  3.0000000e+00],\n",
            "        [ 1.3483886e-01, -4.4366959e-02, -8.5356506e-03, ...,\n",
            "          2.5420508e-01,  1.3238016e-01,  3.0000000e+00],\n",
            "        [ 1.1862171e-01, -1.7317873e-03,  1.1974119e-02, ...,\n",
            "          3.3871147e-01,  1.1562647e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2463879e-01,  1.2764530e-01,  2.4528228e-01, ...,\n",
            "          7.6956660e-02, -7.5910510e-03,  3.0000000e+00],\n",
            "        [-2.5710782e-01,  1.1278194e-01,  3.3198202e-01, ...,\n",
            "          6.0572512e-02, -3.5984527e-02,  3.0000000e+00],\n",
            "        [-3.0271828e-01,  8.9220285e-02,  3.0084261e-01, ...,\n",
            "          4.4762596e-02, -1.6629679e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.0323167e-02, -1.3773121e-01, -2.9960746e-02, ...,\n",
            "          5.5055961e-02,  2.1913098e-01,  3.0000000e+00],\n",
            "        [ 1.4841369e-01, -4.4756491e-02, -8.8663911e-03, ...,\n",
            "          2.4056654e-01,  1.4160377e-01,  3.0000000e+00],\n",
            "        [ 1.3592938e-01,  4.1494183e-03,  1.2184331e-02, ...,\n",
            "          3.2485297e-01, -8.5826876e-05,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-5.9594940e-02,  1.5464541e-01,  2.0000573e-01, ...,\n",
            "          4.6890032e-02,  2.1217873e-02,  3.0000000e+00],\n",
            "        [-2.2963336e-01,  1.4430822e-01,  3.0870330e-01, ...,\n",
            "          5.3201530e-02, -1.4656176e-02,  3.0000000e+00],\n",
            "        [-2.7719381e-01,  1.0698682e-01,  2.8686601e-01, ...,\n",
            "          7.1912944e-02,  2.0158959e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-9.6662687e-03, -1.1324165e-01, -3.4763549e-02, ...,\n",
            "          4.2410508e-02,  2.0851006e-01,  3.0000000e+00],\n",
            "        [ 1.5298787e-01, -1.0524190e-02, -1.3202905e-02, ...,\n",
            "          2.4593966e-01,  1.0085740e-01,  3.0000000e+00],\n",
            "        [ 1.6281842e-01,  6.0497988e-02, -2.8194461e-04, ...,\n",
            "          3.1144196e-01, -4.9244706e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 3.5227805e-02,  1.1680430e-01,  1.2289393e-01, ...,\n",
            "          3.8100347e-02,  5.0202329e-02,  3.0000000e+00],\n",
            "        [-1.8547036e-01,  1.2705946e-01,  3.2412925e-01, ...,\n",
            "          7.6058261e-02,  3.4856386e-03,  3.0000000e+00],\n",
            "        [-2.5679818e-01,  1.1157189e-01,  2.9449177e-01, ...,\n",
            "          5.4932412e-02,  7.3289955e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-1.3215460e-02, -1.2042994e-01, -3.1706471e-02, ...,\n",
            "          4.4977039e-02,  2.1061082e-01,  3.0000000e+00],\n",
            "        [ 1.4992426e-01, -2.2156978e-02, -1.2832073e-02, ...,\n",
            "          2.5777319e-01,  1.1213206e-01,  3.0000000e+00],\n",
            "        [ 1.5633565e-01,  4.6152204e-02,  1.4669942e-03, ...,\n",
            "          3.2887948e-01, -3.2741331e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 7.4714688e-03,  1.2218603e-01,  1.6499254e-01, ...,\n",
            "          6.6342026e-02,  3.5533331e-02,  3.0000000e+00],\n",
            "        [-2.0300514e-01,  1.2663913e-01,  3.2963443e-01, ...,\n",
            "          8.0325708e-02, -9.3540951e-04,  3.0000000e+00],\n",
            "        [-2.6308626e-01,  1.0915706e-01,  2.9554468e-01, ...,\n",
            "          5.8799312e-02,  9.0279942e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03765602, -0.12617788, -0.03910878, ...,  0.06750498,\n",
            "          0.20677991,  3.        ],\n",
            "        [ 0.17430408,  0.01794174, -0.03148841, ...,  0.29172885,\n",
            "          0.12337881,  3.        ],\n",
            "        [ 0.18683533,  0.05670454, -0.00857538, ...,  0.35948253,\n",
            "          0.0546322 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.08459453,  0.10265721,  0.22753972, ...,  0.14022683,\n",
            "         -0.01418083,  3.        ],\n",
            "        [-0.21401122,  0.09748346,  0.30905804, ...,  0.11196777,\n",
            "         -0.03845031,  3.        ],\n",
            "        [-0.27860758,  0.08571183,  0.2802591 , ...,  0.05778735,\n",
            "         -0.01883662,  3.        ]], dtype=float32)\n",
            " array([[-0.0372475 , -0.14063826, -0.03138664, ...,  0.06150356,\n",
            "          0.2143564 ,  3.        ],\n",
            "        [ 0.15818822, -0.06158632, -0.03617916, ...,  0.26221904,\n",
            "          0.1513943 ,  3.        ],\n",
            "        [ 0.12110928, -0.04055912, -0.02064632, ...,  0.35295242,\n",
            "          0.05043113,  3.        ],\n",
            "        ...,\n",
            "        [-0.12884557,  0.10105988,  0.2289939 , ...,  0.06661305,\n",
            "          0.00958864,  3.        ],\n",
            "        [-0.26086116,  0.08855465,  0.28659058, ...,  0.0581761 ,\n",
            "         -0.03500282,  3.        ],\n",
            "        [-0.2951575 ,  0.08005369,  0.2768496 , ...,  0.04646793,\n",
            "         -0.01485887,  3.        ]], dtype=float32)\n",
            " array([[ 0.05606213, -0.2066301 , -0.11454425, ..., -0.01319182,\n",
            "          0.18909787,  3.        ],\n",
            "        [ 0.32013124,  0.02215601, -0.10699871, ...,  0.06091345,\n",
            "          0.01811507,  3.        ],\n",
            "        [ 0.31666487,  0.05735199, -0.08835828, ...,  0.11527643,\n",
            "         -0.08300672,  3.        ],\n",
            "        ...,\n",
            "        [ 0.1674411 , -0.02129094, -0.17718858, ...,  0.03601348,\n",
            "          0.07962772,  3.        ],\n",
            "        [ 0.0269583 ,  0.04357944,  0.10191137, ...,  0.11779964,\n",
            "         -0.01524291,  3.        ],\n",
            "        [-0.16847266,  0.02251454,  0.27832806, ...,  0.0567752 ,\n",
            "         -0.00957952,  3.        ]], dtype=float32)\n",
            " array([[-1.97207872e-02, -1.31224960e-01, -3.35579179e-02, ...,\n",
            "          5.54759465e-02,  2.18666062e-01,  3.00000000e+00],\n",
            "        [ 1.36658177e-01, -4.33818176e-02, -9.66118742e-03, ...,\n",
            "          2.42903739e-01,  1.41674638e-01,  3.00000000e+00],\n",
            "        [ 1.32605359e-01,  1.47242015e-02,  1.46062402e-02, ...,\n",
            "          3.22383851e-01, -7.50580011e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-6.06290475e-02,  1.41855642e-01,  2.20847681e-01, ...,\n",
            "          6.62560835e-02,  8.54363851e-03,  3.00000000e+00],\n",
            "        [-2.37234965e-01,  1.33621141e-01,  3.35862011e-01, ...,\n",
            "          6.71323314e-02, -2.19983608e-02,  3.00000000e+00],\n",
            "        [-2.79400349e-01,  1.00536093e-01,  2.96551406e-01, ...,\n",
            "          6.72592148e-02,  1.24931568e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.9286282e-02, -1.3474585e-01, -3.3612341e-02, ...,\n",
            "          5.3176139e-02,  2.2093399e-01,  3.0000000e+00],\n",
            "        [ 1.4775285e-01, -4.0117234e-02, -1.2729223e-02, ...,\n",
            "          2.6014048e-01,  1.4269218e-01,  3.0000000e+00],\n",
            "        [ 1.4002122e-01,  1.5890583e-02,  1.1442351e-02, ...,\n",
            "          3.4369814e-01,  2.5740927e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-7.5330570e-02,  1.4800769e-01,  2.1301597e-01, ...,\n",
            "          7.5468756e-02,  5.4081273e-03,  3.0000000e+00],\n",
            "        [-2.3136339e-01,  1.3398343e-01,  3.1464535e-01, ...,\n",
            "          6.7554601e-02, -3.0756546e-02,  3.0000000e+00],\n",
            "        [-2.8190383e-01,  9.0156779e-02,  2.8919771e-01, ...,\n",
            "          6.8510413e-02, -1.3499530e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.01752434, -0.13033342, -0.03221682, ...,  0.04303879,\n",
            "          0.20961732,  3.        ],\n",
            "        [ 0.1455017 , -0.03082827, -0.00843588, ...,  0.25994995,\n",
            "          0.12214079,  3.        ],\n",
            "        [ 0.14210454,  0.02506923,  0.01080197, ...,  0.33971724,\n",
            "         -0.01348237,  3.        ],\n",
            "        ...,\n",
            "        [-0.03605311,  0.12654822,  0.18635604, ...,  0.0830823 ,\n",
            "          0.0169796 ,  3.        ],\n",
            "        [-0.2188805 ,  0.1228598 ,  0.32031855, ...,  0.07258447,\n",
            "         -0.01705747,  3.        ],\n",
            "        [-0.27983227,  0.09242395,  0.29089972, ...,  0.05569983,\n",
            "         -0.00981381,  3.        ]], dtype=float32)\n",
            " array([[ 6.0791124e-02, -1.7408335e-01, -1.0676468e-01, ...,\n",
            "          5.6695029e-02,  2.0969565e-01,  3.0000000e+00],\n",
            "        [ 2.8853449e-01, -3.8610487e-03, -1.1435641e-01, ...,\n",
            "          1.9057924e-01,  3.1892478e-02,  3.0000000e+00],\n",
            "        [ 2.6732963e-01,  2.0960540e-02, -8.5680827e-02, ...,\n",
            "          2.6974198e-01, -9.2269965e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 2.1513206e-01, -8.2695568e-03, -1.1078948e-02, ...,\n",
            "          9.3773194e-02, -5.0769942e-03,  3.0000000e+00],\n",
            "        [-1.0342986e-03,  3.2726694e-02,  1.6716059e-01, ...,\n",
            "          1.4074947e-01, -5.0802480e-02,  3.0000000e+00],\n",
            "        [-1.4433403e-01,  2.0009121e-02,  2.6709393e-01, ...,\n",
            "          8.1125587e-02, -1.4697881e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.01637246, -0.1192834 , -0.03568114, ...,  0.03678631,\n",
            "          0.20330194,  3.        ],\n",
            "        [ 0.13471487, -0.0095031 , -0.00880662, ...,  0.239124  ,\n",
            "          0.08793258,  3.        ],\n",
            "        [ 0.14044872,  0.05856425,  0.00576246, ...,  0.31063712,\n",
            "         -0.05553756,  3.        ],\n",
            "        ...,\n",
            "        [ 0.01227452,  0.12616435,  0.13766345, ...,  0.0374716 ,\n",
            "          0.02943558,  3.        ],\n",
            "        [-0.20262788,  0.12285651,  0.32680538, ...,  0.05746879,\n",
            "         -0.01408126,  3.        ],\n",
            "        [-0.27247477,  0.09606472,  0.2998382 , ...,  0.04558321,\n",
            "         -0.00489119,  3.        ]], dtype=float32)\n",
            " array([[-6.47630217e-03, -1.22187816e-01, -4.63827178e-02, ...,\n",
            "          5.14049269e-02,  2.18824714e-01,  3.00000000e+00],\n",
            "        [ 1.41300842e-01, -2.03478783e-02, -1.94900557e-02, ...,\n",
            "          2.31170073e-01,  1.24083340e-01,  3.00000000e+00],\n",
            "        [ 1.40626267e-01,  4.32002172e-02, -2.12780287e-04, ...,\n",
            "          3.13007385e-01, -3.96227241e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.37931388e-02,  1.60088956e-01,  1.63580641e-01, ...,\n",
            "          2.97281314e-02,  2.73445323e-02,  3.00000000e+00],\n",
            "        [-1.96040332e-01,  1.51725665e-01,  3.09362411e-01, ...,\n",
            "          4.51735780e-02, -1.19824754e-02,  3.00000000e+00],\n",
            "        [-2.51595140e-01,  9.51828286e-02,  2.86458910e-01, ...,\n",
            "          6.82941526e-02, -6.44596294e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.01584053, -0.11881967, -0.03534972, ...,  0.04614159,\n",
            "          0.21513692,  3.        ],\n",
            "        [ 0.13429062, -0.01717867, -0.01113086, ...,  0.23357493,\n",
            "          0.11697115,  3.        ],\n",
            "        [ 0.13942863,  0.05225468,  0.00873816, ...,  0.30355152,\n",
            "         -0.03639289,  3.        ],\n",
            "        ...,\n",
            "        [-0.01626606,  0.14287467,  0.16668075, ...,  0.034352  ,\n",
            "          0.02655517,  3.        ],\n",
            "        [-0.21605939,  0.149902  ,  0.32870185, ...,  0.05624273,\n",
            "         -0.00469725,  3.        ],\n",
            "        [-0.2721867 ,  0.10796288,  0.30161443, ...,  0.06632163,\n",
            "          0.00787315,  3.        ]], dtype=float32)\n",
            " array([[-2.39981525e-02, -1.33640990e-01, -2.68301871e-02, ...,\n",
            "          5.18729724e-02,  2.17038080e-01,  3.00000000e+00],\n",
            "        [ 1.35872915e-01, -4.64823171e-02, -2.34293914e-03, ...,\n",
            "          2.40369946e-01,  1.38853922e-01,  3.00000000e+00],\n",
            "        [ 1.28326535e-01,  7.71824503e-03,  2.00396348e-02, ...,\n",
            "          3.18458349e-01, -2.17019464e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.06495000e-01,  1.52710438e-01,  2.45878637e-01, ...,\n",
            "          4.96370830e-02, -1.05128356e-03,  3.00000000e+00],\n",
            "        [-2.50360250e-01,  1.36900470e-01,  3.34929764e-01, ...,\n",
            "          5.54188713e-02, -2.72719841e-02,  3.00000000e+00],\n",
            "        [-2.85584956e-01,  1.04775175e-01,  2.97305763e-01, ...,\n",
            "          6.27260953e-02,  1.07763486e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.4363661e-02, -1.3286442e-01, -2.4839189e-02, ...,\n",
            "          4.4475194e-02,  2.0863806e-01,  3.0000000e+00],\n",
            "        [ 1.3264096e-01, -4.5923423e-02, -3.7946654e-03, ...,\n",
            "          2.5444689e-01,  1.3248068e-01,  3.0000000e+00],\n",
            "        [ 1.1780422e-01, -2.3133727e-03,  1.4644377e-02, ...,\n",
            "          3.3671606e-01,  1.3868334e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2228352e-01,  1.3262552e-01,  2.4991995e-01, ...,\n",
            "          7.8226000e-02, -3.8004518e-03,  3.0000000e+00],\n",
            "        [-2.5722477e-01,  1.1711497e-01,  3.3677322e-01, ...,\n",
            "          6.5319687e-02, -3.1646546e-02,  3.0000000e+00],\n",
            "        [-3.0187878e-01,  9.1062471e-02,  3.0185601e-01, ...,\n",
            "          4.8232481e-02, -1.5336704e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03263953, -0.14863898, -0.03627412, ...,  0.06198514,\n",
            "          0.21629529,  3.        ],\n",
            "        [ 0.16618754, -0.07904869, -0.04904103, ...,  0.2793797 ,\n",
            "          0.15937422,  3.        ],\n",
            "        [ 0.12109112, -0.06362029, -0.0434444 , ...,  0.37363195,\n",
            "          0.05964724,  3.        ],\n",
            "        ...,\n",
            "        [-0.13523263,  0.05945902,  0.22300592, ...,  0.08463722,\n",
            "          0.00305769,  3.        ],\n",
            "        [-0.251825  ,  0.05536093,  0.2622882 , ...,  0.07021257,\n",
            "         -0.0392278 ,  3.        ],\n",
            "        [-0.2842519 ,  0.05627694,  0.2661922 , ...,  0.04131477,\n",
            "         -0.01805978,  3.        ]], dtype=float32)\n",
            " array([[-0.02400226, -0.13181703, -0.02703542, ...,  0.04513605,\n",
            "          0.21024877,  3.        ],\n",
            "        [ 0.13415238, -0.0482038 , -0.01015194, ...,  0.25224125,\n",
            "          0.13568728,  3.        ],\n",
            "        [ 0.11816382, -0.00576683,  0.01067869, ...,  0.3388855 ,\n",
            "          0.01073074,  3.        ],\n",
            "        ...,\n",
            "        [-0.12304031,  0.12940061,  0.24561839, ...,  0.08253802,\n",
            "         -0.0033749 ,  3.        ],\n",
            "        [-0.25495616,  0.11923149,  0.3301165 , ...,  0.06448383,\n",
            "         -0.03441548,  3.        ],\n",
            "        [-0.30387133,  0.08735828,  0.2981568 , ...,  0.04737866,\n",
            "         -0.01771155,  3.        ]], dtype=float32)\n",
            " array([[-0.0345355 , -0.13242282, -0.03353845, ...,  0.05477359,\n",
            "          0.20842277,  3.        ],\n",
            "        [ 0.14286278, -0.06333118, -0.04377036, ...,  0.27167124,\n",
            "          0.14342777,  3.        ],\n",
            "        [ 0.11233077, -0.04194912, -0.03959278, ...,  0.36169723,\n",
            "          0.04092338,  3.        ],\n",
            "        ...,\n",
            "        [-0.1424092 ,  0.0715952 ,  0.22846279, ...,  0.08794331,\n",
            "          0.00892484,  3.        ],\n",
            "        [-0.25387034,  0.06099225,  0.28469336, ...,  0.06713088,\n",
            "         -0.03177129,  3.        ],\n",
            "        [-0.30198324,  0.07172336,  0.2811014 , ...,  0.03652894,\n",
            "         -0.01785707,  3.        ]], dtype=float32)\n",
            " array([[-0.01556515, -0.12577657, -0.02891915, ...,  0.04459435,\n",
            "          0.21094489,  3.        ],\n",
            "        [ 0.15069829, -0.0321804 , -0.0064649 , ...,  0.2600786 ,\n",
            "          0.12171058,  3.        ],\n",
            "        [ 0.15247218,  0.02842396,  0.0093351 , ...,  0.3363011 ,\n",
            "         -0.01783034,  3.        ],\n",
            "        ...,\n",
            "        [-0.02630301,  0.12279201,  0.19120553, ...,  0.07880225,\n",
            "          0.0225908 ,  3.        ],\n",
            "        [-0.22075589,  0.12732486,  0.33080226, ...,  0.07592165,\n",
            "         -0.01061056,  3.        ],\n",
            "        [-0.27155587,  0.10804608,  0.29461443, ...,  0.05538446,\n",
            "          0.0053229 ,  3.        ]], dtype=float32)\n",
            " array([[-2.43096203e-02, -1.30091995e-01, -2.49868706e-02, ...,\n",
            "          4.19969484e-02,  2.08714709e-01,  3.00000000e+00],\n",
            "        [ 1.28278583e-01, -4.59036380e-02, -2.29380559e-03, ...,\n",
            "          2.39335731e-01,  1.32851288e-01,  3.00000000e+00],\n",
            "        [ 1.15803026e-01,  1.74887793e-03,  1.97842550e-02, ...,\n",
            "          3.22644532e-01,  5.17778890e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.14107735e-01,  1.38830975e-01,  2.53774583e-01, ...,\n",
            "          7.02653676e-02,  1.71802030e-03,  3.00000000e+00],\n",
            "        [-2.58953631e-01,  1.26213253e-01,  3.46906513e-01, ...,\n",
            "          5.72355539e-02, -2.94132922e-02,  3.00000000e+00],\n",
            "        [-3.05363119e-01,  9.11866948e-02,  3.03506047e-01, ...,\n",
            "          4.60299514e-02, -1.53266527e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03296309, -0.15572417, -0.03811675, ...,  0.06031336,\n",
            "          0.21503596,  3.        ],\n",
            "        [ 0.17021869, -0.08491901, -0.04989444, ...,  0.27664587,\n",
            "          0.15288655,  3.        ],\n",
            "        [ 0.12534523, -0.0671917 , -0.04571522, ...,  0.36379573,\n",
            "          0.05204917,  3.        ],\n",
            "        ...,\n",
            "        [-0.10622683,  0.06165973,  0.20072164, ...,  0.076522  ,\n",
            "          0.01702583,  3.        ],\n",
            "        [-0.23071168,  0.06216092,  0.24858776, ...,  0.0621007 ,\n",
            "         -0.03273885,  3.        ],\n",
            "        [-0.27345735,  0.05261154,  0.2576379 , ...,  0.04544994,\n",
            "         -0.01907424,  3.        ]], dtype=float32)\n",
            " array([[-3.21111716e-02, -1.58664048e-01, -5.62724173e-02, ...,\n",
            "          6.03674203e-02,  2.11042598e-01,  3.00000000e+00],\n",
            "        [ 1.40671313e-01, -1.14476293e-01, -7.73136914e-02, ...,\n",
            "          3.04532409e-01,  1.52742818e-01,  3.00000000e+00],\n",
            "        [ 8.94295052e-02, -1.15756065e-01, -8.45709518e-02, ...,\n",
            "          4.01393801e-01,  7.70059079e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.44463226e-01,  8.38079397e-03,  1.95589453e-01, ...,\n",
            "          1.14668243e-01, -1.46225924e-02,  3.00000000e+00],\n",
            "        [-2.21103892e-01,  1.74254049e-02,  2.00981781e-01, ...,\n",
            "          9.32140350e-02, -4.50591743e-02,  3.00000000e+00],\n",
            "        [-2.61939704e-01,  1.70496886e-03,  2.32190460e-01, ...,\n",
            "          3.76735814e-02, -2.99146250e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.67018659e-02, -1.19139031e-01, -3.41832750e-02, ...,\n",
            "          3.49256322e-02,  2.04136267e-01,  3.00000000e+00],\n",
            "        [ 1.31395862e-01, -1.40451863e-02, -3.98022030e-03, ...,\n",
            "          2.32611030e-01,  9.49714035e-02,  3.00000000e+00],\n",
            "        [ 1.32704124e-01,  5.09883016e-02,  1.19130295e-02, ...,\n",
            "          3.03918958e-01, -4.81621772e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 2.90670106e-03,  1.28730834e-01,  1.51354104e-01, ...,\n",
            "          3.37664634e-02,  3.41944247e-02,  3.00000000e+00],\n",
            "        [-2.11557940e-01,  1.25267580e-01,  3.32407057e-01, ...,\n",
            "          5.02936542e-02, -1.19981458e-02,  3.00000000e+00],\n",
            "        [-2.80819714e-01,  9.61744413e-02,  3.04516792e-01, ...,\n",
            "          4.26150337e-02, -3.94507172e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.1396449e-02, -1.2505965e-01, -2.6744625e-02, ...,\n",
            "          3.9018389e-02,  2.0784691e-01,  3.0000000e+00],\n",
            "        [ 1.2666708e-01, -3.1450592e-02,  2.7751553e-04, ...,\n",
            "          2.3244916e-01,  1.1868861e-01,  3.0000000e+00],\n",
            "        [ 1.2329386e-01,  2.8911291e-02,  2.0696620e-02, ...,\n",
            "          3.0932200e-01, -1.9827403e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-5.3940028e-02,  1.3435721e-01,  2.1559083e-01, ...,\n",
            "          4.9712915e-02,  2.0289559e-02,  3.0000000e+00],\n",
            "        [-2.3744433e-01,  1.3071197e-01,  3.5054398e-01, ...,\n",
            "          4.8843712e-02, -1.3904695e-02,  3.0000000e+00],\n",
            "        [-2.9442617e-01,  9.7564340e-02,  3.0893916e-01, ...,\n",
            "          4.2614061e-02, -5.5648605e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02651091, -0.1357903 , -0.02618888, ...,  0.05126897,\n",
            "          0.2144228 ,  3.        ],\n",
            "        [ 0.14367259, -0.04612779, -0.00650336, ...,  0.24591309,\n",
            "          0.13611515,  3.        ],\n",
            "        [ 0.13202685,  0.00597478,  0.01926431, ...,  0.32379487,\n",
            "          0.00445902,  3.        ],\n",
            "        ...,\n",
            "        [-0.12747712,  0.15072124,  0.25107872, ...,  0.05862782,\n",
            "         -0.01189997,  3.        ],\n",
            "        [-0.26037502,  0.13085516,  0.33139378, ...,  0.0549744 ,\n",
            "         -0.03576061,  3.        ],\n",
            "        [-0.29170302,  0.09488784,  0.2984373 , ...,  0.05895108,\n",
            "         -0.00750041,  3.        ]], dtype=float32)\n",
            " array([[ 5.0999080e-03, -1.1186360e-01, -5.7125192e-02, ...,\n",
            "          5.0795421e-02,  2.1115413e-01,  3.0000000e+00],\n",
            "        [ 1.5806502e-01, -1.8330384e-02, -4.7397215e-02, ...,\n",
            "          2.1432264e-01,  1.1152190e-01,  3.0000000e+00],\n",
            "        [ 1.4635892e-01,  2.9185625e-02, -3.2058857e-02, ...,\n",
            "          3.0116245e-01, -5.1060021e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 7.1943104e-02,  1.1100489e-01,  7.6416716e-02, ...,\n",
            "          3.1494312e-02,  5.4771237e-02,  3.0000000e+00],\n",
            "        [-1.5249646e-01,  1.4285235e-01,  2.7436268e-01, ...,\n",
            "          7.6557972e-02,  1.3760616e-03,  3.0000000e+00],\n",
            "        [-2.5299785e-01,  9.4361611e-02,  2.7620354e-01, ...,\n",
            "          6.9653504e-02, -1.1767545e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.0311460e-02, -1.2580556e-01, -2.8641954e-02, ...,\n",
            "          3.5458375e-02,  2.0701469e-01,  3.0000000e+00],\n",
            "        [ 1.2230800e-01, -2.7708629e-02,  1.0737504e-03, ...,\n",
            "          2.3894158e-01,  1.0830219e-01,  3.0000000e+00],\n",
            "        [ 1.2803556e-01,  4.1664034e-02,  2.3460614e-02, ...,\n",
            "          3.1473359e-01, -3.3459395e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-2.6616964e-02,  1.2958303e-01,  1.8789612e-01, ...,\n",
            "          4.7080170e-02,  3.1141071e-02,  3.0000000e+00],\n",
            "        [-2.2262232e-01,  1.2875399e-01,  3.4143582e-01, ...,\n",
            "          5.2258935e-02, -7.8531783e-03,  3.0000000e+00],\n",
            "        [-2.8458926e-01,  9.7860813e-02,  3.0253124e-01, ...,\n",
            "          4.4317946e-02, -4.7737053e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03289258, -0.14168464, -0.03860606, ...,  0.05420645,\n",
            "          0.21258114,  3.        ],\n",
            "        [ 0.14811176, -0.07365936, -0.05910559, ...,  0.27998674,\n",
            "          0.15197289,  3.        ],\n",
            "        [ 0.11179678, -0.06148484, -0.06153405, ...,  0.37278974,\n",
            "          0.05040985,  3.        ],\n",
            "        ...,\n",
            "        [-0.13167018,  0.04985314,  0.21178317, ...,  0.09715582,\n",
            "          0.01984994,  3.        ],\n",
            "        [-0.24178858,  0.0441364 ,  0.26683563, ...,  0.07257617,\n",
            "         -0.02525011,  3.        ],\n",
            "        [-0.29347506,  0.05000946,  0.2695207 , ...,  0.03850571,\n",
            "         -0.0185525 ,  3.        ]], dtype=float32)\n",
            " array([[ 6.6920620e-06, -1.0930280e-01, -5.8084287e-02, ...,\n",
            "          4.3424275e-02,  2.1006559e-01,  3.0000000e+00],\n",
            "        [ 1.5178758e-01, -6.2385821e-03, -4.0219482e-02, ...,\n",
            "          2.1845889e-01,  9.1796026e-02,  3.0000000e+00],\n",
            "        [ 1.5763807e-01,  4.8820294e-02, -2.9057076e-02, ...,\n",
            "          2.9690987e-01, -6.8260193e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.1278409e-02,  1.0717771e-01,  8.1310242e-02, ...,\n",
            "          2.2209929e-02,  3.9377566e-02,  3.0000000e+00],\n",
            "        [-1.7111905e-01,  1.3738073e-01,  3.0060548e-01, ...,\n",
            "          7.0908539e-02, -1.1220399e-02,  3.0000000e+00],\n",
            "        [-2.6196405e-01,  1.0320545e-01,  2.9060796e-01, ...,\n",
            "          6.1536621e-02,  3.0910508e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03168089, -0.14038396, -0.038695  , ...,  0.05866873,\n",
            "          0.21004176,  1.        ],\n",
            "        [ 0.14897779, -0.07412195, -0.05799118, ...,  0.2869787 ,\n",
            "          0.13991459,  1.        ],\n",
            "        [ 0.12076312, -0.05719289, -0.06241304, ...,  0.37596157,\n",
            "          0.03702178,  1.        ],\n",
            "        ...,\n",
            "        [-0.11540929,  0.04188072,  0.19513296, ...,  0.09635434,\n",
            "          0.02185475,  1.        ],\n",
            "        [-0.22903784,  0.03910687,  0.25912073, ...,  0.07480802,\n",
            "         -0.02330177,  1.        ],\n",
            "        [-0.28392968,  0.05210161,  0.26507595, ...,  0.04309972,\n",
            "         -0.01682643,  1.        ]], dtype=float32)\n",
            " array([[-2.96707395e-02, -1.65648028e-01, -5.48810735e-02, ...,\n",
            "          5.86438477e-02,  2.09325925e-01,  1.00000000e+00],\n",
            "        [ 1.40921488e-01, -1.23487823e-01, -7.38619938e-02, ...,\n",
            "          2.99359262e-01,  1.50912911e-01,  1.00000000e+00],\n",
            "        [ 9.67810377e-02, -1.24971069e-01, -8.15463960e-02, ...,\n",
            "          3.82254779e-01,  8.78648162e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.27783045e-01,  4.81474563e-04,  1.89470813e-01, ...,\n",
            "          1.14938885e-01,  1.30390539e-03,  1.00000000e+00],\n",
            "        [-2.11345136e-01,  9.71012097e-03,  2.02797487e-01, ...,\n",
            "          9.21567678e-02, -3.77808660e-02,  1.00000000e+00],\n",
            "        [-2.58400589e-01, -2.54332297e-03,  2.32440576e-01, ...,\n",
            "          3.59126441e-02, -2.85749603e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.03519288, -0.15686208, -0.05863317, ...,  0.0621115 ,\n",
            "          0.21081221,  1.        ],\n",
            "        [ 0.13592328, -0.11752284, -0.08158483, ...,  0.30345735,\n",
            "          0.15556388,  1.        ],\n",
            "        [ 0.08198822, -0.11734275, -0.09058322, ...,  0.40318504,\n",
            "          0.07934005,  1.        ],\n",
            "        ...,\n",
            "        [-0.16125062,  0.00928036,  0.19137019, ...,  0.10850102,\n",
            "         -0.03216268,  1.        ],\n",
            "        [-0.2277285 ,  0.01879492,  0.19465002, ...,  0.08818953,\n",
            "         -0.05439419,  1.        ],\n",
            "        [-0.2632017 ,  0.0040849 ,  0.23122641, ...,  0.03058452,\n",
            "         -0.03182989,  1.        ]], dtype=float32)\n",
            " array([[-0.02733649, -0.1356771 , -0.03802711, ...,  0.0613826 ,\n",
            "          0.20886776,  1.        ],\n",
            "        [ 0.15374412, -0.07219581, -0.05574708, ...,  0.28646028,\n",
            "          0.13459897,  1.        ],\n",
            "        [ 0.13510609, -0.05064093, -0.05929709, ...,  0.37892243,\n",
            "          0.02334876,  1.        ],\n",
            "        ...,\n",
            "        [-0.09617367,  0.05538465,  0.18705669, ...,  0.10524058,\n",
            "          0.01880117,  1.        ],\n",
            "        [-0.22247684,  0.0560141 ,  0.26337025, ...,  0.08269707,\n",
            "         -0.02379485,  1.        ],\n",
            "        [-0.28035784,  0.06277973,  0.26634797, ...,  0.04957056,\n",
            "         -0.01923563,  1.        ]], dtype=float32)\n",
            " array([[-2.2219066e-02, -1.3671038e-01, -3.0924490e-02, ...,\n",
            "          5.4141968e-02,  2.1606162e-01,  1.0000000e+00],\n",
            "        [ 1.4186770e-01, -4.8140299e-02, -9.7058490e-03, ...,\n",
            "          2.4890678e-01,  1.3667791e-01,  1.0000000e+00],\n",
            "        [ 1.3318254e-01, -8.3086407e-04,  1.3963878e-02, ...,\n",
            "          3.2744265e-01, -1.0226273e-03,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1401240e-01,  1.5166995e-01,  2.3716657e-01, ...,\n",
            "          5.4467943e-02, -1.0226709e-02,  1.0000000e+00],\n",
            "        [-2.4386832e-01,  1.2755008e-01,  3.1923887e-01, ...,\n",
            "          5.5935387e-02, -3.5379257e-02,  1.0000000e+00],\n",
            "        [-2.7901042e-01,  1.0095960e-01,  2.8922051e-01, ...,\n",
            "          6.0974315e-02, -6.1557177e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02325043, -0.13458689, -0.02797038, ...,  0.05155512,\n",
            "          0.2147662 ,  1.        ],\n",
            "        [ 0.14193875, -0.04717052, -0.00978197, ...,  0.25267318,\n",
            "          0.13708444,  1.        ],\n",
            "        [ 0.1293087 , -0.00267749,  0.01620586, ...,  0.33663607,\n",
            "          0.00528957,  1.        ],\n",
            "        ...,\n",
            "        [-0.12765579,  0.14568979,  0.24615401, ...,  0.06085765,\n",
            "         -0.01248307,  1.        ],\n",
            "        [-0.24975447,  0.12439726,  0.32383928, ...,  0.05797473,\n",
            "         -0.03813874,  1.        ],\n",
            "        [-0.288683  ,  0.09618583,  0.2952273 , ...,  0.05618988,\n",
            "         -0.01157447,  1.        ]], dtype=float32)\n",
            " array([[-0.03246275, -0.1261555 , -0.03141084, ...,  0.063269  ,\n",
            "          0.21246096,  1.        ],\n",
            "        [ 0.15153588, -0.05667331, -0.0319286 , ...,  0.25800517,\n",
            "          0.15007317,  1.        ],\n",
            "        [ 0.12232822, -0.03088791, -0.01335771, ...,  0.35318926,\n",
            "          0.03791112,  1.        ],\n",
            "        ...,\n",
            "        [-0.16975547,  0.11080982,  0.26645255, ...,  0.07976668,\n",
            "         -0.02187725,  1.        ],\n",
            "        [-0.27658886,  0.09548786,  0.30940518, ...,  0.07337851,\n",
            "         -0.04702028,  1.        ],\n",
            "        [-0.29637924,  0.09047251,  0.28230718, ...,  0.04879227,\n",
            "         -0.01306589,  1.        ]], dtype=float32)\n",
            " array([[-0.03606439, -0.15529408, -0.05528739, ...,  0.05820163,\n",
            "          0.21285236,  1.        ],\n",
            "        [ 0.14065063, -0.11330698, -0.07992934, ...,  0.293716  ,\n",
            "          0.15907326,  1.        ],\n",
            "        [ 0.08799924, -0.11544355, -0.08570997, ...,  0.39237785,\n",
            "          0.08269546,  1.        ],\n",
            "        ...,\n",
            "        [-0.1559799 ,  0.00533115,  0.19889131, ...,  0.11380617,\n",
            "         -0.00954693,  1.        ],\n",
            "        [-0.23754652,  0.01776534,  0.2100676 , ...,  0.09054802,\n",
            "         -0.04792377,  1.        ],\n",
            "        [-0.2765568 ,  0.00694067,  0.24162604, ...,  0.02908639,\n",
            "         -0.02961555,  1.        ]], dtype=float32)\n",
            " array([[-0.03293056, -0.13167034, -0.03561874, ...,  0.05822736,\n",
            "          0.21018097,  1.        ],\n",
            "        [ 0.1423172 , -0.06497009, -0.05059374, ...,  0.28015557,\n",
            "          0.14400236,  1.        ],\n",
            "        [ 0.1137423 , -0.04564629, -0.05068811, ...,  0.37416744,\n",
            "          0.03428324,  1.        ],\n",
            "        ...,\n",
            "        [-0.1344817 ,  0.06983668,  0.22199014, ...,  0.10085937,\n",
            "          0.00650398,  1.        ],\n",
            "        [-0.25070593,  0.06178803,  0.28090128, ...,  0.07590018,\n",
            "         -0.03301832,  1.        ],\n",
            "        [-0.29968715,  0.06863825,  0.27799487, ...,  0.04194754,\n",
            "         -0.0204166 ,  1.        ]], dtype=float32)\n",
            " array([[-0.03103615, -0.13386056, -0.02803065, ...,  0.06095063,\n",
            "          0.21038175,  1.        ],\n",
            "        [ 0.15669197, -0.05686193, -0.01733323, ...,  0.26389432,\n",
            "          0.1412625 ,  1.        ],\n",
            "        [ 0.13108796, -0.02526842, -0.00214104, ...,  0.3545716 ,\n",
            "          0.03840961,  1.        ],\n",
            "        ...,\n",
            "        [-0.13071024,  0.12387058,  0.24110505, ...,  0.07262   ,\n",
            "         -0.00254485,  1.        ],\n",
            "        [-0.2589397 ,  0.10101078,  0.30496216, ...,  0.06750104,\n",
            "         -0.03310678,  1.        ],\n",
            "        [-0.29050726,  0.0926737 ,  0.28228965, ...,  0.05643981,\n",
            "         -0.00893   ,  1.        ]], dtype=float32)\n",
            " array([[-0.01466923, -0.1279824 , -0.02943756, ...,  0.04615651,\n",
            "          0.2115993 ,  1.        ],\n",
            "        [ 0.15444236, -0.03175626, -0.0075085 , ...,  0.26987407,\n",
            "          0.12365108,  1.        ],\n",
            "        [ 0.15565315,  0.02640635,  0.00564198, ...,  0.346535  ,\n",
            "         -0.00972374,  1.        ],\n",
            "        ...,\n",
            "        [-0.03225168,  0.12241184,  0.19253202, ...,  0.08787651,\n",
            "          0.02059651,  1.        ],\n",
            "        [-0.2160203 ,  0.12571074,  0.32459962, ...,  0.08139801,\n",
            "         -0.01319796,  1.        ],\n",
            "        [-0.2686987 ,  0.10547164,  0.2925389 , ...,  0.05989752,\n",
            "          0.0034886 ,  1.        ]], dtype=float32)\n",
            " array([[-0.03572368, -0.14632939, -0.04153671, ...,  0.06174657,\n",
            "          0.2174028 ,  1.        ],\n",
            "        [ 0.1575279 , -0.08527543, -0.05384105, ...,  0.28657454,\n",
            "          0.16709729,  1.        ],\n",
            "        [ 0.10685301, -0.07833523, -0.05342168, ...,  0.38612458,\n",
            "          0.07600249,  1.        ],\n",
            "        ...,\n",
            "        [-0.15068658,  0.03938822,  0.22951107, ...,  0.09142182,\n",
            "         -0.00221296,  1.        ],\n",
            "        [-0.26438868,  0.04893238,  0.2496616 , ...,  0.07367581,\n",
            "         -0.04308289,  1.        ],\n",
            "        [-0.2876414 ,  0.04864335,  0.26200435, ...,  0.03574016,\n",
            "         -0.01763892,  1.        ]], dtype=float32)\n",
            " array([[-0.0219829 , -0.15320374, -0.06405683, ...,  0.05156951,\n",
            "          0.18566845,  0.        ],\n",
            "        [ 0.11165898, -0.12850036, -0.0621657 , ...,  0.24400373,\n",
            "          0.15202121,  0.        ],\n",
            "        [ 0.04377288, -0.12826584, -0.07950884, ...,  0.34099033,\n",
            "          0.08883431,  0.        ],\n",
            "        ...,\n",
            "        [-0.21393786,  0.04447453,  0.1923874 , ..., -0.00059264,\n",
            "         -0.08111315,  0.        ],\n",
            "        [-0.2569004 ,  0.06728207,  0.2097998 , ...,  0.01177954,\n",
            "         -0.07765479,  0.        ],\n",
            "        [-0.22624171,  0.03500877,  0.2341682 , ..., -0.01582955,\n",
            "         -0.04900112,  0.        ]], dtype=float32)\n",
            " array([[-0.02858817, -0.15941623, -0.05016449, ...,  0.05607425,\n",
            "          0.21226895,  0.        ],\n",
            "        [ 0.15010156, -0.10508431, -0.0691442 , ...,  0.29579237,\n",
            "          0.15230457,  0.        ],\n",
            "        [ 0.11018132, -0.10941626, -0.07366552, ...,  0.38340196,\n",
            "          0.08235608,  0.        ],\n",
            "        ...,\n",
            "        [-0.11840279,  0.00590978,  0.1997659 , ...,  0.12103761,\n",
            "          0.01064881,  0.        ],\n",
            "        [-0.2164094 ,  0.01238574,  0.22832711, ...,  0.09473285,\n",
            "         -0.03106504,  0.        ],\n",
            "        [-0.26588827,  0.01673085,  0.24507654, ...,  0.03839815,\n",
            "         -0.02044113,  0.        ]], dtype=float32)\n",
            " array([[-0.02061613, -0.12626097, -0.03185982, ...,  0.03982563,\n",
            "          0.20904544,  0.        ],\n",
            "        [ 0.11699611, -0.04502693,  0.00037889, ...,  0.235088  ,\n",
            "          0.11580156,  0.        ],\n",
            "        [ 0.11876044,  0.01517138,  0.01853611, ...,  0.31106827,\n",
            "         -0.0269595 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.05969694,  0.13882285,  0.22415943, ...,  0.06239784,\n",
            "          0.00782607,  0.        ],\n",
            "        [-0.23436621,  0.1396051 ,  0.34454307, ...,  0.06309512,\n",
            "         -0.01499675,  0.        ],\n",
            "        [-0.28334585,  0.10287962,  0.298512  , ...,  0.04746431,\n",
            "         -0.00107966,  0.        ]], dtype=float32)\n",
            " array([[-0.03146018, -0.12771362, -0.03372172, ...,  0.0569599 ,\n",
            "          0.20694195,  1.        ],\n",
            "        [ 0.13438287, -0.06563529, -0.03848175, ...,  0.26707986,\n",
            "          0.13323227,  1.        ],\n",
            "        [ 0.11419789, -0.03955742, -0.03406073, ...,  0.36777204,\n",
            "          0.0149207 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.12994073,  0.09264549,  0.23331188, ...,  0.10663002,\n",
            "         -0.00689792,  1.        ],\n",
            "        [-0.25634852,  0.08520914,  0.30227053, ...,  0.08326019,\n",
            "         -0.03656641,  1.        ],\n",
            "        [-0.2968624 ,  0.08741881,  0.28299472, ...,  0.04453406,\n",
            "         -0.01304263,  1.        ]], dtype=float32)\n",
            " array([[-0.02935029, -0.12905872, -0.03161666, ...,  0.05790498,\n",
            "          0.20878772,  1.        ],\n",
            "        [ 0.14207669, -0.06071998, -0.03439014, ...,  0.2669655 ,\n",
            "          0.13681567,  1.        ],\n",
            "        [ 0.12363777, -0.03384183, -0.023894  , ...,  0.3674036 ,\n",
            "          0.01453358,  1.        ],\n",
            "        ...,\n",
            "        [-0.12073952,  0.0923434 ,  0.22722007, ...,  0.09170184,\n",
            "         -0.00205992,  1.        ],\n",
            "        [-0.24409863,  0.08562726,  0.29399672, ...,  0.07696281,\n",
            "         -0.03119461,  1.        ],\n",
            "        [-0.2928043 ,  0.08731335,  0.28002042, ...,  0.0511817 ,\n",
            "         -0.01106921,  1.        ]], dtype=float32)\n",
            " array([[-0.0320242 , -0.14517078, -0.03975233, ...,  0.05667661,\n",
            "          0.21241398,  1.        ],\n",
            "        [ 0.14857742, -0.07827871, -0.06002158, ...,  0.29108056,\n",
            "          0.14531663,  1.        ],\n",
            "        [ 0.1131751 , -0.06717858, -0.06594674, ...,  0.38526058,\n",
            "          0.04672673,  1.        ],\n",
            "        ...,\n",
            "        [-0.1274412 ,  0.04298184,  0.21096613, ...,  0.10833887,\n",
            "          0.01056082,  1.        ],\n",
            "        [-0.23902735,  0.04213675,  0.26288274, ...,  0.08731084,\n",
            "         -0.02897166,  1.        ],\n",
            "        [-0.2863169 ,  0.05638986,  0.26525137, ...,  0.04368903,\n",
            "         -0.01211508,  1.        ]], dtype=float32)\n",
            " array([[-0.01530563, -0.11971848, -0.03879448, ...,  0.03877658,\n",
            "          0.20961317,  1.        ],\n",
            "        [ 0.11652213, -0.03740506, -0.01072008, ...,  0.23239261,\n",
            "          0.1130315 ,  1.        ],\n",
            "        [ 0.11931169,  0.03032556,  0.00630687, ...,  0.3070106 ,\n",
            "         -0.03665281,  1.        ],\n",
            "        ...,\n",
            "        [-0.03424898,  0.1338496 ,  0.19689919, ...,  0.05768765,\n",
            "          0.0256589 ,  1.        ],\n",
            "        [-0.22483552,  0.13344896,  0.34278658, ...,  0.0654915 ,\n",
            "         -0.00403536,  1.        ],\n",
            "        [-0.28638276,  0.09488621,  0.3031326 , ...,  0.05376844,\n",
            "          0.00136543,  1.        ]], dtype=float32)\n",
            " array([[-0.03282588, -0.13871206, -0.03535999, ...,  0.05401817,\n",
            "          0.21127154,  1.        ],\n",
            "        [ 0.14120407, -0.07542464, -0.04335294, ...,  0.27261287,\n",
            "          0.15172878,  1.        ],\n",
            "        [ 0.10554992, -0.06017422, -0.04190573, ...,  0.36553705,\n",
            "          0.04954536,  1.        ],\n",
            "        ...,\n",
            "        [-0.14286087,  0.06828921,  0.23050684, ...,  0.09935479,\n",
            "          0.00817981,  1.        ],\n",
            "        [-0.25252196,  0.06401131,  0.28478044, ...,  0.08127538,\n",
            "         -0.0349338 ,  1.        ],\n",
            "        [-0.30093926,  0.06571184,  0.28198233, ...,  0.0343153 ,\n",
            "         -0.01335387,  1.        ]], dtype=float32)\n",
            " array([[ 0.02330904, -0.1220863 , -0.07146731, ...,  0.0117717 ,\n",
            "          0.18302168,  1.        ],\n",
            "        [ 0.20423548, -0.03113045, -0.05897428, ...,  0.19906917,\n",
            "          0.02792544,  1.        ],\n",
            "        [ 0.20789741,  0.0131831 , -0.05611333, ...,  0.25726002,\n",
            "         -0.10500649,  1.        ],\n",
            "        ...,\n",
            "        [ 0.12139069,  0.00753898, -0.03714581, ...,  0.05094496,\n",
            "          0.06145121,  1.        ],\n",
            "        [-0.09324409,  0.08716383,  0.27048942, ...,  0.11526657,\n",
            "         -0.02710199,  1.        ],\n",
            "        [-0.25955108,  0.06783333,  0.30768687, ...,  0.07671025,\n",
            "         -0.01063502,  1.        ]], dtype=float32)\n",
            " array([[ 0.01658736, -0.11033   , -0.07012013, ...,  0.02931445,\n",
            "          0.19282976,  1.        ],\n",
            "        [ 0.1791922 , -0.02852413, -0.05170103, ...,  0.22595467,\n",
            "          0.05219283,  1.        ],\n",
            "        [ 0.18634827,  0.02340818, -0.05352934, ...,  0.29708663,\n",
            "         -0.09420501,  1.        ],\n",
            "        ...,\n",
            "        [ 0.10580648,  0.05959006,  0.01465615, ...,  0.05250478,\n",
            "          0.07453158,  1.        ],\n",
            "        [-0.11499153,  0.11159504,  0.27635685, ...,  0.10738701,\n",
            "         -0.01007123,  1.        ],\n",
            "        [-0.24576859,  0.07973887,  0.29736388, ...,  0.07294604,\n",
            "         -0.00524197,  1.        ]], dtype=float32)\n",
            " array([[-0.02022054, -0.11449459, -0.03281657, ...,  0.03707938,\n",
            "          0.20541836,  1.        ],\n",
            "        [ 0.11727405, -0.02946638, -0.00876451, ...,  0.23229581,\n",
            "          0.09877478,  1.        ],\n",
            "        [ 0.12850809,  0.0398055 ,  0.00993627, ...,  0.30303076,\n",
            "         -0.05291422,  1.        ],\n",
            "        ...,\n",
            "        [-0.03159013,  0.13492104,  0.19335587, ...,  0.03957867,\n",
            "          0.01681134,  1.        ],\n",
            "        [-0.22323483,  0.1365458 ,  0.3495384 , ...,  0.05766923,\n",
            "         -0.00992313,  1.        ],\n",
            "        [-0.2831827 ,  0.10352842,  0.31090668, ...,  0.04498808,\n",
            "          0.00267294,  1.        ]], dtype=float32)\n",
            " array([[-2.6839802e-02, -1.6232708e-01, -5.8440860e-02, ...,\n",
            "          6.0786162e-02,  2.1045119e-01,  1.0000000e+00],\n",
            "        [ 1.4046587e-01, -1.2277539e-01, -8.2796700e-02, ...,\n",
            "          3.0439341e-01,  1.4951308e-01,  1.0000000e+00],\n",
            "        [ 9.0917818e-02, -1.2562297e-01, -9.0733550e-02, ...,\n",
            "          4.0088034e-01,  7.0582122e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2811738e-01, -3.8633292e-04,  1.8598019e-01, ...,\n",
            "          1.3122141e-01, -2.6631092e-03,  1.0000000e+00],\n",
            "        [-2.0358533e-01,  4.3280390e-03,  2.0242982e-01, ...,\n",
            "          1.0168999e-01, -3.4687106e-02,  1.0000000e+00],\n",
            "        [-2.5219694e-01, -1.7231617e-02,  2.3340520e-01, ...,\n",
            "          4.2291146e-02, -3.2393835e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.02402237, -0.13073899, -0.02667447, ...,  0.044377  ,\n",
            "          0.20830949,  1.        ],\n",
            "        [ 0.12533106, -0.05234846, -0.01015041, ...,  0.24369214,\n",
            "          0.12836067,  1.        ],\n",
            "        [ 0.1139009 , -0.00503985,  0.01190991, ...,  0.33275294,\n",
            "         -0.00922056,  1.        ],\n",
            "        ...,\n",
            "        [-0.11475337,  0.13021165,  0.2392005 , ...,  0.07657706,\n",
            "         -0.00451631,  1.        ],\n",
            "        [-0.257891  ,  0.12728333,  0.34003016, ...,  0.05934478,\n",
            "         -0.03611124,  1.        ],\n",
            "        [-0.3017055 ,  0.08949185,  0.29837042, ...,  0.04789464,\n",
            "         -0.01343972,  1.        ]], dtype=float32)\n",
            " array([[-0.01619883, -0.12258048, -0.03303647, ...,  0.03816434,\n",
            "          0.2062974 ,  1.        ],\n",
            "        [ 0.12318163, -0.0348659 , -0.00833009, ...,  0.24172032,\n",
            "          0.10585565,  1.        ],\n",
            "        [ 0.12649699,  0.03335485,  0.01283151, ...,  0.32035384,\n",
            "         -0.04104439,  1.        ],\n",
            "        ...,\n",
            "        [-0.03507261,  0.13062498,  0.19050683, ...,  0.06244878,\n",
            "          0.01505908,  1.        ],\n",
            "        [-0.22364455,  0.13356546,  0.33629692, ...,  0.06686611,\n",
            "         -0.00801623,  1.        ],\n",
            "        [-0.27844977,  0.10036729,  0.2973658 , ...,  0.04993908,\n",
            "         -0.00262115,  1.        ]], dtype=float32)\n",
            " array([[-2.2799198e-02, -1.3219519e-01, -2.5184711e-02, ...,\n",
            "          4.3624289e-02,  2.0894235e-01,  1.0000000e+00],\n",
            "        [ 1.2621792e-01, -4.7798667e-02, -5.2864925e-04, ...,\n",
            "          2.4541393e-01,  1.2359359e-01,  1.0000000e+00],\n",
            "        [ 1.2234411e-01,  4.3304195e-03,  2.0621389e-02, ...,\n",
            "          3.2695177e-01, -1.1984013e-02,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0094092e-01,  1.3414794e-01,  2.5064307e-01, ...,\n",
            "          6.9510095e-02, -6.8099666e-03,  1.0000000e+00],\n",
            "        [-2.5025123e-01,  1.2975575e-01,  3.5158128e-01, ...,\n",
            "          6.1500724e-02, -3.0151799e-02,  1.0000000e+00],\n",
            "        [-2.9404122e-01,  9.7847611e-02,  3.0344054e-01, ...,\n",
            "          4.6448037e-02, -7.5813388e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-3.20340768e-02, -1.54850900e-01, -5.54366484e-02, ...,\n",
            "          5.74387088e-02,  2.13140830e-01,  1.00000000e+00],\n",
            "        [ 1.39925733e-01, -1.10193342e-01, -8.05953667e-02, ...,\n",
            "          2.98840612e-01,  1.53121114e-01,  1.00000000e+00],\n",
            "        [ 8.96732211e-02, -1.12741269e-01, -8.89076218e-02, ...,\n",
            "          3.98629278e-01,  6.79630041e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-1.39556512e-01,  1.89623708e-04,  1.95789367e-01, ...,\n",
            "          1.28725395e-01,  4.09573731e-05,  1.00000000e+00],\n",
            "        [-2.22559601e-01,  5.97104849e-03,  2.20387384e-01, ...,\n",
            "          1.00169584e-01, -3.74128036e-02,  1.00000000e+00],\n",
            "        [-2.70199031e-01,  2.01756507e-03,  2.44661987e-01, ...,\n",
            "          3.71354148e-02, -2.88168434e-02,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.0299778 , -0.11958277, -0.02936352, ...,  0.05654799,\n",
            "          0.20481572,  1.        ],\n",
            "        [ 0.13000391, -0.06339668, -0.02917516, ...,  0.25926167,\n",
            "          0.14003618,  1.        ],\n",
            "        [ 0.11730373, -0.02869693, -0.0166303 , ...,  0.35846293,\n",
            "          0.01291678,  1.        ],\n",
            "        ...,\n",
            "        [-0.17421634,  0.1252246 ,  0.26938382, ...,  0.10792283,\n",
            "         -0.0215946 ,  1.        ],\n",
            "        [-0.27712864,  0.10127471,  0.32924607, ...,  0.08003184,\n",
            "         -0.0444396 ,  1.        ],\n",
            "        [-0.30186284,  0.08774574,  0.29489714, ...,  0.04635534,\n",
            "         -0.01600234,  1.        ]], dtype=float32)\n",
            " array([[-0.010466  , -0.11264233, -0.04060423, ...,  0.03678708,\n",
            "          0.20019436,  1.        ],\n",
            "        [ 0.14248024, -0.01801163, -0.02369531, ...,  0.23150125,\n",
            "          0.07150439,  1.        ],\n",
            "        [ 0.15751904,  0.04459667, -0.0155848 , ...,  0.29672486,\n",
            "         -0.07831386,  1.        ],\n",
            "        ...,\n",
            "        [ 0.01563984,  0.1152036 ,  0.13065536, ...,  0.03280066,\n",
            "          0.02510782,  1.        ],\n",
            "        [-0.1924023 ,  0.13212512,  0.32991046, ...,  0.07044253,\n",
            "         -0.0139457 ,  1.        ],\n",
            "        [-0.2679038 ,  0.10295431,  0.30688533, ...,  0.05158453,\n",
            "         -0.0033497 ,  1.        ]], dtype=float32)\n",
            " array([[-0.02161611, -0.12182471, -0.02687137, ...,  0.03573423,\n",
            "          0.2016959 ,  1.        ],\n",
            "        [ 0.12367728, -0.02609516,  0.00293284, ...,  0.2362314 ,\n",
            "          0.09568847,  1.        ],\n",
            "        [ 0.12847362,  0.03965821,  0.02449674, ...,  0.30794105,\n",
            "         -0.0495607 ,  1.        ],\n",
            "        ...,\n",
            "        [-0.02266878,  0.1376799 ,  0.19381055, ...,  0.04167765,\n",
            "          0.01523662,  1.        ],\n",
            "        [-0.21751846,  0.13428481,  0.34761912, ...,  0.04776037,\n",
            "         -0.0113398 ,  1.        ],\n",
            "        [-0.28377837,  0.10557979,  0.30846468, ...,  0.03866153,\n",
            "         -0.00527937,  1.        ]], dtype=float32)\n",
            " array([[-0.0214787 , -0.12898158, -0.02419063, ...,  0.03977524,\n",
            "          0.20710316,  1.        ],\n",
            "        [ 0.12138289, -0.04925561,  0.00315097, ...,  0.24271438,\n",
            "          0.12320927,  1.        ],\n",
            "        [ 0.12268315,  0.00863328,  0.02093124, ...,  0.32580826,\n",
            "         -0.00913699,  1.        ],\n",
            "        ...,\n",
            "        [-0.11539488,  0.13999787,  0.27024645, ...,  0.07898334,\n",
            "         -0.01527476,  1.        ],\n",
            "        [-0.2535563 ,  0.12901998,  0.3621891 , ...,  0.06334206,\n",
            "         -0.03273052,  1.        ],\n",
            "        [-0.2977635 ,  0.0956047 ,  0.31277505, ...,  0.05010311,\n",
            "         -0.01539685,  1.        ]], dtype=float32)\n",
            " array([[-0.02208608, -0.13260946, -0.02809433, ...,  0.04878151,\n",
            "          0.21422581,  1.        ],\n",
            "        [ 0.14454058, -0.0524269 , -0.00943107, ...,  0.23052204,\n",
            "          0.14261077,  1.        ],\n",
            "        [ 0.1289133 , -0.00601971,  0.01362418, ...,  0.31499907,\n",
            "          0.00654138,  1.        ],\n",
            "        ...,\n",
            "        [-0.14668095,  0.15362161,  0.26214054, ...,  0.05573525,\n",
            "         -0.01086606,  1.        ],\n",
            "        [-0.2559371 ,  0.12918784,  0.3254413 , ...,  0.05362561,\n",
            "         -0.03333055,  1.        ],\n",
            "        [-0.28561437,  0.0980811 ,  0.2923513 , ...,  0.05461711,\n",
            "         -0.01112447,  1.        ]], dtype=float32)\n",
            " array([[-5.77106420e-03, -1.13426134e-01, -4.95507009e-02, ...,\n",
            "          3.87220979e-02,  1.99417368e-01,  3.00000000e+00],\n",
            "        [ 1.40844882e-01, -2.45503541e-02, -3.27397585e-02, ...,\n",
            "          2.40959704e-01,  7.04283193e-02,  3.00000000e+00],\n",
            "        [ 1.55676425e-01,  3.91020812e-02, -2.76868492e-02, ...,\n",
            "          3.10778826e-01, -7.58247226e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 5.46317883e-02,  9.96517688e-02,  8.93243253e-02, ...,\n",
            "          5.12790270e-02,  4.55149263e-02,  3.00000000e+00],\n",
            "        [-1.72933027e-01,  1.22564167e-01,  3.09900254e-01, ...,\n",
            "          9.14925113e-02, -8.18562973e-03,  3.00000000e+00],\n",
            "        [-2.57625133e-01,  9.92245600e-02,  2.95799375e-01, ...,\n",
            "          6.16704710e-02,  9.99053009e-04,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.8463928e-02, -1.3101842e-01, -2.9413754e-02, ...,\n",
            "          4.4410583e-02,  2.0643087e-01,  3.0000000e+00],\n",
            "        [ 1.3482703e-01, -5.2449342e-02, -7.8931805e-03, ...,\n",
            "          2.6432991e-01,  1.2401653e-01,  3.0000000e+00],\n",
            "        [ 1.3068527e-01,  1.6595884e-03,  3.7709360e-03, ...,\n",
            "          3.5876825e-01, -1.6478365e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-8.4125452e-02,  1.1630329e-01,  2.1774642e-01, ...,\n",
            "          9.5705509e-02, -9.4049564e-03,  3.0000000e+00],\n",
            "        [-2.3604189e-01,  1.1482376e-01,  3.2621577e-01, ...,\n",
            "          7.8835391e-02, -3.0938733e-02,  3.0000000e+00],\n",
            "        [-2.8532118e-01,  9.5921390e-02,  2.9382080e-01, ...,\n",
            "          5.1319897e-02, -1.0711456e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.2797778e-02, -1.3299553e-01, -2.6981207e-02, ...,\n",
            "          4.5511026e-02,  2.0941976e-01,  3.0000000e+00],\n",
            "        [ 1.3212739e-01, -4.8767492e-02, -9.1922972e-03, ...,\n",
            "          2.5633785e-01,  1.2677203e-01,  3.0000000e+00],\n",
            "        [ 1.2300858e-01, -2.2897411e-03,  9.1021657e-03, ...,\n",
            "          3.4397995e-01, -5.2766204e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0903234e-01,  1.2480000e-01,  2.4428119e-01, ...,\n",
            "          8.3601296e-02, -1.5052218e-02,  3.0000000e+00],\n",
            "        [-2.4604349e-01,  1.1928393e-01,  3.3419627e-01, ...,\n",
            "          7.0251778e-02, -3.4177374e-02,  3.0000000e+00],\n",
            "        [-2.9287830e-01,  9.3225941e-02,  2.9622841e-01, ...,\n",
            "          5.0548233e-02, -9.5643429e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-2.9151846e-02, -1.5608521e-01, -5.1161975e-02, ...,\n",
            "          5.8132082e-02,  2.1457800e-01,  3.0000000e+00],\n",
            "        [ 1.5146132e-01, -9.9043928e-02, -7.3872782e-02, ...,\n",
            "          2.9973480e-01,  1.5275005e-01,  3.0000000e+00],\n",
            "        [ 1.0573684e-01, -1.0206230e-01, -7.9417385e-02, ...,\n",
            "          3.9565197e-01,  6.9989599e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2805466e-01,  6.2076310e-03,  2.0760724e-01, ...,\n",
            "          1.1792136e-01,  8.5470214e-04,  3.0000000e+00],\n",
            "        [-2.1818206e-01,  1.1454998e-02,  2.2952677e-01, ...,\n",
            "          9.3560115e-02, -3.3849120e-02,  3.0000000e+00],\n",
            "        [-2.6607624e-01,  2.0241085e-02,  2.4725850e-01, ...,\n",
            "          4.0469375e-02, -1.5791936e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03375871, -0.15084751, -0.05739906, ...,  0.06405276,\n",
            "          0.20402808,  3.        ],\n",
            "        [ 0.13181227, -0.112735  , -0.06807923, ...,  0.30076018,\n",
            "          0.15197286,  3.        ],\n",
            "        [ 0.06883921, -0.11184493, -0.07510886, ...,  0.4039792 ,\n",
            "          0.08097871,  3.        ],\n",
            "        ...,\n",
            "        [-0.1998136 ,  0.03891187,  0.19650215, ...,  0.10353853,\n",
            "         -0.062539  ,  3.        ],\n",
            "        [-0.25567892,  0.04686004,  0.19707516, ...,  0.08541898,\n",
            "         -0.07620696,  3.        ],\n",
            "        [-0.26048717,  0.03052348,  0.23477742, ...,  0.02598767,\n",
            "         -0.04086171,  3.        ]], dtype=float32)\n",
            " array([[-0.02981128, -0.12799439, -0.03697564, ...,  0.05528156,\n",
            "          0.20957074,  3.        ],\n",
            "        [ 0.13692582, -0.06740607, -0.036604  , ...,  0.2692712 ,\n",
            "          0.14339449,  3.        ],\n",
            "        [ 0.11586213, -0.04738403, -0.03767421, ...,  0.37048733,\n",
            "          0.02520141,  3.        ],\n",
            "        ...,\n",
            "        [-0.13154744,  0.07846002,  0.2345194 , ...,  0.10070831,\n",
            "         -0.0039511 ,  3.        ],\n",
            "        [-0.24851008,  0.06808609,  0.29323354, ...,  0.08274508,\n",
            "         -0.03545779,  3.        ],\n",
            "        [-0.2940951 ,  0.07923756,  0.27783978, ...,  0.04376419,\n",
            "         -0.01463933,  3.        ]], dtype=float32)\n",
            " array([[-2.0164521e-02, -1.3351543e-01, -2.8111184e-02, ...,\n",
            "          5.0774839e-02,  2.1123905e-01,  3.0000000e+00],\n",
            "        [ 1.3638401e-01, -5.4910313e-02, -1.3881037e-02, ...,\n",
            "          2.6582089e-01,  1.3393405e-01,  3.0000000e+00],\n",
            "        [ 1.2519763e-01, -1.5987696e-02,  8.5446698e-04, ...,\n",
            "          3.5817444e-01,  4.2078923e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.1982509e-01,  1.1457288e-01,  2.4578756e-01, ...,\n",
            "          9.6247286e-02, -2.3223678e-02,  3.0000000e+00],\n",
            "        [-2.4745138e-01,  1.0688700e-01,  3.2514697e-01, ...,\n",
            "          8.1849292e-02, -3.9642442e-02,  3.0000000e+00],\n",
            "        [-2.9283285e-01,  8.9748137e-02,  2.9204017e-01, ...,\n",
            "          5.3138014e-02, -1.0990714e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[ 0.00972853, -0.11258149, -0.0607333 , ...,  0.0252244 ,\n",
            "          0.18964837,  3.        ],\n",
            "        [ 0.17713231, -0.02523613, -0.04735305, ...,  0.23078735,\n",
            "          0.03913756,  3.        ],\n",
            "        [ 0.17899987,  0.02264711, -0.04591607, ...,  0.29158577,\n",
            "         -0.09979261,  3.        ],\n",
            "        ...,\n",
            "        [ 0.08960249,  0.05439582,  0.0351621 , ...,  0.04546451,\n",
            "          0.04925188,  3.        ],\n",
            "        [-0.12950854,  0.11367967,  0.3008402 , ...,  0.09934425,\n",
            "         -0.02014535,  3.        ],\n",
            "        [-0.25534445,  0.0848437 ,  0.30273703, ...,  0.06517108,\n",
            "         -0.01013045,  3.        ]], dtype=float32)\n",
            " array([[-0.02625283, -0.12600219, -0.02427731, ...,  0.03639002,\n",
            "          0.20370209,  3.        ],\n",
            "        [ 0.11471019, -0.03972964,  0.01301718, ...,  0.22564164,\n",
            "          0.10943853,  3.        ],\n",
            "        [ 0.11482544,  0.01698927,  0.03447786, ...,  0.29889125,\n",
            "         -0.02941887,  3.        ],\n",
            "        ...,\n",
            "        [-0.10109858,  0.14469355,  0.26333088, ...,  0.05049668,\n",
            "         -0.01112023,  3.        ],\n",
            "        [-0.25069737,  0.13281108,  0.36867142, ...,  0.04256957,\n",
            "         -0.02766019,  3.        ],\n",
            "        [-0.29863095,  0.10066603,  0.31623027, ...,  0.0338348 ,\n",
            "         -0.00741013,  3.        ]], dtype=float32)\n",
            " array([[-1.92765035e-02, -1.25831082e-01, -3.23298015e-02, ...,\n",
            "          4.02164385e-02,  2.08019927e-01,  3.00000000e+00],\n",
            "        [ 1.18973210e-01, -3.58874053e-02, -2.98517826e-03, ...,\n",
            "          2.34409824e-01,  1.08754426e-01,  3.00000000e+00],\n",
            "        [ 1.30011544e-01,  2.53483672e-02,  1.26287248e-02, ...,\n",
            "          3.02913219e-01, -4.03884649e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-7.13506415e-02,  1.43446714e-01,  2.24064916e-01, ...,\n",
            "          5.97694367e-02, -9.13861953e-03,  3.00000000e+00],\n",
            "        [-2.36871764e-01,  1.37470394e-01,  3.51461351e-01, ...,\n",
            "          5.52627742e-02, -2.58191023e-02,  3.00000000e+00],\n",
            "        [-2.83701420e-01,  1.02943547e-01,  3.07204932e-01, ...,\n",
            "          4.43784110e-02, -2.45830673e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.0338434 , -0.13494438, -0.03129611, ...,  0.05993336,\n",
            "          0.21160446,  3.        ],\n",
            "        [ 0.16555543, -0.05941794, -0.027263  , ...,  0.25443473,\n",
            "          0.14624889,  3.        ],\n",
            "        [ 0.12872453, -0.03227044, -0.00989717, ...,  0.34182107,\n",
            "          0.03836967,  3.        ],\n",
            "        ...,\n",
            "        [-0.14449596,  0.10683166,  0.2501367 , ...,  0.06680865,\n",
            "         -0.00753474,  3.        ],\n",
            "        [-0.25005198,  0.08759545,  0.28931752, ...,  0.06075793,\n",
            "         -0.04071204,  3.        ],\n",
            "        [-0.28062335,  0.08077925,  0.27648568, ...,  0.04801811,\n",
            "         -0.01816561,  3.        ]], dtype=float32)\n",
            " array([[-0.03191906, -0.12083417, -0.02869014, ...,  0.05302762,\n",
            "          0.205589  ,  3.        ],\n",
            "        [ 0.12816608, -0.05901944, -0.02041288, ...,  0.24287698,\n",
            "          0.13737439,  3.        ],\n",
            "        [ 0.11157236, -0.02717467, -0.00524223, ...,  0.33512053,\n",
            "          0.01842322,  3.        ],\n",
            "        ...,\n",
            "        [-0.1720293 ,  0.11956781,  0.27027795, ...,  0.08275028,\n",
            "         -0.02439269,  3.        ],\n",
            "        [-0.28180656,  0.09950574,  0.32684934, ...,  0.06841448,\n",
            "         -0.04629679,  3.        ],\n",
            "        [-0.3014756 ,  0.09662105,  0.2920446 , ...,  0.03419911,\n",
            "         -0.01480124,  3.        ]], dtype=float32)\n",
            " array([[-0.03673476, -0.14976062, -0.04340422, ...,  0.0548093 ,\n",
            "          0.21338977,  3.        ],\n",
            "        [ 0.14082836, -0.09285263, -0.05733325, ...,  0.2858256 ,\n",
            "          0.15814394,  3.        ],\n",
            "        [ 0.09762313, -0.09201831, -0.065043  , ...,  0.37848637,\n",
            "          0.07959742,  3.        ],\n",
            "        ...,\n",
            "        [-0.14984117,  0.03336218,  0.22252251, ...,  0.11066452,\n",
            "          0.01024729,  3.        ],\n",
            "        [-0.25405756,  0.03823949,  0.25746295, ...,  0.0863971 ,\n",
            "         -0.03897691,  3.        ],\n",
            "        [-0.2904364 ,  0.03768509,  0.26585123, ...,  0.03045403,\n",
            "         -0.0170591 ,  3.        ]], dtype=float32)\n",
            " array([[-0.03365082, -0.14048488, -0.03606168, ...,  0.05165389,\n",
            "          0.20889755,  3.        ],\n",
            "        [ 0.13745677, -0.07421686, -0.0425311 , ...,  0.2676182 ,\n",
            "          0.1425297 ,  3.        ],\n",
            "        [ 0.10615065, -0.05674819, -0.04331815, ...,  0.35729775,\n",
            "          0.04022665,  3.        ],\n",
            "        ...,\n",
            "        [-0.14263278,  0.06532165,  0.22835083, ...,  0.08829635,\n",
            "          0.0088421 ,  3.        ],\n",
            "        [-0.2501933 ,  0.06243254,  0.281973  , ...,  0.07287394,\n",
            "         -0.03375153,  3.        ],\n",
            "        [-0.29373652,  0.06567511,  0.2806247 , ...,  0.03413124,\n",
            "         -0.01455717,  3.        ]], dtype=float32)\n",
            " array([[-0.03236147, -0.12230533, -0.03096994, ...,  0.05215107,\n",
            "          0.2044309 ,  3.        ],\n",
            "        [ 0.12546146, -0.06443471, -0.02679869, ...,  0.24915107,\n",
            "          0.13444972,  3.        ],\n",
            "        [ 0.10923046, -0.03420969, -0.01646982, ...,  0.3431503 ,\n",
            "          0.01575023,  3.        ],\n",
            "        ...,\n",
            "        [-0.16127022,  0.11514755,  0.26061043, ...,  0.09094582,\n",
            "         -0.01903635,  3.        ],\n",
            "        [-0.27408934,  0.10127728,  0.3199021 , ...,  0.07296458,\n",
            "         -0.0442314 ,  3.        ],\n",
            "        [-0.30261245,  0.09189623,  0.29130757, ...,  0.03267606,\n",
            "         -0.01776919,  3.        ]], dtype=float32)\n",
            " array([[-2.59207319e-02, -1.28751248e-01, -2.55053956e-02, ...,\n",
            "          4.26448435e-02,  2.07067490e-01,  3.00000000e+00],\n",
            "        [ 1.17058463e-01, -5.03225103e-02, -1.51414261e-03, ...,\n",
            "          2.43736073e-01,  1.24665402e-01,  3.00000000e+00],\n",
            "        [ 1.11648135e-01,  6.15156081e-04,  1.67416856e-02, ...,\n",
            "          3.27491134e-01, -9.92884673e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.27014071e-01,  1.38501242e-01,  2.70195156e-01, ...,\n",
            "          6.70526028e-02, -1.84238851e-02,  3.00000000e+00],\n",
            "        [-2.56912738e-01,  1.30712897e-01,  3.56409550e-01, ...,\n",
            "          5.93164898e-02, -3.51295210e-02,  3.00000000e+00],\n",
            "        [-3.00736368e-01,  9.63714793e-02,  3.09608668e-01, ...,\n",
            "          4.13543135e-02, -9.58637521e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03580412, -0.15276387, -0.05172395, ...,  0.05912283,\n",
            "          0.21131386,  3.        ],\n",
            "        [ 0.13726476, -0.11237761, -0.07127362, ...,  0.29361638,\n",
            "          0.15893003,  3.        ],\n",
            "        [ 0.07886523, -0.1126871 , -0.07589324, ...,  0.39410466,\n",
            "          0.08187127,  3.        ],\n",
            "        ...,\n",
            "        [-0.16166687,  0.01918147,  0.20432158, ...,  0.11706856,\n",
            "         -0.01593274,  3.        ],\n",
            "        [-0.24764611,  0.03272326,  0.21482436, ...,  0.09347611,\n",
            "         -0.05310037,  3.        ],\n",
            "        [-0.2752807 ,  0.01528462,  0.24391556, ...,  0.03184511,\n",
            "         -0.03667171,  3.        ]], dtype=float32)\n",
            " array([[-0.03325312, -0.14616685, -0.03796598, ...,  0.052062  ,\n",
            "          0.21223436,  3.        ],\n",
            "        [ 0.1395985 , -0.08561779, -0.0498491 , ...,  0.27164334,\n",
            "          0.15206051,  3.        ],\n",
            "        [ 0.09990145, -0.07354215, -0.05159269, ...,  0.36303017,\n",
            "          0.05601695,  3.        ],\n",
            "        ...,\n",
            "        [-0.15012912,  0.03804706,  0.22563487, ...,  0.1039352 ,\n",
            "          0.0164042 ,  3.        ],\n",
            "        [-0.25060833,  0.04188088,  0.2743813 , ...,  0.08123438,\n",
            "         -0.03479806,  3.        ],\n",
            "        [-0.29285634,  0.04998936,  0.27548108, ...,  0.0311817 ,\n",
            "         -0.02246122,  3.        ]], dtype=float32)\n",
            " array([[-0.03761688, -0.14654465, -0.0465009 , ...,  0.05631119,\n",
            "          0.21404764,  3.        ],\n",
            "        [ 0.13510363, -0.09967351, -0.06939232, ...,  0.2887285 ,\n",
            "          0.15967456,  3.        ],\n",
            "        [ 0.08544319, -0.10163988, -0.07366276, ...,  0.38535532,\n",
            "          0.08302774,  3.        ],\n",
            "        ...,\n",
            "        [-0.15374216,  0.01706693,  0.21482928, ...,  0.12340943,\n",
            "          0.00623269,  3.        ],\n",
            "        [-0.25485873,  0.02554582,  0.24311529, ...,  0.09477589,\n",
            "         -0.04067153,  3.        ],\n",
            "        [-0.2900401 ,  0.02480322,  0.2596219 , ...,  0.03111133,\n",
            "         -0.02834465,  3.        ]], dtype=float32)\n",
            " array([[-0.03365557, -0.12206956, -0.03201787, ...,  0.05227484,\n",
            "          0.20710322,  3.        ],\n",
            "        [ 0.12362584, -0.05936981, -0.02818713, ...,  0.24987262,\n",
            "          0.13937092,  3.        ],\n",
            "        [ 0.10501129, -0.03088814, -0.0161353 , ...,  0.34288785,\n",
            "          0.01943498,  3.        ],\n",
            "        ...,\n",
            "        [-0.16597888,  0.11242104,  0.2696183 , ...,  0.09485579,\n",
            "         -0.01817882,  3.        ],\n",
            "        [-0.27783188,  0.09756421,  0.3246673 , ...,  0.07219635,\n",
            "         -0.04621748,  3.        ],\n",
            "        [-0.3062022 ,  0.08875249,  0.29330948, ...,  0.0321569 ,\n",
            "         -0.0204796 ,  3.        ]], dtype=float32)\n",
            " array([[-0.02942681, -0.11908815, -0.02980764, ...,  0.05386681,\n",
            "          0.20493607,  3.        ],\n",
            "        [ 0.12996429, -0.06129855, -0.03228764, ...,  0.25797364,\n",
            "          0.13845743,  3.        ],\n",
            "        [ 0.11517731, -0.02995219, -0.02127288, ...,  0.3556877 ,\n",
            "          0.01306213,  3.        ],\n",
            "        ...,\n",
            "        [-0.16122451,  0.12117858,  0.2607554 , ...,  0.11451551,\n",
            "         -0.01781373,  3.        ],\n",
            "        [-0.27314043,  0.10972882,  0.32400966, ...,  0.08360948,\n",
            "         -0.04033365,  3.        ],\n",
            "        [-0.3067899 ,  0.0841978 ,  0.2928168 , ...,  0.04446338,\n",
            "         -0.02684383,  3.        ]], dtype=float32)\n",
            " array([[-2.1121070e-02, -1.2455164e-01, -2.7308749e-02, ...,\n",
            "          3.7394688e-02,  2.0569079e-01,  3.0000000e+00],\n",
            "        [ 1.2404425e-01, -3.4314845e-02, -1.9138881e-03, ...,\n",
            "          2.3863979e-01,  1.0913859e-01,  3.0000000e+00],\n",
            "        [ 1.2187372e-01,  2.9034141e-02,  1.6030021e-02, ...,\n",
            "          3.1912291e-01, -3.1404566e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-5.0821301e-02,  1.3145880e-01,  2.1602498e-01, ...,\n",
            "          6.2318042e-02,  4.4347653e-03,  3.0000000e+00],\n",
            "        [-2.3504524e-01,  1.3006583e-01,  3.5182631e-01, ...,\n",
            "          5.7463981e-02, -1.7808715e-02,  3.0000000e+00],\n",
            "        [-2.9217929e-01,  9.4727986e-02,  3.0781114e-01, ...,\n",
            "          4.5448732e-02, -1.1193435e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03148295, -0.15598084, -0.04375713, ...,  0.05151289,\n",
            "          0.21126807,  3.        ],\n",
            "        [ 0.1440089 , -0.09297489, -0.05833964, ...,  0.2726085 ,\n",
            "          0.14786375,  3.        ],\n",
            "        [ 0.1042456 , -0.08474875, -0.06325711, ...,  0.36503062,\n",
            "          0.05020859,  3.        ],\n",
            "        ...,\n",
            "        [-0.12492227,  0.02365418,  0.20128316, ...,  0.09876578,\n",
            "          0.02081433,  3.        ],\n",
            "        [-0.23062754,  0.0282854 ,  0.2517253 , ...,  0.07520614,\n",
            "         -0.03213391,  3.        ],\n",
            "        [-0.27530527,  0.03555173,  0.2599531 , ...,  0.02938017,\n",
            "         -0.01758882,  3.        ]], dtype=float32)\n",
            " array([[-3.21018212e-02, -1.57993063e-01, -5.52570224e-02, ...,\n",
            "          5.76307513e-02,  2.12238938e-01,  3.00000000e+00],\n",
            "        [ 1.38236091e-01, -1.16716042e-01, -8.06559548e-02, ...,\n",
            "          2.96715796e-01,  1.54578999e-01,  3.00000000e+00],\n",
            "        [ 8.78467038e-02, -1.18949063e-01, -8.66742730e-02, ...,\n",
            "          3.93953472e-01,  7.44101480e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.39817432e-01,  1.01435208e-03,  1.92270011e-01, ...,\n",
            "          1.26516551e-01,  2.88162287e-03,  3.00000000e+00],\n",
            "        [-2.22566441e-01,  1.07526705e-02,  2.13017821e-01, ...,\n",
            "          9.88367945e-02, -3.69641259e-02,  3.00000000e+00],\n",
            "        [-2.65458226e-01, -8.49125069e-03,  2.41121739e-01, ...,\n",
            "          3.88302878e-02, -3.43822949e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.01806537, -0.12258662, -0.03378353, ...,  0.03756016,\n",
            "          0.20515436,  3.        ],\n",
            "        [ 0.12085601, -0.02873428, -0.00955439, ...,  0.23779824,\n",
            "          0.09386514,  3.        ],\n",
            "        [ 0.1322161 ,  0.03864106,  0.00807866, ...,  0.3100427 ,\n",
            "         -0.05695739,  3.        ],\n",
            "        ...,\n",
            "        [-0.02720019,  0.12899226,  0.18240651, ...,  0.04652276,\n",
            "          0.01071126,  3.        ],\n",
            "        [-0.21895869,  0.12798503,  0.3388067 , ...,  0.05848043,\n",
            "         -0.01485574,  3.        ],\n",
            "        [-0.27861133,  0.09764937,  0.30196127, ...,  0.04833419,\n",
            "         -0.00302328,  3.        ]], dtype=float32)\n",
            " array([[-2.27094330e-02, -1.34448290e-01, -2.55786981e-02, ...,\n",
            "          4.44022417e-02,  2.06052393e-01,  3.00000000e+00],\n",
            "        [ 1.31656170e-01, -5.31101376e-02, -4.83749574e-03, ...,\n",
            "          2.58621842e-01,  1.20766915e-01,  3.00000000e+00],\n",
            "        [ 1.18016019e-01, -9.77392960e-03,  7.35618360e-03, ...,\n",
            "          3.48370373e-01, -2.11128057e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-9.57594365e-02,  1.21110238e-01,  2.36637190e-01, ...,\n",
            "          9.03910995e-02, -9.62341763e-03,  3.00000000e+00],\n",
            "        [-2.45922044e-01,  1.19162172e-01,  3.36767316e-01, ...,\n",
            "          7.65866265e-02, -3.06761824e-02,  3.00000000e+00],\n",
            "        [-2.93004811e-01,  9.63500142e-02,  2.97441214e-01, ...,\n",
            "          5.15191220e-02, -9.11098812e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-3.65830697e-02, -1.50540978e-01, -5.08662648e-02, ...,\n",
            "          5.63831776e-02,  2.14153185e-01,  3.00000000e+00],\n",
            "        [ 1.39262125e-01, -1.05890684e-01, -7.30569288e-02, ...,\n",
            "          2.94469953e-01,  1.57992721e-01,  3.00000000e+00],\n",
            "        [ 8.79179314e-02, -1.07808650e-01, -7.82882720e-02, ...,\n",
            "          3.92579973e-01,  7.93115050e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.49372131e-01,  5.99496299e-03,  2.06019193e-01, ...,\n",
            "          1.18697748e-01, -9.01551277e-04,  3.00000000e+00],\n",
            "        [-2.38963887e-01,  1.36718238e-02,  2.31105641e-01, ...,\n",
            "          9.34750885e-02, -4.06462476e-02,  3.00000000e+00],\n",
            "        [-2.81303555e-01,  1.42417559e-02,  2.51549393e-01, ...,\n",
            "          3.23445909e-02, -2.71834917e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-1.9235896e-02, -1.2392162e-01, -3.3755381e-02, ...,\n",
            "          3.9687637e-02,  2.0136389e-01,  3.0000000e+00],\n",
            "        [ 1.2627508e-01, -3.1445391e-02, -8.8880742e-03, ...,\n",
            "          2.4626103e-01,  9.7789928e-02,  3.0000000e+00],\n",
            "        [ 1.2731938e-01,  3.4205705e-02,  7.4353698e-03, ...,\n",
            "          3.2631361e-01, -4.6426382e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-2.1675130e-02,  1.2682138e-01,  1.7759624e-01, ...,\n",
            "          6.4751364e-02,  1.5075660e-02,  3.0000000e+00],\n",
            "        [-2.1969716e-01,  1.2698527e-01,  3.3115947e-01, ...,\n",
            "          6.7629248e-02, -1.0641644e-02,  3.0000000e+00],\n",
            "        [-2.7544600e-01,  1.0200601e-01,  2.9188564e-01, ...,\n",
            "          4.6140078e-02, -9.4223238e-04,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.00990508, -0.11480179, -0.04322895, ...,  0.03050138,\n",
            "          0.19440733,  3.        ],\n",
            "        [ 0.15063162, -0.01252074, -0.02272008, ...,  0.23879442,\n",
            "          0.05874696,  3.        ],\n",
            "        [ 0.15291426,  0.0518219 , -0.01498252, ...,  0.30728224,\n",
            "         -0.08056296,  3.        ],\n",
            "        ...,\n",
            "        [ 0.03360715,  0.11913187,  0.11546605, ...,  0.0337767 ,\n",
            "          0.02145026,  3.        ],\n",
            "        [-0.18449146,  0.12857223,  0.32173756, ...,  0.06621842,\n",
            "         -0.02162696,  3.        ],\n",
            "        [-0.26827446,  0.08710448,  0.3035016 , ...,  0.0489798 ,\n",
            "         -0.01817292,  3.        ]], dtype=float32)\n",
            " array([[ 1.26429899e-02, -1.14339679e-01, -6.71406388e-02, ...,\n",
            "          2.14698464e-02,  1.92434698e-01,  3.00000000e+00],\n",
            "        [ 1.80716857e-01, -3.34284306e-02, -6.02313504e-02, ...,\n",
            "          2.17103273e-01,  3.17547247e-02,  3.00000000e+00],\n",
            "        [ 1.86721981e-01,  1.09776827e-02, -6.07245751e-02, ...,\n",
            "          2.73017973e-01, -1.05094165e-01,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.03181735e-01,  2.99183521e-02, -1.65169197e-03, ...,\n",
            "          2.80347690e-02,  5.65515086e-02,  3.00000000e+00],\n",
            "        [-1.11395337e-01,  1.16593614e-01,  2.94944465e-01, ...,\n",
            "          8.48650709e-02, -1.65515840e-02,  3.00000000e+00],\n",
            "        [-2.63473511e-01,  8.58742967e-02,  3.12658131e-01, ...,\n",
            "          6.11772053e-02, -4.03221278e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[ 4.76593114e-02, -1.71373501e-01, -9.44769904e-02, ...,\n",
            "          1.04773976e-03,  1.85875729e-01,  3.00000000e+00],\n",
            "        [ 2.74883807e-01, -1.94049664e-02, -9.19802785e-02, ...,\n",
            "          1.43170819e-01,  2.01121289e-02,  3.00000000e+00],\n",
            "        [ 2.75589824e-01,  2.97632087e-02, -7.62770399e-02, ...,\n",
            "          1.86485007e-01, -9.77631286e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [ 1.42296329e-01,  3.59265669e-03, -1.04541957e-01, ...,\n",
            "          8.81987289e-02,  5.12241796e-02,  3.00000000e+00],\n",
            "        [-1.33836232e-02,  7.65140131e-02,  1.58428803e-01, ...,\n",
            "          1.24680944e-01, -2.83324290e-02,  3.00000000e+00],\n",
            "        [-2.31045961e-01,  5.49465120e-02,  2.93466926e-01, ...,\n",
            "          8.14660490e-02, -7.78377708e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.10155249e-02, -1.17097765e-01, -2.86554359e-02, ...,\n",
            "          4.41239700e-02,  2.16455877e-01,  3.00000000e+00],\n",
            "        [ 1.30313411e-01, -3.21802311e-02,  1.05484331e-03, ...,\n",
            "          2.09888682e-01,  1.27107531e-01,  3.00000000e+00],\n",
            "        [ 1.20534129e-01,  3.10975928e-02,  2.49372106e-02, ...,\n",
            "          2.88456082e-01, -2.33742688e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-8.82543251e-02,  1.65208504e-01,  2.48685136e-01, ...,\n",
            "          2.90381759e-02,  2.75248103e-03,  3.00000000e+00],\n",
            "        [-2.43653178e-01,  1.47751570e-01,  3.52561861e-01, ...,\n",
            "          4.09392081e-02, -1.39522636e-02,  3.00000000e+00],\n",
            "        [-2.80051470e-01,  1.11692682e-01,  3.08009535e-01, ...,\n",
            "          5.93151823e-02,  2.58138333e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.02015561, -0.11555224, -0.03191376, ...,  0.03958203,\n",
            "          0.20372607,  3.        ],\n",
            "        [ 0.12412049, -0.01989096, -0.00387011, ...,  0.23422346,\n",
            "          0.08647777,  3.        ],\n",
            "        [ 0.13769598,  0.04944921,  0.00998566, ...,  0.29878265,\n",
            "         -0.06328046,  3.        ],\n",
            "        ...,\n",
            "        [-0.01193836,  0.1358685 ,  0.16917203, ...,  0.0324842 ,\n",
            "          0.0234336 ,  3.        ],\n",
            "        [-0.21094644,  0.1325309 ,  0.3432699 , ...,  0.05739373,\n",
            "         -0.0071136 ,  3.        ],\n",
            "        [-0.27315   ,  0.10723392,  0.3041126 , ...,  0.0440096 ,\n",
            "          0.00638522,  3.        ]], dtype=float32)\n",
            " array([[-2.24402733e-02, -1.30457371e-01, -2.72116512e-02, ...,\n",
            "          4.17025313e-02,  2.07492962e-01,  3.00000000e+00],\n",
            "        [ 1.23944715e-01, -4.93629910e-02, -3.29079106e-03, ...,\n",
            "          2.49890149e-01,  1.19389951e-01,  3.00000000e+00],\n",
            "        [ 1.20078243e-01,  4.47278563e-03,  1.28055839e-02, ...,\n",
            "          3.34606647e-01, -1.69580877e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-8.70686322e-02,  1.30784482e-01,  2.27753446e-01, ...,\n",
            "          7.25792274e-02, -1.04759343e-03,  3.00000000e+00],\n",
            "        [-2.44264916e-01,  1.29932702e-01,  3.40112686e-01, ...,\n",
            "          6.57258630e-02, -2.56055873e-02,  3.00000000e+00],\n",
            "        [-2.88764596e-01,  9.77883041e-02,  2.98629373e-01, ...,\n",
            "          4.67983596e-02, -5.64509537e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.02487378, -0.13590741, -0.02785897, ...,  0.04422173,\n",
            "          0.20663449,  3.        ],\n",
            "        [ 0.12782963, -0.05375709, -0.01024718, ...,  0.2582845 ,\n",
            "          0.12291991,  3.        ],\n",
            "        [ 0.11838717, -0.00745074,  0.00561116, ...,  0.34373298,\n",
            "         -0.00464397,  3.        ],\n",
            "        ...,\n",
            "        [-0.11863738,  0.13193925,  0.24188527, ...,  0.0773939 ,\n",
            "         -0.01162342,  3.        ],\n",
            "        [-0.24299312,  0.12311039,  0.32650015, ...,  0.0656953 ,\n",
            "         -0.03441283,  3.        ],\n",
            "        [-0.28836218,  0.09480885,  0.30051336, ...,  0.04804932,\n",
            "         -0.01283369,  3.        ]], dtype=float32)\n",
            " array([[-2.3815418e-02, -1.2975281e-01, -2.6826063e-02, ...,\n",
            "          4.1690808e-02,  2.0696785e-01,  3.0000000e+00],\n",
            "        [ 1.1959338e-01, -4.9163949e-02, -1.2335076e-03, ...,\n",
            "          2.4442230e-01,  1.1915302e-01,  3.0000000e+00],\n",
            "        [ 1.1695317e-01,  5.0675371e-03,  1.6199347e-02, ...,\n",
            "          3.2601067e-01, -1.8499827e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-9.8675109e-02,  1.3778965e-01,  2.5280246e-01, ...,\n",
            "          6.8795897e-02, -6.7539993e-03,  3.0000000e+00],\n",
            "        [-2.4860552e-01,  1.3222018e-01,  3.5509765e-01, ...,\n",
            "          6.1990846e-02, -2.8450193e-02,  3.0000000e+00],\n",
            "        [-2.9340118e-01,  1.0042074e-01,  3.0641991e-01, ...,\n",
            "          4.3607157e-02, -5.9007332e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03262919, -0.1600632 , -0.05377334, ...,  0.05434416,\n",
            "          0.2098516 ,  3.        ],\n",
            "        [ 0.13638641, -0.11643462, -0.06919105, ...,  0.286815  ,\n",
            "          0.15044558,  3.        ],\n",
            "        [ 0.08970752, -0.11910625, -0.07559768, ...,  0.3767598 ,\n",
            "          0.07775247,  3.        ],\n",
            "        ...,\n",
            "        [-0.14931732, -0.00357088,  0.2049597 , ...,  0.10465018,\n",
            "         -0.00953945,  3.        ],\n",
            "        [-0.22739252,  0.0217317 ,  0.21488795, ...,  0.08643512,\n",
            "         -0.04433105,  3.        ],\n",
            "        [-0.26103112,  0.01011654,  0.24134658, ...,  0.03055524,\n",
            "         -0.02280935,  3.        ]], dtype=float32)\n",
            " array([[-2.55173277e-02, -1.34997934e-01, -2.77976990e-02, ...,\n",
            "          4.44970094e-02,  2.07637921e-01,  3.00000000e+00],\n",
            "        [ 1.28475145e-01, -5.55717461e-02, -1.04094120e-02, ...,\n",
            "          2.63736904e-01,  1.23502977e-01,  3.00000000e+00],\n",
            "        [ 1.16656244e-01, -1.04600489e-02,  4.75005247e-03, ...,\n",
            "          3.50952625e-01, -7.31651380e-04,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.25790253e-01,  1.24058694e-01,  2.47142062e-01, ...,\n",
            "          7.10380673e-02, -1.37282033e-02,  3.00000000e+00],\n",
            "        [-2.40570948e-01,  1.19286723e-01,  3.20331186e-01, ...,\n",
            "          6.55032769e-02, -3.47874574e-02,  3.00000000e+00],\n",
            "        [-2.91573972e-01,  9.19590294e-02,  3.00894856e-01, ...,\n",
            "          4.65658940e-02, -1.25976130e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.02124436, -0.12425826, -0.03003837, ...,  0.03787656,\n",
            "          0.20455642,  3.        ],\n",
            "        [ 0.121962  , -0.03823803, -0.0045077 , ...,  0.24123414,\n",
            "          0.10787863,  3.        ],\n",
            "        [ 0.12413916,  0.02493836,  0.01384824, ...,  0.319565  ,\n",
            "         -0.03660805,  3.        ],\n",
            "        ...,\n",
            "        [-0.05087145,  0.13706334,  0.20942976, ...,  0.06449993,\n",
            "          0.00524628,  3.        ],\n",
            "        [-0.23120688,  0.13871723,  0.34330162, ...,  0.06154133,\n",
            "         -0.01968662,  3.        ],\n",
            "        [-0.28366518,  0.10594545,  0.30408835, ...,  0.04427962,\n",
            "         -0.00394951,  3.        ]], dtype=float32)\n",
            " array([[-0.03465031, -0.14080895, -0.0348593 , ...,  0.05213465,\n",
            "          0.21292292,  3.        ],\n",
            "        [ 0.13713521, -0.07768145, -0.04953633, ...,  0.2719838 ,\n",
            "          0.15585539,  3.        ],\n",
            "        [ 0.09901278, -0.06302436, -0.04980599, ...,  0.36399087,\n",
            "          0.0567484 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.15393102,  0.05532818,  0.23825032, ...,  0.10412672,\n",
            "          0.01276827,  3.        ],\n",
            "        [-0.2604077 ,  0.05121448,  0.28599623, ...,  0.08013762,\n",
            "         -0.03338965,  3.        ],\n",
            "        [-0.30161616,  0.05558887,  0.2815296 , ...,  0.0346545 ,\n",
            "         -0.021799  ,  3.        ]], dtype=float32)\n",
            " array([[-2.6349511e-02, -1.3375646e-01, -2.6219228e-02, ...,\n",
            "          4.6570927e-02,  2.1001363e-01,  3.0000000e+00],\n",
            "        [ 1.2334053e-01, -5.4781973e-02, -4.0490809e-03, ...,\n",
            "          2.4474868e-01,  1.3148409e-01,  3.0000000e+00],\n",
            "        [ 1.1155966e-01, -1.3820088e-02,  1.6282385e-02, ...,\n",
            "          3.2848936e-01,  2.1197770e-03,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.3818866e-01,  1.2847738e-01,  2.6602623e-01, ...,\n",
            "          7.0458680e-02, -2.2131572e-02,  3.0000000e+00],\n",
            "        [-2.5951979e-01,  1.2026987e-01,  3.4310761e-01, ...,\n",
            "          6.1262444e-02, -4.3857165e-02,  3.0000000e+00],\n",
            "        [-3.0221200e-01,  9.0371691e-02,  3.0385557e-01, ...,\n",
            "          4.3074381e-02, -1.4059938e-02,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03481351, -0.13915446, -0.0329786 , ...,  0.05118736,\n",
            "          0.21104838,  3.        ],\n",
            "        [ 0.13329674, -0.07393695, -0.04596176, ...,  0.27227923,\n",
            "          0.14899838,  3.        ],\n",
            "        [ 0.09925044, -0.05819338, -0.04629309, ...,  0.3615002 ,\n",
            "          0.04951667,  3.        ],\n",
            "        ...,\n",
            "        [-0.14688455,  0.06661443,  0.23236138, ...,  0.10446371,\n",
            "          0.01515322,  3.        ],\n",
            "        [-0.25844595,  0.05485107,  0.28913236, ...,  0.07478023,\n",
            "         -0.0288624 ,  3.        ],\n",
            "        [-0.30167657,  0.06077835,  0.28411925, ...,  0.03475708,\n",
            "         -0.02076996,  3.        ]], dtype=float32)\n",
            " array([[-0.03642388, -0.14413589, -0.04058006, ...,  0.05495886,\n",
            "          0.21410128,  3.        ],\n",
            "        [ 0.13750681, -0.0871869 , -0.0570397 , ...,  0.28681642,\n",
            "          0.1580359 ,  3.        ],\n",
            "        [ 0.09552722, -0.0872163 , -0.06226628, ...,  0.37714326,\n",
            "          0.08226501,  3.        ],\n",
            "        ...,\n",
            "        [-0.15822795,  0.03479892,  0.22855455, ...,  0.11173863,\n",
            "          0.01004804,  3.        ],\n",
            "        [-0.2625398 ,  0.03795423,  0.26521182, ...,  0.08762997,\n",
            "         -0.03774343,  3.        ],\n",
            "        [-0.29806593,  0.04129237,  0.27016056, ...,  0.03200577,\n",
            "         -0.02238477,  3.        ]], dtype=float32)\n",
            " array([[-0.03448787, -0.14519444, -0.04308529, ...,  0.05514093,\n",
            "          0.21468143,  3.        ],\n",
            "        [ 0.13627005, -0.09076608, -0.06226354, ...,  0.2933525 ,\n",
            "          0.15583307,  3.        ],\n",
            "        [ 0.09603819, -0.09329373, -0.06987162, ...,  0.38325888,\n",
            "          0.0825698 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.15168218,  0.02450921,  0.22272176, ...,  0.12198984,\n",
            "          0.01047841,  3.        ],\n",
            "        [-0.2519111 ,  0.02286096,  0.26211074, ...,  0.09205897,\n",
            "         -0.03035798,  3.        ],\n",
            "        [-0.29150853,  0.03134479,  0.26577088, ...,  0.03926785,\n",
            "         -0.02428021,  3.        ]], dtype=float32)\n",
            " array([[-0.02259022, -0.11599946, -0.03095138, ...,  0.03989968,\n",
            "          0.20527428,  3.        ],\n",
            "        [ 0.11424531, -0.03061811, -0.00712416, ...,  0.23406354,\n",
            "          0.10032489,  3.        ],\n",
            "        [ 0.12392182,  0.03796866,  0.01292418, ...,  0.30388686,\n",
            "         -0.04932818,  3.        ],\n",
            "        ...,\n",
            "        [-0.04421627,  0.13516445,  0.20481108, ...,  0.04260269,\n",
            "          0.0154914 ,  3.        ],\n",
            "        [-0.22641797,  0.14062522,  0.35000297, ...,  0.05776798,\n",
            "         -0.0088329 ,  3.        ],\n",
            "        [-0.2852972 ,  0.10478852,  0.31055188, ...,  0.04466429,\n",
            "          0.00599775,  3.        ]], dtype=float32)\n",
            " array([[-0.01097947, -0.11259118, -0.04400494, ...,  0.0393071 ,\n",
            "          0.20218033,  3.        ],\n",
            "        [ 0.13378918, -0.0223803 , -0.02602837, ...,  0.23645805,\n",
            "          0.07892171,  3.        ],\n",
            "        [ 0.14414658,  0.04132855, -0.01539028, ...,  0.30390453,\n",
            "         -0.07075398,  3.        ],\n",
            "        ...,\n",
            "        [ 0.0328493 ,  0.10507789,  0.10128965, ...,  0.03855507,\n",
            "          0.05502559,  3.        ],\n",
            "        [-0.18407656,  0.13140903,  0.31496915, ...,  0.08439607,\n",
            "          0.00303013,  3.        ],\n",
            "        [-0.26841518,  0.09804365,  0.2981491 , ...,  0.05645971,\n",
            "          0.00364547,  3.        ]], dtype=float32)\n",
            " array([[-0.03639153, -0.15272082, -0.05307846, ...,  0.0579443 ,\n",
            "          0.21139824,  3.        ],\n",
            "        [ 0.13371556, -0.11597493, -0.0749682 , ...,  0.2931161 ,\n",
            "          0.1585181 ,  3.        ],\n",
            "        [ 0.07637687, -0.11637484, -0.07982028, ...,  0.39428878,\n",
            "          0.07976915,  3.        ],\n",
            "        ...,\n",
            "        [-0.15898009,  0.00927988,  0.20066553, ...,  0.11456289,\n",
            "         -0.01586635,  3.        ],\n",
            "        [-0.24241175,  0.02377777,  0.21171853, ...,  0.09040972,\n",
            "         -0.05335457,  3.        ],\n",
            "        [-0.27369913,  0.01018722,  0.2429895 , ...,  0.02949326,\n",
            "         -0.03354912,  3.        ]], dtype=float32)\n",
            " array([[-0.03236727, -0.13797839, -0.037877  , ...,  0.05321454,\n",
            "          0.209754  ,  3.        ],\n",
            "        [ 0.1397525 , -0.0760988 , -0.05515943, ...,  0.27469888,\n",
            "          0.14008425,  3.        ],\n",
            "        [ 0.11282735, -0.05726798, -0.05950167, ...,  0.36736274,\n",
            "          0.02928082,  3.        ],\n",
            "        ...,\n",
            "        [-0.13561752,  0.05325273,  0.21238619, ...,  0.10815952,\n",
            "          0.01600758,  3.        ],\n",
            "        [-0.24353468,  0.05183651,  0.27311155, ...,  0.07723302,\n",
            "         -0.02576751,  3.        ],\n",
            "        [-0.29142615,  0.05280491,  0.27437744, ...,  0.04125229,\n",
            "         -0.0228084 ,  3.        ]], dtype=float32)\n",
            " array([[-2.40672119e-02, -1.27811104e-01, -2.21071858e-02, ...,\n",
            "          4.11701612e-02,  2.04936281e-01,  3.00000000e+00],\n",
            "        [ 1.26049474e-01, -4.32838500e-02,  3.96694813e-04, ...,\n",
            "          2.47597277e-01,  1.13792934e-01,  3.00000000e+00],\n",
            "        [ 1.27163187e-01,  2.18883771e-02,  1.95215885e-02, ...,\n",
            "          3.31054926e-01, -2.37325579e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-9.04916972e-02,  1.40032738e-01,  2.49782056e-01, ...,\n",
            "          6.79871812e-02, -4.29555075e-03,  3.00000000e+00],\n",
            "        [-2.44306564e-01,  1.35133728e-01,  3.59500498e-01, ...,\n",
            "          5.77291623e-02, -2.09243596e-02,  3.00000000e+00],\n",
            "        [-2.96047539e-01,  1.01326056e-01,  3.12248319e-01, ...,\n",
            "          4.76289093e-02, -1.14632947e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.66243424e-02, -1.31710902e-01, -2.31973361e-02, ...,\n",
            "          4.29835320e-02,  2.06783906e-01,  3.00000000e+00],\n",
            "        [ 1.20358229e-01, -5.48921116e-02,  2.92089135e-05, ...,\n",
            "          2.47180611e-01,  1.25835001e-01,  3.00000000e+00],\n",
            "        [ 1.08376950e-01, -9.04917996e-03,  1.68202613e-02, ...,\n",
            "          3.31856787e-01,  1.57833332e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.35827810e-01,  1.30864888e-01,  2.67744064e-01, ...,\n",
            "          8.26664567e-02, -1.72458664e-02,  3.00000000e+00],\n",
            "        [-2.61050612e-01,  1.22118324e-01,  3.50397885e-01, ...,\n",
            "          6.36911541e-02, -4.03764099e-02,  3.00000000e+00],\n",
            "        [-3.03932011e-01,  9.09181312e-02,  3.09482098e-01, ...,\n",
            "          4.55953367e-02, -2.10881662e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03311254, -0.13633277, -0.03653162, ...,  0.05326869,\n",
            "          0.20955457,  3.        ],\n",
            "        [ 0.13949718, -0.07377529, -0.05286901, ...,  0.27422085,\n",
            "          0.1395403 ,  3.        ],\n",
            "        [ 0.11137679, -0.0562657 , -0.05677032, ...,  0.36401123,\n",
            "          0.03153837,  3.        ],\n",
            "        ...,\n",
            "        [-0.14002979,  0.06241048,  0.21944763, ...,  0.11129872,\n",
            "          0.01166681,  3.        ],\n",
            "        [-0.24826196,  0.05700942,  0.27749947, ...,  0.08141149,\n",
            "         -0.02857951,  3.        ],\n",
            "        [-0.29332307,  0.05903146,  0.27747267, ...,  0.04162332,\n",
            "         -0.02347614,  3.        ]], dtype=float32)\n",
            " array([[-0.02348108, -0.12915388, -0.02414301, ...,  0.0422509 ,\n",
            "          0.20721002,  3.        ],\n",
            "        [ 0.1236995 , -0.04728536, -0.00328673, ...,  0.25321206,\n",
            "          0.12003246,  3.        ],\n",
            "        [ 0.1189454 ,  0.00813668,  0.01414955, ...,  0.33571368,\n",
            "         -0.01039817,  3.        ],\n",
            "        ...,\n",
            "        [-0.09963024,  0.13289654,  0.25066653, ...,  0.08375174,\n",
            "         -0.01018665,  3.        ],\n",
            "        [-0.24796362,  0.127745  ,  0.3533759 , ...,  0.06610792,\n",
            "         -0.02821089,  3.        ],\n",
            "        [-0.30001944,  0.08864493,  0.3073822 , ...,  0.04931507,\n",
            "         -0.01549272,  3.        ]], dtype=float32)\n",
            " array([[-0.02441304, -0.13171647, -0.02475142, ...,  0.04143228,\n",
            "          0.2079206 ,  3.        ],\n",
            "        [ 0.12281395, -0.05186946, -0.00449393, ...,  0.24426861,\n",
            "          0.1281165 ,  3.        ],\n",
            "        [ 0.1105217 , -0.00751109,  0.01484145, ...,  0.32871014,\n",
            "          0.00429957,  3.        ],\n",
            "        ...,\n",
            "        [-0.1335369 ,  0.13662253,  0.26400065, ...,  0.08465368,\n",
            "         -0.01476511,  3.        ],\n",
            "        [-0.25939074,  0.12673485,  0.3472405 , ...,  0.06251606,\n",
            "         -0.03681611,  3.        ],\n",
            "        [-0.30217734,  0.08708441,  0.30595738, ...,  0.04697151,\n",
            "         -0.02409364,  3.        ]], dtype=float32)\n",
            " array([[-2.59401407e-02, -1.29668653e-01, -2.65336800e-02, ...,\n",
            "          4.13844064e-02,  2.07225695e-01,  3.00000000e+00],\n",
            "        [ 1.17237754e-01, -5.06578796e-02, -1.12701557e-03, ...,\n",
            "          2.42574573e-01,  1.20721526e-01,  3.00000000e+00],\n",
            "        [ 1.16457254e-01,  4.47516609e-03,  1.63844060e-02, ...,\n",
            "          3.24167669e-01, -1.61813982e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.24435440e-01,  1.41583607e-01,  2.71520853e-01, ...,\n",
            "          6.29079342e-02, -1.74563844e-02,  3.00000000e+00],\n",
            "        [-2.54311860e-01,  1.33908182e-01,  3.57779741e-01, ...,\n",
            "          5.77554777e-02, -3.51780802e-02,  3.00000000e+00],\n",
            "        [-2.96029031e-01,  9.95386839e-02,  3.09574783e-01, ...,\n",
            "          4.13736925e-02, -8.83769430e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03340805, -0.15632665, -0.05753306, ...,  0.06148266,\n",
            "          0.21201766,  3.        ],\n",
            "        [ 0.142164  , -0.11430765, -0.07920568, ...,  0.30600727,\n",
            "          0.15485264,  3.        ],\n",
            "        [ 0.08732186, -0.11605141, -0.08564394, ...,  0.40917838,\n",
            "          0.07817008,  3.        ],\n",
            "        ...,\n",
            "        [-0.15474693,  0.01503777,  0.19932465, ...,  0.12114955,\n",
            "         -0.0280026 ,  3.        ],\n",
            "        [-0.22561795,  0.02506073,  0.20231226, ...,  0.09657434,\n",
            "         -0.05256019,  3.        ],\n",
            "        [-0.26424244,  0.00978628,  0.23434216, ...,  0.03604103,\n",
            "         -0.02921795,  3.        ]], dtype=float32)\n",
            " array([[-0.01734843, -0.12475757, -0.0334565 , ...,  0.0394348 ,\n",
            "          0.20509115,  3.        ],\n",
            "        [ 0.12590902, -0.03030984, -0.00952857, ...,  0.2414522 ,\n",
            "          0.10244409,  3.        ],\n",
            "        [ 0.13087459,  0.03553138,  0.00905666, ...,  0.31812355,\n",
            "         -0.04476139,  3.        ],\n",
            "        ...,\n",
            "        [-0.03052458,  0.13186209,  0.18517974, ...,  0.0573793 ,\n",
            "          0.0100527 ,  3.        ],\n",
            "        [-0.2180565 ,  0.12970497,  0.33403137, ...,  0.06578693,\n",
            "         -0.01436453,  3.        ],\n",
            "        [-0.27506268,  0.09879845,  0.29878268, ...,  0.04993171,\n",
            "         -0.00578471,  3.        ]], dtype=float32)\n",
            " array([[-0.00702859, -0.11945689, -0.04473344, ...,  0.04446989,\n",
            "          0.21075118,  3.        ],\n",
            "        [ 0.12409035, -0.03741765, -0.02561476, ...,  0.2374674 ,\n",
            "          0.1095217 ,  3.        ],\n",
            "        [ 0.13182573,  0.03074285, -0.0162643 , ...,  0.31322336,\n",
            "         -0.04662397,  3.        ],\n",
            "        ...,\n",
            "        [-0.04259444,  0.1357939 ,  0.17046405, ...,  0.07059837,\n",
            "          0.01992296,  3.        ],\n",
            "        [-0.22436494,  0.12839653,  0.3252086 , ...,  0.08262432,\n",
            "         -0.00770323,  3.        ],\n",
            "        [-0.26537323,  0.09233804,  0.29772156, ...,  0.0689886 ,\n",
            "          0.00923829,  3.        ]], dtype=float32)\n",
            " array([[-1.88996065e-02, -1.15934059e-01, -3.37220654e-02, ...,\n",
            "          3.86738628e-02,  2.03978702e-01,  3.00000000e+00],\n",
            "        [ 1.21010266e-01, -2.59728990e-02, -8.79450422e-03, ...,\n",
            "          2.33881459e-01,  9.97565165e-02,  3.00000000e+00],\n",
            "        [ 1.28433093e-01,  4.25124206e-02,  1.32510550e-02, ...,\n",
            "          3.08068961e-01, -4.94654365e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-2.94472110e-02,  1.32265061e-01,  1.82749093e-01, ...,\n",
            "          4.47946191e-02,  2.91415695e-02,  3.00000000e+00],\n",
            "        [-2.15751037e-01,  1.32029116e-01,  3.41575056e-01, ...,\n",
            "          5.95004559e-02, -1.13455497e-03,  3.00000000e+00],\n",
            "        [-2.76433766e-01,  1.05465680e-01,  3.00982118e-01, ...,\n",
            "          4.46466394e-02,  4.21565073e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-3.07101961e-02, -1.31473467e-01, -3.42142731e-02, ...,\n",
            "          5.14900684e-02,  2.08553299e-01,  3.00000000e+00],\n",
            "        [ 1.39397606e-01, -6.21558614e-02, -4.01446968e-02, ...,\n",
            "          2.70380497e-01,  1.40791893e-01,  3.00000000e+00],\n",
            "        [ 1.17876463e-01, -3.92119102e-02, -3.75402048e-02, ...,\n",
            "          3.59852284e-01,  3.16236280e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.44738719e-01,  9.21373814e-02,  2.38927111e-01, ...,\n",
            "          1.06637314e-01,  3.37628953e-05,  3.00000000e+00],\n",
            "        [-2.54779905e-01,  7.49822631e-02,  2.97772676e-01, ...,\n",
            "          7.92269260e-02, -3.13698389e-02,  3.00000000e+00],\n",
            "        [-2.96977282e-01,  6.93628863e-02,  2.86067158e-01, ...,\n",
            "          4.34518978e-02, -2.61017568e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03047934, -0.13663167, -0.0371367 , ...,  0.05460845,\n",
            "          0.20852318,  3.        ],\n",
            "        [ 0.14621778, -0.07558379, -0.05202864, ...,  0.28330368,\n",
            "          0.13782708,  3.        ],\n",
            "        [ 0.12077525, -0.05689837, -0.05620532, ...,  0.3735507 ,\n",
            "          0.03381396,  3.        ],\n",
            "        ...,\n",
            "        [-0.12683146,  0.06108353,  0.21632512, ...,  0.1138027 ,\n",
            "          0.00755133,  3.        ],\n",
            "        [-0.23839004,  0.05563614,  0.2774904 , ...,  0.08419067,\n",
            "         -0.02841096,  3.        ],\n",
            "        [-0.2899493 ,  0.06238139,  0.27439833, ...,  0.04499366,\n",
            "         -0.02112967,  3.        ]], dtype=float32)\n",
            " array([[-0.01925903, -0.12744778, -0.03088802, ...,  0.03990886,\n",
            "          0.20328124,  3.        ],\n",
            "        [ 0.127582  , -0.03903618, -0.00825775, ...,  0.24940947,\n",
            "          0.10749737,  3.        ],\n",
            "        [ 0.12563173,  0.02184103,  0.00885351, ...,  0.33305135,\n",
            "         -0.03371508,  3.        ],\n",
            "        ...,\n",
            "        [-0.04388094,  0.12168926,  0.20080636, ...,  0.0716681 ,\n",
            "          0.00661241,  3.        ],\n",
            "        [-0.23099287,  0.12551656,  0.3403888 , ...,  0.06673685,\n",
            "         -0.01551225,  3.        ],\n",
            "        [-0.2838517 ,  0.09933632,  0.29749104, ...,  0.04691488,\n",
            "         -0.00567938,  3.        ]], dtype=float32)\n",
            " array([[-0.02519823, -0.12045938, -0.0253285 , ...,  0.03895503,\n",
            "          0.20556624,  3.        ],\n",
            "        [ 0.11626763, -0.02800715,  0.00671152, ...,  0.23042262,\n",
            "          0.10562423,  3.        ],\n",
            "        [ 0.12331982,  0.0389228 ,  0.02603182, ...,  0.2983689 ,\n",
            "         -0.03751331,  3.        ],\n",
            "        ...,\n",
            "        [-0.05109806,  0.14006048,  0.22120431, ...,  0.03409246,\n",
            "          0.01034515,  3.        ],\n",
            "        [-0.23283607,  0.13255158,  0.3623117 , ...,  0.04450805,\n",
            "         -0.01396735,  3.        ],\n",
            "        [-0.28528622,  0.10878763,  0.31198227, ...,  0.0376408 ,\n",
            "          0.00440981,  3.        ]], dtype=float32)\n",
            " array([[-2.0449586e-02, -1.2689969e-01, -2.8222021e-02, ...,\n",
            "          4.4398163e-02,  2.1522272e-01,  3.0000000e+00],\n",
            "        [ 1.3947648e-01, -3.7686177e-02,  2.2645164e-03, ...,\n",
            "          2.1393241e-01,  1.3094868e-01,  3.0000000e+00],\n",
            "        [ 1.2443437e-01,  1.9758968e-02,  2.3166625e-02, ...,\n",
            "          2.9274905e-01, -1.2103058e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-1.0557750e-01,  1.7179322e-01,  2.5142941e-01, ...,\n",
            "          3.8061589e-02,  2.1945087e-03,  3.0000000e+00],\n",
            "        [-2.4670027e-01,  1.4977075e-01,  3.3918509e-01, ...,\n",
            "          4.1720100e-02, -2.0381307e-02,  3.0000000e+00],\n",
            "        [-2.7822948e-01,  1.1068169e-01,  2.9885671e-01, ...,\n",
            "          5.8028780e-02, -3.9690128e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.02555769, -0.13263996, -0.02736862, ...,  0.04731269,\n",
            "          0.20729354,  3.        ],\n",
            "        [ 0.12528414, -0.06065865, -0.01244512, ...,  0.26471704,\n",
            "          0.12874267,  3.        ],\n",
            "        [ 0.10879354, -0.02655595, -0.00373648, ...,  0.35536242,\n",
            "          0.01025801,  3.        ],\n",
            "        ...,\n",
            "        [-0.12168068,  0.12114187,  0.24588329, ...,  0.09150527,\n",
            "         -0.01160036,  3.        ],\n",
            "        [-0.25153992,  0.11458337,  0.32982242, ...,  0.07373212,\n",
            "         -0.03720096,  3.        ],\n",
            "        [-0.29813656,  0.09127757,  0.29679662, ...,  0.04470073,\n",
            "         -0.01390291,  3.        ]], dtype=float32)\n",
            " array([[-0.03362947, -0.15376644, -0.05640186, ...,  0.05913611,\n",
            "          0.2045425 ,  3.        ],\n",
            "        [ 0.12828933, -0.11726185, -0.06647032, ...,  0.27790388,\n",
            "          0.1592412 ,  3.        ],\n",
            "        [ 0.06573184, -0.11539228, -0.06871335, ...,  0.37942174,\n",
            "          0.08529825,  3.        ],\n",
            "        ...,\n",
            "        [-0.1939595 ,  0.02755469,  0.19977269, ...,  0.08950487,\n",
            "         -0.04503879,  3.        ],\n",
            "        [-0.2639887 ,  0.04841029,  0.20484604, ...,  0.07776015,\n",
            "         -0.07302109,  3.        ],\n",
            "        [-0.26600567,  0.03027704,  0.23795924, ...,  0.01936577,\n",
            "         -0.03815295,  3.        ]], dtype=float32)\n",
            " array([[-2.4392754e-02, -1.2508173e-01, -2.5923617e-02, ...,\n",
            "          3.9791074e-02,  2.0784183e-01,  3.0000000e+00],\n",
            "        [ 1.1387167e-01, -4.1585874e-02,  3.0874293e-03, ...,\n",
            "          2.3292781e-01,  1.1651346e-01,  3.0000000e+00],\n",
            "        [ 1.1703575e-01,  1.8335726e-02,  2.3664627e-02, ...,\n",
            "          3.0824995e-01, -2.8994910e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-7.7524185e-02,  1.4125732e-01,  2.4060529e-01, ...,\n",
            "          5.2111257e-02, -1.9819529e-03,  3.0000000e+00],\n",
            "        [-2.4402855e-01,  1.3789466e-01,  3.5878879e-01, ...,\n",
            "          5.2705698e-02, -2.2693720e-02,  3.0000000e+00],\n",
            "        [-2.9393789e-01,  1.0249141e-01,  3.1130084e-01, ...,\n",
            "          4.0661961e-02, -2.3230405e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.028498  , -0.15419829, -0.05879167, ...,  0.05837439,\n",
            "          0.19922374,  3.        ],\n",
            "        [ 0.1290421 , -0.12349773, -0.06695905, ...,  0.26962268,\n",
            "          0.16066967,  3.        ],\n",
            "        [ 0.06662861, -0.12070934, -0.07141157, ...,  0.3698383 ,\n",
            "          0.09282012,  3.        ],\n",
            "        ...,\n",
            "        [-0.20333561,  0.03060527,  0.18648244, ...,  0.07424344,\n",
            "         -0.06290764,  3.        ],\n",
            "        [-0.261393  ,  0.0444745 ,  0.19942284, ...,  0.06783518,\n",
            "         -0.07597727,  3.        ],\n",
            "        [-0.2542556 ,  0.02625888,  0.23295243, ...,  0.01013871,\n",
            "         -0.04559561,  3.        ]], dtype=float32)\n",
            " array([[-3.03216875e-02, -1.30306289e-01, -3.54777090e-02, ...,\n",
            "          5.33149540e-02,  2.09034920e-01,  3.00000000e+00],\n",
            "        [ 1.38371065e-01, -6.64667562e-02, -4.55721468e-02, ...,\n",
            "          2.70170927e-01,  1.40725434e-01,  3.00000000e+00],\n",
            "        [ 1.17907077e-01, -4.30361219e-02, -4.47542779e-02, ...,\n",
            "          3.64672542e-01,  2.45250985e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.40653118e-01,  7.75505230e-02,  2.24704549e-01, ...,\n",
            "          1.13575324e-01,  2.67466158e-03,  3.00000000e+00],\n",
            "        [-2.52688289e-01,  7.08203986e-02,  2.87976652e-01, ...,\n",
            "          8.17388445e-02, -3.26835513e-02,  3.00000000e+00],\n",
            "        [-2.96363592e-01,  6.42918572e-02,  2.80743450e-01, ...,\n",
            "          4.48924489e-02, -2.58725528e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03301723, -0.14124285, -0.03769327, ...,  0.05421724,\n",
            "          0.21317172,  3.        ],\n",
            "        [ 0.14172933, -0.08223649, -0.05872727, ...,  0.2857487 ,\n",
            "          0.15076856,  3.        ],\n",
            "        [ 0.10479569, -0.06984753, -0.06396817, ...,  0.380451  ,\n",
            "          0.05102573,  3.        ],\n",
            "        ...,\n",
            "        [-0.13455117,  0.04088826,  0.21744034, ...,  0.11444053,\n",
            "          0.01921972,  3.        ],\n",
            "        [-0.2444732 ,  0.03897492,  0.27434814, ...,  0.08630218,\n",
            "         -0.02692552,  3.        ],\n",
            "        [-0.29422766,  0.04984508,  0.27318624, ...,  0.03996495,\n",
            "         -0.01911757,  3.        ]], dtype=float32)\n",
            " array([[-0.02247781, -0.1272444 , -0.02728319, ...,  0.03861277,\n",
            "          0.20622061,  3.        ],\n",
            "        [ 0.1186611 , -0.04083417, -0.00322415, ...,  0.24394691,\n",
            "          0.11346979,  3.        ],\n",
            "        [ 0.11862006,  0.02110849,  0.01342061, ...,  0.3233315 ,\n",
            "         -0.02425218,  3.        ],\n",
            "        ...,\n",
            "        [-0.07145763,  0.13366704,  0.22864467, ...,  0.07571004,\n",
            "         -0.00534579,  3.        ],\n",
            "        [-0.24130529,  0.13212104,  0.35787204, ...,  0.06018023,\n",
            "         -0.02618129,  3.        ],\n",
            "        [-0.29635423,  0.09324899,  0.31031212, ...,  0.04560291,\n",
            "         -0.01651254,  3.        ]], dtype=float32)\n",
            " array([[-1.8680794e-02, -1.1690225e-01, -3.3126298e-02, ...,\n",
            "          3.9417803e-02,  2.0390545e-01,  3.0000000e+00],\n",
            "        [ 1.2300075e-01, -2.8095298e-02, -7.9889745e-03, ...,\n",
            "          2.3766041e-01,  9.3032949e-02,  3.0000000e+00],\n",
            "        [ 1.3051842e-01,  3.8599860e-02,  9.8239407e-03, ...,\n",
            "          3.0652505e-01, -5.4359220e-02,  3.0000000e+00],\n",
            "        ...,\n",
            "        [-6.7725866e-03,  1.3253108e-01,  1.6696091e-01, ...,\n",
            "          4.6570390e-02,  2.9175403e-02,  3.0000000e+00],\n",
            "        [-2.1172790e-01,  1.3423991e-01,  3.3067772e-01, ...,\n",
            "          6.7435890e-02, -3.9693331e-03,  3.0000000e+00],\n",
            "        [-2.7348682e-01,  1.0398811e-01,  2.9796073e-01, ...,\n",
            "          4.3195453e-02,  2.4692379e-03,  3.0000000e+00]], dtype=float32)\n",
            " array([[-0.03289485, -0.14047565, -0.03550848, ...,  0.04881483,\n",
            "          0.21098834,  3.        ],\n",
            "        [ 0.13077506, -0.07804935, -0.04944213, ...,  0.2667449 ,\n",
            "          0.15325445,  3.        ],\n",
            "        [ 0.09546348, -0.06572847, -0.0546941 , ...,  0.35809442,\n",
            "          0.05536297,  3.        ],\n",
            "        ...,\n",
            "        [-0.14752364,  0.05894036,  0.22682154, ...,  0.11869982,\n",
            "          0.01961927,  3.        ],\n",
            "        [-0.26047137,  0.05191864,  0.2880768 , ...,  0.08561406,\n",
            "         -0.02954367,  3.        ],\n",
            "        [-0.29982534,  0.05164141,  0.28290144, ...,  0.03901129,\n",
            "         -0.02663822,  3.        ]], dtype=float32)\n",
            " array([[-0.03433557, -0.14525774, -0.04176388, ...,  0.05301389,\n",
            "          0.21122329,  3.        ],\n",
            "        [ 0.13844323, -0.08787591, -0.05191284, ...,  0.28092274,\n",
            "          0.15487924,  3.        ],\n",
            "        [ 0.10077835, -0.08889294, -0.05818406, ...,  0.36878455,\n",
            "          0.08285046,  3.        ],\n",
            "        ...,\n",
            "        [-0.15722579,  0.03922691,  0.23007238, ...,  0.10769355,\n",
            "          0.00726832,  3.        ],\n",
            "        [-0.2592087 ,  0.03865242,  0.26881438, ...,  0.08420585,\n",
            "         -0.03823658,  3.        ],\n",
            "        [-0.2943581 ,  0.04575617,  0.2726816 , ...,  0.02878365,\n",
            "         -0.01742147,  3.        ]], dtype=float32)\n",
            " array([[-2.97363065e-02, -1.26362845e-01, -2.83826906e-02, ...,\n",
            "          4.97488044e-02,  2.05043748e-01,  3.00000000e+00],\n",
            "        [ 1.27277598e-01, -5.80538400e-02, -1.85732748e-02, ...,\n",
            "          2.49365494e-01,  1.34030864e-01,  3.00000000e+00],\n",
            "        [ 1.13927856e-01, -2.27955077e-02, -2.41766777e-03, ...,\n",
            "          3.41882050e-01,  9.10661463e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.54845580e-01,  1.30735174e-01,  2.66058505e-01, ...,\n",
            "          8.11136961e-02, -1.80446208e-02,  3.00000000e+00],\n",
            "        [-2.66025782e-01,  1.19429164e-01,  3.28107417e-01, ...,\n",
            "          7.11689964e-02, -4.00965102e-02,  3.00000000e+00],\n",
            "        [-3.03884864e-01,  9.39076468e-02,  2.98704237e-01, ...,\n",
            "          4.35755365e-02, -1.60592403e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.21533943e-02, -1.36213526e-01, -3.00319102e-02, ...,\n",
            "          5.09565212e-02,  2.11979270e-01,  3.00000000e+00],\n",
            "        [ 1.37591720e-01, -5.06297983e-02, -1.24618588e-02, ...,\n",
            "          2.62795746e-01,  1.32620618e-01,  3.00000000e+00],\n",
            "        [ 1.25265062e-01, -1.15601914e-02,  7.58244051e-03, ...,\n",
            "          3.49040449e-01,  2.89605674e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.14632756e-01,  1.19941026e-01,  2.35777274e-01, ...,\n",
            "          8.41756687e-02, -1.51085947e-02,  3.00000000e+00],\n",
            "        [-2.41587207e-01,  1.10244095e-01,  3.15542072e-01, ...,\n",
            "          7.05058053e-02, -3.49102020e-02,  3.00000000e+00],\n",
            "        [-2.89474279e-01,  9.13708583e-02,  2.87259400e-01, ...,\n",
            "          5.21364547e-02, -1.16924932e-02,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.67581418e-02, -1.21440202e-01, -2.49756575e-02, ...,\n",
            "          3.93147394e-02,  2.04748601e-01,  3.00000000e+00],\n",
            "        [ 1.15014747e-01, -3.06657366e-02,  6.74786558e-03, ...,\n",
            "          2.31879294e-01,  1.05347365e-01,  3.00000000e+00],\n",
            "        [ 1.24105804e-01,  3.51750478e-02,  2.53514741e-02, ...,\n",
            "          2.99193501e-01, -3.89328115e-02,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-7.14134648e-02,  1.43170312e-01,  2.35238120e-01, ...,\n",
            "          4.07922529e-02, -9.67199728e-03,  3.00000000e+00],\n",
            "        [-2.40943119e-01,  1.37035459e-01,  3.63358200e-01, ...,\n",
            "          4.20625359e-02, -2.50094775e-02,  3.00000000e+00],\n",
            "        [-2.89182425e-01,  1.11364856e-01,  3.14483434e-01, ...,\n",
            "          3.81374396e-02,  2.55997921e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-2.35543288e-02, -1.31975278e-01, -2.46849153e-02, ...,\n",
            "          4.77378480e-02,  2.15225175e-01,  3.00000000e+00],\n",
            "        [ 1.41693354e-01, -4.81317043e-02,  6.31323375e-04, ...,\n",
            "          2.25864768e-01,  1.39583558e-01,  3.00000000e+00],\n",
            "        [ 1.26063243e-01,  2.74516083e-03,  2.67648511e-02, ...,\n",
            "          3.04507166e-01,  3.26262927e-03,  3.00000000e+00],\n",
            "        ...,\n",
            "        [-1.38684332e-01,  1.56768918e-01,  2.75530934e-01, ...,\n",
            "          4.38753776e-02, -7.56388763e-03,  3.00000000e+00],\n",
            "        [-2.53164232e-01,  1.36028081e-01,  3.40771854e-01, ...,\n",
            "          4.85246964e-02, -2.94402447e-02,  3.00000000e+00],\n",
            "        [-2.86562532e-01,  1.00234166e-01,  3.01202536e-01, ...,\n",
            "          5.53612895e-02, -7.39185419e-03,  3.00000000e+00]], dtype=float32)\n",
            " array([[-0.03318226, -0.12428118, -0.03289997, ...,  0.05473684,\n",
            "          0.2059398 ,  3.        ],\n",
            "        [ 0.12545288, -0.06610136, -0.03172934, ...,  0.25735855,\n",
            "          0.13586645,  3.        ],\n",
            "        [ 0.10748557, -0.03764403, -0.02670796, ...,  0.35353002,\n",
            "          0.01861953,  3.        ],\n",
            "        ...,\n",
            "        [-0.15260203,  0.10905447,  0.25415537, ...,  0.09767395,\n",
            "         -0.01631712,  3.        ],\n",
            "        [-0.26908383,  0.09679084,  0.31357616, ...,  0.07756452,\n",
            "         -0.04195781,  3.        ],\n",
            "        [-0.30375645,  0.08925492,  0.28886855, ...,  0.03499823,\n",
            "         -0.01862727,  3.        ]], dtype=float32)\n",
            " array([[-0.03426046, -0.14182542, -0.0373667 , ...,  0.05306241,\n",
            "          0.21306357,  3.        ],\n",
            "        [ 0.13675353, -0.08135054, -0.06079144, ...,  0.2795295 ,\n",
            "          0.15415582,  3.        ],\n",
            "        [ 0.09841625, -0.06949996, -0.06701523, ...,  0.37279993,\n",
            "          0.0554956 ,  3.        ],\n",
            "        ...,\n",
            "        [-0.15639968,  0.05393057,  0.23090371, ...,  0.1064449 ,\n",
            "          0.01371162,  3.        ],\n",
            "        [-0.25472888,  0.04474672,  0.2792923 , ...,  0.08073712,\n",
            "         -0.02719326,  3.        ],\n",
            "        [-0.29606238,  0.04251522,  0.27848172, ...,  0.04183786,\n",
            "         -0.024819  ,  3.        ]], dtype=float32)\n",
            " array([[ 0.00700776, -0.12121573, -0.05871829, ...,  0.03356439,\n",
            "          0.21336672,  0.        ],\n",
            "        [ 0.18571138, -0.04118263, -0.04469114, ...,  0.2210579 ,\n",
            "          0.05417602,  0.        ],\n",
            "        [ 0.18000317, -0.00125242, -0.04133356, ...,  0.29708508,\n",
            "         -0.08696516,  0.        ],\n",
            "        ...,\n",
            "        [ 0.07777606,  0.06910094,  0.09142654, ...,  0.03532757,\n",
            "          0.0287128 ,  0.        ],\n",
            "        [-0.13904798,  0.11524429,  0.2905913 , ...,  0.08736969,\n",
            "         -0.01900087,  0.        ],\n",
            "        [-0.2609551 ,  0.07806277,  0.2946515 , ...,  0.06132105,\n",
            "         -0.00493658,  0.        ]], dtype=float32)\n",
            " array([[ 0.08595707, -0.23312205, -0.14493944, ..., -0.06838554,\n",
            "          0.18181396,  0.        ],\n",
            "        [ 0.28632918, -0.04014616, -0.02836472, ..., -0.07929841,\n",
            "          0.07304562,  0.        ],\n",
            "        [ 0.30915272, -0.02817737, -0.03478722, ..., -0.02569295,\n",
            "          0.0682711 ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.19626613, -0.05924244, -0.0743014 , ..., -0.02442066,\n",
            "          0.12734285,  0.        ],\n",
            "        [ 0.11356533, -0.02568173,  0.06372359, ...,  0.01211534,\n",
            "          0.08248486,  0.        ],\n",
            "        [-0.05945825, -0.04609872,  0.2553727 , ..., -0.07044718,\n",
            "          0.0858706 ,  0.        ]], dtype=float32)\n",
            " array([[ 0.07289682, -0.22845222, -0.14107901, ..., -0.04744861,\n",
            "          0.18507272,  0.        ],\n",
            "        [ 0.28422222, -0.02979705, -0.02982678, ..., -0.05636571,\n",
            "          0.05259674,  0.        ],\n",
            "        [ 0.306784  , -0.01106142, -0.03470717, ...,  0.00690364,\n",
            "          0.0416738 ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.17854084, -0.02962622, -0.06645937, ...,  0.02042201,\n",
            "          0.09780551,  0.        ],\n",
            "        [ 0.08361496, -0.00356203,  0.0769877 , ...,  0.0496488 ,\n",
            "          0.05145945,  0.        ],\n",
            "        [-0.08012842, -0.0267734 ,  0.26631895, ..., -0.03692845,\n",
            "          0.06636737,  0.        ]], dtype=float32)\n",
            " array([[-0.03107671, -0.13879432, -0.0333649 , ...,  0.05745723,\n",
            "          0.21580277,  0.        ],\n",
            "        [ 0.1614718 , -0.06963866, -0.03534304, ...,  0.2866488 ,\n",
            "          0.14646679,  0.        ],\n",
            "        [ 0.1297539 , -0.05061828, -0.02888763, ...,  0.3717757 ,\n",
            "          0.04333708,  0.        ],\n",
            "        ...,\n",
            "        [-0.16282448,  0.06547268,  0.259168  , ...,  0.08869693,\n",
            "         -0.01747047,  0.        ],\n",
            "        [-0.24507433,  0.06147865,  0.2786925 , ...,  0.08054449,\n",
            "         -0.04530066,  0.        ],\n",
            "        [-0.27790397,  0.06669767,  0.27864602, ...,  0.04890203,\n",
            "         -0.01577399,  0.        ]], dtype=float32)\n",
            " array([[ 0.01423795, -0.125876  , -0.05544511, ...,  0.04490371,\n",
            "          0.20629874,  0.        ],\n",
            "        [ 0.18561912, -0.02227423, -0.05405591, ...,  0.2444727 ,\n",
            "          0.05394505,  0.        ],\n",
            "        [ 0.20049362,  0.0297375 , -0.04581936, ...,  0.31367856,\n",
            "         -0.08548922,  0.        ],\n",
            "        ...,\n",
            "        [ 0.08367088,  0.07320598,  0.05639931, ...,  0.05990593,\n",
            "          0.06234261,  0.        ],\n",
            "        [-0.12040646,  0.10716955,  0.25449634, ...,  0.08450714,\n",
            "          0.00434452,  0.        ],\n",
            "        [-0.23015435,  0.0862987 ,  0.26311   , ...,  0.06760325,\n",
            "         -0.00178171,  0.        ]], dtype=float32)\n",
            " array([[-0.00239799, -0.11119966, -0.04400679, ...,  0.03567756,\n",
            "          0.20976222,  0.        ],\n",
            "        [ 0.14034936, -0.01325057, -0.01200681, ...,  0.2222846 ,\n",
            "          0.0962994 ,  0.        ],\n",
            "        [ 0.14929809,  0.05038144,  0.00260373, ...,  0.29672062,\n",
            "         -0.05944657,  0.        ],\n",
            "        ...,\n",
            "        [-0.01836327,  0.14586736,  0.17447554, ...,  0.04811743,\n",
            "          0.01943028,  0.        ],\n",
            "        [-0.20594275,  0.1391396 ,  0.32520536, ...,  0.06821351,\n",
            "         -0.00531773,  0.        ],\n",
            "        [-0.2702017 ,  0.09773653,  0.2983055 , ...,  0.05050671,\n",
            "         -0.00392533,  0.        ]], dtype=float32)\n",
            " array([[-0.0129716 , -0.11721952, -0.03457525, ...,  0.0327548 ,\n",
            "          0.21043876,  0.        ],\n",
            "        [ 0.12663497, -0.02308875, -0.00454935, ...,  0.21690068,\n",
            "          0.11115938,  0.        ],\n",
            "        [ 0.13484977,  0.04635597,  0.01715114, ...,  0.28943983,\n",
            "         -0.04029023,  0.        ],\n",
            "        ...,\n",
            "        [-0.05853937,  0.14315024,  0.21230474, ...,  0.03967139,\n",
            "          0.01414806,  0.        ],\n",
            "        [-0.22289322,  0.14009143,  0.33777016, ...,  0.04783829,\n",
            "         -0.00513622,  0.        ],\n",
            "        [-0.27729306,  0.10055221,  0.30201548, ...,  0.03975596,\n",
            "          0.00258473,  0.        ]], dtype=float32)\n",
            " array([[-0.01854729, -0.12225518, -0.02751272, ...,  0.04129184,\n",
            "          0.20879617,  0.        ],\n",
            "        [ 0.13876362, -0.02041528,  0.00110184, ...,  0.24636759,\n",
            "          0.11122636,  0.        ],\n",
            "        [ 0.1435407 ,  0.04532254,  0.02052077, ...,  0.3169176 ,\n",
            "         -0.03180885,  0.        ],\n",
            "        ...,\n",
            "        [-0.0272238 ,  0.12659901,  0.20000328, ...,  0.05231021,\n",
            "          0.0186674 ,  0.        ],\n",
            "        [-0.21972969,  0.12477769,  0.3502508 , ...,  0.05936915,\n",
            "         -0.00905785,  0.        ],\n",
            "        [-0.27564576,  0.10462592,  0.3056949 , ...,  0.04821517,\n",
            "          0.0018248 ,  0.        ]], dtype=float32)\n",
            " array([[-0.01897302, -0.11899512, -0.03120206, ...,  0.03336735,\n",
            "          0.21324699,  0.        ],\n",
            "        [ 0.12031863, -0.02948083,  0.00744416, ...,  0.22098418,\n",
            "          0.12304716,  0.        ],\n",
            "        [ 0.12595662,  0.03729669,  0.02389764, ...,  0.29041728,\n",
            "         -0.01684641,  0.        ],\n",
            "        ...,\n",
            "        [-0.10902888,  0.16098017,  0.26449272, ...,  0.04639117,\n",
            "          0.00964129,  0.        ],\n",
            "        [-0.23633036,  0.14463763,  0.3455725 , ...,  0.04898103,\n",
            "         -0.01128866,  0.        ],\n",
            "        [-0.28395924,  0.10169097,  0.30264294, ...,  0.04027208,\n",
            "          0.00418518,  0.        ]], dtype=float32)\n",
            " array([[-0.02651502, -0.13321488, -0.02518403, ...,  0.04839493,\n",
            "          0.21515243,  0.        ],\n",
            "        [ 0.14138553, -0.05168042,  0.00054465, ...,  0.25329322,\n",
            "          0.13475482,  0.        ],\n",
            "        [ 0.13127229, -0.01634031,  0.02583261, ...,  0.33070305,\n",
            "          0.01340459,  0.        ],\n",
            "        ...,\n",
            "        [-0.16612671,  0.13853051,  0.2946253 , ...,  0.06826221,\n",
            "         -0.03156554,  0.        ],\n",
            "        [-0.25257015,  0.11847751,  0.3346365 , ...,  0.06622726,\n",
            "         -0.04140575,  0.        ],\n",
            "        [-0.28831825,  0.09364548,  0.30098715, ...,  0.05221   ,\n",
            "         -0.01559851,  0.        ]], dtype=float32)\n",
            " array([[-0.01796262, -0.11997711, -0.03149888, ...,  0.04455241,\n",
            "          0.217802  ,  0.        ],\n",
            "        [ 0.13130224, -0.0394071 ,  0.00351103, ...,  0.23581171,\n",
            "          0.12196733,  0.        ],\n",
            "        [ 0.13092428,  0.01324699,  0.02291025, ...,  0.3054763 ,\n",
            "         -0.02856299,  0.        ],\n",
            "        ...,\n",
            "        [-0.06180875,  0.16260958,  0.22695297, ...,  0.04894011,\n",
            "          0.00387718,  0.        ],\n",
            "        [-0.22236754,  0.1446107 ,  0.33835292, ...,  0.06420287,\n",
            "         -0.01171713,  0.        ],\n",
            "        [-0.27392364,  0.10466035,  0.30189914, ...,  0.06167626,\n",
            "          0.00062515,  0.        ]], dtype=float32)\n",
            " array([[-0.03520855, -0.14937402, -0.04641925, ...,  0.06199359,\n",
            "          0.21346456,  0.        ],\n",
            "        [ 0.14205374, -0.10791991, -0.05826594, ...,  0.2900064 ,\n",
            "          0.16130617,  0.        ],\n",
            "        [ 0.08579351, -0.09941362, -0.05959112, ...,  0.3963629 ,\n",
            "          0.07504549,  0.        ],\n",
            "        ...,\n",
            "        [-0.1879981 ,  0.0212299 ,  0.22481753, ...,  0.09013838,\n",
            "         -0.03880855,  0.        ],\n",
            "        [-0.257501  ,  0.04191131,  0.22577968, ...,  0.07922881,\n",
            "         -0.06203604,  0.        ],\n",
            "        [-0.26756355,  0.02848152,  0.2502776 , ...,  0.03038331,\n",
            "         -0.0303649 ,  0.        ]], dtype=float32)\n",
            " array([[-0.02178062, -0.12349201, -0.02822817, ...,  0.04391631,\n",
            "          0.21665014,  0.        ],\n",
            "        [ 0.12890796, -0.03995658,  0.01115008, ...,  0.24075961,\n",
            "          0.12812886,  0.        ],\n",
            "        [ 0.13016273,  0.01197955,  0.03243918, ...,  0.31121635,\n",
            "         -0.01352415,  0.        ],\n",
            "        ...,\n",
            "        [-0.11147489,  0.15889668,  0.27006885, ...,  0.06099642,\n",
            "         -0.00894056,  0.        ],\n",
            "        [-0.23823398,  0.14406872,  0.35239372, ...,  0.05990027,\n",
            "         -0.02219316,  0.        ],\n",
            "        [-0.28485703,  0.10090395,  0.30912447, ...,  0.05520811,\n",
            "         -0.00401351,  0.        ]], dtype=float32)\n",
            " array([[-0.01989863, -0.12175855, -0.02707812, ...,  0.04333493,\n",
            "          0.21649009,  0.        ],\n",
            "        [ 0.13153823, -0.03966597,  0.01053306, ...,  0.23768292,\n",
            "          0.12727034,  0.        ],\n",
            "        [ 0.1316012 ,  0.01440022,  0.03272696, ...,  0.30803594,\n",
            "         -0.0158307 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.09948809,  0.16063532,  0.26218265, ...,  0.05768604,\n",
            "         -0.00362517,  0.        ],\n",
            "        [-0.23338854,  0.14482565,  0.3496999 , ...,  0.05997318,\n",
            "         -0.01759627,  0.        ],\n",
            "        [-0.28242728,  0.10229842,  0.30860054, ...,  0.05681218,\n",
            "         -0.00327985,  0.        ]], dtype=float32)\n",
            " array([[-0.01281137, -0.11580611, -0.03695689, ...,  0.03308528,\n",
            "          0.21316779,  0.        ],\n",
            "        [ 0.12697658, -0.02081649, -0.00600018, ...,  0.21528114,\n",
            "          0.10997511,  0.        ],\n",
            "        [ 0.14081657,  0.04821046,  0.0127063 , ...,  0.28491256,\n",
            "         -0.04412734,  0.        ],\n",
            "        ...,\n",
            "        [-0.06727462,  0.13948439,  0.21726385, ...,  0.03912292,\n",
            "          0.01897736,  0.        ],\n",
            "        [-0.22510713,  0.13580032,  0.34022093, ...,  0.05317011,\n",
            "         -0.00066438,  0.        ],\n",
            "        [-0.2780708 ,  0.10059238,  0.3049223 , ...,  0.04407717,\n",
            "          0.00615351,  0.        ]], dtype=float32)\n",
            " array([[-2.2442510e-02, -1.2903531e-01, -2.6324516e-02, ...,\n",
            "          4.0578406e-02,  2.1094655e-01,  0.0000000e+00],\n",
            "        [ 1.2964475e-01, -4.6844620e-02,  4.3933713e-03, ...,\n",
            "          2.4596545e-01,  1.2798679e-01,  0.0000000e+00],\n",
            "        [ 1.2301912e-01,  2.4515104e-03,  2.2316417e-02, ...,\n",
            "          3.2389203e-01,  1.0386261e-04,  0.0000000e+00],\n",
            "        ...,\n",
            "        [-1.5631379e-01,  1.3721158e-01,  2.9257053e-01, ...,\n",
            "          6.4346381e-02, -2.0815974e-02,  0.0000000e+00],\n",
            "        [-2.4934967e-01,  1.2404465e-01,  3.4922838e-01, ...,\n",
            "          5.8915451e-02, -3.3643749e-02,  0.0000000e+00],\n",
            "        [-2.9301873e-01,  9.3219012e-02,  3.0492657e-01, ...,\n",
            "          4.4513304e-02, -9.1418810e-03,  0.0000000e+00]], dtype=float32)\n",
            " array([[-0.01563243, -0.14896576, -0.06196394, ...,  0.04433407,\n",
            "          0.1765436 ,  0.        ],\n",
            "        [ 0.10708813, -0.12592931, -0.04688784, ...,  0.2185461 ,\n",
            "          0.15168668,  0.        ],\n",
            "        [ 0.04318253, -0.12784955, -0.06714623, ...,  0.3039874 ,\n",
            "          0.10445117,  0.        ],\n",
            "        ...,\n",
            "        [-0.21328829,  0.0437242 ,  0.24368207, ..., -0.05386687,\n",
            "         -0.09188013,  0.        ],\n",
            "        [-0.25050244,  0.06942098,  0.24456722, ..., -0.04661823,\n",
            "         -0.08765585,  0.        ],\n",
            "        [-0.19485046,  0.06826374,  0.24958554, ..., -0.04881395,\n",
            "         -0.06852582,  0.        ]], dtype=float32)\n",
            " array([[-0.02117808, -0.13539055, -0.03003146, ...,  0.04399785,\n",
            "          0.21467312,  0.        ],\n",
            "        [ 0.14091891, -0.05241654, -0.01049233, ...,  0.25894552,\n",
            "          0.13809133,  0.        ],\n",
            "        [ 0.125844  , -0.0103035 ,  0.00638552, ...,  0.34637666,\n",
            "          0.01433089,  0.        ],\n",
            "        ...,\n",
            "        [-0.15166917,  0.11429839,  0.27157527, ...,  0.06858534,\n",
            "         -0.01539502,  0.        ],\n",
            "        [-0.23804408,  0.09752465,  0.31478882, ...,  0.06403873,\n",
            "         -0.03036517,  0.        ],\n",
            "        [-0.28831044,  0.08034384,  0.2925347 , ...,  0.05192298,\n",
            "         -0.01518079,  0.        ]], dtype=float32)\n",
            " array([[-0.03269628, -0.1523476 , -0.05342713, ...,  0.05734465,\n",
            "          0.1984477 ,  0.        ],\n",
            "        [ 0.12343641, -0.11880431, -0.05618287, ...,  0.27019686,\n",
            "          0.15407152,  0.        ],\n",
            "        [ 0.06130984, -0.1151919 , -0.0626648 , ...,  0.36458775,\n",
            "          0.08819509,  0.        ],\n",
            "        ...,\n",
            "        [-0.228248  ,  0.03135698,  0.20598012, ...,  0.07019059,\n",
            "         -0.07067849,  0.        ],\n",
            "        [-0.27303565,  0.04446249,  0.20521612, ...,  0.05899594,\n",
            "         -0.07268396,  0.        ],\n",
            "        [-0.25775036,  0.02808254,  0.23750791, ...,  0.0101392 ,\n",
            "         -0.04316011,  0.        ]], dtype=float32)\n",
            " array([[-0.03404633, -0.14837405, -0.0440188 , ...,  0.05999411,\n",
            "          0.21635237,  0.        ],\n",
            "        [ 0.1502852 , -0.10079339, -0.05685059, ...,  0.29284832,\n",
            "          0.160225  ,  0.        ],\n",
            "        [ 0.09793992, -0.09526335, -0.05700818, ...,  0.39537838,\n",
            "          0.06958088,  0.        ],\n",
            "        ...,\n",
            "        [-0.16963637,  0.01762548,  0.23320866, ...,  0.09303424,\n",
            "         -0.02443999,  0.        ],\n",
            "        [-0.24680196,  0.03188864,  0.23758492, ...,  0.08069824,\n",
            "         -0.04825743,  0.        ],\n",
            "        [-0.2695033 ,  0.03018944,  0.25763184, ...,  0.03533448,\n",
            "         -0.02033475,  0.        ]], dtype=float32)\n",
            " array([[-0.03181817, -0.14980905, -0.04539027, ...,  0.05354472,\n",
            "          0.21482334,  0.        ],\n",
            "        [ 0.14756034, -0.0942928 , -0.05446149, ...,  0.2815698 ,\n",
            "          0.16376914,  0.        ],\n",
            "        [ 0.10111335, -0.09647407, -0.05546547, ...,  0.37257937,\n",
            "          0.09176812,  0.        ],\n",
            "        ...,\n",
            "        [-0.17158817,  0.00987944,  0.23523606, ...,  0.09119883,\n",
            "         -0.01414114,  0.        ],\n",
            "        [-0.24640915,  0.01641795,  0.24228194, ...,  0.07489064,\n",
            "         -0.03907545,  0.        ],\n",
            "        [-0.27357292,  0.02470393,  0.25785023, ...,  0.03031776,\n",
            "         -0.01971029,  0.        ]], dtype=float32)\n",
            " array([[-0.03199786, -0.14419016, -0.03460344, ...,  0.05676548,\n",
            "          0.2167252 ,  0.        ],\n",
            "        [ 0.16046442, -0.08068898, -0.04252719, ...,  0.2887151 ,\n",
            "          0.15475422,  0.        ],\n",
            "        [ 0.11994702, -0.06711959, -0.03623417, ...,  0.3762595 ,\n",
            "          0.05764559,  0.        ],\n",
            "        ...,\n",
            "        [-0.16500796,  0.04717785,  0.25669172, ...,  0.09410133,\n",
            "         -0.01083357,  0.        ],\n",
            "        [-0.2454307 ,  0.04804774,  0.27138135, ...,  0.08244712,\n",
            "         -0.04194995,  0.        ],\n",
            "        [-0.2778272 ,  0.0537347 ,  0.2751551 , ...,  0.04444867,\n",
            "         -0.01474025,  0.        ]], dtype=float32)\n",
            " array([[-0.0299832 , -0.14719859, -0.03670896, ...,  0.05691534,\n",
            "          0.21761054,  0.        ],\n",
            "        [ 0.16334592, -0.08421469, -0.04615019, ...,  0.2884825 ,\n",
            "          0.15650658,  0.        ],\n",
            "        [ 0.12342826, -0.07070037, -0.04148072, ...,  0.37689722,\n",
            "          0.05900179,  0.        ],\n",
            "        ...,\n",
            "        [-0.15460153,  0.04114982,  0.24569368, ...,  0.09539972,\n",
            "         -0.00708325,  0.        ],\n",
            "        [-0.2393252 ,  0.04531015,  0.2647098 , ...,  0.08289431,\n",
            "         -0.0422713 ,  0.        ],\n",
            "        [-0.27365297,  0.04889805,  0.27016824, ...,  0.04413146,\n",
            "         -0.01741828,  0.        ]], dtype=float32)\n",
            " array([[ 0.00294079, -0.11630236, -0.05487924, ...,  0.03617575,\n",
            "          0.21374367,  0.        ],\n",
            "        [ 0.17211212, -0.03032354, -0.03833764, ...,  0.22148089,\n",
            "          0.06600448,  0.        ],\n",
            "        [ 0.16864656,  0.0094181 , -0.03095239, ...,  0.2987749 ,\n",
            "         -0.07926787,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05757063,  0.09502742,  0.10430934, ...,  0.03007408,\n",
            "          0.03188233,  0.        ],\n",
            "        [-0.15533924,  0.12849993,  0.29820034, ...,  0.08100796,\n",
            "         -0.01232501,  0.        ],\n",
            "        [-0.26026058,  0.08583178,  0.2936247 , ...,  0.06109864,\n",
            "         -0.00526561,  0.        ]], dtype=float32)\n",
            " array([[-0.02614791, -0.13470623, -0.02557459, ...,  0.04949689,\n",
            "          0.21591263,  0.        ],\n",
            "        [ 0.14291015, -0.05377688, -0.00213061, ...,  0.2601215 ,\n",
            "          0.13476437,  0.        ],\n",
            "        [ 0.13162416, -0.01876141,  0.02222867, ...,  0.33854446,\n",
            "          0.01295562,  0.        ],\n",
            "        ...,\n",
            "        [-0.16128558,  0.13612175,  0.2868905 , ...,  0.07386842,\n",
            "         -0.0324467 ,  0.        ],\n",
            "        [-0.24911603,  0.11569372,  0.3278136 , ...,  0.07131767,\n",
            "         -0.0423323 ,  0.        ],\n",
            "        [-0.28333095,  0.09359588,  0.2956395 , ...,  0.05542029,\n",
            "         -0.01338366,  0.        ]], dtype=float32)\n",
            " array([[ 0.04706921, -0.22415741, -0.09947429, ..., -0.00207951,\n",
            "          0.22040437,  0.        ],\n",
            "        [ 0.28971553, -0.00050687, -0.05886016, ...,  0.02992642,\n",
            "          0.01385524,  0.        ],\n",
            "        [ 0.31303066,  0.03593393, -0.04524604, ...,  0.12687717,\n",
            "         -0.04712591,  0.        ],\n",
            "        ...,\n",
            "        [ 0.1640892 , -0.01208123, -0.03480595, ...,  0.08536299,\n",
            "          0.01547081,  0.        ],\n",
            "        [ 0.00177385,  0.03264407,  0.16856536, ...,  0.10453103,\n",
            "         -0.03328167,  0.        ],\n",
            "        [-0.13859832, -0.00283228,  0.30730623, ...,  0.0252378 ,\n",
            "          0.00032815,  0.        ]], dtype=float32)\n",
            " array([[ 0.01577875, -0.12661345, -0.06538437, ...,  0.02624905,\n",
            "          0.20732385,  0.        ],\n",
            "        [ 0.20074736, -0.05351704, -0.05021961, ...,  0.20597978,\n",
            "          0.04229397,  0.        ],\n",
            "        [ 0.19424254, -0.01805274, -0.0549482 , ...,  0.27509716,\n",
            "         -0.09741077,  0.        ],\n",
            "        ...,\n",
            "        [ 0.10973523,  0.03531104,  0.04953938, ...,  0.03010643,\n",
            "          0.03363124,  0.        ],\n",
            "        [-0.11908273,  0.10232173,  0.27888963, ...,  0.08933111,\n",
            "         -0.02654298,  0.        ],\n",
            "        [-0.2684818 ,  0.0603225 ,  0.29941976, ...,  0.06599744,\n",
            "         -0.00917143,  0.        ]], dtype=float32)\n",
            " array([[-0.03216209, -0.1296964 , -0.03136764, ...,  0.05723714,\n",
            "          0.21424276,  0.        ],\n",
            "        [ 0.15293632, -0.06234903, -0.02895515, ...,  0.27711275,\n",
            "          0.14703377,  0.        ],\n",
            "        [ 0.12536396, -0.03974393, -0.01656764, ...,  0.36339337,\n",
            "          0.04180273,  0.        ],\n",
            "        ...,\n",
            "        [-0.18335621,  0.09652196,  0.2797578 , ...,  0.08941193,\n",
            "         -0.02722211,  0.        ],\n",
            "        [-0.2620388 ,  0.08203074,  0.29959384, ...,  0.08186857,\n",
            "         -0.04793477,  0.        ],\n",
            "        [-0.28987187,  0.07926633,  0.28515914, ...,  0.04580878,\n",
            "         -0.0162863 ,  0.        ]], dtype=float32)\n",
            " array([[-0.03252929, -0.14653902, -0.03912885, ...,  0.05686959,\n",
            "          0.21814488,  0.        ],\n",
            "        [ 0.15633792, -0.0879798 , -0.04863747, ...,  0.28719643,\n",
            "          0.15975724,  0.        ],\n",
            "        [ 0.11385351, -0.0767587 , -0.04458841, ...,  0.37997437,\n",
            "          0.06236141,  0.        ],\n",
            "        ...,\n",
            "        [-0.16513588,  0.03481982,  0.24822329, ...,  0.09496869,\n",
            "         -0.00816665,  0.        ],\n",
            "        [-0.24586824,  0.04219659,  0.2602236 , ...,  0.08379982,\n",
            "         -0.04200682,  0.        ],\n",
            "        [-0.2768834 ,  0.03868607,  0.27102214, ...,  0.04056875,\n",
            "         -0.01912552,  0.        ]], dtype=float32)\n",
            " array([[-0.03225595, -0.15189779, -0.05275625, ...,  0.0615435 ,\n",
            "          0.20472728,  0.        ],\n",
            "        [ 0.13343656, -0.12102518, -0.06125297, ...,  0.27381462,\n",
            "          0.16056713,  0.        ],\n",
            "        [ 0.0685446 , -0.10865562, -0.06153159, ...,  0.38645828,\n",
            "          0.07682343,  0.        ],\n",
            "        ...,\n",
            "        [-0.21262965,  0.03053051,  0.19967051, ...,  0.07113218,\n",
            "         -0.06408305,  0.        ],\n",
            "        [-0.2659064 ,  0.05513232,  0.20974278, ...,  0.06612802,\n",
            "         -0.0745932 ,  0.        ],\n",
            "        [-0.25519907,  0.02614085,  0.24252085, ...,  0.02072054,\n",
            "         -0.04287419,  0.        ]], dtype=float32)\n",
            " array([[-0.02365012, -0.13204715, -0.0260233 , ...,  0.04270522,\n",
            "          0.21224017,  0.        ],\n",
            "        [ 0.12802154, -0.05164709,  0.00526692, ...,  0.2487292 ,\n",
            "          0.13385014,  0.        ],\n",
            "        [ 0.11772675, -0.00993063,  0.0180153 , ...,  0.32648218,\n",
            "          0.01358125,  0.        ],\n",
            "        ...,\n",
            "        [-0.16404876,  0.13003737,  0.29859242, ...,  0.07187307,\n",
            "         -0.02451052,  0.        ],\n",
            "        [-0.25575238,  0.11766201,  0.34737554, ...,  0.06443845,\n",
            "         -0.03631271,  0.        ],\n",
            "        [-0.29766166,  0.08847526,  0.30419126, ...,  0.0459684 ,\n",
            "         -0.01104445,  0.        ]], dtype=float32)\n",
            " array([[-0.02909843, -0.1282445 , -0.03274422, ...,  0.0564477 ,\n",
            "          0.21152326,  0.        ],\n",
            "        [ 0.14985257, -0.0610401 , -0.02818616, ...,  0.27061123,\n",
            "          0.14359407,  0.        ],\n",
            "        [ 0.12693426, -0.03165526, -0.01909202, ...,  0.36293775,\n",
            "          0.03305565,  0.        ],\n",
            "        ...,\n",
            "        [-0.16855204,  0.09153896,  0.27483734, ...,  0.08308485,\n",
            "         -0.0197136 ,  0.        ],\n",
            "        [-0.25527394,  0.07430441,  0.30487967, ...,  0.07672241,\n",
            "         -0.03654044,  0.        ],\n",
            "        [-0.2920934 ,  0.08653081,  0.28379118, ...,  0.04776792,\n",
            "         -0.01251234,  0.        ]], dtype=float32)\n",
            " array([[-0.03400921, -0.15052307, -0.04717709, ...,  0.06233777,\n",
            "          0.21643758,  0.        ],\n",
            "        [ 0.1518835 , -0.10773358, -0.06200067, ...,  0.29885858,\n",
            "          0.16182631,  0.        ],\n",
            "        [ 0.09845851, -0.10102212, -0.06282203, ...,  0.40465602,\n",
            "          0.07372326,  0.        ],\n",
            "        ...,\n",
            "        [-0.1642585 ,  0.01270523,  0.22016655, ...,  0.10033546,\n",
            "         -0.02839233,  0.        ],\n",
            "        [-0.24212378,  0.03225478,  0.22442456, ...,  0.08556318,\n",
            "         -0.0525679 ,  0.        ],\n",
            "        [-0.2655722 ,  0.02449305,  0.24934524, ...,  0.03496457,\n",
            "         -0.02329464,  0.        ]], dtype=float32)\n",
            " array([[-0.01613208, -0.126522  , -0.03212648, ...,  0.04431244,\n",
            "          0.21479914,  0.        ],\n",
            "        [ 0.12931846, -0.04631283, -0.0121123 , ...,  0.24575803,\n",
            "          0.1292172 ,  0.        ],\n",
            "        [ 0.12979758,  0.0198958 ,  0.00122414, ...,  0.32831317,\n",
            "         -0.01980948,  0.        ],\n",
            "        ...,\n",
            "        [-0.06890684,  0.14138335,  0.20726612, ...,  0.07809003,\n",
            "          0.0216429 ,  0.        ],\n",
            "        [-0.23707318,  0.13632639,  0.33376083, ...,  0.07002998,\n",
            "         -0.01125014,  0.        ],\n",
            "        [-0.27794525,  0.09473214,  0.3001697 , ...,  0.06606996,\n",
            "          0.00374077,  0.        ]], dtype=float32)\n",
            " array([[-0.03226005, -0.12577656, -0.03262858, ...,  0.05184947,\n",
            "          0.20954561,  0.        ],\n",
            "        [ 0.1353808 , -0.06238559, -0.02869113, ...,  0.25981045,\n",
            "          0.14237225,  0.        ],\n",
            "        [ 0.11152571, -0.03393922, -0.02063806, ...,  0.34713665,\n",
            "          0.03602794,  0.        ],\n",
            "        ...,\n",
            "        [-0.17326044,  0.0927785 ,  0.26868805, ...,  0.08441838,\n",
            "         -0.01464211,  0.        ],\n",
            "        [-0.27219215,  0.0742954 ,  0.30956373, ...,  0.07276172,\n",
            "         -0.04284577,  0.        ],\n",
            "        [-0.29700595,  0.08304212,  0.28789547, ...,  0.03562024,\n",
            "         -0.01310847,  0.        ]], dtype=float32)\n",
            " array([[-0.01204704, -0.1146125 , -0.03671684, ...,  0.02852452,\n",
            "          0.20661826,  0.        ],\n",
            "        [ 0.13043898, -0.0144615 , -0.00514605, ...,  0.22472607,\n",
            "          0.09344899,  0.        ],\n",
            "        [ 0.14820686,  0.05765999,  0.01490349, ...,  0.29299057,\n",
            "         -0.05987002,  0.        ],\n",
            "        ...,\n",
            "        [-0.03548687,  0.1277679 ,  0.18786566, ...,  0.04364097,\n",
            "          0.02105217,  0.        ],\n",
            "        [-0.20131305,  0.13442716,  0.33762488, ...,  0.05469587,\n",
            "         -0.00671031,  0.        ],\n",
            "        [-0.27271265,  0.09677282,  0.3090224 , ...,  0.04125178,\n",
            "         -0.0029937 ,  0.        ]], dtype=float32)\n",
            " array([[-0.00377883, -0.1291658 , -0.03918049, ...,  0.04338002,\n",
            "          0.20891008,  0.        ],\n",
            "        [ 0.15497455, -0.02745488, -0.0294375 , ...,  0.2532139 ,\n",
            "          0.08563703,  0.        ],\n",
            "        [ 0.16988333,  0.04423663, -0.0131862 , ...,  0.32650483,\n",
            "         -0.06357533,  0.        ],\n",
            "        ...,\n",
            "        [ 0.01719997,  0.11908571,  0.11267709, ...,  0.04988396,\n",
            "          0.05603291,  0.        ],\n",
            "        [-0.16475946,  0.12387314,  0.2753    , ...,  0.0698804 ,\n",
            "          0.00551674,  0.        ],\n",
            "        [-0.24075516,  0.09390344,  0.2654623 , ...,  0.07151031,\n",
            "          0.00267665,  0.        ]], dtype=float32)\n",
            " array([[-0.01701311, -0.12013137, -0.03130797, ...,  0.03095932,\n",
            "          0.21081111,  0.        ],\n",
            "        [ 0.1172149 , -0.03279424,  0.00450723, ...,  0.22542989,\n",
            "          0.11460173,  0.        ],\n",
            "        [ 0.1257439 ,  0.03434261,  0.02483578, ...,  0.29926112,\n",
            "         -0.02756488,  0.        ],\n",
            "        ...,\n",
            "        [-0.10364693,  0.14850494,  0.26558298, ...,  0.0529349 ,\n",
            "         -0.00190255,  0.        ],\n",
            "        [-0.23700301,  0.13998409,  0.35748932, ...,  0.04636924,\n",
            "         -0.01737785,  0.        ],\n",
            "        [-0.286881  ,  0.09894899,  0.31006306, ...,  0.04167743,\n",
            "         -0.0015258 ,  0.        ]], dtype=float32)\n",
            " array([[-0.00077202, -0.10814589, -0.05997643, ...,  0.03179545,\n",
            "          0.19946457,  0.        ],\n",
            "        [ 0.16729161, -0.00349374, -0.03786065, ...,  0.24196126,\n",
            "          0.0506482 ,  0.        ],\n",
            "        [ 0.1734263 ,  0.04768408, -0.03251535, ...,  0.30447018,\n",
            "         -0.08703011,  0.        ],\n",
            "        ...,\n",
            "        [ 0.07941841,  0.07196502,  0.03647096, ...,  0.04042561,\n",
            "          0.05396601,  0.        ],\n",
            "        [-0.14210697,  0.1196963 ,  0.30752966, ...,  0.08718408,\n",
            "         -0.01326501,  0.        ],\n",
            "        [-0.26156312,  0.09054302,  0.2994956 , ...,  0.05998604,\n",
            "         -0.00044462,  0.        ]], dtype=float32)\n",
            " array([[-0.01154285, -0.11122017, -0.04071433, ...,  0.03059565,\n",
            "          0.2125218 ,  0.        ],\n",
            "        [ 0.12676054, -0.01738331, -0.01184365, ...,  0.21257725,\n",
            "          0.10753344,  0.        ],\n",
            "        [ 0.14094673,  0.05580653,  0.00433289, ...,  0.27810642,\n",
            "         -0.04179429,  0.        ],\n",
            "        ...,\n",
            "        [-0.05303814,  0.13867287,  0.19538315, ...,  0.0498561 ,\n",
            "          0.03970332,  0.        ],\n",
            "        [-0.2110349 ,  0.13956532,  0.33022085, ...,  0.06723266,\n",
            "          0.01018633,  0.        ],\n",
            "        [-0.2770947 ,  0.09548745,  0.2998795 , ...,  0.0470562 ,\n",
            "          0.01101314,  0.        ]], dtype=float32)\n",
            " array([[-0.02545287, -0.13194267, -0.02429008, ...,  0.04680206,\n",
            "          0.21568146,  0.        ],\n",
            "        [ 0.1397279 , -0.05018974,  0.00681085, ...,  0.2499422 ,\n",
            "          0.13324763,  0.        ],\n",
            "        [ 0.13215828, -0.01071807,  0.03298245, ...,  0.3250015 ,\n",
            "          0.01000475,  0.        ],\n",
            "        ...,\n",
            "        [-0.16046573,  0.1452952 ,  0.29636118, ...,  0.06722059,\n",
            "         -0.02838195,  0.        ],\n",
            "        [-0.2516469 ,  0.1263693 ,  0.34227812, ...,  0.06435831,\n",
            "         -0.03945826,  0.        ],\n",
            "        [-0.28833178,  0.09474126,  0.30401066, ...,  0.05287552,\n",
            "         -0.01454784,  0.        ]], dtype=float32)\n",
            " array([[-0.02700889, -0.13388182, -0.02509754, ...,  0.04910957,\n",
            "          0.21643214,  0.        ],\n",
            "        [ 0.1407072 , -0.05275846, -0.00178207, ...,  0.25349438,\n",
            "          0.13470703,  0.        ],\n",
            "        [ 0.130423  , -0.01819439,  0.02356474, ...,  0.3340299 ,\n",
            "          0.01322313,  0.        ],\n",
            "        ...,\n",
            "        [-0.16254614,  0.14005645,  0.29055905, ...,  0.06850704,\n",
            "         -0.02898013,  0.        ],\n",
            "        [-0.25113514,  0.11954216,  0.3316716 , ...,  0.0665736 ,\n",
            "         -0.04034657,  0.        ],\n",
            "        [-0.28753647,  0.09165376,  0.29947612, ...,  0.05282835,\n",
            "         -0.01613172,  0.        ]], dtype=float32)\n",
            " array([[-0.03111149, -0.14452858, -0.03769698, ...,  0.0577984 ,\n",
            "          0.21846671,  0.        ],\n",
            "        [ 0.16022533, -0.08143276, -0.046421  , ...,  0.2918459 ,\n",
            "          0.1542014 ,  0.        ],\n",
            "        [ 0.12157559, -0.06910045, -0.04234656, ...,  0.381503  ,\n",
            "          0.05513176,  0.        ],\n",
            "        ...,\n",
            "        [-0.1569155 ,  0.04296816,  0.24689989, ...,  0.0943587 ,\n",
            "         -0.0064918 ,  0.        ],\n",
            "        [-0.23810717,  0.04525268,  0.2653889 , ...,  0.08289147,\n",
            "         -0.03950739,  0.        ],\n",
            "        [-0.2750196 ,  0.04920615,  0.27249905, ...,  0.04485337,\n",
            "         -0.01451348,  0.        ]], dtype=float32)\n",
            " array([[-0.01812075, -0.11874626, -0.0300669 , ...,  0.04205133,\n",
            "          0.21730882,  0.        ],\n",
            "        [ 0.12697625, -0.03309022,  0.00964348, ...,  0.23248282,\n",
            "          0.11893766,  0.        ],\n",
            "        [ 0.12975678,  0.02298399,  0.03012556, ...,  0.29837036,\n",
            "         -0.02945413,  0.        ],\n",
            "        ...,\n",
            "        [-0.06869239,  0.1618438 ,  0.2373054 , ...,  0.04456744,\n",
            "         -0.00353903,  0.        ],\n",
            "        [-0.22690186,  0.14820853,  0.34609383, ...,  0.05593412,\n",
            "         -0.01604756,  0.        ],\n",
            "        [-0.27808207,  0.10449354,  0.30708015, ...,  0.05547956,\n",
            "         -0.00250421,  0.        ]], dtype=float32)\n",
            " array([[-0.01179818, -0.1145491 , -0.03952352, ...,  0.03141631,\n",
            "          0.21131411,  0.        ],\n",
            "        [ 0.12688565, -0.01807679, -0.00983386, ...,  0.2179665 ,\n",
            "          0.097174  ,  0.        ],\n",
            "        [ 0.14461428,  0.05310898,  0.00737461, ...,  0.2840583 ,\n",
            "         -0.05661668,  0.        ],\n",
            "        ...,\n",
            "        [-0.04303554,  0.12840368,  0.18391426, ...,  0.0413152 ,\n",
            "          0.0283557 ,  0.        ],\n",
            "        [-0.21494292,  0.13574429,  0.3361643 , ...,  0.05872533,\n",
            "          0.00270739,  0.        ],\n",
            "        [-0.27594826,  0.09855734,  0.30402234, ...,  0.04490619,\n",
            "          0.00658058,  0.        ]], dtype=float32)\n",
            " array([[-0.02207216, -0.13173935, -0.02730157, ...,  0.04248924,\n",
            "          0.21349794,  0.        ],\n",
            "        [ 0.13316093, -0.05074044,  0.00590164, ...,  0.24826501,\n",
            "          0.1338685 ,  0.        ],\n",
            "        [ 0.12723655, -0.00316557,  0.02306948, ...,  0.32333386,\n",
            "          0.00889947,  0.        ],\n",
            "        ...,\n",
            "        [-0.15876187,  0.13640024,  0.2928459 , ...,  0.06565335,\n",
            "         -0.01608665,  0.        ],\n",
            "        [-0.2499443 ,  0.12077042,  0.34261295, ...,  0.06247146,\n",
            "         -0.0297444 ,  0.        ],\n",
            "        [-0.29176277,  0.09212694,  0.30148742, ...,  0.04929849,\n",
            "         -0.00702951,  0.        ]], dtype=float32)\n",
            " array([[-0.00772692, -0.11324249, -0.04120122, ...,  0.02973019,\n",
            "          0.21087469,  0.        ],\n",
            "        [ 0.13336067, -0.01244897, -0.01323526, ...,  0.21322933,\n",
            "          0.09573041,  0.        ],\n",
            "        [ 0.15224141,  0.05603334,  0.00132065, ...,  0.2805341 ,\n",
            "         -0.05915316,  0.        ],\n",
            "        ...,\n",
            "        [-0.03458778,  0.12846556,  0.17398986, ...,  0.03829081,\n",
            "          0.03379643,  0.        ],\n",
            "        [-0.20647213,  0.13720058,  0.33238825, ...,  0.05588588,\n",
            "          0.00480637,  0.        ],\n",
            "        [-0.27086166,  0.09774958,  0.3024701 , ...,  0.0434929 ,\n",
            "          0.00525806,  0.        ]], dtype=float32)\n",
            " array([[-0.02964344, -0.1505772 , -0.04332009, ...,  0.05439489,\n",
            "          0.21752875,  0.        ],\n",
            "        [ 0.1557432 , -0.08805457, -0.05702806, ...,  0.28222582,\n",
            "          0.163848  ,  0.        ],\n",
            "        [ 0.10993211, -0.08102123, -0.05734139, ...,  0.37635848,\n",
            "          0.07060958,  0.        ],\n",
            "        ...,\n",
            "        [-0.15878527,  0.01873585,  0.23329619, ...,  0.08474476,\n",
            "         -0.00445288,  0.        ],\n",
            "        [-0.2364812 ,  0.01960862,  0.24885833, ...,  0.07314763,\n",
            "         -0.03178063,  0.        ],\n",
            "        [-0.2726981 ,  0.0307288 ,  0.26069623, ...,  0.03485947,\n",
            "         -0.01631288,  0.        ]], dtype=float32)\n",
            " array([[-0.01017746, -0.11483784, -0.03589479, ...,  0.03234339,\n",
            "          0.21097855,  0.        ],\n",
            "        [ 0.13105392, -0.01738648, -0.00358006, ...,  0.21572115,\n",
            "          0.10396553,  0.        ],\n",
            "        [ 0.14438309,  0.04977139,  0.01435405, ...,  0.28405827,\n",
            "         -0.04909366,  0.        ],\n",
            "        ...,\n",
            "        [-0.05816586,  0.14389208,  0.20814063, ...,  0.0364228 ,\n",
            "          0.0185853 ,  0.        ],\n",
            "        [-0.22073054,  0.1391208 ,  0.3376901 , ...,  0.04820859,\n",
            "         -0.00134173,  0.        ],\n",
            "        [-0.276918  ,  0.10063647,  0.30279315, ...,  0.0402252 ,\n",
            "          0.00155827,  0.        ]], dtype=float32)\n",
            " array([[-0.03035569, -0.14394163, -0.03829164, ...,  0.05261875,\n",
            "          0.21579218,  0.        ],\n",
            "        [ 0.15174086, -0.07400443, -0.04644144, ...,  0.2745435 ,\n",
            "          0.15723355,  0.        ],\n",
            "        [ 0.11374872, -0.06162934, -0.04480111, ...,  0.36367702,\n",
            "          0.05899142,  0.        ],\n",
            "        ...,\n",
            "        [-0.16307172,  0.03818494,  0.24463548, ...,  0.07525111,\n",
            "          0.00150319,  0.        ],\n",
            "        [-0.24330656,  0.0342785 ,  0.2680904 , ...,  0.06829967,\n",
            "         -0.03065286,  0.        ],\n",
            "        [-0.2818361 ,  0.04616938,  0.27140662, ...,  0.03651327,\n",
            "         -0.01455184,  0.        ]], dtype=float32)\n",
            " array([[-0.02416949, -0.13226113, -0.03195675, ...,  0.04742227,\n",
            "          0.21192223,  0.        ],\n",
            "        [ 0.14019094, -0.05688795, -0.01333029, ...,  0.26033115,\n",
            "          0.13531943,  0.        ],\n",
            "        [ 0.12302135, -0.02390599, -0.00088739, ...,  0.34488696,\n",
            "          0.02097583,  0.        ],\n",
            "        ...,\n",
            "        [-0.16473356,  0.09861657,  0.27502835, ...,  0.06463764,\n",
            "         -0.02180004,  0.        ],\n",
            "        [-0.24367069,  0.08156431,  0.3055256 , ...,  0.06386114,\n",
            "         -0.03485261,  0.        ],\n",
            "        [-0.28695855,  0.08365585,  0.28961146, ...,  0.04580014,\n",
            "         -0.01348868,  0.        ]], dtype=float32)\n",
            " array([[-0.02515195, -0.13165918, -0.02570869, ...,  0.04706053,\n",
            "          0.21479444,  0.        ],\n",
            "        [ 0.13876434, -0.05036478,  0.00199654, ...,  0.25064424,\n",
            "          0.13336165,  0.        ],\n",
            "        [ 0.12985092, -0.01421688,  0.02718248, ...,  0.32740074,\n",
            "          0.01106374,  0.        ],\n",
            "        ...,\n",
            "        [-0.16511923,  0.1413522 ,  0.29251522, ...,  0.06935336,\n",
            "         -0.03201969,  0.        ],\n",
            "        [-0.25417787,  0.12138589,  0.3361748 , ...,  0.06584293,\n",
            "         -0.04261103,  0.        ],\n",
            "        [-0.28858417,  0.09412821,  0.30223265, ...,  0.05158756,\n",
            "         -0.01766109,  0.        ]], dtype=float32)\n",
            " array([[-0.02341508, -0.12743671, -0.02703399, ...,  0.03840305,\n",
            "          0.21147439,  0.        ],\n",
            "        [ 0.12372578, -0.04601764,  0.00726942, ...,  0.23808004,\n",
            "          0.12655519,  0.        ],\n",
            "        [ 0.12405652,  0.00920413,  0.0229684 , ...,  0.31343687,\n",
            "         -0.00713627,  0.        ],\n",
            "        ...,\n",
            "        [-0.15608072,  0.14027841,  0.29397625, ...,  0.05712056,\n",
            "         -0.01774734,  0.        ],\n",
            "        [-0.25197116,  0.12655997,  0.35357478, ...,  0.05538111,\n",
            "         -0.03214179,  0.        ],\n",
            "        [-0.29487744,  0.09607724,  0.30707353, ...,  0.04286646,\n",
            "         -0.00552519,  0.        ]], dtype=float32)\n",
            " array([[ 0.04157147, -0.19624768, -0.08848714, ...,  0.01340269,\n",
            "          0.2166237 ,  0.        ],\n",
            "        [ 0.2843311 ,  0.00990081, -0.07294369, ...,  0.0917082 ,\n",
            "          0.02101849,  0.        ],\n",
            "        [ 0.296605  ,  0.03931672, -0.05120246, ...,  0.16588585,\n",
            "         -0.08133893,  0.        ],\n",
            "        ...,\n",
            "        [ 0.1430453 ,  0.02068866, -0.01364335, ...,  0.08754354,\n",
            "          0.0127855 ,  0.        ],\n",
            "        [-0.01370363,  0.06699152,  0.19638017, ...,  0.12269116,\n",
            "         -0.03535744,  0.        ],\n",
            "        [-0.17917506,  0.025908  ,  0.30873525, ...,  0.05056532,\n",
            "         -0.01612268,  0.        ]], dtype=float32)\n",
            " array([[-0.00701081, -0.10823368, -0.04640722, ...,  0.03660591,\n",
            "          0.2033329 ,  0.        ],\n",
            "        [ 0.15467116, -0.00428683, -0.02337517, ...,  0.23827773,\n",
            "          0.07113247,  0.        ],\n",
            "        [ 0.16662619,  0.05653457, -0.01458263, ...,  0.30215436,\n",
            "         -0.0775309 ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.05590038,  0.09315321,  0.07478552, ...,  0.02586083,\n",
            "          0.05610118,  0.        ],\n",
            "        [-0.16718784,  0.12521987,  0.31792298, ...,  0.07662268,\n",
            "         -0.00363191,  0.        ],\n",
            "        [-0.26295835,  0.10159845,  0.30022565, ...,  0.05325608,\n",
            "          0.00225129,  0.        ]], dtype=float32)\n",
            " array([[-2.38767993e-02, -1.29358307e-01, -2.59075798e-02, ...,\n",
            "          4.53177057e-02,  2.15202138e-01,  0.00000000e+00],\n",
            "        [ 1.36089534e-01, -4.56652679e-02,  9.58600733e-03, ...,\n",
            "          2.43210316e-01,  1.27697572e-01,  0.00000000e+00],\n",
            "        [ 1.34260356e-01,  1.19812037e-04,  3.34225446e-02, ...,\n",
            "          3.14130723e-01, -6.15685154e-03,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-1.19835176e-01,  1.63606539e-01,  2.69141287e-01, ...,\n",
            "          5.89596964e-02, -1.64114814e-02,  0.00000000e+00],\n",
            "        [-2.42971867e-01,  1.43901825e-01,  3.43205452e-01, ...,\n",
            "          5.77809289e-02, -3.12808342e-02,  0.00000000e+00],\n",
            "        [-2.83016652e-01,  1.03380300e-01,  3.01166981e-01, ...,\n",
            "          5.63037246e-02, -8.96128174e-03,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.01848852, -0.11592554, -0.03309156, ...,  0.03198778,\n",
            "          0.21423167,  0.        ],\n",
            "        [ 0.11603616, -0.02606509,  0.00188557, ...,  0.21667568,\n",
            "          0.11842683,  0.        ],\n",
            "        [ 0.12512563,  0.0468571 ,  0.01886794, ...,  0.28300348,\n",
            "         -0.02439204,  0.        ],\n",
            "        ...,\n",
            "        [-0.09437047,  0.15386234,  0.24925129, ...,  0.04658038,\n",
            "          0.02268163,  0.        ],\n",
            "        [-0.23312707,  0.14297624,  0.3474501 , ...,  0.05448499,\n",
            "          0.00038445,  0.        ],\n",
            "        [-0.28776973,  0.09611912,  0.30596194, ...,  0.04363846,\n",
            "          0.00975385,  0.        ]], dtype=float32)\n",
            " array([[-0.01825071, -0.122846  , -0.02748996, ...,  0.0343105 ,\n",
            "          0.21275689,  0.        ],\n",
            "        [ 0.12449414, -0.03420459,  0.00814171, ...,  0.2199615 ,\n",
            "          0.12563655,  0.        ],\n",
            "        [ 0.12859175,  0.02812941,  0.02774048, ...,  0.29200736,\n",
            "         -0.02015633,  0.        ],\n",
            "        ...,\n",
            "        [-0.1206241 ,  0.1514462 ,  0.27644983, ...,  0.04324716,\n",
            "          0.00221597,  0.        ],\n",
            "        [-0.24768035,  0.1382415 ,  0.35989094, ...,  0.04213188,\n",
            "         -0.01709704,  0.        ],\n",
            "        [-0.2921426 ,  0.09803654,  0.31056416, ...,  0.03872663,\n",
            "         -0.0024107 ,  0.        ]], dtype=float32)\n",
            " array([[-1.59328133e-02, -1.15425088e-01, -3.32027376e-02, ...,\n",
            "          4.18796651e-02,  2.17229649e-01,  0.00000000e+00],\n",
            "        [ 1.29213974e-01, -2.96364482e-02,  5.20832697e-03, ...,\n",
            "          2.29184583e-01,  1.14703573e-01,  0.00000000e+00],\n",
            "        [ 1.32801220e-01,  2.62772646e-02,  2.32048947e-02, ...,\n",
            "          2.94871986e-01, -3.54209170e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-5.79190776e-02,  1.58547223e-01,  2.21494481e-01, ...,\n",
            "          4.75351587e-02,  1.18597480e-03,  0.00000000e+00],\n",
            "        [-2.20540985e-01,  1.45834118e-01,  3.40847164e-01, ...,\n",
            "          6.37324080e-02, -1.14895804e-02,  0.00000000e+00],\n",
            "        [-2.75979936e-01,  1.02931455e-01,  3.06050867e-01, ...,\n",
            "          5.73219284e-02,  1.59496485e-04,  0.00000000e+00]], dtype=float32)\n",
            " array([[-0.03157935, -0.1264899 , -0.03031707, ...,  0.05604315,\n",
            "          0.21290116,  0.        ],\n",
            "        [ 0.14645287, -0.06241937, -0.02747508, ...,  0.2664276 ,\n",
            "          0.1446021 ,  0.        ],\n",
            "        [ 0.12147478, -0.03638704, -0.01387045, ...,  0.35455295,\n",
            "          0.03488213,  0.        ],\n",
            "        ...,\n",
            "        [-0.18440628,  0.10234015,  0.28420827, ...,  0.0893947 ,\n",
            "         -0.02647165,  0.        ],\n",
            "        [-0.26802367,  0.08599689,  0.30809265, ...,  0.08008397,\n",
            "         -0.04862546,  0.        ],\n",
            "        [-0.2925638 ,  0.08244661,  0.28824848, ...,  0.04416266,\n",
            "         -0.01976489,  0.        ]], dtype=float32)\n",
            " array([[-0.02442286, -0.13468456, -0.02970384, ...,  0.04538953,\n",
            "          0.21465358,  0.        ],\n",
            "        [ 0.13722338, -0.0531594 , -0.00440455, ...,  0.2572065 ,\n",
            "          0.13753703,  0.        ],\n",
            "        [ 0.12412063, -0.01427202,  0.00840029, ...,  0.33774936,\n",
            "          0.02100434,  0.        ],\n",
            "        ...,\n",
            "        [-0.1741969 ,  0.11464017,  0.28936836, ...,  0.06613719,\n",
            "         -0.02465854,  0.        ],\n",
            "        [-0.24842937,  0.09596737,  0.3191588 , ...,  0.06642728,\n",
            "         -0.03404151,  0.        ],\n",
            "        [-0.28978106,  0.08598851,  0.2932547 , ...,  0.04870721,\n",
            "         -0.00938863,  0.        ]], dtype=float32)\n",
            " array([[-0.03089785, -0.1441692 , -0.03868674, ...,  0.05029674,\n",
            "          0.21508616,  0.        ],\n",
            "        [ 0.14754061, -0.07527723, -0.04569004, ...,  0.26791108,\n",
            "          0.15383139,  0.        ],\n",
            "        [ 0.11021618, -0.06127555, -0.04480116, ...,  0.3549502 ,\n",
            "          0.05483803,  0.        ],\n",
            "        ...,\n",
            "        [-0.16742979,  0.03479603,  0.2467995 , ...,  0.069701  ,\n",
            "          0.0010138 ,  0.        ],\n",
            "        [-0.24347284,  0.03127665,  0.26888856, ...,  0.0640514 ,\n",
            "         -0.02922351,  0.        ],\n",
            "        [-0.2819994 ,  0.04499735,  0.27149308, ...,  0.03588534,\n",
            "         -0.01599279,  0.        ]], dtype=float32)\n",
            " array([[-1.77960116e-02, -1.18005887e-01, -3.46356146e-02, ...,\n",
            "          4.37051319e-02,  2.16943786e-01,  0.00000000e+00],\n",
            "        [ 1.27690494e-01, -3.60951312e-02,  2.67583760e-04, ...,\n",
            "          2.29111061e-01,  1.18421011e-01,  0.00000000e+00],\n",
            "        [ 1.25268579e-01,  1.63613074e-02,  1.83229893e-02, ...,\n",
            "          2.99554110e-01, -3.39029171e-02,  0.00000000e+00],\n",
            "        ...,\n",
            "        [-6.21775575e-02,  1.66522935e-01,  2.25064248e-01, ...,\n",
            "          4.85446826e-02,  1.11505535e-04,  0.00000000e+00],\n",
            "        [-2.25810394e-01,  1.48831710e-01,  3.37397575e-01, ...,\n",
            "          6.53488263e-02, -1.39182191e-02,  0.00000000e+00],\n",
            "        [-2.75666982e-01,  1.06314033e-01,  3.00817192e-01, ...,\n",
            "          5.93609810e-02, -8.41926143e-04,  0.00000000e+00]], dtype=float32)\n",
            " array([[ 0.01034598, -0.12029961, -0.05912405, ...,  0.0356704 ,\n",
            "          0.2110597 ,  0.        ],\n",
            "        [ 0.18954863, -0.04057888, -0.04169979, ...,  0.22100489,\n",
            "          0.05351963,  0.        ],\n",
            "        [ 0.1855607 , -0.00373243, -0.04258515, ...,  0.29455483,\n",
            "         -0.08946687,  0.        ],\n",
            "        ...,\n",
            "        [ 0.07932917,  0.06970396,  0.09375724, ...,  0.03347334,\n",
            "          0.02821662,  0.        ],\n",
            "        [-0.13597994,  0.11444389,  0.2949249 , ...,  0.08611137,\n",
            "         -0.01999091,  0.        ],\n",
            "        [-0.25819385,  0.07212212,  0.29791492, ...,  0.0651257 ,\n",
            "         -0.00569132,  0.        ]], dtype=float32)\n",
            " array([[-0.02168599, -0.12805556, -0.02679232, ...,  0.03682811,\n",
            "          0.21381399,  0.        ],\n",
            "        [ 0.12598993, -0.04260666,  0.00789713, ...,  0.23930958,\n",
            "          0.12684472,  0.        ],\n",
            "        [ 0.12965445,  0.0216309 ,  0.02716574, ...,  0.31464326,\n",
            "         -0.01288917,  0.        ],\n",
            "        ...,\n",
            "        [-0.13665926,  0.14822921,  0.27994296, ...,  0.04980452,\n",
            "         -0.00586561,  0.        ],\n",
            "        [-0.24207047,  0.13187012,  0.34668478, ...,  0.04893003,\n",
            "         -0.02465808,  0.        ],\n",
            "        [-0.28815505,  0.09541312,  0.30327365, ...,  0.04666115,\n",
            "         -0.00468523,  0.        ]], dtype=float32)\n",
            " array([[-0.01685119, -0.11059204, -0.03729867, ...,  0.03942517,\n",
            "          0.20815705,  0.        ],\n",
            "        [ 0.13465133, -0.00824571, -0.01080896, ...,  0.23412713,\n",
            "          0.0915378 ,  0.        ],\n",
            "        [ 0.14575067,  0.06015253,  0.00503196, ...,  0.29678753,\n",
            "         -0.05704921,  0.        ],\n",
            "        ...,\n",
            "        [ 0.00968428,  0.1211001 ,  0.13270083, ...,  0.0280634 ,\n",
            "          0.04413186,  0.        ],\n",
            "        [-0.20205528,  0.12940507,  0.33768734, ...,  0.06217098,\n",
            "         -0.00333207,  0.        ],\n",
            "        [-0.27314785,  0.10310801,  0.30357733, ...,  0.04882103,\n",
            "          0.00720327,  0.        ]], dtype=float32)\n",
            " array([[-0.0168744 , -0.11508321, -0.03364028, ...,  0.03319023,\n",
            "          0.21284243,  0.        ],\n",
            "        [ 0.12039279, -0.02380151,  0.00040638, ...,  0.22034416,\n",
            "          0.11654786,  0.        ],\n",
            "        [ 0.12955134,  0.04844684,  0.01676716, ...,  0.28696334,\n",
            "         -0.02695721,  0.        ],\n",
            "        ...,\n",
            "        [-0.0848102 ,  0.15025295,  0.24086754, ...,  0.04934756,\n",
            "          0.01867913,  0.        ],\n",
            "        [-0.22951032,  0.14059299,  0.34430647, ...,  0.05702265,\n",
            "         -0.00247015,  0.        ],\n",
            "        [-0.28357065,  0.09705777,  0.30387217, ...,  0.04252784,\n",
            "          0.00826583,  0.        ]], dtype=float32)\n",
            " array([[-0.0066418 , -0.11305653, -0.04883409, ...,  0.04099473,\n",
            "          0.21583758,  0.        ],\n",
            "        [ 0.14894398, -0.02678396, -0.02920091, ...,  0.22908176,\n",
            "          0.08614238,  0.        ],\n",
            "        [ 0.14535496,  0.01887965, -0.01591074, ...,  0.30698255,\n",
            "         -0.06280693,  0.        ],\n",
            "        ...,\n",
            "        [ 0.02231011,  0.12308863,  0.13132256, ...,  0.03882335,\n",
            "          0.02994665,  0.        ],\n",
            "        [-0.175634  ,  0.13989449,  0.3064481 , ...,  0.07798101,\n",
            "         -0.00508546,  0.        ],\n",
            "        [-0.26470765,  0.09574105,  0.29016188, ...,  0.06211567,\n",
            "          0.0006737 ,  0.        ]], dtype=float32)\n",
            " array([[-0.02632857, -0.1321999 , -0.02462088, ...,  0.04702675,\n",
            "          0.21547005,  0.        ],\n",
            "        [ 0.14047742, -0.05153893,  0.00191522, ...,  0.249193  ,\n",
            "          0.1360977 ,  0.        ],\n",
            "        [ 0.1284048 , -0.01386654,  0.02824493, ...,  0.32567176,\n",
            "          0.0149331 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.1761336 ,  0.14226069,  0.30135432, ...,  0.06545328,\n",
            "         -0.03048989,  0.        ],\n",
            "        [-0.25654298,  0.11881817,  0.33822748, ...,  0.06268797,\n",
            "         -0.04046345,  0.        ],\n",
            "        [-0.28982097,  0.09236428,  0.30168033, ...,  0.05167316,\n",
            "         -0.0187646 ,  0.        ]], dtype=float32)\n",
            " array([[-0.00609799, -0.10774833, -0.0508933 , ...,  0.03782593,\n",
            "          0.21759541,  0.        ],\n",
            "        [ 0.15278344, -0.02660767, -0.02968775, ...,  0.22008854,\n",
            "          0.08769001,  0.        ],\n",
            "        [ 0.14622173,  0.01998281, -0.02175687, ...,  0.29873398,\n",
            "         -0.05915535,  0.        ],\n",
            "        ...,\n",
            "        [ 0.02265554,  0.12831068,  0.1383886 , ...,  0.03515322,\n",
            "          0.0299893 ,  0.        ],\n",
            "        [-0.17470402,  0.14447999,  0.30868462, ...,  0.0759304 ,\n",
            "         -0.00681428,  0.        ],\n",
            "        [-0.26642546,  0.09515698,  0.29525247, ...,  0.06190841,\n",
            "         -0.00104269,  0.        ]], dtype=float32)\n",
            " array([[-0.02968848, -0.14804648, -0.0384567 , ...,  0.05569221,\n",
            "          0.21809475,  0.        ],\n",
            "        [ 0.15957642, -0.08817648, -0.04576039, ...,  0.2833567 ,\n",
            "          0.15846856,  0.        ],\n",
            "        [ 0.11794957, -0.07438561, -0.04204876, ...,  0.37131104,\n",
            "          0.05869514,  0.        ],\n",
            "        ...,\n",
            "        [-0.15467268,  0.03813313,  0.24492492, ...,  0.09047454,\n",
            "         -0.00589665,  0.        ],\n",
            "        [-0.23494625,  0.04256381,  0.2635629 , ...,  0.07929517,\n",
            "         -0.04010851,  0.        ],\n",
            "        [-0.2717868 ,  0.04433007,  0.26912686, ...,  0.04216835,\n",
            "         -0.01824641,  0.        ]], dtype=float32)\n",
            " array([[-0.02006984, -0.1521474 , -0.0580389 , ...,  0.04959452,\n",
            "          0.18335748,  0.        ],\n",
            "        [ 0.12189309, -0.13340606, -0.04983684, ...,  0.23411608,\n",
            "          0.15221685,  0.        ],\n",
            "        [ 0.0481585 , -0.13076892, -0.0638566 , ...,  0.3447905 ,\n",
            "          0.08348324,  0.        ],\n",
            "        ...,\n",
            "        [-0.20406792,  0.04886345,  0.22170976, ..., -0.04282367,\n",
            "         -0.09117052,  0.        ],\n",
            "        [-0.24449296,  0.07263946,  0.23416276, ..., -0.03558727,\n",
            "         -0.08106366,  0.        ],\n",
            "        [-0.20198588,  0.04950026,  0.24766941, ..., -0.03553693,\n",
            "         -0.05990754,  0.        ]], dtype=float32)\n",
            " array([[-0.02457109, -0.1286834 , -0.02580159, ...,  0.0474126 ,\n",
            "          0.21613126,  0.        ],\n",
            "        [ 0.1363096 , -0.04835297,  0.00906734, ...,  0.24929549,\n",
            "          0.12998372,  0.        ],\n",
            "        [ 0.13462234, -0.0013739 ,  0.03238477, ...,  0.32124195,\n",
            "         -0.00274679,  0.        ],\n",
            "        ...,\n",
            "        [-0.13277155,  0.15630975,  0.28290063, ...,  0.0664307 ,\n",
            "         -0.01629394,  0.        ],\n",
            "        [-0.24226078,  0.13872169,  0.34570423, ...,  0.06548099,\n",
            "         -0.02844999,  0.        ],\n",
            "        [-0.28337124,  0.10064788,  0.30293137, ...,  0.05912138,\n",
            "         -0.0045364 ,  0.        ]], dtype=float32)\n",
            " array([[-0.0161044 , -0.11923417, -0.0324818 , ...,  0.04300335,\n",
            "          0.21716528,  0.        ],\n",
            "        [ 0.12888555, -0.0327874 ,  0.0059396 , ...,  0.23685597,\n",
            "          0.11788758,  0.        ],\n",
            "        [ 0.13169622,  0.02217977,  0.02550709, ...,  0.30364686,\n",
            "         -0.03328488,  0.        ],\n",
            "        ...,\n",
            "        [-0.05484601,  0.15423341,  0.22247611, ...,  0.05185104,\n",
            "         -0.00053251,  0.        ],\n",
            "        [-0.22015435,  0.14475763,  0.34183216, ...,  0.064093  ,\n",
            "         -0.01236977,  0.        ],\n",
            "        [-0.27429938,  0.10066757,  0.30490002, ...,  0.0603322 ,\n",
            "         -0.00127366,  0.        ]], dtype=float32)\n",
            " array([[-0.02262825, -0.13236026, -0.02677754, ...,  0.04281075,\n",
            "          0.21287195,  0.        ],\n",
            "        [ 0.13391642, -0.04959393,  0.00382338, ...,  0.24756394,\n",
            "          0.13368756,  0.        ],\n",
            "        [ 0.12438682, -0.00406587,  0.02436407, ...,  0.32688603,\n",
            "          0.00774009,  0.        ],\n",
            "        ...,\n",
            "        [-0.16246004,  0.13210247,  0.28886   , ...,  0.06233775,\n",
            "         -0.02036065,  0.        ],\n",
            "        [-0.25198218,  0.11610752,  0.3360413 , ...,  0.06063705,\n",
            "         -0.03497994,  0.        ],\n",
            "        [-0.29357934,  0.08993571,  0.30053288, ...,  0.04740259,\n",
            "         -0.01037602,  0.        ]], dtype=float32)\n",
            " array([[-0.01812858, -0.11922652, -0.03155008, ...,  0.03289584,\n",
            "          0.21158014,  0.        ],\n",
            "        [ 0.12157028, -0.02579089,  0.00572403, ...,  0.22088192,\n",
            "          0.10993543,  0.        ],\n",
            "        [ 0.13278079,  0.04175979,  0.02603048, ...,  0.28717628,\n",
            "         -0.03850548,  0.        ],\n",
            "        ...,\n",
            "        [-0.08092237,  0.14386225,  0.24244305, ...,  0.04022753,\n",
            "          0.00764746,  0.        ],\n",
            "        [-0.23313415,  0.1383548 ,  0.35204697, ...,  0.04752777,\n",
            "         -0.00847177,  0.        ],\n",
            "        [-0.286122  ,  0.09876266,  0.31063446, ...,  0.0398506 ,\n",
            "          0.00388713,  0.        ]], dtype=float32)\n",
            " array([[ 0.00075186, -0.10830749, -0.05621456, ...,  0.02391527,\n",
            "          0.2043425 ,  0.        ],\n",
            "        [ 0.14612715, -0.01556833, -0.02796659, ...,  0.21791516,\n",
            "          0.06884164,  0.        ],\n",
            "        [ 0.16675223,  0.04272803, -0.02811562, ...,  0.28805575,\n",
            "         -0.0794021 ,  0.        ],\n",
            "        ...,\n",
            "        [ 0.02598718,  0.09172231,  0.10972323, ...,  0.04120991,\n",
            "          0.05208576,  0.        ],\n",
            "        [-0.16606253,  0.12819831,  0.3050602 , ...,  0.07026529,\n",
            "          0.00568115,  0.        ],\n",
            "        [-0.2616852 ,  0.0857962 ,  0.2976386 , ...,  0.04790465,\n",
            "          0.00479412,  0.        ]], dtype=float32)\n",
            " array([[-0.02264034, -0.13232043, -0.02751353, ...,  0.0423987 ,\n",
            "          0.21397527,  0.        ],\n",
            "        [ 0.13393979, -0.04789666,  0.00175132, ...,  0.24503733,\n",
            "          0.1380653 ,  0.        ],\n",
            "        [ 0.12454981, -0.00227313,  0.02022451, ...,  0.32402316,\n",
            "          0.00901878,  0.        ],\n",
            "        ...,\n",
            "        [-0.1625295 ,  0.133821  ,  0.288257  , ...,  0.06236738,\n",
            "         -0.01966674,  0.        ],\n",
            "        [-0.2530954 ,  0.11684193,  0.3379312 , ...,  0.05857084,\n",
            "         -0.03568344,  0.        ],\n",
            "        [-0.29495776,  0.08735716,  0.3015244 , ...,  0.04630935,\n",
            "         -0.01398391,  0.        ]], dtype=float32)\n",
            " array([[-0.02710336, -0.13178538, -0.02560677, ...,  0.04901037,\n",
            "          0.21555889,  0.        ],\n",
            "        [ 0.14219326, -0.05490704, -0.00154412, ...,  0.2539201 ,\n",
            "          0.1395926 ,  0.        ],\n",
            "        [ 0.13025811, -0.02048335,  0.02341811, ...,  0.33179083,\n",
            "          0.01833704,  0.        ],\n",
            "        ...,\n",
            "        [-0.17859407,  0.13776812,  0.30064443, ...,  0.07223073,\n",
            "         -0.03150574,  0.        ],\n",
            "        [-0.2566985 ,  0.11705704,  0.33306602, ...,  0.07019923,\n",
            "         -0.03961089,  0.        ],\n",
            "        [-0.2900681 ,  0.09116214,  0.30027676, ...,  0.05291688,\n",
            "         -0.01757394,  0.        ]], dtype=float32)\n",
            " array([[-0.02911218, -0.15310107, -0.04876098, ...,  0.05236437,\n",
            "          0.2129107 ,  0.        ],\n",
            "        [ 0.1476837 , -0.10163377, -0.05796647, ...,  0.2857149 ,\n",
            "          0.15779214,  0.        ],\n",
            "        [ 0.11029981, -0.10462702, -0.05824862, ...,  0.36810195,\n",
            "          0.09485164,  0.        ],\n",
            "        ...,\n",
            "        [-0.15319632,  0.00285499,  0.22726795, ...,  0.10262031,\n",
            "         -0.00897536,  0.        ],\n",
            "        [-0.23042066,  0.01024869,  0.23671122, ...,  0.08223029,\n",
            "         -0.03674332,  0.        ],\n",
            "        [-0.26434767,  0.02105645,  0.25237897, ...,  0.03357794,\n",
            "         -0.02148136,  0.        ]], dtype=float32)\n",
            " array([[-0.03200977, -0.12613504, -0.02995234, ...,  0.05740736,\n",
            "          0.21167341,  0.        ],\n",
            "        [ 0.15148295, -0.06012227, -0.02163371, ...,  0.2642152 ,\n",
            "          0.1433889 ,  0.        ],\n",
            "        [ 0.12814648, -0.03264488, -0.0053012 , ...,  0.34818393,\n",
            "          0.0341848 ,  0.        ],\n",
            "        ...,\n",
            "        [-0.17957063,  0.11388556,  0.28013653, ...,  0.08191071,\n",
            "         -0.03258014,  0.        ],\n",
            "        [-0.26560467,  0.09796147,  0.30595508, ...,  0.07736219,\n",
            "         -0.05167352,  0.        ],\n",
            "        [-0.2888913 ,  0.0883541 ,  0.28617013, ...,  0.04602771,\n",
            "         -0.01865413,  0.        ]], dtype=float32)\n",
            " array([[-0.01626742, -0.11799296, -0.03185937, ...,  0.04148853,\n",
            "          0.2164179 ,  0.        ],\n",
            "        [ 0.13011776, -0.03344758,  0.0063827 , ...,  0.23074438,\n",
            "          0.12020778,  0.        ],\n",
            "        [ 0.12922725,  0.01912661,  0.02646807, ...,  0.29788214,\n",
            "         -0.03078164,  0.        ],\n",
            "        ...,\n",
            "        [-0.05423221,  0.1644773 ,  0.21987231, ...,  0.04636726,\n",
            "          0.00231348,  0.        ],\n",
            "        [-0.22206336,  0.15293683,  0.3379485 , ...,  0.05943977,\n",
            "         -0.01206028,  0.        ],\n",
            "        [-0.27729192,  0.10399365,  0.30387002, ...,  0.05759271,\n",
            "         -0.00463146,  0.        ]], dtype=float32)\n",
            " array([[-0.0306651 , -0.12488695, -0.02781424, ...,  0.05882183,\n",
            "          0.21202007,  0.        ],\n",
            "        [ 0.15156806, -0.05838319, -0.0166465 , ...,  0.26706207,\n",
            "          0.1424598 ,  0.        ],\n",
            "        [ 0.13275611, -0.03078111,  0.00231641, ...,  0.35429576,\n",
            "          0.02944541,  0.        ],\n",
            "        ...,\n",
            "        [-0.17730828,  0.12625973,  0.28692293, ...,  0.08469456,\n",
            "         -0.03252523,  0.        ],\n",
            "        [-0.2612671 ,  0.10778181,  0.31374624, ...,  0.08089289,\n",
            "         -0.0453455 ,  0.        ],\n",
            "        [-0.2896018 ,  0.08977181,  0.29045665, ...,  0.05162746,\n",
            "         -0.01805291,  0.        ]], dtype=float32)\n",
            " array([[-0.00942556, -0.11351899, -0.04639596, ...,  0.04027581,\n",
            "          0.21495502,  0.        ],\n",
            "        [ 0.14530899, -0.02682446, -0.01822799, ...,  0.22728935,\n",
            "          0.09049494,  0.        ],\n",
            "        [ 0.14643948,  0.0201604 , -0.006377  , ...,  0.30045474,\n",
            "         -0.06188741,  0.        ],\n",
            "        ...,\n",
            "        [ 0.00387055,  0.13042079,  0.14844196, ...,  0.04116745,\n",
            "          0.01938774,  0.        ],\n",
            "        [-0.18748295,  0.1380443 ,  0.31764448, ...,  0.07434069,\n",
            "         -0.01094949,  0.        ],\n",
            "        [-0.2697114 ,  0.09336618,  0.2976136 , ...,  0.06228701,\n",
            "         -0.00219176,  0.        ]], dtype=float32)\n",
            " array([[ 0.02277771, -0.12714812, -0.08088406, ...,  0.01414192,\n",
            "          0.20238923,  0.        ],\n",
            "        [ 0.19483058, -0.02464392, -0.06441431, ...,  0.19564126,\n",
            "          0.03845721,  0.        ],\n",
            "        [ 0.2057889 ,  0.02337101, -0.06447344, ...,  0.2613714 ,\n",
            "         -0.09494207,  0.        ],\n",
            "        ...,\n",
            "        [ 0.10612767,  0.02641383, -0.00107104, ...,  0.04068161,\n",
            "          0.07847099,  0.        ],\n",
            "        [-0.10197578,  0.11382952,  0.25504953, ...,  0.07777169,\n",
            "          0.00822041,  0.        ],\n",
            "        [-0.25991404,  0.07101943,  0.28913298, ...,  0.05668136,\n",
            "          0.00396229,  0.        ]], dtype=float32)\n",
            " array([[-1.81538202e-02, -1.18900336e-01, -3.02403141e-02, ...,\n",
            "          4.21884879e-02,  2.17359096e-01,  1.00000000e+00],\n",
            "        [ 1.27636194e-01, -3.53214666e-02,  9.83558502e-03, ...,\n",
            "          2.30936617e-01,  1.22313775e-01,  1.00000000e+00],\n",
            "        [ 1.31462604e-01,  2.08377764e-02,  2.96556912e-02, ...,\n",
            "          2.97092497e-01, -2.43357662e-02,  1.00000000e+00],\n",
            "        ...,\n",
            "        [-7.97840282e-02,  1.63163155e-01,  2.44688109e-01, ...,\n",
            "          5.05516194e-02, -4.06118867e-04,  1.00000000e+00],\n",
            "        [-2.28529513e-01,  1.45793274e-01,  3.46266180e-01, ...,\n",
            "          5.89164831e-02, -1.41179739e-02,  1.00000000e+00],\n",
            "        [-2.78182685e-01,  1.06142543e-01,  3.05952430e-01, ...,\n",
            "          5.47593720e-02,  5.77570579e-04,  1.00000000e+00]], dtype=float32)\n",
            " array([[-0.02770626, -0.15468769, -0.04104996, ...,  0.05564665,\n",
            "          0.21519487,  1.        ],\n",
            "        [ 0.1618188 , -0.09653462, -0.04670407, ...,  0.28500992,\n",
            "          0.14751664,  1.        ],\n",
            "        [ 0.11883575, -0.08239118, -0.04590608, ...,  0.37049088,\n",
            "          0.05083673,  1.        ],\n",
            "        ...,\n",
            "        [-0.13528527,  0.01962334,  0.22659121, ...,  0.08797058,\n",
            "         -0.00546379,  1.        ],\n",
            "        [-0.21205314,  0.03025331,  0.2424382 , ...,  0.07705035,\n",
            "         -0.03831394,  1.        ],\n",
            "        [-0.2529522 ,  0.03156137,  0.2559224 , ...,  0.04449863,\n",
            "         -0.01747447,  1.        ]], dtype=float32)\n",
            " array([[-0.02197278, -0.12467737, -0.02668405, ...,  0.04240059,\n",
            "          0.21632473,  1.        ],\n",
            "        [ 0.12983574, -0.04240201,  0.0126361 , ...,  0.23566099,\n",
            "          0.12756617,  1.        ],\n",
            "        [ 0.13080181,  0.01020518,  0.03565934, ...,  0.3039694 ,\n",
            "         -0.01224144,  1.        ],\n",
            "        ...,\n",
            "        [-0.11480428,  0.16308379,  0.27291408, ...,  0.05279243,\n",
            "         -0.01270568,  1.        ],\n",
            "        [-0.24017322,  0.14390399,  0.35269436, ...,  0.05298774,\n",
            "         -0.02650893,  1.        ],\n",
            "        [-0.2840439 ,  0.10381205,  0.30717692, ...,  0.0513704 ,\n",
            "         -0.00612522,  1.        ]], dtype=float32)\n",
            " array([[-0.02513576, -0.13140553, -0.02480767, ...,  0.04872713,\n",
            "          0.21518816,  1.        ],\n",
            "        [ 0.14153914, -0.05201299,  0.00114902, ...,  0.25460482,\n",
            "          0.13398385,  1.        ],\n",
            "        [ 0.13255653, -0.01325426,  0.02670033, ...,  0.33021083,\n",
            "          0.01023339,  1.        ],\n",
            "        ...,\n",
            "        [-0.15712808,  0.14330766,  0.28830808, ...,  0.07201844,\n",
            "         -0.02906775,  1.        ],\n",
            "        [-0.24786149,  0.12295175,  0.33483136, ...,  0.06878646,\n",
            "         -0.03981977,  1.        ],\n",
            "        [-0.2845968 ,  0.09444366,  0.29952976, ...,  0.05605429,\n",
            "         -0.01394429,  1.        ]], dtype=float32)\n",
            " array([[-0.03065528, -0.14403568, -0.03739283, ...,  0.05592931,\n",
            "          0.21709876,  1.        ],\n",
            "        [ 0.15685472, -0.08313914, -0.04556406, ...,  0.28297913,\n",
            "          0.15654989,  1.        ],\n",
            "        [ 0.11711826, -0.06875818, -0.04069972, ...,  0.37122363,\n",
            "          0.05708473,  1.        ],\n",
            "        ...,\n",
            "        [-0.16556083,  0.04391535,  0.25487614, ...,  0.09411148,\n",
            "         -0.00969183,  1.        ],\n",
            "        [-0.24762362,  0.04772923,  0.27164993, ...,  0.08157431,\n",
            "         -0.04329246,  1.        ],\n",
            "        [-0.2776438 ,  0.05258853,  0.27365112, ...,  0.04204644,\n",
            "         -0.01646137,  1.        ]], dtype=float32)\n",
            " array([[-0.03090972, -0.12389157, -0.03101105, ...,  0.05957066,\n",
            "          0.21218257,  1.        ],\n",
            "        [ 0.15164128, -0.05857046, -0.02294366, ...,  0.27182344,\n",
            "          0.14089325,  1.        ],\n",
            "        [ 0.13152704, -0.03290228, -0.00841335, ...,  0.36020178,\n",
            "          0.03006111,  1.        ],\n",
            "        ...,\n",
            "        [-0.18264866,  0.11323591,  0.28681105, ...,  0.08882445,\n",
            "         -0.03360343,  1.        ],\n",
            "        [-0.26437506,  0.09536333,  0.31027335, ...,  0.08179255,\n",
            "         -0.04889799,  1.        ],\n",
            "        [-0.28905165,  0.08728934,  0.28875116, ...,  0.04732971,\n",
            "         -0.01887085,  1.        ]], dtype=float32)\n",
            " array([[-2.3947023e-02, -1.2945250e-01, -2.5191391e-02, ...,\n",
            "          4.5748167e-02,  2.1603973e-01,  1.0000000e+00],\n",
            "        [ 1.3775428e-01, -4.8271909e-02,  9.0470035e-03, ...,\n",
            "          2.4752195e-01,  1.2882276e-01,  1.0000000e+00],\n",
            "        [ 1.3600710e-01,  3.7002112e-04,  3.3707399e-02, ...,\n",
            "          3.1828067e-01, -3.9656428e-03,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.2619250e-01,  1.5681025e-01,  2.7794376e-01, ...,\n",
            "          6.1111957e-02, -1.7915241e-02,  1.0000000e+00],\n",
            "        [-2.4107678e-01,  1.3733573e-01,  3.4773549e-01, ...,\n",
            "          6.0166877e-02, -3.1406876e-02,  1.0000000e+00],\n",
            "        [-2.8509778e-01,  9.8589696e-02,  3.0514166e-01, ...,\n",
            "          5.5642337e-02, -9.6417395e-03,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.0340346 , -0.14686291, -0.04104823, ...,  0.05882207,\n",
            "          0.21787795,  1.        ],\n",
            "        [ 0.15598229, -0.08935867, -0.0548095 , ...,  0.29095048,\n",
            "          0.15884802,  1.        ],\n",
            "        [ 0.11215062, -0.08173983, -0.05253256, ...,  0.3857311 ,\n",
            "          0.06560368,  1.        ],\n",
            "        ...,\n",
            "        [-0.16521847,  0.02839524,  0.24610682, ...,  0.09664837,\n",
            "         -0.01450422,  1.        ],\n",
            "        [-0.24761152,  0.03668065,  0.25423113, ...,  0.08308034,\n",
            "         -0.04414225,  1.        ],\n",
            "        [-0.2757819 ,  0.03838814,  0.26762736, ...,  0.04033781,\n",
            "         -0.0178427 ,  1.        ]], dtype=float32)\n",
            " array([[-0.02236623, -0.12794589, -0.0265013 , ...,  0.03686176,\n",
            "          0.21091832,  1.        ],\n",
            "        [ 0.12413865, -0.04316074,  0.00951853, ...,  0.23714581,\n",
            "          0.12489761,  1.        ],\n",
            "        [ 0.12365489,  0.01130181,  0.02838448, ...,  0.31107286,\n",
            "         -0.00796709,  1.        ],\n",
            "        ...,\n",
            "        [-0.160613  ,  0.14346091,  0.2952965 , ...,  0.05497991,\n",
            "         -0.02258561,  1.        ],\n",
            "        [-0.25097343,  0.12838179,  0.3526518 , ...,  0.04928285,\n",
            "         -0.03516379,  1.        ],\n",
            "        [-0.29252356,  0.09350956,  0.30646124, ...,  0.04078948,\n",
            "         -0.0108101 ,  1.        ]], dtype=float32)\n",
            " array([[-0.00734996, -0.12776662, -0.03855316, ...,  0.04882867,\n",
            "          0.21594706,  1.        ],\n",
            "        [ 0.1421207 , -0.0363253 , -0.02232611, ...,  0.24669278,\n",
            "          0.12194268,  1.        ],\n",
            "        [ 0.14892323,  0.03373036, -0.00466746, ...,  0.3284453 ,\n",
            "         -0.02899633,  1.        ],\n",
            "        ...,\n",
            "        [-0.04307402,  0.13963224,  0.17657256, ...,  0.0918018 ,\n",
            "          0.04293218,  1.        ],\n",
            "        [-0.20829108,  0.13031267,  0.30681434, ...,  0.09307154,\n",
            "          0.00510776,  1.        ],\n",
            "        [-0.25744796,  0.09772215,  0.2841494 , ...,  0.0792682 ,\n",
            "          0.01044326,  1.        ]], dtype=float32)\n",
            " array([[-2.2745289e-02, -1.3046345e-01, -2.6387375e-02, ...,\n",
            "          3.9883494e-02,  2.1314012e-01,  1.0000000e+00],\n",
            "        [ 1.2970082e-01, -4.8096012e-02,  6.1133411e-03, ...,\n",
            "          2.4242193e-01,  1.3426913e-01,  1.0000000e+00],\n",
            "        [ 1.2373582e-01,  2.8451550e-04,  2.5793161e-02, ...,\n",
            "          3.1896466e-01,  5.4023042e-03,  1.0000000e+00],\n",
            "        ...,\n",
            "        [-1.6516618e-01,  1.3702196e-01,  2.9848021e-01, ...,\n",
            "          5.9782147e-02, -2.1832708e-02,  1.0000000e+00],\n",
            "        [-2.5572056e-01,  1.1968662e-01,  3.4957141e-01, ...,\n",
            "          5.4363646e-02, -3.5256572e-02,  1.0000000e+00],\n",
            "        [-2.9595909e-01,  9.0229303e-02,  3.0506837e-01, ...,\n",
            "          4.4172578e-02, -1.2868345e-02,  1.0000000e+00]], dtype=float32)\n",
            " array([[-0.03057549, -0.1261732 , -0.03252254, ...,  0.05506857,\n",
            "          0.21024133,  1.        ],\n",
            "        [ 0.14234652, -0.06078416, -0.02405735, ...,  0.26073846,\n",
            "          0.14190546,  1.        ],\n",
            "        [ 0.12158645, -0.02929177, -0.01320717, ...,  0.35087442,\n",
            "          0.03070291,  1.        ],\n",
            "        ...,\n",
            "        [-0.18170585,  0.09308361,  0.28531864, ...,  0.0689342 ,\n",
            "         -0.02440346,  1.        ],\n",
            "        [-0.25776938,  0.07681671,  0.30298826, ...,  0.06920195,\n",
            "         -0.03744556,  1.        ],\n",
            "        [-0.28752953,  0.08477188,  0.28456563, ...,  0.04024294,\n",
            "         -0.01178728,  1.        ]], dtype=float32)\n",
            " array([[-2.16521826e-02, -1.24379955e-01, -2.83004567e-02, ...,\n",
            "          4.49961163e-02,  2.17681646e-01,  2.00000000e+00],\n",
            "        [ 1.28943697e-01, -4.29518819e-02,  7.41445785e-03, ...,\n",
            "          2.38837719e-01,  1.28419474e-01,  2.00000000e+00],\n",
            "        [ 1.27621904e-01,  8.78469460e-03,  2.89287046e-02, ...,\n",
            "          3.07635307e-01, -1.46974139e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-8.48503783e-02,  1.65329143e-01,  2.45311216e-01, ...,\n",
            "          4.96394932e-02,  1.46807136e-03,  2.00000000e+00],\n",
            "        [-2.30230734e-01,  1.46230236e-01,  3.38769972e-01, ...,\n",
            "          6.03447407e-02, -1.47278132e-02,  2.00000000e+00],\n",
            "        [-2.76556969e-01,  1.06460467e-01,  3.00331712e-01, ...,\n",
            "          6.02724589e-02,  1.69639837e-03,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 0.01771462, -0.12322646, -0.06016443, ...,  0.03161301,\n",
            "          0.20503506,  2.        ],\n",
            "        [ 0.19656147, -0.03725403, -0.04396763, ...,  0.21540035,\n",
            "          0.04364977,  2.        ],\n",
            "        [ 0.19227172, -0.0034365 , -0.04213199, ...,  0.28805137,\n",
            "         -0.09878466,  2.        ],\n",
            "        ...,\n",
            "        [ 0.09453948,  0.05956093,  0.06421281, ...,  0.03568175,\n",
            "          0.03979721,  2.        ],\n",
            "        [-0.13096334,  0.11658146,  0.29172167, ...,  0.09240992,\n",
            "         -0.0203534 ,  2.        ],\n",
            "        [-0.25615686,  0.07057275,  0.29703364, ...,  0.06380027,\n",
            "         -0.01098552,  2.        ]], dtype=float32)\n",
            " array([[-0.00940856, -0.11811146, -0.03850569, ...,  0.04148373,\n",
            "          0.21478526,  2.        ],\n",
            "        [ 0.14814214, -0.03345348, -0.00882314, ...,  0.23411106,\n",
            "          0.09903346,  2.        ],\n",
            "        [ 0.15193352,  0.01986231,  0.00542536, ...,  0.30406633,\n",
            "         -0.05430524,  2.        ],\n",
            "        ...,\n",
            "        [-0.0147634 ,  0.14166899,  0.1779722 , ...,  0.05593038,\n",
            "          0.01838861,  2.        ],\n",
            "        [-0.19936919,  0.14234343,  0.32685235, ...,  0.07632367,\n",
            "         -0.00528945,  2.        ],\n",
            "        [-0.2689462 ,  0.10016677,  0.29642436, ...,  0.06296925,\n",
            "         -0.00218344,  2.        ]], dtype=float32)\n",
            " array([[-1.7439984e-02, -1.2576729e-01, -3.2379061e-02, ...,\n",
            "          4.0128373e-02,  2.1102634e-01,  2.0000000e+00],\n",
            "        [ 1.3356075e-01, -3.3416897e-02, -1.0802641e-03, ...,\n",
            "          2.4026754e-01,  1.1624531e-01,  2.0000000e+00],\n",
            "        [ 1.3925493e-01,  2.3985025e-02,  1.5978027e-02, ...,\n",
            "          3.1106031e-01, -2.3938417e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [-6.6369481e-02,  1.4240567e-01,  2.2863573e-01, ...,\n",
            "          7.0993744e-02, -1.0777167e-03,  2.0000000e+00],\n",
            "        [-2.2607341e-01,  1.3679494e-01,  3.4739897e-01, ...,\n",
            "          6.7969956e-02, -2.1489609e-02,  2.0000000e+00],\n",
            "        [-2.8120437e-01,  1.0519021e-01,  3.0481455e-01, ...,\n",
            "          5.0925575e-02, -6.3045146e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.0181535 , -0.11942912, -0.03177118, ...,  0.04371729,\n",
            "          0.21196046,  2.        ],\n",
            "        [ 0.13386437, -0.0201572 , -0.00509214, ...,  0.23471062,\n",
            "          0.11396865,  2.        ],\n",
            "        [ 0.13753992,  0.04596335,  0.01611471, ...,  0.30321088,\n",
            "         -0.03360489,  2.        ],\n",
            "        ...,\n",
            "        [-0.02491086,  0.12889603,  0.18453178, ...,  0.03866118,\n",
            "          0.03023689,  2.        ],\n",
            "        [-0.21988583,  0.12522216,  0.34327367, ...,  0.05668213,\n",
            "         -0.00429071,  2.        ],\n",
            "        [-0.2756347 ,  0.10237519,  0.30355898, ...,  0.04970731,\n",
            "          0.00715294,  2.        ]], dtype=float32)\n",
            " array([[-2.98077408e-02, -1.18124507e-01, -3.09761781e-02, ...,\n",
            "          4.62581292e-02,  2.07570136e-01,  2.00000000e+00],\n",
            "        [ 1.25540137e-01, -5.71242981e-02, -1.36030382e-02, ...,\n",
            "          2.37518162e-01,  1.45618960e-01,  2.00000000e+00],\n",
            "        [ 1.06034435e-01, -2.84822546e-02, -1.98610639e-03, ...,\n",
            "          3.23634118e-01,  3.04004587e-02,  2.00000000e+00],\n",
            "        ...,\n",
            "        [-1.99928805e-01,  1.20400362e-01,  3.10013652e-01, ...,\n",
            "          7.14072362e-02, -2.60071326e-02,  2.00000000e+00],\n",
            "        [-2.75660485e-01,  1.03278458e-01,  3.36587220e-01, ...,\n",
            "          6.50465861e-02, -3.93897593e-02,  2.00000000e+00],\n",
            "        [-3.03846061e-01,  8.81144479e-02,  2.98411280e-01, ...,\n",
            "          3.64532582e-02, -1.77043285e-02,  2.00000000e+00]], dtype=float32)\n",
            " array([[ 0.02351593, -0.12999648, -0.06812561, ...,  0.02232722,\n",
            "          0.2049217 ,  2.        ],\n",
            "        [ 0.21197063, -0.05653523, -0.05171574, ...,  0.1955109 ,\n",
            "          0.0392524 ,  2.        ],\n",
            "        [ 0.2036758 , -0.01899466, -0.05699364, ...,  0.26482627,\n",
            "         -0.1000618 ,  2.        ],\n",
            "        ...,\n",
            "        [ 0.10411219,  0.02949269,  0.05648071, ...,  0.03761477,\n",
            "          0.02942531,  2.        ],\n",
            "        [-0.11461553,  0.08946176,  0.27408418, ...,  0.09375364,\n",
            "         -0.02924535,  2.        ],\n",
            "        [-0.26704398,  0.0543051 ,  0.29998714, ...,  0.06837266,\n",
            "         -0.00912711,  2.        ]], dtype=float32)\n",
            " array([[ 0.0204486 , -0.12591389, -0.06267533, ...,  0.0292809 ,\n",
            "          0.20478167,  2.        ],\n",
            "        [ 0.20845082, -0.05055865, -0.04413526, ...,  0.21006079,\n",
            "          0.0414988 ,  2.        ],\n",
            "        [ 0.20240946, -0.0164702 , -0.0473366 , ...,  0.2791815 ,\n",
            "         -0.09956154,  2.        ],\n",
            "        ...,\n",
            "        [ 0.09733602,  0.04530997,  0.07070564, ...,  0.04044342,\n",
            "          0.03086337,  2.        ],\n",
            "        [-0.12002558,  0.10147958,  0.28176424, ...,  0.09478126,\n",
            "         -0.02396359,  2.        ],\n",
            "        [-0.2618894 ,  0.06061262,  0.29995054, ...,  0.06853887,\n",
            "         -0.00829996,  2.        ]], dtype=float32)\n",
            " array([[ 8.8080391e-03, -1.1037350e-01, -5.7705875e-02, ...,\n",
            "          2.6457282e-02,  2.0534237e-01,  2.0000000e+00],\n",
            "        [ 1.6632560e-01, -8.0629382e-03, -3.6634117e-02, ...,\n",
            "          2.1619666e-01,  6.4027034e-02,  2.0000000e+00],\n",
            "        [ 1.8534662e-01,  4.4249620e-02, -3.7913952e-02, ...,\n",
            "          2.8136945e-01, -8.1633620e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 5.0508566e-02,  9.0617895e-02,  8.8341571e-02, ...,\n",
            "          2.7549496e-02,  6.1514221e-02,  2.0000000e+00],\n",
            "        [-1.5166837e-01,  1.3187896e-01,  3.0347478e-01, ...,\n",
            "          6.7019887e-02,  7.9187956e-03,  2.0000000e+00],\n",
            "        [-2.5054315e-01,  8.8717036e-02,  2.9750288e-01, ...,\n",
            "          4.8397657e-02,  1.7597520e-03,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.02985589, -0.15091431, -0.04131639, ...,  0.05785504,\n",
            "          0.21782055,  2.        ],\n",
            "        [ 0.16207206, -0.09266863, -0.04990289, ...,  0.2907874 ,\n",
            "          0.15435448,  2.        ],\n",
            "        [ 0.11983494, -0.08103272, -0.04728568, ...,  0.3815717 ,\n",
            "          0.0574152 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.14905308,  0.02744547,  0.23530063, ...,  0.09762163,\n",
            "         -0.005432  ,  2.        ],\n",
            "        [-0.22929038,  0.03544805,  0.25143263, ...,  0.08461349,\n",
            "         -0.0401009 ,  2.        ],\n",
            "        [-0.26574066,  0.03609638,  0.2641277 , ...,  0.04305689,\n",
            "         -0.01753476,  2.        ]], dtype=float32)\n",
            " array([[ 1.1721021e-03, -1.1035882e-01, -5.4334633e-02, ...,\n",
            "          2.4224363e-02,  2.0265210e-01,  2.0000000e+00],\n",
            "        [ 1.4893471e-01, -1.1675606e-02, -2.5375845e-02, ...,\n",
            "          2.1570927e-01,  6.8166681e-02,  2.0000000e+00],\n",
            "        [ 1.6980772e-01,  4.6951983e-02, -2.3690054e-02, ...,\n",
            "          2.8313529e-01, -7.8551784e-02,  2.0000000e+00],\n",
            "        ...,\n",
            "        [ 1.2747981e-02,  9.8542340e-02,  1.2402305e-01, ...,\n",
            "          3.8269583e-02,  4.4430416e-02,  2.0000000e+00],\n",
            "        [-1.7088847e-01,  1.2912992e-01,  3.0919069e-01, ...,\n",
            "          6.5966949e-02,  2.1187009e-03,  2.0000000e+00],\n",
            "        [-2.6152620e-01,  8.5802622e-02,  2.9994047e-01, ...,\n",
            "          4.3303024e-02,  5.6555844e-04,  2.0000000e+00]], dtype=float32)\n",
            " array([[-0.0319242 , -0.14433105, -0.0397898 , ...,  0.05530023,\n",
            "          0.2165835 ,  2.        ],\n",
            "        [ 0.15252735, -0.08626097, -0.04590916, ...,  0.28079224,\n",
            "          0.15828434,  2.        ],\n",
            "        [ 0.10846865, -0.07778811, -0.04287074, ...,  0.3720244 ,\n",
            "          0.06473368,  2.        ],\n",
            "        ...,\n",
            "        [-0.17438585,  0.03390529,  0.25447544, ...,  0.09446078,\n",
            "         -0.01514184,  2.        ],\n",
            "        [-0.254931  ,  0.04028466,  0.2646416 , ...,  0.08090619,\n",
            "         -0.04621978,  2.        ],\n",
            "        [-0.2785306 ,  0.04549032,  0.27251962, ...,  0.03719036,\n",
            "         -0.0183555 ,  2.        ]], dtype=float32)\n",
            " array([[-0.03034768, -0.1538098 , -0.04494685, ...,  0.05127459,\n",
            "          0.21439981,  2.        ],\n",
            "        [ 0.15020753, -0.09530021, -0.05730467, ...,  0.2756294 ,\n",
            "          0.15845267,  2.        ],\n",
            "        [ 0.10306699, -0.08934545, -0.05885244, ...,  0.36712998,\n",
            "          0.0681018 ,  2.        ],\n",
            "        ...,\n",
            "        [-0.15433931,  0.00943076,  0.2309559 , ...,  0.08852749,\n",
            "         -0.00461355,  2.        ],\n",
            "        [-0.23185572,  0.01601072,  0.24498136, ...,  0.07377378,\n",
            "         -0.03465028,  2.        ],\n",
            "        [-0.266517  ,  0.02555505,  0.25792494, ...,  0.03254553,\n",
            "         -0.02100279,  2.        ]], dtype=float32)              ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/data.npy', combined_data)"
      ],
      "metadata": {
        "id": "g76O5KmTHBqd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define the maximum length you want\n",
        "max_length = 117\n",
        "\n",
        "# Truncate sequences longer than max_length and pad sequences shorter than max_length\n",
        "padded_sequences = pad_sequences(combined_data, maxlen=max_length, truncating='post', padding='post', dtype='float32')\n",
        "\n",
        "# Stack the padded sequences into a single numpy array\n",
        "X = np.stack(padded_sequences)"
      ],
      "metadata": {
        "id": "0w8KItoqIOc4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = X[:, :, -1]  # Assuming -1 is the index of the last column\n",
        "\n",
        "# Remove the last column from X to get the features\n",
        "X = X[:, :, :-1]"
      ],
      "metadata": {
        "id": "7bebh7liJG3_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.amax(y, axis=1)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "8S1g4dbSbOWG",
        "outputId": "4e9be7d0-b8e5-472a-9fe4-eab53f72254e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(656,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the class distribution\n",
        "class_distribution = np.bincount(y.astype(int))\n",
        "\n",
        "# Print the class distribution\n",
        "print(\"Class Distribution:\")\n",
        "for class_label, count in enumerate(class_distribution):\n",
        "    print(f\"Class {class_label}: {count} samples\")\n"
      ],
      "metadata": {
        "id": "va7W7B0jJfIS",
        "outputId": "82ba4375-9427-4d77-bd76-feb239561298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "Class 0: 167 samples\n",
            "Class 1: 182 samples\n",
            "Class 2: 164 samples\n",
            "Class 3: 143 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the class distribution\n",
        "plt.bar(range(len(class_distribution)), class_distribution)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Class Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uIfkpUZwzyoD",
        "outputId": "b80f2105-9470-4ae7-96a6-a6b110adadf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "fI7BAGV5IRs7",
        "outputId": "2b8e5958-f188-4cfe-89ab-5f17634e5e68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1., 0., 2.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 0., 3., 3., 2., 2., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "       3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "       3., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming you have already loaded and preprocessed your data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Define LSTM model with dropout\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))  # LSTM layer with dropout\n",
        "model.add(Dense(units=4, activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, batch_size=64, epochs=250)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Extract the class with the highest probability for each sample\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "class_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3']  # Define class names based on your problem\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "SQa_RFYJ0VvP",
        "outputId": "6eef80a4-a028-4dfb-bc42-2d9bb94d766c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (524, 117, 768)\n",
            "X_test shape: (132, 117, 768)\n",
            "y_train shape: (524,)\n",
            "y_test shape: (132,)\n",
            "Epoch 1/250\n",
            "5/5 [==============================] - 10s 354ms/step - loss: 1.4091 - accuracy: 0.2634\n",
            "Epoch 2/250\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 1.3791 - accuracy: 0.3244\n",
            "Epoch 3/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.3876 - accuracy: 0.2920\n",
            "Epoch 4/250\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 1.3598 - accuracy: 0.3378\n",
            "Epoch 5/250\n",
            "5/5 [==============================] - 3s 516ms/step - loss: 1.3704 - accuracy: 0.3263\n",
            "Epoch 6/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.3692 - accuracy: 0.3206\n",
            "Epoch 7/250\n",
            "5/5 [==============================] - 2s 328ms/step - loss: 1.3541 - accuracy: 0.3359\n",
            "Epoch 8/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.3524 - accuracy: 0.3416\n",
            "Epoch 9/250\n",
            "5/5 [==============================] - 2s 344ms/step - loss: 1.3485 - accuracy: 0.3454\n",
            "Epoch 10/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.3352 - accuracy: 0.3531\n",
            "Epoch 11/250\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 1.3334 - accuracy: 0.3607\n",
            "Epoch 12/250\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 1.3368 - accuracy: 0.3645\n",
            "Epoch 13/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.3303 - accuracy: 0.3531\n",
            "Epoch 14/250\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 1.3289 - accuracy: 0.3511\n",
            "Epoch 15/250\n",
            "5/5 [==============================] - 2s 343ms/step - loss: 1.3353 - accuracy: 0.3416\n",
            "Epoch 16/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.3286 - accuracy: 0.3492\n",
            "Epoch 17/250\n",
            "5/5 [==============================] - 2s 352ms/step - loss: 1.3312 - accuracy: 0.3511\n",
            "Epoch 18/250\n",
            "5/5 [==============================] - 2s 444ms/step - loss: 1.3259 - accuracy: 0.3664\n",
            "Epoch 19/250\n",
            "5/5 [==============================] - 3s 624ms/step - loss: 1.3238 - accuracy: 0.3531\n",
            "Epoch 20/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.3345 - accuracy: 0.3473\n",
            "Epoch 21/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.3248 - accuracy: 0.3721\n",
            "Epoch 22/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.3190 - accuracy: 0.3721\n",
            "Epoch 23/250\n",
            "5/5 [==============================] - 2s 343ms/step - loss: 1.3265 - accuracy: 0.3626\n",
            "Epoch 24/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.3149 - accuracy: 0.3626\n",
            "Epoch 25/250\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 1.3098 - accuracy: 0.3912\n",
            "Epoch 26/250\n",
            "5/5 [==============================] - 3s 596ms/step - loss: 1.3106 - accuracy: 0.3740\n",
            "Epoch 27/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.3027 - accuracy: 0.3836\n",
            "Epoch 28/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.3052 - accuracy: 0.3760\n",
            "Epoch 29/250\n",
            "5/5 [==============================] - 2s 351ms/step - loss: 1.3096 - accuracy: 0.3645\n",
            "Epoch 30/250\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 1.3056 - accuracy: 0.3798\n",
            "Epoch 31/250\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 1.2958 - accuracy: 0.3702\n",
            "Epoch 32/250\n",
            "5/5 [==============================] - 2s 345ms/step - loss: 1.2909 - accuracy: 0.3740\n",
            "Epoch 33/250\n",
            "5/5 [==============================] - 3s 617ms/step - loss: 1.2997 - accuracy: 0.3817\n",
            "Epoch 34/250\n",
            "5/5 [==============================] - 2s 380ms/step - loss: 1.3113 - accuracy: 0.3683\n",
            "Epoch 35/250\n",
            "5/5 [==============================] - 2s 345ms/step - loss: 1.2954 - accuracy: 0.3969\n",
            "Epoch 36/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.2765 - accuracy: 0.3874\n",
            "Epoch 37/250\n",
            "5/5 [==============================] - 2s 537ms/step - loss: 1.2885 - accuracy: 0.3817\n",
            "Epoch 38/250\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 1.2760 - accuracy: 0.3817\n",
            "Epoch 39/250\n",
            "5/5 [==============================] - 3s 613ms/step - loss: 1.2740 - accuracy: 0.4027\n",
            "Epoch 40/250\n",
            "5/5 [==============================] - 2s 359ms/step - loss: 1.3404 - accuracy: 0.3721\n",
            "Epoch 41/250\n",
            "5/5 [==============================] - 2s 344ms/step - loss: 1.3199 - accuracy: 0.3721\n",
            "Epoch 42/250\n",
            "5/5 [==============================] - 2s 338ms/step - loss: 1.3083 - accuracy: 0.3855\n",
            "Epoch 43/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.3036 - accuracy: 0.3893\n",
            "Epoch 44/250\n",
            "5/5 [==============================] - 2s 345ms/step - loss: 1.2986 - accuracy: 0.3721\n",
            "Epoch 45/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.2846 - accuracy: 0.3855\n",
            "Epoch 46/250\n",
            "5/5 [==============================] - 3s 638ms/step - loss: 1.3077 - accuracy: 0.3817\n",
            "Epoch 47/250\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 1.3085 - accuracy: 0.3855\n",
            "Epoch 48/250\n",
            "5/5 [==============================] - 2s 353ms/step - loss: 1.3190 - accuracy: 0.3683\n",
            "Epoch 49/250\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 1.2992 - accuracy: 0.3969\n",
            "Epoch 50/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.3046 - accuracy: 0.3683\n",
            "Epoch 51/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.2897 - accuracy: 0.3931\n",
            "Epoch 52/250\n",
            "5/5 [==============================] - 2s 346ms/step - loss: 1.2929 - accuracy: 0.4237\n",
            "Epoch 53/250\n",
            "5/5 [==============================] - 3s 619ms/step - loss: 1.3034 - accuracy: 0.3931\n",
            "Epoch 54/250\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 1.2868 - accuracy: 0.4065\n",
            "Epoch 55/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.2908 - accuracy: 0.3912\n",
            "Epoch 56/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.2887 - accuracy: 0.3836\n",
            "Epoch 57/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.3043 - accuracy: 0.3702\n",
            "Epoch 58/250\n",
            "5/5 [==============================] - 2s 338ms/step - loss: 1.2920 - accuracy: 0.4027\n",
            "Epoch 59/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.2870 - accuracy: 0.4027\n",
            "Epoch 60/250\n",
            "5/5 [==============================] - 3s 632ms/step - loss: 1.2775 - accuracy: 0.3989\n",
            "Epoch 61/250\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 1.2734 - accuracy: 0.4008\n",
            "Epoch 62/250\n",
            "5/5 [==============================] - 2s 344ms/step - loss: 1.2684 - accuracy: 0.4160\n",
            "Epoch 63/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.2688 - accuracy: 0.4103\n",
            "Epoch 64/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.2764 - accuracy: 0.4084\n",
            "Epoch 65/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.2932 - accuracy: 0.3893\n",
            "Epoch 66/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.2736 - accuracy: 0.4103\n",
            "Epoch 67/250\n",
            "5/5 [==============================] - 3s 569ms/step - loss: 1.2748 - accuracy: 0.4027\n",
            "Epoch 68/250\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 1.2664 - accuracy: 0.4027\n",
            "Epoch 69/250\n",
            "5/5 [==============================] - 2s 344ms/step - loss: 1.2548 - accuracy: 0.4237\n",
            "Epoch 70/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.2524 - accuracy: 0.4237\n",
            "Epoch 71/250\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 1.2563 - accuracy: 0.4065\n",
            "Epoch 72/250\n",
            "5/5 [==============================] - 2s 343ms/step - loss: 1.2665 - accuracy: 0.4065\n",
            "Epoch 73/250\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 1.2544 - accuracy: 0.4027\n",
            "Epoch 74/250\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 1.2673 - accuracy: 0.3989\n",
            "Epoch 75/250\n",
            "5/5 [==============================] - 3s 583ms/step - loss: 1.2433 - accuracy: 0.4237\n",
            "Epoch 76/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.2496 - accuracy: 0.4160\n",
            "Epoch 77/250\n",
            "5/5 [==============================] - 2s 345ms/step - loss: 1.2406 - accuracy: 0.4218\n",
            "Epoch 78/250\n",
            "5/5 [==============================] - 2s 340ms/step - loss: 1.2556 - accuracy: 0.3931\n",
            "Epoch 79/250\n",
            "5/5 [==============================] - 2s 340ms/step - loss: 1.2412 - accuracy: 0.4179\n",
            "Epoch 80/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.2423 - accuracy: 0.4008\n",
            "Epoch 81/250\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 1.2241 - accuracy: 0.4389\n",
            "Epoch 82/250\n",
            "5/5 [==============================] - 3s 605ms/step - loss: 1.2507 - accuracy: 0.4046\n",
            "Epoch 83/250\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 1.2291 - accuracy: 0.4065\n",
            "Epoch 84/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.2273 - accuracy: 0.4389\n",
            "Epoch 85/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.2633 - accuracy: 0.3989\n",
            "Epoch 86/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.2641 - accuracy: 0.4103\n",
            "Epoch 87/250\n",
            "5/5 [==============================] - 2s 349ms/step - loss: 1.2487 - accuracy: 0.4065\n",
            "Epoch 88/250\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 1.2543 - accuracy: 0.4198\n",
            "Epoch 89/250\n",
            "5/5 [==============================] - 3s 630ms/step - loss: 1.2480 - accuracy: 0.4141\n",
            "Epoch 90/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.2413 - accuracy: 0.4160\n",
            "Epoch 91/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.2392 - accuracy: 0.4218\n",
            "Epoch 92/250\n",
            "5/5 [==============================] - 2s 344ms/step - loss: 1.2445 - accuracy: 0.4218\n",
            "Epoch 93/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.2379 - accuracy: 0.4198\n",
            "Epoch 94/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.2379 - accuracy: 0.4160\n",
            "Epoch 95/250\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 1.2326 - accuracy: 0.4275\n",
            "Epoch 96/250\n",
            "5/5 [==============================] - 3s 617ms/step - loss: 1.2212 - accuracy: 0.4485\n",
            "Epoch 97/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.2224 - accuracy: 0.4427\n",
            "Epoch 98/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.2270 - accuracy: 0.4332\n",
            "Epoch 99/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.2184 - accuracy: 0.4408\n",
            "Epoch 100/250\n",
            "5/5 [==============================] - 2s 344ms/step - loss: 1.2105 - accuracy: 0.4275\n",
            "Epoch 101/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.2047 - accuracy: 0.4256\n",
            "Epoch 102/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.2028 - accuracy: 0.4218\n",
            "Epoch 103/250\n",
            "5/5 [==============================] - 3s 590ms/step - loss: 1.1988 - accuracy: 0.4313\n",
            "Epoch 104/250\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 1.2049 - accuracy: 0.4370\n",
            "Epoch 105/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.2292 - accuracy: 0.4256\n",
            "Epoch 106/250\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 1.2273 - accuracy: 0.4122\n",
            "Epoch 107/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.2234 - accuracy: 0.4408\n",
            "Epoch 108/250\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 1.2330 - accuracy: 0.4332\n",
            "Epoch 109/250\n",
            "5/5 [==============================] - 2s 340ms/step - loss: 1.2213 - accuracy: 0.4332\n",
            "Epoch 110/250\n",
            "5/5 [==============================] - 3s 560ms/step - loss: 1.2193 - accuracy: 0.4275\n",
            "Epoch 111/250\n",
            "5/5 [==============================] - 3s 482ms/step - loss: 1.2271 - accuracy: 0.4179\n",
            "Epoch 112/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.2027 - accuracy: 0.4447\n",
            "Epoch 113/250\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 1.1987 - accuracy: 0.4447\n",
            "Epoch 114/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.2277 - accuracy: 0.4332\n",
            "Epoch 115/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.2070 - accuracy: 0.4351\n",
            "Epoch 116/250\n",
            "5/5 [==============================] - 2s 344ms/step - loss: 1.1886 - accuracy: 0.4561\n",
            "Epoch 117/250\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 1.1931 - accuracy: 0.4389\n",
            "Epoch 118/250\n",
            "5/5 [==============================] - 3s 579ms/step - loss: 1.2044 - accuracy: 0.4275\n",
            "Epoch 119/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.1960 - accuracy: 0.4408\n",
            "Epoch 120/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.2220 - accuracy: 0.4179\n",
            "Epoch 121/250\n",
            "5/5 [==============================] - 2s 374ms/step - loss: 1.2634 - accuracy: 0.4122\n",
            "Epoch 122/250\n",
            "5/5 [==============================] - 3s 620ms/step - loss: 1.2402 - accuracy: 0.4332\n",
            "Epoch 123/250\n",
            "5/5 [==============================] - 3s 464ms/step - loss: 1.2268 - accuracy: 0.4313\n",
            "Epoch 124/250\n",
            "5/5 [==============================] - 3s 592ms/step - loss: 1.2313 - accuracy: 0.4218\n",
            "Epoch 125/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.2223 - accuracy: 0.4466\n",
            "Epoch 126/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.2044 - accuracy: 0.4580\n",
            "Epoch 127/250\n",
            "5/5 [==============================] - 2s 345ms/step - loss: 1.2065 - accuracy: 0.4332\n",
            "Epoch 128/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.2099 - accuracy: 0.4332\n",
            "Epoch 129/250\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 1.1990 - accuracy: 0.4580\n",
            "Epoch 130/250\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 1.1957 - accuracy: 0.4618\n",
            "Epoch 131/250\n",
            "5/5 [==============================] - 3s 579ms/step - loss: 1.2012 - accuracy: 0.4370\n",
            "Epoch 132/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.2114 - accuracy: 0.4313\n",
            "Epoch 133/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.1855 - accuracy: 0.4447\n",
            "Epoch 134/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.2391 - accuracy: 0.4294\n",
            "Epoch 135/250\n",
            "5/5 [==============================] - 2s 338ms/step - loss: 1.2197 - accuracy: 0.4237\n",
            "Epoch 136/250\n",
            "5/5 [==============================] - 2s 343ms/step - loss: 1.2404 - accuracy: 0.4103\n",
            "Epoch 137/250\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 1.2060 - accuracy: 0.4313\n",
            "Epoch 138/250\n",
            "5/5 [==============================] - 3s 605ms/step - loss: 1.2379 - accuracy: 0.4084\n",
            "Epoch 139/250\n",
            "5/5 [==============================] - 2s 328ms/step - loss: 1.2088 - accuracy: 0.4485\n",
            "Epoch 140/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.2124 - accuracy: 0.4408\n",
            "Epoch 141/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.1892 - accuracy: 0.4447\n",
            "Epoch 142/250\n",
            "5/5 [==============================] - 2s 342ms/step - loss: 1.2147 - accuracy: 0.4389\n",
            "Epoch 143/250\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 1.1957 - accuracy: 0.4389\n",
            "Epoch 144/250\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 1.2021 - accuracy: 0.4408\n",
            "Epoch 145/250\n",
            "5/5 [==============================] - 3s 585ms/step - loss: 1.1960 - accuracy: 0.4389\n",
            "Epoch 146/250\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 1.1906 - accuracy: 0.4427\n",
            "Epoch 147/250\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 1.1826 - accuracy: 0.4637\n",
            "Epoch 148/250\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 1.2181 - accuracy: 0.4122\n",
            "Epoch 149/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.1948 - accuracy: 0.4447\n",
            "Epoch 150/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.1903 - accuracy: 0.4351\n",
            "Epoch 151/250\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 1.1854 - accuracy: 0.4656\n",
            "Epoch 152/250\n",
            "5/5 [==============================] - 2s 536ms/step - loss: 1.1797 - accuracy: 0.4599\n",
            "Epoch 153/250\n",
            "5/5 [==============================] - 3s 521ms/step - loss: 1.1768 - accuracy: 0.4561\n",
            "Epoch 154/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.2225 - accuracy: 0.4370\n",
            "Epoch 155/250\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 1.1928 - accuracy: 0.4523\n",
            "Epoch 156/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.2401 - accuracy: 0.4160\n",
            "Epoch 157/250\n",
            "5/5 [==============================] - 2s 340ms/step - loss: 1.1989 - accuracy: 0.4389\n",
            "Epoch 158/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.2009 - accuracy: 0.4370\n",
            "Epoch 159/250\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 1.1959 - accuracy: 0.4466\n",
            "Epoch 160/250\n",
            "5/5 [==============================] - 3s 579ms/step - loss: 1.1858 - accuracy: 0.4580\n",
            "Epoch 161/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.1810 - accuracy: 0.4523\n",
            "Epoch 162/250\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 1.1756 - accuracy: 0.4561\n",
            "Epoch 163/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.1820 - accuracy: 0.4561\n",
            "Epoch 164/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.1852 - accuracy: 0.4332\n",
            "Epoch 165/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.1777 - accuracy: 0.4580\n",
            "Epoch 166/250\n",
            "5/5 [==============================] - 2s 420ms/step - loss: 1.1594 - accuracy: 0.4676\n",
            "Epoch 167/250\n",
            "5/5 [==============================] - 3s 599ms/step - loss: 1.1671 - accuracy: 0.4485\n",
            "Epoch 168/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.1660 - accuracy: 0.4542\n",
            "Epoch 169/250\n",
            "5/5 [==============================] - 2s 343ms/step - loss: 1.1600 - accuracy: 0.4523\n",
            "Epoch 170/250\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 1.1921 - accuracy: 0.4447\n",
            "Epoch 171/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.1586 - accuracy: 0.4847\n",
            "Epoch 172/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.1673 - accuracy: 0.4580\n",
            "Epoch 173/250\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 1.1975 - accuracy: 0.4466\n",
            "Epoch 174/250\n",
            "5/5 [==============================] - 3s 620ms/step - loss: 1.1941 - accuracy: 0.4370\n",
            "Epoch 175/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.1622 - accuracy: 0.4714\n",
            "Epoch 176/250\n",
            "5/5 [==============================] - 2s 321ms/step - loss: 1.2350 - accuracy: 0.4141\n",
            "Epoch 177/250\n",
            "5/5 [==============================] - 2s 350ms/step - loss: 1.1792 - accuracy: 0.4580\n",
            "Epoch 178/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.1756 - accuracy: 0.4561\n",
            "Epoch 179/250\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 1.1429 - accuracy: 0.4885\n",
            "Epoch 180/250\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 1.1472 - accuracy: 0.4847\n",
            "Epoch 181/250\n",
            "5/5 [==============================] - 3s 584ms/step - loss: 1.1419 - accuracy: 0.4905\n",
            "Epoch 182/250\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 1.1562 - accuracy: 0.4523\n",
            "Epoch 183/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.1385 - accuracy: 0.4962\n",
            "Epoch 184/250\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 1.1336 - accuracy: 0.4924\n",
            "Epoch 185/250\n",
            "5/5 [==============================] - 2s 328ms/step - loss: 1.1521 - accuracy: 0.4790\n",
            "Epoch 186/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.1603 - accuracy: 0.4523\n",
            "Epoch 187/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.1697 - accuracy: 0.4599\n",
            "Epoch 188/250\n",
            "5/5 [==============================] - 3s 597ms/step - loss: 1.1692 - accuracy: 0.4504\n",
            "Epoch 189/250\n",
            "5/5 [==============================] - 2s 425ms/step - loss: 1.1600 - accuracy: 0.4599\n",
            "Epoch 190/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.1614 - accuracy: 0.4618\n",
            "Epoch 191/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.1520 - accuracy: 0.4656\n",
            "Epoch 192/250\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 1.1457 - accuracy: 0.4752\n",
            "Epoch 193/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.1409 - accuracy: 0.4828\n",
            "Epoch 194/250\n",
            "5/5 [==============================] - 2s 341ms/step - loss: 1.1413 - accuracy: 0.4828\n",
            "Epoch 195/250\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 1.1814 - accuracy: 0.4466\n",
            "Epoch 196/250\n",
            "5/5 [==============================] - 3s 511ms/step - loss: 1.2135 - accuracy: 0.4351\n",
            "Epoch 197/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.2241 - accuracy: 0.4294\n",
            "Epoch 198/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.2032 - accuracy: 0.4447\n",
            "Epoch 199/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.1937 - accuracy: 0.4427\n",
            "Epoch 200/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.1917 - accuracy: 0.4485\n",
            "Epoch 201/250\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 1.1668 - accuracy: 0.4504\n",
            "Epoch 202/250\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 1.1590 - accuracy: 0.4924\n",
            "Epoch 203/250\n",
            "5/5 [==============================] - 3s 576ms/step - loss: 1.1496 - accuracy: 0.4752\n",
            "Epoch 204/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.1421 - accuracy: 0.4790\n",
            "Epoch 205/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.1962 - accuracy: 0.4370\n",
            "Epoch 206/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.1690 - accuracy: 0.4523\n",
            "Epoch 207/250\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 1.1682 - accuracy: 0.4714\n",
            "Epoch 208/250\n",
            "5/5 [==============================] - 3s 630ms/step - loss: 1.1688 - accuracy: 0.4485\n",
            "Epoch 209/250\n",
            "5/5 [==============================] - 3s 599ms/step - loss: 1.1614 - accuracy: 0.4676\n",
            "Epoch 210/250\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 1.1834 - accuracy: 0.4637\n",
            "Epoch 211/250\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 1.2137 - accuracy: 0.4198\n",
            "Epoch 212/250\n",
            "5/5 [==============================] - 2s 338ms/step - loss: 1.1994 - accuracy: 0.4427\n",
            "Epoch 213/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.1576 - accuracy: 0.4656\n",
            "Epoch 214/250\n",
            "5/5 [==============================] - 2s 329ms/step - loss: 1.1680 - accuracy: 0.4714\n",
            "Epoch 215/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.1684 - accuracy: 0.4847\n",
            "Epoch 216/250\n",
            "5/5 [==============================] - 3s 612ms/step - loss: 1.1737 - accuracy: 0.4447\n",
            "Epoch 217/250\n",
            "5/5 [==============================] - 2s 381ms/step - loss: 1.1558 - accuracy: 0.4656\n",
            "Epoch 218/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.1500 - accuracy: 0.4656\n",
            "Epoch 219/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.1535 - accuracy: 0.4790\n",
            "Epoch 220/250\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 1.1220 - accuracy: 0.4962\n",
            "Epoch 221/250\n",
            "5/5 [==============================] - 2s 327ms/step - loss: 1.1120 - accuracy: 0.4981\n",
            "Epoch 222/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.1064 - accuracy: 0.5248\n",
            "Epoch 223/250\n",
            "5/5 [==============================] - 3s 541ms/step - loss: 1.1176 - accuracy: 0.5019\n",
            "Epoch 224/250\n",
            "5/5 [==============================] - 2s 460ms/step - loss: 1.1235 - accuracy: 0.5076\n",
            "Epoch 225/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.1138 - accuracy: 0.5057\n",
            "Epoch 226/250\n",
            "5/5 [==============================] - 2s 335ms/step - loss: 1.1082 - accuracy: 0.5019\n",
            "Epoch 227/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.1056 - accuracy: 0.4885\n",
            "Epoch 228/250\n",
            "5/5 [==============================] - 2s 355ms/step - loss: 1.0942 - accuracy: 0.4962\n",
            "Epoch 229/250\n",
            "5/5 [==============================] - 2s 332ms/step - loss: 1.0978 - accuracy: 0.5401\n",
            "Epoch 230/250\n",
            "5/5 [==============================] - 2s 501ms/step - loss: 1.0859 - accuracy: 0.5324\n",
            "Epoch 231/250\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 1.1117 - accuracy: 0.5038\n",
            "Epoch 232/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.0748 - accuracy: 0.5210\n",
            "Epoch 233/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.1096 - accuracy: 0.4905\n",
            "Epoch 234/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.2336 - accuracy: 0.4427\n",
            "Epoch 235/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.1073 - accuracy: 0.4752\n",
            "Epoch 236/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.1369 - accuracy: 0.4656\n",
            "Epoch 237/250\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 1.1221 - accuracy: 0.4962\n",
            "Epoch 238/250\n",
            "5/5 [==============================] - 3s 581ms/step - loss: 1.1344 - accuracy: 0.4695\n",
            "Epoch 239/250\n",
            "5/5 [==============================] - 2s 336ms/step - loss: 1.1121 - accuracy: 0.5057\n",
            "Epoch 240/250\n",
            "5/5 [==============================] - 2s 339ms/step - loss: 1.1063 - accuracy: 0.5019\n",
            "Epoch 241/250\n",
            "5/5 [==============================] - 2s 331ms/step - loss: 1.1156 - accuracy: 0.4885\n",
            "Epoch 242/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.1155 - accuracy: 0.4943\n",
            "Epoch 243/250\n",
            "5/5 [==============================] - 2s 334ms/step - loss: 1.1429 - accuracy: 0.4809\n",
            "Epoch 244/250\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 1.0961 - accuracy: 0.5076\n",
            "Epoch 245/250\n",
            "5/5 [==============================] - 3s 608ms/step - loss: 1.0762 - accuracy: 0.5344\n",
            "Epoch 246/250\n",
            "5/5 [==============================] - 2s 348ms/step - loss: 1.0726 - accuracy: 0.5267\n",
            "Epoch 247/250\n",
            "5/5 [==============================] - 2s 337ms/step - loss: 1.0842 - accuracy: 0.5172\n",
            "Epoch 248/250\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 1.0593 - accuracy: 0.5401\n",
            "Epoch 249/250\n",
            "5/5 [==============================] - 2s 344ms/step - loss: 1.0599 - accuracy: 0.5305\n",
            "Epoch 250/250\n",
            "5/5 [==============================] - 2s 328ms/step - loss: 1.0473 - accuracy: 0.5210\n",
            "5/5 [==============================] - 1s 51ms/step - loss: 1.4839 - accuracy: 0.3485\n",
            "Test Loss: 1.483886957168579, Test Accuracy: 0.3484848439693451\n",
            "5/5 [==============================] - 0s 38ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.49      0.47      0.48        36\n",
            "     Class 1       0.30      0.55      0.39        29\n",
            "     Class 2       0.45      0.19      0.27        47\n",
            "     Class 3       0.17      0.20      0.19        20\n",
            "\n",
            "    accuracy                           0.35       132\n",
            "   macro avg       0.35      0.35      0.33       132\n",
            "weighted avg       0.38      0.35      0.34       132\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EmotionClassifier(feature_dim, hidden_dim, num_classes).to(device)"
      ],
      "metadata": {
        "id": "6qXp_DZp0mbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay_epoch epochs\"\"\"\n",
        "    lr = initial_lr * (0.1**(epoch // lr_decay_epoch))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "def train_model(num_epochs, initial_lr=0.001, lr_decay_epoch=3):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epoch)\n",
        "        for features, labels in loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Optional: Print average gradients per epoch to check for vanishing/exploding gradients\n",
        "        avg_gradients = {name: torch.mean(param.grad.abs()).item() for name, param in model.named_parameters() if param.grad is not None}\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(loader)}, Avg Gradients: {avg_gradients}\")\n",
        "\n",
        "        # Check for NaN loss\n",
        "        if torch.isnan(loss).any():\n",
        "            print(\"NaN loss detected\")\n",
        "            break\n",
        "\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "I1nsJZ3a0oqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(50)\n",
        "evaluate_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqi6fr7x0s80",
        "outputId": "23427e20-2fe2-4ea7-988d-0c425ea6717c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7050982117652893, Avg Gradients: {'lstm.weight_ih_l0': 0.00015319950762204826, 'lstm.weight_hh_l0': 0.0001138313818955794, 'lstm.bias_ih_l0': 0.00045707906247116625, 'lstm.bias_hh_l0': 0.00045707906247116625, 'classifier.weight': 0.010660267435014248, 'classifier.bias': 0.004405215382575989}\n",
            "Epoch 2, Loss: 0.6446354389190674, Avg Gradients: {'lstm.weight_ih_l0': 0.00011407291458453983, 'lstm.weight_hh_l0': 9.138100722339004e-05, 'lstm.bias_ih_l0': 0.0005290161934681237, 'lstm.bias_hh_l0': 0.0005290161934681237, 'classifier.weight': 0.010138976387679577, 'classifier.bias': 0.028205230832099915}\n",
            "Epoch 3, Loss: 0.6003038883209229, Avg Gradients: {'lstm.weight_ih_l0': 8.434417395619676e-05, 'lstm.weight_hh_l0': 8.907501614885405e-05, 'lstm.bias_ih_l0': 0.0007479123887605965, 'lstm.bias_hh_l0': 0.0007479123887605965, 'classifier.weight': 0.010165289044380188, 'classifier.bias': 0.055923957377672195}\n",
            "Epoch 4, Loss: 0.5680534839630127, Avg Gradients: {'lstm.weight_ih_l0': 5.7642406318336725e-05, 'lstm.weight_hh_l0': 8.380445069633424e-05, 'lstm.bias_ih_l0': 0.0009154333965852857, 'lstm.bias_hh_l0': 0.0009154333965852857, 'classifier.weight': 0.009360942989587784, 'classifier.bias': 0.07788243889808655}\n",
            "Epoch 5, Loss: 0.5654211640357971, Avg Gradients: {'lstm.weight_ih_l0': 5.526038512471132e-05, 'lstm.weight_hh_l0': 8.30204226076603e-05, 'lstm.bias_ih_l0': 0.0009281523525714874, 'lstm.bias_hh_l0': 0.0009281523525714874, 'classifier.weight': 0.009229740127921104, 'classifier.bias': 0.0796666294336319}\n",
            "Epoch 6, Loss: 0.5628683567047119, Avg Gradients: {'lstm.weight_ih_l0': 5.2991508709965274e-05, 'lstm.weight_hh_l0': 8.228303340729326e-05, 'lstm.bias_ih_l0': 0.0009401073330081999, 'lstm.bias_hh_l0': 0.0009401073330081999, 'classifier.weight': 0.009092732332646847, 'classifier.bias': 0.08135106414556503}\n",
            "Epoch 7, Loss: 0.5603942275047302, Avg Gradients: {'lstm.weight_ih_l0': 5.0801823817892e-05, 'lstm.weight_hh_l0': 8.154720126185566e-05, 'lstm.bias_ih_l0': 0.0009514251141808927, 'lstm.bias_hh_l0': 0.0009514251141808927, 'classifier.weight': 0.008949346840381622, 'classifier.bias': 0.08294837176799774}\n",
            "Epoch 8, Loss: 0.5601511597633362, Avg Gradients: {'lstm.weight_ih_l0': 5.058874376118183e-05, 'lstm.weight_hh_l0': 8.14757077023387e-05, 'lstm.bias_ih_l0': 0.0009525122586637735, 'lstm.bias_hh_l0': 0.0009525122586637735, 'classifier.weight': 0.008934767916798592, 'classifier.bias': 0.08310237526893616}\n",
            "Epoch 9, Loss: 0.5599085688591003, Avg Gradients: {'lstm.weight_ih_l0': 5.037964365328662e-05, 'lstm.weight_hh_l0': 8.140889985952526e-05, 'lstm.bias_ih_l0': 0.000953582813963294, 'lstm.bias_hh_l0': 0.000953582813963294, 'classifier.weight': 0.008920280262827873, 'classifier.bias': 0.0832539051771164}\n",
            "Epoch 10, Loss: 0.559666633605957, Avg Gradients: {'lstm.weight_ih_l0': 5.017354851588607e-05, 'lstm.weight_hh_l0': 8.134573727147654e-05, 'lstm.bias_ih_l0': 0.0009546603541821241, 'lstm.bias_hh_l0': 0.0009546603541821241, 'classifier.weight': 0.008905836381018162, 'classifier.bias': 0.08340348303318024}\n",
            "Epoch 11, Loss: 0.5596424341201782, Avg Gradients: {'lstm.weight_ih_l0': 5.0153186748502776e-05, 'lstm.weight_hh_l0': 8.133973460644484e-05, 'lstm.bias_ih_l0': 0.0009547670488245785, 'lstm.bias_hh_l0': 0.0009547670488245785, 'classifier.weight': 0.008904400281608105, 'classifier.bias': 0.08341828733682632}\n",
            "Epoch 12, Loss: 0.5596181750297546, Avg Gradients: {'lstm.weight_ih_l0': 5.01329886901658e-05, 'lstm.weight_hh_l0': 8.133399387588724e-05, 'lstm.bias_ih_l0': 0.0009548733360134065, 'lstm.bias_hh_l0': 0.0009548733360134065, 'classifier.weight': 0.008902967907488346, 'classifier.bias': 0.08343301713466644}\n",
            "Epoch 13, Loss: 0.5595939755439758, Avg Gradients: {'lstm.weight_ih_l0': 5.011292523704469e-05, 'lstm.weight_hh_l0': 8.132847142405808e-05, 'lstm.bias_ih_l0': 0.0009549791575409472, 'lstm.bias_hh_l0': 0.0009549791575409472, 'classifier.weight': 0.00890154018998146, 'classifier.bias': 0.08344767242670059}\n",
            "Epoch 14, Loss: 0.55959153175354, Avg Gradients: {'lstm.weight_ih_l0': 5.0110946176573634e-05, 'lstm.weight_hh_l0': 8.132794755510986e-05, 'lstm.bias_ih_l0': 0.0009549895767122507, 'lstm.bias_hh_l0': 0.0009549895767122507, 'classifier.weight': 0.008901399560272694, 'classifier.bias': 0.08344912528991699}\n",
            "Epoch 15, Loss: 0.5595890879631042, Avg Gradients: {'lstm.weight_ih_l0': 5.0108945288229734e-05, 'lstm.weight_hh_l0': 8.132740913424641e-05, 'lstm.bias_ih_l0': 0.0009550002869218588, 'lstm.bias_hh_l0': 0.0009550002869218588, 'classifier.weight': 0.008901255205273628, 'classifier.bias': 0.08345059305429459}\n",
            "Epoch 16, Loss: 0.5595866441726685, Avg Gradients: {'lstm.weight_ih_l0': 5.010697350371629e-05, 'lstm.weight_hh_l0': 8.132692892104387e-05, 'lstm.bias_ih_l0': 0.0009550107643008232, 'lstm.bias_hh_l0': 0.0009550107643008232, 'classifier.weight': 0.008901115506887436, 'classifier.bias': 0.08345203846693039}\n",
            "Epoch 17, Loss: 0.5595864057540894, Avg Gradients: {'lstm.weight_ih_l0': 5.010676977690309e-05, 'lstm.weight_hh_l0': 8.132685616146773e-05, 'lstm.bias_ih_l0': 0.0009550119284540415, 'lstm.bias_hh_l0': 0.0009550119284540415, 'classifier.weight': 0.008901100605726242, 'classifier.bias': 0.08345219492912292}\n",
            "Epoch 18, Loss: 0.559586226940155, Avg Gradients: {'lstm.weight_ih_l0': 5.010657332604751e-05, 'lstm.weight_hh_l0': 8.132679795380682e-05, 'lstm.bias_ih_l0': 0.0009550127433612943, 'lstm.bias_hh_l0': 0.0009550127433612943, 'classifier.weight': 0.008901085704565048, 'classifier.bias': 0.08345231413841248}\n",
            "Epoch 19, Loss: 0.5595859885215759, Avg Gradients: {'lstm.weight_ih_l0': 5.010638778912835e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550138493068516, 'lstm.bias_hh_l0': 0.0009550138493068516, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345246315002441}\n",
            "Epoch 20, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132675429806113e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 21, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 22, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 23, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132677612593397e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.0834524855017662}\n",
            "Epoch 24, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 25, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 26, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 27, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637687519193e-05, 'lstm.weight_hh_l0': 8.132677612593397e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901072666049004, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 28, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 29, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 30, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 31, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 32, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 33, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 34, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 35, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 36, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 37, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 38, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 39, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 40, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 41, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 42, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 43, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 44, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 45, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 46, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901070803403854, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 47, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 48, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Epoch 49, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247805118561}\n",
            "Epoch 50, Loss: 0.5595859289169312, Avg Gradients: {'lstm.weight_ih_l0': 5.010637323721312e-05, 'lstm.weight_hh_l0': 8.132676884997636e-05, 'lstm.bias_ih_l0': 0.0009550139075145125, 'lstm.bias_hh_l0': 0.0009550139075145125, 'classifier.weight': 0.008901071734726429, 'classifier.bias': 0.08345247060060501}\n",
            "Accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GO0bvm6a02Fu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}